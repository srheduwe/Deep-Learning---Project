2022-12-28 18:37:09.697 INFO: {
    "bag_scale": 6,
    "beta": "-10",
    "canvas_size": 6,
    "clip_ratio": 0.2,
    "cutoff": 4.0,
    "data_dir": "runs/CH3NO_painn/data",
    "device": "cuda",
    "discount": 1.0,
    "entropy_coef": 0.06,
    "eval_formulas": "CH3NO",
    "eval_freq": 1,
    "formulas": "CH3NO",
    "gradient_clip": 0.5,
    "keep_models": false,
    "lam": 1.0,
    "learning_rate": 0.0003,
    "load_latest": false,
    "load_model": null,
    "log_dir": "runs/CH3NO_painn/logs",
    "log_level": "DEBUG",
    "max_mean_distance": 1.8,
    "max_num_steps": 30000,
    "max_num_train_iters": 10,
    "max_solo_distance": 2.0,
    "maxl": 4,
    "min_atomic_distance": 0.6,
    "min_mean_distance": 0.8,
    "min_reward": -20.0,
    "mini_batch_size": 64,
    "model": "painn",
    "model_dir": "runs/CH3NO_painn/models",
    "name": "CH3NO_painn",
    "network_width": 128,
    "num_cg_levels": 3,
    "num_channels_hidden": 10,
    "num_channels_per_element": 4,
    "num_envs": 12,
    "num_eval_episodes": null,
    "num_gaussians": 3,
    "num_interactions": 3,
    "num_steps_per_iter": 216,
    "optimizer": "adam",
    "results_dir": "runs/CH3NO_painn/results",
    "save_freq": 10,
    "save_rollouts": "train",
    "seed": 1,
    "symbols": "X,C,H,N,O",
    "target_kl": 0.03,
    "update_edges": true,
    "vf_coef": 0.001
}
2022-12-28 18:37:09.734 INFO: CUDA Device: 0
2022-12-28 18:37:09.735 INFO: Training bags: ['CH3NO']
2022-12-28 18:37:09.735 INFO: Evaluation bags: ['CH3NO']
2022-12-28 18:37:12.499 INFO: Number of parameters: 241966
2022-12-28 18:37:12.512 INFO: Starting PPO
2022-12-28 18:37:12.512 INFO: Iteration: 0/137, steps: 0
2022-12-28 18:37:19.268 DEBUG: There is a single atom floating around
2022-12-28 18:37:30.527 DEBUG: There is a single atom floating around
2022-12-28 18:37:33.146 DEBUG: There is a single atom floating around
2022-12-28 18:37:33.147 DEBUG: There is a single atom floating around
2022-12-28 18:37:33.148 DEBUG: There is a single atom floating around
2022-12-28 18:37:34.884 DEBUG: There is a single atom floating around
2022-12-28 18:37:38.445 DEBUG: There is a single atom floating around
2022-12-28 18:37:39.734 DEBUG: There is a single atom floating around
2022-12-28 18:37:50.835 DEBUG: There is a single atom floating around
2022-12-28 18:37:54.989 DEBUG: There is a single atom floating around
2022-12-28 18:37:59.243 DEBUG: There is a single atom floating around
2022-12-28 18:38:15.710 DEBUG: There is a single atom floating around
2022-12-28 18:38:16.007 DEBUG: There is a single atom floating around
2022-12-28 18:38:18.052 INFO: Training rollout: return=-6.492 (9.7), episode length=5.6
2022-12-28 18:38:18.053 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 18:38:18.056 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-0_train.pkl
2022-12-28 18:38:22.101 DEBUG: Taking gradient step
2022-12-28 18:38:22.111 DEBUG: Loss 0: {'policy_loss': -0.00897098204549015, 'entropy_loss': -0.0814263429492712, 'vf_loss': 0.12485386483692472, 'total_loss': 0.03445653984216336, 'approx_kl': -8.040418286725526e-08, 'clip_fraction': 0.0, 'grad_norm': 11.700532913208008}
2022-12-28 18:38:26.376 DEBUG: Early stopping at step 1 for reaching max KL.
2022-12-28 18:38:26.377 INFO: Optimization: policy loss=-0.009, vf loss=0.125, entropy loss=-0.081, total loss=0.034, num steps=1
2022-12-28 18:38:26.377 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 18:38:28.491 DEBUG: Atoms are too close
2022-12-28 18:38:28.493 INFO: Evaluation rollout: return=-19.078 (0.0), episode length=6.0
2022-12-28 18:38:28.494 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 18:38:28.497 DEBUG: Saving model: runs/CH3NO_painn/models/CH3NO_painn_run-1_steps-216.model
2022-12-28 18:38:28.527 INFO: Iteration: 1/137, steps: 216
2022-12-28 18:38:33.909 DEBUG: There is a single atom floating around
2022-12-28 18:38:45.220 DEBUG: There is a single atom floating around
2022-12-28 18:38:48.422 DEBUG: There is a single atom floating around
2022-12-28 18:38:48.424 DEBUG: There is a single atom floating around
2022-12-28 18:38:48.579 DEBUG: There is a single atom floating around
2022-12-28 18:39:09.770 DEBUG: Atoms are too close
2022-12-28 18:39:10.927 DEBUG: There is a single atom floating around
2022-12-28 18:39:11.246 DEBUG: There is a single atom floating around
2022-12-28 18:39:16.088 DEBUG: There is a single atom floating around
2022-12-28 18:39:22.072 DEBUG: There is a single atom floating around
2022-12-28 18:39:26.516 DEBUG: Atoms are too close
2022-12-28 18:39:26.517 DEBUG: Atoms are too close
2022-12-28 18:39:27.466 DEBUG: There is a single atom floating around
2022-12-28 18:39:30.282 DEBUG: There is a single atom floating around
2022-12-28 18:39:31.934 INFO: Training rollout: return=-7.084 (9.8), episode length=5.6
2022-12-28 18:39:31.936 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 18:39:31.938 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-216_train.pkl
2022-12-28 18:39:36.424 DEBUG: Taking gradient step
2022-12-28 18:39:36.433 DEBUG: Loss 0: {'policy_loss': -0.013163214981053613, 'entropy_loss': -0.08195256628096104, 'vf_loss': 0.12998604647713438, 'total_loss': 0.03487026521511973, 'approx_kl': 8.746671298354158e-08, 'clip_fraction': 0.0, 'grad_norm': 22.0053768157959}
2022-12-28 18:39:40.668 DEBUG: Taking gradient step
2022-12-28 18:39:40.676 DEBUG: Loss 1: {'policy_loss': 0.04820534428399975, 'entropy_loss': -0.08253663033246994, 'vf_loss': 0.1333665771937516, 'total_loss': 0.09903529114528144, 'approx_kl': 0.032782758586108685, 'clip_fraction': 0.3958333358168602, 'grad_norm': 27.44932746887207}
2022-12-28 18:39:44.902 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-28 18:39:44.903 INFO: Optimization: policy loss=0.048, vf loss=0.133, entropy loss=-0.083, total loss=0.099, num steps=2
2022-12-28 18:39:44.903 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 18:39:47.392 INFO: Evaluation rollout: return=0.983 (0.0), episode length=6.0
2022-12-28 18:39:47.393 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 18:39:47.395 INFO: Iteration: 2/137, steps: 432
2022-12-28 18:40:04.084 DEBUG: Atoms are too close
2022-12-28 18:40:06.437 DEBUG: There is a single atom floating around
2022-12-28 18:40:27.333 DEBUG: Atoms are too close
2022-12-28 18:40:51.880 DEBUG: There is a single atom floating around
2022-12-28 18:40:53.966 INFO: Training rollout: return=-1.468 (6.3), episode length=5.9
2022-12-28 18:40:53.968 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 18:40:53.972 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-432_train.pkl
2022-12-28 18:40:58.360 DEBUG: Taking gradient step
2022-12-28 18:40:58.369 DEBUG: Loss 0: {'policy_loss': 0.013483067978788899, 'entropy_loss': -0.0840765256434679, 'vf_loss': 0.04171267069740983, 'total_loss': -0.028880786967269166, 'approx_kl': 1.0399769045932317e-08, 'clip_fraction': 0.0, 'grad_norm': 14.473773956298828}
2022-12-28 18:41:02.627 DEBUG: Taking gradient step
2022-12-28 18:41:02.636 DEBUG: Loss 1: {'policy_loss': -0.04209666567643545, 'entropy_loss': -0.08325274474918842, 'vf_loss': 0.03863078767042397, 'total_loss': -0.0867186227551999, 'approx_kl': 0.037662408547475934, 'clip_fraction': 0.2265625, 'grad_norm': 7.36665153503418}
2022-12-28 18:41:06.895 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-28 18:41:06.896 INFO: Optimization: policy loss=-0.042, vf loss=0.039, entropy loss=-0.083, total loss=-0.087, num steps=2
2022-12-28 18:41:06.897 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 18:41:09.469 INFO: Evaluation rollout: return=0.913 (0.0), episode length=6.0
2022-12-28 18:41:09.470 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 18:41:09.474 INFO: Iteration: 3/137, steps: 648
2022-12-28 18:41:30.508 DEBUG: There is a single atom floating around
2022-12-28 18:41:36.083 DEBUG: There is a single atom floating around
2022-12-28 18:41:58.333 DEBUG: There is a single atom floating around
2022-12-28 18:41:59.572 DEBUG: There is a single atom floating around
2022-12-28 18:42:05.194 DEBUG: There is a single atom floating around
2022-12-28 18:42:11.402 DEBUG: Atoms are too close
2022-12-28 18:42:12.792 DEBUG: There is a single atom floating around
2022-12-28 18:42:14.024 DEBUG: There is a single atom floating around
2022-12-28 18:42:16.057 INFO: Training rollout: return=-3.899 (8.4), episode length=5.6
2022-12-28 18:42:16.058 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 18:42:16.061 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-648_train.pkl
2022-12-28 18:42:20.407 DEBUG: Taking gradient step
2022-12-28 18:42:20.416 DEBUG: Loss 0: {'policy_loss': -0.06158442453533637, 'entropy_loss': -0.08518272079527378, 'vf_loss': 0.049247145304896094, 'total_loss': -0.09752000002571407, 'approx_kl': 6.216578185558319e-08, 'clip_fraction': 0.0, 'grad_norm': 17.827829360961914}
2022-12-28 18:42:24.690 DEBUG: Taking gradient step
2022-12-28 18:42:24.699 DEBUG: Loss 1: {'policy_loss': -0.02459566640075234, 'entropy_loss': -0.08552877604961395, 'vf_loss': 0.05813776829239814, 'total_loss': -0.051986674157968156, 'approx_kl': 0.014935379615053535, 'clip_fraction': 0.1796875, 'grad_norm': 6.835795879364014}
2022-12-28 18:42:28.822 DEBUG: Taking gradient step
2022-12-28 18:42:28.830 DEBUG: Loss 2: {'policy_loss': 0.009000731302485424, 'entropy_loss': -0.0861956812441349, 'vf_loss': 0.06286061100620624, 'total_loss': -0.014334338935443239, 'approx_kl': 0.038172680186107755, 'clip_fraction': 0.34765625, 'grad_norm': 7.8838372230529785}
2022-12-28 18:42:33.016 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-28 18:42:33.016 INFO: Optimization: policy loss=0.009, vf loss=0.063, entropy loss=-0.086, total loss=-0.014, num steps=3
2022-12-28 18:42:33.017 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 18:42:35.246 DEBUG: Atoms are too close
2022-12-28 18:42:35.249 INFO: Evaluation rollout: return=-19.254 (0.0), episode length=6.0
2022-12-28 18:42:35.250 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 18:42:35.252 INFO: Iteration: 4/137, steps: 864
2022-12-28 18:42:56.148 DEBUG: There is a single atom floating around
2022-12-28 18:43:39.832 DEBUG: Atoms are too close
2022-12-28 18:43:40.784 DEBUG: Atoms are too close
2022-12-28 18:43:42.712 INFO: Training rollout: return=-0.981 (5.6), episode length=6.0
2022-12-28 18:43:42.714 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 18:43:42.717 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-864_train.pkl
2022-12-28 18:43:47.122 DEBUG: Taking gradient step
2022-12-28 18:43:47.131 DEBUG: Loss 0: {'policy_loss': -0.04770297565520348, 'entropy_loss': -0.08570300228893757, 'vf_loss': 0.027094323026705884, 'total_loss': -0.10631165491743516, 'approx_kl': -2.4757657257623578e-08, 'clip_fraction': 0.0, 'grad_norm': 14.320113182067871}
2022-12-28 18:43:51.466 DEBUG: Taking gradient step
2022-12-28 18:43:51.480 DEBUG: Loss 1: {'policy_loss': 0.02597491340806666, 'entropy_loss': -0.08691231906414032, 'vf_loss': 0.03662093276077645, 'total_loss': -0.024316472895297224, 'approx_kl': 0.00637505785562098, 'clip_fraction': 0.1236979179084301, 'grad_norm': 8.659751892089844}
2022-12-28 18:43:55.761 DEBUG: Taking gradient step
2022-12-28 18:43:55.769 DEBUG: Loss 2: {'policy_loss': -0.030786394367224825, 'entropy_loss': -0.08709251508116722, 'vf_loss': 0.031788040974481666, 'total_loss': -0.08609086847391038, 'approx_kl': 0.024542461847886443, 'clip_fraction': 0.28515625, 'grad_norm': 7.873310565948486}
2022-12-28 18:43:59.998 DEBUG: Taking gradient step
2022-12-28 18:44:00.010 DEBUG: Loss 3: {'policy_loss': -0.028058758919259266, 'entropy_loss': -0.08628291636705399, 'vf_loss': 0.031318266160625705, 'total_loss': -0.08302340912568755, 'approx_kl': 0.0430881034117192, 'clip_fraction': 0.3294270858168602, 'grad_norm': 7.20075798034668}
2022-12-28 18:44:04.244 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-28 18:44:04.244 INFO: Optimization: policy loss=-0.028, vf loss=0.031, entropy loss=-0.086, total loss=-0.083, num steps=4
2022-12-28 18:44:04.245 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 18:44:06.472 DEBUG: Atoms are too close
2022-12-28 18:44:06.474 INFO: Evaluation rollout: return=-19.231 (0.0), episode length=6.0
2022-12-28 18:44:06.475 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 18:44:06.478 INFO: Iteration: 5/137, steps: 1080
2022-12-28 18:44:55.559 DEBUG: There is a single atom floating around
2022-12-28 18:45:13.113 DEBUG: There is a single atom floating around
2022-12-28 18:45:14.347 INFO: Training rollout: return=-0.377 (4.7), episode length=5.9
2022-12-28 18:45:14.348 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 18:45:14.351 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-1080_train.pkl
2022-12-28 18:45:18.722 DEBUG: Taking gradient step
2022-12-28 18:45:18.732 DEBUG: Loss 0: {'policy_loss': -0.03834070728016901, 'entropy_loss': -0.08440552465617657, 'vf_loss': 0.013114397250653182, 'total_loss': -0.10963183468569239, 'approx_kl': -3.1043967396726657e-10, 'clip_fraction': 0.0, 'grad_norm': 9.495051383972168}
2022-12-28 18:45:22.957 DEBUG: Taking gradient step
2022-12-28 18:45:22.965 DEBUG: Loss 1: {'policy_loss': -0.011195784364922523, 'entropy_loss': -0.08291798643767834, 'vf_loss': 0.015136466784439266, 'total_loss': -0.07897730401816158, 'approx_kl': -0.01786924130283296, 'clip_fraction': 0.11848958395421505, 'grad_norm': 10.684846878051758}
2022-12-28 18:45:27.340 DEBUG: Taking gradient step
2022-12-28 18:45:27.348 DEBUG: Loss 2: {'policy_loss': -0.045368013740988894, 'entropy_loss': -0.08339152298867702, 'vf_loss': 0.013405762981885316, 'total_loss': -0.11535377374778061, 'approx_kl': 0.002477930160239339, 'clip_fraction': 0.3919270858168602, 'grad_norm': 6.059515476226807}
2022-12-28 18:45:31.404 DEBUG: Taking gradient step
2022-12-28 18:45:31.412 DEBUG: Loss 3: {'policy_loss': -0.0519011303307964, 'entropy_loss': -0.08385654538869858, 'vf_loss': 0.013492942752207545, 'total_loss': -0.12226473296728743, 'approx_kl': -0.009838273981586099, 'clip_fraction': 0.44921875, 'grad_norm': 5.160144329071045}
2022-12-28 18:45:35.602 DEBUG: Taking gradient step
2022-12-28 18:45:35.611 DEBUG: Loss 4: {'policy_loss': -0.05496310330592538, 'entropy_loss': -0.08370030671358109, 'vf_loss': 0.013406976960204221, 'total_loss': -0.12525643305930223, 'approx_kl': -0.0026935976929962635, 'clip_fraction': 0.4296875, 'grad_norm': 3.5602049827575684}
2022-12-28 18:45:39.832 DEBUG: Taking gradient step
2022-12-28 18:45:39.840 DEBUG: Loss 5: {'policy_loss': -0.023262679678232704, 'entropy_loss': -0.08321393467485905, 'vf_loss': 0.015397155804497312, 'total_loss': -0.09107945854859444, 'approx_kl': 0.01787257776595652, 'clip_fraction': 0.3971354216337204, 'grad_norm': 4.59710693359375}
2022-12-28 18:45:44.270 DEBUG: Taking gradient step
2022-12-28 18:45:44.278 DEBUG: Loss 6: {'policy_loss': -0.04046505724815984, 'entropy_loss': -0.08401454985141754, 'vf_loss': 0.0152625047969055, 'total_loss': -0.10921710230267188, 'approx_kl': -0.00915523199364543, 'clip_fraction': 0.4609375, 'grad_norm': 5.405929088592529}
2022-12-28 18:45:48.484 DEBUG: Taking gradient step
2022-12-28 18:45:48.492 DEBUG: Loss 7: {'policy_loss': -0.009557633065162267, 'entropy_loss': -0.08369358628988266, 'vf_loss': 0.017504262408977886, 'total_loss': -0.07574695694606705, 'approx_kl': -0.028550319373607635, 'clip_fraction': 0.3997395858168602, 'grad_norm': 6.037788391113281}
2022-12-28 18:45:52.728 DEBUG: Taking gradient step
2022-12-28 18:45:52.737 DEBUG: Loss 8: {'policy_loss': -0.02694620183727802, 'entropy_loss': -0.0831356979906559, 'vf_loss': 0.015419866250874699, 'total_loss': -0.09466203357705923, 'approx_kl': -0.02492724102921784, 'clip_fraction': 0.4505208358168602, 'grad_norm': 3.775895357131958}
2022-12-28 18:45:56.905 DEBUG: Taking gradient step
2022-12-28 18:45:56.913 DEBUG: Loss 9: {'policy_loss': -0.06853114909174535, 'entropy_loss': -0.08360259048640728, 'vf_loss': 0.012706812857042936, 'total_loss': -0.13942692672110968, 'approx_kl': -0.05445930175483227, 'clip_fraction': 0.4309895858168602, 'grad_norm': 3.47514271736145}
2022-12-28 18:45:56.913 INFO: Optimization: policy loss=-0.069, vf loss=0.013, entropy loss=-0.084, total loss=-0.139, num steps=10
2022-12-28 18:45:56.914 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 18:45:59.248 DEBUG: Atoms are too close
2022-12-28 18:45:59.250 INFO: Evaluation rollout: return=-19.230 (0.0), episode length=6.0
2022-12-28 18:45:59.250 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 18:45:59.253 INFO: Iteration: 6/137, steps: 1296
2022-12-28 18:46:19.086 DEBUG: There is a single atom floating around
2022-12-28 18:47:03.865 DEBUG: There is a single atom floating around
2022-12-28 18:47:06.663 INFO: Training rollout: return=-0.463 (4.6), episode length=6.0
2022-12-28 18:47:06.665 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 18:47:06.667 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-1296_train.pkl
2022-12-28 18:47:11.123 DEBUG: Taking gradient step
2022-12-28 18:47:11.132 DEBUG: Loss 0: {'policy_loss': -0.012685813422087508, 'entropy_loss': -0.08563465811312199, 'vf_loss': 0.02091775699095223, 'total_loss': -0.07740271454425726, 'approx_kl': 2.2972622915062857e-08, 'clip_fraction': 0.0, 'grad_norm': 16.265304565429688}
2022-12-28 18:47:15.333 DEBUG: Taking gradient step
2022-12-28 18:47:15.341 DEBUG: Loss 1: {'policy_loss': 0.01707473372031931, 'entropy_loss': -0.08462328277528286, 'vf_loss': 0.023387933009776575, 'total_loss': -0.044160616045186986, 'approx_kl': 0.00011044996790587902, 'clip_fraction': 0.02734375, 'grad_norm': 16.365079879760742}
2022-12-28 18:47:19.587 DEBUG: Taking gradient step
2022-12-28 18:47:19.595 DEBUG: Loss 2: {'policy_loss': -0.025268293217073103, 'entropy_loss': -0.08597027510404587, 'vf_loss': 0.020918142727054462, 'total_loss': -0.0903204255940645, 'approx_kl': 0.0029046188574284315, 'clip_fraction': 0.16145833395421505, 'grad_norm': 12.509605407714844}
2022-12-28 18:47:23.885 DEBUG: Taking gradient step
2022-12-28 18:47:23.894 DEBUG: Loss 3: {'policy_loss': 0.018748684605258345, 'entropy_loss': -0.08542589470744133, 'vf_loss': 0.02566687104887007, 'total_loss': -0.041010339053312916, 'approx_kl': 0.008055646438151598, 'clip_fraction': 0.2578125, 'grad_norm': 7.366957664489746}
2022-12-28 18:47:28.062 DEBUG: Taking gradient step
2022-12-28 18:47:28.071 DEBUG: Loss 4: {'policy_loss': -0.013577805169848543, 'entropy_loss': -0.08464946784079075, 'vf_loss': 0.023234950063059694, 'total_loss': -0.0749923229475796, 'approx_kl': 0.02925450960174203, 'clip_fraction': 0.3763020858168602, 'grad_norm': 5.476131439208984}
2022-12-28 18:47:32.248 DEBUG: Taking gradient step
2022-12-28 18:47:32.257 DEBUG: Loss 5: {'policy_loss': -0.05040449333804857, 'entropy_loss': -0.08512519299983978, 'vf_loss': 0.018372867394703053, 'total_loss': -0.1171568189431853, 'approx_kl': 0.033129796385765076, 'clip_fraction': 0.4348958358168602, 'grad_norm': 5.322137355804443}
2022-12-28 18:47:36.439 DEBUG: Taking gradient step
2022-12-28 18:47:36.447 DEBUG: Loss 6: {'policy_loss': -0.041145818041202806, 'entropy_loss': -0.08591180108487606, 'vf_loss': 0.020855232215189836, 'total_loss': -0.10620238691088901, 'approx_kl': 0.025068025570362806, 'clip_fraction': 0.4661458432674408, 'grad_norm': 5.546867370605469}
2022-12-28 18:47:40.629 DEBUG: Taking gradient step
2022-12-28 18:47:40.641 DEBUG: Loss 7: {'policy_loss': -0.05009713117770617, 'entropy_loss': -0.08480180241167545, 'vf_loss': 0.02084031191180047, 'total_loss': -0.11405862167758116, 'approx_kl': 0.0037598642520606518, 'clip_fraction': 0.453125, 'grad_norm': 4.5910468101501465}
2022-12-28 18:47:44.824 DEBUG: Taking gradient step
2022-12-28 18:47:44.833 DEBUG: Loss 8: {'policy_loss': -0.07120982784670196, 'entropy_loss': -0.08547849953174591, 'vf_loss': 0.018326908976701296, 'total_loss': -0.1383614184017466, 'approx_kl': -0.03286370821297169, 'clip_fraction': 0.40234375, 'grad_norm': 5.784430980682373}
2022-12-28 18:47:49.058 DEBUG: Taking gradient step
2022-12-28 18:47:49.066 DEBUG: Loss 9: {'policy_loss': -0.0395975452095836, 'entropy_loss': -0.08474071882665157, 'vf_loss': 0.020640893639749143, 'total_loss': -0.10369737039648602, 'approx_kl': -0.04310984257608652, 'clip_fraction': 0.38671875, 'grad_norm': 7.824042797088623}
2022-12-28 18:47:49.067 INFO: Optimization: policy loss=-0.040, vf loss=0.021, entropy loss=-0.085, total loss=-0.104, num steps=10
2022-12-28 18:47:49.067 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 18:47:51.278 DEBUG: Atoms are too close
2022-12-28 18:47:51.280 INFO: Evaluation rollout: return=-19.169 (0.0), episode length=6.0
2022-12-28 18:47:51.281 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 18:47:51.283 INFO: Iteration: 7/137, steps: 1512
2022-12-28 18:48:07.797 DEBUG: Atoms are too close
2022-12-28 18:48:35.923 DEBUG: Atoms are too close
2022-12-28 18:48:58.558 INFO: Training rollout: return=-0.417 (4.7), episode length=6.0
2022-12-28 18:48:58.560 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 18:48:58.563 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-1512_train.pkl
2022-12-28 18:49:02.838 DEBUG: Taking gradient step
2022-12-28 18:49:02.847 DEBUG: Loss 0: {'policy_loss': 0.030161992834142937, 'entropy_loss': -0.08468759432435036, 'vf_loss': 0.02252837954607334, 'total_loss': -0.03199722194413409, 'approx_kl': 2.964710432706852e-08, 'clip_fraction': 0.0, 'grad_norm': 17.104507446289062}
2022-12-28 18:49:07.157 DEBUG: Taking gradient step
2022-12-28 18:49:07.166 DEBUG: Loss 1: {'policy_loss': 0.0065055968274662125, 'entropy_loss': -0.08560254611074924, 'vf_loss': 0.022467838247159103, 'total_loss': -0.05662911103612393, 'approx_kl': 0.012969681527465582, 'clip_fraction': 0.057291666977107525, 'grad_norm': 12.317764282226562}
2022-12-28 18:49:11.409 DEBUG: Taking gradient step
2022-12-28 18:49:11.417 DEBUG: Loss 2: {'policy_loss': -0.05285676022173469, 'entropy_loss': -0.08509154617786407, 'vf_loss': 0.0174318827862974, 'total_loss': -0.12051642361330137, 'approx_kl': 0.028184822760522366, 'clip_fraction': 0.16015625, 'grad_norm': 8.848276138305664}
2022-12-28 18:49:15.640 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-28 18:49:15.641 INFO: Optimization: policy loss=-0.053, vf loss=0.017, entropy loss=-0.085, total loss=-0.121, num steps=3
2022-12-28 18:49:15.641 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 18:49:17.820 DEBUG: Atoms are too close
2022-12-28 18:49:17.822 INFO: Evaluation rollout: return=-19.153 (0.0), episode length=6.0
2022-12-28 18:49:17.823 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 18:49:17.826 INFO: Iteration: 8/137, steps: 1728
2022-12-28 18:49:38.324 DEBUG: Atoms are too close
2022-12-28 18:49:59.546 DEBUG: Atoms are too close
2022-12-28 18:49:59.548 DEBUG: Atoms are too close
2022-12-28 18:50:22.859 DEBUG: There is a single atom floating around
2022-12-28 18:50:25.360 INFO: Training rollout: return=-1.550 (6.3), episode length=6.0
2022-12-28 18:50:25.361 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 18:50:25.364 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-1728_train.pkl
2022-12-28 18:50:29.753 DEBUG: Taking gradient step
2022-12-28 18:50:29.761 DEBUG: Loss 0: {'policy_loss': -0.03563420750315155, 'entropy_loss': -0.08252566121518612, 'vf_loss': 0.03793346819689734, 'total_loss': -0.08022640052144034, 'approx_kl': 7.380731403827667e-08, 'clip_fraction': 0.0, 'grad_norm': 15.811296463012695}
2022-12-28 18:50:33.980 DEBUG: Taking gradient step
2022-12-28 18:50:33.988 DEBUG: Loss 1: {'policy_loss': -0.07264611537767057, 'entropy_loss': -0.08158723078668118, 'vf_loss': 0.03548974513357112, 'total_loss': -0.1187436010307806, 'approx_kl': 0.001903239288367331, 'clip_fraction': 0.07942708395421505, 'grad_norm': 10.004554748535156}
2022-12-28 18:50:38.243 DEBUG: Taking gradient step
2022-12-28 18:50:38.255 DEBUG: Loss 2: {'policy_loss': -0.05921813340511601, 'entropy_loss': -0.08156991750001907, 'vf_loss': 0.03781887962134316, 'total_loss': -0.10296917128379192, 'approx_kl': 0.029021698981523514, 'clip_fraction': 0.296875, 'grad_norm': 6.795590400695801}
2022-12-28 18:50:42.532 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-28 18:50:42.533 INFO: Optimization: policy loss=-0.059, vf loss=0.038, entropy loss=-0.082, total loss=-0.103, num steps=3
2022-12-28 18:50:42.533 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 18:50:44.712 DEBUG: Atoms are too close
2022-12-28 18:50:44.714 INFO: Evaluation rollout: return=-19.186 (0.0), episode length=6.0
2022-12-28 18:50:44.715 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 18:50:44.717 INFO: Iteration: 9/137, steps: 1944
2022-12-28 18:51:22.288 DEBUG: Atoms are too close
2022-12-28 18:51:23.460 DEBUG: Atoms are too close
2022-12-28 18:51:25.772 DEBUG: Atoms are too close
2022-12-28 18:51:46.961 DEBUG: Atoms are too close
2022-12-28 18:51:47.993 DEBUG: Atoms are too close
2022-12-28 18:51:50.832 INFO: Training rollout: return=-2.100 (7.1), episode length=5.9
2022-12-28 18:51:50.834 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 18:51:50.837 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-1944_train.pkl
2022-12-28 18:51:54.953 DEBUG: Taking gradient step
2022-12-28 18:51:54.962 DEBUG: Loss 0: {'policy_loss': 0.02077906531025923, 'entropy_loss': -0.08279859647154808, 'vf_loss': 0.05126248580236372, 'total_loss': -0.010757045358925126, 'approx_kl': -3.7640951688899804e-08, 'clip_fraction': 0.0, 'grad_norm': 18.503124237060547}
2022-12-28 18:51:59.099 DEBUG: Taking gradient step
2022-12-28 18:51:59.107 DEBUG: Loss 1: {'policy_loss': -0.056305210944293305, 'entropy_loss': -0.08323907665908337, 'vf_loss': 0.04394927978170248, 'total_loss': -0.09559500782167421, 'approx_kl': -0.012246343307197094, 'clip_fraction': 0.05208333395421505, 'grad_norm': 11.371368408203125}
2022-12-28 18:52:02.860 DEBUG: Taking gradient step
2022-12-28 18:52:02.868 DEBUG: Loss 2: {'policy_loss': 0.016537302022911385, 'entropy_loss': -0.08277560211718082, 'vf_loss': 0.054877907680986174, 'total_loss': -0.011360392413283266, 'approx_kl': -0.004041381762363017, 'clip_fraction': 0.1927083358168602, 'grad_norm': 12.448204040527344}
2022-12-28 18:52:07.071 DEBUG: Taking gradient step
2022-12-28 18:52:07.079 DEBUG: Loss 3: {'policy_loss': -0.054081284337982705, 'entropy_loss': -0.0837358757853508, 'vf_loss': 0.045806025537010006, 'total_loss': -0.0920111345863235, 'approx_kl': 0.0036501861177384853, 'clip_fraction': 0.3020833358168602, 'grad_norm': 6.5825066566467285}
2022-12-28 18:52:11.275 DEBUG: Taking gradient step
2022-12-28 18:52:11.284 DEBUG: Loss 4: {'policy_loss': -0.018069830014075538, 'entropy_loss': -0.08362144231796265, 'vf_loss': 0.050253129028946374, 'total_loss': -0.051438143303091814, 'approx_kl': 0.02582368440926075, 'clip_fraction': 0.3385416716337204, 'grad_norm': 7.881582736968994}
2022-12-28 18:52:15.595 DEBUG: Taking gradient step
2022-12-28 18:52:15.603 DEBUG: Loss 5: {'policy_loss': -0.0670883167821102, 'entropy_loss': -0.08341451734304428, 'vf_loss': 0.04590398477782525, 'total_loss': -0.10459884934732924, 'approx_kl': 0.010709499008953571, 'clip_fraction': 0.36328125, 'grad_norm': 8.039029121398926}
2022-12-28 18:52:19.767 DEBUG: Taking gradient step
2022-12-28 18:52:19.775 DEBUG: Loss 6: {'policy_loss': -0.07723092975163429, 'entropy_loss': -0.08297543786466122, 'vf_loss': 0.043327842227634014, 'total_loss': -0.11687852538866148, 'approx_kl': 0.04484662692993879, 'clip_fraction': 0.3919270858168602, 'grad_norm': 8.707260131835938}
2022-12-28 18:52:24.035 DEBUG: Taking gradient step
2022-12-28 18:52:24.043 DEBUG: Loss 7: {'policy_loss': -0.0605323353167036, 'entropy_loss': -0.08333227224647999, 'vf_loss': 0.045694233925260425, 'total_loss': -0.09817037363792316, 'approx_kl': 0.029771386180073023, 'clip_fraction': 0.3763020858168602, 'grad_norm': 7.33411979675293}
2022-12-28 18:52:28.293 DEBUG: Taking gradient step
2022-12-28 18:52:28.301 DEBUG: Loss 8: {'policy_loss': -0.04668312410023512, 'entropy_loss': -0.08266421221196651, 'vf_loss': 0.04693684412779935, 'total_loss': -0.08241049218440227, 'approx_kl': 0.025896192528307438, 'clip_fraction': 0.4140625, 'grad_norm': 8.111804962158203}
2022-12-28 18:52:32.526 DEBUG: Taking gradient step
2022-12-28 18:52:32.534 DEBUG: Loss 9: {'policy_loss': -0.05010004365968148, 'entropy_loss': -0.08339474722743034, 'vf_loss': 0.04707059190315108, 'total_loss': -0.08642419898396074, 'approx_kl': 0.022247150540351868, 'clip_fraction': 0.3919270858168602, 'grad_norm': 8.628891944885254}
2022-12-28 18:52:32.534 INFO: Optimization: policy loss=-0.050, vf loss=0.047, entropy loss=-0.083, total loss=-0.086, num steps=10
2022-12-28 18:52:32.535 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 18:52:35.045 INFO: Evaluation rollout: return=0.892 (0.0), episode length=6.0
2022-12-28 18:52:35.047 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 18:52:35.050 INFO: Iteration: 10/137, steps: 2160
2022-12-28 18:52:51.853 DEBUG: Atoms are too close
2022-12-28 18:53:11.750 DEBUG: Atoms are too close
2022-12-28 18:53:39.887 DEBUG: Atoms are too close
2022-12-28 18:53:42.031 INFO: Training rollout: return=-0.981 (5.5), episode length=5.9
2022-12-28 18:53:42.033 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 18:53:42.035 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-2160_train.pkl
2022-12-28 18:53:45.512 DEBUG: Taking gradient step
2022-12-28 18:53:45.520 DEBUG: Loss 0: {'policy_loss': 0.005805257082230127, 'entropy_loss': -0.08323805220425129, 'vf_loss': 0.028272806202988682, 'total_loss': -0.04915998891903248, 'approx_kl': -4.509153583853731e-08, 'clip_fraction': 0.0, 'grad_norm': 16.293479919433594}
2022-12-28 18:53:49.715 DEBUG: Taking gradient step
2022-12-28 18:53:49.722 DEBUG: Loss 1: {'policy_loss': -0.05412128573101012, 'entropy_loss': -0.08310320414602757, 'vf_loss': 0.02385459964736824, 'total_loss': -0.11336989022966945, 'approx_kl': -0.005520908161997795, 'clip_fraction': 0.06380208395421505, 'grad_norm': 11.214488983154297}
2022-12-28 18:53:53.989 DEBUG: Taking gradient step
2022-12-28 18:53:53.998 DEBUG: Loss 2: {'policy_loss': -0.06132133764110154, 'entropy_loss': -0.08369236811995506, 'vf_loss': 0.02386720874529665, 'total_loss': -0.12114649701575995, 'approx_kl': 0.0008423595572821796, 'clip_fraction': 0.1875, 'grad_norm': 7.6860737800598145}
2022-12-28 18:53:58.208 DEBUG: Taking gradient step
2022-12-28 18:53:58.218 DEBUG: Loss 3: {'policy_loss': 0.01162957666480604, 'entropy_loss': -0.08321711048483849, 'vf_loss': 0.030626768488736498, 'total_loss': -0.04096076533129596, 'approx_kl': 0.006091538583859801, 'clip_fraction': 0.3372395858168602, 'grad_norm': 10.384119987487793}
2022-12-28 18:54:02.433 DEBUG: Taking gradient step
2022-12-28 18:54:02.441 DEBUG: Loss 4: {'policy_loss': -0.009968094842031028, 'entropy_loss': -0.08328038267791271, 'vf_loss': 0.030750566593044766, 'total_loss': -0.06249791092689896, 'approx_kl': 0.015452484600245953, 'clip_fraction': 0.42578125, 'grad_norm': 4.901885509490967}
2022-12-28 18:54:06.668 DEBUG: Taking gradient step
2022-12-28 18:54:06.677 DEBUG: Loss 5: {'policy_loss': -0.05825784102787831, 'entropy_loss': -0.08235575072467327, 'vf_loss': 0.02630009554694347, 'total_loss': -0.1143134962056081, 'approx_kl': 0.009171580895781517, 'clip_fraction': 0.4739583358168602, 'grad_norm': 5.394859790802002}
2022-12-28 18:54:10.819 DEBUG: Taking gradient step
2022-12-28 18:54:10.832 DEBUG: Loss 6: {'policy_loss': -0.05396722686160492, 'entropy_loss': -0.08324828557670116, 'vf_loss': 0.026261146251958342, 'total_loss': -0.11095436618634774, 'approx_kl': 0.021655128861311823, 'clip_fraction': 0.4921875, 'grad_norm': 6.423508167266846}
2022-12-28 18:54:15.072 DEBUG: Taking gradient step
2022-12-28 18:54:15.081 DEBUG: Loss 7: {'policy_loss': -0.07608487135145757, 'entropy_loss': -0.08313799649477005, 'vf_loss': 0.02394109227683003, 'total_loss': -0.13528177556939758, 'approx_kl': 0.021557794883847237, 'clip_fraction': 0.453125, 'grad_norm': 7.1875691413879395}
2022-12-28 18:54:19.376 DEBUG: Taking gradient step
2022-12-28 18:54:19.384 DEBUG: Loss 8: {'policy_loss': 0.004405304620753447, 'entropy_loss': -0.0823386050760746, 'vf_loss': 0.03273444081916693, 'total_loss': -0.045198859636154214, 'approx_kl': 0.019589609932154417, 'clip_fraction': 0.4427083358168602, 'grad_norm': 4.363068580627441}
2022-12-28 18:54:23.522 DEBUG: Taking gradient step
2022-12-28 18:54:23.530 DEBUG: Loss 9: {'policy_loss': -0.038686010529606775, 'entropy_loss': -0.08230144158005714, 'vf_loss': 0.028118818723501825, 'total_loss': -0.09286863338616208, 'approx_kl': 0.00034128734841942787, 'clip_fraction': 0.4075520858168602, 'grad_norm': 4.982272148132324}
2022-12-28 18:54:23.530 INFO: Optimization: policy loss=-0.039, vf loss=0.028, entropy loss=-0.082, total loss=-0.093, num steps=10
2022-12-28 18:54:23.531 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 18:54:25.778 DEBUG: Atoms are too close
2022-12-28 18:54:25.780 INFO: Evaluation rollout: return=-19.418 (0.0), episode length=6.0
2022-12-28 18:54:25.781 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 18:54:25.783 DEBUG: Deleting old model: runs/CH3NO_painn/models/CH3NO_painn_run-1_steps-216.model
2022-12-28 18:54:25.787 DEBUG: Saving model: runs/CH3NO_painn/models/CH3NO_painn_run-1_steps-2376.model
2022-12-28 18:54:25.811 INFO: Iteration: 11/137, steps: 2376
2022-12-28 18:54:42.828 DEBUG: Atoms are too close
2022-12-28 18:55:08.069 DEBUG: There is a single atom floating around
2022-12-28 18:55:32.349 DEBUG: Atoms are too close
2022-12-28 18:55:33.259 INFO: Training rollout: return=-0.929 (5.6), episode length=6.0
2022-12-28 18:55:33.260 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 18:55:33.263 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-2376_train.pkl
2022-12-28 18:55:37.675 DEBUG: Taking gradient step
2022-12-28 18:55:37.683 DEBUG: Loss 0: {'policy_loss': 0.002011812862184011, 'entropy_loss': -0.08420013263821602, 'vf_loss': 0.030055607297756633, 'total_loss': -0.05213271247827538, 'approx_kl': 1.5289213450842e-08, 'clip_fraction': 0.0, 'grad_norm': 14.580118179321289}
2022-12-28 18:55:41.945 DEBUG: Taking gradient step
2022-12-28 18:55:41.953 DEBUG: Loss 1: {'policy_loss': -0.03738100143363617, 'entropy_loss': -0.08516525663435459, 'vf_loss': 0.027927760890344305, 'total_loss': -0.09461849717764645, 'approx_kl': 0.014309496385976672, 'clip_fraction': 0.09765625, 'grad_norm': 12.759906768798828}
2022-12-28 18:55:46.114 DEBUG: Taking gradient step
2022-12-28 18:55:46.123 DEBUG: Loss 2: {'policy_loss': -0.0037546214149799715, 'entropy_loss': -0.08479157835245132, 'vf_loss': 0.030371074271722406, 'total_loss': -0.05817512549570889, 'approx_kl': 0.044916583923622966, 'clip_fraction': 0.2513020858168602, 'grad_norm': 11.615623474121094}
2022-12-28 18:55:50.359 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-28 18:55:50.360 INFO: Optimization: policy loss=-0.004, vf loss=0.030, entropy loss=-0.085, total loss=-0.058, num steps=3
2022-12-28 18:55:50.361 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 18:55:52.369 DEBUG: Atoms are too close
2022-12-28 18:55:52.371 INFO: Evaluation rollout: return=-19.403 (0.0), episode length=6.0
2022-12-28 18:55:52.372 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 18:55:52.374 INFO: Iteration: 12/137, steps: 2592
2022-12-28 18:56:33.638 DEBUG: Atoms are too close
2022-12-28 18:56:57.300 DEBUG: Atoms are too close
2022-12-28 18:57:00.380 INFO: Training rollout: return=-0.360 (4.6), episode length=6.0
2022-12-28 18:57:00.381 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 18:57:00.384 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-2592_train.pkl
2022-12-28 18:57:04.394 DEBUG: Taking gradient step
2022-12-28 18:57:04.402 DEBUG: Loss 0: {'policy_loss': 0.018368475619172972, 'entropy_loss': -0.08181004226207733, 'vf_loss': 0.021783757112355927, 'total_loss': -0.04165780953054843, 'approx_kl': -6.05359673500061e-08, 'clip_fraction': 0.0, 'grad_norm': 21.229063034057617}
2022-12-28 18:57:08.611 DEBUG: Taking gradient step
2022-12-28 18:57:08.620 DEBUG: Loss 1: {'policy_loss': -0.015118052289182424, 'entropy_loss': -0.08231544494628906, 'vf_loss': 0.01960002514317924, 'total_loss': -0.07783347209229224, 'approx_kl': 0.013623625272884965, 'clip_fraction': 0.049479166977107525, 'grad_norm': 9.661837577819824}
2022-12-28 18:57:12.844 DEBUG: Taking gradient step
2022-12-28 18:57:12.852 DEBUG: Loss 2: {'policy_loss': -0.049196902896962165, 'entropy_loss': -0.08243022300302982, 'vf_loss': 0.017235572630583985, 'total_loss': -0.114391553269408, 'approx_kl': 0.02747014770284295, 'clip_fraction': 0.2109375, 'grad_norm': 10.079435348510742}
2022-12-28 18:57:17.134 DEBUG: Taking gradient step
2022-12-28 18:57:17.142 DEBUG: Loss 3: {'policy_loss': -0.028819597216055544, 'entropy_loss': -0.08243093080818653, 'vf_loss': 0.01930281028873517, 'total_loss': -0.09194771773550692, 'approx_kl': 0.028956420021131635, 'clip_fraction': 0.2916666716337204, 'grad_norm': 7.78797721862793}
2022-12-28 18:57:21.398 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-28 18:57:21.399 INFO: Optimization: policy loss=-0.029, vf loss=0.019, entropy loss=-0.082, total loss=-0.092, num steps=4
2022-12-28 18:57:21.400 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 18:57:24.052 INFO: Evaluation rollout: return=0.811 (0.0), episode length=6.0
2022-12-28 18:57:24.053 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 18:57:24.056 INFO: Iteration: 13/137, steps: 2808
2022-12-28 18:57:41.584 DEBUG: Atoms are too close
2022-12-28 18:57:41.924 DEBUG: Atoms are too close
2022-12-28 18:57:44.766 DEBUG: There is a single atom floating around
2022-12-28 18:58:27.759 DEBUG: Atoms are too close
2022-12-28 18:58:31.193 INFO: Training rollout: return=-1.500 (6.3), episode length=5.9
2022-12-28 18:58:31.195 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 18:58:31.197 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-2808_train.pkl
2022-12-28 18:58:35.230 DEBUG: Taking gradient step
2022-12-28 18:58:35.238 DEBUG: Loss 0: {'policy_loss': 0.01396548965847935, 'entropy_loss': -0.08514968492090702, 'vf_loss': 0.0384359304427164, 'total_loss': -0.03274826481971127, 'approx_kl': -2.3748725652694702e-08, 'clip_fraction': 0.0, 'grad_norm': 19.90219497680664}
2022-12-28 18:58:39.482 DEBUG: Taking gradient step
2022-12-28 18:58:39.490 DEBUG: Loss 1: {'policy_loss': 0.001850109797432272, 'entropy_loss': -0.08538618125021458, 'vf_loss': 0.03837935230439074, 'total_loss': -0.04515671914839156, 'approx_kl': 0.002803496550768614, 'clip_fraction': 0.03515625, 'grad_norm': 15.147473335266113}
2022-12-28 18:58:43.708 DEBUG: Taking gradient step
2022-12-28 18:58:43.716 DEBUG: Loss 2: {'policy_loss': -0.05752887027996406, 'entropy_loss': -0.08537049405276775, 'vf_loss': 0.03400770818138889, 'total_loss': -0.10889165615134293, 'approx_kl': 0.014644775161286816, 'clip_fraction': 0.1119791679084301, 'grad_norm': 7.915949821472168}
2022-12-28 18:58:47.928 DEBUG: Taking gradient step
2022-12-28 18:58:47.936 DEBUG: Loss 3: {'policy_loss': -0.003143019483380416, 'entropy_loss': -0.08458859845995903, 'vf_loss': 0.04065511826952094, 'total_loss': -0.0470764996738185, 'approx_kl': 0.03152385354042053, 'clip_fraction': 0.2044270858168602, 'grad_norm': 4.938083648681641}
2022-12-28 18:58:52.158 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-28 18:58:52.159 INFO: Optimization: policy loss=-0.003, vf loss=0.041, entropy loss=-0.085, total loss=-0.047, num steps=4
2022-12-28 18:58:52.160 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 18:58:54.797 INFO: Evaluation rollout: return=0.880 (0.0), episode length=6.0
2022-12-28 18:58:54.799 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 18:58:54.802 INFO: Iteration: 14/137, steps: 3024
2022-12-28 18:59:02.276 DEBUG: There is a single atom floating around
2022-12-28 18:59:10.229 DEBUG: Atoms are too close
2022-12-28 18:59:15.917 DEBUG: Atoms are too close
2022-12-28 18:59:41.587 DEBUG: Atoms are too close
2022-12-28 19:00:01.221 INFO: Training rollout: return=-1.461 (6.4), episode length=5.9
2022-12-28 19:00:01.223 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 19:00:01.225 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-3024_train.pkl
2022-12-28 19:00:05.300 DEBUG: Taking gradient step
2022-12-28 19:00:05.309 DEBUG: Loss 0: {'policy_loss': -0.0516621395985744, 'entropy_loss': -0.08648787625133991, 'vf_loss': 0.028545810540753672, 'total_loss': -0.10960420530916065, 'approx_kl': 4.2064737471037006e-08, 'clip_fraction': 0.0, 'grad_norm': 9.664634704589844}
2022-12-28 19:00:09.324 DEBUG: Taking gradient step
2022-12-28 19:00:09.333 DEBUG: Loss 1: {'policy_loss': 0.031317079479251386, 'entropy_loss': -0.08722187578678131, 'vf_loss': 0.03776118549889901, 'total_loss': -0.018143610808630903, 'approx_kl': 0.0012695849873125553, 'clip_fraction': 0.08333333395421505, 'grad_norm': 8.617044448852539}
2022-12-28 19:00:13.559 DEBUG: Taking gradient step
2022-12-28 19:00:13.571 DEBUG: Loss 2: {'policy_loss': 0.023085972683077743, 'entropy_loss': -0.08684596791863441, 'vf_loss': 0.03778281572831244, 'total_loss': -0.02597717950724423, 'approx_kl': 0.015422026626765728, 'clip_fraction': 0.2721354216337204, 'grad_norm': 8.004907608032227}
2022-12-28 19:00:17.830 DEBUG: Taking gradient step
2022-12-28 19:00:17.839 DEBUG: Loss 3: {'policy_loss': -0.07028599476113236, 'entropy_loss': -0.08613591082394123, 'vf_loss': 0.02847995215443584, 'total_loss': -0.12794195343063774, 'approx_kl': 0.02416424499824643, 'clip_fraction': 0.3984375, 'grad_norm': 9.689950942993164}
2022-12-28 19:00:22.077 DEBUG: Taking gradient step
2022-12-28 19:00:22.089 DEBUG: Loss 4: {'policy_loss': -0.04829196872719402, 'entropy_loss': -0.08673129789531231, 'vf_loss': 0.030787683026919428, 'total_loss': -0.1042355835955869, 'approx_kl': 0.011761993169784546, 'clip_fraction': 0.4244791716337204, 'grad_norm': 6.618195056915283}
2022-12-28 19:00:26.336 DEBUG: Taking gradient step
2022-12-28 19:00:26.345 DEBUG: Loss 5: {'policy_loss': 0.0033527447705058097, 'entropy_loss': -0.0875012669712305, 'vf_loss': 0.03762562896846034, 'total_loss': -0.046522893232264356, 'approx_kl': 0.025783746736124158, 'clip_fraction': 0.4674479216337204, 'grad_norm': 8.012430191040039}
2022-12-28 19:00:30.623 DEBUG: Taking gradient step
2022-12-28 19:00:30.632 DEBUG: Loss 6: {'policy_loss': -0.006679845776552937, 'entropy_loss': -0.08648624829947948, 'vf_loss': 0.037605408391461974, 'total_loss': -0.055560685684570454, 'approx_kl': 0.03579525230452418, 'clip_fraction': 0.44140625, 'grad_norm': 4.702743053436279}
2022-12-28 19:00:34.812 DEBUG: Taking gradient step
2022-12-28 19:00:34.821 DEBUG: Loss 7: {'policy_loss': -0.06506692407060989, 'entropy_loss': -0.08626998588442802, 'vf_loss': 0.03066419561213027, 'total_loss': -0.12067271434290763, 'approx_kl': 0.024152949918061495, 'clip_fraction': 0.37109375, 'grad_norm': 5.545276165008545}
2022-12-28 19:00:38.954 DEBUG: Taking gradient step
2022-12-28 19:00:38.966 DEBUG: Loss 8: {'policy_loss': -0.04717720238112554, 'entropy_loss': -0.0865546241402626, 'vf_loss': 0.03277861378867443, 'total_loss': -0.10095321273271371, 'approx_kl': 0.0007609534077346325, 'clip_fraction': 0.3893229216337204, 'grad_norm': 5.251945495605469}
2022-12-28 19:00:42.795 DEBUG: Taking gradient step
2022-12-28 19:00:42.803 DEBUG: Loss 9: {'policy_loss': 0.014512177448125663, 'entropy_loss': -0.0862660426646471, 'vf_loss': 0.03968973369043208, 'total_loss': -0.032064131526089376, 'approx_kl': 0.015490529360249639, 'clip_fraction': 0.38671875, 'grad_norm': 5.569720268249512}
2022-12-28 19:00:42.803 INFO: Optimization: policy loss=0.015, vf loss=0.040, entropy loss=-0.086, total loss=-0.032, num steps=10
2022-12-28 19:00:42.803 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 19:00:45.336 INFO: Evaluation rollout: return=0.828 (0.0), episode length=6.0
2022-12-28 19:00:45.337 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 19:00:45.340 INFO: Iteration: 15/137, steps: 3240
2022-12-28 19:01:24.398 DEBUG: Atoms are too close
2022-12-28 19:01:27.308 DEBUG: Atoms are too close
2022-12-28 19:01:53.228 INFO: Training rollout: return=-0.334 (4.6), episode length=6.0
2022-12-28 19:01:53.229 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 19:01:53.232 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-3240_train.pkl
2022-12-28 19:01:57.533 DEBUG: Taking gradient step
2022-12-28 19:01:57.541 DEBUG: Loss 0: {'policy_loss': -0.0031684104926041692, 'entropy_loss': -0.08468866162002087, 'vf_loss': 0.019036396752090123, 'total_loss': -0.06882067536053492, 'approx_kl': -5.541369318962097e-08, 'clip_fraction': 0.0, 'grad_norm': 22.64466667175293}
2022-12-28 19:02:01.891 DEBUG: Taking gradient step
2022-12-28 19:02:01.904 DEBUG: Loss 1: {'policy_loss': -0.045911140522605934, 'entropy_loss': -0.08416367322206497, 'vf_loss': 0.01690130312112243, 'total_loss': -0.11317351062354848, 'approx_kl': 0.009106460027396679, 'clip_fraction': 0.11067708395421505, 'grad_norm': 10.253180503845215}
2022-12-28 19:02:06.058 DEBUG: Taking gradient step
2022-12-28 19:02:06.068 DEBUG: Loss 2: {'policy_loss': -0.026917053754076464, 'entropy_loss': -0.08365927822887897, 'vf_loss': 0.019221873629903276, 'total_loss': -0.09135445835305217, 'approx_kl': 0.04038853268139064, 'clip_fraction': 0.2486979179084301, 'grad_norm': 7.47819709777832}
2022-12-28 19:02:10.275 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-28 19:02:10.276 INFO: Optimization: policy loss=-0.027, vf loss=0.019, entropy loss=-0.084, total loss=-0.091, num steps=3
2022-12-28 19:02:10.276 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 19:02:12.691 INFO: Evaluation rollout: return=0.728 (0.0), episode length=6.0
2022-12-28 19:02:12.693 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 19:02:12.696 INFO: Iteration: 16/137, steps: 3456
2022-12-28 19:02:32.506 DEBUG: Atoms are too close
2022-12-28 19:02:33.439 DEBUG: Atoms are too close
2022-12-28 19:02:56.125 DEBUG: Atoms are too close
2022-12-28 19:02:56.837 DEBUG: Atoms are too close
2022-12-28 19:03:13.854 DEBUG: Atoms are too close
2022-12-28 19:03:15.080 DEBUG: Atoms are too close
2022-12-28 19:03:18.925 INFO: Training rollout: return=-2.624 (7.5), episode length=5.9
2022-12-28 19:03:18.927 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 19:03:18.929 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-3456_train.pkl
2022-12-28 19:03:23.261 DEBUG: Taking gradient step
2022-12-28 19:03:23.269 DEBUG: Loss 0: {'policy_loss': -0.01412963535563019, 'entropy_loss': -0.08264948055148125, 'vf_loss': 0.05463296613884744, 'total_loss': -0.04214614976826399, 'approx_kl': -7.82310962677002e-08, 'clip_fraction': 0.0, 'grad_norm': 19.33246421813965}
2022-12-28 19:03:27.522 DEBUG: Taking gradient step
2022-12-28 19:03:27.534 DEBUG: Loss 1: {'policy_loss': 0.005212956488531088, 'entropy_loss': -0.08283345401287079, 'vf_loss': 0.058898228195000096, 'total_loss': -0.018722269329339597, 'approx_kl': 0.02332829963415861, 'clip_fraction': 0.11458333395421505, 'grad_norm': 12.746984481811523}
2022-12-28 19:03:31.703 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-28 19:03:31.703 INFO: Optimization: policy loss=0.005, vf loss=0.059, entropy loss=-0.083, total loss=-0.019, num steps=2
2022-12-28 19:03:31.704 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 19:03:34.208 INFO: Evaluation rollout: return=0.754 (0.0), episode length=6.0
2022-12-28 19:03:34.209 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 19:03:34.211 INFO: Iteration: 17/137, steps: 3672
2022-12-28 19:04:37.908 DEBUG: Atoms are too close
2022-12-28 19:04:37.909 DEBUG: Atoms are too close
2022-12-28 19:04:39.969 DEBUG: Atoms are too close
2022-12-28 19:04:40.656 DEBUG: Atoms are too close
2022-12-28 19:04:41.809 INFO: Training rollout: return=-1.461 (6.3), episode length=5.9
2022-12-28 19:04:41.811 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 19:04:41.813 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-3672_train.pkl
2022-12-28 19:04:46.207 DEBUG: Taking gradient step
2022-12-28 19:04:46.220 DEBUG: Loss 0: {'policy_loss': 0.013269160793851115, 'entropy_loss': -0.08385173790156841, 'vf_loss': 0.03809025724388279, 'total_loss': -0.032492319863834516, 'approx_kl': 6.783132633358946e-08, 'clip_fraction': 0.0, 'grad_norm': 15.830022811889648}
2022-12-28 19:04:50.423 DEBUG: Taking gradient step
2022-12-28 19:04:50.431 DEBUG: Loss 1: {'policy_loss': -0.06408294506015821, 'entropy_loss': -0.0835088025778532, 'vf_loss': 0.03164026945993509, 'total_loss': -0.11595147817807633, 'approx_kl': 0.012204635422676802, 'clip_fraction': 0.037760416977107525, 'grad_norm': 11.979388236999512}
2022-12-28 19:04:54.697 DEBUG: Taking gradient step
2022-12-28 19:04:54.705 DEBUG: Loss 2: {'policy_loss': -0.026977734168660908, 'entropy_loss': -0.08418066240847111, 'vf_loss': 0.03606676147419537, 'total_loss': -0.07509163510293665, 'approx_kl': 0.02653187746182084, 'clip_fraction': 0.19140625, 'grad_norm': 9.77102279663086}
2022-12-28 19:04:59.032 DEBUG: Taking gradient step
2022-12-28 19:04:59.040 DEBUG: Loss 3: {'policy_loss': 0.08128756516338505, 'entropy_loss': -0.08377071656286716, 'vf_loss': 0.04906880714289692, 'total_loss': 0.046585655743414806, 'approx_kl': 0.03607947286218405, 'clip_fraction': 0.2447916716337204, 'grad_norm': 13.160232543945312}
2022-12-28 19:05:03.195 DEBUG: Taking gradient step
2022-12-28 19:05:03.203 DEBUG: Loss 4: {'policy_loss': -0.07606035799027845, 'entropy_loss': -0.08359197899699211, 'vf_loss': 0.03153693030951579, 'total_loss': -0.12811540667775476, 'approx_kl': 0.026546373264864087, 'clip_fraction': 0.2734375, 'grad_norm': 6.272435665130615}
2022-12-28 19:05:07.411 DEBUG: Early stopping at step 5 for reaching max KL.
2022-12-28 19:05:07.411 INFO: Optimization: policy loss=-0.076, vf loss=0.032, entropy loss=-0.084, total loss=-0.128, num steps=5
2022-12-28 19:05:07.412 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 19:05:09.719 INFO: Evaluation rollout: return=0.743 (0.0), episode length=6.0
2022-12-28 19:05:09.720 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 19:05:09.722 INFO: Iteration: 18/137, steps: 3888
2022-12-28 19:05:23.154 DEBUG: There is a single atom floating around
2022-12-28 19:05:48.882 DEBUG: Atoms are too close
2022-12-28 19:06:00.252 DEBUG: Atoms are too close
2022-12-28 19:06:16.893 INFO: Training rollout: return=-0.986 (5.6), episode length=5.9
2022-12-28 19:06:16.895 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 19:06:16.897 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-3888_train.pkl
2022-12-28 19:06:21.314 DEBUG: Taking gradient step
2022-12-28 19:06:21.323 DEBUG: Loss 0: {'policy_loss': -0.013826507470255827, 'entropy_loss': -0.08501601219177246, 'vf_loss': 0.022108352998180703, 'total_loss': -0.07673416666384758, 'approx_kl': -8.017135399995823e-08, 'clip_fraction': 0.0, 'grad_norm': 8.819197654724121}
2022-12-28 19:06:25.646 DEBUG: Taking gradient step
2022-12-28 19:06:25.654 DEBUG: Loss 1: {'policy_loss': 0.036388210402959524, 'entropy_loss': -0.08402212522923946, 'vf_loss': 0.02626570731870871, 'total_loss': -0.021368207507571235, 'approx_kl': 0.0010974716860800982, 'clip_fraction': 0.0, 'grad_norm': 10.221501350402832}
2022-12-28 19:06:29.786 DEBUG: Taking gradient step
2022-12-28 19:06:29.794 DEBUG: Loss 2: {'policy_loss': -0.031913071493969575, 'entropy_loss': -0.08391517959535122, 'vf_loss': 0.02217158368449056, 'total_loss': -0.09365666740483022, 'approx_kl': -0.0029114671051502228, 'clip_fraction': 0.12890625, 'grad_norm': 7.045424461364746}
2022-12-28 19:06:34.030 DEBUG: Taking gradient step
2022-12-28 19:06:34.038 DEBUG: Loss 3: {'policy_loss': 0.015947586954749432, 'entropy_loss': -0.08433479256927967, 'vf_loss': 0.02664582410573635, 'total_loss': -0.041741381508793876, 'approx_kl': 0.03889611968770623, 'clip_fraction': 0.265625, 'grad_norm': 6.325174808502197}
2022-12-28 19:06:38.261 DEBUG: Taking gradient step
2022-12-28 19:06:38.269 DEBUG: Loss 4: {'policy_loss': 0.04171188605157849, 'entropy_loss': -0.08352894894778728, 'vf_loss': 0.02882702054377779, 'total_loss': -0.012990042352430994, 'approx_kl': 0.029549642000347376, 'clip_fraction': 0.3125, 'grad_norm': 7.0246148109436035}
2022-12-28 19:06:42.494 DEBUG: Taking gradient step
2022-12-28 19:06:42.503 DEBUG: Loss 5: {'policy_loss': -0.013189083063808883, 'entropy_loss': -0.08461484499275684, 'vf_loss': 0.024470415655839295, 'total_loss': -0.07333351240072643, 'approx_kl': 0.019435045775026083, 'clip_fraction': 0.32421875, 'grad_norm': 13.017335891723633}
2022-12-28 19:06:46.669 DEBUG: Taking gradient step
2022-12-28 19:06:46.679 DEBUG: Loss 6: {'policy_loss': -0.0387654594206904, 'entropy_loss': -0.0836816132068634, 'vf_loss': 0.021882345290819588, 'total_loss': -0.10056472733673422, 'approx_kl': 0.020188844529911876, 'clip_fraction': 0.35546875, 'grad_norm': 4.004779815673828}
2022-12-28 19:06:50.864 DEBUG: Taking gradient step
2022-12-28 19:06:50.872 DEBUG: Loss 7: {'policy_loss': -0.043637132405818166, 'entropy_loss': -0.08379777520895004, 'vf_loss': 0.02179524945494228, 'total_loss': -0.10563965815982593, 'approx_kl': 0.006600997410714626, 'clip_fraction': 0.3854166716337204, 'grad_norm': 4.903544902801514}
2022-12-28 19:06:55.236 DEBUG: Taking gradient step
2022-12-28 19:06:55.245 DEBUG: Loss 8: {'policy_loss': -0.008894515520097346, 'entropy_loss': -0.08378020860254765, 'vf_loss': 0.026196349283310046, 'total_loss': -0.06647837483933494, 'approx_kl': 0.0014259032905101776, 'clip_fraction': 0.4231770932674408, 'grad_norm': 5.432624816894531}
2022-12-28 19:06:59.453 DEBUG: Taking gradient step
2022-12-28 19:06:59.461 DEBUG: Loss 9: {'policy_loss': -0.052795812601143695, 'entropy_loss': -0.08416669443249702, 'vf_loss': 0.021912141336148428, 'total_loss': -0.11505036569749229, 'approx_kl': -0.000384641345590353, 'clip_fraction': 0.3802083358168602, 'grad_norm': 3.040684223175049}
2022-12-28 19:06:59.461 INFO: Optimization: policy loss=-0.053, vf loss=0.022, entropy loss=-0.084, total loss=-0.115, num steps=10
2022-12-28 19:06:59.462 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 19:07:01.962 INFO: Evaluation rollout: return=0.950 (0.0), episode length=6.0
2022-12-28 19:07:01.963 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 19:07:01.967 INFO: Iteration: 19/137, steps: 4104
2022-12-28 19:07:39.369 DEBUG: Atoms are too close
2022-12-28 19:07:45.838 DEBUG: Atoms are too close
2022-12-28 19:07:50.502 DEBUG: There is a single atom floating around
2022-12-28 19:08:08.678 INFO: Training rollout: return=-1.062 (5.6), episode length=5.9
2022-12-28 19:08:08.680 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 19:08:08.682 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-4104_train.pkl
2022-12-28 19:08:12.962 DEBUG: Taking gradient step
2022-12-28 19:08:12.972 DEBUG: Loss 0: {'policy_loss': -0.010490693511136524, 'entropy_loss': -0.08180488273501396, 'vf_loss': 0.02185534040263859, 'total_loss': -0.07044023584351189, 'approx_kl': -1.6298145055770874e-08, 'clip_fraction': 0.0, 'grad_norm': 13.631524085998535}
2022-12-28 19:08:17.280 DEBUG: Taking gradient step
2022-12-28 19:08:17.290 DEBUG: Loss 1: {'policy_loss': 0.07982862302818239, 'entropy_loss': -0.0821752306073904, 'vf_loss': 0.0309209213423171, 'total_loss': 0.028574313763109094, 'approx_kl': 0.03570558992214501, 'clip_fraction': 0.1666666679084301, 'grad_norm': 9.462782859802246}
2022-12-28 19:08:21.521 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-28 19:08:21.522 INFO: Optimization: policy loss=0.080, vf loss=0.031, entropy loss=-0.082, total loss=0.029, num steps=2
2022-12-28 19:08:21.523 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 19:08:24.086 INFO: Evaluation rollout: return=0.968 (0.0), episode length=6.0
2022-12-28 19:08:24.087 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 19:08:24.090 INFO: Iteration: 20/137, steps: 4320
2022-12-28 19:09:06.026 DEBUG: Atoms are too close
2022-12-28 19:09:07.945 DEBUG: There is a single atom floating around
2022-12-28 19:09:32.504 INFO: Training rollout: return=-0.385 (4.6), episode length=6.0
2022-12-28 19:09:32.506 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 19:09:32.508 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-4320_train.pkl
2022-12-28 19:09:36.617 DEBUG: Taking gradient step
2022-12-28 19:09:36.625 DEBUG: Loss 0: {'policy_loss': 0.022026270907169757, 'entropy_loss': -0.08142150565981865, 'vf_loss': 0.023062708747670156, 'total_loss': -0.03633252600497873, 'approx_kl': -1.7617518999202275e-08, 'clip_fraction': 0.0, 'grad_norm': 17.91788673400879}
2022-12-28 19:09:40.825 DEBUG: Taking gradient step
2022-12-28 19:09:40.832 DEBUG: Loss 1: {'policy_loss': 0.04300313616665028, 'entropy_loss': -0.08087913878262043, 'vf_loss': 0.025523701068106346, 'total_loss': -0.012352301547863792, 'approx_kl': 0.014905116287991405, 'clip_fraction': 0.08333333395421505, 'grad_norm': 14.745797157287598}
2022-12-28 19:09:45.035 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-28 19:09:45.036 INFO: Optimization: policy loss=0.043, vf loss=0.026, entropy loss=-0.081, total loss=-0.012, num steps=2
2022-12-28 19:09:45.036 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 19:09:47.557 INFO: Evaluation rollout: return=0.985 (0.0), episode length=6.0
2022-12-28 19:09:47.559 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 19:09:47.561 DEBUG: Deleting old model: runs/CH3NO_painn/models/CH3NO_painn_run-1_steps-2376.model
2022-12-28 19:09:47.565 DEBUG: Saving model: runs/CH3NO_painn/models/CH3NO_painn_run-1_steps-4536.model
2022-12-28 19:09:47.588 INFO: Iteration: 21/137, steps: 4536
2022-12-28 19:10:07.347 DEBUG: Atoms are too close
2022-12-28 19:10:09.257 DEBUG: There is a single atom floating around
2022-12-28 19:10:29.634 DEBUG: There is a single atom floating around
2022-12-28 19:10:51.433 DEBUG: Atoms are too close
2022-12-28 19:10:55.077 INFO: Training rollout: return=-1.400 (6.3), episode length=6.0
2022-12-28 19:10:55.079 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 19:10:55.081 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-4536_train.pkl
2022-12-28 19:10:56.839 DEBUG: Taking gradient step
2022-12-28 19:10:56.847 DEBUG: Loss 0: {'policy_loss': -0.03337776259380944, 'entropy_loss': -0.08373105525970459, 'vf_loss': 0.037348929344210975, 'total_loss': -0.07975988850930307, 'approx_kl': -7.155662018476505e-08, 'clip_fraction': 0.0, 'grad_norm': 14.040064811706543}
2022-12-28 19:10:58.877 DEBUG: Taking gradient step
2022-12-28 19:10:58.885 DEBUG: Loss 1: {'policy_loss': -0.0026465896713452827, 'entropy_loss': -0.08406915329396725, 'vf_loss': 0.042108527181419525, 'total_loss': -0.044607215783893, 'approx_kl': 0.007031333012491814, 'clip_fraction': 0.0234375, 'grad_norm': 14.554598808288574}
2022-12-28 19:11:03.325 DEBUG: Taking gradient step
2022-12-28 19:11:03.333 DEBUG: Loss 2: {'policy_loss': 0.02319473856498861, 'entropy_loss': -0.08347521536052227, 'vf_loss': 0.04690780817126121, 'total_loss': -0.013372668624272471, 'approx_kl': 0.023714599898084998, 'clip_fraction': 0.13802083395421505, 'grad_norm': 9.80042839050293}
2022-12-28 19:11:07.533 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-28 19:11:07.533 INFO: Optimization: policy loss=0.023, vf loss=0.047, entropy loss=-0.083, total loss=-0.013, num steps=3
2022-12-28 19:11:07.534 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 19:11:10.213 INFO: Evaluation rollout: return=0.966 (0.0), episode length=6.0
2022-12-28 19:11:10.214 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 19:11:10.216 INFO: Iteration: 22/137, steps: 4752
2022-12-28 19:11:29.839 DEBUG: Atoms are too close
2022-12-28 19:11:35.167 DEBUG: There is a single atom floating around
2022-12-28 19:11:53.378 DEBUG: Atoms are too close
2022-12-28 19:12:14.575 DEBUG: Atoms are too close
2022-12-28 19:12:15.442 DEBUG: There is a single atom floating around
2022-12-28 19:12:17.020 INFO: Training rollout: return=-2.008 (7.0), episode length=5.9
2022-12-28 19:12:17.022 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 19:12:17.024 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-4752_train.pkl
2022-12-28 19:12:21.050 DEBUG: Taking gradient step
2022-12-28 19:12:21.059 DEBUG: Loss 0: {'policy_loss': 0.020094515121277634, 'entropy_loss': -0.08297829329967499, 'vf_loss': 0.047136224868674845, 'total_loss': -0.015747553309722502, 'approx_kl': 8.009374141693115e-08, 'clip_fraction': 0.0, 'grad_norm': 26.581775665283203}
2022-12-28 19:12:25.355 DEBUG: Taking gradient step
2022-12-28 19:12:25.363 DEBUG: Loss 1: {'policy_loss': -0.07372539672926723, 'entropy_loss': -0.08269836381077766, 'vf_loss': 0.03772443833401819, 'total_loss': -0.11869932220602672, 'approx_kl': 0.00882615428417921, 'clip_fraction': 0.06770833395421505, 'grad_norm': 10.519381523132324}
2022-12-28 19:12:29.618 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-28 19:12:29.621 INFO: Optimization: policy loss=-0.074, vf loss=0.038, entropy loss=-0.083, total loss=-0.119, num steps=2
2022-12-28 19:12:29.622 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 19:12:32.192 INFO: Evaluation rollout: return=0.898 (0.0), episode length=6.0
2022-12-28 19:12:32.193 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 19:12:32.195 INFO: Iteration: 23/137, steps: 4968
2022-12-28 19:12:37.954 DEBUG: There is a single atom floating around
2022-12-28 19:13:13.067 DEBUG: Atoms are too close
2022-12-28 19:13:33.983 DEBUG: Atoms are too close
2022-12-28 19:13:39.140 INFO: Training rollout: return=-0.891 (5.6), episode length=5.9
2022-12-28 19:13:39.141 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 19:13:39.144 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-4968_train.pkl
2022-12-28 19:13:43.568 DEBUG: Taking gradient step
2022-12-28 19:13:43.577 DEBUG: Loss 0: {'policy_loss': 0.07030864634377806, 'entropy_loss': -0.08453140035271645, 'vf_loss': 0.02910562265086617, 'total_loss': 0.014882868641927796, 'approx_kl': -1.9402559559011934e-09, 'clip_fraction': 0.0, 'grad_norm': 15.351184844970703}
2022-12-28 19:13:47.865 DEBUG: Taking gradient step
2022-12-28 19:13:47.874 DEBUG: Loss 1: {'policy_loss': 0.010932374729015967, 'entropy_loss': -0.0831767451018095, 'vf_loss': 0.024411387325653497, 'total_loss': -0.04783298304714004, 'approx_kl': -0.0015252885641530156, 'clip_fraction': 0.07942708395421505, 'grad_norm': 10.237686157226562}
2022-12-28 19:13:52.089 DEBUG: Taking gradient step
2022-12-28 19:13:52.099 DEBUG: Loss 2: {'policy_loss': 0.024759819453128787, 'entropy_loss': -0.08401882275938988, 'vf_loss': 0.02654399282155544, 'total_loss': -0.03271501048470565, 'approx_kl': 0.011934563051909208, 'clip_fraction': 0.2916666716337204, 'grad_norm': 11.324885368347168}
2022-12-28 19:13:56.327 DEBUG: Taking gradient step
2022-12-28 19:13:56.335 DEBUG: Loss 3: {'policy_loss': -0.052273639963666546, 'entropy_loss': -0.08418558351695538, 'vf_loss': 0.01963758686749968, 'total_loss': -0.11682163661312223, 'approx_kl': 0.03043127921409905, 'clip_fraction': 0.3984375, 'grad_norm': 7.246949672698975}
2022-12-28 19:14:00.503 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-28 19:14:00.504 INFO: Optimization: policy loss=-0.052, vf loss=0.020, entropy loss=-0.084, total loss=-0.117, num steps=4
2022-12-28 19:14:00.504 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 19:14:03.050 INFO: Evaluation rollout: return=0.936 (0.0), episode length=6.0
2022-12-28 19:14:03.052 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 19:14:03.054 INFO: Iteration: 24/137, steps: 5184
2022-12-28 19:14:08.718 DEBUG: There is a single atom floating around
2022-12-28 19:14:28.675 DEBUG: There is a single atom floating around
2022-12-28 19:15:10.056 INFO: Training rollout: return=-0.383 (4.8), episode length=5.8
2022-12-28 19:15:10.058 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 19:15:10.060 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-5184_train.pkl
2022-12-28 19:15:14.322 DEBUG: Taking gradient step
2022-12-28 19:15:14.330 DEBUG: Loss 0: {'policy_loss': -0.012596810728725275, 'entropy_loss': -0.08163723535835743, 'vf_loss': 0.007246945643461503, 'total_loss': -0.0869871004436212, 'approx_kl': -5.727633833885193e-08, 'clip_fraction': 0.0, 'grad_norm': 7.620824813842773}
2022-12-28 19:15:18.699 DEBUG: Taking gradient step
2022-12-28 19:15:18.707 DEBUG: Loss 1: {'policy_loss': -0.022294351292218142, 'entropy_loss': -0.08126319572329521, 'vf_loss': 0.00726765490510404, 'total_loss': -0.09628989211040931, 'approx_kl': -0.0036001891421619803, 'clip_fraction': 0.018229166977107525, 'grad_norm': 7.259646892547607}
2022-12-28 19:15:23.030 DEBUG: Taking gradient step
2022-12-28 19:15:23.038 DEBUG: Loss 2: {'policy_loss': 0.032304209648423565, 'entropy_loss': -0.08052878081798553, 'vf_loss': 0.011993489830253392, 'total_loss': -0.03623108133930858, 'approx_kl': -0.0008376504993066192, 'clip_fraction': 0.109375, 'grad_norm': 3.1473143100738525}
2022-12-28 19:15:27.304 DEBUG: Taking gradient step
2022-12-28 19:15:27.312 DEBUG: Loss 3: {'policy_loss': 0.012896903389486632, 'entropy_loss': -0.08140777610242367, 'vf_loss': 0.009629267696970041, 'total_loss': -0.058881605015966995, 'approx_kl': -0.0025636693462729454, 'clip_fraction': 0.20703125, 'grad_norm': 2.7277674674987793}
2022-12-28 19:15:31.494 DEBUG: Taking gradient step
2022-12-28 19:15:31.503 DEBUG: Loss 4: {'policy_loss': -0.04813740550461288, 'entropy_loss': -0.08043473958969116, 'vf_loss': 0.007162962951330628, 'total_loss': -0.12140918214297342, 'approx_kl': -0.0005507238674908876, 'clip_fraction': 0.2643229216337204, 'grad_norm': 2.1733648777008057}
2022-12-28 19:15:35.777 DEBUG: Taking gradient step
2022-12-28 19:15:35.785 DEBUG: Loss 5: {'policy_loss': 0.00045328000698720977, 'entropy_loss': -0.08079966530203819, 'vf_loss': 0.009398356751347018, 'total_loss': -0.07094802854370397, 'approx_kl': -0.0033680240157991648, 'clip_fraction': 0.2877604216337204, 'grad_norm': 2.222383737564087}
2022-12-28 19:15:40.008 DEBUG: Taking gradient step
2022-12-28 19:15:40.016 DEBUG: Loss 6: {'policy_loss': -0.00764543204721305, 'entropy_loss': -0.08053717389702797, 'vf_loss': 0.009165863857083751, 'total_loss': -0.07901674208715727, 'approx_kl': 0.01642204518429935, 'clip_fraction': 0.29296875, 'grad_norm': 1.927535891532898}
2022-12-28 19:15:44.167 DEBUG: Taking gradient step
2022-12-28 19:15:44.174 DEBUG: Loss 7: {'policy_loss': -0.04679624133714945, 'entropy_loss': -0.08063124679028988, 'vf_loss': 0.006708402591253565, 'total_loss': -0.12071908553618574, 'approx_kl': 0.0075802612118422985, 'clip_fraction': 0.3463541716337204, 'grad_norm': 2.2680673599243164}
2022-12-28 19:15:48.417 DEBUG: Taking gradient step
2022-12-28 19:15:48.425 DEBUG: Loss 8: {'policy_loss': -0.056318540341324344, 'entropy_loss': -0.0797757301479578, 'vf_loss': 0.006661261908977527, 'total_loss': -0.12943300858030463, 'approx_kl': 0.00047564529813826084, 'clip_fraction': 0.3450520858168602, 'grad_norm': 2.197113275527954}
2022-12-28 19:15:52.769 DEBUG: Taking gradient step
2022-12-28 19:15:52.778 DEBUG: Loss 9: {'policy_loss': -0.05545733971491763, 'entropy_loss': -0.07985512726008892, 'vf_loss': 0.006558204461647978, 'total_loss': -0.12875426251335859, 'approx_kl': -0.00019230833277106285, 'clip_fraction': 0.3841145858168602, 'grad_norm': 2.8405823707580566}
2022-12-28 19:15:52.778 INFO: Optimization: policy loss=-0.055, vf loss=0.007, entropy loss=-0.080, total loss=-0.129, num steps=10
2022-12-28 19:15:52.778 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 19:15:55.332 INFO: Evaluation rollout: return=0.899 (0.0), episode length=6.0
2022-12-28 19:15:55.333 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 19:15:55.335 INFO: Iteration: 25/137, steps: 5400
2022-12-28 19:17:03.895 INFO: Training rollout: return=0.732 (0.4), episode length=6.0
2022-12-28 19:17:03.897 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 19:17:03.900 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-5400_train.pkl
2022-12-28 19:17:08.321 DEBUG: Taking gradient step
2022-12-28 19:17:08.330 DEBUG: Loss 0: {'policy_loss': -0.021234237314882713, 'entropy_loss': -0.08104758709669113, 'vf_loss': 0.000907693927894344, 'total_loss': -0.10137413048367949, 'approx_kl': -4.656612873077393e-10, 'clip_fraction': 0.0, 'grad_norm': 23.978336334228516}
2022-12-28 19:17:12.518 DEBUG: Taking gradient step
2022-12-28 19:17:12.526 DEBUG: Loss 1: {'policy_loss': 0.02284400561478242, 'entropy_loss': -0.08105562254786491, 'vf_loss': 0.0008739735354718315, 'total_loss': -0.05733764339761066, 'approx_kl': 0.0027326929848641157, 'clip_fraction': 0.01171875, 'grad_norm': 25.300806045532227}
2022-12-28 19:17:16.690 DEBUG: Taking gradient step
2022-12-28 19:17:16.698 DEBUG: Loss 2: {'policy_loss': -0.01219479413482588, 'entropy_loss': -0.0804375410079956, 'vf_loss': 0.0008840304675494081, 'total_loss': -0.09174830467527208, 'approx_kl': 0.035182649502530694, 'clip_fraction': 0.1653645858168602, 'grad_norm': 11.392763137817383}
2022-12-28 19:17:20.996 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-28 19:17:20.996 INFO: Optimization: policy loss=-0.012, vf loss=0.001, entropy loss=-0.080, total loss=-0.092, num steps=3
2022-12-28 19:17:20.997 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 19:17:23.567 INFO: Evaluation rollout: return=0.895 (0.0), episode length=6.0
2022-12-28 19:17:23.568 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 19:17:23.570 INFO: Iteration: 26/137, steps: 5616
2022-12-28 19:18:32.302 INFO: Training rollout: return=0.766 (0.1), episode length=6.0
2022-12-28 19:18:32.304 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 19:18:32.306 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-5616_train.pkl
2022-12-28 19:18:36.388 DEBUG: Taking gradient step
2022-12-28 19:18:36.396 DEBUG: Loss 0: {'policy_loss': 0.01319242923069177, 'entropy_loss': -0.07879483886063099, 'vf_loss': 0.0007825243424784926, 'total_loss': -0.06481988528746072, 'approx_kl': -9.049351135104189e-08, 'clip_fraction': 0.0, 'grad_norm': 15.216704368591309}
2022-12-28 19:18:40.574 DEBUG: Taking gradient step
2022-12-28 19:18:40.582 DEBUG: Loss 1: {'policy_loss': -0.06997963355429897, 'entropy_loss': -0.07866453379392624, 'vf_loss': 0.0008068929471842028, 'total_loss': -0.147837274401041, 'approx_kl': 0.021269603166729212, 'clip_fraction': 0.1510416679084301, 'grad_norm': 12.1585054397583}
2022-12-28 19:18:44.923 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-28 19:18:44.923 INFO: Optimization: policy loss=-0.070, vf loss=0.001, entropy loss=-0.079, total loss=-0.148, num steps=2
2022-12-28 19:18:44.924 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 19:18:47.428 INFO: Evaluation rollout: return=0.927 (0.0), episode length=6.0
2022-12-28 19:18:47.429 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 19:18:47.432 INFO: Iteration: 27/137, steps: 5832
2022-12-28 19:19:55.244 INFO: Training rollout: return=0.821 (0.1), episode length=6.0
2022-12-28 19:19:55.246 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 19:19:55.248 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-5832_train.pkl
2022-12-28 19:19:59.665 DEBUG: Taking gradient step
2022-12-28 19:19:59.674 DEBUG: Loss 0: {'policy_loss': -0.046323942265858876, 'entropy_loss': -0.08229580707848072, 'vf_loss': 0.0008863990897318233, 'total_loss': -0.12773335025460777, 'approx_kl': -2.5688981053484383e-08, 'clip_fraction': 0.0, 'grad_norm': 12.712395668029785}
2022-12-28 19:20:03.992 DEBUG: Taking gradient step
2022-12-28 19:20:04.000 DEBUG: Loss 1: {'policy_loss': -0.03550353540602859, 'entropy_loss': -0.08255806006491184, 'vf_loss': 0.0008724040900674852, 'total_loss': -0.11718919138087294, 'approx_kl': 0.01129568088799715, 'clip_fraction': 0.01953125, 'grad_norm': 13.344751358032227}
2022-12-28 19:20:08.228 DEBUG: Taking gradient step
2022-12-28 19:20:08.236 DEBUG: Loss 2: {'policy_loss': -0.047613754279928484, 'entropy_loss': -0.0824619960039854, 'vf_loss': 0.0008710178952948505, 'total_loss': -0.12920473238861904, 'approx_kl': 0.037816211581230164, 'clip_fraction': 0.21875, 'grad_norm': 10.929927825927734}
2022-12-28 19:20:12.346 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-28 19:20:12.347 INFO: Optimization: policy loss=-0.048, vf loss=0.001, entropy loss=-0.082, total loss=-0.129, num steps=3
2022-12-28 19:20:12.347 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 19:20:14.938 INFO: Evaluation rollout: return=0.899 (0.0), episode length=6.0
2022-12-28 19:20:14.939 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 19:20:14.943 INFO: Iteration: 28/137, steps: 6048
2022-12-28 19:20:59.299 DEBUG: There is a single atom floating around
2022-12-28 19:21:23.213 INFO: Training rollout: return=0.258 (3.3), episode length=6.0
2022-12-28 19:21:23.215 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 19:21:23.219 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-6048_train.pkl
2022-12-28 19:21:27.694 DEBUG: Taking gradient step
2022-12-28 19:21:27.703 DEBUG: Loss 0: {'policy_loss': -0.02483572755840579, 'entropy_loss': -0.07975170947611332, 'vf_loss': 0.010168191985480671, 'total_loss': -0.09441924504903842, 'approx_kl': -1.5677262155122662e-08, 'clip_fraction': 0.0, 'grad_norm': 13.296100616455078}
2022-12-28 19:21:31.869 DEBUG: Taking gradient step
2022-12-28 19:21:31.877 DEBUG: Loss 1: {'policy_loss': -0.039292085867849505, 'entropy_loss': -0.08075409941375256, 'vf_loss': 0.010202767977994586, 'total_loss': -0.10984341730360747, 'approx_kl': 0.007328847248572856, 'clip_fraction': 0.022135416977107525, 'grad_norm': 12.741448402404785}
2022-12-28 19:21:36.173 DEBUG: Taking gradient step
2022-12-28 19:21:36.181 DEBUG: Loss 2: {'policy_loss': -0.010953431064103271, 'entropy_loss': -0.08062543533742428, 'vf_loss': 0.013134081974518893, 'total_loss': -0.07844478442700867, 'approx_kl': 0.028794992249459028, 'clip_fraction': 0.2161458358168602, 'grad_norm': 6.465639591217041}
2022-12-28 19:21:40.450 DEBUG: Taking gradient step
2022-12-28 19:21:40.458 DEBUG: Loss 3: {'policy_loss': -0.008319059732136494, 'entropy_loss': -0.07968353852629662, 'vf_loss': 0.013066598185464934, 'total_loss': -0.07493600007296818, 'approx_kl': 0.04130327492021024, 'clip_fraction': 0.3645833358168602, 'grad_norm': 3.3081445693969727}
2022-12-28 19:21:44.744 DEBUG: Taking gradient step
2022-12-28 19:21:44.752 DEBUG: Loss 4: {'policy_loss': -0.03701608821899882, 'entropy_loss': -0.07969793863594532, 'vf_loss': 0.0100725716665602, 'total_loss': -0.10664145518838394, 'approx_kl': 0.041023279540240765, 'clip_fraction': 0.4322916716337204, 'grad_norm': 4.123802661895752}
2022-12-28 19:21:48.962 DEBUG: Early stopping at step 5 for reaching max KL.
2022-12-28 19:21:48.963 INFO: Optimization: policy loss=-0.037, vf loss=0.010, entropy loss=-0.080, total loss=-0.107, num steps=5
2022-12-28 19:21:48.963 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 19:21:51.521 INFO: Evaluation rollout: return=0.878 (0.0), episode length=6.0
2022-12-28 19:21:51.523 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 19:21:51.525 INFO: Iteration: 29/137, steps: 6264
2022-12-28 19:22:36.140 DEBUG: Atoms are too close
2022-12-28 19:22:59.568 INFO: Training rollout: return=0.228 (3.4), episode length=6.0
2022-12-28 19:22:59.570 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 19:22:59.573 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-6264_train.pkl
2022-12-28 19:23:03.508 DEBUG: Taking gradient step
2022-12-28 19:23:03.517 DEBUG: Loss 0: {'policy_loss': -0.02300713289288254, 'entropy_loss': -0.08092570677399635, 'vf_loss': 0.010229022105226505, 'total_loss': -0.0937038175616524, 'approx_kl': 5.855690687894821e-08, 'clip_fraction': 0.0, 'grad_norm': 21.664735794067383}
2022-12-28 19:23:07.692 DEBUG: Taking gradient step
2022-12-28 19:23:07.700 DEBUG: Loss 1: {'policy_loss': -0.005486737941493566, 'entropy_loss': -0.08054540306329727, 'vf_loss': 0.012580223800609854, 'total_loss': -0.07345191720418098, 'approx_kl': 0.01520813861861825, 'clip_fraction': 0.0078125, 'grad_norm': 14.792518615722656}
2022-12-28 19:23:12.012 DEBUG: Taking gradient step
2022-12-28 19:23:12.020 DEBUG: Loss 2: {'policy_loss': -0.012440486760359467, 'entropy_loss': -0.07994258962571621, 'vf_loss': 0.012670375845570079, 'total_loss': -0.0797127005405056, 'approx_kl': 0.04001252818852663, 'clip_fraction': 0.2018229216337204, 'grad_norm': 3.984107732772827}
2022-12-28 19:23:16.174 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-28 19:23:16.174 INFO: Optimization: policy loss=-0.012, vf loss=0.013, entropy loss=-0.080, total loss=-0.080, num steps=3
2022-12-28 19:23:16.175 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 19:23:18.691 INFO: Evaluation rollout: return=0.863 (0.0), episode length=6.0
2022-12-28 19:23:18.692 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 19:23:18.695 INFO: Iteration: 30/137, steps: 6480
2022-12-28 19:24:00.879 DEBUG: Atoms are too close
2022-12-28 19:24:01.197 DEBUG: Atoms are too close
2022-12-28 19:24:18.311 DEBUG: Atoms are too close
2022-12-28 19:24:26.045 INFO: Training rollout: return=-0.830 (5.6), episode length=6.0
2022-12-28 19:24:26.046 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 19:24:26.051 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-6480_train.pkl
2022-12-28 19:24:30.104 DEBUG: Taking gradient step
2022-12-28 19:24:30.113 DEBUG: Loss 0: {'policy_loss': -0.027165146419389302, 'entropy_loss': -0.07849194295704365, 'vf_loss': 0.029802181564416896, 'total_loss': -0.07585490781201605, 'approx_kl': 6.58910721540451e-08, 'clip_fraction': 0.0, 'grad_norm': 24.697784423828125}
2022-12-28 19:24:34.340 DEBUG: Taking gradient step
2022-12-28 19:24:34.348 DEBUG: Loss 1: {'policy_loss': -0.033778310835767364, 'entropy_loss': -0.07783493213355541, 'vf_loss': 0.0295334398923289, 'total_loss': -0.08207980307699388, 'approx_kl': 0.008072102442383766, 'clip_fraction': 0.10546875, 'grad_norm': 8.555322647094727}
2022-12-28 19:24:38.504 DEBUG: Taking gradient step
2022-12-28 19:24:38.516 DEBUG: Loss 2: {'policy_loss': -0.06015243285037679, 'entropy_loss': -0.07800690457224846, 'vf_loss': 0.02662840211501837, 'total_loss': -0.11153093530760688, 'approx_kl': 0.03717929730191827, 'clip_fraction': 0.2838541716337204, 'grad_norm': 6.292001724243164}
2022-12-28 19:24:42.814 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-28 19:24:42.815 INFO: Optimization: policy loss=-0.060, vf loss=0.027, entropy loss=-0.078, total loss=-0.112, num steps=3
2022-12-28 19:24:42.815 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 19:24:45.372 INFO: Evaluation rollout: return=0.869 (0.0), episode length=6.0
2022-12-28 19:24:45.373 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 19:24:45.375 DEBUG: Deleting old model: runs/CH3NO_painn/models/CH3NO_painn_run-1_steps-4536.model
2022-12-28 19:24:45.379 DEBUG: Saving model: runs/CH3NO_painn/models/CH3NO_painn_run-1_steps-6696.model
2022-12-28 19:24:45.403 INFO: Iteration: 31/137, steps: 6696
2022-12-28 19:25:04.258 DEBUG: Atoms are too close
2022-12-28 19:25:53.852 INFO: Training rollout: return=0.268 (3.3), episode length=6.0
2022-12-28 19:25:53.854 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 19:25:53.856 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-6696_train.pkl
2022-12-28 19:25:57.899 DEBUG: Taking gradient step
2022-12-28 19:25:57.907 DEBUG: Loss 0: {'policy_loss': 0.012894141556935693, 'entropy_loss': -0.08082953095436096, 'vf_loss': 0.011910313659788393, 'total_loss': -0.056025075737636876, 'approx_kl': 9.002785184009099e-09, 'clip_fraction': 0.0, 'grad_norm': 16.645824432373047}
2022-12-28 19:26:02.107 DEBUG: Taking gradient step
2022-12-28 19:26:02.117 DEBUG: Loss 1: {'policy_loss': 0.04594104476641091, 'entropy_loss': -0.07940259203314781, 'vf_loss': 0.013974541553229934, 'total_loss': -0.019487005713506964, 'approx_kl': 0.006658756406977773, 'clip_fraction': 0.015625, 'grad_norm': 26.377239227294922}
2022-12-28 19:26:06.330 DEBUG: Taking gradient step
2022-12-28 19:26:06.338 DEBUG: Loss 2: {'policy_loss': 0.01567148313100264, 'entropy_loss': -0.079244714230299, 'vf_loss': 0.014218009322278301, 'total_loss': -0.04935522177701805, 'approx_kl': 0.02372120157815516, 'clip_fraction': 0.2005208358168602, 'grad_norm': 3.2774879932403564}
2022-12-28 19:26:10.552 DEBUG: Taking gradient step
2022-12-28 19:26:10.562 DEBUG: Loss 3: {'policy_loss': -0.05726441547663387, 'entropy_loss': -0.07892942242324352, 'vf_loss': 0.00933007960168014, 'total_loss': -0.12686375829819724, 'approx_kl': 0.039792279712855816, 'clip_fraction': 0.3151041716337204, 'grad_norm': 2.74739933013916}
2022-12-28 19:26:14.829 DEBUG: Taking gradient step
2022-12-28 19:26:14.839 DEBUG: Loss 4: {'policy_loss': -0.04507761479478676, 'entropy_loss': -0.07833060249686241, 'vf_loss': 0.009267154149456424, 'total_loss': -0.11414106314219274, 'approx_kl': 0.03655959277966758, 'clip_fraction': 0.3515625, 'grad_norm': 1.805601954460144}
2022-12-28 19:26:18.959 DEBUG: Taking gradient step
2022-12-28 19:26:18.968 DEBUG: Loss 5: {'policy_loss': -0.05373671718635521, 'entropy_loss': -0.07931305654346943, 'vf_loss': 0.009282819579789284, 'total_loss': -0.12376695415003536, 'approx_kl': 0.04350744001567364, 'clip_fraction': 0.3580729216337204, 'grad_norm': 2.3503010272979736}
2022-12-28 19:26:23.151 DEBUG: Early stopping at step 6 for reaching max KL.
2022-12-28 19:26:23.152 INFO: Optimization: policy loss=-0.054, vf loss=0.009, entropy loss=-0.079, total loss=-0.124, num steps=6
2022-12-28 19:26:23.152 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 19:26:25.683 INFO: Evaluation rollout: return=0.821 (0.0), episode length=6.0
2022-12-28 19:26:25.684 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 19:26:25.686 INFO: Iteration: 32/137, steps: 6912
2022-12-28 19:26:47.566 DEBUG: There is a single atom floating around
2022-12-28 19:27:30.142 DEBUG: There is a single atom floating around
2022-12-28 19:27:33.773 INFO: Training rollout: return=-0.284 (4.6), episode length=6.0
2022-12-28 19:27:33.775 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 19:27:33.778 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-6912_train.pkl
2022-12-28 19:27:38.127 DEBUG: Taking gradient step
2022-12-28 19:27:38.136 DEBUG: Loss 0: {'policy_loss': -0.006612757173154944, 'entropy_loss': -0.07969829067587852, 'vf_loss': 0.02094295080143938, 'total_loss': -0.0653680970475941, 'approx_kl': -6.208817193709137e-08, 'clip_fraction': 0.0, 'grad_norm': 12.957804679870605}
2022-12-28 19:27:42.460 DEBUG: Taking gradient step
2022-12-28 19:27:42.469 DEBUG: Loss 1: {'policy_loss': 0.005901456512916138, 'entropy_loss': -0.07883450202643871, 'vf_loss': 0.02351492801065335, 'total_loss': -0.04941811750286922, 'approx_kl': 0.007408682256937027, 'clip_fraction': 0.00390625, 'grad_norm': 18.46407699584961}
2022-12-28 19:27:46.705 DEBUG: Taking gradient step
2022-12-28 19:27:46.714 DEBUG: Loss 2: {'policy_loss': 0.0016378591173704452, 'entropy_loss': -0.07892680540680885, 'vf_loss': 0.0234656048976131, 'total_loss': -0.05382334139182531, 'approx_kl': 0.014600713271647692, 'clip_fraction': 0.10807291697710752, 'grad_norm': 8.452424049377441}
2022-12-28 19:27:51.003 DEBUG: Taking gradient step
2022-12-28 19:27:51.011 DEBUG: Loss 3: {'policy_loss': -0.02181692249509812, 'entropy_loss': -0.07901053316891193, 'vf_loss': 0.02103513368268682, 'total_loss': -0.07979232198132324, 'approx_kl': 0.02967906859703362, 'clip_fraction': 0.2578125, 'grad_norm': 9.885795593261719}
2022-12-28 19:27:55.206 DEBUG: Taking gradient step
2022-12-28 19:27:55.214 DEBUG: Loss 4: {'policy_loss': -0.028128363860832402, 'entropy_loss': -0.07850234024226665, 'vf_loss': 0.020835779362174074, 'total_loss': -0.08579492474092498, 'approx_kl': 0.027442915365099907, 'clip_fraction': 0.3411458358168602, 'grad_norm': 5.060324668884277}
2022-12-28 19:27:59.354 DEBUG: Taking gradient step
2022-12-28 19:27:59.362 DEBUG: Loss 5: {'policy_loss': -0.033445432569649075, 'entropy_loss': -0.07830728963017464, 'vf_loss': 0.020998853923072405, 'total_loss': -0.0907538682767513, 'approx_kl': 0.04282217565923929, 'clip_fraction': 0.33203125, 'grad_norm': 6.587368965148926}
2022-12-28 19:28:03.614 DEBUG: Taking gradient step
2022-12-28 19:28:03.622 DEBUG: Loss 6: {'policy_loss': -0.01327386476852787, 'entropy_loss': -0.0777785237878561, 'vf_loss': 0.023497465772796766, 'total_loss': -0.0675549227835872, 'approx_kl': 0.03584837052039802, 'clip_fraction': 0.3802083358168602, 'grad_norm': 5.9608635902404785}
2022-12-28 19:28:07.815 DEBUG: Taking gradient step
2022-12-28 19:28:07.824 DEBUG: Loss 7: {'policy_loss': -0.045779814659336046, 'entropy_loss': -0.07750704698264599, 'vf_loss': 0.02091729402381532, 'total_loss': -0.1023695676181667, 'approx_kl': 0.04199121426790953, 'clip_fraction': 0.4388020858168602, 'grad_norm': 4.818122863769531}
2022-12-28 19:28:12.056 DEBUG: Early stopping at step 8 for reaching max KL.
2022-12-28 19:28:12.057 INFO: Optimization: policy loss=-0.046, vf loss=0.021, entropy loss=-0.078, total loss=-0.102, num steps=8
2022-12-28 19:28:12.058 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 19:28:14.650 INFO: Evaluation rollout: return=0.868 (0.0), episode length=6.0
2022-12-28 19:28:14.651 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 19:28:14.654 INFO: Iteration: 33/137, steps: 7128
2022-12-28 19:29:19.321 DEBUG: Atoms are too close
2022-12-28 19:29:20.702 INFO: Training rollout: return=0.264 (3.3), episode length=6.0
2022-12-28 19:29:20.703 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 19:29:20.705 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-7128_train.pkl
2022-12-28 19:29:25.020 DEBUG: Taking gradient step
2022-12-28 19:29:25.032 DEBUG: Loss 0: {'policy_loss': -0.02623935556124699, 'entropy_loss': -0.0766451433300972, 'vf_loss': 0.009476677955085826, 'total_loss': -0.09340782093625835, 'approx_kl': 6.441648103816533e-09, 'clip_fraction': 0.0, 'grad_norm': 9.393847465515137}
2022-12-28 19:29:29.313 DEBUG: Taking gradient step
2022-12-28 19:29:29.322 DEBUG: Loss 1: {'policy_loss': -0.03666855359534013, 'entropy_loss': -0.0760789792984724, 'vf_loss': 0.00949342237390174, 'total_loss': -0.10325411051991079, 'approx_kl': 0.0011594989337027073, 'clip_fraction': 0.041666666977107525, 'grad_norm': 4.884873867034912}
2022-12-28 19:29:33.532 DEBUG: Taking gradient step
2022-12-28 19:29:33.540 DEBUG: Loss 2: {'policy_loss': -0.0013682293669203642, 'entropy_loss': -0.07589420676231384, 'vf_loss': 0.011832212223416943, 'total_loss': -0.06543022390581728, 'approx_kl': 0.011208463460206985, 'clip_fraction': 0.20703125, 'grad_norm': 5.100681781768799}
2022-12-28 19:29:37.764 DEBUG: Taking gradient step
2022-12-28 19:29:37.772 DEBUG: Loss 3: {'policy_loss': -0.043099792860372334, 'entropy_loss': -0.07658909633755684, 'vf_loss': 0.009498576373714478, 'total_loss': -0.1101903128242147, 'approx_kl': 0.03680985467508435, 'clip_fraction': 0.30078125, 'grad_norm': 4.521633625030518}
2022-12-28 19:29:41.442 DEBUG: Taking gradient step
2022-12-28 19:29:41.450 DEBUG: Loss 4: {'policy_loss': -0.04342162914086298, 'entropy_loss': -0.0768011137843132, 'vf_loss': 0.009459483153850059, 'total_loss': -0.11076325977132613, 'approx_kl': 0.03358947578817606, 'clip_fraction': 0.3697916716337204, 'grad_norm': 4.738277912139893}
2022-12-28 19:29:45.777 DEBUG: Early stopping at step 5 for reaching max KL.
2022-12-28 19:29:45.778 INFO: Optimization: policy loss=-0.043, vf loss=0.009, entropy loss=-0.077, total loss=-0.111, num steps=5
2022-12-28 19:29:45.778 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 19:29:48.265 INFO: Evaluation rollout: return=0.840 (0.0), episode length=6.0
2022-12-28 19:29:48.266 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 19:29:48.268 INFO: Iteration: 34/137, steps: 7344
2022-12-28 19:30:51.612 DEBUG: Atoms are too close
2022-12-28 19:30:53.671 INFO: Training rollout: return=0.275 (3.3), episode length=6.0
2022-12-28 19:30:53.673 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 19:30:53.676 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-7344_train.pkl
2022-12-28 19:30:58.101 DEBUG: Taking gradient step
2022-12-28 19:30:58.113 DEBUG: Loss 0: {'policy_loss': 0.014935002108194033, 'entropy_loss': -0.07779989764094353, 'vf_loss': 0.012075976537848108, 'total_loss': -0.050788918994901386, 'approx_kl': 9.530534228474608e-08, 'clip_fraction': 0.0, 'grad_norm': 19.22935676574707}
2022-12-28 19:31:02.331 DEBUG: Taking gradient step
2022-12-28 19:31:02.339 DEBUG: Loss 1: {'policy_loss': -0.002390563064103901, 'entropy_loss': -0.07794003002345562, 'vf_loss': 0.012167792430863895, 'total_loss': -0.06816280065669562, 'approx_kl': 0.013051104848273098, 'clip_fraction': 0.045572916977107525, 'grad_norm': 8.79653263092041}
2022-12-28 19:31:06.602 DEBUG: Taking gradient step
2022-12-28 19:31:06.610 DEBUG: Loss 2: {'policy_loss': -0.04476386885922347, 'entropy_loss': -0.07779913395643234, 'vf_loss': 0.009673202662697411, 'total_loss': -0.11288980015295841, 'approx_kl': 0.021978777600452304, 'clip_fraction': 0.12630208395421505, 'grad_norm': 3.790790319442749}
2022-12-28 19:31:10.846 DEBUG: Taking gradient step
2022-12-28 19:31:10.854 DEBUG: Loss 3: {'policy_loss': 0.01974302393052582, 'entropy_loss': -0.07860742136836052, 'vf_loss': 0.014507825823562661, 'total_loss': -0.04435657161427205, 'approx_kl': 0.03435917291790247, 'clip_fraction': 0.203125, 'grad_norm': 3.8311429023742676}
2022-12-28 19:31:15.084 DEBUG: Taking gradient step
2022-12-28 19:31:15.092 DEBUG: Loss 4: {'policy_loss': -0.02095134202271473, 'entropy_loss': -0.07955766655504704, 'vf_loss': 0.012025527422624903, 'total_loss': -0.08848348115513688, 'approx_kl': 0.01559014356462285, 'clip_fraction': 0.2864583358168602, 'grad_norm': 3.900872230529785}
2022-12-28 19:31:19.251 DEBUG: Taking gradient step
2022-12-28 19:31:19.259 DEBUG: Loss 5: {'policy_loss': -0.04838613353471359, 'entropy_loss': -0.07849759422242641, 'vf_loss': 0.009551730371218908, 'total_loss': -0.1173319973859211, 'approx_kl': -0.014746703207492828, 'clip_fraction': 0.3020833358168602, 'grad_norm': 2.1712558269500732}
2022-12-28 19:31:23.460 DEBUG: Taking gradient step
2022-12-28 19:31:23.468 DEBUG: Loss 6: {'policy_loss': -0.013432484264601616, 'entropy_loss': -0.07924026623368263, 'vf_loss': 0.012002839498683675, 'total_loss': -0.08066991099960057, 'approx_kl': -0.03327661380171776, 'clip_fraction': 0.3346354216337204, 'grad_norm': 21.268278121948242}
2022-12-28 19:31:27.726 DEBUG: Taking gradient step
2022-12-28 19:31:27.733 DEBUG: Loss 7: {'policy_loss': -0.020859319814146914, 'entropy_loss': -0.07917515002191067, 'vf_loss': 0.011862706757544035, 'total_loss': -0.08817176307851354, 'approx_kl': -0.009675166569650173, 'clip_fraction': 0.42578125, 'grad_norm': 1.9535712003707886}
2022-12-28 19:31:31.961 DEBUG: Taking gradient step
2022-12-28 19:31:31.970 DEBUG: Loss 8: {'policy_loss': -0.05169529333592771, 'entropy_loss': -0.07958196476101875, 'vf_loss': 0.009409623629054157, 'total_loss': -0.1218676344678923, 'approx_kl': -0.022997436113655567, 'clip_fraction': 0.4231770858168602, 'grad_norm': 1.9522494077682495}
2022-12-28 19:31:36.170 DEBUG: Taking gradient step
2022-12-28 19:31:36.178 DEBUG: Loss 9: {'policy_loss': -0.052871527373696506, 'entropy_loss': -0.07942576333880424, 'vf_loss': 0.009376465641970493, 'total_loss': -0.12292082507053026, 'approx_kl': -0.011949149891734123, 'clip_fraction': 0.4153645858168602, 'grad_norm': 1.9364733695983887}
2022-12-28 19:31:36.179 INFO: Optimization: policy loss=-0.053, vf loss=0.009, entropy loss=-0.079, total loss=-0.123, num steps=10
2022-12-28 19:31:36.179 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 19:31:38.541 INFO: Evaluation rollout: return=0.826 (0.0), episode length=6.0
2022-12-28 19:31:38.542 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 19:31:38.544 INFO: Iteration: 35/137, steps: 7560
2022-12-28 19:32:15.924 DEBUG: Atoms are too close
2022-12-28 19:32:20.907 DEBUG: There is a single atom floating around
2022-12-28 19:32:40.133 DEBUG: There is a single atom floating around
2022-12-28 19:32:42.158 DEBUG: Atoms are too close
2022-12-28 19:32:43.041 INFO: Training rollout: return=-1.411 (6.3), episode length=6.0
2022-12-28 19:32:43.043 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 19:32:43.045 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-7560_train.pkl
2022-12-28 19:32:47.335 DEBUG: Taking gradient step
2022-12-28 19:32:47.343 DEBUG: Loss 0: {'policy_loss': -0.034872864464557105, 'entropy_loss': -0.07795163989067078, 'vf_loss': 0.03705030881626021, 'total_loss': -0.07577419553896766, 'approx_kl': 3.5545479448728656e-08, 'clip_fraction': 0.0, 'grad_norm': 13.220871925354004}
2022-12-28 19:32:50.255 DEBUG: Taking gradient step
2022-12-28 19:32:50.263 DEBUG: Loss 1: {'policy_loss': 0.057449563482817045, 'entropy_loss': -0.07840244472026825, 'vf_loss': 0.04985612527023096, 'total_loss': 0.02890324403277976, 'approx_kl': 0.0026683281175792217, 'clip_fraction': 0.05208333395421505, 'grad_norm': 14.578672409057617}
2022-12-28 19:32:52.003 DEBUG: Taking gradient step
2022-12-28 19:32:52.011 DEBUG: Loss 2: {'policy_loss': -0.02832079423132789, 'entropy_loss': -0.07801091112196445, 'vf_loss': 0.039812048928188654, 'total_loss': -0.06651965642510368, 'approx_kl': 0.00456736795604229, 'clip_fraction': 0.1861979216337204, 'grad_norm': 8.282593727111816}
2022-12-28 19:32:53.762 DEBUG: Taking gradient step
2022-12-28 19:32:53.770 DEBUG: Loss 3: {'policy_loss': -0.025576290822034282, 'entropy_loss': -0.07891400903463364, 'vf_loss': 0.03979633601102922, 'total_loss': -0.06469396384563869, 'approx_kl': 0.016948090167716146, 'clip_fraction': 0.2864583358168602, 'grad_norm': 11.139241218566895}
2022-12-28 19:32:55.379 DEBUG: Taking gradient step
2022-12-28 19:32:55.387 DEBUG: Loss 4: {'policy_loss': -0.011703227771446275, 'entropy_loss': -0.07881460525095463, 'vf_loss': 0.04220251155129245, 'total_loss': -0.04831532147110846, 'approx_kl': 0.02581654430832714, 'clip_fraction': 0.3684895858168602, 'grad_norm': 7.800032138824463}
2022-12-28 19:32:58.402 DEBUG: Taking gradient step
2022-12-28 19:32:58.414 DEBUG: Loss 5: {'policy_loss': 0.026440099089093526, 'entropy_loss': -0.0785390418022871, 'vf_loss': 0.046940390478928125, 'total_loss': -0.005158552234265451, 'approx_kl': 0.03636963228927925, 'clip_fraction': 0.4427083358168602, 'grad_norm': 7.133370876312256}
2022-12-28 19:33:02.522 DEBUG: Taking gradient step
2022-12-28 19:33:02.531 DEBUG: Loss 6: {'policy_loss': 0.04190329586331712, 'entropy_loss': -0.07850026711821556, 'vf_loss': 0.04929838126549588, 'total_loss': 0.012701410010597422, 'approx_kl': 0.037697222374845296, 'clip_fraction': 0.4401041716337204, 'grad_norm': 9.956024169921875}
2022-12-28 19:33:06.775 DEBUG: Taking gradient step
2022-12-28 19:33:06.783 DEBUG: Loss 7: {'policy_loss': -0.03653130974481811, 'entropy_loss': -0.07811510004103184, 'vf_loss': 0.03933059436022777, 'total_loss': -0.07531581542562218, 'approx_kl': 0.029136936413124204, 'clip_fraction': 0.42578125, 'grad_norm': 10.973257064819336}
2022-12-28 19:33:10.897 DEBUG: Taking gradient step
2022-12-28 19:33:10.905 DEBUG: Loss 8: {'policy_loss': -0.021968929750178008, 'entropy_loss': -0.07898365147411823, 'vf_loss': 0.04145927000374042, 'total_loss': -0.05949331122055581, 'approx_kl': 0.041113500483334064, 'clip_fraction': 0.4830729216337204, 'grad_norm': 5.1036858558654785}
2022-12-28 19:33:15.292 DEBUG: Taking gradient step
2022-12-28 19:33:15.303 DEBUG: Loss 9: {'policy_loss': -0.044596149372623434, 'entropy_loss': -0.0782561469823122, 'vf_loss': 0.03879169535846844, 'total_loss': -0.08406060099646719, 'approx_kl': 0.029389972798526287, 'clip_fraction': 0.45703125, 'grad_norm': 5.130546569824219}
2022-12-28 19:33:15.303 INFO: Optimization: policy loss=-0.045, vf loss=0.039, entropy loss=-0.078, total loss=-0.084, num steps=10
2022-12-28 19:33:15.304 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 19:33:17.772 INFO: Evaluation rollout: return=0.819 (0.0), episode length=6.0
2022-12-28 19:33:17.773 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 19:33:17.775 INFO: Iteration: 36/137, steps: 7776
2022-12-28 19:33:31.885 DEBUG: There is a single atom floating around
2022-12-28 19:33:38.378 DEBUG: There is a single atom floating around
2022-12-28 19:34:00.228 DEBUG: Atoms are too close
2022-12-28 19:34:22.343 INFO: Training rollout: return=-0.830 (5.6), episode length=6.0
2022-12-28 19:34:22.345 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 19:34:22.347 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-7776_train.pkl
2022-12-28 19:34:26.549 DEBUG: Taking gradient step
2022-12-28 19:34:26.559 DEBUG: Loss 0: {'policy_loss': 0.0016570207534673887, 'entropy_loss': -0.07963499426841736, 'vf_loss': 0.029844757336487244, 'total_loss': -0.04813321617846272, 'approx_kl': 5.626740673392305e-08, 'clip_fraction': 0.0, 'grad_norm': 11.88333511352539}
2022-12-28 19:34:30.992 DEBUG: Taking gradient step
2022-12-28 19:34:31.001 DEBUG: Loss 1: {'policy_loss': 0.03690684524012637, 'entropy_loss': -0.07976566627621651, 'vf_loss': 0.03458734728643029, 'total_loss': -0.008271473749659863, 'approx_kl': 0.01127229887060821, 'clip_fraction': 0.06640625, 'grad_norm': 9.288739204406738}
2022-12-28 19:34:35.236 DEBUG: Taking gradient step
2022-12-28 19:34:35.244 DEBUG: Loss 2: {'policy_loss': 0.006186506546699749, 'entropy_loss': -0.07886386290192604, 'vf_loss': 0.03210086804751713, 'total_loss': -0.04057648830770917, 'approx_kl': 0.02734328992664814, 'clip_fraction': 0.1822916679084301, 'grad_norm': 12.272188186645508}
2022-12-28 19:34:39.465 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-28 19:34:39.466 INFO: Optimization: policy loss=0.006, vf loss=0.032, entropy loss=-0.079, total loss=-0.041, num steps=3
2022-12-28 19:34:39.467 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 19:34:42.023 INFO: Evaluation rollout: return=0.727 (0.0), episode length=6.0
2022-12-28 19:34:42.024 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 19:34:42.027 INFO: Iteration: 37/137, steps: 7992
2022-12-28 19:35:47.770 INFO: Training rollout: return=0.839 (0.1), episode length=6.0
2022-12-28 19:35:47.773 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 19:35:47.776 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-7992_train.pkl
2022-12-28 19:35:51.820 DEBUG: Taking gradient step
2022-12-28 19:35:51.829 DEBUG: Loss 0: {'policy_loss': 0.03877095703323944, 'entropy_loss': -0.0811183750629425, 'vf_loss': 0.0014022507083849135, 'total_loss': -0.04094516732131814, 'approx_kl': -7.58251808008481e-08, 'clip_fraction': 0.0, 'grad_norm': 29.941991806030273}
2022-12-28 19:35:56.155 DEBUG: Taking gradient step
2022-12-28 19:35:56.167 DEBUG: Loss 1: {'policy_loss': 0.0027644717388522998, 'entropy_loss': -0.08042005263268948, 'vf_loss': 0.0015643499048172338, 'total_loss': -0.07609123098901995, 'approx_kl': 0.004708588821813464, 'clip_fraction': 0.05989583395421505, 'grad_norm': 15.091612815856934}
2022-12-28 19:36:00.344 DEBUG: Taking gradient step
2022-12-28 19:36:00.353 DEBUG: Loss 2: {'policy_loss': -0.046021008268954985, 'entropy_loss': -0.08069284446537495, 'vf_loss': 0.001733509067516431, 'total_loss': -0.1249803436668135, 'approx_kl': 0.015022858278825879, 'clip_fraction': 0.23958333395421505, 'grad_norm': 14.804315567016602}
2022-12-28 19:36:04.556 DEBUG: Taking gradient step
2022-12-28 19:36:04.568 DEBUG: Loss 3: {'policy_loss': -0.001736729571140667, 'entropy_loss': -0.08051160722970963, 'vf_loss': 0.0017834851618286985, 'total_loss': -0.08046485163902159, 'approx_kl': 0.024652278516441584, 'clip_fraction': 0.3229166716337204, 'grad_norm': 15.678451538085938}
2022-12-28 19:36:08.790 DEBUG: Taking gradient step
2022-12-28 19:36:08.802 DEBUG: Loss 4: {'policy_loss': -0.03561897182185235, 'entropy_loss': -0.08058817125856876, 'vf_loss': 0.001875545991907028, 'total_loss': -0.11433159708851409, 'approx_kl': 0.005301713012158871, 'clip_fraction': 0.33984375, 'grad_norm': 16.441144943237305}
2022-12-28 19:36:12.985 DEBUG: Taking gradient step
2022-12-28 19:36:12.997 DEBUG: Loss 5: {'policy_loss': -0.06223773151409634, 'entropy_loss': -0.08138106763362885, 'vf_loss': 0.001916313080054694, 'total_loss': -0.1417024860676705, 'approx_kl': -0.003037119866348803, 'clip_fraction': 0.3932291716337204, 'grad_norm': 10.450026512145996}
2022-12-28 19:36:17.243 DEBUG: Taking gradient step
2022-12-28 19:36:17.252 DEBUG: Loss 6: {'policy_loss': -0.002169562181746666, 'entropy_loss': -0.08020889759063721, 'vf_loss': 0.0018429733232514824, 'total_loss': -0.08053548644913239, 'approx_kl': -0.018128768308088183, 'clip_fraction': 0.4166666716337204, 'grad_norm': 13.035196304321289}
2022-12-28 19:36:21.468 DEBUG: Taking gradient step
2022-12-28 19:36:21.476 DEBUG: Loss 7: {'policy_loss': -0.05652694931787475, 'entropy_loss': -0.0800363589078188, 'vf_loss': 0.0018492507703279204, 'total_loss': -0.1347140574553656, 'approx_kl': -0.002576584927737713, 'clip_fraction': 0.3619791716337204, 'grad_norm': 14.362567901611328}
2022-12-28 19:36:25.749 DEBUG: Taking gradient step
2022-12-28 19:36:25.757 DEBUG: Loss 8: {'policy_loss': -0.02892314279949499, 'entropy_loss': -0.08046108484268188, 'vf_loss': 0.001760980351631316, 'total_loss': -0.10762324729054557, 'approx_kl': -0.015584347303956747, 'clip_fraction': 0.359375, 'grad_norm': 19.43682289123535}
2022-12-28 19:36:29.979 DEBUG: Taking gradient step
2022-12-28 19:36:29.991 DEBUG: Loss 9: {'policy_loss': -0.04785681412099627, 'entropy_loss': -0.07948102988302708, 'vf_loss': 0.001715264996901455, 'total_loss': -0.12562257900712187, 'approx_kl': -0.0075404043309390545, 'clip_fraction': 0.43359375, 'grad_norm': 17.334917068481445}
2022-12-28 19:36:29.991 INFO: Optimization: policy loss=-0.048, vf loss=0.002, entropy loss=-0.079, total loss=-0.126, num steps=10
2022-12-28 19:36:29.992 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 19:36:32.390 INFO: Evaluation rollout: return=0.829 (0.0), episode length=6.0
2022-12-28 19:36:32.391 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 19:36:32.393 INFO: Iteration: 38/137, steps: 8208
2022-12-28 19:36:51.586 DEBUG: There is a single atom floating around
2022-12-28 19:36:52.743 DEBUG: Atoms are too close
2022-12-28 19:37:37.156 INFO: Training rollout: return=-0.337 (4.6), episode length=6.0
2022-12-28 19:37:37.158 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 19:37:37.160 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-8208_train.pkl
2022-12-28 19:37:41.583 DEBUG: Taking gradient step
2022-12-28 19:37:41.591 DEBUG: Loss 0: {'policy_loss': -0.008319423244405887, 'entropy_loss': -0.07826649956405163, 'vf_loss': 0.020648684084375774, 'total_loss': -0.06593723872408175, 'approx_kl': 9.437402326284428e-08, 'clip_fraction': 0.0, 'grad_norm': 27.236522674560547}
2022-12-28 19:37:45.813 DEBUG: Taking gradient step
2022-12-28 19:37:45.823 DEBUG: Loss 1: {'policy_loss': -0.014209123662260084, 'entropy_loss': -0.07835806719958782, 'vf_loss': 0.020556362751433282, 'total_loss': -0.07201082811041462, 'approx_kl': 0.00828801840543747, 'clip_fraction': 0.01953125, 'grad_norm': 29.497831344604492}
2022-12-28 19:37:50.005 DEBUG: Taking gradient step
2022-12-28 19:37:50.013 DEBUG: Loss 2: {'policy_loss': -0.001449433291999782, 'entropy_loss': -0.0782814659178257, 'vf_loss': 0.022939190664958076, 'total_loss': -0.05679170854486741, 'approx_kl': 0.026328190695494413, 'clip_fraction': 0.1484375, 'grad_norm': 15.54499626159668}
2022-12-28 19:37:54.317 DEBUG: Taking gradient step
2022-12-28 19:37:54.325 DEBUG: Loss 3: {'policy_loss': -0.013654030998255847, 'entropy_loss': -0.07832562364637852, 'vf_loss': 0.02276874541021702, 'total_loss': -0.06921090923441735, 'approx_kl': 0.02633202006109059, 'clip_fraction': 0.2421875, 'grad_norm': 10.106224060058594}
2022-12-28 19:37:58.454 DEBUG: Taking gradient step
2022-12-28 19:37:58.466 DEBUG: Loss 4: {'policy_loss': -0.03387014906299454, 'entropy_loss': -0.07771465368568897, 'vf_loss': 0.020544933887252044, 'total_loss': -0.09103986886143146, 'approx_kl': 0.022657846566289663, 'clip_fraction': 0.2981770858168602, 'grad_norm': 5.972518444061279}
2022-12-28 19:38:02.697 DEBUG: Taking gradient step
2022-12-28 19:38:02.705 DEBUG: Loss 5: {'policy_loss': -0.023646791591987598, 'entropy_loss': -0.07809939421713352, 'vf_loss': 0.022638267768533414, 'total_loss': -0.07910791804058771, 'approx_kl': 0.01282329810783267, 'clip_fraction': 0.4049479216337204, 'grad_norm': 3.8569583892822266}
2022-12-28 19:38:07.009 DEBUG: Taking gradient step
2022-12-28 19:38:07.020 DEBUG: Loss 6: {'policy_loss': -0.06685347282215477, 'entropy_loss': -0.07844280824065208, 'vf_loss': 0.01810510737242271, 'total_loss': -0.12719117369038416, 'approx_kl': 0.015301907900720835, 'clip_fraction': 0.4596354216337204, 'grad_norm': 4.637141704559326}
2022-12-28 19:38:10.754 DEBUG: Taking gradient step
2022-12-28 19:38:10.762 DEBUG: Loss 7: {'policy_loss': -0.02189215159942125, 'entropy_loss': -0.0784290973097086, 'vf_loss': 0.02278798389394742, 'total_loss': -0.07753326501518244, 'approx_kl': 0.005576979368925095, 'clip_fraction': 0.48828125, 'grad_norm': 4.177119255065918}
2022-12-28 19:38:14.977 DEBUG: Taking gradient step
2022-12-28 19:38:14.991 DEBUG: Loss 8: {'policy_loss': -0.0696094837038994, 'entropy_loss': -0.07917307689785957, 'vf_loss': 0.018059994051317262, 'total_loss': -0.13072256655044168, 'approx_kl': -0.006218351889401674, 'clip_fraction': 0.5065104216337204, 'grad_norm': 3.488290309906006}
2022-12-28 19:38:19.187 DEBUG: Taking gradient step
2022-12-28 19:38:19.195 DEBUG: Loss 9: {'policy_loss': -0.04123389950769125, 'entropy_loss': -0.07841118052601814, 'vf_loss': 0.020360515327679636, 'total_loss': -0.09928456470602975, 'approx_kl': -0.018073597457259893, 'clip_fraction': 0.39453125, 'grad_norm': 9.98626708984375}
2022-12-28 19:38:19.196 INFO: Optimization: policy loss=-0.041, vf loss=0.020, entropy loss=-0.078, total loss=-0.099, num steps=10
2022-12-28 19:38:19.197 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 19:38:21.718 INFO: Evaluation rollout: return=0.920 (0.0), episode length=6.0
2022-12-28 19:38:21.720 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 19:38:21.723 INFO: Iteration: 39/137, steps: 8424
2022-12-28 19:39:03.729 DEBUG: There is a single atom floating around
2022-12-28 19:39:27.293 INFO: Training rollout: return=0.281 (3.3), episode length=6.0
2022-12-28 19:39:27.294 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 19:39:27.297 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-8424_train.pkl
2022-12-28 19:39:31.654 DEBUG: Taking gradient step
2022-12-28 19:39:31.665 DEBUG: Loss 0: {'policy_loss': -0.0271366608585224, 'entropy_loss': -0.07997837848961353, 'vf_loss': 0.009544282733771533, 'total_loss': -0.09757075661436439, 'approx_kl': -8.226681558198834e-09, 'clip_fraction': 0.0, 'grad_norm': 10.289421081542969}
2022-12-28 19:39:35.926 DEBUG: Taking gradient step
2022-12-28 19:39:35.935 DEBUG: Loss 1: {'policy_loss': -0.006738275312372071, 'entropy_loss': -0.08040870353579521, 'vf_loss': 0.011877835710104161, 'total_loss': -0.07526914313806313, 'approx_kl': 0.0004886842798441648, 'clip_fraction': 0.03125, 'grad_norm': 14.96545696258545}
2022-12-28 19:39:40.111 DEBUG: Taking gradient step
2022-12-28 19:39:40.124 DEBUG: Loss 2: {'policy_loss': -0.01241050646773778, 'entropy_loss': -0.08073718659579754, 'vf_loss': 0.011915204389203179, 'total_loss': -0.08123248867433215, 'approx_kl': 0.008950676769018173, 'clip_fraction': 0.2005208358168602, 'grad_norm': 7.621521472930908}
2022-12-28 19:39:44.413 DEBUG: Taking gradient step
2022-12-28 19:39:44.426 DEBUG: Loss 3: {'policy_loss': 0.023292961663425607, 'entropy_loss': -0.0803342405706644, 'vf_loss': 0.014287757277801582, 'total_loss': -0.04275352162943721, 'approx_kl': 0.003322354983538389, 'clip_fraction': 0.3229166716337204, 'grad_norm': 2.659179210662842}
2022-12-28 19:39:48.693 DEBUG: Taking gradient step
2022-12-28 19:39:48.701 DEBUG: Loss 4: {'policy_loss': -0.044260600266526305, 'entropy_loss': -0.08026260510087013, 'vf_loss': 0.009476093626133861, 'total_loss': -0.11504711174126259, 'approx_kl': 0.0351524876896292, 'clip_fraction': 0.3411458358168602, 'grad_norm': 2.3709025382995605}
2022-12-28 19:39:52.943 DEBUG: Taking gradient step
2022-12-28 19:39:52.951 DEBUG: Loss 5: {'policy_loss': -0.04813846532653645, 'entropy_loss': -0.08056078664958477, 'vf_loss': 0.00943777100964659, 'total_loss': -0.11926148096647463, 'approx_kl': 0.010544893331825733, 'clip_fraction': 0.375, 'grad_norm': 3.03912615776062}
2022-12-28 19:39:57.156 DEBUG: Taking gradient step
2022-12-28 19:39:57.164 DEBUG: Loss 6: {'policy_loss': -0.04677073136379875, 'entropy_loss': -0.08068481832742691, 'vf_loss': 0.009386998243359665, 'total_loss': -0.11806855144786599, 'approx_kl': 0.0093371057882905, 'clip_fraction': 0.41015625, 'grad_norm': 2.9214529991149902}
2022-12-28 19:40:01.430 DEBUG: Taking gradient step
2022-12-28 19:40:01.438 DEBUG: Loss 7: {'policy_loss': -0.0524586622356628, 'entropy_loss': -0.08060751482844353, 'vf_loss': 0.009368446465336765, 'total_loss': -0.12369773059876957, 'approx_kl': -0.0032383252400904894, 'clip_fraction': 0.3619791716337204, 'grad_norm': 2.2913010120391846}
2022-12-28 19:40:05.654 DEBUG: Taking gradient step
2022-12-28 19:40:05.661 DEBUG: Loss 8: {'policy_loss': -0.016569019766180932, 'entropy_loss': -0.08055154047906399, 'vf_loss': 0.011694670322157635, 'total_loss': -0.08542588992308728, 'approx_kl': -0.00385107658803463, 'clip_fraction': 0.3255208358168602, 'grad_norm': 3.7440991401672363}
2022-12-28 19:40:09.975 DEBUG: Taking gradient step
2022-12-28 19:40:09.983 DEBUG: Loss 9: {'policy_loss': -0.04957811502359948, 'entropy_loss': -0.07987079210579395, 'vf_loss': 0.009287651201548423, 'total_loss': -0.12016125592784502, 'approx_kl': 0.0006366502493619919, 'clip_fraction': 0.38671875, 'grad_norm': 3.610506296157837}
2022-12-28 19:40:09.983 INFO: Optimization: policy loss=-0.050, vf loss=0.009, entropy loss=-0.080, total loss=-0.120, num steps=10
2022-12-28 19:40:09.984 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 19:40:12.429 INFO: Evaluation rollout: return=0.881 (0.0), episode length=6.0
2022-12-28 19:40:12.430 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 19:40:12.434 INFO: Iteration: 40/137, steps: 8640
2022-12-28 19:40:31.711 DEBUG: Atoms are too close
2022-12-28 19:41:13.851 DEBUG: There is a single atom floating around
2022-12-28 19:41:13.852 DEBUG: Atoms are too close
2022-12-28 19:41:17.094 INFO: Training rollout: return=-0.833 (5.5), episode length=6.0
2022-12-28 19:41:17.096 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 19:41:17.100 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-8640_train.pkl
2022-12-28 19:41:21.366 DEBUG: Taking gradient step
2022-12-28 19:41:21.375 DEBUG: Loss 0: {'policy_loss': -0.024241005498803425, 'entropy_loss': -0.08074726536870003, 'vf_loss': 0.02921774098589932, 'total_loss': -0.07577052988160413, 'approx_kl': 5.727633833885193e-08, 'clip_fraction': 0.0, 'grad_norm': 13.630996704101562}
2022-12-28 19:41:25.585 DEBUG: Taking gradient step
2022-12-28 19:41:25.594 DEBUG: Loss 1: {'policy_loss': -0.009720371170654841, 'entropy_loss': -0.0802799966186285, 'vf_loss': 0.03171376604395486, 'total_loss': -0.05828660174532848, 'approx_kl': 0.009805910987779498, 'clip_fraction': 0.04817708395421505, 'grad_norm': 10.924079895019531}
2022-12-28 19:41:29.659 DEBUG: Taking gradient step
2022-12-28 19:41:29.668 DEBUG: Loss 2: {'policy_loss': -0.06481210818320766, 'entropy_loss': -0.07966725900769234, 'vf_loss': 0.02689094070225697, 'total_loss': -0.11758842648864302, 'approx_kl': 0.018683618865907192, 'clip_fraction': 0.2213541716337204, 'grad_norm': 7.839303970336914}
2022-12-28 19:41:34.016 DEBUG: Taking gradient step
2022-12-28 19:41:34.024 DEBUG: Loss 3: {'policy_loss': -0.06715317284669398, 'entropy_loss': -0.08104118146002293, 'vf_loss': 0.026900647316959413, 'total_loss': -0.12129370698975749, 'approx_kl': 0.035355354426428676, 'clip_fraction': 0.3125, 'grad_norm': 6.835572242736816}
2022-12-28 19:41:38.100 DEBUG: Taking gradient step
2022-12-28 19:41:38.108 DEBUG: Loss 4: {'policy_loss': -0.05288910198085106, 'entropy_loss': -0.0801904946565628, 'vf_loss': 0.02922132997231237, 'total_loss': -0.1038582666651015, 'approx_kl': 0.03564530238509178, 'clip_fraction': 0.4401041716337204, 'grad_norm': 5.937928676605225}
2022-12-28 19:41:42.270 DEBUG: Early stopping at step 5 for reaching max KL.
2022-12-28 19:41:42.270 INFO: Optimization: policy loss=-0.053, vf loss=0.029, entropy loss=-0.080, total loss=-0.104, num steps=5
2022-12-28 19:41:42.271 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 19:41:44.770 INFO: Evaluation rollout: return=0.834 (0.0), episode length=6.0
2022-12-28 19:41:44.772 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 19:41:44.774 DEBUG: Deleting old model: runs/CH3NO_painn/models/CH3NO_painn_run-1_steps-6696.model
2022-12-28 19:41:44.779 DEBUG: Saving model: runs/CH3NO_painn/models/CH3NO_painn_run-1_steps-8856.model
2022-12-28 19:41:44.803 INFO: Iteration: 41/137, steps: 8856
2022-12-28 19:42:22.150 DEBUG: Atoms are too close
2022-12-28 19:42:23.025 DEBUG: Atoms are too close
2022-12-28 19:42:49.842 INFO: Training rollout: return=-0.341 (4.6), episode length=5.9
2022-12-28 19:42:49.844 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 19:42:49.846 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-8856_train.pkl
2022-12-28 19:42:53.717 DEBUG: Taking gradient step
2022-12-28 19:42:53.725 DEBUG: Loss 0: {'policy_loss': 0.003774370269182911, 'entropy_loss': -0.08096450939774513, 'vf_loss': 0.017951551572910084, 'total_loss': -0.05923858755565213, 'approx_kl': -1.8005569923928988e-08, 'clip_fraction': 0.0, 'grad_norm': 13.098358154296875}
2022-12-28 19:42:56.803 DEBUG: Taking gradient step
2022-12-28 19:42:56.811 DEBUG: Loss 1: {'policy_loss': -0.010277070445469771, 'entropy_loss': -0.08062042109668255, 'vf_loss': 0.017791334678878393, 'total_loss': -0.07310615686327393, 'approx_kl': 0.006309504096861929, 'clip_fraction': 0.045572916977107525, 'grad_norm': 8.012605667114258}
2022-12-28 19:42:57.780 DEBUG: Taking gradient step
2022-12-28 19:42:57.788 DEBUG: Loss 2: {'policy_loss': -0.04840436321130155, 'entropy_loss': -0.0816397424787283, 'vf_loss': 0.015299627458946408, 'total_loss': -0.11474447823108344, 'approx_kl': 0.009677318390458822, 'clip_fraction': 0.2291666716337204, 'grad_norm': 6.4093451499938965}
2022-12-28 19:42:58.795 DEBUG: Taking gradient step
2022-12-28 19:42:58.802 DEBUG: Loss 3: {'policy_loss': 0.00041702386361814475, 'entropy_loss': -0.0815608948469162, 'vf_loss': 0.020233746772400404, 'total_loss': -0.06091012421089764, 'approx_kl': 0.03545211791060865, 'clip_fraction': 0.3125, 'grad_norm': 6.147802829742432}
2022-12-28 19:42:59.787 DEBUG: Taking gradient step
2022-12-28 19:42:59.794 DEBUG: Loss 4: {'policy_loss': -0.05558419489854055, 'entropy_loss': -0.0810339692980051, 'vf_loss': 0.015283825903167927, 'total_loss': -0.12133433829337772, 'approx_kl': 0.0031544044613838196, 'clip_fraction': 0.3854166716337204, 'grad_norm': 4.08781623840332}
2022-12-28 19:43:00.756 DEBUG: Taking gradient step
2022-12-28 19:43:00.764 DEBUG: Loss 5: {'policy_loss': -0.025328271623309407, 'entropy_loss': -0.082270922139287, 'vf_loss': 0.017693606004667288, 'total_loss': -0.08990558775792912, 'approx_kl': 0.020902569638565183, 'clip_fraction': 0.4440104216337204, 'grad_norm': 2.9095611572265625}
2022-12-28 19:43:01.726 DEBUG: Taking gradient step
2022-12-28 19:43:01.733 DEBUG: Loss 6: {'policy_loss': -0.05751309153346801, 'entropy_loss': -0.08128732070326805, 'vf_loss': 0.015259250148786308, 'total_loss': -0.12354116208794975, 'approx_kl': 0.007336304057389498, 'clip_fraction': 0.390625, 'grad_norm': 3.308854103088379}
2022-12-28 19:43:02.726 DEBUG: Taking gradient step
2022-12-28 19:43:02.734 DEBUG: Loss 7: {'policy_loss': -0.056253452194507364, 'entropy_loss': -0.08165223896503448, 'vf_loss': 0.015244426140863358, 'total_loss': -0.1226612650186785, 'approx_kl': -0.007342288037762046, 'clip_fraction': 0.4088541716337204, 'grad_norm': 3.0956404209136963}
2022-12-28 19:43:03.701 DEBUG: Taking gradient step
2022-12-28 19:43:03.709 DEBUG: Loss 8: {'policy_loss': -0.06141638385080849, 'entropy_loss': -0.08251119032502174, 'vf_loss': 0.01526186223498322, 'total_loss': -0.12866571194084703, 'approx_kl': -0.0070238865446299314, 'clip_fraction': 0.4440104216337204, 'grad_norm': 3.698906421661377}
2022-12-28 19:43:04.678 DEBUG: Taking gradient step
2022-12-28 19:43:04.686 DEBUG: Loss 9: {'policy_loss': -0.03653596214580321, 'entropy_loss': -0.08222295343875885, 'vf_loss': 0.017572687981334975, 'total_loss': -0.10118622760322707, 'approx_kl': 0.020972344325855374, 'clip_fraction': 0.4309895858168602, 'grad_norm': 4.07373046875}
2022-12-28 19:43:04.686 INFO: Optimization: policy loss=-0.037, vf loss=0.018, entropy loss=-0.082, total loss=-0.101, num steps=10
2022-12-28 19:43:04.687 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 19:43:06.499 INFO: Evaluation rollout: return=0.890 (0.0), episode length=6.0
2022-12-28 19:43:06.500 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 19:43:06.503 INFO: Iteration: 42/137, steps: 9072
2022-12-28 19:43:18.644 DEBUG: Atoms are too close
2022-12-28 19:43:53.049 DEBUG: There is a single atom floating around
2022-12-28 19:44:07.482 DEBUG: There is a single atom floating around
2022-12-28 19:44:10.546 INFO: Training rollout: return=-0.907 (5.6), episode length=5.8
2022-12-28 19:44:10.547 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 19:44:10.549 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-9072_train.pkl
2022-12-28 19:44:11.518 DEBUG: Taking gradient step
2022-12-28 19:44:11.526 DEBUG: Loss 0: {'policy_loss': -0.006935074003159616, 'entropy_loss': -0.08283556811511517, 'vf_loss': 0.02086368103379716, 'total_loss': -0.06890696108447762, 'approx_kl': -8.715627330957432e-08, 'clip_fraction': 0.0, 'grad_norm': 10.49686050415039}
2022-12-28 19:44:12.526 DEBUG: Taking gradient step
2022-12-28 19:44:12.535 DEBUG: Loss 1: {'policy_loss': -0.01816005134856855, 'entropy_loss': -0.08291974849998951, 'vf_loss': 0.020946142134540643, 'total_loss': -0.08013365771401741, 'approx_kl': -0.005068379919975996, 'clip_fraction': 0.018229166977107525, 'grad_norm': 10.908120155334473}
2022-12-28 19:44:13.505 DEBUG: Taking gradient step
2022-12-28 19:44:13.513 DEBUG: Loss 2: {'policy_loss': -0.053407700933810115, 'entropy_loss': -0.08306359499692917, 'vf_loss': 0.018434168912487288, 'total_loss': -0.11803712701825199, 'approx_kl': 0.0037613054737448692, 'clip_fraction': 0.14192708395421505, 'grad_norm': 6.073331356048584}
2022-12-28 19:44:14.514 DEBUG: Taking gradient step
2022-12-28 19:44:14.524 DEBUG: Loss 3: {'policy_loss': 0.017364497307193277, 'entropy_loss': -0.08274110220372677, 'vf_loss': 0.025775399183981147, 'total_loss': -0.03960120571255235, 'approx_kl': 0.00917007913812995, 'clip_fraction': 0.32421875, 'grad_norm': 5.591030120849609}
2022-12-28 19:44:15.479 DEBUG: Taking gradient step
2022-12-28 19:44:15.487 DEBUG: Loss 4: {'policy_loss': -0.037247956146185826, 'entropy_loss': -0.08207615651190281, 'vf_loss': 0.02088562460744632, 'total_loss': -0.09843848805064231, 'approx_kl': 0.01782988104969263, 'clip_fraction': 0.4388020858168602, 'grad_norm': 4.363857269287109}
2022-12-28 19:44:16.463 DEBUG: Taking gradient step
2022-12-28 19:44:16.471 DEBUG: Loss 5: {'policy_loss': -0.04068737611862205, 'entropy_loss': -0.08282744698226452, 'vf_loss': 0.02091136480692751, 'total_loss': -0.10260345829395906, 'approx_kl': 0.025112581439316273, 'clip_fraction': 0.4153645858168602, 'grad_norm': 4.64285135269165}
2022-12-28 19:44:17.450 DEBUG: Taking gradient step
2022-12-28 19:44:17.459 DEBUG: Loss 6: {'policy_loss': 0.0035838642319715452, 'entropy_loss': -0.08240486495196819, 'vf_loss': 0.02577732106538906, 'total_loss': -0.05304367965460758, 'approx_kl': 0.018700272776186466, 'clip_fraction': 0.3502604216337204, 'grad_norm': 4.554176330566406}
2022-12-28 19:44:18.454 DEBUG: Taking gradient step
2022-12-28 19:44:18.463 DEBUG: Loss 7: {'policy_loss': -0.02220888413027905, 'entropy_loss': -0.08199016004800797, 'vf_loss': 0.023228165495807078, 'total_loss': -0.08097087868247996, 'approx_kl': -0.010035503190010786, 'clip_fraction': 0.3268229216337204, 'grad_norm': 4.5342302322387695}
2022-12-28 19:44:19.436 DEBUG: Taking gradient step
2022-12-28 19:44:19.444 DEBUG: Loss 8: {'policy_loss': -0.03400784869643397, 'entropy_loss': -0.08250009827315807, 'vf_loss': 0.020911865752569078, 'total_loss': -0.09559608121702295, 'approx_kl': 0.0008277392480522394, 'clip_fraction': 0.3515625, 'grad_norm': 4.069395065307617}
2022-12-28 19:44:20.412 DEBUG: Taking gradient step
2022-12-28 19:44:20.420 DEBUG: Loss 9: {'policy_loss': -0.04047060715270599, 'entropy_loss': -0.0835627019405365, 'vf_loss': 0.020773617416904887, 'total_loss': -0.10325969167633761, 'approx_kl': 0.004394726362079382, 'clip_fraction': 0.3971354216337204, 'grad_norm': 8.012304306030273}
2022-12-28 19:44:20.420 INFO: Optimization: policy loss=-0.040, vf loss=0.021, entropy loss=-0.084, total loss=-0.103, num steps=10
2022-12-28 19:44:20.421 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 19:44:22.056 INFO: Evaluation rollout: return=0.783 (0.0), episode length=6.0
2022-12-28 19:44:22.057 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 19:44:22.060 INFO: Iteration: 43/137, steps: 9288
2022-12-28 19:44:59.533 DEBUG: There is a single atom floating around
2022-12-28 19:45:24.046 INFO: Training rollout: return=0.153 (3.3), episode length=6.0
2022-12-28 19:45:24.048 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 19:45:24.050 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-9288_train.pkl
2022-12-28 19:45:25.055 DEBUG: Taking gradient step
2022-12-28 19:45:25.064 DEBUG: Loss 0: {'policy_loss': -0.029702094935625617, 'entropy_loss': -0.08337407372891903, 'vf_loss': 0.009308961418182386, 'total_loss': -0.10376720724636226, 'approx_kl': 8.746671653625526e-08, 'clip_fraction': 0.0, 'grad_norm': 7.986680030822754}
2022-12-28 19:45:26.052 DEBUG: Taking gradient step
2022-12-28 19:45:26.060 DEBUG: Loss 1: {'policy_loss': 0.04292210656835009, 'entropy_loss': -0.084353381767869, 'vf_loss': 0.014040948964715666, 'total_loss': -0.02739032623480324, 'approx_kl': -0.001848255516961217, 'clip_fraction': 0.0, 'grad_norm': 15.278860092163086}
2022-12-28 19:45:27.059 DEBUG: Taking gradient step
2022-12-28 19:45:27.067 DEBUG: Loss 2: {'policy_loss': -0.0489999695893064, 'entropy_loss': -0.08404068276286125, 'vf_loss': 0.009315065827830893, 'total_loss': -0.12372558652433677, 'approx_kl': -0.012501166202127934, 'clip_fraction': 0.07161458395421505, 'grad_norm': 3.993435859680176}
2022-12-28 19:45:28.088 DEBUG: Taking gradient step
2022-12-28 19:45:28.096 DEBUG: Loss 3: {'policy_loss': -0.043797778572751626, 'entropy_loss': -0.0837576761841774, 'vf_loss': 0.009272357656273812, 'total_loss': -0.11828309710065521, 'approx_kl': 0.0026879243087023497, 'clip_fraction': 0.2395833358168602, 'grad_norm': 6.616093635559082}
2022-12-28 19:45:29.064 DEBUG: Taking gradient step
2022-12-28 19:45:29.072 DEBUG: Loss 4: {'policy_loss': -0.051601758056794664, 'entropy_loss': -0.08376955986022949, 'vf_loss': 0.009284751565995257, 'total_loss': -0.12608656635102888, 'approx_kl': 0.0033313336316496134, 'clip_fraction': 0.3359375, 'grad_norm': 7.1103081703186035}
2022-12-28 19:45:30.059 DEBUG: Taking gradient step
2022-12-28 19:45:30.068 DEBUG: Loss 5: {'policy_loss': 0.013715992769972069, 'entropy_loss': -0.0836813747882843, 'vf_loss': 0.013945693913854746, 'total_loss': -0.05601968810445749, 'approx_kl': -0.0026564172003418207, 'clip_fraction': 0.3854166716337204, 'grad_norm': 2.0372889041900635}
2022-12-28 19:45:31.055 DEBUG: Taking gradient step
2022-12-28 19:45:31.063 DEBUG: Loss 6: {'policy_loss': -0.050856912011975224, 'entropy_loss': -0.08447817154228687, 'vf_loss': 0.009220154613996981, 'total_loss': -0.12611492894026513, 'approx_kl': 0.004502830561250448, 'clip_fraction': 0.37890625, 'grad_norm': 2.472891092300415}
2022-12-28 19:45:32.037 DEBUG: Taking gradient step
2022-12-28 19:45:32.045 DEBUG: Loss 7: {'policy_loss': -0.01119750499184504, 'entropy_loss': -0.08483797498047352, 'vf_loss': 0.011521496745431818, 'total_loss': -0.08451398322688673, 'approx_kl': -0.008373966440558434, 'clip_fraction': 0.41015625, 'grad_norm': 4.3730058670043945}
2022-12-28 19:45:33.018 DEBUG: Taking gradient step
2022-12-28 19:45:33.026 DEBUG: Loss 8: {'policy_loss': 0.05201530290656001, 'entropy_loss': -0.08408713899552822, 'vf_loss': 0.01621159611952106, 'total_loss': -0.01586023996944716, 'approx_kl': 0.0026512849144637585, 'clip_fraction': 0.4296875, 'grad_norm': 1.405462384223938}
2022-12-28 19:45:34.054 DEBUG: Taking gradient step
2022-12-28 19:45:34.062 DEBUG: Loss 9: {'policy_loss': -0.030167579219583025, 'entropy_loss': -0.08539173565804958, 'vf_loss': 0.011620997692181643, 'total_loss': -0.10393831718545096, 'approx_kl': -0.020842429250478745, 'clip_fraction': 0.4895833432674408, 'grad_norm': 1.7025341987609863}
2022-12-28 19:45:34.062 INFO: Optimization: policy loss=-0.030, vf loss=0.012, entropy loss=-0.085, total loss=-0.104, num steps=10
2022-12-28 19:45:34.062 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 19:45:35.915 INFO: Evaluation rollout: return=0.735 (0.0), episode length=6.0
2022-12-28 19:45:35.917 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 19:45:35.920 INFO: Iteration: 44/137, steps: 9504
2022-12-28 19:46:31.978 DEBUG: Atoms are too close
2022-12-28 19:46:37.357 INFO: Training rollout: return=0.263 (3.3), episode length=6.0
2022-12-28 19:46:37.358 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 19:46:37.361 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-9504_train.pkl
2022-12-28 19:46:38.366 DEBUG: Taking gradient step
2022-12-28 19:46:38.374 DEBUG: Loss 0: {'policy_loss': -0.024661071305140947, 'entropy_loss': -0.08342436142265797, 'vf_loss': 0.008022007467091963, 'total_loss': -0.10006342526070694, 'approx_kl': -2.1032366959161664e-08, 'clip_fraction': 0.0, 'grad_norm': 16.21056365966797}
2022-12-28 19:46:39.367 DEBUG: Taking gradient step
2022-12-28 19:46:39.375 DEBUG: Loss 1: {'policy_loss': 0.005107024212439231, 'entropy_loss': -0.08324347250163555, 'vf_loss': 0.0103212633132002, 'total_loss': -0.06781518497599612, 'approx_kl': 0.008253598702140152, 'clip_fraction': 0.00390625, 'grad_norm': 17.26283836364746}
2022-12-28 19:46:40.341 DEBUG: Taking gradient step
2022-12-28 19:46:40.349 DEBUG: Loss 2: {'policy_loss': 0.0007029723891950682, 'entropy_loss': -0.08441061154007912, 'vf_loss': 0.010394667225984602, 'total_loss': -0.07331297192489944, 'approx_kl': 0.02852547261863947, 'clip_fraction': 0.1510416679084301, 'grad_norm': 2.799508571624756}
2022-12-28 19:46:41.350 DEBUG: Taking gradient step
2022-12-28 19:46:41.358 DEBUG: Loss 3: {'policy_loss': -0.043429062522291506, 'entropy_loss': -0.08445162698626518, 'vf_loss': 0.00801691561989162, 'total_loss': -0.11986377388866506, 'approx_kl': 0.02861939708236605, 'clip_fraction': 0.19661458395421505, 'grad_norm': 2.9797632694244385}
2022-12-28 19:46:42.346 DEBUG: Taking gradient step
2022-12-28 19:46:42.354 DEBUG: Loss 4: {'policy_loss': -0.014180286979633742, 'entropy_loss': -0.0833433847874403, 'vf_loss': 0.010341711301758526, 'total_loss': -0.08718196046531551, 'approx_kl': 0.02170562674291432, 'clip_fraction': 0.2005208358168602, 'grad_norm': 2.3694615364074707}
2022-12-28 19:46:43.343 DEBUG: Taking gradient step
2022-12-28 19:46:43.351 DEBUG: Loss 5: {'policy_loss': -0.04668739750565868, 'entropy_loss': -0.08433099091053009, 'vf_loss': 0.007986976162162342, 'total_loss': -0.12303141225402643, 'approx_kl': 0.011073630303144455, 'clip_fraction': 0.2239583358168602, 'grad_norm': 2.4174118041992188}
2022-12-28 19:46:44.378 DEBUG: Taking gradient step
2022-12-28 19:46:44.386 DEBUG: Loss 6: {'policy_loss': -0.005002510054034102, 'entropy_loss': -0.08414367400109768, 'vf_loss': 0.010291175179688045, 'total_loss': -0.07885500887544374, 'approx_kl': 0.001973614329472184, 'clip_fraction': 0.3450520858168602, 'grad_norm': 8.554076194763184}
2022-12-28 19:46:45.336 DEBUG: Taking gradient step
2022-12-28 19:46:45.344 DEBUG: Loss 7: {'policy_loss': -0.03396359993526692, 'entropy_loss': -0.08423882722854614, 'vf_loss': 0.007907278689763306, 'total_loss': -0.11029514847404975, 'approx_kl': -0.008249577833339572, 'clip_fraction': 0.3528645858168602, 'grad_norm': 9.038602828979492}
2022-12-28 19:46:46.339 DEBUG: Taking gradient step
2022-12-28 19:46:46.350 DEBUG: Loss 8: {'policy_loss': 0.000607326329979594, 'entropy_loss': -0.08328461460769176, 'vf_loss': 0.010277266704406523, 'total_loss': -0.07240002157330566, 'approx_kl': -0.002850849647074938, 'clip_fraction': 0.4036458358168602, 'grad_norm': 8.32365608215332}
2022-12-28 19:46:47.301 DEBUG: Taking gradient step
2022-12-28 19:46:47.309 DEBUG: Loss 9: {'policy_loss': -0.05165496365860464, 'entropy_loss': -0.08412050642073154, 'vf_loss': 0.00789769416528856, 'total_loss': -0.12787777591404764, 'approx_kl': -0.006688856519758701, 'clip_fraction': 0.3932291716337204, 'grad_norm': 2.7755730152130127}
2022-12-28 19:46:47.309 INFO: Optimization: policy loss=-0.052, vf loss=0.008, entropy loss=-0.084, total loss=-0.128, num steps=10
2022-12-28 19:46:47.309 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 19:46:49.068 INFO: Evaluation rollout: return=0.258 (0.0), episode length=6.0
2022-12-28 19:46:49.069 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 19:46:49.071 INFO: Iteration: 45/137, steps: 9720
2022-12-28 19:47:22.511 DEBUG: Atoms are too close
2022-12-28 19:47:48.440 DEBUG: There is a single atom floating around
2022-12-28 19:47:49.684 DEBUG: Atoms are too close
2022-12-28 19:47:50.629 INFO: Training rollout: return=-0.874 (5.6), episode length=5.9
2022-12-28 19:47:50.631 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 19:47:50.633 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-9720_train.pkl
2022-12-28 19:47:51.631 DEBUG: Taking gradient step
2022-12-28 19:47:51.643 DEBUG: Loss 0: {'policy_loss': 0.007540327492380256, 'entropy_loss': -0.08581498451530933, 'vf_loss': 0.02972494000367249, 'total_loss': -0.04854971701925658, 'approx_kl': -6.441647826260777e-09, 'clip_fraction': 0.0, 'grad_norm': 20.961204528808594}
2022-12-28 19:47:52.642 DEBUG: Taking gradient step
2022-12-28 19:47:52.650 DEBUG: Loss 1: {'policy_loss': -0.00906066709679612, 'entropy_loss': -0.08553098887205124, 'vf_loss': 0.02966570926232649, 'total_loss': -0.06492594670652087, 'approx_kl': 0.006338891806080937, 'clip_fraction': 0.049479166977107525, 'grad_norm': 9.855393409729004}
2022-12-28 19:47:53.638 DEBUG: Taking gradient step
2022-12-28 19:47:53.647 DEBUG: Loss 2: {'policy_loss': -0.035709825397934505, 'entropy_loss': -0.08566706627607346, 'vf_loss': 0.026818190647019305, 'total_loss': -0.09455870102698866, 'approx_kl': 0.010943763656541705, 'clip_fraction': 0.1666666679084301, 'grad_norm': 6.411306381225586}
2022-12-28 19:47:54.615 DEBUG: Taking gradient step
2022-12-28 19:47:54.623 DEBUG: Loss 3: {'policy_loss': -0.008384407513157457, 'entropy_loss': -0.08493293263018131, 'vf_loss': 0.029401697034419298, 'total_loss': -0.06391564310891946, 'approx_kl': 0.023561605892609805, 'clip_fraction': 0.2955729216337204, 'grad_norm': 7.461965560913086}
2022-12-28 19:47:55.602 DEBUG: Taking gradient step
2022-12-28 19:47:55.610 DEBUG: Loss 4: {'policy_loss': 0.00189825596121811, 'entropy_loss': -0.0854032039642334, 'vf_loss': 0.03184978906745453, 'total_loss': -0.05165515893556075, 'approx_kl': 0.03645740170031786, 'clip_fraction': 0.3359375, 'grad_norm': 4.831692695617676}
2022-12-28 19:47:56.608 DEBUG: Taking gradient step
2022-12-28 19:47:56.615 DEBUG: Loss 5: {'policy_loss': -0.04655411700618241, 'entropy_loss': -0.08605765178799629, 'vf_loss': 0.02673562435570695, 'total_loss': -0.10587614443847175, 'approx_kl': 0.01846599718555808, 'clip_fraction': 0.3463541716337204, 'grad_norm': 4.97076940536499}
2022-12-28 19:47:57.592 DEBUG: Taking gradient step
2022-12-28 19:47:57.600 DEBUG: Loss 6: {'policy_loss': -0.07412640950246138, 'entropy_loss': -0.08529636077582836, 'vf_loss': 0.02411742810659592, 'total_loss': -0.13530534217169382, 'approx_kl': 0.012589780613780022, 'clip_fraction': 0.421875, 'grad_norm': 3.607071876525879}
2022-12-28 19:47:58.558 DEBUG: Taking gradient step
2022-12-28 19:47:58.566 DEBUG: Loss 7: {'policy_loss': -0.05101597776022726, 'entropy_loss': -0.08569883555173874, 'vf_loss': 0.026301025991055188, 'total_loss': -0.1104137873209108, 'approx_kl': 0.0025341100990772247, 'clip_fraction': 0.4440104216337204, 'grad_norm': 3.9843661785125732}
2022-12-28 19:47:59.537 DEBUG: Taking gradient step
2022-12-28 19:47:59.545 DEBUG: Loss 8: {'policy_loss': -0.03043018936782898, 'entropy_loss': -0.08494533225893974, 'vf_loss': 0.028471992300518206, 'total_loss': -0.08690352932625052, 'approx_kl': 0.0330443549901247, 'clip_fraction': 0.453125, 'grad_norm': 3.7446794509887695}
2022-12-28 19:48:00.491 DEBUG: Taking gradient step
2022-12-28 19:48:00.499 DEBUG: Loss 9: {'policy_loss': 0.007043541363270969, 'entropy_loss': -0.08527782373130322, 'vf_loss': 0.0333029754432812, 'total_loss': -0.04493130692475103, 'approx_kl': 0.009682531235739589, 'clip_fraction': 0.49609375, 'grad_norm': 2.6625773906707764}
2022-12-28 19:48:00.499 INFO: Optimization: policy loss=0.007, vf loss=0.033, entropy loss=-0.085, total loss=-0.045, num steps=10
2022-12-28 19:48:00.500 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 19:48:02.336 INFO: Evaluation rollout: return=0.738 (0.0), episode length=6.0
2022-12-28 19:48:02.337 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 19:48:02.339 INFO: Iteration: 46/137, steps: 9936
2022-12-28 19:48:42.155 DEBUG: There is a single atom floating around
2022-12-28 19:49:05.039 INFO: Training rollout: return=0.217 (3.3), episode length=6.0
2022-12-28 19:49:05.041 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 19:49:05.044 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-9936_train.pkl
2022-12-28 19:49:06.114 DEBUG: Taking gradient step
2022-12-28 19:49:06.122 DEBUG: Loss 0: {'policy_loss': 0.012145404952496795, 'entropy_loss': -0.08556723408401012, 'vf_loss': 0.011964443973096806, 'total_loss': -0.061457385158416526, 'approx_kl': 5.541369318962097e-08, 'clip_fraction': 0.0, 'grad_norm': 7.197670936584473}
2022-12-28 19:49:07.144 DEBUG: Taking gradient step
2022-12-28 19:49:07.152 DEBUG: Loss 1: {'policy_loss': 0.03861607386200188, 'entropy_loss': -0.08439629711210728, 'vf_loss': 0.01447624597311602, 'total_loss': -0.031303977276989386, 'approx_kl': 0.0003080464666709304, 'clip_fraction': 0.049479166977107525, 'grad_norm': 15.224283218383789}
2022-12-28 19:49:08.148 DEBUG: Taking gradient step
2022-12-28 19:49:08.155 DEBUG: Loss 2: {'policy_loss': -0.027848748235680378, 'entropy_loss': -0.08462014608085155, 'vf_loss': 0.009907975785342218, 'total_loss': -0.1025609185311897, 'approx_kl': 0.010204311809502542, 'clip_fraction': 0.2122395858168602, 'grad_norm': 4.943161487579346}
2022-12-28 19:49:09.182 DEBUG: Taking gradient step
2022-12-28 19:49:09.194 DEBUG: Loss 3: {'policy_loss': -0.0357957618986979, 'entropy_loss': -0.08427626453340054, 'vf_loss': 0.010047428103600872, 'total_loss': -0.11002459832849758, 'approx_kl': 0.022026713471859694, 'clip_fraction': 0.3489583358168602, 'grad_norm': 5.5076704025268555}
2022-12-28 19:49:10.233 DEBUG: Taking gradient step
2022-12-28 19:49:10.242 DEBUG: Loss 4: {'policy_loss': -0.040288484018349724, 'entropy_loss': -0.08376949094235897, 'vf_loss': 0.010141879097827662, 'total_loss': -0.11391609586288103, 'approx_kl': 0.026978044537827373, 'clip_fraction': 0.3515625, 'grad_norm': 4.19761323928833}
2022-12-28 19:49:11.210 DEBUG: Taking gradient step
2022-12-28 19:49:11.218 DEBUG: Loss 5: {'policy_loss': 0.01782435748127449, 'entropy_loss': -0.08265752717852592, 'vf_loss': 0.014854688458289866, 'total_loss': -0.04997848123896156, 'approx_kl': 0.0075877022463828325, 'clip_fraction': 0.375, 'grad_norm': 2.8979599475860596}
2022-12-28 19:49:12.180 DEBUG: Taking gradient step
2022-12-28 19:49:12.188 DEBUG: Loss 6: {'policy_loss': 0.05685688210517263, 'entropy_loss': -0.08246676251292229, 'vf_loss': 0.016661703302505385, 'total_loss': -0.008948177105244287, 'approx_kl': 0.02643800829537213, 'clip_fraction': 0.4153645858168602, 'grad_norm': 3.2545390129089355}
2022-12-28 19:49:13.223 DEBUG: Taking gradient step
2022-12-28 19:49:13.232 DEBUG: Loss 7: {'policy_loss': -0.018029213100298456, 'entropy_loss': -0.0829315260052681, 'vf_loss': 0.012169186093858298, 'total_loss': -0.08879155301170827, 'approx_kl': -0.00033760862424969673, 'clip_fraction': 0.4466145858168602, 'grad_norm': 2.9305758476257324}
2022-12-28 19:49:14.240 DEBUG: Taking gradient step
2022-12-28 19:49:14.248 DEBUG: Loss 8: {'policy_loss': -0.055509547842929635, 'entropy_loss': -0.08285756409168243, 'vf_loss': 0.009881885333151808, 'total_loss': -0.12848522660146025, 'approx_kl': 0.019295922480523586, 'clip_fraction': 0.4283854216337204, 'grad_norm': 2.1191811561584473}
2022-12-28 19:49:15.291 DEBUG: Early stopping at step 9 for reaching max KL.
2022-12-28 19:49:15.292 INFO: Optimization: policy loss=-0.056, vf loss=0.010, entropy loss=-0.083, total loss=-0.128, num steps=9
2022-12-28 19:49:15.292 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 19:49:17.091 INFO: Evaluation rollout: return=0.740 (0.0), episode length=6.0
2022-12-28 19:49:17.092 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 19:49:17.095 INFO: Iteration: 47/137, steps: 10152
2022-12-28 19:49:34.601 DEBUG: Atoms are too close
2022-12-28 19:49:36.694 DEBUG: Atoms are too close
2022-12-28 19:50:15.758 DEBUG: There is a single atom floating around
2022-12-28 19:50:18.814 INFO: Training rollout: return=-0.943 (5.6), episode length=6.0
2022-12-28 19:50:18.816 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 19:50:18.818 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-10152_train.pkl
2022-12-28 19:50:19.822 DEBUG: Taking gradient step
2022-12-28 19:50:19.830 DEBUG: Loss 0: {'policy_loss': -0.0009561832851970528, 'entropy_loss': -0.08234203420579433, 'vf_loss': 0.031620003998007566, 'total_loss': -0.05167821349298383, 'approx_kl': 5.1533184830532264e-08, 'clip_fraction': 0.0, 'grad_norm': 19.87759780883789}
2022-12-28 19:50:20.795 DEBUG: Taking gradient step
2022-12-28 19:50:20.802 DEBUG: Loss 1: {'policy_loss': -0.04362424465857614, 'entropy_loss': -0.08179175108671188, 'vf_loss': 0.029394640257518406, 'total_loss': -0.0960213554877696, 'approx_kl': -0.0007589375600218773, 'clip_fraction': 0.06380208395421505, 'grad_norm': 15.816225051879883}
2022-12-28 19:50:21.783 DEBUG: Taking gradient step
2022-12-28 19:50:21.793 DEBUG: Loss 2: {'policy_loss': -0.030089436237986787, 'entropy_loss': -0.08190075308084488, 'vf_loss': 0.03168509041317785, 'total_loss': -0.08030509890565381, 'approx_kl': 0.019436883041635156, 'clip_fraction': 0.2877604179084301, 'grad_norm': 7.434483051300049}
2022-12-28 19:50:22.756 DEBUG: Taking gradient step
2022-12-28 19:50:22.763 DEBUG: Loss 3: {'policy_loss': -0.052541046017797785, 'entropy_loss': -0.08228117227554321, 'vf_loss': 0.029321605226731353, 'total_loss': -0.10550061306660966, 'approx_kl': 0.040596799459308386, 'clip_fraction': 0.3932291716337204, 'grad_norm': 6.174849510192871}
2022-12-28 19:50:23.773 DEBUG: Taking gradient step
2022-12-28 19:50:23.781 DEBUG: Loss 4: {'policy_loss': -0.07457026579302803, 'entropy_loss': -0.08235486410558224, 'vf_loss': 0.027052984697002437, 'total_loss': -0.12987214520160784, 'approx_kl': 0.03791404329240322, 'clip_fraction': 0.453125, 'grad_norm': 5.469944953918457}
2022-12-28 19:50:24.764 DEBUG: Early stopping at step 5 for reaching max KL.
2022-12-28 19:50:24.764 INFO: Optimization: policy loss=-0.075, vf loss=0.027, entropy loss=-0.082, total loss=-0.130, num steps=5
2022-12-28 19:50:24.765 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 19:50:26.607 INFO: Evaluation rollout: return=0.734 (0.0), episode length=6.0
2022-12-28 19:50:26.608 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 19:50:26.611 INFO: Iteration: 48/137, steps: 10368
2022-12-28 19:50:45.307 DEBUG: Atoms are too close
2022-12-28 19:51:29.090 INFO: Training rollout: return=0.209 (3.3), episode length=6.0
2022-12-28 19:51:29.092 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 19:51:29.094 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-10368_train.pkl
2022-12-28 19:51:30.147 DEBUG: Taking gradient step
2022-12-28 19:51:30.156 DEBUG: Loss 0: {'policy_loss': 0.022408435628906154, 'entropy_loss': -0.08215544186532497, 'vf_loss': 0.011626780327747367, 'total_loss': -0.048120225908671446, 'approx_kl': 1.7850349198766935e-08, 'clip_fraction': 0.0, 'grad_norm': 24.86901092529297}
2022-12-28 19:51:31.171 DEBUG: Taking gradient step
2022-12-28 19:51:31.183 DEBUG: Loss 1: {'policy_loss': -0.030121695604999887, 'entropy_loss': -0.08103305287659168, 'vf_loss': 0.00920546268098522, 'total_loss': -0.10194928580060636, 'approx_kl': 0.014806018909439445, 'clip_fraction': 0.04296875, 'grad_norm': 5.105948448181152}
2022-12-28 19:51:32.194 DEBUG: Taking gradient step
2022-12-28 19:51:32.202 DEBUG: Loss 2: {'policy_loss': -0.03363615925968594, 'entropy_loss': -0.08147099800407887, 'vf_loss': 0.009172742209450593, 'total_loss': -0.10593441505431421, 'approx_kl': 0.03393700462765992, 'clip_fraction': 0.1588541679084301, 'grad_norm': 4.179386138916016}
2022-12-28 19:51:33.194 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-28 19:51:33.194 INFO: Optimization: policy loss=-0.034, vf loss=0.009, entropy loss=-0.081, total loss=-0.106, num steps=3
2022-12-28 19:51:33.195 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 19:51:35.055 INFO: Evaluation rollout: return=0.734 (0.0), episode length=6.0
2022-12-28 19:51:35.056 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 19:51:35.059 INFO: Iteration: 49/137, steps: 10584
2022-12-28 19:52:13.503 DEBUG: There is a single atom floating around
2022-12-28 19:52:37.135 INFO: Training rollout: return=0.237 (3.3), episode length=6.0
2022-12-28 19:52:37.136 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 19:52:37.138 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-10584_train.pkl
2022-12-28 19:52:38.127 DEBUG: Taking gradient step
2022-12-28 19:52:38.135 DEBUG: Loss 0: {'policy_loss': 0.014779118324406645, 'entropy_loss': -0.08363569900393486, 'vf_loss': 0.012051033355321868, 'total_loss': -0.05680554732420635, 'approx_kl': -4.943770548493376e-08, 'clip_fraction': 0.0, 'grad_norm': 31.947694778442383}
2022-12-28 19:52:39.156 DEBUG: Taking gradient step
2022-12-28 19:52:39.164 DEBUG: Loss 1: {'policy_loss': 0.005848011638130774, 'entropy_loss': -0.08321746438741684, 'vf_loss': 0.011940901105774695, 'total_loss': -0.06542855164351136, 'approx_kl': 0.01002698065713048, 'clip_fraction': 0.10416666697710752, 'grad_norm': 9.390336990356445}
2022-12-28 19:52:40.192 DEBUG: Taking gradient step
2022-12-28 19:52:40.200 DEBUG: Loss 2: {'policy_loss': 0.0068516120479252905, 'entropy_loss': -0.08281726948916912, 'vf_loss': 0.011920697473864723, 'total_loss': -0.06404495996737912, 'approx_kl': 0.0209674087818712, 'clip_fraction': 0.2486979179084301, 'grad_norm': 7.565915584564209}
2022-12-28 19:52:41.191 DEBUG: Taking gradient step
2022-12-28 19:52:41.202 DEBUG: Loss 3: {'policy_loss': -0.027899596211781126, 'entropy_loss': -0.08249003440141678, 'vf_loss': 0.009559833376820715, 'total_loss': -0.1008297972363772, 'approx_kl': 0.04451151192188263, 'clip_fraction': 0.2747395858168602, 'grad_norm': 7.86613130569458}
2022-12-28 19:52:42.243 DEBUG: Taking gradient step
2022-12-28 19:52:42.251 DEBUG: Loss 4: {'policy_loss': 0.0009322362850119302, 'entropy_loss': -0.08342148177325726, 'vf_loss': 0.012120654944771596, 'total_loss': -0.07036859054347373, 'approx_kl': 0.04336810577660799, 'clip_fraction': 0.3502604216337204, 'grad_norm': 12.976968765258789}
2022-12-28 19:52:43.268 DEBUG: Early stopping at step 5 for reaching max KL.
2022-12-28 19:52:43.269 INFO: Optimization: policy loss=0.001, vf loss=0.012, entropy loss=-0.083, total loss=-0.070, num steps=5
2022-12-28 19:52:43.269 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 19:52:45.157 INFO: Evaluation rollout: return=0.736 (0.0), episode length=6.0
2022-12-28 19:52:45.158 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 19:52:45.160 INFO: Iteration: 50/137, steps: 10800
2022-12-28 19:53:26.254 DEBUG: There is a single atom floating around
2022-12-28 19:53:47.458 INFO: Training rollout: return=0.260 (3.3), episode length=6.0
2022-12-28 19:53:47.460 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 19:53:47.462 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-10800_train.pkl
2022-12-28 19:53:48.464 DEBUG: Taking gradient step
2022-12-28 19:53:48.473 DEBUG: Loss 0: {'policy_loss': -0.029131718359805207, 'entropy_loss': -0.08178370259702206, 'vf_loss': 0.009244541645589884, 'total_loss': -0.10167087931123739, 'approx_kl': -2.1730860666480112e-08, 'clip_fraction': 0.0, 'grad_norm': 14.865494728088379}
2022-12-28 19:53:49.475 DEBUG: Taking gradient step
2022-12-28 19:53:49.483 DEBUG: Loss 1: {'policy_loss': 0.0020558234322423444, 'entropy_loss': -0.08226659893989563, 'vf_loss': 0.011778983597779054, 'total_loss': -0.06843179190987424, 'approx_kl': 0.013869871152564883, 'clip_fraction': 0.1276041679084301, 'grad_norm': 8.36158561706543}
2022-12-28 19:53:50.456 DEBUG: Taking gradient step
2022-12-28 19:53:50.464 DEBUG: Loss 2: {'policy_loss': -0.037129197463670174, 'entropy_loss': -0.08177013136446476, 'vf_loss': 0.009235976259619073, 'total_loss': -0.10966335256851586, 'approx_kl': 0.037351361475884914, 'clip_fraction': 0.1979166679084301, 'grad_norm': 7.224151134490967}
2022-12-28 19:53:51.492 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-28 19:53:51.493 INFO: Optimization: policy loss=-0.037, vf loss=0.009, entropy loss=-0.082, total loss=-0.110, num steps=3
2022-12-28 19:53:51.493 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 19:53:53.256 INFO: Evaluation rollout: return=0.762 (0.0), episode length=6.0
2022-12-28 19:53:53.257 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 19:53:53.259 DEBUG: Deleting old model: runs/CH3NO_painn/models/CH3NO_painn_run-1_steps-8856.model
2022-12-28 19:53:53.262 DEBUG: Saving model: runs/CH3NO_painn/models/CH3NO_painn_run-1_steps-11016.model
2022-12-28 19:53:53.289 INFO: Iteration: 51/137, steps: 11016
2022-12-28 19:54:31.653 DEBUG: Atoms are too close
2022-12-28 19:54:52.340 DEBUG: Atoms are too close
2022-12-28 19:54:53.898 INFO: Training rollout: return=-0.301 (4.6), episode length=6.0
2022-12-28 19:54:53.900 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 19:54:53.902 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-11016_train.pkl
2022-12-28 19:54:54.897 DEBUG: Taking gradient step
2022-12-28 19:54:54.905 DEBUG: Loss 0: {'policy_loss': -0.033655315038711844, 'entropy_loss': -0.08305566944181919, 'vf_loss': 0.018336231258595542, 'total_loss': -0.09837475322193548, 'approx_kl': -6.05359673500061e-09, 'clip_fraction': 0.0, 'grad_norm': 13.683069229125977}
2022-12-28 19:54:55.911 DEBUG: Taking gradient step
2022-12-28 19:54:55.920 DEBUG: Loss 1: {'policy_loss': 0.011288295192632202, 'entropy_loss': -0.08327836729586124, 'vf_loss': 0.02348022960088675, 'total_loss': -0.048509842502342276, 'approx_kl': 0.01918209856376052, 'clip_fraction': 0.1197916679084301, 'grad_norm': 16.291824340820312}
2022-12-28 19:54:56.943 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-28 19:54:56.943 INFO: Optimization: policy loss=0.011, vf loss=0.023, entropy loss=-0.083, total loss=-0.049, num steps=2
2022-12-28 19:54:56.944 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 19:54:58.648 INFO: Evaluation rollout: return=0.768 (0.0), episode length=6.0
2022-12-28 19:54:58.649 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 19:54:58.652 INFO: Iteration: 52/137, steps: 11232
2022-12-28 19:55:16.564 DEBUG: Atoms are too close
2022-12-28 19:55:31.822 DEBUG: Atoms are too close
2022-12-28 19:55:59.043 INFO: Training rollout: return=-0.324 (4.6), episode length=6.0
2022-12-28 19:55:59.045 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 19:55:59.047 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-11232_train.pkl
2022-12-28 19:56:00.091 DEBUG: Taking gradient step
2022-12-28 19:56:00.099 DEBUG: Loss 0: {'policy_loss': -0.008214804312994895, 'entropy_loss': -0.0838538259267807, 'vf_loss': 0.020192322571775057, 'total_loss': -0.07187630766800053, 'approx_kl': -1.1051694670527468e-07, 'clip_fraction': 0.0, 'grad_norm': 21.83176040649414}
2022-12-28 19:56:01.065 DEBUG: Taking gradient step
2022-12-28 19:56:01.073 DEBUG: Loss 1: {'policy_loss': -0.0408696612423734, 'entropy_loss': -0.08324404619634151, 'vf_loss': 0.017259270491578948, 'total_loss': -0.10685443694713598, 'approx_kl': -0.0023134874645620584, 'clip_fraction': 0.033854166977107525, 'grad_norm': 6.142460823059082}
2022-12-28 19:56:02.027 DEBUG: Taking gradient step
2022-12-28 19:56:02.035 DEBUG: Loss 2: {'policy_loss': 0.004837761813783356, 'entropy_loss': -0.08403394930064678, 'vf_loss': 0.02214180853814114, 'total_loss': -0.05705437894872228, 'approx_kl': 0.0007120093796402216, 'clip_fraction': 0.1471354179084301, 'grad_norm': 10.8454008102417}
2022-12-28 19:56:03.068 DEBUG: Taking gradient step
2022-12-28 19:56:03.081 DEBUG: Loss 3: {'policy_loss': -0.032495327732804946, 'entropy_loss': -0.08426632545888424, 'vf_loss': 0.019551169186324508, 'total_loss': -0.09721048400536468, 'approx_kl': 0.010521394899114966, 'clip_fraction': 0.2109375, 'grad_norm': 13.162306785583496}
2022-12-28 19:56:04.051 DEBUG: Taking gradient step
2022-12-28 19:56:04.059 DEBUG: Loss 4: {'policy_loss': 0.010460039434770446, 'entropy_loss': -0.08477011136710644, 'vf_loss': 0.0247424673647716, 'total_loss': -0.0495676045675644, 'approx_kl': 0.03755539422854781, 'clip_fraction': 0.4205729216337204, 'grad_norm': 3.8581366539001465}
2022-12-28 19:56:05.025 DEBUG: Taking gradient step
2022-12-28 19:56:05.033 DEBUG: Loss 5: {'policy_loss': -0.037682601304536475, 'entropy_loss': -0.08478762954473495, 'vf_loss': 0.019404970383037172, 'total_loss': -0.10306526046623427, 'approx_kl': 0.029195069044362754, 'clip_fraction': 0.4518229216337204, 'grad_norm': 3.7296528816223145}
2022-12-28 19:56:06.008 DEBUG: Taking gradient step
2022-12-28 19:56:06.016 DEBUG: Loss 6: {'policy_loss': -0.03805789411016997, 'entropy_loss': -0.08554643206298351, 'vf_loss': 0.019275930322904904, 'total_loss': -0.10432839585024858, 'approx_kl': 0.018544868798926473, 'clip_fraction': 0.47265625, 'grad_norm': 3.104503870010376}
2022-12-28 19:56:07.037 DEBUG: Early stopping at step 7 for reaching max KL.
2022-12-28 19:56:07.037 INFO: Optimization: policy loss=-0.038, vf loss=0.019, entropy loss=-0.086, total loss=-0.104, num steps=7
2022-12-28 19:56:07.038 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 19:56:08.819 INFO: Evaluation rollout: return=0.718 (0.0), episode length=6.0
2022-12-28 19:56:08.820 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 19:56:08.822 INFO: Iteration: 53/137, steps: 11448
2022-12-28 19:57:10.443 INFO: Training rollout: return=0.753 (0.4), episode length=6.0
2022-12-28 19:57:10.444 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 19:57:10.447 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-11448_train.pkl
2022-12-28 19:57:11.477 DEBUG: Taking gradient step
2022-12-28 19:57:11.489 DEBUG: Loss 0: {'policy_loss': -0.012933493795695025, 'entropy_loss': -0.08328824117779732, 'vf_loss': 0.0007730037638944357, 'total_loss': -0.0954487312095979, 'approx_kl': -3.112170077201881e-08, 'clip_fraction': 0.0, 'grad_norm': 15.419380187988281}
2022-12-28 19:57:12.496 DEBUG: Taking gradient step
2022-12-28 19:57:12.504 DEBUG: Loss 1: {'policy_loss': -0.010908627518864386, 'entropy_loss': -0.08316558413207531, 'vf_loss': 0.000823861630404088, 'total_loss': -0.09325035002053561, 'approx_kl': 0.009430091129615903, 'clip_fraction': 0.041666666977107525, 'grad_norm': 9.787099838256836}
2022-12-28 19:57:13.593 DEBUG: Taking gradient step
2022-12-28 19:57:13.605 DEBUG: Loss 2: {'policy_loss': 0.013601773149115488, 'entropy_loss': -0.08358487114310265, 'vf_loss': 0.000865241469957914, 'total_loss': -0.06911785652402924, 'approx_kl': 0.020423647947609425, 'clip_fraction': 0.13671875, 'grad_norm': 14.250539779663086}
2022-12-28 19:57:14.603 DEBUG: Taking gradient step
2022-12-28 19:57:14.614 DEBUG: Loss 3: {'policy_loss': 0.023382818627806196, 'entropy_loss': -0.08393241465091705, 'vf_loss': 0.0008846246690261087, 'total_loss': -0.05966497135408475, 'approx_kl': 0.036584006156772375, 'clip_fraction': 0.2447916716337204, 'grad_norm': 11.76073932647705}
2022-12-28 19:57:15.579 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-28 19:57:15.580 INFO: Optimization: policy loss=0.023, vf loss=0.001, entropy loss=-0.084, total loss=-0.060, num steps=4
2022-12-28 19:57:15.580 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 19:57:17.393 INFO: Evaluation rollout: return=0.684 (0.0), episode length=6.0
2022-12-28 19:57:17.395 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 19:57:17.397 INFO: Iteration: 54/137, steps: 11664
2022-12-28 19:58:13.475 DEBUG: There is a single atom floating around
2022-12-28 19:58:18.652 DEBUG: Atoms are too close
2022-12-28 19:58:18.653 DEBUG: There is a single atom floating around
2022-12-28 19:58:18.707 INFO: Training rollout: return=-0.840 (5.6), episode length=6.0
2022-12-28 19:58:18.709 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 19:58:18.711 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-11664_train.pkl
2022-12-28 19:58:19.721 DEBUG: Taking gradient step
2022-12-28 19:58:19.729 DEBUG: Loss 0: {'policy_loss': 0.027385157238909687, 'entropy_loss': -0.0844991859048605, 'vf_loss': 0.03235980999900535, 'total_loss': -0.024754218666945473, 'approx_kl': 2.444721758365631e-08, 'clip_fraction': 0.0, 'grad_norm': 15.5738525390625}
2022-12-28 19:58:20.715 DEBUG: Taking gradient step
2022-12-28 19:58:20.723 DEBUG: Loss 1: {'policy_loss': 0.06951158702447514, 'entropy_loss': -0.08476296626031399, 'vf_loss': 0.0371602425501277, 'total_loss': 0.021908863314288873, 'approx_kl': 0.008134947936923709, 'clip_fraction': 0.03125, 'grad_norm': 12.733309745788574}
2022-12-28 19:58:21.745 DEBUG: Taking gradient step
2022-12-28 19:58:21.757 DEBUG: Loss 2: {'policy_loss': 0.015548988158657722, 'entropy_loss': -0.08539405092597008, 'vf_loss': 0.0323664465378213, 'total_loss': -0.03747861622949106, 'approx_kl': 0.01771063031628728, 'clip_fraction': 0.14453125, 'grad_norm': 14.777047157287598}
2022-12-28 19:58:22.711 DEBUG: Taking gradient step
2022-12-28 19:58:22.719 DEBUG: Loss 3: {'policy_loss': -0.016679089537543327, 'entropy_loss': -0.0852795671671629, 'vf_loss': 0.029862125126486692, 'total_loss': -0.07209653157821953, 'approx_kl': 0.016390026081353426, 'clip_fraction': 0.1809895858168602, 'grad_norm': 12.136528968811035}
2022-12-28 19:58:23.737 DEBUG: Taking gradient step
2022-12-28 19:58:23.745 DEBUG: Loss 4: {'policy_loss': -0.023981576150789264, 'entropy_loss': -0.08456400223076344, 'vf_loss': 0.029845422944689535, 'total_loss': -0.07870015543686315, 'approx_kl': 0.010054100130219012, 'clip_fraction': 0.2109375, 'grad_norm': 4.528111934661865}
2022-12-28 19:58:24.737 DEBUG: Taking gradient step
2022-12-28 19:58:24.745 DEBUG: Loss 5: {'policy_loss': -0.05054804953331596, 'entropy_loss': -0.08505857177078724, 'vf_loss': 0.02746817629720099, 'total_loss': -0.1081384450069022, 'approx_kl': 0.02424078853800893, 'clip_fraction': 0.2864583358168602, 'grad_norm': 5.8111162185668945}
2022-12-28 19:58:25.708 DEBUG: Taking gradient step
2022-12-28 19:58:25.716 DEBUG: Loss 6: {'policy_loss': -0.054592043408058614, 'entropy_loss': -0.08502812683582306, 'vf_loss': 0.02746172675556117, 'total_loss': -0.11215844348832049, 'approx_kl': 0.015480225818464532, 'clip_fraction': 0.3346354216337204, 'grad_norm': 5.4221320152282715}
2022-12-28 19:58:26.716 DEBUG: Taking gradient step
2022-12-28 19:58:26.723 DEBUG: Loss 7: {'policy_loss': -0.05527169437826598, 'entropy_loss': -0.0844146478921175, 'vf_loss': 0.027393267820248424, 'total_loss': -0.11229307445013506, 'approx_kl': 0.021337951067835093, 'clip_fraction': 0.3815104216337204, 'grad_norm': 3.920470714569092}
2022-12-28 19:58:27.757 DEBUG: Taking gradient step
2022-12-28 19:58:27.766 DEBUG: Loss 8: {'policy_loss': -0.03619838628705819, 'entropy_loss': -0.08458785898983479, 'vf_loss': 0.029735771759212194, 'total_loss': -0.09105047351768078, 'approx_kl': 0.004071272211149335, 'clip_fraction': 0.3802083358168602, 'grad_norm': 4.066680431365967}
2022-12-28 19:58:28.753 DEBUG: Taking gradient step
2022-12-28 19:58:28.763 DEBUG: Loss 9: {'policy_loss': -0.0570843632744701, 'entropy_loss': -0.08456869423389435, 'vf_loss': 0.02754394311244819, 'total_loss': -0.11410911439591626, 'approx_kl': 0.0039934986270964146, 'clip_fraction': 0.3697916716337204, 'grad_norm': 4.13615083694458}
2022-12-28 19:58:28.763 INFO: Optimization: policy loss=-0.057, vf loss=0.028, entropy loss=-0.085, total loss=-0.114, num steps=10
2022-12-28 19:58:28.764 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 19:58:30.571 INFO: Evaluation rollout: return=0.730 (0.0), episode length=6.0
2022-12-28 19:58:30.572 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 19:58:30.574 INFO: Iteration: 55/137, steps: 11880
2022-12-28 19:58:49.929 DEBUG: There is a single atom floating around
2022-12-28 19:59:32.050 INFO: Training rollout: return=0.279 (3.3), episode length=6.0
2022-12-28 19:59:32.051 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 19:59:32.054 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-11880_train.pkl
2022-12-28 19:59:33.055 DEBUG: Taking gradient step
2022-12-28 19:59:33.064 DEBUG: Loss 0: {'policy_loss': 0.0529457085261169, 'entropy_loss': -0.08477163501083851, 'vf_loss': 0.01462235677468371, 'total_loss': -0.017203569710037905, 'approx_kl': -7.085812825380344e-08, 'clip_fraction': 0.0, 'grad_norm': 17.794921875}
2022-12-28 19:59:34.055 DEBUG: Taking gradient step
2022-12-28 19:59:34.063 DEBUG: Loss 1: {'policy_loss': -0.03784245566270933, 'entropy_loss': -0.08511899784207344, 'vf_loss': 0.009996407328426398, 'total_loss': -0.11296504617635637, 'approx_kl': -0.0008954050717875361, 'clip_fraction': 0.00390625, 'grad_norm': 9.981489181518555}
2022-12-28 19:59:35.081 DEBUG: Taking gradient step
2022-12-28 19:59:35.089 DEBUG: Loss 2: {'policy_loss': -0.006664853338450835, 'entropy_loss': -0.0845241155475378, 'vf_loss': 0.012329298108885193, 'total_loss': -0.07885967077710344, 'approx_kl': 0.009544787695631385, 'clip_fraction': 0.1419270858168602, 'grad_norm': 3.5124783515930176}
2022-12-28 19:59:36.070 DEBUG: Taking gradient step
2022-12-28 19:59:36.078 DEBUG: Loss 3: {'policy_loss': -0.04448276181435806, 'entropy_loss': -0.08509376272559166, 'vf_loss': 0.010033805648163792, 'total_loss': -0.11954271889178592, 'approx_kl': 0.02357647684402764, 'clip_fraction': 0.29296875, 'grad_norm': 3.4650111198425293}
2022-12-28 19:59:37.108 DEBUG: Taking gradient step
2022-12-28 19:59:37.116 DEBUG: Loss 4: {'policy_loss': -0.013389178960751907, 'entropy_loss': -0.08512285724282265, 'vf_loss': 0.012285533472360843, 'total_loss': -0.08622650273121371, 'approx_kl': 0.03811200428754091, 'clip_fraction': 0.4283854216337204, 'grad_norm': 3.5196619033813477}
2022-12-28 19:59:38.167 DEBUG: Taking gradient step
2022-12-28 19:59:38.175 DEBUG: Loss 5: {'policy_loss': -0.013152003622827584, 'entropy_loss': -0.08447830565273762, 'vf_loss': 0.012190685372072418, 'total_loss': -0.08543962390349277, 'approx_kl': 0.036425577476620674, 'clip_fraction': 0.4244791716337204, 'grad_norm': 4.53181791305542}
2022-12-28 19:59:39.154 DEBUG: Taking gradient step
2022-12-28 19:59:39.162 DEBUG: Loss 6: {'policy_loss': -0.04415469765416012, 'entropy_loss': -0.08454858511686325, 'vf_loss': 0.009756597361422299, 'total_loss': -0.11894668540960107, 'approx_kl': 0.03068538848310709, 'clip_fraction': 0.4205729216337204, 'grad_norm': 4.075841426849365}
2022-12-28 19:59:40.186 DEBUG: Taking gradient step
2022-12-28 19:59:40.194 DEBUG: Loss 7: {'policy_loss': -0.04738768650626607, 'entropy_loss': -0.08554313518106937, 'vf_loss': 0.00965517712317359, 'total_loss': -0.12327564456416186, 'approx_kl': 0.01945659751072526, 'clip_fraction': 0.4153645858168602, 'grad_norm': 3.3814964294433594}
2022-12-28 19:59:41.196 DEBUG: Taking gradient step
2022-12-28 19:59:41.204 DEBUG: Loss 8: {'policy_loss': -0.01042902250269026, 'entropy_loss': -0.08504302985966206, 'vf_loss': 0.01193845601283065, 'total_loss': -0.08353359634952166, 'approx_kl': -0.0068422346375882626, 'clip_fraction': 0.3671875, 'grad_norm': 3.2771337032318115}
2022-12-28 19:59:42.211 DEBUG: Taking gradient step
2022-12-28 19:59:42.219 DEBUG: Loss 9: {'policy_loss': -0.04871135734813935, 'entropy_loss': -0.08471360430121422, 'vf_loss': 0.009487940496973934, 'total_loss': -0.12393702115237963, 'approx_kl': -0.03161623841151595, 'clip_fraction': 0.3567708358168602, 'grad_norm': 4.808401584625244}
2022-12-28 19:59:42.219 INFO: Optimization: policy loss=-0.049, vf loss=0.009, entropy loss=-0.085, total loss=-0.124, num steps=10
2022-12-28 19:59:42.220 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 19:59:44.051 INFO: Evaluation rollout: return=0.749 (0.0), episode length=6.0
2022-12-28 19:59:44.053 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 19:59:44.056 INFO: Iteration: 56/137, steps: 12096
2022-12-28 19:59:58.624 DEBUG: Atoms are too close
2022-12-28 20:00:46.011 INFO: Training rollout: return=0.239 (3.3), episode length=6.0
2022-12-28 20:00:46.012 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:00:46.015 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-12096_train.pkl
2022-12-28 20:00:47.009 DEBUG: Taking gradient step
2022-12-28 20:00:47.017 DEBUG: Loss 0: {'policy_loss': -0.02536791756534685, 'entropy_loss': -0.08335703611373901, 'vf_loss': 0.007915101163450207, 'total_loss': -0.10080985251563565, 'approx_kl': 7.784304756341953e-08, 'clip_fraction': 0.0, 'grad_norm': 7.2798991203308105}
2022-12-28 20:00:47.999 DEBUG: Taking gradient step
2022-12-28 20:00:48.007 DEBUG: Loss 1: {'policy_loss': 0.01533858915318528, 'entropy_loss': -0.08451254665851593, 'vf_loss': 0.010210409686633191, 'total_loss': -0.05896354781869745, 'approx_kl': -0.009202554123476148, 'clip_fraction': 0.037760416977107525, 'grad_norm': 6.565954208374023}
2022-12-28 20:00:48.952 DEBUG: Taking gradient step
2022-12-28 20:00:48.960 DEBUG: Loss 2: {'policy_loss': -0.04036332527387436, 'entropy_loss': -0.08375062420964241, 'vf_loss': 0.007797750899977543, 'total_loss': -0.11631619858353923, 'approx_kl': -0.013865401269868016, 'clip_fraction': 0.1796875, 'grad_norm': 3.2960314750671387}
2022-12-28 20:00:49.921 DEBUG: Taking gradient step
2022-12-28 20:00:49.932 DEBUG: Loss 3: {'policy_loss': -0.03984452296183723, 'entropy_loss': -0.0845277737826109, 'vf_loss': 0.0077540743676592, 'total_loss': -0.11661822237678893, 'approx_kl': -0.017968072555959225, 'clip_fraction': 0.3046875, 'grad_norm': 2.434309959411621}
2022-12-28 20:00:50.951 DEBUG: Taking gradient step
2022-12-28 20:00:50.960 DEBUG: Loss 4: {'policy_loss': -0.046691554694351475, 'entropy_loss': -0.08343139104545116, 'vf_loss': 0.007761502586239946, 'total_loss': -0.1223614431535627, 'approx_kl': 0.004971020622178912, 'clip_fraction': 0.29296875, 'grad_norm': 2.580425977706909}
2022-12-28 20:00:52.012 DEBUG: Taking gradient step
2022-12-28 20:00:52.020 DEBUG: Loss 5: {'policy_loss': -0.042515358628248845, 'entropy_loss': -0.08417946472764015, 'vf_loss': 0.007708175235857746, 'total_loss': -0.11898664812003125, 'approx_kl': -0.011817662743851542, 'clip_fraction': 0.3763020858168602, 'grad_norm': 2.3189752101898193}
2022-12-28 20:00:52.966 DEBUG: Taking gradient step
2022-12-28 20:00:52.980 DEBUG: Loss 6: {'policy_loss': -0.04474395347240604, 'entropy_loss': -0.08347721584141254, 'vf_loss': 0.007728843777816078, 'total_loss': -0.1204923255360025, 'approx_kl': -0.0020435121841728687, 'clip_fraction': 0.3489583358168602, 'grad_norm': 2.473829507827759}
2022-12-28 20:00:53.985 DEBUG: Taking gradient step
2022-12-28 20:00:53.994 DEBUG: Loss 7: {'policy_loss': -0.0504482291249605, 'entropy_loss': -0.08287226036190987, 'vf_loss': 0.0077612849635553816, 'total_loss': -0.12555920452331498, 'approx_kl': -0.0028181266970932484, 'clip_fraction': 0.3268229179084301, 'grad_norm': 3.1588687896728516}
2022-12-28 20:00:54.986 DEBUG: Taking gradient step
2022-12-28 20:00:54.994 DEBUG: Loss 8: {'policy_loss': -0.050371095675172346, 'entropy_loss': -0.08345147036015987, 'vf_loss': 0.007735611176468032, 'total_loss': -0.12608695485886418, 'approx_kl': -0.004350876435637474, 'clip_fraction': 0.4361979216337204, 'grad_norm': 1.419424057006836}
2022-12-28 20:00:55.949 DEBUG: Taking gradient step
2022-12-28 20:00:55.956 DEBUG: Loss 9: {'policy_loss': -0.046419814176250095, 'entropy_loss': -0.08361235074698925, 'vf_loss': 0.007755768696531524, 'total_loss': -0.12227639622670781, 'approx_kl': -0.005161300301551819, 'clip_fraction': 0.4440104216337204, 'grad_norm': 1.7931681871414185}
2022-12-28 20:00:55.957 INFO: Optimization: policy loss=-0.046, vf loss=0.008, entropy loss=-0.084, total loss=-0.122, num steps=10
2022-12-28 20:00:55.957 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:00:57.830 INFO: Evaluation rollout: return=0.930 (0.0), episode length=6.0
2022-12-28 20:00:57.831 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:00:57.835 INFO: Iteration: 57/137, steps: 12312
2022-12-28 20:01:55.806 DEBUG: There is a single atom floating around
2022-12-28 20:01:55.807 DEBUG: There is a single atom floating around
2022-12-28 20:01:56.095 DEBUG: Atoms are too close
2022-12-28 20:01:58.280 INFO: Training rollout: return=-0.973 (5.9), episode length=6.0
2022-12-28 20:01:58.281 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:01:58.284 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-12312_train.pkl
2022-12-28 20:01:59.321 DEBUG: Taking gradient step
2022-12-28 20:01:59.329 DEBUG: Loss 0: {'policy_loss': 0.0022685737324147936, 'entropy_loss': -0.08530330285429955, 'vf_loss': 0.036646750121715636, 'total_loss': -0.04638797900016911, 'approx_kl': 3.6476794917916777e-09, 'clip_fraction': 0.0, 'grad_norm': 17.70465660095215}
2022-12-28 20:02:00.309 DEBUG: Taking gradient step
2022-12-28 20:02:00.317 DEBUG: Loss 1: {'policy_loss': 0.005500870741363852, 'entropy_loss': -0.08678189665079117, 'vf_loss': 0.0364100497335623, 'total_loss': -0.04487097617586502, 'approx_kl': 0.015255866339430213, 'clip_fraction': 0.06901041697710752, 'grad_norm': 11.63821792602539}
2022-12-28 20:02:01.316 DEBUG: Taking gradient step
2022-12-28 20:02:01.326 DEBUG: Loss 2: {'policy_loss': -0.007428007418213016, 'entropy_loss': -0.08510614186525345, 'vf_loss': 0.03547233661689997, 'total_loss': -0.05706181266656649, 'approx_kl': 0.027963411761447787, 'clip_fraction': 0.11067708395421505, 'grad_norm': 15.865998268127441}
2022-12-28 20:02:02.379 DEBUG: Taking gradient step
2022-12-28 20:02:02.387 DEBUG: Loss 3: {'policy_loss': 0.02329696000139897, 'entropy_loss': -0.08495764806866646, 'vf_loss': 0.04312306948911861, 'total_loss': -0.01853761857814888, 'approx_kl': 0.03740064939484, 'clip_fraction': 0.16015625, 'grad_norm': 12.517348289489746}
2022-12-28 20:02:03.409 DEBUG: Taking gradient step
2022-12-28 20:02:03.416 DEBUG: Loss 4: {'policy_loss': -0.049746493065910516, 'entropy_loss': -0.08503633365035057, 'vf_loss': 0.03278371933898216, 'total_loss': -0.10199910737727894, 'approx_kl': 0.04102450888603926, 'clip_fraction': 0.2252604179084301, 'grad_norm': 9.000191688537598}
2022-12-28 20:02:04.396 DEBUG: Early stopping at step 5 for reaching max KL.
2022-12-28 20:02:04.397 INFO: Optimization: policy loss=-0.050, vf loss=0.033, entropy loss=-0.085, total loss=-0.102, num steps=5
2022-12-28 20:02:04.397 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:02:06.139 INFO: Evaluation rollout: return=0.764 (0.0), episode length=6.0
2022-12-28 20:02:06.140 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:02:06.143 INFO: Iteration: 58/137, steps: 12528
2022-12-28 20:02:47.248 DEBUG: There is a single atom floating around
2022-12-28 20:03:04.535 DEBUG: Atoms are too close
2022-12-28 20:03:07.363 INFO: Training rollout: return=-0.343 (4.6), episode length=6.0
2022-12-28 20:03:07.364 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:03:07.367 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-12528_train.pkl
2022-12-28 20:03:08.385 DEBUG: Taking gradient step
2022-12-28 20:03:08.393 DEBUG: Loss 0: {'policy_loss': 0.04264196689184666, 'entropy_loss': -0.08564328774809837, 'vf_loss': 0.025905761341360682, 'total_loss': -0.017095559514891022, 'approx_kl': -6.752088665962219e-08, 'clip_fraction': 0.0, 'grad_norm': 11.825376510620117}
2022-12-28 20:03:09.359 DEBUG: Taking gradient step
2022-12-28 20:03:09.367 DEBUG: Loss 1: {'policy_loss': 0.00935585219217554, 'entropy_loss': -0.08678360469639301, 'vf_loss': 0.02288996744293774, 'total_loss': -0.05453778506127973, 'approx_kl': 0.007453933823853731, 'clip_fraction': 0.033854166977107525, 'grad_norm': 7.070620059967041}
2022-12-28 20:03:10.360 DEBUG: Taking gradient step
2022-12-28 20:03:10.367 DEBUG: Loss 2: {'policy_loss': -0.031098205226777434, 'entropy_loss': -0.08565991930663586, 'vf_loss': 0.020668673871625548, 'total_loss': -0.09608945066178773, 'approx_kl': 0.01582519500516355, 'clip_fraction': 0.14192708395421505, 'grad_norm': 6.01389217376709}
2022-12-28 20:03:11.360 DEBUG: Taking gradient step
2022-12-28 20:03:11.368 DEBUG: Loss 3: {'policy_loss': -0.003650797544962718, 'entropy_loss': -0.08502122201025486, 'vf_loss': 0.02297853954989034, 'total_loss': -0.06569348000532724, 'approx_kl': 0.04148808727040887, 'clip_fraction': 0.2395833358168602, 'grad_norm': 4.647491931915283}
2022-12-28 20:03:12.338 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-28 20:03:12.338 INFO: Optimization: policy loss=-0.004, vf loss=0.023, entropy loss=-0.085, total loss=-0.066, num steps=4
2022-12-28 20:03:12.338 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:03:14.146 INFO: Evaluation rollout: return=0.893 (0.0), episode length=6.0
2022-12-28 20:03:14.147 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:03:14.149 INFO: Iteration: 59/137, steps: 12744
2022-12-28 20:03:24.343 DEBUG: Atoms are too close
2022-12-28 20:03:53.879 DEBUG: Atoms are too close
2022-12-28 20:04:10.626 DEBUG: There is a single atom floating around
2022-12-28 20:04:14.706 INFO: Training rollout: return=-0.847 (5.6), episode length=5.9
2022-12-28 20:04:14.708 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:04:14.710 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-12744_train.pkl
2022-12-28 20:04:15.703 DEBUG: Taking gradient step
2022-12-28 20:04:15.711 DEBUG: Loss 0: {'policy_loss': -0.019290001587065862, 'entropy_loss': -0.08645856380462646, 'vf_loss': 0.025638889060473423, 'total_loss': -0.0801096763312189, 'approx_kl': 6.340754499234436e-08, 'clip_fraction': 0.0, 'grad_norm': 14.003716468811035}
2022-12-28 20:04:16.681 DEBUG: Taking gradient step
2022-12-28 20:04:16.689 DEBUG: Loss 1: {'policy_loss': -0.032913155480586286, 'entropy_loss': -0.08475448377430439, 'vf_loss': 0.02555584099765066, 'total_loss': -0.09211179825724003, 'approx_kl': -0.001567671773955226, 'clip_fraction': 0.041666666977107525, 'grad_norm': 12.142951965332031}
2022-12-28 20:04:17.689 DEBUG: Taking gradient step
2022-12-28 20:04:17.698 DEBUG: Loss 2: {'policy_loss': -0.05255816726480116, 'entropy_loss': -0.08693654648959637, 'vf_loss': 0.022841946118176963, 'total_loss': -0.11665276763622057, 'approx_kl': 0.017710849409922957, 'clip_fraction': 0.1848958358168602, 'grad_norm': 7.943646430969238}
2022-12-28 20:04:18.653 DEBUG: Taking gradient step
2022-12-28 20:04:18.660 DEBUG: Loss 3: {'policy_loss': -0.010602802381524987, 'entropy_loss': -0.08611719124019146, 'vf_loss': 0.027850798725069854, 'total_loss': -0.06886919489664659, 'approx_kl': 0.02292752033099532, 'clip_fraction': 0.2734375, 'grad_norm': 6.712019920349121}
2022-12-28 20:04:19.648 DEBUG: Taking gradient step
2022-12-28 20:04:19.656 DEBUG: Loss 4: {'policy_loss': -0.03612648934335128, 'entropy_loss': -0.08547667413949966, 'vf_loss': 0.025050073374118693, 'total_loss': -0.09655309010873225, 'approx_kl': 0.030581063823774457, 'clip_fraction': 0.37109375, 'grad_norm': 5.863287925720215}
2022-12-28 20:04:20.624 DEBUG: Early stopping at step 5 for reaching max KL.
2022-12-28 20:04:20.624 INFO: Optimization: policy loss=-0.036, vf loss=0.025, entropy loss=-0.085, total loss=-0.097, num steps=5
2022-12-28 20:04:20.625 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:04:22.527 INFO: Evaluation rollout: return=0.947 (0.0), episode length=6.0
2022-12-28 20:04:22.528 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:04:22.531 INFO: Iteration: 60/137, steps: 12960
2022-12-28 20:05:03.169 DEBUG: Atoms are too close
2022-12-28 20:05:14.060 DEBUG: There is a single atom floating around
2022-12-28 20:05:23.303 INFO: Training rollout: return=-0.311 (4.6), episode length=5.9
2022-12-28 20:05:23.305 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:05:23.307 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-12960_train.pkl
2022-12-28 20:05:24.276 DEBUG: Taking gradient step
2022-12-28 20:05:24.284 DEBUG: Loss 0: {'policy_loss': 0.029569697638879025, 'entropy_loss': -0.086042370647192, 'vf_loss': 0.020500830685654253, 'total_loss': -0.03597184232265874, 'approx_kl': -3.119930624961853e-08, 'clip_fraction': 0.0, 'grad_norm': 18.52569007873535}
2022-12-28 20:05:25.255 DEBUG: Taking gradient step
2022-12-28 20:05:25.263 DEBUG: Loss 1: {'policy_loss': 0.01759598888118774, 'entropy_loss': -0.08517861366271973, 'vf_loss': 0.020634366360592467, 'total_loss': -0.04694825842093951, 'approx_kl': 0.01208138675428927, 'clip_fraction': 0.05859375, 'grad_norm': 14.691751480102539}
2022-12-28 20:05:26.277 DEBUG: Taking gradient step
2022-12-28 20:05:26.285 DEBUG: Loss 2: {'policy_loss': -0.011526197599782267, 'entropy_loss': -0.08464509434998035, 'vf_loss': 0.017991033463607635, 'total_loss': -0.07818025848615498, 'approx_kl': 0.01606216444633901, 'clip_fraction': 0.2395833358168602, 'grad_norm': 9.121045112609863}
2022-12-28 20:05:27.251 DEBUG: Taking gradient step
2022-12-28 20:05:27.259 DEBUG: Loss 3: {'policy_loss': 0.006565861875609945, 'entropy_loss': -0.08645242638885975, 'vf_loss': 0.020489552560809518, 'total_loss': -0.05939701195244029, 'approx_kl': 0.03760527539998293, 'clip_fraction': 0.3268229216337204, 'grad_norm': 6.935654640197754}
2022-12-28 20:05:28.258 DEBUG: Taking gradient step
2022-12-28 20:05:28.266 DEBUG: Loss 4: {'policy_loss': -0.043099545572904706, 'entropy_loss': -0.08574850484728813, 'vf_loss': 0.015629284493300408, 'total_loss': -0.11321876592689242, 'approx_kl': 0.04056287603452802, 'clip_fraction': 0.3580729216337204, 'grad_norm': 5.902892589569092}
2022-12-28 20:05:29.247 DEBUG: Taking gradient step
2022-12-28 20:05:29.255 DEBUG: Loss 5: {'policy_loss': -0.05029065363376745, 'entropy_loss': -0.08508517406880856, 'vf_loss': 0.015645458194444257, 'total_loss': -0.11973036950813175, 'approx_kl': 0.03544135787524283, 'clip_fraction': 0.3424479216337204, 'grad_norm': 6.006031036376953}
2022-12-28 20:05:30.239 DEBUG: Early stopping at step 6 for reaching max KL.
2022-12-28 20:05:30.240 INFO: Optimization: policy loss=-0.050, vf loss=0.016, entropy loss=-0.085, total loss=-0.120, num steps=6
2022-12-28 20:05:30.240 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:05:32.048 INFO: Evaluation rollout: return=0.866 (0.0), episode length=6.0
2022-12-28 20:05:32.049 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:05:32.052 DEBUG: Deleting old model: runs/CH3NO_painn/models/CH3NO_painn_run-1_steps-11016.model
2022-12-28 20:05:32.056 DEBUG: Saving model: runs/CH3NO_painn/models/CH3NO_painn_run-1_steps-13176.model
2022-12-28 20:05:32.079 INFO: Iteration: 61/137, steps: 13176
2022-12-28 20:06:30.636 DEBUG: Atoms are too close
2022-12-28 20:06:33.182 INFO: Training rollout: return=0.207 (3.3), episode length=6.0
2022-12-28 20:06:33.183 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:06:33.186 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-13176_train.pkl
2022-12-28 20:06:34.185 DEBUG: Taking gradient step
2022-12-28 20:06:34.194 DEBUG: Loss 0: {'policy_loss': 0.010660557302537704, 'entropy_loss': -0.08381623029708862, 'vf_loss': 0.012239975102473509, 'total_loss': -0.06091569789207742, 'approx_kl': -1.0974084574399967e-07, 'clip_fraction': 0.0, 'grad_norm': 9.266217231750488}
2022-12-28 20:06:35.145 DEBUG: Taking gradient step
2022-12-28 20:06:35.152 DEBUG: Loss 1: {'policy_loss': -0.04060149922034785, 'entropy_loss': -0.08462554588913918, 'vf_loss': 0.009812466811377589, 'total_loss': -0.11541457829810942, 'approx_kl': -0.0032476396299898624, 'clip_fraction': 0.0390625, 'grad_norm': 5.573078632354736}
2022-12-28 20:06:36.136 DEBUG: Taking gradient step
2022-12-28 20:06:36.144 DEBUG: Loss 2: {'policy_loss': -0.011735991805125983, 'entropy_loss': -0.08457986824214458, 'vf_loss': 0.01213201774170708, 'total_loss': -0.08418384230556349, 'approx_kl': -0.0019328435882925987, 'clip_fraction': 0.1888020858168602, 'grad_norm': 3.468763589859009}
2022-12-28 20:06:37.140 DEBUG: Taking gradient step
2022-12-28 20:06:37.148 DEBUG: Loss 3: {'policy_loss': -0.051473726167032774, 'entropy_loss': -0.08380171284079552, 'vf_loss': 0.00978943718074143, 'total_loss': -0.12548600182708686, 'approx_kl': -0.0033351583406329155, 'clip_fraction': 0.2708333358168602, 'grad_norm': 3.3447916507720947}
2022-12-28 20:06:38.135 DEBUG: Taking gradient step
2022-12-28 20:06:38.143 DEBUG: Loss 4: {'policy_loss': -0.05024050793304381, 'entropy_loss': -0.08440847136080265, 'vf_loss': 0.00971188566639948, 'total_loss': -0.12493709362744697, 'approx_kl': -0.006202457472681999, 'clip_fraction': 0.328125, 'grad_norm': 2.7494404315948486}
2022-12-28 20:06:39.110 DEBUG: Taking gradient step
2022-12-28 20:06:39.118 DEBUG: Loss 5: {'policy_loss': -0.055178013884647555, 'entropy_loss': -0.084146274253726, 'vf_loss': 0.009697432506070027, 'total_loss': -0.12962685563230353, 'approx_kl': 0.01607315568253398, 'clip_fraction': 0.3671875, 'grad_norm': 4.142242908477783}
2022-12-28 20:06:40.084 DEBUG: Taking gradient step
2022-12-28 20:06:40.092 DEBUG: Loss 6: {'policy_loss': -0.055195676720597456, 'entropy_loss': -0.08425965718924999, 'vf_loss': 0.009623210403748268, 'total_loss': -0.12983212350609918, 'approx_kl': 0.0006891386583447456, 'clip_fraction': 0.3932291716337204, 'grad_norm': 4.730783939361572}
2022-12-28 20:06:41.081 DEBUG: Taking gradient step
2022-12-28 20:06:41.089 DEBUG: Loss 7: {'policy_loss': -0.05534978725519571, 'entropy_loss': -0.08445172384381294, 'vf_loss': 0.009570005842625517, 'total_loss': -0.13023150525638313, 'approx_kl': -0.0005272678099572659, 'clip_fraction': 0.4674479216337204, 'grad_norm': 2.842724561691284}
2022-12-28 20:06:42.057 DEBUG: Taking gradient step
2022-12-28 20:06:42.064 DEBUG: Loss 8: {'policy_loss': -0.05884891788127928, 'entropy_loss': -0.08541508577764034, 'vf_loss': 0.009512395787964156, 'total_loss': -0.13475160787095547, 'approx_kl': -0.02663178974762559, 'clip_fraction': 0.5247395858168602, 'grad_norm': 1.6402701139450073}
2022-12-28 20:06:43.040 DEBUG: Taking gradient step
2022-12-28 20:06:43.048 DEBUG: Loss 9: {'policy_loss': -0.05967091392287598, 'entropy_loss': -0.0847305916249752, 'vf_loss': 0.009466925369148104, 'total_loss': -0.13493458017870308, 'approx_kl': -0.03369256854057312, 'clip_fraction': 0.5755208432674408, 'grad_norm': 2.194037437438965}
2022-12-28 20:06:43.049 INFO: Optimization: policy loss=-0.060, vf loss=0.009, entropy loss=-0.085, total loss=-0.135, num steps=10
2022-12-28 20:06:43.049 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:06:44.744 INFO: Evaluation rollout: return=0.861 (0.0), episode length=6.0
2022-12-28 20:06:44.745 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:06:44.747 INFO: Iteration: 62/137, steps: 13392
2022-12-28 20:06:48.840 DEBUG: There is a single atom floating around
2022-12-28 20:07:08.337 DEBUG: There is a single atom floating around
2022-12-28 20:07:17.876 DEBUG: Atoms are too close
2022-12-28 20:07:41.066 DEBUG: Atoms are too close
2022-12-28 20:07:44.611 INFO: Training rollout: return=-1.502 (6.5), episode length=5.7
2022-12-28 20:07:44.613 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:07:44.615 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-13392_train.pkl
2022-12-28 20:07:45.574 DEBUG: Taking gradient step
2022-12-28 20:07:45.582 DEBUG: Loss 0: {'policy_loss': -0.01355861259975557, 'entropy_loss': -0.08585257641971111, 'vf_loss': 0.024284380399058402, 'total_loss': -0.07512680862040828, 'approx_kl': -1.2627182144342441e-07, 'clip_fraction': 0.0, 'grad_norm': 11.435297012329102}
2022-12-28 20:07:46.533 DEBUG: Taking gradient step
2022-12-28 20:07:46.541 DEBUG: Loss 1: {'policy_loss': 0.018470829982954615, 'entropy_loss': -0.0860431008040905, 'vf_loss': 0.029320574955466, 'total_loss': -0.03825169586566988, 'approx_kl': -0.000560068991035223, 'clip_fraction': 0.05598958395421505, 'grad_norm': 8.726787567138672}
2022-12-28 20:07:47.505 DEBUG: Taking gradient step
2022-12-28 20:07:47.514 DEBUG: Loss 2: {'policy_loss': -0.014018774031980508, 'entropy_loss': -0.08557263761758804, 'vf_loss': 0.02669576640631184, 'total_loss': -0.07289564524325672, 'approx_kl': -0.009213466197252274, 'clip_fraction': 0.1484375, 'grad_norm': 8.651124000549316}
2022-12-28 20:07:48.486 DEBUG: Taking gradient step
2022-12-28 20:07:48.494 DEBUG: Loss 3: {'policy_loss': -0.022480436710725277, 'entropy_loss': -0.08650489151477814, 'vf_loss': 0.026649502689239157, 'total_loss': -0.08233582553626424, 'approx_kl': 0.013585246168076992, 'clip_fraction': 0.2239583358168602, 'grad_norm': 3.3040642738342285}
2022-12-28 20:07:49.555 DEBUG: Taking gradient step
2022-12-28 20:07:49.563 DEBUG: Loss 4: {'policy_loss': -0.04620492125382361, 'entropy_loss': -0.086087916046381, 'vf_loss': 0.02407565842477856, 'total_loss': -0.10821717887542605, 'approx_kl': 0.004317707847803831, 'clip_fraction': 0.33203125, 'grad_norm': 3.1760454177856445}
2022-12-28 20:07:50.503 DEBUG: Taking gradient step
2022-12-28 20:07:50.511 DEBUG: Loss 5: {'policy_loss': -0.0546244316325332, 'entropy_loss': -0.0859124343842268, 'vf_loss': 0.024091539535624512, 'total_loss': -0.11644532648113548, 'approx_kl': 0.0005985344760119915, 'clip_fraction': 0.3606770858168602, 'grad_norm': 3.7301583290100098}
2022-12-28 20:07:51.468 DEBUG: Taking gradient step
2022-12-28 20:07:51.476 DEBUG: Loss 6: {'policy_loss': -0.04977074393185688, 'entropy_loss': -0.08612978830933571, 'vf_loss': 0.023801840994229793, 'total_loss': -0.11209869124696281, 'approx_kl': 0.008437704527750611, 'clip_fraction': 0.3541666716337204, 'grad_norm': 3.419306755065918}
2022-12-28 20:07:52.451 DEBUG: Taking gradient step
2022-12-28 20:07:52.464 DEBUG: Loss 7: {'policy_loss': -0.05392699002321752, 'entropy_loss': -0.08550514094531536, 'vf_loss': 0.023542103942954543, 'total_loss': -0.11589002702557834, 'approx_kl': -0.005815793061628938, 'clip_fraction': 0.3606770858168602, 'grad_norm': 3.450821876525879}
2022-12-28 20:07:53.454 DEBUG: Taking gradient step
2022-12-28 20:07:53.461 DEBUG: Loss 8: {'policy_loss': -0.08274873530900075, 'entropy_loss': -0.08626225590705872, 'vf_loss': 0.02102252206039801, 'total_loss': -0.14798846915566144, 'approx_kl': -0.019772339146584272, 'clip_fraction': 0.3645833358168602, 'grad_norm': 2.7961955070495605}
2022-12-28 20:07:54.466 DEBUG: Taking gradient step
2022-12-28 20:07:54.478 DEBUG: Loss 9: {'policy_loss': -0.016555364760981635, 'entropy_loss': -0.08623171411454678, 'vf_loss': 0.02748990428436864, 'total_loss': -0.07529717459115978, 'approx_kl': 0.011438966263085604, 'clip_fraction': 0.2916666716337204, 'grad_norm': 2.475602388381958}
2022-12-28 20:07:54.478 INFO: Optimization: policy loss=-0.017, vf loss=0.027, entropy loss=-0.086, total loss=-0.075, num steps=10
2022-12-28 20:07:54.479 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:07:56.113 INFO: Evaluation rollout: return=0.741 (0.0), episode length=6.0
2022-12-28 20:07:56.114 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:07:56.116 INFO: Iteration: 63/137, steps: 13608
2022-12-28 20:08:13.495 DEBUG: There is a single atom floating around
2022-12-28 20:08:50.482 DEBUG: Atoms are too close
2022-12-28 20:08:57.551 INFO: Training rollout: return=0.520 (7.0), episode length=6.0
2022-12-28 20:08:57.553 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:08:57.555 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-13608_train.pkl
2022-12-28 20:08:58.538 DEBUG: Taking gradient step
2022-12-28 20:08:58.546 DEBUG: Loss 0: {'policy_loss': -0.004602831187335057, 'entropy_loss': -0.08532755449414253, 'vf_loss': 0.042448916529826984, 'total_loss': -0.047481469151650614, 'approx_kl': -5.083469645228433e-09, 'clip_fraction': 0.0, 'grad_norm': 10.792503356933594}
2022-12-28 20:08:59.585 DEBUG: Taking gradient step
2022-12-28 20:08:59.595 DEBUG: Loss 1: {'policy_loss': 0.0008721101903230236, 'entropy_loss': -0.08613108657300472, 'vf_loss': 0.05368304905655952, 'total_loss': -0.03157592732612219, 'approx_kl': 5.497876554727554e-05, 'clip_fraction': 0.01171875, 'grad_norm': 10.796022415161133}
2022-12-28 20:09:00.575 DEBUG: Taking gradient step
2022-12-28 20:09:00.584 DEBUG: Loss 2: {'policy_loss': -0.020243147214930313, 'entropy_loss': -0.0850633755326271, 'vf_loss': 0.04244012271813093, 'total_loss': -0.06286640002942648, 'approx_kl': -0.0021041317377239466, 'clip_fraction': 0.1015625, 'grad_norm': 8.629939079284668}
2022-12-28 20:09:01.618 DEBUG: Taking gradient step
2022-12-28 20:09:01.626 DEBUG: Loss 3: {'policy_loss': 0.007247762958594958, 'entropy_loss': -0.08520973287522793, 'vf_loss': 0.04706635783000325, 'total_loss': -0.030895612086629727, 'approx_kl': 0.021024541230872273, 'clip_fraction': 0.3333333358168602, 'grad_norm': 8.817553520202637}
2022-12-28 20:09:02.603 DEBUG: Taking gradient step
2022-12-28 20:09:02.612 DEBUG: Loss 4: {'policy_loss': 0.016085080284227053, 'entropy_loss': -0.08478374406695366, 'vf_loss': 0.04930156460358878, 'total_loss': -0.019397099179137837, 'approx_kl': 0.04344974458217621, 'clip_fraction': 0.4075520932674408, 'grad_norm': 3.2514851093292236}
2022-12-28 20:09:03.613 DEBUG: Early stopping at step 5 for reaching max KL.
2022-12-28 20:09:03.613 INFO: Optimization: policy loss=0.016, vf loss=0.049, entropy loss=-0.085, total loss=-0.019, num steps=5
2022-12-28 20:09:03.614 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:09:05.399 INFO: Evaluation rollout: return=0.741 (0.0), episode length=6.0
2022-12-28 20:09:05.400 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:09:05.402 INFO: Iteration: 64/137, steps: 13824
2022-12-28 20:09:22.193 DEBUG: Atoms are too close
2022-12-28 20:09:31.111 DEBUG: There is a single atom floating around
2022-12-28 20:09:40.580 DEBUG: Atoms are too close
2022-12-28 20:09:44.618 DEBUG: There is a single atom floating around
2022-12-28 20:10:05.720 INFO: Training rollout: return=-1.472 (6.3), episode length=5.9
2022-12-28 20:10:05.721 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:10:05.724 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-13824_train.pkl
2022-12-28 20:10:06.733 DEBUG: Taking gradient step
2022-12-28 20:10:06.741 DEBUG: Loss 0: {'policy_loss': -0.005581376496237633, 'entropy_loss': -0.08405988477170467, 'vf_loss': 0.03556315441377817, 'total_loss': -0.054078106854164136, 'approx_kl': -5.207645425997498e-08, 'clip_fraction': 0.0, 'grad_norm': 15.443230628967285}
2022-12-28 20:10:07.701 DEBUG: Taking gradient step
2022-12-28 20:10:07.710 DEBUG: Loss 1: {'policy_loss': 0.03955772988035286, 'entropy_loss': -0.083222771063447, 'vf_loss': 0.040605114699815543, 'total_loss': -0.003059926483278602, 'approx_kl': 0.0004032494034618139, 'clip_fraction': 0.03515625, 'grad_norm': 16.85464859008789}
2022-12-28 20:10:08.688 DEBUG: Taking gradient step
2022-12-28 20:10:08.698 DEBUG: Loss 2: {'policy_loss': -0.017178072083256203, 'entropy_loss': -0.08289701864123344, 'vf_loss': 0.035615340974863505, 'total_loss': -0.06445974974962615, 'approx_kl': 0.016267747545498423, 'clip_fraction': 0.140625, 'grad_norm': 9.672669410705566}
2022-12-28 20:10:09.672 DEBUG: Taking gradient step
2022-12-28 20:10:09.679 DEBUG: Loss 3: {'policy_loss': -0.00497558623510962, 'entropy_loss': -0.08240700140595436, 'vf_loss': 0.038268681555054355, 'total_loss': -0.04911390608600962, 'approx_kl': 0.033438087557442486, 'clip_fraction': 0.2408854179084301, 'grad_norm': 7.159762859344482}
2022-12-28 20:10:10.604 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-28 20:10:10.606 INFO: Optimization: policy loss=-0.005, vf loss=0.038, entropy loss=-0.082, total loss=-0.049, num steps=4
2022-12-28 20:10:10.607 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:10:12.524 INFO: Evaluation rollout: return=0.730 (0.0), episode length=6.0
2022-12-28 20:10:12.525 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:10:12.528 INFO: Iteration: 65/137, steps: 14040
2022-12-28 20:10:31.900 DEBUG: Atoms are too close
2022-12-28 20:11:14.570 INFO: Training rollout: return=0.228 (3.3), episode length=6.0
2022-12-28 20:11:14.572 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:11:14.574 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-14040_train.pkl
2022-12-28 20:11:15.585 DEBUG: Taking gradient step
2022-12-28 20:11:15.594 DEBUG: Loss 0: {'policy_loss': -0.02515956877756942, 'entropy_loss': -0.08262976445257664, 'vf_loss': 0.009659959694438046, 'total_loss': -0.098129373535708, 'approx_kl': 2.3283064365386963e-08, 'clip_fraction': 0.0, 'grad_norm': 5.973367214202881}
2022-12-28 20:11:16.597 DEBUG: Taking gradient step
2022-12-28 20:11:16.605 DEBUG: Loss 1: {'policy_loss': -0.036616098244442646, 'entropy_loss': -0.0819279570132494, 'vf_loss': 0.009710179862450187, 'total_loss': -0.10883387539524186, 'approx_kl': 0.004659771686419845, 'clip_fraction': 0.10286458395421505, 'grad_norm': 5.412197113037109}
2022-12-28 20:11:17.591 DEBUG: Taking gradient step
2022-12-28 20:11:17.599 DEBUG: Loss 2: {'policy_loss': -0.03904497048403778, 'entropy_loss': -0.08182017505168915, 'vf_loss': 0.009667765887453762, 'total_loss': -0.11119737964827317, 'approx_kl': -0.0081261966843158, 'clip_fraction': 0.2955729216337204, 'grad_norm': 4.31610107421875}
2022-12-28 20:11:18.592 DEBUG: Taking gradient step
2022-12-28 20:11:18.601 DEBUG: Loss 3: {'policy_loss': -0.003930563785146498, 'entropy_loss': -0.08133461698889732, 'vf_loss': 0.012176029998934877, 'total_loss': -0.07308915077510894, 'approx_kl': -0.007231720257550478, 'clip_fraction': 0.3619791716337204, 'grad_norm': 3.9138314723968506}
2022-12-28 20:11:19.564 DEBUG: Taking gradient step
2022-12-28 20:11:19.571 DEBUG: Loss 4: {'policy_loss': -0.012204724274323127, 'entropy_loss': -0.08194846101105213, 'vf_loss': 0.01202017943768603, 'total_loss': -0.08213300584768922, 'approx_kl': 0.008988219313323498, 'clip_fraction': 0.4114583358168602, 'grad_norm': 3.7897045612335205}
2022-12-28 20:11:20.521 DEBUG: Taking gradient step
2022-12-28 20:11:20.532 DEBUG: Loss 5: {'policy_loss': -0.04430482460927777, 'entropy_loss': -0.08171578496694565, 'vf_loss': 0.009537113855809897, 'total_loss': -0.11648349572041351, 'approx_kl': -0.014526331797242165, 'clip_fraction': 0.4557291716337204, 'grad_norm': 2.822753429412842}
2022-12-28 20:11:21.479 DEBUG: Taking gradient step
2022-12-28 20:11:21.487 DEBUG: Loss 6: {'policy_loss': -0.049852787990496986, 'entropy_loss': -0.0829988643527031, 'vf_loss': 0.009493152612762063, 'total_loss': -0.12335849973043803, 'approx_kl': -0.03590742661617696, 'clip_fraction': 0.4309895858168602, 'grad_norm': 2.6888458728790283}
2022-12-28 20:11:22.480 DEBUG: Taking gradient step
2022-12-28 20:11:22.488 DEBUG: Loss 7: {'policy_loss': -0.04977307337243188, 'entropy_loss': -0.08253397792577744, 'vf_loss': 0.009442092991564868, 'total_loss': -0.12286495830664446, 'approx_kl': -0.04259588569402695, 'clip_fraction': 0.4140625, 'grad_norm': 2.452143669128418}
2022-12-28 20:11:23.520 DEBUG: Taking gradient step
2022-12-28 20:11:23.527 DEBUG: Loss 8: {'policy_loss': 0.004097649717686724, 'entropy_loss': -0.08466493710875511, 'vf_loss': 0.013956850789934106, 'total_loss': -0.0666104366011343, 'approx_kl': -0.029579955153167248, 'clip_fraction': 0.4348958432674408, 'grad_norm': 5.301986217498779}
2022-12-28 20:11:24.518 DEBUG: Taking gradient step
2022-12-28 20:11:24.529 DEBUG: Loss 9: {'policy_loss': -0.05880115226358113, 'entropy_loss': -0.0834964718669653, 'vf_loss': 0.009397224163210234, 'total_loss': -0.13290039996733619, 'approx_kl': -0.04367246385663748, 'clip_fraction': 0.421875, 'grad_norm': 5.938141345977783}
2022-12-28 20:11:24.529 INFO: Optimization: policy loss=-0.059, vf loss=0.009, entropy loss=-0.083, total loss=-0.133, num steps=10
2022-12-28 20:11:24.530 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:11:26.347 INFO: Evaluation rollout: return=0.702 (0.0), episode length=6.0
2022-12-28 20:11:26.349 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:11:26.351 INFO: Iteration: 66/137, steps: 14256
2022-12-28 20:12:12.488 DEBUG: There is a single atom floating around
2022-12-28 20:12:25.160 DEBUG: Atoms are too close
2022-12-28 20:12:27.061 INFO: Training rollout: return=-0.351 (4.7), episode length=5.9
2022-12-28 20:12:27.062 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:12:27.064 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-14256_train.pkl
2022-12-28 20:12:28.038 DEBUG: Taking gradient step
2022-12-28 20:12:28.046 DEBUG: Loss 0: {'policy_loss': 0.032065696006749085, 'entropy_loss': -0.08363988995552063, 'vf_loss': 0.018125565442072104, 'total_loss': -0.03344862850669944, 'approx_kl': 1.1641532182693481e-09, 'clip_fraction': 0.0, 'grad_norm': 11.667340278625488}
2022-12-28 20:12:29.003 DEBUG: Taking gradient step
2022-12-28 20:12:29.011 DEBUG: Loss 1: {'policy_loss': -0.036216243457235134, 'entropy_loss': -0.08412539400160313, 'vf_loss': 0.012891496079423215, 'total_loss': -0.10745014137941505, 'approx_kl': 0.006211861036717892, 'clip_fraction': 0.05598958395421505, 'grad_norm': 6.663689613342285}
2022-12-28 20:12:29.996 DEBUG: Taking gradient step
2022-12-28 20:12:30.004 DEBUG: Loss 2: {'policy_loss': -0.007642107914045657, 'entropy_loss': -0.08398685790598392, 'vf_loss': 0.015441016387276428, 'total_loss': -0.07618794943275316, 'approx_kl': 0.013995491433888674, 'clip_fraction': 0.140625, 'grad_norm': 8.977130889892578}
2022-12-28 20:12:30.955 DEBUG: Taking gradient step
2022-12-28 20:12:30.963 DEBUG: Loss 3: {'policy_loss': -0.04905711391346686, 'entropy_loss': -0.08411619439721107, 'vf_loss': 0.012876408286534729, 'total_loss': -0.1202969000241432, 'approx_kl': 0.019916419638320804, 'clip_fraction': 0.2682291716337204, 'grad_norm': 4.32880163192749}
2022-12-28 20:12:31.963 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-28 20:12:31.964 INFO: Optimization: policy loss=-0.049, vf loss=0.013, entropy loss=-0.084, total loss=-0.120, num steps=4
2022-12-28 20:12:31.965 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:12:33.795 INFO: Evaluation rollout: return=0.734 (0.0), episode length=6.0
2022-12-28 20:12:33.796 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:12:33.799 INFO: Iteration: 67/137, steps: 14472
2022-12-28 20:13:36.368 INFO: Training rollout: return=0.771 (0.1), episode length=6.0
2022-12-28 20:13:36.370 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:13:36.372 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-14472_train.pkl
2022-12-28 20:13:37.364 DEBUG: Taking gradient step
2022-12-28 20:13:37.372 DEBUG: Loss 0: {'policy_loss': 0.0019232343272361251, 'entropy_loss': -0.08375770412385464, 'vf_loss': 0.0004659122746791459, 'total_loss': -0.08136855752193937, 'approx_kl': 2.064431736670258e-08, 'clip_fraction': 0.0, 'grad_norm': 13.362929344177246}
2022-12-28 20:13:38.367 DEBUG: Taking gradient step
2022-12-28 20:13:38.374 DEBUG: Loss 1: {'policy_loss': -0.05367969747966775, 'entropy_loss': -0.08374963700771332, 'vf_loss': 0.0004675811236433604, 'total_loss': -0.13696175336373773, 'approx_kl': 0.013358110561966896, 'clip_fraction': 0.10546875, 'grad_norm': 12.237432479858398}
2022-12-28 20:13:39.345 DEBUG: Taking gradient step
2022-12-28 20:13:39.353 DEBUG: Loss 2: {'policy_loss': 0.01823211728028036, 'entropy_loss': -0.08524718880653381, 'vf_loss': 0.00041794460848322383, 'total_loss': -0.06659712691777024, 'approx_kl': 0.022861256496980786, 'clip_fraction': 0.2265625, 'grad_norm': 14.316039085388184}
2022-12-28 20:13:40.299 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-28 20:13:40.299 INFO: Optimization: policy loss=0.018, vf loss=0.000, entropy loss=-0.085, total loss=-0.067, num steps=3
2022-12-28 20:13:40.300 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:13:41.882 DEBUG: Atoms are too close
2022-12-28 20:13:41.884 INFO: Evaluation rollout: return=-19.500 (0.0), episode length=6.0
2022-12-28 20:13:41.885 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:13:41.887 INFO: Iteration: 68/137, steps: 14688
2022-12-28 20:13:47.150 DEBUG: There is a single atom floating around
2022-12-28 20:14:22.042 DEBUG: Atoms are too close
2022-12-28 20:14:43.209 INFO: Training rollout: return=-0.342 (4.7), episode length=5.9
2022-12-28 20:14:43.211 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:14:43.213 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-14688_train.pkl
2022-12-28 20:14:44.209 DEBUG: Taking gradient step
2022-12-28 20:14:44.218 DEBUG: Loss 0: {'policy_loss': -0.027589581748194918, 'entropy_loss': -0.08461245521903038, 'vf_loss': 0.012110037992205723, 'total_loss': -0.10009199897501957, 'approx_kl': 8.133550455369232e-08, 'clip_fraction': 0.0, 'grad_norm': 5.085824966430664}
2022-12-28 20:14:45.181 DEBUG: Taking gradient step
2022-12-28 20:14:45.190 DEBUG: Loss 1: {'policy_loss': -0.013148597888460565, 'entropy_loss': -0.08506802655756474, 'vf_loss': 0.014691720270047448, 'total_loss': -0.08352490417597785, 'approx_kl': -4.072231240570545e-05, 'clip_fraction': 0.01953125, 'grad_norm': 7.688520908355713}
2022-12-28 20:14:46.189 DEBUG: Taking gradient step
2022-12-28 20:14:46.197 DEBUG: Loss 2: {'policy_loss': 0.014731167788157029, 'entropy_loss': -0.08615305460989475, 'vf_loss': 0.016741071077916173, 'total_loss': -0.05468081574382155, 'approx_kl': 0.010171215748414397, 'clip_fraction': 0.1640625, 'grad_norm': 7.537024021148682}
2022-12-28 20:14:47.162 DEBUG: Taking gradient step
2022-12-28 20:14:47.170 DEBUG: Loss 3: {'policy_loss': -0.044316982471496916, 'entropy_loss': -0.08511053398251534, 'vf_loss': 0.012105477078047778, 'total_loss': -0.11732203937596447, 'approx_kl': 0.028620047494769096, 'clip_fraction': 0.2942708358168602, 'grad_norm': 2.2398478984832764}
2022-12-28 20:14:48.118 DEBUG: Taking gradient step
2022-12-28 20:14:48.126 DEBUG: Loss 4: {'policy_loss': -0.04879109999969166, 'entropy_loss': -0.0851182583719492, 'vf_loss': 0.012084284020005361, 'total_loss': -0.12182507435163548, 'approx_kl': 0.034716514870524406, 'clip_fraction': 0.3541666716337204, 'grad_norm': 2.584256172180176}
2022-12-28 20:14:49.080 DEBUG: Taking gradient step
2022-12-28 20:14:49.087 DEBUG: Loss 5: {'policy_loss': -0.05415609707845606, 'entropy_loss': -0.08474906906485558, 'vf_loss': 0.012077908005730036, 'total_loss': -0.1268272581375816, 'approx_kl': 0.03667048760689795, 'clip_fraction': 0.41015625, 'grad_norm': 1.9630542993545532}
2022-12-28 20:14:50.043 DEBUG: Early stopping at step 6 for reaching max KL.
2022-12-28 20:14:50.043 INFO: Optimization: policy loss=-0.054, vf loss=0.012, entropy loss=-0.085, total loss=-0.127, num steps=6
2022-12-28 20:14:50.044 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:14:51.849 INFO: Evaluation rollout: return=0.724 (0.0), episode length=6.0
2022-12-28 20:14:51.850 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:14:51.853 INFO: Iteration: 69/137, steps: 14904
2022-12-28 20:15:31.128 DEBUG: There is a single atom floating around
2022-12-28 20:15:53.733 INFO: Training rollout: return=0.267 (3.3), episode length=6.0
2022-12-28 20:15:53.735 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:15:53.737 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-14904_train.pkl
2022-12-28 20:15:54.772 DEBUG: Taking gradient step
2022-12-28 20:15:54.780 DEBUG: Loss 0: {'policy_loss': -0.02275674158609054, 'entropy_loss': -0.08213979005813599, 'vf_loss': 0.00939254630139941, 'total_loss': -0.09550398534282711, 'approx_kl': 4.57900267702982e-09, 'clip_fraction': 0.0, 'grad_norm': 17.960697174072266}
2022-12-28 20:15:55.747 DEBUG: Taking gradient step
2022-12-28 20:15:55.755 DEBUG: Loss 1: {'policy_loss': 0.014000186625596087, 'entropy_loss': -0.08160458505153656, 'vf_loss': 0.011987717391644337, 'total_loss': -0.055616681034296137, 'approx_kl': 0.007249720394611359, 'clip_fraction': 0.022135416977107525, 'grad_norm': 23.579111099243164}
2022-12-28 20:15:56.801 DEBUG: Taking gradient step
2022-12-28 20:15:56.809 DEBUG: Loss 2: {'policy_loss': -0.03703064892683649, 'entropy_loss': -0.08153643645346165, 'vf_loss': 0.00941159662650247, 'total_loss': -0.10915548875379566, 'approx_kl': 0.018566409591585398, 'clip_fraction': 0.1197916679084301, 'grad_norm': 6.463860034942627}
2022-12-28 20:15:57.760 DEBUG: Taking gradient step
2022-12-28 20:15:57.774 DEBUG: Loss 3: {'policy_loss': -0.03955828003230229, 'entropy_loss': -0.08164003118872643, 'vf_loss': 0.00941255333409624, 'total_loss': -0.11178575788693246, 'approx_kl': 0.035776798613369465, 'clip_fraction': 0.171875, 'grad_norm': 5.830636501312256}
2022-12-28 20:15:58.731 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-28 20:15:58.732 INFO: Optimization: policy loss=-0.040, vf loss=0.009, entropy loss=-0.082, total loss=-0.112, num steps=4
2022-12-28 20:15:58.732 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:16:00.594 INFO: Evaluation rollout: return=0.764 (0.0), episode length=6.0
2022-12-28 20:16:00.595 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:16:00.597 INFO: Iteration: 70/137, steps: 15120
2022-12-28 20:16:18.742 DEBUG: Atoms are too close
2022-12-28 20:16:41.121 DEBUG: There is a single atom floating around
2022-12-28 20:17:03.109 INFO: Training rollout: return=-0.317 (4.6), episode length=6.0
2022-12-28 20:17:03.111 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:17:03.113 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-15120_train.pkl
2022-12-28 20:17:04.131 DEBUG: Taking gradient step
2022-12-28 20:17:04.139 DEBUG: Loss 0: {'policy_loss': 0.01588372078542768, 'entropy_loss': -0.08091779612004757, 'vf_loss': 0.023430080831135437, 'total_loss': -0.041603994503484454, 'approx_kl': -4.105580231339445e-08, 'clip_fraction': 0.0, 'grad_norm': 32.364315032958984}
2022-12-28 20:17:05.147 DEBUG: Taking gradient step
2022-12-28 20:17:05.156 DEBUG: Loss 1: {'policy_loss': -0.02632711379401264, 'entropy_loss': -0.08017789572477341, 'vf_loss': 0.02047433073819244, 'total_loss': -0.08603067878059359, 'approx_kl': -0.0004960938822478056, 'clip_fraction': 0.03645833395421505, 'grad_norm': 7.842439651489258}
2022-12-28 20:17:06.141 DEBUG: Taking gradient step
2022-12-28 20:17:06.148 DEBUG: Loss 2: {'policy_loss': -0.04705326012633783, 'entropy_loss': -0.0807670820504427, 'vf_loss': 0.018130842243411882, 'total_loss': -0.10968949993336864, 'approx_kl': 0.00872671976685524, 'clip_fraction': 0.1627604179084301, 'grad_norm': 6.3596510887146}
2022-12-28 20:17:07.155 DEBUG: Taking gradient step
2022-12-28 20:17:07.167 DEBUG: Loss 3: {'policy_loss': -0.02085733407265642, 'entropy_loss': -0.08107230067253113, 'vf_loss': 0.020465771445854722, 'total_loss': -0.08146386329933283, 'approx_kl': 0.014045597054064274, 'clip_fraction': 0.23046875, 'grad_norm': 5.977321147918701}
2022-12-28 20:17:08.180 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-28 20:17:08.181 INFO: Optimization: policy loss=-0.021, vf loss=0.020, entropy loss=-0.081, total loss=-0.081, num steps=4
2022-12-28 20:17:08.181 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:17:10.071 INFO: Evaluation rollout: return=0.873 (0.0), episode length=6.0
2022-12-28 20:17:10.073 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:17:10.076 DEBUG: Deleting old model: runs/CH3NO_painn/models/CH3NO_painn_run-1_steps-13176.model
2022-12-28 20:17:10.077 DEBUG: Saving model: runs/CH3NO_painn/models/CH3NO_painn_run-1_steps-15336.model
2022-12-28 20:17:10.100 INFO: Iteration: 71/137, steps: 15336
2022-12-28 20:17:27.122 DEBUG: There is a single atom floating around
2022-12-28 20:18:12.632 INFO: Training rollout: return=0.282 (3.3), episode length=6.0
2022-12-28 20:18:12.634 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:18:12.636 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-15336_train.pkl
2022-12-28 20:18:13.635 DEBUG: Taking gradient step
2022-12-28 20:18:13.644 DEBUG: Loss 0: {'policy_loss': 0.011755609454727964, 'entropy_loss': -0.08209829218685627, 'vf_loss': 0.012038404119414517, 'total_loss': -0.05830427861271379, 'approx_kl': 5.029141902923584e-08, 'clip_fraction': 0.0, 'grad_norm': 12.22204303741455}
2022-12-28 20:18:14.641 DEBUG: Taking gradient step
2022-12-28 20:18:14.649 DEBUG: Loss 1: {'policy_loss': 0.0046421780962123335, 'entropy_loss': -0.08301353454589844, 'vf_loss': 0.012066915949641564, 'total_loss': -0.06630444050004454, 'approx_kl': -0.006733528105542064, 'clip_fraction': 0.015625, 'grad_norm': 11.11207103729248}
2022-12-28 20:18:15.632 DEBUG: Taking gradient step
2022-12-28 20:18:15.640 DEBUG: Loss 2: {'policy_loss': -0.007615452659167084, 'entropy_loss': -0.08245353400707245, 'vf_loss': 0.011984411162359557, 'total_loss': -0.07808457550387998, 'approx_kl': -0.0006633705925196409, 'clip_fraction': 0.1927083358168602, 'grad_norm': 2.4567301273345947}
2022-12-28 20:18:16.655 DEBUG: Taking gradient step
2022-12-28 20:18:16.663 DEBUG: Loss 3: {'policy_loss': -0.007460298080329527, 'entropy_loss': -0.08258087933063507, 'vf_loss': 0.012057563748439299, 'total_loss': -0.07798361366252529, 'approx_kl': 0.008987291250377893, 'clip_fraction': 0.2513020858168602, 'grad_norm': 3.019479513168335}
2022-12-28 20:18:17.656 DEBUG: Taking gradient step
2022-12-28 20:18:17.668 DEBUG: Loss 4: {'policy_loss': -0.04166534655251934, 'entropy_loss': -0.0823783129453659, 'vf_loss': 0.009562319578130248, 'total_loss': -0.11448133991975501, 'approx_kl': 0.011293675284832716, 'clip_fraction': 0.2747395858168602, 'grad_norm': 2.5497820377349854}
2022-12-28 20:18:18.694 DEBUG: Taking gradient step
2022-12-28 20:18:18.702 DEBUG: Loss 5: {'policy_loss': -0.04367000573509894, 'entropy_loss': -0.08293757028877735, 'vf_loss': 0.009550300692074685, 'total_loss': -0.1170572753318016, 'approx_kl': 0.020011860877275467, 'clip_fraction': 0.3229166716337204, 'grad_norm': 3.9416909217834473}
2022-12-28 20:18:19.669 DEBUG: Taking gradient step
2022-12-28 20:18:19.677 DEBUG: Loss 6: {'policy_loss': 0.015069753379616038, 'entropy_loss': -0.08267839439213276, 'vf_loss': 0.014524079870592368, 'total_loss': -0.05308456114192435, 'approx_kl': 0.0038718481082469225, 'clip_fraction': 0.3684895858168602, 'grad_norm': 2.563844919204712}
2022-12-28 20:18:20.656 DEBUG: Taking gradient step
2022-12-28 20:18:20.665 DEBUG: Loss 7: {'policy_loss': -0.04659077517820745, 'entropy_loss': -0.08287522196769714, 'vf_loss': 0.009493781350405761, 'total_loss': -0.11997221579549883, 'approx_kl': -0.022870185784995556, 'clip_fraction': 0.4296875, 'grad_norm': 3.4271609783172607}
2022-12-28 20:18:21.637 DEBUG: Taking gradient step
2022-12-28 20:18:21.645 DEBUG: Loss 8: {'policy_loss': -0.05793133747301147, 'entropy_loss': -0.0828984547406435, 'vf_loss': 0.009497486595425451, 'total_loss': -0.1313323056182295, 'approx_kl': -0.051141178235411644, 'clip_fraction': 0.4440104216337204, 'grad_norm': 3.2853145599365234}
2022-12-28 20:18:22.595 DEBUG: Taking gradient step
2022-12-28 20:18:22.603 DEBUG: Loss 9: {'policy_loss': 0.01199402592179049, 'entropy_loss': -0.08248353935778141, 'vf_loss': 0.01433818303260162, 'total_loss': -0.056151330403389293, 'approx_kl': -0.040079244412481785, 'clip_fraction': 0.4752604216337204, 'grad_norm': 3.286461353302002}
2022-12-28 20:18:22.603 INFO: Optimization: policy loss=0.012, vf loss=0.014, entropy loss=-0.082, total loss=-0.056, num steps=10
2022-12-28 20:18:22.603 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:18:24.428 INFO: Evaluation rollout: return=0.651 (0.0), episode length=6.0
2022-12-28 20:18:24.429 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:18:24.432 INFO: Iteration: 72/137, steps: 15552
2022-12-28 20:19:26.943 INFO: Training rollout: return=0.801 (0.2), episode length=6.0
2022-12-28 20:19:26.945 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:19:26.947 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-15552_train.pkl
2022-12-28 20:19:27.955 DEBUG: Taking gradient step
2022-12-28 20:19:27.964 DEBUG: Loss 0: {'policy_loss': 0.011826858178840214, 'entropy_loss': -0.08486740291118622, 'vf_loss': 0.0006208350310664762, 'total_loss': -0.07241970970127953, 'approx_kl': -4.377216100692749e-08, 'clip_fraction': 0.0, 'grad_norm': 12.720476150512695}
2022-12-28 20:19:28.969 DEBUG: Taking gradient step
2022-12-28 20:19:28.977 DEBUG: Loss 1: {'policy_loss': -0.02091059001378441, 'entropy_loss': -0.08478631637990475, 'vf_loss': 0.0006123191735250066, 'total_loss': -0.10508458722016416, 'approx_kl': 0.00805333536118269, 'clip_fraction': 0.061197916977107525, 'grad_norm': 21.438247680664062}
2022-12-28 20:19:29.939 DEBUG: Taking gradient step
2022-12-28 20:19:29.946 DEBUG: Loss 2: {'policy_loss': 0.018256365009202614, 'entropy_loss': -0.08441632986068726, 'vf_loss': 0.0005682701011488683, 'total_loss': -0.06559169475033577, 'approx_kl': 0.03089934471063316, 'clip_fraction': 0.2825520858168602, 'grad_norm': 15.591939926147461}
2022-12-28 20:19:30.910 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-28 20:19:30.911 INFO: Optimization: policy loss=0.018, vf loss=0.001, entropy loss=-0.084, total loss=-0.066, num steps=3
2022-12-28 20:19:30.912 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:19:32.689 INFO: Evaluation rollout: return=0.908 (0.0), episode length=6.0
2022-12-28 20:19:32.691 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:19:32.694 INFO: Iteration: 73/137, steps: 15768
2022-12-28 20:20:35.709 INFO: Training rollout: return=0.805 (0.1), episode length=6.0
2022-12-28 20:20:35.711 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:20:35.714 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-15768_train.pkl
2022-12-28 20:20:36.722 DEBUG: Taking gradient step
2022-12-28 20:20:36.730 DEBUG: Loss 0: {'policy_loss': 0.04084487325621597, 'entropy_loss': -0.08317953906953335, 'vf_loss': 0.0006161669631671563, 'total_loss': -0.04171849885015022, 'approx_kl': -4.6100467443466187e-08, 'clip_fraction': 0.0, 'grad_norm': 16.303503036499023}
2022-12-28 20:20:37.751 DEBUG: Taking gradient step
2022-12-28 20:20:37.763 DEBUG: Loss 1: {'policy_loss': 0.04018455694357745, 'entropy_loss': -0.08251703158020973, 'vf_loss': 0.0005914128701172798, 'total_loss': -0.041741061766515014, 'approx_kl': 0.007265679771080613, 'clip_fraction': 0.0078125, 'grad_norm': 14.802352905273438}
2022-12-28 20:20:38.806 DEBUG: Taking gradient step
2022-12-28 20:20:38.816 DEBUG: Loss 2: {'policy_loss': -0.049477117815088324, 'entropy_loss': -0.08309752680361271, 'vf_loss': 0.0005959154349295989, 'total_loss': -0.13197872918377143, 'approx_kl': 0.02214162307791412, 'clip_fraction': 0.1692708358168602, 'grad_norm': 12.85484790802002}
2022-12-28 20:20:39.810 DEBUG: Taking gradient step
2022-12-28 20:20:39.818 DEBUG: Loss 3: {'policy_loss': -0.008928354719581609, 'entropy_loss': -0.08383284509181976, 'vf_loss': 0.0005423813498282368, 'total_loss': -0.09221881846157315, 'approx_kl': 0.041886734776198864, 'clip_fraction': 0.3229166679084301, 'grad_norm': 8.555649757385254}
2022-12-28 20:20:40.770 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-28 20:20:40.770 INFO: Optimization: policy loss=-0.009, vf loss=0.001, entropy loss=-0.084, total loss=-0.092, num steps=4
2022-12-28 20:20:40.771 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:20:42.653 INFO: Evaluation rollout: return=0.792 (0.0), episode length=6.0
2022-12-28 20:20:42.654 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:20:42.658 INFO: Iteration: 74/137, steps: 15984
2022-12-28 20:21:00.002 DEBUG: Atoms are too close
2022-12-28 20:21:40.438 DEBUG: There is a single atom floating around
2022-12-28 20:21:45.081 INFO: Training rollout: return=-0.324 (4.6), episode length=6.0
2022-12-28 20:21:45.083 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:21:45.086 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-15984_train.pkl
2022-12-28 20:21:46.063 DEBUG: Taking gradient step
2022-12-28 20:21:46.071 DEBUG: Loss 0: {'policy_loss': -0.006402965929956671, 'entropy_loss': -0.08537680469453335, 'vf_loss': 0.0194706972523475, 'total_loss': -0.07230907337214251, 'approx_kl': 3.8029007498607825e-08, 'clip_fraction': 0.0, 'grad_norm': 11.658479690551758}
2022-12-28 20:21:47.115 DEBUG: Taking gradient step
2022-12-28 20:21:47.124 DEBUG: Loss 1: {'policy_loss': -0.047652798223484755, 'entropy_loss': -0.0846816673874855, 'vf_loss': 0.01688554128086428, 'total_loss': -0.11544892433010598, 'approx_kl': 0.0006603898946195841, 'clip_fraction': 0.05598958395421505, 'grad_norm': 8.669105529785156}
2022-12-28 20:21:48.084 DEBUG: Taking gradient step
2022-12-28 20:21:48.091 DEBUG: Loss 2: {'policy_loss': -0.028471046076642227, 'entropy_loss': -0.08379972912371159, 'vf_loss': 0.01939710266860692, 'total_loss': -0.0928736725317469, 'approx_kl': 0.013742174953222275, 'clip_fraction': 0.2161458358168602, 'grad_norm': 3.526416301727295}
2022-12-28 20:21:49.088 DEBUG: Taking gradient step
2022-12-28 20:21:49.101 DEBUG: Loss 3: {'policy_loss': -0.025320821793256086, 'entropy_loss': -0.08426268957555294, 'vf_loss': 0.01933139794958527, 'total_loss': -0.09025211341922376, 'approx_kl': 0.024437226820737123, 'clip_fraction': 0.3385416679084301, 'grad_norm': 4.677672863006592}
2022-12-28 20:21:50.080 DEBUG: Taking gradient step
2022-12-28 20:21:50.088 DEBUG: Loss 4: {'policy_loss': -0.012245348312069936, 'entropy_loss': -0.08469407074153423, 'vf_loss': 0.021813389271696508, 'total_loss': -0.07512602978190766, 'approx_kl': 0.02975485718343407, 'clip_fraction': 0.4127604216337204, 'grad_norm': 3.3830156326293945}
2022-12-28 20:21:51.082 DEBUG: Taking gradient step
2022-12-28 20:21:51.090 DEBUG: Loss 5: {'policy_loss': -0.03207357217637928, 'entropy_loss': -0.08440369740128517, 'vf_loss': 0.019304903827493673, 'total_loss': -0.09717236575017078, 'approx_kl': 0.02877033967524767, 'clip_fraction': 0.453125, 'grad_norm': 3.32576322555542}
2022-12-28 20:21:52.064 DEBUG: Taking gradient step
2022-12-28 20:21:52.073 DEBUG: Loss 6: {'policy_loss': -0.03214567130524055, 'entropy_loss': -0.08461790531873703, 'vf_loss': 0.019388269029303826, 'total_loss': -0.09737530759467376, 'approx_kl': 0.016952548176050186, 'clip_fraction': 0.3919270858168602, 'grad_norm': 3.0723910331726074}
2022-12-28 20:21:53.053 DEBUG: Taking gradient step
2022-12-28 20:21:53.061 DEBUG: Loss 7: {'policy_loss': -0.03603002099595853, 'entropy_loss': -0.08477926813066006, 'vf_loss': 0.019212825173505154, 'total_loss': -0.10159646395311343, 'approx_kl': -0.003869433654472232, 'clip_fraction': 0.3359375, 'grad_norm': 2.7886452674865723}
2022-12-28 20:21:54.024 DEBUG: Taking gradient step
2022-12-28 20:21:54.034 DEBUG: Loss 8: {'policy_loss': -0.04725776582607215, 'entropy_loss': -0.08375069685280323, 'vf_loss': 0.019154155028390372, 'total_loss': -0.11185430765048501, 'approx_kl': -0.01498153223656118, 'clip_fraction': 0.3333333358168602, 'grad_norm': 2.531686544418335}
2022-12-28 20:21:55.012 DEBUG: Taking gradient step
2022-12-28 20:21:55.023 DEBUG: Loss 9: {'policy_loss': -0.026560642599539934, 'entropy_loss': -0.08415599726140499, 'vf_loss': 0.021568822577665882, 'total_loss': -0.08914781728327904, 'approx_kl': -0.022398119093850255, 'clip_fraction': 0.33203125, 'grad_norm': 4.971072196960449}
2022-12-28 20:21:55.024 INFO: Optimization: policy loss=-0.027, vf loss=0.022, entropy loss=-0.084, total loss=-0.089, num steps=10
2022-12-28 20:21:55.024 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:21:56.939 INFO: Evaluation rollout: return=0.908 (0.0), episode length=6.0
2022-12-28 20:21:56.940 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:21:56.943 INFO: Iteration: 75/137, steps: 16200
2022-12-28 20:22:35.278 DEBUG: There is a single atom floating around
2022-12-28 20:22:59.387 INFO: Training rollout: return=0.226 (3.3), episode length=6.0
2022-12-28 20:22:59.388 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:22:59.392 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-16200_train.pkl
2022-12-28 20:23:00.410 DEBUG: Taking gradient step
2022-12-28 20:23:00.418 DEBUG: Loss 0: {'policy_loss': -0.02225090571405785, 'entropy_loss': -0.08542981743812561, 'vf_loss': 0.009575423595036735, 'total_loss': -0.09810529955714672, 'approx_kl': -4.579002643723129e-08, 'clip_fraction': 0.0, 'grad_norm': 11.446937561035156}
2022-12-28 20:23:01.399 DEBUG: Taking gradient step
2022-12-28 20:23:01.407 DEBUG: Loss 1: {'policy_loss': -0.04422834886946721, 'entropy_loss': -0.08454370126128197, 'vf_loss': 0.00961926779662708, 'total_loss': -0.1191527823341221, 'approx_kl': 0.011498047271743417, 'clip_fraction': 0.03515625, 'grad_norm': 9.373512268066406}
2022-12-28 20:23:02.411 DEBUG: Taking gradient step
2022-12-28 20:23:02.419 DEBUG: Loss 2: {'policy_loss': -0.047002523069988575, 'entropy_loss': -0.08394566550850868, 'vf_loss': 0.0096047809271224, 'total_loss': -0.12134340765137486, 'approx_kl': 0.03340957569889724, 'clip_fraction': 0.2330729216337204, 'grad_norm': 3.884249448776245}
2022-12-28 20:23:03.392 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-28 20:23:03.392 INFO: Optimization: policy loss=-0.047, vf loss=0.010, entropy loss=-0.084, total loss=-0.121, num steps=3
2022-12-28 20:23:03.393 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:23:05.212 INFO: Evaluation rollout: return=0.903 (0.0), episode length=6.0
2022-12-28 20:23:05.213 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:23:05.216 INFO: Iteration: 76/137, steps: 16416
2022-12-28 20:23:23.786 DEBUG: There is a single atom floating around
2022-12-28 20:23:29.480 DEBUG: There is a single atom floating around
2022-12-28 20:24:07.363 INFO: Training rollout: return=-0.326 (4.7), episode length=5.9
2022-12-28 20:24:07.364 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:24:07.367 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-16416_train.pkl
2022-12-28 20:24:08.360 DEBUG: Taking gradient step
2022-12-28 20:24:08.367 DEBUG: Loss 0: {'policy_loss': -0.03295275373979224, 'entropy_loss': -0.08231489546597004, 'vf_loss': 0.012527958139943977, 'total_loss': -0.1027396910658183, 'approx_kl': 6.752088665962219e-09, 'clip_fraction': 0.0, 'grad_norm': 16.027637481689453}
2022-12-28 20:24:09.413 DEBUG: Taking gradient step
2022-12-28 20:24:09.423 DEBUG: Loss 1: {'policy_loss': -0.009402646005778817, 'entropy_loss': -0.08218931406736374, 'vf_loss': 0.014948018716659559, 'total_loss': -0.07664394135648299, 'approx_kl': 0.0032818885520100594, 'clip_fraction': 0.02864583395421505, 'grad_norm': 8.764055252075195}
2022-12-28 20:24:10.425 DEBUG: Taking gradient step
2022-12-28 20:24:10.439 DEBUG: Loss 2: {'policy_loss': -0.002797010635395312, 'entropy_loss': -0.08236198872327805, 'vf_loss': 0.014942031629828607, 'total_loss': -0.07021696772884475, 'approx_kl': 0.0016414481215178967, 'clip_fraction': 0.11588541697710752, 'grad_norm': 8.726530075073242}
2022-12-28 20:24:11.425 DEBUG: Taking gradient step
2022-12-28 20:24:11.433 DEBUG: Loss 3: {'policy_loss': -0.014096675094057622, 'entropy_loss': -0.08243009634315968, 'vf_loss': 0.015047725072834073, 'total_loss': -0.08147904636438322, 'approx_kl': -0.0004117228090763092, 'clip_fraction': 0.1888020858168602, 'grad_norm': 4.621705532073975}
2022-12-28 20:24:12.422 DEBUG: Taking gradient step
2022-12-28 20:24:12.429 DEBUG: Loss 4: {'policy_loss': -0.01672389664485872, 'entropy_loss': -0.082345275208354, 'vf_loss': 0.015154546336021816, 'total_loss': -0.0839146255171909, 'approx_kl': -0.006200911244377494, 'clip_fraction': 0.2434895858168602, 'grad_norm': 4.416321754455566}
2022-12-28 20:24:13.420 DEBUG: Taking gradient step
2022-12-28 20:24:13.428 DEBUG: Loss 5: {'policy_loss': 0.009593656430071262, 'entropy_loss': -0.0816015936434269, 'vf_loss': 0.017500687551889396, 'total_loss': -0.05450724966146622, 'approx_kl': -0.006441784091293812, 'clip_fraction': 0.2369791679084301, 'grad_norm': 3.9233546257019043}
2022-12-28 20:24:14.430 DEBUG: Taking gradient step
2022-12-28 20:24:14.442 DEBUG: Loss 6: {'policy_loss': -0.03723359991669693, 'entropy_loss': -0.08145150914788246, 'vf_loss': 0.014942313794732622, 'total_loss': -0.10374279526984678, 'approx_kl': -0.02343876287341118, 'clip_fraction': 0.3098958358168602, 'grad_norm': 2.878131866455078}
2022-12-28 20:24:15.465 DEBUG: Taking gradient step
2022-12-28 20:24:15.473 DEBUG: Loss 7: {'policy_loss': -0.0033797699639972756, 'entropy_loss': -0.08185559324920177, 'vf_loss': 0.017522967783754437, 'total_loss': -0.06771239542944463, 'approx_kl': -0.03517750184983015, 'clip_fraction': 0.3385416716337204, 'grad_norm': 2.4489262104034424}
2022-12-28 20:24:16.464 DEBUG: Taking gradient step
2022-12-28 20:24:16.472 DEBUG: Loss 8: {'policy_loss': -0.034391884141313694, 'entropy_loss': -0.08163795061409473, 'vf_loss': 0.014818459401180702, 'total_loss': -0.10121137535422774, 'approx_kl': -0.040461343713104725, 'clip_fraction': 0.34765625, 'grad_norm': 2.273365020751953}
2022-12-28 20:24:17.452 DEBUG: Taking gradient step
2022-12-28 20:24:17.459 DEBUG: Loss 9: {'policy_loss': -0.05949277076910468, 'entropy_loss': -0.08080824837088585, 'vf_loss': 0.01244856645646911, 'total_loss': -0.1278524526835214, 'approx_kl': -0.050824970472604036, 'clip_fraction': 0.3658854216337204, 'grad_norm': 5.39451265335083}
2022-12-28 20:24:17.460 INFO: Optimization: policy loss=-0.059, vf loss=0.012, entropy loss=-0.081, total loss=-0.128, num steps=10
2022-12-28 20:24:17.460 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:24:18.948 DEBUG: Atoms are too close
2022-12-28 20:24:18.951 INFO: Evaluation rollout: return=-19.476 (0.0), episode length=6.0
2022-12-28 20:24:18.952 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:24:18.954 INFO: Iteration: 77/137, steps: 16632
2022-12-28 20:25:00.129 DEBUG: Atoms are too close
2022-12-28 20:25:21.046 INFO: Training rollout: return=0.274 (3.3), episode length=6.0
2022-12-28 20:25:21.047 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:25:21.050 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-16632_train.pkl
2022-12-28 20:25:22.056 DEBUG: Taking gradient step
2022-12-28 20:25:22.064 DEBUG: Loss 0: {'policy_loss': 0.05535983959769651, 'entropy_loss': -0.08173798583447933, 'vf_loss': 0.014473070304392394, 'total_loss': -0.011905075932390416, 'approx_kl': 1.3504177331924438e-08, 'clip_fraction': 0.0, 'grad_norm': 16.624319076538086}
2022-12-28 20:25:23.038 DEBUG: Taking gradient step
2022-12-28 20:25:23.046 DEBUG: Loss 1: {'policy_loss': -0.00392802774672088, 'entropy_loss': -0.0816431064158678, 'vf_loss': 0.01209502456120174, 'total_loss': -0.07347610960138695, 'approx_kl': 0.003989346558228135, 'clip_fraction': 0.015625, 'grad_norm': 16.81332015991211}
2022-12-28 20:25:24.059 DEBUG: Taking gradient step
2022-12-28 20:25:24.071 DEBUG: Loss 2: {'policy_loss': -0.03915665218282204, 'entropy_loss': -0.08193393051624298, 'vf_loss': 0.00957687750562364, 'total_loss': -0.11151370519344139, 'approx_kl': 0.01575620612129569, 'clip_fraction': 0.1640625, 'grad_norm': 4.779432773590088}
2022-12-28 20:25:25.065 DEBUG: Taking gradient step
2022-12-28 20:25:25.073 DEBUG: Loss 3: {'policy_loss': -0.009519319680905297, 'entropy_loss': -0.08201801590621471, 'vf_loss': 0.01208687251595929, 'total_loss': -0.07945046307116072, 'approx_kl': 0.03565566265024245, 'clip_fraction': 0.3190104216337204, 'grad_norm': 4.365577697753906}
2022-12-28 20:25:26.073 DEBUG: Taking gradient step
2022-12-28 20:25:26.081 DEBUG: Loss 4: {'policy_loss': -0.0463834855338792, 'entropy_loss': -0.08127566240727901, 'vf_loss': 0.00956954174943207, 'total_loss': -0.11808960619172615, 'approx_kl': 0.01762616541236639, 'clip_fraction': 0.3463541716337204, 'grad_norm': 2.795842409133911}
2022-12-28 20:25:27.080 DEBUG: Early stopping at step 5 for reaching max KL.
2022-12-28 20:25:27.081 INFO: Optimization: policy loss=-0.046, vf loss=0.010, entropy loss=-0.081, total loss=-0.118, num steps=5
2022-12-28 20:25:27.081 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:25:28.810 INFO: Evaluation rollout: return=0.494 (0.0), episode length=6.0
2022-12-28 20:25:28.812 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:25:28.814 INFO: Iteration: 78/137, steps: 16848
2022-12-28 20:26:32.291 INFO: Training rollout: return=0.772 (0.1), episode length=6.0
2022-12-28 20:26:32.293 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:26:32.296 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-16848_train.pkl
2022-12-28 20:26:33.302 DEBUG: Taking gradient step
2022-12-28 20:26:33.310 DEBUG: Loss 0: {'policy_loss': 0.04068033568177162, 'entropy_loss': -0.08076541870832443, 'vf_loss': 0.0005634449651004279, 'total_loss': -0.03952163806145238, 'approx_kl': -4.035729972429181e-09, 'clip_fraction': 0.0, 'grad_norm': 17.970447540283203}
2022-12-28 20:26:34.301 DEBUG: Taking gradient step
2022-12-28 20:26:34.308 DEBUG: Loss 1: {'policy_loss': -0.05073762333898961, 'entropy_loss': -0.08074560016393661, 'vf_loss': 0.0005671916001903144, 'total_loss': -0.1309160319027359, 'approx_kl': 0.010153056588023901, 'clip_fraction': 0.0234375, 'grad_norm': 19.421192169189453}
2022-12-28 20:26:35.283 DEBUG: Taking gradient step
2022-12-28 20:26:35.291 DEBUG: Loss 2: {'policy_loss': -0.0387362330427974, 'entropy_loss': -0.08081786893308163, 'vf_loss': 0.0005325081650300823, 'total_loss': -0.11902159381084895, 'approx_kl': 0.0260388245806098, 'clip_fraction': 0.22265625, 'grad_norm': 18.36669158935547}
2022-12-28 20:26:36.343 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-28 20:26:36.343 INFO: Optimization: policy loss=-0.039, vf loss=0.001, entropy loss=-0.081, total loss=-0.119, num steps=3
2022-12-28 20:26:36.344 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:26:38.184 INFO: Evaluation rollout: return=0.758 (0.0), episode length=6.0
2022-12-28 20:26:38.186 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:26:38.188 INFO: Iteration: 79/137, steps: 17064
2022-12-28 20:27:17.104 DEBUG: Atoms are too close
2022-12-28 20:27:17.106 DEBUG: There is a single atom floating around
2022-12-28 20:27:18.309 DEBUG: There is a single atom floating around
2022-12-28 20:27:40.311 INFO: Training rollout: return=-0.863 (5.5), episode length=6.0
2022-12-28 20:27:40.313 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:27:40.315 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-17064_train.pkl
2022-12-28 20:27:41.303 DEBUG: Taking gradient step
2022-12-28 20:27:41.311 DEBUG: Loss 0: {'policy_loss': -0.0013993123146859411, 'entropy_loss': -0.07983963005244732, 'vf_loss': 0.03167237256479678, 'total_loss': -0.04956656980233648, 'approx_kl': -6.938353180885315e-08, 'clip_fraction': 0.0, 'grad_norm': 8.320594787597656}
2022-12-28 20:27:42.278 DEBUG: Taking gradient step
2022-12-28 20:27:42.287 DEBUG: Loss 1: {'policy_loss': -0.029747668079929613, 'entropy_loss': -0.08029991202056408, 'vf_loss': 0.029243669113411398, 'total_loss': -0.0808039109870823, 'approx_kl': 0.004474757704883814, 'clip_fraction': 0.0234375, 'grad_norm': 8.654836654663086}
2022-12-28 20:27:43.249 DEBUG: Taking gradient step
2022-12-28 20:27:43.257 DEBUG: Loss 2: {'policy_loss': -0.0358514408700605, 'entropy_loss': -0.0799286849796772, 'vf_loss': 0.029217657097415722, 'total_loss': -0.08656246875232197, 'approx_kl': 0.006760400719940662, 'clip_fraction': 0.11458333395421505, 'grad_norm': 8.100428581237793}
2022-12-28 20:27:44.280 DEBUG: Taking gradient step
2022-12-28 20:27:44.287 DEBUG: Loss 3: {'policy_loss': -0.008053957468204302, 'entropy_loss': -0.07877960801124573, 'vf_loss': 0.03403683519224211, 'total_loss': -0.052796730287207924, 'approx_kl': 0.009033380774781108, 'clip_fraction': 0.15364583395421505, 'grad_norm': 6.280571460723877}
2022-12-28 20:27:45.289 DEBUG: Taking gradient step
2022-12-28 20:27:45.297 DEBUG: Loss 4: {'policy_loss': -0.007606580696591141, 'entropy_loss': -0.07998047769069672, 'vf_loss': 0.03409596564965489, 'total_loss': -0.05349109273763297, 'approx_kl': 0.008483096491545439, 'clip_fraction': 0.2408854179084301, 'grad_norm': 18.151569366455078}
2022-12-28 20:27:46.256 DEBUG: Taking gradient step
2022-12-28 20:27:46.263 DEBUG: Loss 5: {'policy_loss': -0.03237069452523599, 'entropy_loss': -0.07946961559355259, 'vf_loss': 0.03162864832281678, 'total_loss': -0.0802116617959718, 'approx_kl': 0.014514538168441504, 'clip_fraction': 0.3411458358168602, 'grad_norm': 7.008444309234619}
2022-12-28 20:27:47.242 DEBUG: Taking gradient step
2022-12-28 20:27:47.249 DEBUG: Loss 6: {'policy_loss': -0.07713863230469963, 'entropy_loss': -0.07903891615569592, 'vf_loss': 0.026703912717954192, 'total_loss': -0.12947363574244136, 'approx_kl': 0.01359840901568532, 'clip_fraction': 0.34375, 'grad_norm': 4.779965400695801}
2022-12-28 20:27:48.266 DEBUG: Taking gradient step
2022-12-28 20:27:48.274 DEBUG: Loss 7: {'policy_loss': -0.06204642744539067, 'entropy_loss': -0.0790492407977581, 'vf_loss': 0.029009525654168325, 'total_loss': -0.11208614258898045, 'approx_kl': 0.0065116286277771, 'clip_fraction': 0.3854166716337204, 'grad_norm': 9.631896018981934}
2022-12-28 20:27:49.231 DEBUG: Taking gradient step
2022-12-28 20:27:49.239 DEBUG: Loss 8: {'policy_loss': -0.04298638866427455, 'entropy_loss': -0.07879842817783356, 'vf_loss': 0.03141097946846841, 'total_loss': -0.09037383737363971, 'approx_kl': -0.00042477110400795937, 'clip_fraction': 0.4127604216337204, 'grad_norm': 3.5179827213287354}
2022-12-28 20:27:50.277 DEBUG: Taking gradient step
2022-12-28 20:27:50.289 DEBUG: Loss 9: {'policy_loss': -0.030918511422004108, 'entropy_loss': -0.07845649495720863, 'vf_loss': 0.0336427898637929, 'total_loss': -0.07573221651541984, 'approx_kl': 0.02628909796476364, 'clip_fraction': 0.43359375, 'grad_norm': 3.128938913345337}
2022-12-28 20:27:50.290 INFO: Optimization: policy loss=-0.031, vf loss=0.034, entropy loss=-0.078, total loss=-0.076, num steps=10
2022-12-28 20:27:50.290 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:27:52.292 INFO: Evaluation rollout: return=0.813 (0.0), episode length=6.0
2022-12-28 20:27:52.293 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:27:52.296 INFO: Iteration: 80/137, steps: 17280
2022-12-28 20:28:32.257 DEBUG: There is a single atom floating around
2022-12-28 20:28:54.947 INFO: Training rollout: return=0.236 (3.3), episode length=6.0
2022-12-28 20:28:54.948 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:28:54.951 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-17280_train.pkl
2022-12-28 20:28:55.981 DEBUG: Taking gradient step
2022-12-28 20:28:55.989 DEBUG: Loss 0: {'policy_loss': 0.014957953058485267, 'entropy_loss': -0.08197170123457909, 'vf_loss': 0.012054910455734629, 'total_loss': -0.05495883772035919, 'approx_kl': -3.41484938104486e-08, 'clip_fraction': 0.0, 'grad_norm': 14.902517318725586}
2022-12-28 20:28:56.952 DEBUG: Taking gradient step
2022-12-28 20:28:56.960 DEBUG: Loss 1: {'policy_loss': 0.0014680230642961124, 'entropy_loss': -0.08239906653761864, 'vf_loss': 0.012094475436907896, 'total_loss': -0.06883656803641462, 'approx_kl': 0.0071802951861172915, 'clip_fraction': 0.08072916697710752, 'grad_norm': 13.446083068847656}
2022-12-28 20:28:57.909 DEBUG: Taking gradient step
2022-12-28 20:28:57.917 DEBUG: Loss 2: {'policy_loss': -0.03880212726804753, 'entropy_loss': -0.08146789483726025, 'vf_loss': 0.009717645272318073, 'total_loss': -0.1105523768329897, 'approx_kl': 0.011635031085461378, 'clip_fraction': 0.25, 'grad_norm': 7.733420372009277}
2022-12-28 20:28:58.883 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-28 20:28:58.883 INFO: Optimization: policy loss=-0.039, vf loss=0.010, entropy loss=-0.081, total loss=-0.111, num steps=3
2022-12-28 20:28:58.884 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:29:00.718 INFO: Evaluation rollout: return=0.797 (0.0), episode length=6.0
2022-12-28 20:29:00.719 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:29:00.721 DEBUG: Deleting old model: runs/CH3NO_painn/models/CH3NO_painn_run-1_steps-15336.model
2022-12-28 20:29:00.726 DEBUG: Saving model: runs/CH3NO_painn/models/CH3NO_painn_run-1_steps-17496.model
2022-12-28 20:29:00.749 INFO: Iteration: 81/137, steps: 17496
2022-12-28 20:30:03.886 INFO: Training rollout: return=0.796 (0.2), episode length=6.0
2022-12-28 20:30:03.888 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:30:03.891 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-17496_train.pkl
2022-12-28 20:30:04.906 DEBUG: Taking gradient step
2022-12-28 20:30:04.917 DEBUG: Loss 0: {'policy_loss': 0.03062372357429475, 'entropy_loss': -0.07910594902932644, 'vf_loss': 0.0010651679428740142, 'total_loss': -0.047417057512157676, 'approx_kl': 5.960464477539063e-08, 'clip_fraction': 0.0, 'grad_norm': 26.868412017822266}
2022-12-28 20:30:05.894 DEBUG: Taking gradient step
2022-12-28 20:30:05.903 DEBUG: Loss 1: {'policy_loss': 0.050448233940959264, 'entropy_loss': -0.07975327968597412, 'vf_loss': 0.001125187258808138, 'total_loss': -0.02817985848620673, 'approx_kl': 0.010340207183617167, 'clip_fraction': 0.0859375, 'grad_norm': 24.890159606933594}
2022-12-28 20:30:06.877 DEBUG: Taking gradient step
2022-12-28 20:30:06.885 DEBUG: Loss 2: {'policy_loss': -0.04094265301713304, 'entropy_loss': -0.07884136401116848, 'vf_loss': 0.001210046886734692, 'total_loss': -0.11857397014156681, 'approx_kl': 0.03162016696296632, 'clip_fraction': 0.25, 'grad_norm': 15.893797874450684}
2022-12-28 20:30:07.893 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-28 20:30:07.894 INFO: Optimization: policy loss=-0.041, vf loss=0.001, entropy loss=-0.079, total loss=-0.119, num steps=3
2022-12-28 20:30:07.894 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:30:09.656 INFO: Evaluation rollout: return=0.796 (0.0), episode length=6.0
2022-12-28 20:30:09.657 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:30:09.660 INFO: Iteration: 82/137, steps: 17712
2022-12-28 20:31:10.355 DEBUG: Atoms are too close
2022-12-28 20:31:11.610 INFO: Training rollout: return=0.267 (3.3), episode length=6.0
2022-12-28 20:31:11.611 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:31:11.614 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-17712_train.pkl
2022-12-28 20:31:12.586 DEBUG: Taking gradient step
2022-12-28 20:31:12.594 DEBUG: Loss 0: {'policy_loss': -0.02466169073752468, 'entropy_loss': -0.0819703210145235, 'vf_loss': 0.009641600941003, 'total_loss': -0.09699041081104517, 'approx_kl': -1.0392007965265293e-07, 'clip_fraction': 0.0, 'grad_norm': 19.52792739868164}
2022-12-28 20:31:13.590 DEBUG: Taking gradient step
2022-12-28 20:31:13.602 DEBUG: Loss 1: {'policy_loss': -0.006627006405270742, 'entropy_loss': -0.08137387037277222, 'vf_loss': 0.01202889878086019, 'total_loss': -0.07597197799718276, 'approx_kl': 0.0050225649029016495, 'clip_fraction': 0.045572916977107525, 'grad_norm': 12.222180366516113}
2022-12-28 20:31:14.632 DEBUG: Taking gradient step
2022-12-28 20:31:14.640 DEBUG: Loss 2: {'policy_loss': -0.04319280571455433, 'entropy_loss': -0.08024218305945396, 'vf_loss': 0.009663783669509957, 'total_loss': -0.11377120510449834, 'approx_kl': -0.002191950799897313, 'clip_fraction': 0.2591145858168602, 'grad_norm': 3.6201589107513428}
2022-12-28 20:31:15.608 DEBUG: Taking gradient step
2022-12-28 20:31:15.616 DEBUG: Loss 3: {'policy_loss': 0.023777312455679614, 'entropy_loss': -0.08244655095040798, 'vf_loss': 0.014242250474241063, 'total_loss': -0.04442698802048729, 'approx_kl': 0.01055862964130938, 'clip_fraction': 0.37890625, 'grad_norm': 3.7189722061157227}
2022-12-28 20:31:16.605 DEBUG: Taking gradient step
2022-12-28 20:31:16.613 DEBUG: Loss 4: {'policy_loss': -0.042181458082947515, 'entropy_loss': -0.08045931905508041, 'vf_loss': 0.00960842867954632, 'total_loss': -0.1130323484584816, 'approx_kl': 0.010132429888471961, 'clip_fraction': 0.3828125, 'grad_norm': 3.5853803157806396}
2022-12-28 20:31:17.602 DEBUG: Taking gradient step
2022-12-28 20:31:17.610 DEBUG: Loss 5: {'policy_loss': -0.017372718937562932, 'entropy_loss': -0.08087833598256111, 'vf_loss': 0.011940206859537651, 'total_loss': -0.08631084806058638, 'approx_kl': 0.0076105594635009766, 'clip_fraction': 0.4010416716337204, 'grad_norm': 3.621757984161377}
2022-12-28 20:31:18.591 DEBUG: Taking gradient step
2022-12-28 20:31:18.599 DEBUG: Loss 6: {'policy_loss': 0.010081014267685776, 'entropy_loss': -0.08160778321325779, 'vf_loss': 0.014137524157647366, 'total_loss': -0.05738924478792466, 'approx_kl': -0.006393494782969356, 'clip_fraction': 0.3984375, 'grad_norm': 4.1447296142578125}
2022-12-28 20:31:19.584 DEBUG: Taking gradient step
2022-12-28 20:31:19.591 DEBUG: Loss 7: {'policy_loss': -0.0529938229512765, 'entropy_loss': -0.08169825002551079, 'vf_loss': 0.009460260833480137, 'total_loss': -0.12523181214330714, 'approx_kl': -0.02645570132881403, 'clip_fraction': 0.33203125, 'grad_norm': 7.298954963684082}
2022-12-28 20:31:20.592 DEBUG: Taking gradient step
2022-12-28 20:31:20.600 DEBUG: Loss 8: {'policy_loss': -0.053005604273156204, 'entropy_loss': -0.08222786150872707, 'vf_loss': 0.009401313924312146, 'total_loss': -0.12583215185757113, 'approx_kl': -0.028095588088035583, 'clip_fraction': 0.4010416716337204, 'grad_norm': 5.911965847015381}
2022-12-28 20:31:21.576 DEBUG: Taking gradient step
2022-12-28 20:31:21.584 DEBUG: Loss 9: {'policy_loss': -0.0563389082619363, 'entropy_loss': -0.0821184515953064, 'vf_loss': 0.009357666602513318, 'total_loss': -0.12909969325472936, 'approx_kl': -0.03706998657435179, 'clip_fraction': 0.3932291716337204, 'grad_norm': 3.400153875350952}
2022-12-28 20:31:21.584 INFO: Optimization: policy loss=-0.056, vf loss=0.009, entropy loss=-0.082, total loss=-0.129, num steps=10
2022-12-28 20:31:21.585 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:31:23.477 INFO: Evaluation rollout: return=1.002 (0.0), episode length=6.0
2022-12-28 20:31:23.479 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:31:23.481 INFO: Iteration: 83/137, steps: 17928
2022-12-28 20:31:59.639 DEBUG: Atoms are too close
2022-12-28 20:32:21.201 DEBUG: There is a single atom floating around
2022-12-28 20:32:25.382 INFO: Training rollout: return=-0.315 (4.6), episode length=5.9
2022-12-28 20:32:25.384 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:32:25.387 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-17928_train.pkl
2022-12-28 20:32:26.388 DEBUG: Taking gradient step
2022-12-28 20:32:26.396 DEBUG: Loss 0: {'policy_loss': 0.026747512401933522, 'entropy_loss': -0.0820157490670681, 'vf_loss': 0.019872565350917352, 'total_loss': -0.035395671314217225, 'approx_kl': 4.67213503441144e-08, 'clip_fraction': 0.0, 'grad_norm': 15.024168968200684}
2022-12-28 20:32:27.375 DEBUG: Taking gradient step
2022-12-28 20:32:27.383 DEBUG: Loss 1: {'policy_loss': -0.0424846114455793, 'entropy_loss': -0.08220023103058338, 'vf_loss': 0.015121035271523945, 'total_loss': -0.10956380720463874, 'approx_kl': 0.00234191189520061, 'clip_fraction': 0.0078125, 'grad_norm': 11.241436004638672}
2022-12-28 20:32:28.339 DEBUG: Taking gradient step
2022-12-28 20:32:28.347 DEBUG: Loss 2: {'policy_loss': 0.009632892409973073, 'entropy_loss': -0.0821324922144413, 'vf_loss': 0.019915435919479745, 'total_loss': -0.05258416388498848, 'approx_kl': 0.004865665454417467, 'clip_fraction': 0.09114583395421505, 'grad_norm': 5.938653945922852}
2022-12-28 20:32:29.304 DEBUG: Taking gradient step
2022-12-28 20:32:29.312 DEBUG: Loss 3: {'policy_loss': 1.2019262045068202e-05, 'entropy_loss': -0.0826746504753828, 'vf_loss': 0.019845497418075016, 'total_loss': -0.06281713379526271, 'approx_kl': 0.015773385297507048, 'clip_fraction': 0.15364583395421505, 'grad_norm': 6.2501540184021}
2022-12-28 20:32:30.302 DEBUG: Taking gradient step
2022-12-28 20:32:30.310 DEBUG: Loss 4: {'policy_loss': -0.06316509077232839, 'entropy_loss': -0.08193194307386875, 'vf_loss': 0.015168337740941179, 'total_loss': -0.12992869610525595, 'approx_kl': 0.005378606729209423, 'clip_fraction': 0.3411458358168602, 'grad_norm': 3.4665417671203613}
2022-12-28 20:32:31.272 DEBUG: Taking gradient step
2022-12-28 20:32:31.279 DEBUG: Loss 5: {'policy_loss': -0.031176791637064508, 'entropy_loss': -0.08156603388488293, 'vf_loss': 0.017569692408713727, 'total_loss': -0.09517313311323371, 'approx_kl': 0.01826646225526929, 'clip_fraction': 0.4140625, 'grad_norm': 11.514204025268555}
2022-12-28 20:32:32.279 DEBUG: Taking gradient step
2022-12-28 20:32:32.287 DEBUG: Loss 6: {'policy_loss': -0.008642180303910292, 'entropy_loss': -0.08192568272352219, 'vf_loss': 0.01982758181960648, 'total_loss': -0.07074028120782601, 'approx_kl': 0.016178753692656755, 'clip_fraction': 0.4817708432674408, 'grad_norm': 10.945209503173828}
2022-12-28 20:32:33.246 DEBUG: Taking gradient step
2022-12-28 20:32:33.255 DEBUG: Loss 7: {'policy_loss': -0.011052581932082532, 'entropy_loss': -0.08174999989569187, 'vf_loss': 0.020092525755201228, 'total_loss': -0.07271005607257318, 'approx_kl': 0.01776093221269548, 'clip_fraction': 0.4934895932674408, 'grad_norm': 3.338935613632202}
2022-12-28 20:32:34.204 DEBUG: Taking gradient step
2022-12-28 20:32:34.212 DEBUG: Loss 8: {'policy_loss': -0.06242725678846135, 'entropy_loss': -0.08191660791635513, 'vf_loss': 0.015116636276628683, 'total_loss': -0.1292272284281878, 'approx_kl': 0.0020506822038441896, 'clip_fraction': 0.45703125, 'grad_norm': 3.46612548828125}
2022-12-28 20:32:35.168 DEBUG: Taking gradient step
2022-12-28 20:32:35.176 DEBUG: Loss 9: {'policy_loss': -0.04232021802602709, 'entropy_loss': -0.08154883980751038, 'vf_loss': 0.017503117614099603, 'total_loss': -0.10636594021943786, 'approx_kl': -0.010532773332670331, 'clip_fraction': 0.4192708358168602, 'grad_norm': 2.768444538116455}
2022-12-28 20:32:35.176 INFO: Optimization: policy loss=-0.042, vf loss=0.018, entropy loss=-0.082, total loss=-0.106, num steps=10
2022-12-28 20:32:35.176 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:32:37.190 INFO: Evaluation rollout: return=0.890 (0.0), episode length=6.0
2022-12-28 20:32:37.191 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:32:37.193 INFO: Iteration: 84/137, steps: 18144
2022-12-28 20:33:39.546 INFO: Training rollout: return=0.823 (0.1), episode length=6.0
2022-12-28 20:33:39.547 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:33:39.549 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-18144_train.pkl
2022-12-28 20:33:40.542 DEBUG: Taking gradient step
2022-12-28 20:33:40.550 DEBUG: Loss 0: {'policy_loss': 0.0020534904996200956, 'entropy_loss': -0.0825422964990139, 'vf_loss': 0.0006051640274952006, 'total_loss': -0.07988364197189861, 'approx_kl': -5.0873495638370514e-08, 'clip_fraction': 0.0, 'grad_norm': 13.330141067504883}
2022-12-28 20:33:41.555 DEBUG: Taking gradient step
2022-12-28 20:33:41.563 DEBUG: Loss 1: {'policy_loss': -0.032793245534893836, 'entropy_loss': -0.08177407085895538, 'vf_loss': 0.0006325351059680712, 'total_loss': -0.11393478128788116, 'approx_kl': 0.026666653342545033, 'clip_fraction': 0.07682291697710752, 'grad_norm': 11.13262939453125}
2022-12-28 20:33:42.544 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-28 20:33:42.545 INFO: Optimization: policy loss=-0.033, vf loss=0.001, entropy loss=-0.082, total loss=-0.114, num steps=2
2022-12-28 20:33:42.545 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:33:44.356 INFO: Evaluation rollout: return=0.876 (0.0), episode length=6.0
2022-12-28 20:33:44.357 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:33:44.360 INFO: Iteration: 85/137, steps: 18360
2022-12-28 20:34:25.295 DEBUG: Atoms are too close
2022-12-28 20:34:39.128 DEBUG: There is a single atom floating around
2022-12-28 20:34:46.044 INFO: Training rollout: return=-0.378 (4.6), episode length=6.0
2022-12-28 20:34:46.045 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:34:46.048 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-18360_train.pkl
2022-12-28 20:34:47.033 DEBUG: Taking gradient step
2022-12-28 20:34:47.040 DEBUG: Loss 0: {'policy_loss': -0.01306421676131465, 'entropy_loss': -0.08193358406424522, 'vf_loss': 0.01940099043860937, 'total_loss': -0.0755968103869505, 'approx_kl': 6.713283795534153e-08, 'clip_fraction': 0.0, 'grad_norm': 10.497648239135742}
2022-12-28 20:34:48.038 DEBUG: Taking gradient step
2022-12-28 20:34:48.046 DEBUG: Loss 1: {'policy_loss': -0.018097694520084567, 'entropy_loss': -0.08212772756814957, 'vf_loss': 0.019424157569416952, 'total_loss': -0.08080126451881718, 'approx_kl': 9.111320832744241e-05, 'clip_fraction': 0.09635416697710752, 'grad_norm': 16.710630416870117}
2022-12-28 20:34:49.035 DEBUG: Taking gradient step
2022-12-28 20:34:49.043 DEBUG: Loss 2: {'policy_loss': -0.022406755753853886, 'entropy_loss': -0.081914396956563, 'vf_loss': 0.01940361158310874, 'total_loss': -0.08491754112730814, 'approx_kl': 0.014015264110639691, 'clip_fraction': 0.3072916716337204, 'grad_norm': 16.287267684936523}
2022-12-28 20:34:50.032 DEBUG: Taking gradient step
2022-12-28 20:34:50.040 DEBUG: Loss 3: {'policy_loss': -0.023574633481935822, 'entropy_loss': -0.08249532617628574, 'vf_loss': 0.019437266688772162, 'total_loss': -0.0866326929694494, 'approx_kl': 0.017936581280082464, 'clip_fraction': 0.3606770858168602, 'grad_norm': 14.519171714782715}
2022-12-28 20:34:50.990 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-28 20:34:50.990 INFO: Optimization: policy loss=-0.024, vf loss=0.019, entropy loss=-0.082, total loss=-0.087, num steps=4
2022-12-28 20:34:50.991 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:34:52.715 INFO: Evaluation rollout: return=0.929 (0.0), episode length=6.0
2022-12-28 20:34:52.716 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:34:52.718 INFO: Iteration: 86/137, steps: 18576
2022-12-28 20:35:03.648 DEBUG: Atoms are too close
2022-12-28 20:35:08.972 DEBUG: Atoms are too close
2022-12-28 20:35:53.297 DEBUG: There is a single atom floating around
2022-12-28 20:35:54.068 INFO: Training rollout: return=-0.897 (5.6), episode length=5.9
2022-12-28 20:35:54.070 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:35:54.072 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-18576_train.pkl
2022-12-28 20:35:55.052 DEBUG: Taking gradient step
2022-12-28 20:35:55.060 DEBUG: Loss 0: {'policy_loss': 0.04064770722093668, 'entropy_loss': -0.07923285104334354, 'vf_loss': 0.029368504796042985, 'total_loss': -0.009216639026363875, 'approx_kl': -5.029141902923584e-08, 'clip_fraction': 0.0, 'grad_norm': 27.83063316345215}
2022-12-28 20:35:56.025 DEBUG: Taking gradient step
2022-12-28 20:35:56.033 DEBUG: Loss 1: {'policy_loss': -0.03703977245463708, 'entropy_loss': -0.07944192364811897, 'vf_loss': 0.024658226542538166, 'total_loss': -0.09182346956021789, 'approx_kl': -0.0005558368284255266, 'clip_fraction': 0.06901041697710752, 'grad_norm': 10.870121002197266}
2022-12-28 20:35:57.008 DEBUG: Taking gradient step
2022-12-28 20:35:57.016 DEBUG: Loss 2: {'policy_loss': -0.03458127827734582, 'entropy_loss': -0.08036663755774498, 'vf_loss': 0.02465707551731064, 'total_loss': -0.09029084031778016, 'approx_kl': 0.014740562066435814, 'clip_fraction': 0.2486979216337204, 'grad_norm': 9.035361289978027}
2022-12-28 20:35:58.004 DEBUG: Taking gradient step
2022-12-28 20:35:58.012 DEBUG: Loss 3: {'policy_loss': -0.0041034611656395915, 'entropy_loss': -0.0801357626914978, 'vf_loss': 0.02715424117294365, 'total_loss': -0.05708498268419374, 'approx_kl': 0.03194818738847971, 'clip_fraction': 0.375, 'grad_norm': 7.066147327423096}
2022-12-28 20:35:58.983 DEBUG: Taking gradient step
2022-12-28 20:35:58.990 DEBUG: Loss 4: {'policy_loss': -0.04028931236626007, 'entropy_loss': -0.07926746271550655, 'vf_loss': 0.02465219485103192, 'total_loss': -0.0949045802307347, 'approx_kl': 0.03293507965281606, 'clip_fraction': 0.3684895858168602, 'grad_norm': 6.223611831665039}
2022-12-28 20:35:59.935 DEBUG: Taking gradient step
2022-12-28 20:35:59.942 DEBUG: Loss 5: {'policy_loss': -0.01873460395445698, 'entropy_loss': -0.08055763132870197, 'vf_loss': 0.027057179534491983, 'total_loss': -0.07223505574866698, 'approx_kl': 0.015764172188937664, 'clip_fraction': 0.3372395858168602, 'grad_norm': 7.159607410430908}
2022-12-28 20:36:00.947 DEBUG: Taking gradient step
2022-12-28 20:36:00.955 DEBUG: Loss 6: {'policy_loss': -0.061123348167042, 'entropy_loss': -0.0797736756503582, 'vf_loss': 0.02220563924130186, 'total_loss': -0.11869138457609833, 'approx_kl': -0.006235787725017872, 'clip_fraction': 0.3333333358168602, 'grad_norm': 12.767014503479004}
2022-12-28 20:36:01.954 DEBUG: Taking gradient step
2022-12-28 20:36:01.966 DEBUG: Loss 7: {'policy_loss': 0.017637587438444534, 'entropy_loss': -0.07912440225481987, 'vf_loss': 0.029214354715839733, 'total_loss': -0.03227246010053561, 'approx_kl': -0.01177167915739119, 'clip_fraction': 0.30859375, 'grad_norm': 30.176340103149414}
2022-12-28 20:36:02.938 DEBUG: Taking gradient step
2022-12-28 20:36:02.945 DEBUG: Loss 8: {'policy_loss': -0.04829298376801971, 'entropy_loss': -0.07918553613126278, 'vf_loss': 0.02463607143861632, 'total_loss': -0.10284244846066617, 'approx_kl': -0.0007680291309952736, 'clip_fraction': 0.3046875, 'grad_norm': 13.060300827026367}
2022-12-28 20:36:03.929 DEBUG: Taking gradient step
2022-12-28 20:36:03.940 DEBUG: Loss 9: {'policy_loss': -0.0017906115510833084, 'entropy_loss': -0.07902608811855316, 'vf_loss': 0.02919663996596203, 'total_loss': -0.05162005970367444, 'approx_kl': 0.028369288658723235, 'clip_fraction': 0.296875, 'grad_norm': 10.216835021972656}
2022-12-28 20:36:03.941 INFO: Optimization: policy loss=-0.002, vf loss=0.029, entropy loss=-0.079, total loss=-0.052, num steps=10
2022-12-28 20:36:03.941 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:36:05.846 INFO: Evaluation rollout: return=0.949 (0.0), episode length=6.0
2022-12-28 20:36:05.848 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:36:05.850 INFO: Iteration: 87/137, steps: 18792
2022-12-28 20:36:25.126 DEBUG: Atoms are too close
2022-12-28 20:37:04.833 DEBUG: There is a single atom floating around
2022-12-28 20:37:05.735 DEBUG: There is a single atom floating around
2022-12-28 20:37:06.726 DEBUG: There is a single atom floating around
2022-12-28 20:37:07.385 INFO: Training rollout: return=-1.420 (6.3), episode length=6.0
2022-12-28 20:37:07.386 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:37:07.389 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-18792_train.pkl
2022-12-28 20:37:08.396 DEBUG: Taking gradient step
2022-12-28 20:37:08.404 DEBUG: Loss 0: {'policy_loss': -0.057743343996647836, 'entropy_loss': -0.08047151751816273, 'vf_loss': 0.03590446874520065, 'total_loss': -0.1023103927696099, 'approx_kl': 3.570069573299861e-09, 'clip_fraction': 0.0, 'grad_norm': 12.369946479797363}
2022-12-28 20:37:09.364 DEBUG: Taking gradient step
2022-12-28 20:37:09.372 DEBUG: Loss 1: {'policy_loss': -0.0024564216186087444, 'entropy_loss': -0.081022959202528, 'vf_loss': 0.04330398322726897, 'total_loss': -0.040175397593867776, 'approx_kl': 0.007470095530152321, 'clip_fraction': 0.01953125, 'grad_norm': 12.461551666259766}
2022-12-28 20:37:10.331 DEBUG: Taking gradient step
2022-12-28 20:37:10.341 DEBUG: Loss 2: {'policy_loss': -0.008690656565904257, 'entropy_loss': -0.08181948214769363, 'vf_loss': 0.04307785578543534, 'total_loss': -0.04743228292816256, 'approx_kl': 0.020926118828356266, 'clip_fraction': 0.1536458358168602, 'grad_norm': 9.865635871887207}
2022-12-28 20:37:11.327 DEBUG: Taking gradient step
2022-12-28 20:37:11.335 DEBUG: Loss 3: {'policy_loss': -0.037222004239350126, 'entropy_loss': -0.08104540035128593, 'vf_loss': 0.04058815417360064, 'total_loss': -0.07767925041703541, 'approx_kl': 0.016158236423507333, 'clip_fraction': 0.25, 'grad_norm': 7.399467945098877}
2022-12-28 20:37:12.299 DEBUG: Taking gradient step
2022-12-28 20:37:12.307 DEBUG: Loss 4: {'policy_loss': -0.0036703659795586374, 'entropy_loss': -0.0809604711830616, 'vf_loss': 0.04516255104562522, 'total_loss': -0.039468286116995016, 'approx_kl': 0.018273424357175827, 'clip_fraction': 0.2903645858168602, 'grad_norm': 10.506930351257324}
2022-12-28 20:37:13.311 DEBUG: Taking gradient step
2022-12-28 20:37:13.319 DEBUG: Loss 5: {'policy_loss': 0.014973476751644663, 'entropy_loss': -0.08125089667737484, 'vf_loss': 0.04740436105345171, 'total_loss': -0.01887305887227847, 'approx_kl': 0.015102331759408116, 'clip_fraction': 0.3268229216337204, 'grad_norm': 7.706354141235352}
2022-12-28 20:37:14.414 DEBUG: Taking gradient step
2022-12-28 20:37:14.422 DEBUG: Loss 6: {'policy_loss': -0.03938357960442476, 'entropy_loss': -0.08000027947127819, 'vf_loss': 0.04238672471890049, 'total_loss': -0.07699713435680247, 'approx_kl': -0.008858873508870602, 'clip_fraction': 0.3684895858168602, 'grad_norm': 4.3482842445373535}
2022-12-28 20:37:15.399 DEBUG: Taking gradient step
2022-12-28 20:37:15.407 DEBUG: Loss 7: {'policy_loss': -0.0756236218449383, 'entropy_loss': -0.08024060167372227, 'vf_loss': 0.03739855463368965, 'total_loss': -0.11846566888497091, 'approx_kl': -0.005696344189345837, 'clip_fraction': 0.3984375, 'grad_norm': 5.514966011047363}
2022-12-28 20:37:16.371 DEBUG: Taking gradient step
2022-12-28 20:37:16.379 DEBUG: Loss 8: {'policy_loss': -0.06226064018752089, 'entropy_loss': -0.08071460574865341, 'vf_loss': 0.03954304939140005, 'total_loss': -0.10343219654477424, 'approx_kl': 0.00339322816580534, 'clip_fraction': 0.4036458358168602, 'grad_norm': 7.461084842681885}
2022-12-28 20:37:17.358 DEBUG: Taking gradient step
2022-12-28 20:37:17.366 DEBUG: Loss 9: {'policy_loss': -0.05052507111962501, 'entropy_loss': -0.0805448442697525, 'vf_loss': 0.04166025653576715, 'total_loss': -0.08940965885361035, 'approx_kl': 0.001761475345119834, 'clip_fraction': 0.4700520932674408, 'grad_norm': 4.618474960327148}
2022-12-28 20:37:17.366 INFO: Optimization: policy loss=-0.051, vf loss=0.042, entropy loss=-0.081, total loss=-0.089, num steps=10
2022-12-28 20:37:17.366 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:37:19.186 INFO: Evaluation rollout: return=1.001 (0.0), episode length=6.0
2022-12-28 20:37:19.187 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:37:19.189 INFO: Iteration: 88/137, steps: 19008
2022-12-28 20:37:38.811 DEBUG: There is a single atom floating around
2022-12-28 20:38:21.695 INFO: Training rollout: return=0.258 (3.3), episode length=6.0
2022-12-28 20:38:21.697 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:38:21.699 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-19008_train.pkl
2022-12-28 20:38:22.725 DEBUG: Taking gradient step
2022-12-28 20:38:22.732 DEBUG: Loss 0: {'policy_loss': -0.026874972433143615, 'entropy_loss': -0.08371510915458202, 'vf_loss': 0.010254011211797656, 'total_loss': -0.10033607037592798, 'approx_kl': -6.527019280611057e-08, 'clip_fraction': 0.0, 'grad_norm': 12.050399780273438}
2022-12-28 20:38:23.714 DEBUG: Taking gradient step
2022-12-28 20:38:23.721 DEBUG: Loss 1: {'policy_loss': -0.036129775579167744, 'entropy_loss': -0.08501657098531723, 'vf_loss': 0.010437451429229761, 'total_loss': -0.11070889513525521, 'approx_kl': -0.00022757076658308506, 'clip_fraction': 0.05859375, 'grad_norm': 9.903291702270508}
2022-12-28 20:38:24.689 DEBUG: Taking gradient step
2022-12-28 20:38:24.697 DEBUG: Loss 2: {'policy_loss': -0.013906403711291707, 'entropy_loss': -0.08488059975206852, 'vf_loss': 0.012632111002249875, 'total_loss': -0.08615489246111036, 'approx_kl': 0.012464457075111568, 'clip_fraction': 0.1966145858168602, 'grad_norm': 7.57579231262207}
2022-12-28 20:38:25.700 DEBUG: Taking gradient step
2022-12-28 20:38:25.709 DEBUG: Loss 3: {'policy_loss': -0.04887590676855983, 'entropy_loss': -0.08495526760816574, 'vf_loss': 0.010736028168917354, 'total_loss': -0.12309514620780823, 'approx_kl': 0.013372532790526748, 'clip_fraction': 0.2252604179084301, 'grad_norm': 6.08303165435791}
2022-12-28 20:38:26.711 DEBUG: Taking gradient step
2022-12-28 20:38:26.721 DEBUG: Loss 4: {'policy_loss': -0.043361461580965314, 'entropy_loss': -0.08437597565352917, 'vf_loss': 0.010678471637165858, 'total_loss': -0.11705896559732862, 'approx_kl': 0.026935303583741188, 'clip_fraction': 0.29296875, 'grad_norm': 3.9366555213928223}
2022-12-28 20:38:27.746 DEBUG: Taking gradient step
2022-12-28 20:38:27.757 DEBUG: Loss 5: {'policy_loss': -0.04336664330841442, 'entropy_loss': -0.08371098898351192, 'vf_loss': 0.01057531684209421, 'total_loss': -0.11650231544983214, 'approx_kl': 0.0253766558598727, 'clip_fraction': 0.2877604216337204, 'grad_norm': 3.8621726036071777}
2022-12-28 20:38:28.732 DEBUG: Taking gradient step
2022-12-28 20:38:28.744 DEBUG: Loss 6: {'policy_loss': -0.01428156081885995, 'entropy_loss': -0.08513198792934418, 'vf_loss': 0.012864446187651835, 'total_loss': -0.08654910256055229, 'approx_kl': -0.007166717667132616, 'clip_fraction': 0.2721354216337204, 'grad_norm': 3.9134654998779297}
2022-12-28 20:38:29.776 DEBUG: Taking gradient step
2022-12-28 20:38:29.784 DEBUG: Loss 7: {'policy_loss': -0.017145512626467175, 'entropy_loss': -0.0854803342372179, 'vf_loss': 0.012675915412374186, 'total_loss': -0.0899499314513109, 'approx_kl': -0.01519098924472928, 'clip_fraction': 0.2864583358168602, 'grad_norm': 4.18721342086792}
2022-12-28 20:38:30.765 DEBUG: Taking gradient step
2022-12-28 20:38:30.774 DEBUG: Loss 8: {'policy_loss': -0.046733187765167924, 'entropy_loss': -0.08381303399801254, 'vf_loss': 0.010035319040799939, 'total_loss': -0.12051090272238052, 'approx_kl': -0.01655288808979094, 'clip_fraction': 0.3359375, 'grad_norm': 3.484919548034668}
2022-12-28 20:38:31.745 DEBUG: Taking gradient step
2022-12-28 20:38:31.753 DEBUG: Loss 9: {'policy_loss': -0.060787543292286986, 'entropy_loss': -0.08526943065226078, 'vf_loss': 0.00989329323888882, 'total_loss': -0.13616368070565893, 'approx_kl': -0.043366486905142665, 'clip_fraction': 0.4375, 'grad_norm': 2.5755345821380615}
2022-12-28 20:38:31.753 INFO: Optimization: policy loss=-0.061, vf loss=0.010, entropy loss=-0.085, total loss=-0.136, num steps=10
2022-12-28 20:38:31.754 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:38:33.496 INFO: Evaluation rollout: return=0.943 (0.0), episode length=6.0
2022-12-28 20:38:33.497 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:38:33.500 INFO: Iteration: 89/137, steps: 19224
2022-12-28 20:39:34.764 DEBUG: There is a single atom floating around
2022-12-28 20:39:35.657 INFO: Training rollout: return=0.251 (3.3), episode length=6.0
2022-12-28 20:39:35.658 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:39:35.661 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-19224_train.pkl
2022-12-28 20:39:36.679 DEBUG: Taking gradient step
2022-12-28 20:39:36.690 DEBUG: Loss 0: {'policy_loss': -0.02778698714946897, 'entropy_loss': -0.08370396867394447, 'vf_loss': 0.009804664396415726, 'total_loss': -0.10168629142699771, 'approx_kl': -4.819594323635101e-08, 'clip_fraction': 0.0, 'grad_norm': 10.82884407043457}
2022-12-28 20:39:37.758 DEBUG: Taking gradient step
2022-12-28 20:39:37.770 DEBUG: Loss 1: {'policy_loss': -0.03553705200432892, 'entropy_loss': -0.0845537930727005, 'vf_loss': 0.009663409516046625, 'total_loss': -0.11042743556098279, 'approx_kl': -0.006352162454277277, 'clip_fraction': 0.01953125, 'grad_norm': 9.759066581726074}
2022-12-28 20:39:38.756 DEBUG: Taking gradient step
2022-12-28 20:39:38.764 DEBUG: Loss 2: {'policy_loss': -0.042150385699303586, 'entropy_loss': -0.08434656262397766, 'vf_loss': 0.009595579213165657, 'total_loss': -0.11690136911011559, 'approx_kl': -0.019470686791464686, 'clip_fraction': 0.1588541716337204, 'grad_norm': 7.7381486892700195}
2022-12-28 20:39:39.716 DEBUG: Taking gradient step
2022-12-28 20:39:39.728 DEBUG: Loss 3: {'policy_loss': 0.021355660617168808, 'entropy_loss': -0.08399314619600773, 'vf_loss': 0.014349428151755687, 'total_loss': -0.04828805742708323, 'approx_kl': -0.022443445399403572, 'clip_fraction': 0.296875, 'grad_norm': 3.831465244293213}
2022-12-28 20:39:40.694 DEBUG: Taking gradient step
2022-12-28 20:39:40.702 DEBUG: Loss 4: {'policy_loss': -0.04914005677468898, 'entropy_loss': -0.08409562520682812, 'vf_loss': 0.009449102462634478, 'total_loss': -0.12378657951888261, 'approx_kl': -0.02687716274522245, 'clip_fraction': 0.3997395858168602, 'grad_norm': 3.3665618896484375}
2022-12-28 20:39:41.665 DEBUG: Taking gradient step
2022-12-28 20:39:41.673 DEBUG: Loss 5: {'policy_loss': -0.044296093979454915, 'entropy_loss': -0.08417680114507675, 'vf_loss': 0.009386779692690996, 'total_loss': -0.11908611543184067, 'approx_kl': -0.037000845884904265, 'clip_fraction': 0.4375, 'grad_norm': 3.171576499938965}
2022-12-28 20:39:42.647 DEBUG: Taking gradient step
2022-12-28 20:39:42.655 DEBUG: Loss 6: {'policy_loss': 0.025858746506478007, 'entropy_loss': -0.0828235037624836, 'vf_loss': 0.014159533188537137, 'total_loss': -0.04280522406746845, 'approx_kl': -0.010018202941864729, 'clip_fraction': 0.4544270858168602, 'grad_norm': 3.415922164916992}
2022-12-28 20:39:43.614 DEBUG: Taking gradient step
2022-12-28 20:39:43.621 DEBUG: Loss 7: {'policy_loss': -0.05354113060475976, 'entropy_loss': -0.0850200206041336, 'vf_loss': 0.009385021812770665, 'total_loss': -0.12917612939612272, 'approx_kl': -0.018867101287469268, 'clip_fraction': 0.4609375, 'grad_norm': 3.4753262996673584}
2022-12-28 20:39:44.586 DEBUG: Taking gradient step
2022-12-28 20:39:44.594 DEBUG: Loss 8: {'policy_loss': 0.02050843350386091, 'entropy_loss': -0.08454571850597858, 'vf_loss': 0.014169191805061753, 'total_loss': -0.04986809319705591, 'approx_kl': -0.020148849114775658, 'clip_fraction': 0.42578125, 'grad_norm': 2.811006546020508}
2022-12-28 20:39:45.652 DEBUG: Taking gradient step
2022-12-28 20:39:45.660 DEBUG: Loss 9: {'policy_loss': -0.01742236153138388, 'entropy_loss': -0.08383720368146896, 'vf_loss': 0.011727535830172307, 'total_loss': -0.08953202938268054, 'approx_kl': -0.06272436724975705, 'clip_fraction': 0.3919270858168602, 'grad_norm': 5.4690165519714355}
2022-12-28 20:39:45.660 INFO: Optimization: policy loss=-0.017, vf loss=0.012, entropy loss=-0.084, total loss=-0.090, num steps=10
2022-12-28 20:39:45.660 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:39:47.428 INFO: Evaluation rollout: return=0.990 (0.0), episode length=6.0
2022-12-28 20:39:47.429 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:39:47.432 INFO: Iteration: 90/137, steps: 19440
2022-12-28 20:40:05.310 DEBUG: There is a single atom floating around
2022-12-28 20:40:49.553 INFO: Training rollout: return=0.240 (3.3), episode length=6.0
2022-12-28 20:40:49.555 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:40:49.558 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-19440_train.pkl
2022-12-28 20:40:50.565 DEBUG: Taking gradient step
2022-12-28 20:40:50.574 DEBUG: Loss 0: {'policy_loss': 0.04837935869483151, 'entropy_loss': -0.08119296841323376, 'vf_loss': 0.01415802952664026, 'total_loss': -0.018655580191762, 'approx_kl': -6.371798733084688e-08, 'clip_fraction': 0.0, 'grad_norm': 30.542102813720703}
2022-12-28 20:40:51.533 DEBUG: Taking gradient step
2022-12-28 20:40:51.540 DEBUG: Loss 1: {'policy_loss': -0.042215179461026375, 'entropy_loss': -0.08144461363554001, 'vf_loss': 0.009308790858237718, 'total_loss': -0.11435100223832867, 'approx_kl': -0.006311524659395218, 'clip_fraction': 0.1393229179084301, 'grad_norm': 7.566035747528076}
2022-12-28 20:40:52.570 DEBUG: Taking gradient step
2022-12-28 20:40:52.578 DEBUG: Loss 2: {'policy_loss': -0.011596767791168064, 'entropy_loss': -0.08170774951577187, 'vf_loss': 0.011707056078381923, 'total_loss': -0.081597461228558, 'approx_kl': 0.02347458922304213, 'clip_fraction': 0.296875, 'grad_norm': 9.196859359741211}
2022-12-28 20:40:53.558 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-28 20:40:53.558 INFO: Optimization: policy loss=-0.012, vf loss=0.012, entropy loss=-0.082, total loss=-0.082, num steps=3
2022-12-28 20:40:53.559 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:40:55.401 INFO: Evaluation rollout: return=0.943 (0.0), episode length=6.0
2022-12-28 20:40:55.402 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:40:55.406 DEBUG: Deleting old model: runs/CH3NO_painn/models/CH3NO_painn_run-1_steps-17496.model
2022-12-28 20:40:55.410 DEBUG: Saving model: runs/CH3NO_painn/models/CH3NO_painn_run-1_steps-19656.model
2022-12-28 20:40:55.435 INFO: Iteration: 91/137, steps: 19656
2022-12-28 20:41:12.704 DEBUG: There is a single atom floating around
2022-12-28 20:41:56.506 DEBUG: Atoms are too close
2022-12-28 20:41:57.199 INFO: Training rollout: return=-0.290 (4.6), episode length=6.0
2022-12-28 20:41:57.200 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:41:57.203 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-19656_train.pkl
2022-12-28 20:41:58.194 DEBUG: Taking gradient step
2022-12-28 20:41:58.206 DEBUG: Loss 0: {'policy_loss': 0.04942973476374457, 'entropy_loss': -0.0814930908381939, 'vf_loss': 0.025416605716110513, 'total_loss': -0.006646750358338824, 'approx_kl': -4.190951585769653e-08, 'clip_fraction': 0.0, 'grad_norm': 20.142732620239258}
2022-12-28 20:41:59.261 DEBUG: Taking gradient step
2022-12-28 20:41:59.270 DEBUG: Loss 1: {'policy_loss': -0.015636094384464738, 'entropy_loss': -0.08056635595858097, 'vf_loss': 0.02040443102694932, 'total_loss': -0.0757980193160964, 'approx_kl': 0.008179484866559505, 'clip_fraction': 0.08723958395421505, 'grad_norm': 15.015853881835938}
2022-12-28 20:42:00.272 DEBUG: Taking gradient step
2022-12-28 20:42:00.280 DEBUG: Loss 2: {'policy_loss': -0.04885870286701127, 'entropy_loss': -0.0808250829577446, 'vf_loss': 0.018029311468222738, 'total_loss': -0.11165447435653314, 'approx_kl': 0.020806217566132545, 'clip_fraction': 0.16015625, 'grad_norm': 10.845771789550781}
2022-12-28 20:42:01.237 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-28 20:42:01.237 INFO: Optimization: policy loss=-0.049, vf loss=0.018, entropy loss=-0.081, total loss=-0.112, num steps=3
2022-12-28 20:42:01.238 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:42:03.117 INFO: Evaluation rollout: return=0.927 (0.0), episode length=6.0
2022-12-28 20:42:03.118 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:42:03.121 INFO: Iteration: 92/137, steps: 19872
2022-12-28 20:42:22.336 DEBUG: Atoms are too close
2022-12-28 20:43:05.109 INFO: Training rollout: return=0.274 (3.3), episode length=6.0
2022-12-28 20:43:05.111 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:43:05.113 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-19872_train.pkl
2022-12-28 20:43:06.095 DEBUG: Taking gradient step
2022-12-28 20:43:06.103 DEBUG: Loss 0: {'policy_loss': 0.021040318447510184, 'entropy_loss': -0.08410663343966007, 'vf_loss': 0.011501724130798734, 'total_loss': -0.051564590861351164, 'approx_kl': -1.6453364892754507e-08, 'clip_fraction': 0.0, 'grad_norm': 22.26279640197754}
2022-12-28 20:43:07.078 DEBUG: Taking gradient step
2022-12-28 20:43:07.086 DEBUG: Loss 1: {'policy_loss': 0.014681228716142473, 'entropy_loss': -0.08290290273725986, 'vf_loss': 0.011594281848501087, 'total_loss': -0.056627392172616295, 'approx_kl': 0.004183938377536833, 'clip_fraction': 0.01171875, 'grad_norm': 22.1356201171875}
2022-12-28 20:43:08.077 DEBUG: Taking gradient step
2022-12-28 20:43:08.085 DEBUG: Loss 2: {'policy_loss': -0.004294336005207126, 'entropy_loss': -0.08277513831853867, 'vf_loss': 0.0115100343115089, 'total_loss': -0.07555944001223688, 'approx_kl': 0.018921986920759082, 'clip_fraction': 0.1119791679084301, 'grad_norm': 16.183401107788086}
2022-12-28 20:43:09.110 DEBUG: Taking gradient step
2022-12-28 20:43:09.118 DEBUG: Loss 3: {'policy_loss': -0.008988843986865861, 'entropy_loss': -0.08288881182670593, 'vf_loss': 0.011485885591558229, 'total_loss': -0.08039177022201356, 'approx_kl': 0.028077490162104368, 'clip_fraction': 0.2747395858168602, 'grad_norm': 3.888000726699829}
2022-12-28 20:43:10.071 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-28 20:43:10.072 INFO: Optimization: policy loss=-0.009, vf loss=0.011, entropy loss=-0.083, total loss=-0.080, num steps=4
2022-12-28 20:43:10.072 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:43:11.974 INFO: Evaluation rollout: return=0.902 (0.0), episode length=6.0
2022-12-28 20:43:11.975 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:43:11.977 INFO: Iteration: 93/137, steps: 20088
2022-12-28 20:44:15.340 INFO: Training rollout: return=0.855 (0.1), episode length=6.0
2022-12-28 20:44:15.341 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:44:15.344 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-20088_train.pkl
2022-12-28 20:44:16.333 DEBUG: Taking gradient step
2022-12-28 20:44:16.341 DEBUG: Loss 0: {'policy_loss': -0.010806996572150583, 'entropy_loss': -0.08248088508844376, 'vf_loss': 0.0005335007205713797, 'total_loss': -0.09275438094002295, 'approx_kl': 2.6387471763200665e-08, 'clip_fraction': 0.0, 'grad_norm': 12.927797317504883}
2022-12-28 20:44:17.297 DEBUG: Taking gradient step
2022-12-28 20:44:17.305 DEBUG: Loss 1: {'policy_loss': -0.025400117074743517, 'entropy_loss': -0.08359152637422085, 'vf_loss': 0.000536367279595703, 'total_loss': -0.10845527616936868, 'approx_kl': 0.033583336509764194, 'clip_fraction': 0.09505208395421505, 'grad_norm': 9.54664134979248}
2022-12-28 20:44:18.333 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-28 20:44:18.334 INFO: Optimization: policy loss=-0.025, vf loss=0.001, entropy loss=-0.084, total loss=-0.108, num steps=2
2022-12-28 20:44:18.334 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:44:20.196 INFO: Evaluation rollout: return=0.877 (0.0), episode length=6.0
2022-12-28 20:44:20.198 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:44:20.200 INFO: Iteration: 94/137, steps: 20304
2022-12-28 20:45:23.514 INFO: Training rollout: return=0.811 (0.1), episode length=6.0
2022-12-28 20:45:23.516 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:45:23.518 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-20304_train.pkl
2022-12-28 20:45:24.561 DEBUG: Taking gradient step
2022-12-28 20:45:24.569 DEBUG: Loss 0: {'policy_loss': -0.0026492896806545006, 'entropy_loss': -0.08388183265924454, 'vf_loss': 0.0004421827290380552, 'total_loss': -0.08608893961086098, 'approx_kl': 6.930592189036133e-08, 'clip_fraction': 0.0, 'grad_norm': 20.80218505859375}
2022-12-28 20:45:25.537 DEBUG: Taking gradient step
2022-12-28 20:45:25.545 DEBUG: Loss 1: {'policy_loss': 0.015876881145182084, 'entropy_loss': -0.08302280306816101, 'vf_loss': 0.00044084026220041396, 'total_loss': -0.06670508166077851, 'approx_kl': 0.01689855692529818, 'clip_fraction': 0.02734375, 'grad_norm': 20.298494338989258}
2022-12-28 20:45:26.542 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-28 20:45:26.542 INFO: Optimization: policy loss=0.016, vf loss=0.000, entropy loss=-0.083, total loss=-0.067, num steps=2
2022-12-28 20:45:26.543 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:45:28.276 INFO: Evaluation rollout: return=0.871 (0.0), episode length=6.0
2022-12-28 20:45:28.277 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:45:28.280 INFO: Iteration: 95/137, steps: 20520
2022-12-28 20:46:08.838 DEBUG: Atoms are too close
2022-12-28 20:46:30.486 DEBUG: Atoms are too close
2022-12-28 20:46:30.535 INFO: Training rollout: return=-0.345 (4.6), episode length=6.0
2022-12-28 20:46:30.536 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:46:30.538 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-20520_train.pkl
2022-12-28 20:46:31.529 DEBUG: Taking gradient step
2022-12-28 20:46:31.537 DEBUG: Loss 0: {'policy_loss': 0.04533929150701825, 'entropy_loss': -0.08332554623484612, 'vf_loss': 0.02547102612281004, 'total_loss': -0.01251522860501783, 'approx_kl': 7.528190792971401e-09, 'clip_fraction': 0.0, 'grad_norm': 20.699121475219727}
2022-12-28 20:46:32.549 DEBUG: Taking gradient step
2022-12-28 20:46:32.557 DEBUG: Loss 1: {'policy_loss': -0.0399489248878062, 'entropy_loss': -0.08463035523891449, 'vf_loss': 0.018173677668794998, 'total_loss': -0.10640560245792567, 'approx_kl': -0.00013137725181877613, 'clip_fraction': 0.057291666977107525, 'grad_norm': 12.032029151916504}
2022-12-28 20:46:33.516 DEBUG: Taking gradient step
2022-12-28 20:46:33.524 DEBUG: Loss 2: {'policy_loss': -0.0196937241425677, 'entropy_loss': -0.08420521579682827, 'vf_loss': 0.020473944363772294, 'total_loss': -0.08342499557562368, 'approx_kl': 0.009534748503938317, 'clip_fraction': 0.2317708358168602, 'grad_norm': 10.60118579864502}
2022-12-28 20:46:34.561 DEBUG: Taking gradient step
2022-12-28 20:46:34.573 DEBUG: Loss 3: {'policy_loss': -0.017084616681439256, 'entropy_loss': -0.08370966650545597, 'vf_loss': 0.02050930467654517, 'total_loss': -0.08028497851035006, 'approx_kl': 0.02784530585631728, 'clip_fraction': 0.30859375, 'grad_norm': 9.915228843688965}
2022-12-28 20:46:35.563 DEBUG: Taking gradient step
2022-12-28 20:46:35.571 DEBUG: Loss 4: {'policy_loss': -0.03299021087979603, 'entropy_loss': -0.0840926244854927, 'vf_loss': 0.020725336135784183, 'total_loss': -0.09635749922950455, 'approx_kl': 0.015547433868050575, 'clip_fraction': 0.3098958358168602, 'grad_norm': 5.97468900680542}
2022-12-28 20:46:36.531 DEBUG: Taking gradient step
2022-12-28 20:46:36.539 DEBUG: Loss 5: {'policy_loss': -0.017392724138239987, 'entropy_loss': -0.08357912674546242, 'vf_loss': 0.023317851174591106, 'total_loss': -0.07765399970911128, 'approx_kl': 0.026887540705502033, 'clip_fraction': 0.3033854216337204, 'grad_norm': 5.426780700683594}
2022-12-28 20:46:37.520 DEBUG: Taking gradient step
2022-12-28 20:46:37.528 DEBUG: Loss 6: {'policy_loss': 0.017544029134580065, 'entropy_loss': -0.08344202302396297, 'vf_loss': 0.025117151161678796, 'total_loss': -0.04078084272770412, 'approx_kl': 0.007042330922558904, 'clip_fraction': 0.3489583358168602, 'grad_norm': 8.581768989562988}
2022-12-28 20:46:38.527 DEBUG: Taking gradient step
2022-12-28 20:46:38.534 DEBUG: Loss 7: {'policy_loss': -0.015595481610535323, 'entropy_loss': -0.08404822647571564, 'vf_loss': 0.022996725515080488, 'total_loss': -0.07664698257117047, 'approx_kl': 0.00734397117048502, 'clip_fraction': 0.3958333358168602, 'grad_norm': 7.9155659675598145}
2022-12-28 20:46:39.528 DEBUG: Taking gradient step
2022-12-28 20:46:39.535 DEBUG: Loss 8: {'policy_loss': -0.05917696678519016, 'entropy_loss': -0.08366961218416691, 'vf_loss': 0.01797653352081395, 'total_loss': -0.12487004544854312, 'approx_kl': 0.022572212386876345, 'clip_fraction': 0.43359375, 'grad_norm': 4.013369083404541}
2022-12-28 20:46:40.505 DEBUG: Taking gradient step
2022-12-28 20:46:40.517 DEBUG: Loss 9: {'policy_loss': -0.036420543871630795, 'entropy_loss': -0.08497265353798866, 'vf_loss': 0.020255818406223005, 'total_loss': -0.10113737900339645, 'approx_kl': -0.006048098439350724, 'clip_fraction': 0.4375, 'grad_norm': 4.107126712799072}
2022-12-28 20:46:40.517 INFO: Optimization: policy loss=-0.036, vf loss=0.020, entropy loss=-0.085, total loss=-0.101, num steps=10
2022-12-28 20:46:40.518 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:46:42.425 INFO: Evaluation rollout: return=0.917 (0.0), episode length=6.0
2022-12-28 20:46:42.426 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:46:42.428 INFO: Iteration: 96/137, steps: 20736
2022-12-28 20:47:44.287 INFO: Training rollout: return=0.827 (0.1), episode length=6.0
2022-12-28 20:47:44.289 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:47:44.291 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-20736_train.pkl
2022-12-28 20:47:45.283 DEBUG: Taking gradient step
2022-12-28 20:47:45.293 DEBUG: Loss 0: {'policy_loss': -0.03515103298039968, 'entropy_loss': -0.08348903618752956, 'vf_loss': 0.0005750255687539977, 'total_loss': -0.11806504359917525, 'approx_kl': -1.234002411365509e-08, 'clip_fraction': 0.0, 'grad_norm': 15.343443870544434}
2022-12-28 20:47:46.271 DEBUG: Taking gradient step
2022-12-28 20:47:46.282 DEBUG: Loss 1: {'policy_loss': -0.03918844897448995, 'entropy_loss': -0.08383477665483952, 'vf_loss': 0.000602046390328349, 'total_loss': -0.12242117923900112, 'approx_kl': 0.00930424826219678, 'clip_fraction': 0.00390625, 'grad_norm': 20.595645904541016}
2022-12-28 20:47:47.246 DEBUG: Taking gradient step
2022-12-28 20:47:47.257 DEBUG: Loss 2: {'policy_loss': -0.04023559249759576, 'entropy_loss': -0.08376632072031498, 'vf_loss': 0.0006152825064077908, 'total_loss': -0.12338663071150294, 'approx_kl': 0.01655912888236344, 'clip_fraction': 0.14453125, 'grad_norm': 11.134820938110352}
2022-12-28 20:47:48.273 DEBUG: Taking gradient step
2022-12-28 20:47:48.280 DEBUG: Loss 3: {'policy_loss': -0.02907021039830123, 'entropy_loss': -0.08475355617702007, 'vf_loss': 0.00062261636883048, 'total_loss': -0.11320115020649082, 'approx_kl': 0.038948304019868374, 'clip_fraction': 0.2903645858168602, 'grad_norm': 11.136675834655762}
2022-12-28 20:47:49.281 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-28 20:47:49.281 INFO: Optimization: policy loss=-0.029, vf loss=0.001, entropy loss=-0.085, total loss=-0.113, num steps=4
2022-12-28 20:47:49.282 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:47:51.027 INFO: Evaluation rollout: return=0.957 (0.0), episode length=6.0
2022-12-28 20:47:51.028 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:47:51.031 INFO: Iteration: 97/137, steps: 20952
2022-12-28 20:48:54.180 INFO: Training rollout: return=0.816 (0.1), episode length=6.0
2022-12-28 20:48:54.182 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:48:54.184 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-20952_train.pkl
2022-12-28 20:48:55.188 DEBUG: Taking gradient step
2022-12-28 20:48:55.196 DEBUG: Loss 0: {'policy_loss': 0.012166757571086404, 'entropy_loss': -0.08339750207960606, 'vf_loss': 0.000648001115864978, 'total_loss': -0.07058274339265468, 'approx_kl': 8.76995187581997e-09, 'clip_fraction': 0.0, 'grad_norm': 26.05074691772461}
2022-12-28 20:48:56.159 DEBUG: Taking gradient step
2022-12-28 20:48:56.168 DEBUG: Loss 1: {'policy_loss': 0.029208168946363237, 'entropy_loss': -0.08460164442658424, 'vf_loss': 0.0006531247167968761, 'total_loss': -0.054740350763424116, 'approx_kl': 0.0033553384710103273, 'clip_fraction': 0.0, 'grad_norm': 28.53522300720215}
2022-12-28 20:48:57.167 DEBUG: Taking gradient step
2022-12-28 20:48:57.175 DEBUG: Loss 2: {'policy_loss': -0.03627353315033452, 'entropy_loss': -0.08331541158258915, 'vf_loss': 0.0006811628541797056, 'total_loss': -0.11890778187874397, 'approx_kl': 0.02594307088293135, 'clip_fraction': 0.23046875, 'grad_norm': 15.140467643737793}
2022-12-28 20:48:58.168 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-28 20:48:58.169 INFO: Optimization: policy loss=-0.036, vf loss=0.001, entropy loss=-0.083, total loss=-0.119, num steps=3
2022-12-28 20:48:58.169 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:48:59.982 INFO: Evaluation rollout: return=0.913 (0.0), episode length=6.0
2022-12-28 20:48:59.984 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:48:59.987 INFO: Iteration: 98/137, steps: 21168
2022-12-28 20:49:26.090 DEBUG: There is a single atom floating around
2022-12-28 20:50:02.770 INFO: Training rollout: return=0.246 (3.4), episode length=5.9
2022-12-28 20:50:02.771 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:50:02.774 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-21168_train.pkl
2022-12-28 20:50:03.770 DEBUG: Taking gradient step
2022-12-28 20:50:03.778 DEBUG: Loss 0: {'policy_loss': -0.01658819484445468, 'entropy_loss': -0.08352997899055481, 'vf_loss': 0.0037695270650359965, 'total_loss': -0.0963486467699735, 'approx_kl': -1.2184806053028296e-08, 'clip_fraction': 0.0, 'grad_norm': 8.115950584411621}
2022-12-28 20:50:04.767 DEBUG: Taking gradient step
2022-12-28 20:50:04.775 DEBUG: Loss 1: {'policy_loss': -0.018121542385383015, 'entropy_loss': -0.08352486230432987, 'vf_loss': 0.0037608165917037686, 'total_loss': -0.09788558809800912, 'approx_kl': 0.002477023983374238, 'clip_fraction': 0.07942708395421505, 'grad_norm': 7.247685432434082}
2022-12-28 20:50:05.728 DEBUG: Taking gradient step
2022-12-28 20:50:05.735 DEBUG: Loss 2: {'policy_loss': -0.027670545786318355, 'entropy_loss': -0.08333617076277733, 'vf_loss': 0.0037788580308614024, 'total_loss': -0.10722785851823427, 'approx_kl': 0.022681189933791757, 'clip_fraction': 0.25, 'grad_norm': 2.777663469314575}
2022-12-28 20:50:06.797 DEBUG: Taking gradient step
2022-12-28 20:50:06.805 DEBUG: Loss 3: {'policy_loss': -0.018642905864237447, 'entropy_loss': -0.0841991025954485, 'vf_loss': 0.003738287509369284, 'total_loss': -0.09910372095031665, 'approx_kl': 0.04355122521519661, 'clip_fraction': 0.3203125, 'grad_norm': 2.210749864578247}
2022-12-28 20:50:07.752 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-28 20:50:07.752 INFO: Optimization: policy loss=-0.019, vf loss=0.004, entropy loss=-0.084, total loss=-0.099, num steps=4
2022-12-28 20:50:07.753 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:50:09.595 INFO: Evaluation rollout: return=0.997 (0.0), episode length=6.0
2022-12-28 20:50:09.596 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:50:09.598 INFO: Iteration: 99/137, steps: 21384
2022-12-28 20:51:11.439 INFO: Training rollout: return=0.833 (0.1), episode length=6.0
2022-12-28 20:51:11.442 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:51:11.444 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-21384_train.pkl
2022-12-28 20:51:12.445 DEBUG: Taking gradient step
2022-12-28 20:51:12.453 DEBUG: Loss 0: {'policy_loss': 0.00506494839342779, 'entropy_loss': -0.08480439707636833, 'vf_loss': 0.0006376608788897011, 'total_loss': -0.07910178780405085, 'approx_kl': 6.045835743151429e-08, 'clip_fraction': 0.0, 'grad_norm': 11.961976051330566}
2022-12-28 20:51:13.484 DEBUG: Taking gradient step
2022-12-28 20:51:13.492 DEBUG: Loss 1: {'policy_loss': -0.0014648313541683698, 'entropy_loss': -0.0845192763954401, 'vf_loss': 0.0006101665980070066, 'total_loss': -0.08537394115160148, 'approx_kl': -0.002005567541345954, 'clip_fraction': 0.04817708395421505, 'grad_norm': 15.882087707519531}
2022-12-28 20:51:14.479 DEBUG: Taking gradient step
2022-12-28 20:51:14.487 DEBUG: Loss 2: {'policy_loss': -0.023977680482107883, 'entropy_loss': -0.0844537504017353, 'vf_loss': 0.0005959104512050123, 'total_loss': -0.10783552043263818, 'approx_kl': 0.013014961266890168, 'clip_fraction': 0.23828125, 'grad_norm': 11.435583114624023}
2022-12-28 20:51:15.474 DEBUG: Taking gradient step
2022-12-28 20:51:15.481 DEBUG: Loss 3: {'policy_loss': -0.0006645692242068513, 'entropy_loss': -0.08480441384017467, 'vf_loss': 0.0005585410294650413, 'total_loss': -0.08491044203491648, 'approx_kl': 0.021532552083954215, 'clip_fraction': 0.3671875, 'grad_norm': 9.84867000579834}
2022-12-28 20:51:16.467 DEBUG: Taking gradient step
2022-12-28 20:51:16.474 DEBUG: Loss 4: {'policy_loss': -0.07899687370518514, 'entropy_loss': -0.08364629931747913, 'vf_loss': 0.0005641555632683014, 'total_loss': -0.16207901745939599, 'approx_kl': 0.028480784967541695, 'clip_fraction': 0.4075520858168602, 'grad_norm': 11.384793281555176}
2022-12-28 20:51:17.447 DEBUG: Taking gradient step
2022-12-28 20:51:17.455 DEBUG: Loss 5: {'policy_loss': -0.01395178858103049, 'entropy_loss': -0.0842326171696186, 'vf_loss': 0.0005114314080298955, 'total_loss': -0.0976729743426192, 'approx_kl': 0.038908973801881075, 'clip_fraction': 0.4309895858168602, 'grad_norm': 9.662821769714355}
2022-12-28 20:51:18.410 DEBUG: Taking gradient step
2022-12-28 20:51:18.418 DEBUG: Loss 6: {'policy_loss': -0.06647208022143611, 'entropy_loss': -0.08444463647902012, 'vf_loss': 0.0005039280315768666, 'total_loss': -0.15041278866887936, 'approx_kl': 0.02824082807637751, 'clip_fraction': 0.4140625, 'grad_norm': 11.687540054321289}
2022-12-28 20:51:19.385 DEBUG: Taking gradient step
2022-12-28 20:51:19.393 DEBUG: Loss 7: {'policy_loss': 0.013088588634364046, 'entropy_loss': -0.08443751186132431, 'vf_loss': 0.00045466899998046343, 'total_loss': -0.07089425422697979, 'approx_kl': 0.044994003139436245, 'clip_fraction': 0.37109375, 'grad_norm': 11.24979019165039}
2022-12-28 20:51:20.354 DEBUG: Taking gradient step
2022-12-28 20:51:20.365 DEBUG: Loss 8: {'policy_loss': -0.057505039147680875, 'entropy_loss': -0.08420198410749435, 'vf_loss': 0.0004537475237409603, 'total_loss': -0.14125327573143426, 'approx_kl': 0.032689639599993825, 'clip_fraction': 0.3723958358168602, 'grad_norm': 10.808856964111328}
2022-12-28 20:51:21.335 DEBUG: Early stopping at step 9 for reaching max KL.
2022-12-28 20:51:21.336 INFO: Optimization: policy loss=-0.058, vf loss=0.000, entropy loss=-0.084, total loss=-0.141, num steps=9
2022-12-28 20:51:21.336 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:51:23.206 INFO: Evaluation rollout: return=0.989 (0.0), episode length=6.0
2022-12-28 20:51:23.207 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:51:23.210 INFO: Iteration: 100/137, steps: 21600
2022-12-28 20:51:40.709 DEBUG: There is a single atom floating around
2022-12-28 20:52:26.345 INFO: Training rollout: return=0.288 (3.3), episode length=6.0
2022-12-28 20:52:26.347 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:52:26.350 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-21600_train.pkl
2022-12-28 20:52:27.374 DEBUG: Taking gradient step
2022-12-28 20:52:27.384 DEBUG: Loss 0: {'policy_loss': 0.015027499943345611, 'entropy_loss': -0.08377066813409328, 'vf_loss': 0.011708165076774895, 'total_loss': -0.057035003113972776, 'approx_kl': -4.7497451305389404e-08, 'clip_fraction': 0.0, 'grad_norm': 21.030027389526367}
2022-12-28 20:52:28.440 DEBUG: Taking gradient step
2022-12-28 20:52:28.453 DEBUG: Loss 1: {'policy_loss': 0.01680070000996648, 'entropy_loss': -0.08514958992600441, 'vf_loss': 0.011732658032845834, 'total_loss': -0.05661623188319209, 'approx_kl': 0.0013126666890457273, 'clip_fraction': 0.02864583395421505, 'grad_norm': 13.46087646484375}
2022-12-28 20:52:29.433 DEBUG: Taking gradient step
2022-12-28 20:52:29.441 DEBUG: Loss 2: {'policy_loss': -0.040166456113245395, 'entropy_loss': -0.08358856290578842, 'vf_loss': 0.009261933885783575, 'total_loss': -0.11449308513325024, 'approx_kl': 0.008072944045125041, 'clip_fraction': 0.1458333358168602, 'grad_norm': 5.022646903991699}
2022-12-28 20:52:30.420 DEBUG: Taking gradient step
2022-12-28 20:52:30.428 DEBUG: Loss 3: {'policy_loss': -0.009900429517853943, 'entropy_loss': -0.08387215249240398, 'vf_loss': 0.011654411049312531, 'total_loss': -0.08211817096094538, 'approx_kl': 0.02319637523032725, 'clip_fraction': 0.2669270858168602, 'grad_norm': 7.679744243621826}
2022-12-28 20:52:31.467 DEBUG: Taking gradient step
2022-12-28 20:52:31.475 DEBUG: Loss 4: {'policy_loss': -0.014925146706697142, 'entropy_loss': -0.08387738466262817, 'vf_loss': 0.011774214287339603, 'total_loss': -0.0870283170819857, 'approx_kl': 0.029361562803387642, 'clip_fraction': 0.3411458358168602, 'grad_norm': 2.6716744899749756}
2022-12-28 20:52:32.441 DEBUG: Taking gradient step
2022-12-28 20:52:32.452 DEBUG: Loss 5: {'policy_loss': -0.04826127464700546, 'entropy_loss': -0.08359997160732746, 'vf_loss': 0.009249886847232935, 'total_loss': -0.1226113594071, 'approx_kl': 0.036718148505315185, 'clip_fraction': 0.40625, 'grad_norm': 2.284658193588257}
2022-12-28 20:52:33.423 DEBUG: Taking gradient step
2022-12-28 20:52:33.431 DEBUG: Loss 6: {'policy_loss': -0.05027308390535504, 'entropy_loss': -0.08316345885396004, 'vf_loss': 0.009244694517427415, 'total_loss': -0.12419184824188766, 'approx_kl': 0.02076628478243947, 'clip_fraction': 0.3763020858168602, 'grad_norm': 2.2089810371398926}
2022-12-28 20:52:34.413 DEBUG: Taking gradient step
2022-12-28 20:52:34.425 DEBUG: Loss 7: {'policy_loss': -0.04235208029465965, 'entropy_loss': -0.08342330902814865, 'vf_loss': 0.009217690352793432, 'total_loss': -0.11655769897001486, 'approx_kl': 0.030123458243906498, 'clip_fraction': 0.3932291716337204, 'grad_norm': 2.04530668258667}
2022-12-28 20:52:35.421 DEBUG: Taking gradient step
2022-12-28 20:52:35.429 DEBUG: Loss 8: {'policy_loss': -0.024354165326201202, 'entropy_loss': -0.08204985968768597, 'vf_loss': 0.011749958719292707, 'total_loss': -0.09465406629459445, 'approx_kl': -0.0023425843100994825, 'clip_fraction': 0.35546875, 'grad_norm': 1.8229494094848633}
2022-12-28 20:52:36.387 DEBUG: Taking gradient step
2022-12-28 20:52:36.395 DEBUG: Loss 9: {'policy_loss': -0.020460377553733117, 'entropy_loss': -0.08325363509356976, 'vf_loss': 0.011658564228498125, 'total_loss': -0.09205544841880474, 'approx_kl': -0.014052130129130092, 'clip_fraction': 0.3802083358168602, 'grad_norm': 1.8981002569198608}
2022-12-28 20:52:36.395 INFO: Optimization: policy loss=-0.020, vf loss=0.012, entropy loss=-0.083, total loss=-0.092, num steps=10
2022-12-28 20:52:36.395 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:52:38.152 INFO: Evaluation rollout: return=0.877 (0.0), episode length=6.0
2022-12-28 20:52:38.153 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:52:38.156 DEBUG: Deleting old model: runs/CH3NO_painn/models/CH3NO_painn_run-1_steps-19656.model
2022-12-28 20:52:38.159 DEBUG: Saving model: runs/CH3NO_painn/models/CH3NO_painn_run-1_steps-21816.model
2022-12-28 20:52:38.182 INFO: Iteration: 101/137, steps: 21816
2022-12-28 20:53:40.862 INFO: Training rollout: return=0.832 (0.1), episode length=6.0
2022-12-28 20:53:40.864 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:53:40.866 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-21816_train.pkl
2022-12-28 20:53:41.845 DEBUG: Taking gradient step
2022-12-28 20:53:41.854 DEBUG: Loss 0: {'policy_loss': -0.0009077515386883652, 'entropy_loss': -0.08091577515006065, 'vf_loss': 0.00038593609178923596, 'total_loss': -0.08143759059695979, 'approx_kl': 3.158735850661287e-08, 'clip_fraction': 0.0, 'grad_norm': 19.984233856201172}
2022-12-28 20:53:42.875 DEBUG: Taking gradient step
2022-12-28 20:53:42.883 DEBUG: Loss 1: {'policy_loss': 0.029361413824510796, 'entropy_loss': -0.08126016147434711, 'vf_loss': 0.00038236532261915824, 'total_loss': -0.05151638232721716, 'approx_kl': 0.021924172062426805, 'clip_fraction': 0.08984375, 'grad_norm': 11.4776029586792}
2022-12-28 20:53:43.882 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-28 20:53:43.882 INFO: Optimization: policy loss=0.029, vf loss=0.000, entropy loss=-0.081, total loss=-0.052, num steps=2
2022-12-28 20:53:43.883 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:53:45.770 INFO: Evaluation rollout: return=0.888 (0.0), episode length=6.0
2022-12-28 20:53:45.771 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:53:45.773 INFO: Iteration: 102/137, steps: 22032
2022-12-28 20:54:01.807 DEBUG: Atoms are too close
2022-12-28 20:54:02.430 DEBUG: Atoms are too close
2022-12-28 20:54:45.856 DEBUG: Atoms are too close
2022-12-28 20:54:47.203 INFO: Training rollout: return=-0.879 (5.6), episode length=5.9
2022-12-28 20:54:47.204 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:54:47.206 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-22032_train.pkl
2022-12-28 20:54:48.196 DEBUG: Taking gradient step
2022-12-28 20:54:48.207 DEBUG: Loss 0: {'policy_loss': 0.004320729489963792, 'entropy_loss': -0.08495648577809334, 'vf_loss': 0.028992550384480665, 'total_loss': -0.05164320590364889, 'approx_kl': 4.873921533032899e-08, 'clip_fraction': 0.0, 'grad_norm': 14.221295356750488}
2022-12-28 20:54:49.194 DEBUG: Taking gradient step
2022-12-28 20:54:49.202 DEBUG: Loss 1: {'policy_loss': 0.010352748232339153, 'entropy_loss': -0.08462091907858849, 'vf_loss': 0.03168056562160555, 'total_loss': -0.042587605224643776, 'approx_kl': 0.01117916963994503, 'clip_fraction': 0.11458333395421505, 'grad_norm': 8.505721092224121}
2022-12-28 20:54:50.179 DEBUG: Taking gradient step
2022-12-28 20:54:50.188 DEBUG: Loss 2: {'policy_loss': 0.05055606337385131, 'entropy_loss': -0.08452318981289864, 'vf_loss': 0.03640885825835867, 'total_loss': 0.0024417318193113435, 'approx_kl': 0.01258684997446835, 'clip_fraction': 0.2955729216337204, 'grad_norm': 10.14832878112793}
2022-12-28 20:54:51.140 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-28 20:54:51.140 INFO: Optimization: policy loss=0.051, vf loss=0.036, entropy loss=-0.085, total loss=0.002, num steps=3
2022-12-28 20:54:51.141 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:54:52.882 INFO: Evaluation rollout: return=0.950 (0.0), episode length=6.0
2022-12-28 20:54:52.884 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:54:52.886 INFO: Iteration: 103/137, steps: 22248
2022-12-28 20:55:27.090 DEBUG: Atoms are too close
2022-12-28 20:55:54.687 INFO: Training rollout: return=0.250 (3.3), episode length=6.0
2022-12-28 20:55:54.689 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:55:54.691 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-22248_train.pkl
2022-12-28 20:55:55.671 DEBUG: Taking gradient step
2022-12-28 20:55:55.683 DEBUG: Loss 0: {'policy_loss': -0.021649491771983644, 'entropy_loss': -0.08329439349472523, 'vf_loss': 0.007951421370107292, 'total_loss': -0.0969924638966016, 'approx_kl': -1.6065314412117004e-08, 'clip_fraction': 0.0, 'grad_norm': 16.68820571899414}
2022-12-28 20:55:56.702 DEBUG: Taking gradient step
2022-12-28 20:55:56.710 DEBUG: Loss 1: {'policy_loss': -0.03769769944774616, 'entropy_loss': -0.08253674954175949, 'vf_loss': 0.007959251254945642, 'total_loss': -0.11227519773456002, 'approx_kl': 0.0032419513445347548, 'clip_fraction': 0.1432291679084301, 'grad_norm': 5.847489356994629}
2022-12-28 20:55:57.701 DEBUG: Taking gradient step
2022-12-28 20:55:57.709 DEBUG: Loss 2: {'policy_loss': -0.0034381527818126457, 'entropy_loss': -0.08127706497907639, 'vf_loss': 0.010446074250912946, 'total_loss': -0.07426914350997608, 'approx_kl': 0.011684798635542393, 'clip_fraction': 0.2890625, 'grad_norm': 3.027942180633545}
2022-12-28 20:55:58.706 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-28 20:55:58.706 INFO: Optimization: policy loss=-0.003, vf loss=0.010, entropy loss=-0.081, total loss=-0.074, num steps=3
2022-12-28 20:55:58.707 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:56:00.500 INFO: Evaluation rollout: return=0.963 (0.0), episode length=6.0
2022-12-28 20:56:00.501 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:56:00.503 INFO: Iteration: 104/137, steps: 22464
2022-12-28 20:56:18.972 DEBUG: Atoms are too close
2022-12-28 20:57:02.938 INFO: Training rollout: return=0.245 (3.3), episode length=6.0
2022-12-28 20:57:02.940 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:57:02.942 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-22464_train.pkl
2022-12-28 20:57:03.910 DEBUG: Taking gradient step
2022-12-28 20:57:03.917 DEBUG: Loss 0: {'policy_loss': -0.025910886082722122, 'entropy_loss': -0.08148963004350662, 'vf_loss': 0.00902095783194952, 'total_loss': -0.09837955829427922, 'approx_kl': 2.087714801035645e-08, 'clip_fraction': 0.0, 'grad_norm': 17.982097625732422}
2022-12-28 20:57:04.914 DEBUG: Taking gradient step
2022-12-28 20:57:04.924 DEBUG: Loss 1: {'policy_loss': -0.026286325080210476, 'entropy_loss': -0.08089467883110046, 'vf_loss': 0.009022089514525563, 'total_loss': -0.09815891439678538, 'approx_kl': 0.007153990911319852, 'clip_fraction': 0.049479166977107525, 'grad_norm': 17.672475814819336}
2022-12-28 20:57:05.998 DEBUG: Taking gradient step
2022-12-28 20:57:06.006 DEBUG: Loss 2: {'policy_loss': -0.026868969937948704, 'entropy_loss': -0.081020787358284, 'vf_loss': 0.009021304227838636, 'total_loss': -0.09886845306839406, 'approx_kl': 0.031132600270211697, 'clip_fraction': 0.15234375, 'grad_norm': 6.464030742645264}
2022-12-28 20:57:06.963 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-28 20:57:06.963 INFO: Optimization: policy loss=-0.027, vf loss=0.009, entropy loss=-0.081, total loss=-0.099, num steps=3
2022-12-28 20:57:06.964 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:57:08.716 INFO: Evaluation rollout: return=0.954 (0.0), episode length=6.0
2022-12-28 20:57:08.717 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:57:08.720 INFO: Iteration: 105/137, steps: 22680
2022-12-28 20:57:13.885 DEBUG: There is a single atom floating around
2022-12-28 20:57:25.772 DEBUG: Atoms are too close
2022-12-28 20:57:47.866 DEBUG: Atoms are too close
2022-12-28 20:57:47.867 DEBUG: Atoms are too close
2022-12-28 20:58:10.344 INFO: Training rollout: return=-1.455 (6.4), episode length=5.9
2022-12-28 20:58:10.345 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:58:10.348 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-22680_train.pkl
2022-12-28 20:58:11.342 DEBUG: Taking gradient step
2022-12-28 20:58:11.350 DEBUG: Loss 0: {'policy_loss': -0.005581556462433888, 'entropy_loss': -0.0823790393769741, 'vf_loss': 0.03556081741547603, 'total_loss': -0.05239977842393196, 'approx_kl': 8.405186235904694e-08, 'clip_fraction': 0.0, 'grad_norm': 16.467350006103516}
2022-12-28 20:58:12.340 DEBUG: Taking gradient step
2022-12-28 20:58:12.347 DEBUG: Loss 1: {'policy_loss': 0.06743308919003291, 'entropy_loss': -0.08383739180862904, 'vf_loss': 0.04511853388335725, 'total_loss': 0.02871423126476111, 'approx_kl': 0.007626689737662673, 'clip_fraction': 0.01953125, 'grad_norm': 13.67011547088623}
2022-12-28 20:58:13.327 DEBUG: Taking gradient step
2022-12-28 20:58:13.335 DEBUG: Loss 2: {'policy_loss': -0.005837588660098685, 'entropy_loss': -0.08267542533576488, 'vf_loss': 0.03787694045031667, 'total_loss': -0.050636073545546896, 'approx_kl': 0.016630238387733698, 'clip_fraction': 0.1770833358168602, 'grad_norm': 8.229754447937012}
2022-12-28 20:58:14.289 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-28 20:58:14.289 INFO: Optimization: policy loss=-0.006, vf loss=0.038, entropy loss=-0.083, total loss=-0.051, num steps=3
2022-12-28 20:58:14.289 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:58:16.121 INFO: Evaluation rollout: return=0.940 (0.0), episode length=6.0
2022-12-28 20:58:16.123 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:58:16.125 INFO: Iteration: 106/137, steps: 22896
2022-12-28 20:59:19.271 INFO: Training rollout: return=0.775 (0.1), episode length=6.0
2022-12-28 20:59:19.273 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 20:59:19.275 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-22896_train.pkl
2022-12-28 20:59:20.248 DEBUG: Taking gradient step
2022-12-28 20:59:20.255 DEBUG: Loss 0: {'policy_loss': -0.01623247010517523, 'entropy_loss': -0.08116170018911362, 'vf_loss': 0.0005091195377479521, 'total_loss': -0.09688505075654089, 'approx_kl': -9.577100534841065e-08, 'clip_fraction': 0.0, 'grad_norm': 16.247268676757812}
2022-12-28 20:59:21.223 DEBUG: Taking gradient step
2022-12-28 20:59:21.231 DEBUG: Loss 1: {'policy_loss': 0.0014272105245142167, 'entropy_loss': -0.08162156119942665, 'vf_loss': 0.0005234566212154951, 'total_loss': -0.07967089405369694, 'approx_kl': 0.00022439053282141685, 'clip_fraction': 0.07291666697710752, 'grad_norm': 11.861849784851074}
2022-12-28 20:59:22.215 DEBUG: Taking gradient step
2022-12-28 20:59:22.222 DEBUG: Loss 2: {'policy_loss': 0.01105925858371182, 'entropy_loss': -0.0815797857940197, 'vf_loss': 0.00053311162503734, 'total_loss': -0.06998741558527054, 'approx_kl': 0.0030883734580129385, 'clip_fraction': 0.1705729179084301, 'grad_norm': 8.799092292785645}
2022-12-28 20:59:23.200 DEBUG: Taking gradient step
2022-12-28 20:59:23.208 DEBUG: Loss 3: {'policy_loss': -0.004027435239976181, 'entropy_loss': -0.08084717765450478, 'vf_loss': 0.0005439707917404007, 'total_loss': -0.08433064210274055, 'approx_kl': 0.00853820308111608, 'clip_fraction': 0.20833333395421505, 'grad_norm': 11.318676948547363}
2022-12-28 20:59:24.171 DEBUG: Taking gradient step
2022-12-28 20:59:24.179 DEBUG: Loss 4: {'policy_loss': -0.004278985084385463, 'entropy_loss': -0.0809297002851963, 'vf_loss': 0.0005439500059835182, 'total_loss': -0.08466473536359823, 'approx_kl': 0.02224909048527479, 'clip_fraction': 0.27734375, 'grad_norm': 7.786755561828613}
2022-12-28 20:59:25.149 DEBUG: Taking gradient step
2022-12-28 20:59:25.157 DEBUG: Loss 5: {'policy_loss': -0.02922961701963539, 'entropy_loss': -0.08182308822870255, 'vf_loss': 0.0005500830463455078, 'total_loss': -0.11050262220199243, 'approx_kl': 0.022020951699232683, 'clip_fraction': 0.2513020858168602, 'grad_norm': 11.56415843963623}
2022-12-28 20:59:26.160 DEBUG: Taking gradient step
2022-12-28 20:59:26.168 DEBUG: Loss 6: {'policy_loss': -0.10085500939304258, 'entropy_loss': -0.0806350689381361, 'vf_loss': 0.0005601300262912086, 'total_loss': -0.18092994830488748, 'approx_kl': 0.03342728456482291, 'clip_fraction': 0.32421875, 'grad_norm': 6.560760021209717}
2022-12-28 20:59:27.192 DEBUG: Taking gradient step
2022-12-28 20:59:27.200 DEBUG: Loss 7: {'policy_loss': -0.07295762610153195, 'entropy_loss': -0.07960237190127373, 'vf_loss': 0.0005355788043790006, 'total_loss': -0.15202441919842666, 'approx_kl': 0.03816347988322377, 'clip_fraction': 0.3580729216337204, 'grad_norm': 8.02789306640625}
2022-12-28 20:59:28.148 DEBUG: Early stopping at step 8 for reaching max KL.
2022-12-28 20:59:28.148 INFO: Optimization: policy loss=-0.073, vf loss=0.001, entropy loss=-0.080, total loss=-0.152, num steps=8
2022-12-28 20:59:28.149 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 20:59:29.935 INFO: Evaluation rollout: return=0.252 (0.0), episode length=6.0
2022-12-28 20:59:29.936 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 20:59:29.939 INFO: Iteration: 107/137, steps: 23112
2022-12-28 21:00:32.678 INFO: Training rollout: return=0.763 (0.2), episode length=6.0
2022-12-28 21:00:32.679 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 21:00:32.683 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-23112_train.pkl
2022-12-28 21:00:33.686 DEBUG: Taking gradient step
2022-12-28 21:00:33.694 DEBUG: Loss 0: {'policy_loss': 0.03702140610877185, 'entropy_loss': -0.08149618096649647, 'vf_loss': 0.0004471197117116816, 'total_loss': -0.04402765514601294, 'approx_kl': -3.4924596548080444e-09, 'clip_fraction': 0.0, 'grad_norm': 18.70126724243164}
2022-12-28 21:00:34.678 DEBUG: Taking gradient step
2022-12-28 21:00:34.686 DEBUG: Loss 1: {'policy_loss': 0.048140521938663874, 'entropy_loss': -0.08201848901808262, 'vf_loss': 0.000428423510277925, 'total_loss': -0.03344954356914083, 'approx_kl': 0.009378423914313316, 'clip_fraction': 0.046875, 'grad_norm': 16.121782302856445}
2022-12-28 21:00:35.708 DEBUG: Taking gradient step
2022-12-28 21:00:35.721 DEBUG: Loss 2: {'policy_loss': -0.001096545958490465, 'entropy_loss': -0.08151507750153542, 'vf_loss': 0.00042610481352073543, 'total_loss': -0.08218551864650514, 'approx_kl': 0.032700368436053395, 'clip_fraction': 0.1770833358168602, 'grad_norm': 11.558633804321289}
2022-12-28 21:00:36.776 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-28 21:00:36.776 INFO: Optimization: policy loss=-0.001, vf loss=0.000, entropy loss=-0.082, total loss=-0.082, num steps=3
2022-12-28 21:00:36.777 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 21:00:38.705 INFO: Evaluation rollout: return=0.872 (0.0), episode length=6.0
2022-12-28 21:00:38.706 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 21:00:38.710 INFO: Iteration: 108/137, steps: 23328
2022-12-28 21:01:42.550 INFO: Training rollout: return=0.816 (0.1), episode length=6.0
2022-12-28 21:01:42.552 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 21:01:42.554 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-23328_train.pkl
2022-12-28 21:01:43.541 DEBUG: Taking gradient step
2022-12-28 21:01:43.550 DEBUG: Loss 0: {'policy_loss': -0.03929197635756643, 'entropy_loss': -0.08009464852511883, 'vf_loss': 0.0005397347632122315, 'total_loss': -0.11884689011947303, 'approx_kl': 4.315127988263612e-08, 'clip_fraction': 0.0, 'grad_norm': 10.791245460510254}
2022-12-28 21:01:44.553 DEBUG: Taking gradient step
2022-12-28 21:01:44.565 DEBUG: Loss 1: {'policy_loss': 0.012165569436180121, 'entropy_loss': -0.0801130123436451, 'vf_loss': 0.0005079173818094034, 'total_loss': -0.06743952552565557, 'approx_kl': 0.00304385251365602, 'clip_fraction': 0.109375, 'grad_norm': 27.530223846435547}
2022-12-28 21:01:45.531 DEBUG: Taking gradient step
2022-12-28 21:01:45.538 DEBUG: Loss 2: {'policy_loss': 0.008139541813198085, 'entropy_loss': -0.07974127121269703, 'vf_loss': 0.0004885275015610571, 'total_loss': -0.0711132018979379, 'approx_kl': 0.005357236135751009, 'clip_fraction': 0.16015625, 'grad_norm': 16.41368865966797}
2022-12-28 21:01:46.581 DEBUG: Taking gradient step
2022-12-28 21:01:46.593 DEBUG: Loss 3: {'policy_loss': -0.028284307402957284, 'entropy_loss': -0.08046944439411163, 'vf_loss': 0.0004748311319888403, 'total_loss': -0.10827892066508008, 'approx_kl': 0.02355248318053782, 'clip_fraction': 0.26171875, 'grad_norm': 16.726512908935547}
2022-12-28 21:01:47.626 DEBUG: Taking gradient step
2022-12-28 21:01:47.637 DEBUG: Loss 4: {'policy_loss': -0.026825474520595975, 'entropy_loss': -0.08028852008283138, 'vf_loss': 0.00045257166461242404, 'total_loss': -0.10666142293881495, 'approx_kl': 0.04028837103396654, 'clip_fraction': 0.2825520858168602, 'grad_norm': 11.684097290039062}
2022-12-28 21:01:48.598 DEBUG: Early stopping at step 5 for reaching max KL.
2022-12-28 21:01:48.598 INFO: Optimization: policy loss=-0.027, vf loss=0.000, entropy loss=-0.080, total loss=-0.107, num steps=5
2022-12-28 21:01:48.599 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 21:01:50.375 INFO: Evaluation rollout: return=0.912 (0.0), episode length=6.0
2022-12-28 21:01:50.376 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 21:01:50.379 INFO: Iteration: 109/137, steps: 23544
2022-12-28 21:02:31.712 DEBUG: There is a single atom floating around
2022-12-28 21:02:53.340 INFO: Training rollout: return=0.096 (3.3), episode length=6.0
2022-12-28 21:02:53.341 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 21:02:53.344 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-23544_train.pkl
2022-12-28 21:02:54.318 DEBUG: Taking gradient step
2022-12-28 21:02:54.326 DEBUG: Loss 0: {'policy_loss': -0.026740706479208648, 'entropy_loss': -0.08266702480614185, 'vf_loss': 0.009357990190397637, 'total_loss': -0.10004974109495286, 'approx_kl': -4.734223146840577e-08, 'clip_fraction': 0.0, 'grad_norm': 10.719954490661621}
2022-12-28 21:02:55.327 DEBUG: Taking gradient step
2022-12-28 21:02:55.335 DEBUG: Loss 1: {'policy_loss': -0.032329861750883294, 'entropy_loss': -0.08240528404712677, 'vf_loss': 0.009394288803619505, 'total_loss': -0.10534085699439057, 'approx_kl': -0.005888798041269183, 'clip_fraction': 0.07552083395421505, 'grad_norm': 7.512669563293457}
2022-12-28 21:02:56.293 DEBUG: Taking gradient step
2022-12-28 21:02:56.301 DEBUG: Loss 2: {'policy_loss': -0.03574426057069642, 'entropy_loss': -0.08213315904140472, 'vf_loss': 0.00939066222943808, 'total_loss': -0.10848675738266307, 'approx_kl': 0.0028126626275479794, 'clip_fraction': 0.1770833358168602, 'grad_norm': 5.285314559936523}
2022-12-28 21:02:57.262 DEBUG: Taking gradient step
2022-12-28 21:02:57.273 DEBUG: Loss 3: {'policy_loss': -0.04623469494598233, 'entropy_loss': -0.08235246688127518, 'vf_loss': 0.00936473152152957, 'total_loss': -0.11922243030572793, 'approx_kl': 0.026629113592207432, 'clip_fraction': 0.27734375, 'grad_norm': 4.615316867828369}
2022-12-28 21:02:58.273 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-28 21:02:58.273 INFO: Optimization: policy loss=-0.046, vf loss=0.009, entropy loss=-0.082, total loss=-0.119, num steps=4
2022-12-28 21:02:58.274 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 21:03:00.183 INFO: Evaluation rollout: return=0.989 (0.0), episode length=6.0
2022-12-28 21:03:00.184 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 21:03:00.186 INFO: Iteration: 110/137, steps: 23760
2022-12-28 21:04:02.739 INFO: Training rollout: return=0.795 (0.2), episode length=6.0
2022-12-28 21:04:02.741 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 21:04:02.743 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-23760_train.pkl
2022-12-28 21:04:03.748 DEBUG: Taking gradient step
2022-12-28 21:04:03.756 DEBUG: Loss 0: {'policy_loss': -0.01745433825486056, 'entropy_loss': -0.08176282793283463, 'vf_loss': 0.0003609908314278163, 'total_loss': -0.09885617535626737, 'approx_kl': 1.218480392140009e-07, 'clip_fraction': 0.0, 'grad_norm': 18.735334396362305}
2022-12-28 21:04:04.738 DEBUG: Taking gradient step
2022-12-28 21:04:04.746 DEBUG: Loss 1: {'policy_loss': -0.015168271966911043, 'entropy_loss': -0.08210575953125954, 'vf_loss': 0.0003494308277413481, 'total_loss': -0.09692460067042923, 'approx_kl': 0.006472230423241854, 'clip_fraction': 0.08203125, 'grad_norm': 9.707904815673828}
2022-12-28 21:04:05.721 DEBUG: Taking gradient step
2022-12-28 21:04:05.729 DEBUG: Loss 2: {'policy_loss': -0.01860015971487046, 'entropy_loss': -0.08197346329689026, 'vf_loss': 0.00034161481947351006, 'total_loss': -0.10023200819228721, 'approx_kl': 0.040312177035957575, 'clip_fraction': 0.2486979216337204, 'grad_norm': 8.7122802734375}
2022-12-28 21:04:06.783 DEBUG: Taking gradient step
2022-12-28 21:04:06.793 DEBUG: Loss 3: {'policy_loss': -0.03891677092746324, 'entropy_loss': -0.08279247209429741, 'vf_loss': 0.0003347424624600199, 'total_loss': -0.12137450055930063, 'approx_kl': 0.0366181789431721, 'clip_fraction': 0.3203125, 'grad_norm': 11.088640213012695}
2022-12-28 21:04:07.772 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-28 21:04:07.772 INFO: Optimization: policy loss=-0.039, vf loss=0.000, entropy loss=-0.083, total loss=-0.121, num steps=4
2022-12-28 21:04:07.773 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 21:04:09.557 INFO: Evaluation rollout: return=0.915 (0.0), episode length=6.0
2022-12-28 21:04:09.558 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 21:04:09.560 DEBUG: Deleting old model: runs/CH3NO_painn/models/CH3NO_painn_run-1_steps-21816.model
2022-12-28 21:04:09.564 DEBUG: Saving model: runs/CH3NO_painn/models/CH3NO_painn_run-1_steps-23976.model
2022-12-28 21:04:09.587 INFO: Iteration: 111/137, steps: 23976
2022-12-28 21:04:29.675 DEBUG: Atoms are too close
2022-12-28 21:05:10.966 DEBUG: There is a single atom floating around
2022-12-28 21:05:11.913 INFO: Training rollout: return=-0.283 (4.6), episode length=6.0
2022-12-28 21:05:11.915 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 21:05:11.917 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-23976_train.pkl
2022-12-28 21:05:12.888 DEBUG: Taking gradient step
2022-12-28 21:05:12.896 DEBUG: Loss 0: {'policy_loss': 0.01776565791408662, 'entropy_loss': -0.08078587613999844, 'vf_loss': 0.023133682345940133, 'total_loss': -0.03988653587997168, 'approx_kl': 5.2231673208780194e-08, 'clip_fraction': 0.0, 'grad_norm': 13.020263671875}
2022-12-28 21:05:13.878 DEBUG: Taking gradient step
2022-12-28 21:05:13.886 DEBUG: Loss 1: {'policy_loss': -0.021886168492932047, 'entropy_loss': -0.0811273381114006, 'vf_loss': 0.020711942920982766, 'total_loss': -0.08230156368334987, 'approx_kl': 0.005798536818474531, 'clip_fraction': 0.05598958395421505, 'grad_norm': 9.552915573120117}
2022-12-28 21:05:14.895 DEBUG: Taking gradient step
2022-12-28 21:05:14.903 DEBUG: Loss 2: {'policy_loss': -0.02668135900899464, 'entropy_loss': -0.08063959889113903, 'vf_loss': 0.020586998967064674, 'total_loss': -0.08673395893306898, 'approx_kl': 0.01765004056505859, 'clip_fraction': 0.2018229179084301, 'grad_norm': 5.049868106842041}
2022-12-28 21:05:15.887 DEBUG: Taking gradient step
2022-12-28 21:05:15.895 DEBUG: Loss 3: {'policy_loss': -0.007694391933475389, 'entropy_loss': -0.0813601203262806, 'vf_loss': 0.023016561293730017, 'total_loss': -0.06603795096602595, 'approx_kl': 0.034123708959668875, 'clip_fraction': 0.2877604216337204, 'grad_norm': 4.187232494354248}
2022-12-28 21:05:16.873 DEBUG: Taking gradient step
2022-12-28 21:05:16.882 DEBUG: Loss 4: {'policy_loss': -0.06646005416298352, 'entropy_loss': -0.08092860318720341, 'vf_loss': 0.018121800971198223, 'total_loss': -0.12926685637898871, 'approx_kl': 0.012222664430737495, 'clip_fraction': 0.35546875, 'grad_norm': 4.221734523773193}
2022-12-28 21:05:17.848 DEBUG: Taking gradient step
2022-12-28 21:05:17.857 DEBUG: Loss 5: {'policy_loss': -0.01882989263333866, 'entropy_loss': -0.0809676293283701, 'vf_loss': 0.022908973498534414, 'total_loss': -0.07688854846317435, 'approx_kl': 0.03328457102179527, 'clip_fraction': 0.3802083358168602, 'grad_norm': 2.757483720779419}
2022-12-28 21:05:18.820 DEBUG: Taking gradient step
2022-12-28 21:05:18.828 DEBUG: Loss 6: {'policy_loss': -0.02014872342862413, 'entropy_loss': -0.08183149434626102, 'vf_loss': 0.022965116054405384, 'total_loss': -0.07901510172047979, 'approx_kl': 0.011887934291735291, 'clip_fraction': 0.3997395858168602, 'grad_norm': 5.638574123382568}
2022-12-28 21:05:19.791 DEBUG: Taking gradient step
2022-12-28 21:05:19.800 DEBUG: Loss 7: {'policy_loss': -0.04595207280119595, 'entropy_loss': -0.08223338983952999, 'vf_loss': 0.020499778959490067, 'total_loss': -0.10768568368123588, 'approx_kl': 0.02360655483789742, 'clip_fraction': 0.40625, 'grad_norm': 3.6077988147735596}
2022-12-28 21:05:20.768 DEBUG: Taking gradient step
2022-12-28 21:05:20.776 DEBUG: Loss 8: {'policy_loss': -0.0703792906798945, 'entropy_loss': -0.08204055763781071, 'vf_loss': 0.017960662173973775, 'total_loss': -0.13445918614373142, 'approx_kl': -0.012529102386906743, 'clip_fraction': 0.3997395858168602, 'grad_norm': 2.6962404251098633}
2022-12-28 21:05:21.762 DEBUG: Taking gradient step
2022-12-28 21:05:21.771 DEBUG: Loss 9: {'policy_loss': -0.03188304932283035, 'entropy_loss': -0.08159271627664566, 'vf_loss': 0.022787686566857375, 'total_loss': -0.09068807903261862, 'approx_kl': 0.013186707627028227, 'clip_fraction': 0.3216145858168602, 'grad_norm': 2.148298740386963}
2022-12-28 21:05:21.771 INFO: Optimization: policy loss=-0.032, vf loss=0.023, entropy loss=-0.082, total loss=-0.091, num steps=10
2022-12-28 21:05:21.771 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 21:05:23.674 INFO: Evaluation rollout: return=0.910 (0.0), episode length=6.0
2022-12-28 21:05:23.675 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 21:05:23.677 INFO: Iteration: 112/137, steps: 24192
2022-12-28 21:06:26.379 INFO: Training rollout: return=0.793 (0.4), episode length=6.0
2022-12-28 21:06:26.380 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 21:06:26.383 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-24192_train.pkl
2022-12-28 21:06:27.377 DEBUG: Taking gradient step
2022-12-28 21:06:27.385 DEBUG: Loss 0: {'policy_loss': -0.03418206231704975, 'entropy_loss': -0.08333083800971508, 'vf_loss': 0.0005966442938125599, 'total_loss': -0.11691625603295228, 'approx_kl': -1.9480164148433232e-08, 'clip_fraction': 0.0, 'grad_norm': 18.935577392578125}
2022-12-28 21:06:28.342 DEBUG: Taking gradient step
2022-12-28 21:06:28.349 DEBUG: Loss 1: {'policy_loss': -0.007324207872166733, 'entropy_loss': -0.08428170718252659, 'vf_loss': 0.0006305469857663241, 'total_loss': -0.090975368068927, 'approx_kl': -0.0019900978077203035, 'clip_fraction': 0.045572916977107525, 'grad_norm': 10.981098175048828}
2022-12-28 21:06:29.346 DEBUG: Taking gradient step
2022-12-28 21:06:29.354 DEBUG: Loss 2: {'policy_loss': 0.006072451437711412, 'entropy_loss': -0.08377706632018089, 'vf_loss': 0.0006943200782071345, 'total_loss': -0.07701029480426234, 'approx_kl': -0.004424873739480972, 'clip_fraction': 0.1979166716337204, 'grad_norm': 8.028185844421387}
2022-12-28 21:06:30.325 DEBUG: Taking gradient step
2022-12-28 21:06:30.333 DEBUG: Loss 3: {'policy_loss': -0.011536253710719736, 'entropy_loss': -0.08293596282601357, 'vf_loss': 0.0007018811892651439, 'total_loss': -0.09377033534746816, 'approx_kl': -0.004910769173875451, 'clip_fraction': 0.25, 'grad_norm': 5.564120769500732}
2022-12-28 21:06:31.340 DEBUG: Taking gradient step
2022-12-28 21:06:31.348 DEBUG: Loss 4: {'policy_loss': -0.007613342307415713, 'entropy_loss': -0.083487119525671, 'vf_loss': 0.0007513190293367665, 'total_loss': -0.09034914280374995, 'approx_kl': 0.019525583367794752, 'clip_fraction': 0.2526041679084301, 'grad_norm': 7.018760681152344}
2022-12-28 21:06:32.335 DEBUG: Taking gradient step
2022-12-28 21:06:32.345 DEBUG: Loss 5: {'policy_loss': -0.012875266528730694, 'entropy_loss': -0.08375835977494717, 'vf_loss': 0.000766438137498974, 'total_loss': -0.09586718816617891, 'approx_kl': 0.033724755281582475, 'clip_fraction': 0.2981770858168602, 'grad_norm': 6.714172840118408}
2022-12-28 21:06:33.378 DEBUG: Taking gradient step
2022-12-28 21:06:33.386 DEBUG: Loss 6: {'policy_loss': -0.05499002976197605, 'entropy_loss': -0.08490931428968906, 'vf_loss': 0.0007752131870191541, 'total_loss': -0.13912413086464598, 'approx_kl': 0.027355960570275784, 'clip_fraction': 0.359375, 'grad_norm': 4.0494256019592285}
2022-12-28 21:06:34.447 DEBUG: Early stopping at step 7 for reaching max KL.
2022-12-28 21:06:34.447 INFO: Optimization: policy loss=-0.055, vf loss=0.001, entropy loss=-0.085, total loss=-0.139, num steps=7
2022-12-28 21:06:34.448 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 21:06:36.223 INFO: Evaluation rollout: return=0.947 (0.0), episode length=6.0
2022-12-28 21:06:36.225 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 21:06:36.227 INFO: Iteration: 113/137, steps: 24408
2022-12-28 21:07:38.913 INFO: Training rollout: return=0.797 (0.1), episode length=6.0
2022-12-28 21:07:38.915 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 21:07:38.918 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-24408_train.pkl
2022-12-28 21:07:39.932 DEBUG: Taking gradient step
2022-12-28 21:07:39.940 DEBUG: Loss 0: {'policy_loss': -0.030425251501938283, 'entropy_loss': -0.08248143456876278, 'vf_loss': 0.0006741046051831383, 'total_loss': -0.11223258146551791, 'approx_kl': -7.493266451774616e-08, 'clip_fraction': 0.0, 'grad_norm': 12.345898628234863}
2022-12-28 21:07:40.905 DEBUG: Taking gradient step
2022-12-28 21:07:40.912 DEBUG: Loss 1: {'policy_loss': -0.01878309099318007, 'entropy_loss': -0.08157681487500668, 'vf_loss': 0.0006501209858536434, 'total_loss': -0.09970978488233309, 'approx_kl': -0.0024947605561465025, 'clip_fraction': 0.06770833395421505, 'grad_norm': 10.66175365447998}
2022-12-28 21:07:41.874 DEBUG: Taking gradient step
2022-12-28 21:07:41.882 DEBUG: Loss 2: {'policy_loss': -0.051972749189614864, 'entropy_loss': -0.0818924643099308, 'vf_loss': 0.0006465033088762525, 'total_loss': -0.13321871019066941, 'approx_kl': 0.006201755488291383, 'clip_fraction': 0.1953125, 'grad_norm': 12.373769760131836}
2022-12-28 21:07:42.884 DEBUG: Taking gradient step
2022-12-28 21:07:42.895 DEBUG: Loss 3: {'policy_loss': -0.04901056472662678, 'entropy_loss': -0.0829368494451046, 'vf_loss': 0.0006269148415557211, 'total_loss': -0.13132049933017564, 'approx_kl': 0.007574762450531125, 'clip_fraction': 0.29296875, 'grad_norm': 11.858226776123047}
2022-12-28 21:07:43.896 DEBUG: Taking gradient step
2022-12-28 21:07:43.904 DEBUG: Loss 4: {'policy_loss': -0.042799239263698365, 'entropy_loss': -0.08171362802386284, 'vf_loss': 0.0005950446835109801, 'total_loss': -0.12391782260405022, 'approx_kl': -0.005217290949076414, 'clip_fraction': 0.3828125, 'grad_norm': 8.367632865905762}
2022-12-28 21:07:44.892 DEBUG: Taking gradient step
2022-12-28 21:07:44.900 DEBUG: Loss 5: {'policy_loss': -0.10554077669970952, 'entropy_loss': -0.08285480551421642, 'vf_loss': 0.0005900807934021974, 'total_loss': -0.18780550142052374, 'approx_kl': -0.020130578195676208, 'clip_fraction': 0.3541666716337204, 'grad_norm': 8.061092376708984}
2022-12-28 21:07:45.941 DEBUG: Taking gradient step
2022-12-28 21:07:45.949 DEBUG: Loss 6: {'policy_loss': -0.10211326355863126, 'entropy_loss': -0.08222979679703712, 'vf_loss': 0.000559769692016421, 'total_loss': -0.18378329066365195, 'approx_kl': -0.021643368061631918, 'clip_fraction': 0.3841145858168602, 'grad_norm': 6.028693199157715}
2022-12-28 21:07:46.983 DEBUG: Taking gradient step
2022-12-28 21:07:46.991 DEBUG: Loss 7: {'policy_loss': -0.09794352906283682, 'entropy_loss': -0.08215370401740074, 'vf_loss': 0.0005289658532312675, 'total_loss': -0.17956826722700628, 'approx_kl': -0.016842439770698547, 'clip_fraction': 0.3658854216337204, 'grad_norm': 10.18407154083252}
2022-12-28 21:07:47.962 DEBUG: Taking gradient step
2022-12-28 21:07:47.972 DEBUG: Loss 8: {'policy_loss': -0.05784733199061054, 'entropy_loss': -0.08292021416127682, 'vf_loss': 0.0004851614702575158, 'total_loss': -0.14028238468162985, 'approx_kl': -0.009156879037618637, 'clip_fraction': 0.3619791679084301, 'grad_norm': 9.711634635925293}
2022-12-28 21:07:48.995 DEBUG: Taking gradient step
2022-12-28 21:07:49.003 DEBUG: Loss 9: {'policy_loss': -0.048140179109242606, 'entropy_loss': -0.08211502060294151, 'vf_loss': 0.00044888421449520576, 'total_loss': -0.12980631549768892, 'approx_kl': 0.0041466208640486, 'clip_fraction': 0.4010416716337204, 'grad_norm': 7.140717029571533}
2022-12-28 21:07:49.003 INFO: Optimization: policy loss=-0.048, vf loss=0.000, entropy loss=-0.082, total loss=-0.130, num steps=10
2022-12-28 21:07:49.004 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 21:07:50.745 INFO: Evaluation rollout: return=0.915 (0.0), episode length=6.0
2022-12-28 21:07:50.746 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 21:07:50.748 INFO: Iteration: 114/137, steps: 24624
2022-12-28 21:08:52.382 DEBUG: There is a single atom floating around
2022-12-28 21:08:53.088 INFO: Training rollout: return=0.264 (3.3), episode length=6.0
2022-12-28 21:08:53.090 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 21:08:53.092 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-24624_train.pkl
2022-12-28 21:08:54.078 DEBUG: Taking gradient step
2022-12-28 21:08:54.090 DEBUG: Loss 0: {'policy_loss': -0.026581416254107836, 'entropy_loss': -0.07855665497481823, 'vf_loss': 0.009278064319516964, 'total_loss': -0.0958600069094091, 'approx_kl': -6.239861249923706e-08, 'clip_fraction': 0.0, 'grad_norm': 9.722204208374023}
2022-12-28 21:08:55.069 DEBUG: Taking gradient step
2022-12-28 21:08:55.080 DEBUG: Loss 1: {'policy_loss': -0.035308261092420704, 'entropy_loss': -0.0788524504750967, 'vf_loss': 0.00927342550165728, 'total_loss': -0.10488728606586012, 'approx_kl': -0.005842512473464012, 'clip_fraction': 0.03125, 'grad_norm': 8.336689949035645}
2022-12-28 21:08:56.074 DEBUG: Taking gradient step
2022-12-28 21:08:56.081 DEBUG: Loss 2: {'policy_loss': -0.004853980452361087, 'entropy_loss': -0.0775400660932064, 'vf_loss': 0.011667786151087843, 'total_loss': -0.07072626039447964, 'approx_kl': 0.009140947367995977, 'clip_fraction': 0.14192708395421505, 'grad_norm': 3.134948253631592}
2022-12-28 21:08:57.118 DEBUG: Taking gradient step
2022-12-28 21:08:57.127 DEBUG: Loss 3: {'policy_loss': -0.0014020989435552904, 'entropy_loss': -0.07824385911226273, 'vf_loss': 0.011714709322478159, 'total_loss': -0.06793124873333986, 'approx_kl': 0.01664932002313435, 'clip_fraction': 0.23046875, 'grad_norm': 3.3526110649108887}
2022-12-28 21:08:58.123 DEBUG: Taking gradient step
2022-12-28 21:08:58.131 DEBUG: Loss 4: {'policy_loss': -0.046884721640735746, 'entropy_loss': -0.07796789146959782, 'vf_loss': 0.009232029985449875, 'total_loss': -0.11562058312488369, 'approx_kl': 0.009648561710491776, 'clip_fraction': 0.2760416716337204, 'grad_norm': 5.242120742797852}
2022-12-28 21:08:59.143 DEBUG: Taking gradient step
2022-12-28 21:08:59.151 DEBUG: Loss 5: {'policy_loss': 0.025885241823821778, 'entropy_loss': -0.07799608074128628, 'vf_loss': 0.014095014562744673, 'total_loss': -0.03801582435471983, 'approx_kl': 0.0007354887202382088, 'clip_fraction': 0.3294270858168602, 'grad_norm': 4.759799480438232}
2022-12-28 21:09:00.110 DEBUG: Taking gradient step
2022-12-28 21:09:00.117 DEBUG: Loss 6: {'policy_loss': -0.051208010269153226, 'entropy_loss': -0.07845279946923256, 'vf_loss': 0.009183049032358564, 'total_loss': -0.12047776070602721, 'approx_kl': -0.02242243569344282, 'clip_fraction': 0.3203125, 'grad_norm': 2.955650568008423}
2022-12-28 21:09:01.095 DEBUG: Taking gradient step
2022-12-28 21:09:01.103 DEBUG: Loss 7: {'policy_loss': -0.0522447404762474, 'entropy_loss': -0.077784463763237, 'vf_loss': 0.009170598372945923, 'total_loss': -0.12085860586653847, 'approx_kl': -0.04290425358340144, 'clip_fraction': 0.3645833358168602, 'grad_norm': 7.619376182556152}
2022-12-28 21:09:02.059 DEBUG: Taking gradient step
2022-12-28 21:09:02.066 DEBUG: Loss 8: {'policy_loss': -0.05349143728616025, 'entropy_loss': -0.07874509878456593, 'vf_loss': 0.009152219237401548, 'total_loss': -0.12308431683332463, 'approx_kl': -0.04980257013812661, 'clip_fraction': 0.4127604216337204, 'grad_norm': 8.802140235900879}
2022-12-28 21:09:03.045 DEBUG: Taking gradient step
2022-12-28 21:09:03.053 DEBUG: Loss 9: {'policy_loss': -0.024404493884766055, 'entropy_loss': -0.07753151841461658, 'vf_loss': 0.011519739661346288, 'total_loss': -0.09041627263803635, 'approx_kl': -0.0539820184931159, 'clip_fraction': 0.3815104216337204, 'grad_norm': 3.4244139194488525}
2022-12-28 21:09:03.053 INFO: Optimization: policy loss=-0.024, vf loss=0.012, entropy loss=-0.078, total loss=-0.090, num steps=10
2022-12-28 21:09:03.054 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 21:09:04.998 INFO: Evaluation rollout: return=0.891 (0.0), episode length=6.0
2022-12-28 21:09:04.999 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 21:09:05.001 INFO: Iteration: 115/137, steps: 24840
2022-12-28 21:10:07.922 INFO: Training rollout: return=0.837 (0.1), episode length=6.0
2022-12-28 21:10:07.924 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 21:10:07.926 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-24840_train.pkl
2022-12-28 21:10:08.911 DEBUG: Taking gradient step
2022-12-28 21:10:08.920 DEBUG: Loss 0: {'policy_loss': 0.03878634873704332, 'entropy_loss': -0.07822173833847046, 'vf_loss': 0.00028620890190717853, 'total_loss': -0.03914918069951995, 'approx_kl': 8.273248930379395e-08, 'clip_fraction': 0.0, 'grad_norm': 17.303831100463867}
2022-12-28 21:10:09.916 DEBUG: Taking gradient step
2022-12-28 21:10:09.925 DEBUG: Loss 1: {'policy_loss': -0.01294834084494298, 'entropy_loss': -0.07818613387644291, 'vf_loss': 0.00028048581509170916, 'total_loss': -0.09085398890629418, 'approx_kl': 0.007237635552883148, 'clip_fraction': 0.03515625, 'grad_norm': 12.071455001831055}
2022-12-28 21:10:10.891 DEBUG: Taking gradient step
2022-12-28 21:10:10.899 DEBUG: Loss 2: {'policy_loss': -0.024395173705317488, 'entropy_loss': -0.07828567549586296, 'vf_loss': 0.00027384490171034255, 'total_loss': -0.1024070042994701, 'approx_kl': 0.02335227280855179, 'clip_fraction': 0.2213541679084301, 'grad_norm': 7.15480899810791}
2022-12-28 21:10:11.844 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-28 21:10:11.845 INFO: Optimization: policy loss=-0.024, vf loss=0.000, entropy loss=-0.078, total loss=-0.102, num steps=3
2022-12-28 21:10:11.845 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 21:10:13.708 INFO: Evaluation rollout: return=0.901 (0.0), episode length=6.0
2022-12-28 21:10:13.709 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 21:10:13.712 INFO: Iteration: 116/137, steps: 25056
2022-12-28 21:10:19.441 DEBUG: There is a single atom floating around
2022-12-28 21:10:24.890 DEBUG: Atoms are too close
2022-12-28 21:11:13.561 DEBUG: There is a single atom floating around
2022-12-28 21:11:15.519 INFO: Training rollout: return=-0.876 (5.6), episode length=5.9
2022-12-28 21:11:15.520 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 21:11:15.522 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-25056_train.pkl
2022-12-28 21:11:16.602 DEBUG: Taking gradient step
2022-12-28 21:11:16.610 DEBUG: Loss 0: {'policy_loss': -0.013095808433792197, 'entropy_loss': -0.07640521973371506, 'vf_loss': 0.0229891289082216, 'total_loss': -0.06651189925928566, 'approx_kl': -9.229794883935938e-08, 'clip_fraction': 0.0, 'grad_norm': 15.055877685546875}
2022-12-28 21:11:17.573 DEBUG: Taking gradient step
2022-12-28 21:11:17.581 DEBUG: Loss 1: {'policy_loss': 0.04326010841221569, 'entropy_loss': -0.07676927372813225, 'vf_loss': 0.028285375172003333, 'total_loss': -0.0052237901439132345, 'approx_kl': -0.0011492795310914516, 'clip_fraction': 0.029947916977107525, 'grad_norm': 17.2690486907959}
2022-12-28 21:11:18.538 DEBUG: Taking gradient step
2022-12-28 21:11:18.546 DEBUG: Loss 2: {'policy_loss': -0.004938869782871485, 'entropy_loss': -0.07674255967140198, 'vf_loss': 0.025540407106544795, 'total_loss': -0.056141022347728664, 'approx_kl': -0.003925572382286191, 'clip_fraction': 0.11458333395421505, 'grad_norm': 7.659870624542236}
2022-12-28 21:11:19.508 DEBUG: Taking gradient step
2022-12-28 21:11:19.516 DEBUG: Loss 3: {'policy_loss': -0.007909027414101644, 'entropy_loss': -0.0771001260727644, 'vf_loss': 0.025708777285557857, 'total_loss': -0.05930037620130818, 'approx_kl': -0.002992057939991355, 'clip_fraction': 0.2825520858168602, 'grad_norm': 8.844550132751465}
2022-12-28 21:11:20.503 DEBUG: Taking gradient step
2022-12-28 21:11:20.511 DEBUG: Loss 4: {'policy_loss': -0.04274762261989243, 'entropy_loss': -0.07779460214078426, 'vf_loss': 0.022959631157921614, 'total_loss': -0.09758259360275508, 'approx_kl': 0.0029966142028570175, 'clip_fraction': 0.3229166716337204, 'grad_norm': 3.1126203536987305}
2022-12-28 21:11:21.490 DEBUG: Taking gradient step
2022-12-28 21:11:21.498 DEBUG: Loss 5: {'policy_loss': -0.03990543411729294, 'entropy_loss': -0.07713022083044052, 'vf_loss': 0.022941338204740803, 'total_loss': -0.09409431674299265, 'approx_kl': 0.008597274776548147, 'clip_fraction': 0.3919270858168602, 'grad_norm': 3.4950637817382812}
2022-12-28 21:11:22.466 DEBUG: Taking gradient step
2022-12-28 21:11:22.475 DEBUG: Loss 6: {'policy_loss': -0.0676412179595913, 'entropy_loss': -0.07698318175971508, 'vf_loss': 0.020361081703222823, 'total_loss': -0.12426331801608356, 'approx_kl': -0.0077127874828875065, 'clip_fraction': 0.45703125, 'grad_norm': 3.691124200820923}
2022-12-28 21:11:23.427 DEBUG: Taking gradient step
2022-12-28 21:11:23.435 DEBUG: Loss 7: {'policy_loss': -0.01980767812794549, 'entropy_loss': -0.07655728794634342, 'vf_loss': 0.0254096467790496, 'total_loss': -0.07095531929523931, 'approx_kl': 0.00717252935282886, 'clip_fraction': 0.45703125, 'grad_norm': 3.523817300796509}
2022-12-28 21:11:24.370 DEBUG: Taking gradient step
2022-12-28 21:11:24.379 DEBUG: Loss 8: {'policy_loss': 0.01935279679525506, 'entropy_loss': -0.07580267637968063, 'vf_loss': 0.030562060119633642, 'total_loss': -0.025887819464791934, 'approx_kl': 0.004444480407983065, 'clip_fraction': 0.4088541716337204, 'grad_norm': 2.9418506622314453}
2022-12-28 21:11:25.357 DEBUG: Taking gradient step
2022-12-28 21:11:25.365 DEBUG: Loss 9: {'policy_loss': -0.05142369607523456, 'entropy_loss': -0.07562864385545254, 'vf_loss': 0.022737847781814008, 'total_loss': -0.10431449214887309, 'approx_kl': -0.0308684129267931, 'clip_fraction': 0.4088541716337204, 'grad_norm': 2.189517021179199}
2022-12-28 21:11:25.365 INFO: Optimization: policy loss=-0.051, vf loss=0.023, entropy loss=-0.076, total loss=-0.104, num steps=10
2022-12-28 21:11:25.366 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 21:11:27.276 INFO: Evaluation rollout: return=0.937 (0.0), episode length=6.0
2022-12-28 21:11:27.277 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 21:11:27.280 INFO: Iteration: 117/137, steps: 25272
2022-12-28 21:12:08.984 DEBUG: Atoms are too close
2022-12-28 21:12:30.189 INFO: Training rollout: return=0.311 (3.3), episode length=6.0
2022-12-28 21:12:30.191 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 21:12:30.193 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-25272_train.pkl
2022-12-28 21:12:31.179 DEBUG: Taking gradient step
2022-12-28 21:12:31.187 DEBUG: Loss 0: {'policy_loss': 0.056253088779369395, 'entropy_loss': -0.07614720612764359, 'vf_loss': 0.014105682542134164, 'total_loss': -0.005788434806140025, 'approx_kl': 2.4389009922742844e-08, 'clip_fraction': 0.0, 'grad_norm': 34.37311553955078}
2022-12-28 21:12:32.145 DEBUG: Taking gradient step
2022-12-28 21:12:32.155 DEBUG: Loss 1: {'policy_loss': 0.0004636445949080248, 'entropy_loss': -0.07567909732460976, 'vf_loss': 0.011654217838970582, 'total_loss': -0.06356123489073115, 'approx_kl': 0.006045814836397767, 'clip_fraction': 0.0078125, 'grad_norm': 21.837158203125}
2022-12-28 21:12:33.142 DEBUG: Taking gradient step
2022-12-28 21:12:33.149 DEBUG: Loss 2: {'policy_loss': -0.041258423865177835, 'entropy_loss': -0.07694448344409466, 'vf_loss': 0.009228569981894773, 'total_loss': -0.10897433732737771, 'approx_kl': 0.013693352229893208, 'clip_fraction': 0.125, 'grad_norm': 2.286740303039551}
2022-12-28 21:12:34.117 DEBUG: Taking gradient step
2022-12-28 21:12:34.125 DEBUG: Loss 3: {'policy_loss': -0.04604098278515213, 'entropy_loss': -0.07533673942089081, 'vf_loss': 0.009247933728833028, 'total_loss': -0.11212978847720992, 'approx_kl': 0.014945156406611204, 'clip_fraction': 0.2096354216337204, 'grad_norm': 2.4742400646209717}
2022-12-28 21:12:35.089 DEBUG: Taking gradient step
2022-12-28 21:12:35.096 DEBUG: Loss 4: {'policy_loss': -0.04497480929057705, 'entropy_loss': -0.0755034051835537, 'vf_loss': 0.00924820107402613, 'total_loss': -0.11123001340010463, 'approx_kl': 0.01638680847827345, 'clip_fraction': 0.2239583358168602, 'grad_norm': 2.429973602294922}
2022-12-28 21:12:36.063 DEBUG: Taking gradient step
2022-12-28 21:12:36.071 DEBUG: Loss 5: {'policy_loss': -0.04682116088311923, 'entropy_loss': -0.07538019306957722, 'vf_loss': 0.009247343844829108, 'total_loss': -0.11295401010786735, 'approx_kl': 0.006737623829394579, 'clip_fraction': 0.2018229179084301, 'grad_norm': 2.402303457260132}
2022-12-28 21:12:37.032 DEBUG: Taking gradient step
2022-12-28 21:12:37.040 DEBUG: Loss 6: {'policy_loss': -0.015303462627064238, 'entropy_loss': -0.07459860853850842, 'vf_loss': 0.011669608663615817, 'total_loss': -0.07823246250195685, 'approx_kl': 0.01211023423820734, 'clip_fraction': 0.2434895858168602, 'grad_norm': 2.310166120529175}
2022-12-28 21:12:38.018 DEBUG: Taking gradient step
2022-12-28 21:12:38.030 DEBUG: Loss 7: {'policy_loss': -0.05874615226458303, 'entropy_loss': -0.07636052742600441, 'vf_loss': 0.009260128921438432, 'total_loss': -0.12584655076914902, 'approx_kl': -0.014808996114879847, 'clip_fraction': 0.2669270858168602, 'grad_norm': 2.3594489097595215}
2022-12-28 21:12:39.015 DEBUG: Taking gradient step
2022-12-28 21:12:39.023 DEBUG: Loss 8: {'policy_loss': 0.02076078268684601, 'entropy_loss': -0.07481876201927662, 'vf_loss': 0.014021217211647268, 'total_loss': -0.040036762120783345, 'approx_kl': 0.005930651444941759, 'clip_fraction': 0.3190104216337204, 'grad_norm': 8.04096794128418}
2022-12-28 21:12:40.017 DEBUG: Taking gradient step
2022-12-28 21:12:40.025 DEBUG: Loss 9: {'policy_loss': -0.05608304330098948, 'entropy_loss': -0.0747890267521143, 'vf_loss': 0.009241550851496638, 'total_loss': -0.12163051920160714, 'approx_kl': -0.008867461234331131, 'clip_fraction': 0.3098958358168602, 'grad_norm': 8.047175407409668}
2022-12-28 21:12:40.025 INFO: Optimization: policy loss=-0.056, vf loss=0.009, entropy loss=-0.075, total loss=-0.122, num steps=10
2022-12-28 21:12:40.026 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 21:12:41.829 INFO: Evaluation rollout: return=0.939 (0.0), episode length=6.0
2022-12-28 21:12:41.830 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 21:12:41.832 INFO: Iteration: 118/137, steps: 25488
2022-12-28 21:13:44.339 INFO: Training rollout: return=0.835 (0.1), episode length=6.0
2022-12-28 21:13:44.341 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 21:13:44.343 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-25488_train.pkl
2022-12-28 21:13:45.341 DEBUG: Taking gradient step
2022-12-28 21:13:45.349 DEBUG: Loss 0: {'policy_loss': 0.02020098283174044, 'entropy_loss': -0.07572955824434757, 'vf_loss': 0.0005552893011521911, 'total_loss': -0.05497328611145494, 'approx_kl': 7.34968743643094e-08, 'clip_fraction': 0.0, 'grad_norm': 13.525364875793457}
2022-12-28 21:13:46.308 DEBUG: Taking gradient step
2022-12-28 21:13:46.315 DEBUG: Loss 1: {'policy_loss': 0.0011901564463521613, 'entropy_loss': -0.07545535452663898, 'vf_loss': 0.0005530556778117341, 'total_loss': -0.07371214240247508, 'approx_kl': 0.0016086030955193564, 'clip_fraction': 0.0, 'grad_norm': 17.93771743774414}
2022-12-28 21:13:47.292 DEBUG: Taking gradient step
2022-12-28 21:13:47.300 DEBUG: Loss 2: {'policy_loss': -0.0418009987547955, 'entropy_loss': -0.07697094790637493, 'vf_loss': 0.000546674980846386, 'total_loss': -0.11822527168032405, 'approx_kl': 0.006051724194549024, 'clip_fraction': 0.05989583395421505, 'grad_norm': 16.637048721313477}
2022-12-28 21:13:48.307 DEBUG: Taking gradient step
2022-12-28 21:13:48.316 DEBUG: Loss 3: {'policy_loss': -0.05062083742976789, 'entropy_loss': -0.07586838118731976, 'vf_loss': 0.0005283914965808232, 'total_loss': -0.12596082712050682, 'approx_kl': 0.01578599982894957, 'clip_fraction': 0.1705729179084301, 'grad_norm': 6.555549144744873}
2022-12-28 21:13:49.296 DEBUG: Taking gradient step
2022-12-28 21:13:49.305 DEBUG: Loss 4: {'policy_loss': 0.011399269948667426, 'entropy_loss': -0.07579970546066761, 'vf_loss': 0.0004943544858967856, 'total_loss': -0.0639060810261034, 'approx_kl': 0.04235514625906944, 'clip_fraction': 0.27734375, 'grad_norm': 7.612046718597412}
2022-12-28 21:13:50.264 DEBUG: Early stopping at step 5 for reaching max KL.
2022-12-28 21:13:50.265 INFO: Optimization: policy loss=0.011, vf loss=0.000, entropy loss=-0.076, total loss=-0.064, num steps=5
2022-12-28 21:13:50.265 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 21:13:52.033 INFO: Evaluation rollout: return=0.927 (0.0), episode length=6.0
2022-12-28 21:13:52.034 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 21:13:52.037 INFO: Iteration: 119/137, steps: 25704
2022-12-28 21:14:05.676 DEBUG: Atoms are too close
2022-12-28 21:14:10.609 DEBUG: Atoms are too close
2022-12-28 21:14:31.036 DEBUG: Atoms are too close
2022-12-28 21:14:43.725 DEBUG: Atoms are too close
2022-12-28 21:14:51.898 DEBUG: Atoms are too close
2022-12-28 21:14:53.133 INFO: Training rollout: return=-1.994 (7.0), episode length=5.9
2022-12-28 21:14:53.135 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 21:14:53.137 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-25704_train.pkl
2022-12-28 21:14:54.111 DEBUG: Taking gradient step
2022-12-28 21:14:54.118 DEBUG: Loss 0: {'policy_loss': 0.05947111521687799, 'entropy_loss': -0.07740388810634613, 'vf_loss': 0.05542035658678304, 'total_loss': 0.03748758369731492, 'approx_kl': -8.963979780673981e-08, 'clip_fraction': 0.0, 'grad_norm': 20.867673873901367}
2022-12-28 21:14:55.126 DEBUG: Taking gradient step
2022-12-28 21:14:55.134 DEBUG: Loss 1: {'policy_loss': -0.01394320174907133, 'entropy_loss': -0.07692102901637554, 'vf_loss': 0.04806218891471925, 'total_loss': -0.04280204185072763, 'approx_kl': 0.0075163686778978445, 'clip_fraction': 0.01953125, 'grad_norm': 12.727304458618164}
2022-12-28 21:14:56.141 DEBUG: Taking gradient step
2022-12-28 21:14:56.149 DEBUG: Loss 2: {'policy_loss': -0.008844514171551177, 'entropy_loss': -0.07730389572679996, 'vf_loss': 0.05052444894232385, 'total_loss': -0.035623960956027295, 'approx_kl': 0.03134155226871371, 'clip_fraction': 0.1809895858168602, 'grad_norm': 6.28673791885376}
2022-12-28 21:14:57.131 DEBUG: Taking gradient step
2022-12-28 21:14:57.139 DEBUG: Loss 3: {'policy_loss': -0.05856886370913107, 'entropy_loss': -0.07710032723844051, 'vf_loss': 0.04290747910749796, 'total_loss': -0.09276171184007362, 'approx_kl': 0.02428929414600134, 'clip_fraction': 0.2486979179084301, 'grad_norm': 7.271649360656738}
2022-12-28 21:14:58.092 DEBUG: Taking gradient step
2022-12-28 21:14:58.100 DEBUG: Loss 4: {'policy_loss': -0.025386125773567757, 'entropy_loss': -0.07613326236605644, 'vf_loss': 0.04772038379573733, 'total_loss': -0.05379900434388688, 'approx_kl': 0.04148231795988977, 'clip_fraction': 0.3059895858168602, 'grad_norm': 8.824588775634766}
2022-12-28 21:14:59.052 DEBUG: Taking gradient step
2022-12-28 21:14:59.060 DEBUG: Loss 5: {'policy_loss': 0.004317792171789694, 'entropy_loss': -0.07721037790179253, 'vf_loss': 0.0524155562852041, 'total_loss': -0.020477029444798733, 'approx_kl': 0.03554793377406895, 'clip_fraction': 0.3502604179084301, 'grad_norm': 7.140078067779541}
2022-12-28 21:15:00.017 DEBUG: Taking gradient step
2022-12-28 21:15:00.024 DEBUG: Loss 6: {'policy_loss': -0.011230910566041183, 'entropy_loss': -0.0773214977234602, 'vf_loss': 0.05006701608695307, 'total_loss': -0.038485392202548305, 'approx_kl': 0.03631815314292908, 'clip_fraction': 0.4049479216337204, 'grad_norm': 8.19722843170166}
2022-12-28 21:15:00.981 DEBUG: Taking gradient step
2022-12-28 21:15:00.988 DEBUG: Loss 7: {'policy_loss': -0.04869789487079494, 'entropy_loss': -0.07700743898749352, 'vf_loss': 0.04746486024424574, 'total_loss': -0.07824047361404271, 'approx_kl': 0.022737114690244198, 'clip_fraction': 0.3541666679084301, 'grad_norm': 6.684138774871826}
2022-12-28 21:15:01.979 DEBUG: Taking gradient step
2022-12-28 21:15:01.987 DEBUG: Loss 8: {'policy_loss': -0.07126076461489833, 'entropy_loss': -0.07793581672012806, 'vf_loss': 0.04473917242456714, 'total_loss': -0.10445740891045925, 'approx_kl': 0.005214618053287268, 'clip_fraction': 0.359375, 'grad_norm': 4.188525199890137}
2022-12-28 21:15:02.928 DEBUG: Taking gradient step
2022-12-28 21:15:02.936 DEBUG: Loss 9: {'policy_loss': -0.06685666492672351, 'entropy_loss': -0.07817150093615055, 'vf_loss': 0.04469824932762657, 'total_loss': -0.10032991653524749, 'approx_kl': -0.012438028119504452, 'clip_fraction': 0.3294270858168602, 'grad_norm': 10.604442596435547}
2022-12-28 21:15:02.936 INFO: Optimization: policy loss=-0.067, vf loss=0.045, entropy loss=-0.078, total loss=-0.100, num steps=10
2022-12-28 21:15:02.937 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 21:15:04.696 INFO: Evaluation rollout: return=0.941 (0.0), episode length=6.0
2022-12-28 21:15:04.698 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 21:15:04.700 INFO: Iteration: 120/137, steps: 25920
2022-12-28 21:15:44.846 DEBUG: There is a single atom floating around
2022-12-28 21:16:04.130 DEBUG: Atoms are too close
2022-12-28 21:16:05.940 INFO: Training rollout: return=-0.279 (4.6), episode length=6.0
2022-12-28 21:16:05.942 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 21:16:05.944 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-25920_train.pkl
2022-12-28 21:16:06.918 DEBUG: Taking gradient step
2022-12-28 21:16:06.930 DEBUG: Loss 0: {'policy_loss': 0.01777044820492192, 'entropy_loss': -0.07780302315950394, 'vf_loss': 0.02301065707283947, 'total_loss': -0.03702191788174256, 'approx_kl': 4.757506388841648e-08, 'clip_fraction': 0.0, 'grad_norm': 14.460805892944336}
2022-12-28 21:16:07.915 DEBUG: Taking gradient step
2022-12-28 21:16:07.923 DEBUG: Loss 1: {'policy_loss': -0.04449117333996074, 'entropy_loss': -0.07746315561234951, 'vf_loss': 0.018159078758267073, 'total_loss': -0.10379525019404318, 'approx_kl': -0.0028323683072812855, 'clip_fraction': 0.0078125, 'grad_norm': 5.661806106567383}
2022-12-28 21:16:08.902 DEBUG: Taking gradient step
2022-12-28 21:16:08.911 DEBUG: Loss 2: {'policy_loss': -0.023434784902394583, 'entropy_loss': -0.07711462862789631, 'vf_loss': 0.020680017284544817, 'total_loss': -0.07986939624574607, 'approx_kl': -0.008482668432407081, 'clip_fraction': 0.07421875, 'grad_norm': 5.778461456298828}
2022-12-28 21:16:09.871 DEBUG: Taking gradient step
2022-12-28 21:16:09.879 DEBUG: Loss 3: {'policy_loss': 0.04701985196817857, 'entropy_loss': -0.07732294499874115, 'vf_loss': 0.027859517438406894, 'total_loss': -0.002443575592155675, 'approx_kl': -0.015453355270437896, 'clip_fraction': 0.1848958358168602, 'grad_norm': 11.520758628845215}
2022-12-28 21:16:10.863 DEBUG: Taking gradient step
2022-12-28 21:16:10.870 DEBUG: Loss 4: {'policy_loss': -0.06243650225712916, 'entropy_loss': -0.07725310325622559, 'vf_loss': 0.0182017607748159, 'total_loss': -0.12148784473853884, 'approx_kl': 0.0005210370291024446, 'clip_fraction': 0.3216145858168602, 'grad_norm': 4.616405487060547}
2022-12-28 21:16:11.903 DEBUG: Taking gradient step
2022-12-28 21:16:11.911 DEBUG: Loss 5: {'policy_loss': -0.016018876417309008, 'entropy_loss': -0.07661166787147522, 'vf_loss': 0.022918385186071307, 'total_loss': -0.06971215910271292, 'approx_kl': -0.011550700291991234, 'clip_fraction': 0.4075520858168602, 'grad_norm': 4.621316432952881}
2022-12-28 21:16:12.907 DEBUG: Taking gradient step
2022-12-28 21:16:12.915 DEBUG: Loss 6: {'policy_loss': -0.04576110912975411, 'entropy_loss': -0.07649505324661732, 'vf_loss': 0.020487472205113984, 'total_loss': -0.10176869017125745, 'approx_kl': -0.02409089799039066, 'clip_fraction': 0.4322916716337204, 'grad_norm': 4.27556848526001}
2022-12-28 21:16:13.867 DEBUG: Taking gradient step
2022-12-28 21:16:13.875 DEBUG: Loss 7: {'policy_loss': -0.05058676304650377, 'entropy_loss': -0.07711373083293438, 'vf_loss': 0.020583841891341076, 'total_loss': -0.10711665198809708, 'approx_kl': -0.037717890460044146, 'clip_fraction': 0.390625, 'grad_norm': 2.504753828048706}
2022-12-28 21:16:14.850 DEBUG: Taking gradient step
2022-12-28 21:16:14.858 DEBUG: Loss 8: {'policy_loss': -0.023885032448898287, 'entropy_loss': -0.0753479152917862, 'vf_loss': 0.02306652413560688, 'total_loss': -0.0761664236050776, 'approx_kl': -0.03858053032308817, 'clip_fraction': 0.4348958432674408, 'grad_norm': 3.068913459777832}
2022-12-28 21:16:15.846 DEBUG: Taking gradient step
2022-12-28 21:16:15.856 DEBUG: Loss 9: {'policy_loss': -0.07444784193782866, 'entropy_loss': -0.07512271590530872, 'vf_loss': 0.018200781344929248, 'total_loss': -0.13136977649820814, 'approx_kl': -0.024472059682011604, 'clip_fraction': 0.4036458358168602, 'grad_norm': 3.0730695724487305}
2022-12-28 21:16:15.857 INFO: Optimization: policy loss=-0.074, vf loss=0.018, entropy loss=-0.075, total loss=-0.131, num steps=10
2022-12-28 21:16:15.857 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 21:16:17.553 INFO: Evaluation rollout: return=0.974 (0.0), episode length=6.0
2022-12-28 21:16:17.555 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 21:16:17.557 DEBUG: Deleting old model: runs/CH3NO_painn/models/CH3NO_painn_run-1_steps-23976.model
2022-12-28 21:16:17.559 DEBUG: Saving model: runs/CH3NO_painn/models/CH3NO_painn_run-1_steps-26136.model
2022-12-28 21:16:17.583 INFO: Iteration: 121/137, steps: 26136
2022-12-28 21:16:32.601 DEBUG: Atoms are too close
2022-12-28 21:17:19.938 INFO: Training rollout: return=0.231 (3.3), episode length=6.0
2022-12-28 21:17:19.939 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 21:17:19.942 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-26136_train.pkl
2022-12-28 21:17:20.962 DEBUG: Taking gradient step
2022-12-28 21:17:20.970 DEBUG: Loss 0: {'policy_loss': 0.013755419226997016, 'entropy_loss': -0.0746275931596756, 'vf_loss': 0.010786898172117716, 'total_loss': -0.05008527576056086, 'approx_kl': -2.242935082108488e-08, 'clip_fraction': 0.0, 'grad_norm': 14.169612884521484}
2022-12-28 21:17:21.935 DEBUG: Taking gradient step
2022-12-28 21:17:21.943 DEBUG: Loss 1: {'policy_loss': -0.03376543375056054, 'entropy_loss': -0.07394841499626637, 'vf_loss': 0.008393400223611996, 'total_loss': -0.09932044852321491, 'approx_kl': -0.0016721126157790422, 'clip_fraction': 0.01953125, 'grad_norm': 4.114201545715332}
2022-12-28 21:17:22.934 DEBUG: Taking gradient step
2022-12-28 21:17:22.942 DEBUG: Loss 2: {'policy_loss': -0.042999787467325995, 'entropy_loss': -0.07411984726786613, 'vf_loss': 0.008394837875199498, 'total_loss': -0.10872479685999262, 'approx_kl': -0.002416230272501707, 'clip_fraction': 0.11458333395421505, 'grad_norm': 3.334789276123047}
2022-12-28 21:17:23.919 DEBUG: Taking gradient step
2022-12-28 21:17:23.928 DEBUG: Loss 3: {'policy_loss': -0.009014783214274569, 'entropy_loss': -0.07339232042431831, 'vf_loss': 0.010688888258269231, 'total_loss': -0.07171821538032364, 'approx_kl': 0.0003986726514995098, 'clip_fraction': 0.22265625, 'grad_norm': 3.2949864864349365}
2022-12-28 21:17:24.908 DEBUG: Taking gradient step
2022-12-28 21:17:24.916 DEBUG: Loss 4: {'policy_loss': -0.04595073420176766, 'entropy_loss': -0.07296252995729446, 'vf_loss': 0.008338138464353464, 'total_loss': -0.11057512569470865, 'approx_kl': -0.005541609367355704, 'clip_fraction': 0.2356770858168602, 'grad_norm': 4.124563217163086}
2022-12-28 21:17:25.885 DEBUG: Taking gradient step
2022-12-28 21:17:25.893 DEBUG: Loss 5: {'policy_loss': 0.014901698732097457, 'entropy_loss': -0.07300289534032345, 'vf_loss': 0.012985672886464909, 'total_loss': -0.045115523721761086, 'approx_kl': 0.01065103430300951, 'clip_fraction': 0.24609375, 'grad_norm': 2.9685025215148926}
2022-12-28 21:17:26.840 DEBUG: Taking gradient step
2022-12-28 21:17:26.849 DEBUG: Loss 6: {'policy_loss': -0.05620552443194083, 'entropy_loss': -0.07256976701319218, 'vf_loss': 0.008244772338787754, 'total_loss': -0.12053051910634524, 'approx_kl': -0.005215354263782501, 'clip_fraction': 0.2591145858168602, 'grad_norm': 4.975887298583984}
2022-12-28 21:17:27.905 DEBUG: Taking gradient step
2022-12-28 21:17:27.917 DEBUG: Loss 7: {'policy_loss': -0.057568402164833325, 'entropy_loss': -0.07307174615561962, 'vf_loss': 0.008170683922255834, 'total_loss': -0.12246946439819713, 'approx_kl': -0.008058207109570503, 'clip_fraction': 0.29296875, 'grad_norm': 3.2004477977752686}
2022-12-28 21:17:28.879 DEBUG: Taking gradient step
2022-12-28 21:17:28.887 DEBUG: Loss 8: {'policy_loss': 0.016436375221020386, 'entropy_loss': -0.07216721400618553, 'vf_loss': 0.012772239237972695, 'total_loss': -0.042958599547192444, 'approx_kl': 0.012961780885234475, 'clip_fraction': 0.3307291716337204, 'grad_norm': 1.847746729850769}
2022-12-28 21:17:29.876 DEBUG: Taking gradient step
2022-12-28 21:17:29.884 DEBUG: Loss 9: {'policy_loss': -0.014566499646750317, 'entropy_loss': -0.07212482765316963, 'vf_loss': 0.010360576351109731, 'total_loss': -0.07633075094881023, 'approx_kl': 0.02257178258150816, 'clip_fraction': 0.3606770858168602, 'grad_norm': 2.0473668575286865}
2022-12-28 21:17:29.884 INFO: Optimization: policy loss=-0.015, vf loss=0.010, entropy loss=-0.072, total loss=-0.076, num steps=10
2022-12-28 21:17:29.885 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 21:17:31.727 INFO: Evaluation rollout: return=0.894 (0.0), episode length=6.0
2022-12-28 21:17:31.728 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 21:17:31.730 INFO: Iteration: 122/137, steps: 26352
2022-12-28 21:17:44.947 DEBUG: Atoms are too close
2022-12-28 21:18:11.763 DEBUG: Atoms are too close
2022-12-28 21:18:33.514 INFO: Training rollout: return=-0.277 (4.6), episode length=6.0
2022-12-28 21:18:33.515 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 21:18:33.518 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-26352_train.pkl
2022-12-28 21:18:34.546 DEBUG: Taking gradient step
2022-12-28 21:18:34.556 DEBUG: Loss 0: {'policy_loss': -0.006081810200111127, 'entropy_loss': -0.07353838719427586, 'vf_loss': 0.019012804048821955, 'total_loss': -0.06060739334556503, 'approx_kl': 1.569666530087943e-08, 'clip_fraction': 0.0, 'grad_norm': 11.756499290466309}
2022-12-28 21:18:35.513 DEBUG: Taking gradient step
2022-12-28 21:18:35.521 DEBUG: Loss 1: {'policy_loss': -0.015779641984620507, 'entropy_loss': -0.07343321852385998, 'vf_loss': 0.019020333535349872, 'total_loss': -0.07019252697313061, 'approx_kl': 0.008389240014366806, 'clip_fraction': 0.04296875, 'grad_norm': 8.427061080932617}
2022-12-28 21:18:36.488 DEBUG: Taking gradient step
2022-12-28 21:18:36.496 DEBUG: Loss 2: {'policy_loss': -0.02416361776356382, 'entropy_loss': -0.07251272723078728, 'vf_loss': 0.019069650308254634, 'total_loss': -0.07760669468609646, 'approx_kl': 0.031568297650665045, 'clip_fraction': 0.1901041679084301, 'grad_norm': 10.79344654083252}
2022-12-28 21:18:37.453 DEBUG: Taking gradient step
2022-12-28 21:18:37.461 DEBUG: Loss 3: {'policy_loss': 0.019003490515457758, 'entropy_loss': -0.07281226105988026, 'vf_loss': 0.02402554721652051, 'total_loss': -0.029783223327901995, 'approx_kl': 0.028088432038202882, 'clip_fraction': 0.3151041716337204, 'grad_norm': 8.272660255432129}
2022-12-28 21:18:38.425 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-28 21:18:38.426 INFO: Optimization: policy loss=0.019, vf loss=0.024, entropy loss=-0.073, total loss=-0.030, num steps=4
2022-12-28 21:18:38.426 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 21:18:40.314 INFO: Evaluation rollout: return=0.904 (0.0), episode length=6.0
2022-12-28 21:18:40.315 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 21:18:40.318 INFO: Iteration: 123/137, steps: 26568
2022-12-28 21:19:19.387 DEBUG: There is a single atom floating around
2022-12-28 21:19:20.292 DEBUG: Atoms are too close
2022-12-28 21:19:42.055 INFO: Training rollout: return=-0.248 (4.6), episode length=6.0
2022-12-28 21:19:42.059 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 21:19:42.061 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-26568_train.pkl
2022-12-28 21:19:43.056 DEBUG: Taking gradient step
2022-12-28 21:19:43.064 DEBUG: Loss 0: {'policy_loss': -0.008876379944109718, 'entropy_loss': -0.0715974010527134, 'vf_loss': 0.02055911844120393, 'total_loss': -0.059914662555619176, 'approx_kl': 1.4253116376039543e-07, 'clip_fraction': 0.0, 'grad_norm': 10.284224510192871}
2022-12-28 21:19:44.093 DEBUG: Taking gradient step
2022-12-28 21:19:44.101 DEBUG: Loss 1: {'policy_loss': -0.025348256239021726, 'entropy_loss': -0.07142987847328186, 'vf_loss': 0.020615809283144763, 'total_loss': -0.07616232542915882, 'approx_kl': -0.0016952954465523362, 'clip_fraction': 0.01953125, 'grad_norm': 13.510773658752441}
2022-12-28 21:19:45.045 DEBUG: Taking gradient step
2022-12-28 21:19:45.054 DEBUG: Loss 2: {'policy_loss': -0.03173222355443904, 'entropy_loss': -0.07137900404632092, 'vf_loss': 0.020570840562710566, 'total_loss': -0.08254038703804939, 'approx_kl': -0.0002684192731976509, 'clip_fraction': 0.2669270858168602, 'grad_norm': 4.032352924346924}
2022-12-28 21:19:46.003 DEBUG: Taking gradient step
2022-12-28 21:19:46.012 DEBUG: Loss 3: {'policy_loss': -0.004756406102358942, 'entropy_loss': -0.07164912112057209, 'vf_loss': 0.02302161728927124, 'total_loss': -0.053383909933659796, 'approx_kl': 0.03274827217683196, 'clip_fraction': 0.3815104216337204, 'grad_norm': 4.334475040435791}
2022-12-28 21:19:46.993 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-28 21:19:46.993 INFO: Optimization: policy loss=-0.005, vf loss=0.023, entropy loss=-0.072, total loss=-0.053, num steps=4
2022-12-28 21:19:46.994 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 21:19:48.767 INFO: Evaluation rollout: return=0.990 (0.0), episode length=6.0
2022-12-28 21:19:48.768 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 21:19:48.771 INFO: Iteration: 124/137, steps: 26784
2022-12-28 21:20:29.318 DEBUG: Atoms are too close
2022-12-28 21:20:49.908 DEBUG: Atoms are too close
2022-12-28 21:20:50.890 INFO: Training rollout: return=-0.235 (4.6), episode length=6.0
2022-12-28 21:20:50.891 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 21:20:50.894 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-26784_train.pkl
2022-12-28 21:20:51.889 DEBUG: Taking gradient step
2022-12-28 21:20:51.897 DEBUG: Loss 0: {'policy_loss': -0.00944692803511489, 'entropy_loss': -0.07395409233868122, 'vf_loss': 0.020714082957382862, 'total_loss': -0.06268693741641324, 'approx_kl': -7.683411240577698e-09, 'clip_fraction': 0.0, 'grad_norm': 21.679595947265625}
2022-12-28 21:20:52.845 DEBUG: Taking gradient step
2022-12-28 21:20:52.852 DEBUG: Loss 1: {'policy_loss': 0.03965115341399641, 'entropy_loss': -0.07375187054276466, 'vf_loss': 0.025502594847182716, 'total_loss': -0.008598122281585546, 'approx_kl': -0.0002757840557023883, 'clip_fraction': 0.0, 'grad_norm': 19.940622329711914}
2022-12-28 21:20:53.874 DEBUG: Taking gradient step
2022-12-28 21:20:53.883 DEBUG: Loss 2: {'policy_loss': -0.05335672806787913, 'entropy_loss': -0.07358733005821705, 'vf_loss': 0.018224748730102838, 'total_loss': -0.10871930939599334, 'approx_kl': 0.002521150279790163, 'clip_fraction': 0.08333333395421505, 'grad_norm': 6.321200847625732}
2022-12-28 21:20:54.960 DEBUG: Taking gradient step
2022-12-28 21:20:54.974 DEBUG: Loss 3: {'policy_loss': -0.008385537256909513, 'entropy_loss': -0.07349070720374584, 'vf_loss': 0.02313449231116991, 'total_loss': -0.05874175214948546, 'approx_kl': 0.019421269418671727, 'clip_fraction': 0.171875, 'grad_norm': 5.276453018188477}
2022-12-28 21:20:55.993 DEBUG: Taking gradient step
2022-12-28 21:20:56.001 DEBUG: Loss 4: {'policy_loss': -0.055819003045164024, 'entropy_loss': -0.07370143011212349, 'vf_loss': 0.018216981413426484, 'total_loss': -0.11130345174386104, 'approx_kl': 0.021251028403639793, 'clip_fraction': 0.20963541697710752, 'grad_norm': 4.932944297790527}
2022-12-28 21:20:56.962 DEBUG: Taking gradient step
2022-12-28 21:20:56.970 DEBUG: Loss 5: {'policy_loss': -0.029266641995730928, 'entropy_loss': -0.0734363067895174, 'vf_loss': 0.02071149394899293, 'total_loss': -0.08199145483625539, 'approx_kl': 0.027795759728178382, 'clip_fraction': 0.2708333358168602, 'grad_norm': 3.4788966178894043}
2022-12-28 21:20:58.034 DEBUG: Taking gradient step
2022-12-28 21:20:58.041 DEBUG: Loss 6: {'policy_loss': -0.011109169676222878, 'entropy_loss': -0.07381770014762878, 'vf_loss': 0.023091294022892776, 'total_loss': -0.0618355758009589, 'approx_kl': 0.022378955269232392, 'clip_fraction': 0.2799479216337204, 'grad_norm': 4.064529895782471}
2022-12-28 21:20:58.989 DEBUG: Taking gradient step
2022-12-28 21:20:58.996 DEBUG: Loss 7: {'policy_loss': -0.06358600333277685, 'entropy_loss': -0.07248303666710854, 'vf_loss': 0.018168923355140757, 'total_loss': -0.11790011664474462, 'approx_kl': 0.014041067333891988, 'clip_fraction': 0.2473958358168602, 'grad_norm': 3.827382802963257}
2022-12-28 21:20:59.953 DEBUG: Taking gradient step
2022-12-28 21:20:59.961 DEBUG: Loss 8: {'policy_loss': -0.02095516378283413, 'entropy_loss': -0.0738583579659462, 'vf_loss': 0.02314606653271569, 'total_loss': -0.07166745521606464, 'approx_kl': 0.014992707641795278, 'clip_fraction': 0.3072916679084301, 'grad_norm': 6.6331868171691895}
2022-12-28 21:21:00.915 DEBUG: Taking gradient step
2022-12-28 21:21:00.923 DEBUG: Loss 9: {'policy_loss': -0.044006604812427914, 'entropy_loss': -0.07382728718221188, 'vf_loss': 0.020560883909147263, 'total_loss': -0.09727300808549252, 'approx_kl': 0.012566891266033053, 'clip_fraction': 0.3450520858168602, 'grad_norm': 6.354110240936279}
2022-12-28 21:21:00.923 INFO: Optimization: policy loss=-0.044, vf loss=0.021, entropy loss=-0.074, total loss=-0.097, num steps=10
2022-12-28 21:21:00.924 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 21:21:02.790 INFO: Evaluation rollout: return=0.995 (0.0), episode length=6.0
2022-12-28 21:21:02.792 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 21:21:02.796 INFO: Iteration: 125/137, steps: 27000
2022-12-28 21:22:05.244 INFO: Training rollout: return=0.877 (0.1), episode length=6.0
2022-12-28 21:22:05.245 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 21:22:05.248 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-27000_train.pkl
2022-12-28 21:22:06.223 DEBUG: Taking gradient step
2022-12-28 21:22:06.231 DEBUG: Loss 0: {'policy_loss': 0.008057680300303436, 'entropy_loss': -0.07380369864404202, 'vf_loss': 0.0006705509422270284, 'total_loss': -0.06507546740151154, 'approx_kl': -5.529727786779404e-09, 'clip_fraction': 0.0, 'grad_norm': 18.33440589904785}
2022-12-28 21:22:07.189 DEBUG: Taking gradient step
2022-12-28 21:22:07.197 DEBUG: Loss 1: {'policy_loss': -0.07531346796528716, 'entropy_loss': -0.07356412149965763, 'vf_loss': 0.0007180169865201752, 'total_loss': -0.14815957247842462, 'approx_kl': -0.003061596847146575, 'clip_fraction': 0.0078125, 'grad_norm': 15.250947952270508}
2022-12-28 21:22:08.173 DEBUG: Taking gradient step
2022-12-28 21:22:08.181 DEBUG: Loss 2: {'policy_loss': 0.005356179477478497, 'entropy_loss': -0.07365739531815052, 'vf_loss': 0.000698197178497913, 'total_loss': -0.06760301866217411, 'approx_kl': -0.00035731703974306583, 'clip_fraction': 0.15364583395421505, 'grad_norm': 17.48615074157715}
2022-12-28 21:22:09.154 DEBUG: Taking gradient step
2022-12-28 21:22:09.161 DEBUG: Loss 3: {'policy_loss': 0.02461002526886895, 'entropy_loss': -0.07419683784246445, 'vf_loss': 0.0006924070936591303, 'total_loss': -0.04889440547993637, 'approx_kl': 0.01571875438094139, 'clip_fraction': 0.2317708358168602, 'grad_norm': 14.184478759765625}
2022-12-28 21:22:10.113 DEBUG: Taking gradient step
2022-12-28 21:22:10.125 DEBUG: Loss 4: {'policy_loss': -0.06286622390005019, 'entropy_loss': -0.07336818054318428, 'vf_loss': 0.0007316416543656846, 'total_loss': -0.13550276278886877, 'approx_kl': 0.019753979053348303, 'clip_fraction': 0.3203125, 'grad_norm': 15.56429672241211}
2022-12-28 21:22:11.119 DEBUG: Taking gradient step
2022-12-28 21:22:11.127 DEBUG: Loss 5: {'policy_loss': -0.05327645321181052, 'entropy_loss': -0.07354247570037842, 'vf_loss': 0.000726236800885204, 'total_loss': -0.12609269211130372, 'approx_kl': 0.03268934052903205, 'clip_fraction': 0.3059895858168602, 'grad_norm': 7.6780900955200195}
2022-12-28 21:22:12.099 DEBUG: Early stopping at step 6 for reaching max KL.
2022-12-28 21:22:12.100 INFO: Optimization: policy loss=-0.053, vf loss=0.001, entropy loss=-0.074, total loss=-0.126, num steps=6
2022-12-28 21:22:12.100 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 21:22:13.822 INFO: Evaluation rollout: return=1.006 (0.0), episode length=6.0
2022-12-28 21:22:13.825 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 21:22:13.828 INFO: Iteration: 126/137, steps: 27216
2022-12-28 21:23:15.935 INFO: Training rollout: return=0.873 (0.1), episode length=6.0
2022-12-28 21:23:15.936 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 21:23:15.939 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-27216_train.pkl
2022-12-28 21:23:16.952 DEBUG: Taking gradient step
2022-12-28 21:23:16.960 DEBUG: Loss 0: {'policy_loss': 0.05160097692767377, 'entropy_loss': -0.07374823652207851, 'vf_loss': 0.0006910398654236206, 'total_loss': -0.021456219728981124, 'approx_kl': 5.277492221011926e-09, 'clip_fraction': 0.0, 'grad_norm': 14.02383041381836}
2022-12-28 21:23:17.924 DEBUG: Taking gradient step
2022-12-28 21:23:17.933 DEBUG: Loss 1: {'policy_loss': -0.007588204690029493, 'entropy_loss': -0.07294911332428455, 'vf_loss': 0.0007068480677661354, 'total_loss': -0.07983046994654791, 'approx_kl': 0.023893512901850045, 'clip_fraction': 0.1432291679084301, 'grad_norm': 15.093531608581543}
2022-12-28 21:23:18.935 DEBUG: Taking gradient step
2022-12-28 21:23:18.943 DEBUG: Loss 2: {'policy_loss': 0.07581548153460298, 'entropy_loss': -0.07293768972158432, 'vf_loss': 0.0006712591567979851, 'total_loss': 0.0035490509698166417, 'approx_kl': 0.042526662815362215, 'clip_fraction': 0.2981770858168602, 'grad_norm': 24.364900588989258}
2022-12-28 21:23:19.988 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-28 21:23:19.989 INFO: Optimization: policy loss=0.076, vf loss=0.001, entropy loss=-0.073, total loss=0.004, num steps=3
2022-12-28 21:23:19.989 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 21:23:21.753 INFO: Evaluation rollout: return=1.013 (0.0), episode length=6.0
2022-12-28 21:23:21.754 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 21:23:21.757 INFO: Iteration: 127/137, steps: 27432
2022-12-28 21:23:32.202 DEBUG: Atoms are too close
2022-12-28 21:23:54.802 DEBUG: Atoms are too close
2022-12-28 21:24:23.746 INFO: Training rollout: return=-0.263 (4.6), episode length=5.9
2022-12-28 21:24:23.748 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 21:24:23.750 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-27432_train.pkl
2022-12-28 21:24:24.741 DEBUG: Taking gradient step
2022-12-28 21:24:24.748 DEBUG: Loss 0: {'policy_loss': -0.029361306379843417, 'entropy_loss': -0.07300850749015808, 'vf_loss': 0.012638099712503703, 'total_loss': -0.0897317141574978, 'approx_kl': -3.7175293066127324e-08, 'clip_fraction': 0.0, 'grad_norm': 11.649581909179688}
2022-12-28 21:24:25.749 DEBUG: Taking gradient step
2022-12-28 21:24:25.757 DEBUG: Loss 1: {'policy_loss': -0.03666270150854655, 'entropy_loss': -0.07317070476710796, 'vf_loss': 0.01266329716948462, 'total_loss': -0.0971701091061699, 'approx_kl': -0.00023834867170080543, 'clip_fraction': 0.014322916977107525, 'grad_norm': 10.250672340393066}
2022-12-28 21:24:26.726 DEBUG: Taking gradient step
2022-12-28 21:24:26.734 DEBUG: Loss 2: {'policy_loss': -0.013044166951402585, 'entropy_loss': -0.07260956056416035, 'vf_loss': 0.01504888634813666, 'total_loss': -0.07060484116742627, 'approx_kl': 0.0012483724858611822, 'clip_fraction': 0.09505208395421505, 'grad_norm': 4.214017868041992}
2022-12-28 21:24:27.685 DEBUG: Taking gradient step
2022-12-28 21:24:27.694 DEBUG: Loss 3: {'policy_loss': -0.017200683789215944, 'entropy_loss': -0.07242412678897381, 'vf_loss': 0.015167804858411495, 'total_loss': -0.07445700571977827, 'approx_kl': 0.00438318494707346, 'clip_fraction': 0.1653645858168602, 'grad_norm': 8.224210739135742}
2022-12-28 21:24:28.684 DEBUG: Taking gradient step
2022-12-28 21:24:28.692 DEBUG: Loss 4: {'policy_loss': 0.021622291447126143, 'entropy_loss': -0.07337016984820366, 'vf_loss': 0.01744176712784972, 'total_loss': -0.034306111273227795, 'approx_kl': 0.01744217425584793, 'clip_fraction': 0.29296875, 'grad_norm': 4.074294567108154}
2022-12-28 21:24:29.665 DEBUG: Taking gradient step
2022-12-28 21:24:29.673 DEBUG: Loss 5: {'policy_loss': 0.013432897559542911, 'entropy_loss': -0.07293833419680595, 'vf_loss': 0.017576568908494274, 'total_loss': -0.041928867728768755, 'approx_kl': 0.03719704900868237, 'clip_fraction': 0.2890625, 'grad_norm': 5.268617153167725}
2022-12-28 21:24:30.643 DEBUG: Early stopping at step 6 for reaching max KL.
2022-12-28 21:24:30.644 INFO: Optimization: policy loss=0.013, vf loss=0.018, entropy loss=-0.073, total loss=-0.042, num steps=6
2022-12-28 21:24:30.644 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 21:24:32.445 INFO: Evaluation rollout: return=0.991 (0.0), episode length=6.0
2022-12-28 21:24:32.447 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 21:24:32.449 INFO: Iteration: 128/137, steps: 27648
2022-12-28 21:25:34.346 INFO: Training rollout: return=0.821 (0.1), episode length=6.0
2022-12-28 21:25:34.347 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 21:25:34.350 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-27648_train.pkl
2022-12-28 21:25:35.349 DEBUG: Taking gradient step
2022-12-28 21:25:35.357 DEBUG: Loss 0: {'policy_loss': 0.0473999500579053, 'entropy_loss': -0.07373673655092716, 'vf_loss': 0.0005435054169610135, 'total_loss': -0.025793281076060867, 'approx_kl': -4.423782229423523e-08, 'clip_fraction': 0.0, 'grad_norm': 11.175015449523926}
2022-12-28 21:25:36.321 DEBUG: Taking gradient step
2022-12-28 21:25:36.329 DEBUG: Loss 1: {'policy_loss': -0.05805459540548366, 'entropy_loss': -0.07341692969202995, 'vf_loss': 0.0005585311789874621, 'total_loss': -0.13091299391852615, 'approx_kl': 0.0009277691133320332, 'clip_fraction': 0.01171875, 'grad_norm': 12.45959758758545}
2022-12-28 21:25:37.298 DEBUG: Taking gradient step
2022-12-28 21:25:37.306 DEBUG: Loss 2: {'policy_loss': -0.022563146600156042, 'entropy_loss': -0.07399802841246128, 'vf_loss': 0.000517934449750453, 'total_loss': -0.09604324056286688, 'approx_kl': 0.01404863316565752, 'clip_fraction': 0.1080729179084301, 'grad_norm': 8.166718482971191}
2022-12-28 21:25:38.277 DEBUG: Taking gradient step
2022-12-28 21:25:38.285 DEBUG: Loss 3: {'policy_loss': -0.042728566702851564, 'entropy_loss': -0.07341512478888035, 'vf_loss': 0.0005025149248781902, 'total_loss': -0.11564117656685372, 'approx_kl': 0.019050363771384582, 'clip_fraction': 0.2239583358168602, 'grad_norm': 6.88931131362915}
2022-12-28 21:25:39.253 DEBUG: Taking gradient step
2022-12-28 21:25:39.261 DEBUG: Loss 4: {'policy_loss': -0.01857456561749063, 'entropy_loss': -0.07298515364527702, 'vf_loss': 0.00047930728349075306, 'total_loss': -0.09108041197927688, 'approx_kl': 0.03526004124432802, 'clip_fraction': 0.2864583358168602, 'grad_norm': 12.02885913848877}
2022-12-28 21:25:40.226 DEBUG: Early stopping at step 5 for reaching max KL.
2022-12-28 21:25:40.226 INFO: Optimization: policy loss=-0.019, vf loss=0.000, entropy loss=-0.073, total loss=-0.091, num steps=5
2022-12-28 21:25:40.227 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 21:25:42.095 INFO: Evaluation rollout: return=1.018 (0.0), episode length=6.0
2022-12-28 21:25:42.096 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 21:25:42.099 INFO: Iteration: 129/137, steps: 27864
2022-12-28 21:26:45.613 INFO: Training rollout: return=0.844 (0.1), episode length=6.0
2022-12-28 21:26:45.614 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 21:26:45.616 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-27864_train.pkl
2022-12-28 21:26:46.598 DEBUG: Taking gradient step
2022-12-28 21:26:46.606 DEBUG: Loss 0: {'policy_loss': -0.011711716114127205, 'entropy_loss': -0.0721678901463747, 'vf_loss': 0.00047520230011323134, 'total_loss': -0.08340440396038867, 'approx_kl': 5.745096132159233e-08, 'clip_fraction': 0.0, 'grad_norm': 16.156312942504883}
2022-12-28 21:26:47.562 DEBUG: Taking gradient step
2022-12-28 21:26:47.571 DEBUG: Loss 1: {'policy_loss': 0.022118314311349474, 'entropy_loss': -0.07312381640076637, 'vf_loss': 0.0004354170563515648, 'total_loss': -0.05057008503306534, 'approx_kl': 0.010430777096189559, 'clip_fraction': 0.033854166977107525, 'grad_norm': 7.629964351654053}
2022-12-28 21:26:48.525 DEBUG: Taking gradient step
2022-12-28 21:26:48.532 DEBUG: Loss 2: {'policy_loss': 0.0014221603823654644, 'entropy_loss': -0.07310100644826889, 'vf_loss': 0.0004281126469618834, 'total_loss': -0.07125073341894153, 'approx_kl': 0.035757024539634585, 'clip_fraction': 0.2096354216337204, 'grad_norm': 10.462964057922363}
2022-12-28 21:26:49.537 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-28 21:26:49.538 INFO: Optimization: policy loss=0.001, vf loss=0.000, entropy loss=-0.073, total loss=-0.071, num steps=3
2022-12-28 21:26:49.538 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 21:26:51.322 INFO: Evaluation rollout: return=1.011 (0.0), episode length=6.0
2022-12-28 21:26:51.323 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 21:26:51.325 INFO: Iteration: 130/137, steps: 28080
2022-12-28 21:27:07.638 DEBUG: Atoms are too close
2022-12-28 21:27:49.566 DEBUG: There is a single atom floating around
2022-12-28 21:27:52.620 INFO: Training rollout: return=-0.210 (4.6), episode length=6.0
2022-12-28 21:27:52.622 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 21:27:52.624 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-28080_train.pkl
2022-12-28 21:27:53.673 DEBUG: Taking gradient step
2022-12-28 21:27:53.683 DEBUG: Loss 0: {'policy_loss': 0.02270952525061153, 'entropy_loss': -0.07284600287675858, 'vf_loss': 0.021839716792819035, 'total_loss': -0.028296760833328, 'approx_kl': -8.917413651943207e-08, 'clip_fraction': 0.0, 'grad_norm': 25.57727813720703}
2022-12-28 21:27:54.656 DEBUG: Taking gradient step
2022-12-28 21:27:54.664 DEBUG: Loss 1: {'policy_loss': -0.0160156925224355, 'entropy_loss': -0.0741090439260006, 'vf_loss': 0.01930680266303688, 'total_loss': -0.07081793378539922, 'approx_kl': -0.0009015440009534359, 'clip_fraction': 0.09635416697710752, 'grad_norm': 13.021368026733398}
2022-12-28 21:27:55.635 DEBUG: Taking gradient step
2022-12-28 21:27:55.643 DEBUG: Loss 2: {'policy_loss': -0.05356765662856215, 'entropy_loss': -0.07349717430770397, 'vf_loss': 0.016794903770081904, 'total_loss': -0.11026992716618421, 'approx_kl': -0.011404952965676785, 'clip_fraction': 0.2903645858168602, 'grad_norm': 6.507087230682373}
2022-12-28 21:27:56.599 DEBUG: Taking gradient step
2022-12-28 21:27:56.609 DEBUG: Loss 3: {'policy_loss': 0.03900790704700846, 'entropy_loss': -0.0738091804087162, 'vf_loss': 0.024075406320334627, 'total_loss': -0.010725867041373113, 'approx_kl': 0.02423809701576829, 'clip_fraction': 0.40625, 'grad_norm': 4.911637783050537}
2022-12-28 21:27:57.593 DEBUG: Taking gradient step
2022-12-28 21:27:57.604 DEBUG: Loss 4: {'policy_loss': -0.05029423534971185, 'entropy_loss': -0.07450959272682667, 'vf_loss': 0.016764274344970846, 'total_loss': -0.10803955373156766, 'approx_kl': 0.024908725812565535, 'clip_fraction': 0.4036458358168602, 'grad_norm': 3.731382369995117}
2022-12-28 21:27:58.578 DEBUG: Taking gradient step
2022-12-28 21:27:58.586 DEBUG: Loss 5: {'policy_loss': -0.050447816474908626, 'entropy_loss': -0.07387865148484707, 'vf_loss': 0.016753867204335637, 'total_loss': -0.10757260075542005, 'approx_kl': 0.0366858821362257, 'clip_fraction': 0.4140625, 'grad_norm': 3.5502495765686035}
2022-12-28 21:27:59.552 DEBUG: Taking gradient step
2022-12-28 21:27:59.560 DEBUG: Loss 6: {'policy_loss': -0.03102095584051775, 'entropy_loss': -0.0749776791781187, 'vf_loss': 0.01924895408493626, 'total_loss': -0.0867496809337002, 'approx_kl': 0.030900418758392334, 'clip_fraction': 0.3541666716337204, 'grad_norm': 3.1210663318634033}
2022-12-28 21:28:00.510 DEBUG: Taking gradient step
2022-12-28 21:28:00.517 DEBUG: Loss 7: {'policy_loss': 0.014751648108842871, 'entropy_loss': -0.0734694842249155, 'vf_loss': 0.024194470376703248, 'total_loss': -0.034523365739369385, 'approx_kl': 0.011233811965212226, 'clip_fraction': 0.3203125, 'grad_norm': 2.4890754222869873}
2022-12-28 21:28:01.463 DEBUG: Taking gradient step
2022-12-28 21:28:01.471 DEBUG: Loss 8: {'policy_loss': 0.012152490977844273, 'entropy_loss': -0.07444155216217041, 'vf_loss': 0.02418060317708565, 'total_loss': -0.038108458007240484, 'approx_kl': 0.00026474536571186036, 'clip_fraction': 0.3151041716337204, 'grad_norm': 3.061038017272949}
2022-12-28 21:28:02.441 DEBUG: Taking gradient step
2022-12-28 21:28:02.449 DEBUG: Loss 9: {'policy_loss': -0.016912103037552435, 'entropy_loss': -0.07461323589086533, 'vf_loss': 0.02151753002782925, 'total_loss': -0.07000780890058851, 'approx_kl': -2.613931428641081e-05, 'clip_fraction': 0.3815104216337204, 'grad_norm': 4.123467922210693}
2022-12-28 21:28:02.449 INFO: Optimization: policy loss=-0.017, vf loss=0.022, entropy loss=-0.075, total loss=-0.070, num steps=10
2022-12-28 21:28:02.450 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 21:28:04.337 INFO: Evaluation rollout: return=0.909 (0.0), episode length=6.0
2022-12-28 21:28:04.339 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 21:28:04.342 DEBUG: Deleting old model: runs/CH3NO_painn/models/CH3NO_painn_run-1_steps-26136.model
2022-12-28 21:28:04.346 DEBUG: Saving model: runs/CH3NO_painn/models/CH3NO_painn_run-1_steps-28296.model
2022-12-28 21:28:04.370 INFO: Iteration: 131/137, steps: 28296
2022-12-28 21:28:24.795 DEBUG: Atoms are too close
2022-12-28 21:29:07.595 INFO: Training rollout: return=0.299 (3.3), episode length=6.0
2022-12-28 21:29:07.597 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 21:29:07.599 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-28296_train.pkl
2022-12-28 21:29:08.596 DEBUG: Taking gradient step
2022-12-28 21:29:08.607 DEBUG: Loss 0: {'policy_loss': -0.02512894702210324, 'entropy_loss': -0.07696611434221268, 'vf_loss': 0.0093182455013267, 'total_loss': -0.09277681586298922, 'approx_kl': 9.778887033462524e-09, 'clip_fraction': 0.0, 'grad_norm': 9.604684829711914}
2022-12-28 21:29:09.584 DEBUG: Taking gradient step
2022-12-28 21:29:09.592 DEBUG: Loss 1: {'policy_loss': -0.02807018166549137, 'entropy_loss': -0.07686552964150906, 'vf_loss': 0.009324620193805618, 'total_loss': -0.09561109111319482, 'approx_kl': -0.003401024267077446, 'clip_fraction': 0.022135416977107525, 'grad_norm': 9.474976539611816}
2022-12-28 21:29:10.591 DEBUG: Taking gradient step
2022-12-28 21:29:10.599 DEBUG: Loss 2: {'policy_loss': 0.0002875524901548264, 'entropy_loss': -0.0776512660086155, 'vf_loss': 0.011697239140410088, 'total_loss': -0.06566647437805057, 'approx_kl': 0.0017851912416517735, 'clip_fraction': 0.1002604179084301, 'grad_norm': 8.812516212463379}
2022-12-28 21:29:11.598 DEBUG: Taking gradient step
2022-12-28 21:29:11.605 DEBUG: Loss 3: {'policy_loss': -0.04740646993186755, 'entropy_loss': -0.07644540816545486, 'vf_loss': 0.009330724842121928, 'total_loss': -0.11452115325520049, 'approx_kl': -0.004164044046774507, 'clip_fraction': 0.1666666679084301, 'grad_norm': 3.021693229675293}
2022-12-28 21:29:12.561 DEBUG: Taking gradient step
2022-12-28 21:29:12.574 DEBUG: Loss 4: {'policy_loss': -0.04274915805728345, 'entropy_loss': -0.07697982899844646, 'vf_loss': 0.009296137429034379, 'total_loss': -0.11043284962669553, 'approx_kl': -9.176204912364483e-05, 'clip_fraction': 0.234375, 'grad_norm': 2.889772891998291}
2022-12-28 21:29:13.571 DEBUG: Taking gradient step
2022-12-28 21:29:13.579 DEBUG: Loss 5: {'policy_loss': -0.04469508451818295, 'entropy_loss': -0.07633575610816479, 'vf_loss': 0.00929469655205519, 'total_loss': -0.11173614407429255, 'approx_kl': -0.0036080459831282496, 'clip_fraction': 0.2734375, 'grad_norm': 2.2672786712646484}
2022-12-28 21:29:14.538 DEBUG: Taking gradient step
2022-12-28 21:29:14.547 DEBUG: Loss 6: {'policy_loss': -0.013820096470181169, 'entropy_loss': -0.07706090435385704, 'vf_loss': 0.011656416648525222, 'total_loss': -0.07922458417551298, 'approx_kl': -0.019640683196485043, 'clip_fraction': 0.3307291716337204, 'grad_norm': 2.5879011154174805}
2022-12-28 21:29:15.525 DEBUG: Taking gradient step
2022-12-28 21:29:15.534 DEBUG: Loss 7: {'policy_loss': 0.012272153574398731, 'entropy_loss': -0.0775335505604744, 'vf_loss': 0.014213889832428358, 'total_loss': -0.05104750715364731, 'approx_kl': -0.005458775907754898, 'clip_fraction': 0.4127604216337204, 'grad_norm': 2.9211606979370117}
2022-12-28 21:29:16.540 DEBUG: Taking gradient step
2022-12-28 21:29:16.548 DEBUG: Loss 8: {'policy_loss': -0.057069352964993256, 'entropy_loss': -0.07726032100617886, 'vf_loss': 0.009293673146318645, 'total_loss': -0.12503600082485347, 'approx_kl': -0.03266922169132158, 'clip_fraction': 0.4114583358168602, 'grad_norm': 2.238759994506836}
2022-12-28 21:29:17.513 DEBUG: Taking gradient step
2022-12-28 21:29:17.521 DEBUG: Loss 9: {'policy_loss': -0.056139254689577256, 'entropy_loss': -0.07680083625018597, 'vf_loss': 0.009277029014484933, 'total_loss': -0.12366306192527828, 'approx_kl': -0.0476299412548542, 'clip_fraction': 0.4153645858168602, 'grad_norm': 4.67233419418335}
2022-12-28 21:29:17.521 INFO: Optimization: policy loss=-0.056, vf loss=0.009, entropy loss=-0.077, total loss=-0.124, num steps=10
2022-12-28 21:29:17.522 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 21:29:19.452 INFO: Evaluation rollout: return=1.099 (0.0), episode length=6.0
2022-12-28 21:29:19.453 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 21:29:19.455 INFO: Iteration: 132/137, steps: 28512
2022-12-28 21:29:56.276 DEBUG: Atoms are too close
2022-12-28 21:30:21.866 INFO: Training rollout: return=0.287 (3.3), episode length=6.0
2022-12-28 21:30:21.868 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 21:30:21.870 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-28512_train.pkl
2022-12-28 21:30:22.880 DEBUG: Taking gradient step
2022-12-28 21:30:22.888 DEBUG: Loss 0: {'policy_loss': 0.01822319107251548, 'entropy_loss': -0.07914731279015541, 'vf_loss': 0.010439226838054923, 'total_loss': -0.05048489487958501, 'approx_kl': -2.693074474535706e-08, 'clip_fraction': 0.0, 'grad_norm': 16.365020751953125}
2022-12-28 21:30:23.884 DEBUG: Taking gradient step
2022-12-28 21:30:23.893 DEBUG: Loss 1: {'policy_loss': -0.0333833605385226, 'entropy_loss': -0.07906622253358364, 'vf_loss': 0.007888673684752353, 'total_loss': -0.10456090938735388, 'approx_kl': 0.01627957879099995, 'clip_fraction': 0.0390625, 'grad_norm': 9.329154968261719}
2022-12-28 21:30:24.859 DEBUG: Taking gradient step
2022-12-28 21:30:24.867 DEBUG: Loss 2: {'policy_loss': -0.032900469131746546, 'entropy_loss': -0.0788895096629858, 'vf_loss': 0.007873440933212301, 'total_loss': -0.10391653786152005, 'approx_kl': 0.04394603939726949, 'clip_fraction': 0.1953125, 'grad_norm': 4.251490592956543}
2022-12-28 21:30:25.842 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-28 21:30:25.842 INFO: Optimization: policy loss=-0.033, vf loss=0.008, entropy loss=-0.079, total loss=-0.104, num steps=3
2022-12-28 21:30:25.843 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 21:30:27.666 INFO: Evaluation rollout: return=1.037 (0.0), episode length=6.0
2022-12-28 21:30:27.667 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 21:30:27.670 INFO: Iteration: 133/137, steps: 28728
2022-12-28 21:31:08.970 DEBUG: There is a single atom floating around
2022-12-28 21:31:29.994 INFO: Training rollout: return=0.302 (3.3), episode length=6.0
2022-12-28 21:31:29.996 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 21:31:29.998 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-28728_train.pkl
2022-12-28 21:31:31.004 DEBUG: Taking gradient step
2022-12-28 21:31:31.013 DEBUG: Loss 0: {'policy_loss': 0.09302006369334533, 'entropy_loss': -0.07745669782161713, 'vf_loss': 0.016705786022496442, 'total_loss': 0.032269151894224635, 'approx_kl': -4.656612873077393e-10, 'clip_fraction': 0.0, 'grad_norm': 28.774744033813477}
2022-12-28 21:31:31.981 DEBUG: Taking gradient step
2022-12-28 21:31:31.989 DEBUG: Loss 1: {'policy_loss': -0.004037199493387495, 'entropy_loss': -0.07724025845527649, 'vf_loss': 0.011899663540749011, 'total_loss': -0.06937779440791497, 'approx_kl': -0.0012219370109960437, 'clip_fraction': 0.022135416977107525, 'grad_norm': 7.030115604400635}
2022-12-28 21:31:32.981 DEBUG: Taking gradient step
2022-12-28 21:31:32.989 DEBUG: Loss 2: {'policy_loss': 0.02790402630972543, 'entropy_loss': -0.07838293351233006, 'vf_loss': 0.014301589580487677, 'total_loss': -0.036177317622116956, 'approx_kl': -0.00035984080750495195, 'clip_fraction': 0.08984375, 'grad_norm': 13.571761131286621}
2022-12-28 21:31:33.955 DEBUG: Taking gradient step
2022-12-28 21:31:33.963 DEBUG: Loss 3: {'policy_loss': -0.048918665380552714, 'entropy_loss': -0.0781517755240202, 'vf_loss': 0.009398150630700739, 'total_loss': -0.11767229027387216, 'approx_kl': -0.0013462092611007392, 'clip_fraction': 0.1953125, 'grad_norm': 2.404888391494751}
2022-12-28 21:31:34.914 DEBUG: Taking gradient step
2022-12-28 21:31:34.923 DEBUG: Loss 4: {'policy_loss': -0.016690560980020856, 'entropy_loss': -0.07736034318804741, 'vf_loss': 0.011759702665220258, 'total_loss': -0.08229120150284801, 'approx_kl': 0.01793733797967434, 'clip_fraction': 0.31640625, 'grad_norm': 2.303257703781128}
2022-12-28 21:31:35.929 DEBUG: Taking gradient step
2022-12-28 21:31:35.937 DEBUG: Loss 5: {'policy_loss': 0.015428290202992904, 'entropy_loss': -0.07777072116732597, 'vf_loss': 0.014224585502464105, 'total_loss': -0.048117845461868966, 'approx_kl': 0.00934632821008563, 'clip_fraction': 0.3736979216337204, 'grad_norm': 2.2466182708740234}
2022-12-28 21:31:36.879 DEBUG: Taking gradient step
2022-12-28 21:31:36.887 DEBUG: Loss 6: {'policy_loss': -0.047941102772855876, 'entropy_loss': -0.07869431935250759, 'vf_loss': 0.009350850695162687, 'total_loss': -0.11728457143020077, 'approx_kl': -0.008273904211819172, 'clip_fraction': 0.3424479179084301, 'grad_norm': 2.2111756801605225}
2022-12-28 21:31:37.902 DEBUG: Taking gradient step
2022-12-28 21:31:37.914 DEBUG: Loss 7: {'policy_loss': 0.0846958346107086, 'entropy_loss': -0.07835488952696323, 'vf_loss': 0.019093281888510612, 'total_loss': 0.025434226972255974, 'approx_kl': 0.003857298055663705, 'clip_fraction': 0.3372395858168602, 'grad_norm': 1.9319524765014648}
2022-12-28 21:31:38.890 DEBUG: Taking gradient step
2022-12-28 21:31:38.898 DEBUG: Loss 8: {'policy_loss': -0.05684033656835034, 'entropy_loss': -0.07902548089623451, 'vf_loss': 0.009339133796730459, 'total_loss': -0.12652668366785438, 'approx_kl': -0.03784011444076896, 'clip_fraction': 0.3424479216337204, 'grad_norm': 1.540715217590332}
2022-12-28 21:31:39.900 DEBUG: Taking gradient step
2022-12-28 21:31:39.908 DEBUG: Loss 9: {'policy_loss': 0.023227888404417724, 'entropy_loss': -0.0805144589394331, 'vf_loss': 0.014195641743524227, 'total_loss': -0.04309092879149115, 'approx_kl': -0.03913235943764448, 'clip_fraction': 0.3294270858168602, 'grad_norm': 25.361665725708008}
2022-12-28 21:31:39.908 INFO: Optimization: policy loss=0.023, vf loss=0.014, entropy loss=-0.081, total loss=-0.043, num steps=10
2022-12-28 21:31:39.908 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 21:31:41.744 INFO: Evaluation rollout: return=0.999 (0.0), episode length=6.0
2022-12-28 21:31:41.745 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 21:31:41.748 INFO: Iteration: 134/137, steps: 28944
2022-12-28 21:32:42.999 DEBUG: Atoms are too close
2022-12-28 21:32:43.701 INFO: Training rollout: return=0.309 (3.3), episode length=6.0
2022-12-28 21:32:43.702 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 21:32:43.705 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-28944_train.pkl
2022-12-28 21:32:44.698 DEBUG: Taking gradient step
2022-12-28 21:32:44.708 DEBUG: Loss 0: {'policy_loss': 0.014927881804504706, 'entropy_loss': -0.08046064525842667, 'vf_loss': 0.011760024805888242, 'total_loss': -0.05377273864803372, 'approx_kl': 5.6189797703609656e-08, 'clip_fraction': 0.0, 'grad_norm': 13.083022117614746}
2022-12-28 21:32:45.805 DEBUG: Taking gradient step
2022-12-28 21:32:45.813 DEBUG: Loss 1: {'policy_loss': 0.004760489042890573, 'entropy_loss': -0.0798030961304903, 'vf_loss': 0.011660523216552136, 'total_loss': -0.06338208387104757, 'approx_kl': 0.0023384345695376396, 'clip_fraction': 0.033854166977107525, 'grad_norm': 6.3955583572387695}
2022-12-28 21:32:46.752 DEBUG: Taking gradient step
2022-12-28 21:32:46.760 DEBUG: Loss 2: {'policy_loss': 0.00010236194502848822, 'entropy_loss': -0.07937737554311752, 'vf_loss': 0.011687699129388576, 'total_loss': -0.06758731446870045, 'approx_kl': 0.008743410697206855, 'clip_fraction': 0.1549479179084301, 'grad_norm': 5.561619281768799}
2022-12-28 21:32:47.740 DEBUG: Taking gradient step
2022-12-28 21:32:47.751 DEBUG: Loss 3: {'policy_loss': -0.04223513361492372, 'entropy_loss': -0.07967066951096058, 'vf_loss': 0.009298719905990876, 'total_loss': -0.11260708321989343, 'approx_kl': 0.0029885447584092617, 'clip_fraction': 0.24609375, 'grad_norm': 3.826481342315674}
2022-12-28 21:32:48.772 DEBUG: Taking gradient step
2022-12-28 21:32:48.779 DEBUG: Loss 4: {'policy_loss': -0.042273167496235976, 'entropy_loss': -0.08073383755981922, 'vf_loss': 0.009282288488977752, 'total_loss': -0.11372471656707744, 'approx_kl': 0.022271529771387577, 'clip_fraction': 0.3033854216337204, 'grad_norm': 2.430433511734009}
2022-12-28 21:32:49.739 DEBUG: Taking gradient step
2022-12-28 21:32:49.747 DEBUG: Loss 5: {'policy_loss': -0.020505929877130184, 'entropy_loss': -0.07905044034123421, 'vf_loss': 0.011713848333856226, 'total_loss': -0.08784252188450818, 'approx_kl': 0.011253313161432743, 'clip_fraction': 0.33984375, 'grad_norm': 2.1517555713653564}
2022-12-28 21:32:50.693 DEBUG: Taking gradient step
2022-12-28 21:32:50.701 DEBUG: Loss 6: {'policy_loss': -0.052107774514380534, 'entropy_loss': -0.07950953207910061, 'vf_loss': 0.009289620275804749, 'total_loss': -0.12232768631767639, 'approx_kl': 0.007556058466434479, 'clip_fraction': 0.3919270858168602, 'grad_norm': 2.2414448261260986}
2022-12-28 21:32:51.645 DEBUG: Taking gradient step
2022-12-28 21:32:51.653 DEBUG: Loss 7: {'policy_loss': -0.046384272493178585, 'entropy_loss': -0.0805686917155981, 'vf_loss': 0.009247739283561048, 'total_loss': -0.11770522492521565, 'approx_kl': 0.025560853304341435, 'clip_fraction': 0.4205729216337204, 'grad_norm': 2.6075308322906494}
2022-12-28 21:32:52.649 DEBUG: Taking gradient step
2022-12-28 21:32:52.657 DEBUG: Loss 8: {'policy_loss': -0.01998123292395514, 'entropy_loss': -0.0794062577188015, 'vf_loss': 0.011668893213575114, 'total_loss': -0.08771859742918153, 'approx_kl': 0.013959704898297787, 'clip_fraction': 0.421875, 'grad_norm': 2.746843099594116}
2022-12-28 21:32:53.620 DEBUG: Taking gradient step
2022-12-28 21:32:53.632 DEBUG: Loss 9: {'policy_loss': -0.02251040652319147, 'entropy_loss': -0.07929812371730804, 'vf_loss': 0.011610771182072255, 'total_loss': -0.09019775905842727, 'approx_kl': 0.00799981551244855, 'clip_fraction': 0.4036458432674408, 'grad_norm': 1.792667031288147}
2022-12-28 21:32:53.632 INFO: Optimization: policy loss=-0.023, vf loss=0.012, entropy loss=-0.079, total loss=-0.090, num steps=10
2022-12-28 21:32:53.632 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 21:32:55.464 INFO: Evaluation rollout: return=1.127 (0.0), episode length=6.0
2022-12-28 21:32:55.466 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 21:32:55.468 INFO: Iteration: 135/137, steps: 29160
2022-12-28 21:33:58.365 INFO: Training rollout: return=0.875 (0.1), episode length=6.0
2022-12-28 21:33:58.367 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 21:33:58.369 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-29160_train.pkl
2022-12-28 21:33:59.352 DEBUG: Taking gradient step
2022-12-28 21:33:59.364 DEBUG: Loss 0: {'policy_loss': 0.01773230550660997, 'entropy_loss': -0.07994396053254604, 'vf_loss': 0.0005438388586251398, 'total_loss': -0.06166781616731093, 'approx_kl': -6.457169865470291e-08, 'clip_fraction': 0.0, 'grad_norm': 12.577216148376465}
2022-12-28 21:34:00.371 DEBUG: Taking gradient step
2022-12-28 21:34:00.379 DEBUG: Loss 1: {'policy_loss': -0.007689469017736941, 'entropy_loss': -0.08054215274751186, 'vf_loss': 0.0005404428582604665, 'total_loss': -0.08769117890698834, 'approx_kl': 0.006378787104040384, 'clip_fraction': 0.10026041697710752, 'grad_norm': 14.737055778503418}
2022-12-28 21:34:01.366 DEBUG: Taking gradient step
2022-12-28 21:34:01.374 DEBUG: Loss 2: {'policy_loss': -0.007724765913681036, 'entropy_loss': -0.08079470694065094, 'vf_loss': 0.0005315231921513774, 'total_loss': -0.0879879496621806, 'approx_kl': 0.021217396948486567, 'clip_fraction': 0.2513020858168602, 'grad_norm': 13.687996864318848}
2022-12-28 21:34:02.335 DEBUG: Taking gradient step
2022-12-28 21:34:02.343 DEBUG: Loss 3: {'policy_loss': 0.0013730282719841974, 'entropy_loss': -0.080971360206604, 'vf_loss': 0.0005132862431698132, 'total_loss': -0.07908504569145, 'approx_kl': 0.03634893738490064, 'clip_fraction': 0.34765625, 'grad_norm': 12.48581314086914}
2022-12-28 21:34:03.314 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-28 21:34:03.315 INFO: Optimization: policy loss=0.001, vf loss=0.001, entropy loss=-0.081, total loss=-0.079, num steps=4
2022-12-28 21:34:03.315 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 21:34:05.143 INFO: Evaluation rollout: return=0.988 (0.0), episode length=6.0
2022-12-28 21:34:05.144 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 21:34:05.146 INFO: Iteration: 136/137, steps: 29376
2022-12-28 21:35:07.216 INFO: Training rollout: return=0.781 (0.4), episode length=6.0
2022-12-28 21:35:07.217 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 21:35:07.219 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-29376_train.pkl
2022-12-28 21:35:08.203 DEBUG: Taking gradient step
2022-12-28 21:35:08.211 DEBUG: Loss 0: {'policy_loss': 0.021333842348238305, 'entropy_loss': -0.08121597394347191, 'vf_loss': 0.0006537842676317496, 'total_loss': -0.05922834732760186, 'approx_kl': -4.016328603029251e-08, 'clip_fraction': 0.0, 'grad_norm': 9.656046867370605}
2022-12-28 21:35:09.204 DEBUG: Taking gradient step
2022-12-28 21:35:09.212 DEBUG: Loss 1: {'policy_loss': 0.031234043498092376, 'entropy_loss': -0.08160845749080181, 'vf_loss': 0.000677624561154109, 'total_loss': -0.04969678943155532, 'approx_kl': 0.0003054442349821329, 'clip_fraction': 0.029947916977107525, 'grad_norm': 10.453648567199707}
2022-12-28 21:35:10.162 DEBUG: Taking gradient step
2022-12-28 21:35:10.171 DEBUG: Loss 2: {'policy_loss': -0.05200333189681743, 'entropy_loss': -0.08091293461620808, 'vf_loss': 0.0006032638428149118, 'total_loss': -0.1323130026702106, 'approx_kl': 0.012651533586904407, 'clip_fraction': 0.1171875, 'grad_norm': 9.006562232971191}
2022-12-28 21:35:11.156 DEBUG: Taking gradient step
2022-12-28 21:35:11.167 DEBUG: Loss 3: {'policy_loss': -0.021683542991356698, 'entropy_loss': -0.08155572973191738, 'vf_loss': 0.0006047776300322218, 'total_loss': -0.10263449509324185, 'approx_kl': 0.023653840646147728, 'clip_fraction': 0.2395833358168602, 'grad_norm': 11.746575355529785}
2022-12-28 21:35:12.162 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-28 21:35:12.163 INFO: Optimization: policy loss=-0.022, vf loss=0.001, entropy loss=-0.082, total loss=-0.103, num steps=4
2022-12-28 21:35:12.163 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 21:35:14.033 INFO: Evaluation rollout: return=1.010 (0.0), episode length=6.0
2022-12-28 21:35:14.034 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 21:35:14.036 INFO: Iteration: 137/137, steps: 29592
2022-12-28 21:35:27.555 DEBUG: Atoms are too close
2022-12-28 21:36:16.052 INFO: Training rollout: return=0.278 (3.3), episode length=6.0
2022-12-28 21:36:16.054 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_train.txt
2022-12-28 21:36:16.057 DEBUG: Saving rollout: runs/CH3NO_painn/data/CH3NO_painn_run-1_steps-29592_train.pkl
2022-12-28 21:36:17.058 DEBUG: Taking gradient step
2022-12-28 21:36:17.066 DEBUG: Loss 0: {'policy_loss': 0.0202012632351261, 'entropy_loss': -0.07941563241183758, 'vf_loss': 0.01014016504311168, 'total_loss': -0.0490742041335998, 'approx_kl': 4.338411230264683e-08, 'clip_fraction': 0.0, 'grad_norm': 11.38008975982666}
2022-12-28 21:36:18.011 DEBUG: Taking gradient step
2022-12-28 21:36:18.019 DEBUG: Loss 1: {'policy_loss': -0.034045533462535936, 'entropy_loss': -0.07919710874557495, 'vf_loss': 0.0077285510864223824, 'total_loss': -0.1055140911216885, 'approx_kl': 0.0006162187783047557, 'clip_fraction': 0.09895833395421505, 'grad_norm': 6.320392608642578}
2022-12-28 21:36:19.005 DEBUG: Taking gradient step
2022-12-28 21:36:19.013 DEBUG: Loss 2: {'policy_loss': -0.03813078204231127, 'entropy_loss': -0.07911068946123123, 'vf_loss': 0.007719242251087981, 'total_loss': -0.10952222925245451, 'approx_kl': 0.011416069988626987, 'clip_fraction': 0.2942708358168602, 'grad_norm': 4.1455841064453125}
2022-12-28 21:36:20.007 DEBUG: Taking gradient step
2022-12-28 21:36:20.019 DEBUG: Loss 3: {'policy_loss': -0.03867842800754359, 'entropy_loss': -0.08046522736549377, 'vf_loss': 0.007717868394845112, 'total_loss': -0.11142578697819225, 'approx_kl': 0.034140124917030334, 'clip_fraction': 0.3880208358168602, 'grad_norm': 3.196636915206909}
2022-12-28 21:36:20.980 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-28 21:36:20.981 INFO: Optimization: policy loss=-0.039, vf loss=0.008, entropy loss=-0.080, total loss=-0.111, num steps=4
2022-12-28 21:36:20.981 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_opt.txt
2022-12-28 21:36:22.977 INFO: Evaluation rollout: return=0.914 (0.0), episode length=6.0
2022-12-28 21:36:22.979 DEBUG: Saving info: runs/CH3NO_painn/results/CH3NO_painn_run-1_eval.txt
2022-12-28 21:36:22.981 DEBUG: Deleting old model: runs/CH3NO_painn/models/CH3NO_painn_run-1_steps-28296.model
2022-12-28 21:36:22.983 DEBUG: Saving model: runs/CH3NO_painn/models/CH3NO_painn_run-1_steps-29808.model
2022-12-28 21:36:23.006 INFO: Finished PPO
