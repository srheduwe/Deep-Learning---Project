2022-12-29 21:28:45.495 INFO: {
    "bag_scale": 5,
    "beta": "-10",
    "canvas_size": 5,
    "clip_ratio": 0.2,
    "cutoff": 4.0,
    "data_dir": "runs/CH4_int/data",
    "device": "cuda",
    "discount": 1.0,
    "entropy_coef": 0.06,
    "eval_formulas": "CH4",
    "eval_freq": 1,
    "formulas": "CH4",
    "gradient_clip": 0.5,
    "keep_models": false,
    "lam": 1.0,
    "learning_rate": 0.0005,
    "load_latest": false,
    "load_model": null,
    "log_dir": "runs/CH4_int/logs",
    "log_level": "DEBUG",
    "max_mean_distance": 1.8,
    "max_num_steps": 30000,
    "max_num_train_iters": 10,
    "max_solo_distance": 2.0,
    "maxl": 4,
    "min_atomic_distance": 0.6,
    "min_mean_distance": 0.8,
    "min_reward": -20.0,
    "mini_batch_size": 64,
    "model": "internal",
    "model_dir": "runs/CH4_int/models",
    "name": "CH4_int",
    "network_width": 128,
    "num_cg_levels": 3,
    "num_channels_hidden": 10,
    "num_channels_per_element": 4,
    "num_envs": 12,
    "num_eval_episodes": null,
    "num_gaussians": 3,
    "num_interactions": 3,
    "num_steps_per_iter": 216,
    "optimizer": "adam",
    "results_dir": "runs/CH4_int/results",
    "save_freq": 10,
    "save_rollouts": "train",
    "seed": 1,
    "symbols": "X,H,C",
    "target_kl": 0.03,
    "update_edges": true,
    "vf_coef": 0.001
}
2022-12-29 21:28:45.533 INFO: CUDA Device: 0
2022-12-29 21:28:45.534 INFO: Training bags: ['CH4']
2022-12-29 21:28:45.534 INFO: Evaluation bags: ['CH4']
2022-12-29 21:28:47.236 INFO: Number of parameters: 212524
2022-12-29 21:28:47.254 INFO: Starting PPO
2022-12-29 21:28:47.254 INFO: Iteration: 0/137, steps: 0
2022-12-29 21:28:50.265 DEBUG: There is a single atom floating around
2022-12-29 21:28:50.533 DEBUG: There is a single atom floating around
2022-12-29 21:28:51.050 DEBUG: There is a single atom floating around
2022-12-29 21:28:52.223 DEBUG: There is a single atom floating around
2022-12-29 21:28:53.236 DEBUG: There is a single atom floating around
2022-12-29 21:28:55.135 DEBUG: There is a single atom floating around
2022-12-29 21:28:55.418 DEBUG: There is a single atom floating around
2022-12-29 21:28:56.381 DEBUG: There is a single atom floating around
2022-12-29 21:28:56.647 DEBUG: There is a single atom floating around
2022-12-29 21:28:58.480 DEBUG: There is a single atom floating around
2022-12-29 21:29:00.365 DEBUG: There is a single atom floating around
2022-12-29 21:29:00.968 DEBUG: There is a single atom floating around
2022-12-29 21:29:03.070 DEBUG: There is a single atom floating around
2022-12-29 21:29:03.071 DEBUG: There is a single atom floating around
2022-12-29 21:29:04.883 DEBUG: There is a single atom floating around
2022-12-29 21:29:06.584 DEBUG: There is a single atom floating around
2022-12-29 21:29:07.814 DEBUG: There is a single atom floating around
2022-12-29 21:29:07.815 DEBUG: There is a single atom floating around
2022-12-29 21:29:08.620 DEBUG: There is a single atom floating around
2022-12-29 21:29:09.083 DEBUG: There is a single atom floating around
2022-12-29 21:29:09.083 DEBUG: There is a single atom floating around
2022-12-29 21:29:10.636 DEBUG: There is a single atom floating around
2022-12-29 21:29:11.697 DEBUG: Atoms are too close
2022-12-29 21:29:12.390 DEBUG: There is a single atom floating around
2022-12-29 21:29:12.392 DEBUG: There is a single atom floating around
2022-12-29 21:29:12.393 DEBUG: There is a single atom floating around
2022-12-29 21:29:15.874 DEBUG: There is a single atom floating around
2022-12-29 21:29:16.721 DEBUG: There is a single atom floating around
2022-12-29 21:29:16.722 DEBUG: There is a single atom floating around
2022-12-29 21:29:18.021 DEBUG: There is a single atom floating around
2022-12-29 21:29:20.090 DEBUG: There is a single atom floating around
2022-12-29 21:29:21.833 DEBUG: There is a single atom floating around
2022-12-29 21:29:22.846 DEBUG: There is a single atom floating around
2022-12-29 21:29:22.847 DEBUG: There is a single atom floating around
2022-12-29 21:29:22.849 DEBUG: There is a single atom floating around
2022-12-29 21:29:22.992 DEBUG: There is a single atom floating around
2022-12-29 21:29:25.980 DEBUG: There is a single atom floating around
2022-12-29 21:29:27.527 DEBUG: There is a single atom floating around
2022-12-29 21:29:27.528 DEBUG: There is a single atom floating around
2022-12-29 21:29:27.529 DEBUG: There is a single atom floating around
2022-12-29 21:29:27.530 DEBUG: There is a single atom floating around
2022-12-29 21:29:28.232 DEBUG: There is a single atom floating around
2022-12-29 21:29:28.234 DEBUG: There is a single atom floating around
2022-12-29 21:29:28.235 DEBUG: There is a single atom floating around
2022-12-29 21:29:28.356 DEBUG: There is a single atom floating around
2022-12-29 21:29:30.724 INFO: Training rollout: return=-16.706 (7.3), episode length=3.8
2022-12-29 21:29:30.726 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 21:29:30.729 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-0_train.pkl
2022-12-29 21:29:34.043 DEBUG: Taking gradient step
2022-12-29 21:29:34.057 DEBUG: Loss 0: {'policy_loss': -0.07095907793364437, 'entropy_loss': -0.041449401527643204, 'vf_loss': 0.27592158481581497, 'total_loss': 0.16351310535452743, 'approx_kl': 3.0617229640483856e-08, 'clip_fraction': 0.0, 'grad_norm': 11.51149845123291}
2022-12-29 21:29:37.926 DEBUG: Early stopping at step 1 for reaching max KL.
2022-12-29 21:29:37.927 INFO: Optimization: policy loss=-0.071, vf loss=0.276, entropy loss=-0.041, total loss=0.164, num steps=1
2022-12-29 21:29:37.933 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 21:29:39.426 INFO: Evaluation rollout: return=0.536 (0.0), episode length=5.0
2022-12-29 21:29:39.426 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 21:29:39.430 DEBUG: Saving model: runs/CH4_int/models/CH4_int_run-1_steps-216.model
2022-12-29 21:29:39.453 INFO: Iteration: 1/137, steps: 216
2022-12-29 21:29:42.340 DEBUG: There is a single atom floating around
2022-12-29 21:29:42.341 DEBUG: There is a single atom floating around
2022-12-29 21:29:43.202 DEBUG: There is a single atom floating around
2022-12-29 21:29:45.634 DEBUG: There is a single atom floating around
2022-12-29 21:29:47.369 DEBUG: There is a single atom floating around
2022-12-29 21:29:50.547 DEBUG: Atoms are too close
2022-12-29 21:29:50.549 DEBUG: There is a single atom floating around
2022-12-29 21:29:51.145 DEBUG: There is a single atom floating around
2022-12-29 21:29:51.147 DEBUG: There is a single atom floating around
2022-12-29 21:29:53.877 DEBUG: There is a single atom floating around
2022-12-29 21:29:58.228 DEBUG: There is a single atom floating around
2022-12-29 21:29:59.260 DEBUG: There is a single atom floating around
2022-12-29 21:29:59.552 DEBUG: There is a single atom floating around
2022-12-29 21:30:01.249 DEBUG: There is a single atom floating around
2022-12-29 21:30:01.251 DEBUG: There is a single atom floating around
2022-12-29 21:30:04.242 DEBUG: There is a single atom floating around
2022-12-29 21:30:05.050 DEBUG: There is a single atom floating around
2022-12-29 21:30:05.051 DEBUG: There is a single atom floating around
2022-12-29 21:30:05.051 DEBUG: There is a single atom floating around
2022-12-29 21:30:09.513 DEBUG: There is a single atom floating around
2022-12-29 21:30:11.080 DEBUG: There is a single atom floating around
2022-12-29 21:30:14.868 DEBUG: Atoms are too close
2022-12-29 21:30:14.870 DEBUG: Atoms are too close
2022-12-29 21:30:14.870 DEBUG: There is a single atom floating around
2022-12-29 21:30:15.580 DEBUG: There is a single atom floating around
2022-12-29 21:30:15.580 DEBUG: There is a single atom floating around
2022-12-29 21:30:16.024 DEBUG: There is a single atom floating around
2022-12-29 21:30:16.026 DEBUG: There is a single atom floating around
2022-12-29 21:30:19.356 DEBUG: There is a single atom floating around
2022-12-29 21:30:21.539 DEBUG: There is a single atom floating around
2022-12-29 21:30:22.240 DEBUG: There is a single atom floating around
2022-12-29 21:30:22.241 DEBUG: There is a single atom floating around
2022-12-29 21:30:22.243 DEBUG: There is a single atom floating around
2022-12-29 21:30:23.578 DEBUG: There is a single atom floating around
2022-12-29 21:30:26.021 INFO: Training rollout: return=-13.876 (9.2), episode length=3.9
2022-12-29 21:30:26.023 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 21:30:26.026 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-216_train.pkl
2022-12-29 21:30:29.362 DEBUG: Taking gradient step
2022-12-29 21:30:29.370 DEBUG: Loss 0: {'policy_loss': -0.06733263156704941, 'entropy_loss': -0.04126734007149935, 'vf_loss': 0.19670991986119185, 'total_loss': 0.08810994822264309, 'approx_kl': -1.257285475730896e-08, 'clip_fraction': 0.0, 'grad_norm': 22.004772186279297}
2022-12-29 21:30:32.842 DEBUG: Early stopping at step 1 for reaching max KL.
2022-12-29 21:30:32.843 INFO: Optimization: policy loss=-0.067, vf loss=0.197, entropy loss=-0.041, total loss=0.088, num steps=1
2022-12-29 21:30:32.849 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 21:30:34.147 INFO: Evaluation rollout: return=0.554 (0.0), episode length=5.0
2022-12-29 21:30:34.149 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 21:30:34.151 INFO: Iteration: 2/137, steps: 432
2022-12-29 21:30:36.178 DEBUG: There is a single atom floating around
2022-12-29 21:30:36.459 DEBUG: There is a single atom floating around
2022-12-29 21:30:36.725 DEBUG: There is a single atom floating around
2022-12-29 21:30:45.893 DEBUG: There is a single atom floating around
2022-12-29 21:30:47.357 DEBUG: Atoms are too close
2022-12-29 21:30:47.358 DEBUG: Atoms are too close
2022-12-29 21:30:47.359 DEBUG: There is a single atom floating around
2022-12-29 21:30:47.359 DEBUG: There is a single atom floating around
2022-12-29 21:30:51.865 DEBUG: There is a single atom floating around
2022-12-29 21:30:52.763 DEBUG: There is a single atom floating around
2022-12-29 21:30:53.774 DEBUG: There is a single atom floating around
2022-12-29 21:30:56.558 DEBUG: There is a single atom floating around
2022-12-29 21:30:56.705 DEBUG: There is a single atom floating around
2022-12-29 21:30:56.983 DEBUG: There is a single atom floating around
2022-12-29 21:30:57.842 DEBUG: There is a single atom floating around
2022-12-29 21:31:04.555 DEBUG: There is a single atom floating around
2022-12-29 21:31:05.120 DEBUG: There is a single atom floating around
2022-12-29 21:31:07.904 DEBUG: There is a single atom floating around
2022-12-29 21:31:08.351 DEBUG: There is a single atom floating around
2022-12-29 21:31:09.243 DEBUG: Atoms are too close
2022-12-29 21:31:10.657 DEBUG: There is a single atom floating around
2022-12-29 21:31:14.279 DEBUG: There is a single atom floating around
2022-12-29 21:31:15.539 DEBUG: There is a single atom floating around
2022-12-29 21:31:21.965 DEBUG: There is a single atom floating around
2022-12-29 21:31:22.795 DEBUG: Atoms are too close
2022-12-29 21:31:23.642 DEBUG: There is a single atom floating around
2022-12-29 21:31:24.090 INFO: Training rollout: return=-10.731 (10.1), episode length=4.1
2022-12-29 21:31:24.092 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 21:31:24.095 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-432_train.pkl
2022-12-29 21:31:27.407 DEBUG: Taking gradient step
2022-12-29 21:31:27.415 DEBUG: Loss 0: {'policy_loss': 0.014348658161480399, 'entropy_loss': -0.03933468367904425, 'vf_loss': 0.15944463239656473, 'total_loss': 0.13445860687900088, 'approx_kl': -1.1292286217212677e-08, 'clip_fraction': 0.0, 'grad_norm': 15.78160285949707}
2022-12-29 21:31:30.718 DEBUG: Early stopping at step 1 for reaching max KL.
2022-12-29 21:31:30.719 INFO: Optimization: policy loss=0.014, vf loss=0.159, entropy loss=-0.039, total loss=0.134, num steps=1
2022-12-29 21:31:30.725 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 21:31:32.187 INFO: Evaluation rollout: return=0.564 (0.0), episode length=5.0
2022-12-29 21:31:32.189 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 21:31:32.191 INFO: Iteration: 3/137, steps: 648
2022-12-29 21:31:34.805 DEBUG: There is a single atom floating around
2022-12-29 21:31:34.807 DEBUG: There is a single atom floating around
2022-12-29 21:31:35.411 DEBUG: There is a single atom floating around
2022-12-29 21:31:35.728 DEBUG: There is a single atom floating around
2022-12-29 21:31:35.729 DEBUG: There is a single atom floating around
2022-12-29 21:31:36.025 DEBUG: There is a single atom floating around
2022-12-29 21:31:36.154 DEBUG: There is a single atom floating around
2022-12-29 21:31:39.343 DEBUG: There is a single atom floating around
2022-12-29 21:31:43.229 DEBUG: There is a single atom floating around
2022-12-29 21:31:51.640 DEBUG: Atoms are too close
2022-12-29 21:31:56.787 DEBUG: There is a single atom floating around
2022-12-29 21:32:03.161 DEBUG: There is a single atom floating around
2022-12-29 21:32:09.215 DEBUG: There is a single atom floating around
2022-12-29 21:32:11.832 DEBUG: There is a single atom floating around
2022-12-29 21:32:14.067 DEBUG: There is a single atom floating around
2022-12-29 21:32:14.358 DEBUG: Atoms are too close
2022-12-29 21:32:19.184 DEBUG: Atoms are too close
2022-12-29 21:32:20.067 DEBUG: Atoms are too close
2022-12-29 21:32:22.296 DEBUG: There is a single atom floating around
2022-12-29 21:32:24.661 INFO: Training rollout: return=-8.074 (10.0), episode length=4.3
2022-12-29 21:32:24.664 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 21:32:24.666 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-648_train.pkl
2022-12-29 21:32:28.128 DEBUG: Taking gradient step
2022-12-29 21:32:28.136 DEBUG: Loss 0: {'policy_loss': 0.0313750118435277, 'entropy_loss': -0.035604548174887896, 'vf_loss': 0.11330976565922579, 'total_loss': 0.1090802293278656, 'approx_kl': 1.5366822481155396e-08, 'clip_fraction': 0.0, 'grad_norm': 15.959786415100098}
2022-12-29 21:32:31.475 DEBUG: Early stopping at step 1 for reaching max KL.
2022-12-29 21:32:31.475 INFO: Optimization: policy loss=0.031, vf loss=0.113, entropy loss=-0.036, total loss=0.109, num steps=1
2022-12-29 21:32:31.482 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 21:32:32.868 INFO: Evaluation rollout: return=0.574 (0.0), episode length=5.0
2022-12-29 21:32:32.870 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 21:32:32.873 INFO: Iteration: 4/137, steps: 864
2022-12-29 21:32:37.240 DEBUG: There is a single atom floating around
2022-12-29 21:32:37.241 DEBUG: There is a single atom floating around
2022-12-29 21:32:46.313 DEBUG: Atoms are too close
2022-12-29 21:33:02.469 DEBUG: Atoms are too close
2022-12-29 21:33:03.952 DEBUG: Atoms are too close
2022-12-29 21:33:18.828 DEBUG: Atoms are too close
2022-12-29 21:33:23.069 DEBUG: There is a single atom floating around
2022-12-29 21:33:28.748 INFO: Training rollout: return=-3.141 (7.8), episode length=4.8
2022-12-29 21:33:28.750 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 21:33:28.753 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-864_train.pkl
2022-12-29 21:33:32.503 DEBUG: Taking gradient step
2022-12-29 21:33:32.515 DEBUG: Loss 0: {'policy_loss': -0.0206752461881319, 'entropy_loss': -0.03457119408994913, 'vf_loss': 0.043050439521586215, 'total_loss': -0.012196000756494817, 'approx_kl': 5.21928689156681e-09, 'clip_fraction': 0.0, 'grad_norm': 11.566539764404297}
2022-12-29 21:33:35.847 DEBUG: Taking gradient step
2022-12-29 21:33:35.855 DEBUG: Loss 1: {'policy_loss': -0.008322421894775727, 'entropy_loss': -0.03350500203669071, 'vf_loss': 0.045683223250041614, 'total_loss': 0.0038557993185751767, 'approx_kl': 0.03451738879084587, 'clip_fraction': 0.2239583358168602, 'grad_norm': 6.535669326782227}
2022-12-29 21:33:39.553 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-29 21:33:39.554 INFO: Optimization: policy loss=-0.008, vf loss=0.046, entropy loss=-0.034, total loss=0.004, num steps=2
2022-12-29 21:33:39.560 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 21:33:40.941 INFO: Evaluation rollout: return=0.591 (0.0), episode length=5.0
2022-12-29 21:33:40.942 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 21:33:40.945 INFO: Iteration: 5/137, steps: 1080
2022-12-29 21:33:43.772 DEBUG: There is a single atom floating around
2022-12-29 21:33:54.003 DEBUG: Atoms are too close
2022-12-29 21:33:56.334 DEBUG: Atoms are too close
2022-12-29 21:33:58.521 DEBUG: There is a single atom floating around
2022-12-29 21:33:59.648 DEBUG: There is a single atom floating around
2022-12-29 21:34:00.838 DEBUG: There is a single atom floating around
2022-12-29 21:34:07.565 DEBUG: There is a single atom floating around
2022-12-29 21:34:13.759 DEBUG: Atoms are too close
2022-12-29 21:34:14.346 DEBUG: Atoms are too close
2022-12-29 21:34:14.613 DEBUG: Atoms are too close
2022-12-29 21:34:23.316 DEBUG: Atoms are too close
2022-12-29 21:34:35.806 INFO: Training rollout: return=-5.051 (9.1), episode length=4.7
2022-12-29 21:34:35.808 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 21:34:35.811 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-1080_train.pkl
2022-12-29 21:34:39.132 DEBUG: Taking gradient step
2022-12-29 21:34:39.140 DEBUG: Loss 0: {'policy_loss': -0.009404784418526529, 'entropy_loss': -0.03390850871801376, 'vf_loss': 0.06941158156143823, 'total_loss': 0.026098288424897937, 'approx_kl': -2.112938091158867e-08, 'clip_fraction': 0.0, 'grad_norm': 24.326536178588867}
2022-12-29 21:34:42.660 DEBUG: Taking gradient step
2022-12-29 21:34:42.671 DEBUG: Loss 1: {'policy_loss': 0.04158770670391984, 'entropy_loss': -0.033804620150476694, 'vf_loss': 0.07628616149323453, 'total_loss': 0.08406924804667767, 'approx_kl': 0.02655284758657217, 'clip_fraction': 0.3268229216337204, 'grad_norm': 13.528358459472656}
2022-12-29 21:34:46.321 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-29 21:34:46.321 INFO: Optimization: policy loss=0.042, vf loss=0.076, entropy loss=-0.034, total loss=0.084, num steps=2
2022-12-29 21:34:46.326 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 21:34:47.734 INFO: Evaluation rollout: return=0.608 (0.0), episode length=5.0
2022-12-29 21:34:47.735 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 21:34:47.737 INFO: Iteration: 6/137, steps: 1296
2022-12-29 21:35:15.388 DEBUG: Atoms are too close
2022-12-29 21:35:18.366 DEBUG: Atoms are too close
2022-12-29 21:35:25.046 DEBUG: There is a single atom floating around
2022-12-29 21:35:33.416 DEBUG: Atoms are too close
2022-12-29 21:35:38.509 DEBUG: There is a single atom floating around
2022-12-29 21:35:44.661 INFO: Training rollout: return=-2.129 (6.9), episode length=4.8
2022-12-29 21:35:44.664 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 21:35:44.666 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-1296_train.pkl
2022-12-29 21:35:47.949 DEBUG: Taking gradient step
2022-12-29 21:35:47.957 DEBUG: Loss 0: {'policy_loss': -0.014894731453763011, 'entropy_loss': -0.03277271240949631, 'vf_loss': 0.029867562383484245, 'total_loss': -0.017799881479775074, 'approx_kl': -4.526615882127771e-08, 'clip_fraction': 0.0, 'grad_norm': 13.895631790161133}
2022-12-29 21:35:51.319 DEBUG: Taking gradient step
2022-12-29 21:35:51.327 DEBUG: Loss 1: {'policy_loss': -0.03402192313764305, 'entropy_loss': -0.03355815447866917, 'vf_loss': 0.03005043075867228, 'total_loss': -0.03752964685763994, 'approx_kl': 0.009141843067482114, 'clip_fraction': 0.2265625, 'grad_norm': 9.288243293762207}
2022-12-29 21:35:55.055 DEBUG: Taking gradient step
2022-12-29 21:35:55.063 DEBUG: Loss 2: {'policy_loss': -0.006383229056229282, 'entropy_loss': -0.03379425313323736, 'vf_loss': 0.034564782446516576, 'total_loss': -0.005612699742950068, 'approx_kl': 0.020811251597478986, 'clip_fraction': 0.2265625, 'grad_norm': 9.0574312210083}
2022-12-29 21:35:58.663 DEBUG: Taking gradient step
2022-12-29 21:35:58.674 DEBUG: Loss 3: {'policy_loss': -0.07503364037945828, 'entropy_loss': -0.03382487129420042, 'vf_loss': 0.027769167746046004, 'total_loss': -0.08108934392761269, 'approx_kl': 0.008160428231349215, 'clip_fraction': 0.16536458395421505, 'grad_norm': 8.118108749389648}
2022-12-29 21:36:02.135 DEBUG: Taking gradient step
2022-12-29 21:36:02.143 DEBUG: Loss 4: {'policy_loss': -0.00853137358372848, 'entropy_loss': -0.033976136706769466, 'vf_loss': 0.03430485818613881, 'total_loss': -0.00820265210435913, 'approx_kl': 0.023459710646420717, 'clip_fraction': 0.1744791679084301, 'grad_norm': 17.201587677001953}
2022-12-29 21:36:05.624 DEBUG: Taking gradient step
2022-12-29 21:36:05.636 DEBUG: Loss 5: {'policy_loss': -0.07485393543118739, 'entropy_loss': -0.034355463460087776, 'vf_loss': 0.027896733721720114, 'total_loss': -0.08131266516955504, 'approx_kl': 0.02584555046632886, 'clip_fraction': 0.26953125, 'grad_norm': 7.695199012756348}
2022-12-29 21:36:09.035 DEBUG: Taking gradient step
2022-12-29 21:36:09.043 DEBUG: Loss 6: {'policy_loss': -0.023372924290793438, 'entropy_loss': -0.0339107783511281, 'vf_loss': 0.031999013951689775, 'total_loss': -0.02528468869023176, 'approx_kl': 0.035712505923584104, 'clip_fraction': 0.37890625, 'grad_norm': 13.980324745178223}
2022-12-29 21:36:12.576 DEBUG: Taking gradient step
2022-12-29 21:36:12.583 DEBUG: Loss 7: {'policy_loss': -0.026548660798084014, 'entropy_loss': -0.03409896232187748, 'vf_loss': 0.03203500374296426, 'total_loss': -0.02861261937699723, 'approx_kl': 0.025112930685281754, 'clip_fraction': 0.3984375, 'grad_norm': 11.64515495300293}
2022-12-29 21:36:16.091 DEBUG: Taking gradient step
2022-12-29 21:36:16.099 DEBUG: Loss 8: {'policy_loss': -0.010512906457569061, 'entropy_loss': -0.03471002262085676, 'vf_loss': 0.037057500880197616, 'total_loss': -0.008165428198228207, 'approx_kl': 0.029726285603828728, 'clip_fraction': 0.3111979216337204, 'grad_norm': 3.894979953765869}
2022-12-29 21:36:19.549 DEBUG: Early stopping at step 9 for reaching max KL.
2022-12-29 21:36:19.549 INFO: Optimization: policy loss=-0.011, vf loss=0.037, entropy loss=-0.035, total loss=-0.008, num steps=9
2022-12-29 21:36:19.554 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 21:36:20.994 INFO: Evaluation rollout: return=0.610 (0.0), episode length=5.0
2022-12-29 21:36:20.995 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 21:36:20.998 INFO: Iteration: 7/137, steps: 1512
2022-12-29 21:36:34.056 DEBUG: Atoms are too close
2022-12-29 21:36:35.465 DEBUG: Atoms are too close
2022-12-29 21:36:35.746 DEBUG: Atoms are too close
2022-12-29 21:36:36.082 DEBUG: Atoms are too close
2022-12-29 21:36:50.433 DEBUG: Atoms are too close
2022-12-29 21:37:07.309 DEBUG: Atoms are too close
2022-12-29 21:37:07.584 DEBUG: Atoms are too close
2022-12-29 21:37:07.585 DEBUG: Atoms are too close
2022-12-29 21:37:17.545 INFO: Training rollout: return=-3.964 (8.3), episode length=5.0
2022-12-29 21:37:17.547 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 21:37:17.549 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-1512_train.pkl
2022-12-29 21:37:21.008 DEBUG: Taking gradient step
2022-12-29 21:37:21.016 DEBUG: Loss 0: {'policy_loss': 0.024357960397962803, 'entropy_loss': -0.03411012748256326, 'vf_loss': 0.06631071463150218, 'total_loss': 0.05655854754690172, 'approx_kl': -4.064835046335702e-08, 'clip_fraction': 0.0, 'grad_norm': 25.835325241088867}
2022-12-29 21:37:24.379 DEBUG: Taking gradient step
2022-12-29 21:37:24.386 DEBUG: Loss 1: {'policy_loss': -0.028928276769070532, 'entropy_loss': -0.03436563257128, 'vf_loss': 0.0610338933906022, 'total_loss': -0.0022600159497483396, 'approx_kl': 0.006469837971962988, 'clip_fraction': 0.109375, 'grad_norm': 11.687395095825195}
2022-12-29 21:37:27.940 DEBUG: Taking gradient step
2022-12-29 21:37:27.948 DEBUG: Loss 2: {'policy_loss': -0.027866311190076237, 'entropy_loss': -0.033227190375328064, 'vf_loss': 0.06298319642812403, 'total_loss': 0.0018896948627197298, 'approx_kl': 0.007207947259303182, 'clip_fraction': 0.2317708358168602, 'grad_norm': 11.029708862304688}
2022-12-29 21:37:31.486 DEBUG: Taking gradient step
2022-12-29 21:37:31.498 DEBUG: Loss 3: {'policy_loss': 0.024443790291951983, 'entropy_loss': -0.033194984309375286, 'vf_loss': 0.06940329134476576, 'total_loss': 0.06065209732734246, 'approx_kl': 0.007860537152737379, 'clip_fraction': 0.17578125, 'grad_norm': 7.121913909912109}
2022-12-29 21:37:34.997 DEBUG: Taking gradient step
2022-12-29 21:37:35.004 DEBUG: Loss 4: {'policy_loss': -0.0032506244654458283, 'entropy_loss': -0.034471007995307446, 'vf_loss': 0.06695252850886048, 'total_loss': 0.029230896048107198, 'approx_kl': 0.020061037503182888, 'clip_fraction': 0.19921875, 'grad_norm': 7.69575834274292}
2022-12-29 21:37:38.560 DEBUG: Taking gradient step
2022-12-29 21:37:38.572 DEBUG: Loss 5: {'policy_loss': -0.05406700323989089, 'entropy_loss': -0.03567233309149742, 'vf_loss': 0.06176692511315146, 'total_loss': -0.027972411218236855, 'approx_kl': 0.026957656256854534, 'clip_fraction': 0.2799479216337204, 'grad_norm': 6.230825424194336}
2022-12-29 21:37:41.990 DEBUG: Taking gradient step
2022-12-29 21:37:41.998 DEBUG: Loss 6: {'policy_loss': -0.04797778185776785, 'entropy_loss': -0.03560187015682459, 'vf_loss': 0.06126679248466681, 'total_loss': -0.022312859529925635, 'approx_kl': 0.0409585596062243, 'clip_fraction': 0.3346354216337204, 'grad_norm': 4.45372200012207}
2022-12-29 21:37:45.542 DEBUG: Early stopping at step 7 for reaching max KL.
2022-12-29 21:37:45.543 INFO: Optimization: policy loss=-0.048, vf loss=0.061, entropy loss=-0.036, total loss=-0.022, num steps=7
2022-12-29 21:37:45.549 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 21:37:46.979 INFO: Evaluation rollout: return=0.621 (0.0), episode length=5.0
2022-12-29 21:37:46.981 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 21:37:46.985 INFO: Iteration: 8/137, steps: 1728
2022-12-29 21:38:03.218 DEBUG: Atoms are too close
2022-12-29 21:38:17.215 DEBUG: Atoms are too close
2022-12-29 21:38:18.387 DEBUG: Atoms are too close
2022-12-29 21:38:44.191 INFO: Training rollout: return=-1.183 (5.6), episode length=5.0
2022-12-29 21:38:44.194 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 21:38:44.196 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-1728_train.pkl
2022-12-29 21:38:47.650 DEBUG: Taking gradient step
2022-12-29 21:38:47.658 DEBUG: Loss 0: {'policy_loss': -0.022712713231715143, 'entropy_loss': -0.036964628379791975, 'vf_loss': 0.025366520495913505, 'total_loss': -0.03431082111559361, 'approx_kl': -3.950360039084444e-08, 'clip_fraction': 0.0, 'grad_norm': 30.379472732543945}
2022-12-29 21:38:51.020 DEBUG: Taking gradient step
2022-12-29 21:38:51.028 DEBUG: Loss 1: {'policy_loss': 0.016934152981067846, 'entropy_loss': -0.03651582635939121, 'vf_loss': 0.02976885278215337, 'total_loss': 0.010187179403830002, 'approx_kl': 0.012069679331034422, 'clip_fraction': 0.08333333395421505, 'grad_norm': 22.64108657836914}
2022-12-29 21:38:54.529 DEBUG: Taking gradient step
2022-12-29 21:38:54.537 DEBUG: Loss 2: {'policy_loss': -0.02232282933787643, 'entropy_loss': -0.036849040538072586, 'vf_loss': 0.026108990030725254, 'total_loss': -0.03306287984522377, 'approx_kl': 0.026640509720891714, 'clip_fraction': 0.1979166716337204, 'grad_norm': 15.549969673156738}
2022-12-29 21:38:58.058 DEBUG: Taking gradient step
2022-12-29 21:38:58.066 DEBUG: Loss 3: {'policy_loss': -0.03201799402629582, 'entropy_loss': -0.036389539018273354, 'vf_loss': 0.026687007503023608, 'total_loss': -0.041720525541545574, 'approx_kl': 0.04003069829195738, 'clip_fraction': 0.3333333358168602, 'grad_norm': 8.582188606262207}
2022-12-29 21:39:01.461 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-29 21:39:01.461 INFO: Optimization: policy loss=-0.032, vf loss=0.027, entropy loss=-0.036, total loss=-0.042, num steps=4
2022-12-29 21:39:01.468 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 21:39:02.860 INFO: Evaluation rollout: return=0.628 (0.0), episode length=5.0
2022-12-29 21:39:02.862 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 21:39:02.865 INFO: Iteration: 9/137, steps: 1944
2022-12-29 21:39:34.932 DEBUG: Atoms are too close
2022-12-29 21:39:45.686 DEBUG: Atoms are too close
2022-12-29 21:40:00.378 INFO: Training rollout: return=-0.640 (4.6), episode length=5.0
2022-12-29 21:40:00.380 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 21:40:00.383 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-1944_train.pkl
2022-12-29 21:40:03.863 DEBUG: Taking gradient step
2022-12-29 21:40:03.871 DEBUG: Loss 0: {'policy_loss': 0.024029808720157683, 'entropy_loss': -0.036072589457035065, 'vf_loss': 0.02140968175271952, 'total_loss': 0.009366901015842137, 'approx_kl': -3.0462006250786544e-09, 'clip_fraction': 0.0, 'grad_norm': 18.799467086791992}
2022-12-29 21:40:07.193 DEBUG: Taking gradient step
2022-12-29 21:40:07.200 DEBUG: Loss 1: {'policy_loss': -0.018274534558632184, 'entropy_loss': -0.036567495204508305, 'vf_loss': 0.017597562111993214, 'total_loss': -0.03724446765114727, 'approx_kl': 0.009688134305179119, 'clip_fraction': 0.08723958395421505, 'grad_norm': 12.438898086547852}
2022-12-29 21:40:10.560 DEBUG: Taking gradient step
2022-12-29 21:40:10.570 DEBUG: Loss 2: {'policy_loss': 0.047211265017404656, 'entropy_loss': -0.03684667870402336, 'vf_loss': 0.022004541030810135, 'total_loss': 0.03236912734419143, 'approx_kl': 0.03154904395341873, 'clip_fraction': 0.22265625, 'grad_norm': 13.140642166137695}
2022-12-29 21:40:14.179 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-29 21:40:14.180 INFO: Optimization: policy loss=0.047, vf loss=0.022, entropy loss=-0.037, total loss=0.032, num steps=3
2022-12-29 21:40:14.185 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 21:40:15.573 INFO: Evaluation rollout: return=0.635 (0.0), episode length=5.0
2022-12-29 21:40:15.574 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 21:40:15.578 INFO: Iteration: 10/137, steps: 2160
2022-12-29 21:40:26.351 DEBUG: Atoms are too close
2022-12-29 21:40:31.287 DEBUG: Atoms are too close
2022-12-29 21:40:45.830 DEBUG: Atoms are too close
2022-12-29 21:40:58.099 DEBUG: Atoms are too close
2022-12-29 21:41:00.590 DEBUG: Atoms are too close
2022-12-29 21:41:02.879 DEBUG: Atoms are too close
2022-12-29 21:41:12.503 INFO: Training rollout: return=-2.881 (7.5), episode length=5.0
2022-12-29 21:41:12.505 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 21:41:12.507 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-2160_train.pkl
2022-12-29 21:41:15.913 DEBUG: Taking gradient step
2022-12-29 21:41:15.922 DEBUG: Loss 0: {'policy_loss': -0.04630642088006799, 'entropy_loss': -0.03927912097424269, 'vf_loss': 0.04440898489519711, 'total_loss': -0.04117655695911357, 'approx_kl': -7.070291019317665e-08, 'clip_fraction': 0.0, 'grad_norm': 20.019426345825195}
2022-12-29 21:41:19.433 DEBUG: Taking gradient step
2022-12-29 21:41:19.440 DEBUG: Loss 1: {'policy_loss': 0.009896738497470099, 'entropy_loss': -0.039337669499218464, 'vf_loss': 0.0484109825058256, 'total_loss': 0.018970051504077233, 'approx_kl': 0.034914144314825535, 'clip_fraction': 0.2109375, 'grad_norm': 15.323358535766602}
2022-12-29 21:41:23.014 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-29 21:41:23.015 INFO: Optimization: policy loss=0.010, vf loss=0.048, entropy loss=-0.039, total loss=0.019, num steps=2
2022-12-29 21:41:23.020 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 21:41:24.431 INFO: Evaluation rollout: return=0.635 (0.0), episode length=5.0
2022-12-29 21:41:24.431 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 21:41:24.434 DEBUG: Deleting old model: runs/CH4_int/models/CH4_int_run-1_steps-216.model
2022-12-29 21:41:24.439 DEBUG: Saving model: runs/CH4_int/models/CH4_int_run-1_steps-2376.model
2022-12-29 21:41:24.460 INFO: Iteration: 11/137, steps: 2376
2022-12-29 21:41:37.725 DEBUG: There is a single atom floating around
2022-12-29 21:41:49.856 DEBUG: There is a single atom floating around
2022-12-29 21:42:01.160 DEBUG: There is a single atom floating around
2022-12-29 21:42:04.190 DEBUG: Atoms are too close
2022-12-29 21:42:21.469 INFO: Training rollout: return=-1.667 (6.2), episode length=4.8
2022-12-29 21:42:21.471 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 21:42:21.474 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-2376_train.pkl
2022-12-29 21:42:24.747 DEBUG: Taking gradient step
2022-12-29 21:42:24.754 DEBUG: Loss 0: {'policy_loss': -0.04384722983649278, 'entropy_loss': -0.039198887534439564, 'vf_loss': 0.024178204183250437, 'total_loss': -0.058867913187681906, 'approx_kl': -4.509153583853731e-08, 'clip_fraction': 0.0, 'grad_norm': 11.65153980255127}
2022-12-29 21:42:28.262 DEBUG: Taking gradient step
2022-12-29 21:42:28.270 DEBUG: Loss 1: {'policy_loss': -0.014599860316308404, 'entropy_loss': -0.038733518682420254, 'vf_loss': 0.023871698628303076, 'total_loss': -0.02946168037042558, 'approx_kl': 0.017773273051716387, 'clip_fraction': 0.08333333395421505, 'grad_norm': 7.179929733276367}
2022-12-29 21:42:31.913 DEBUG: Taking gradient step
2022-12-29 21:42:31.922 DEBUG: Loss 2: {'policy_loss': -0.05123953675042428, 'entropy_loss': -0.03984939306974411, 'vf_loss': 0.0239889116326141, 'total_loss': -0.06710001818755429, 'approx_kl': 0.012023822870105505, 'clip_fraction': 0.06901041697710752, 'grad_norm': 5.283571720123291}
2022-12-29 21:42:35.538 DEBUG: Taking gradient step
2022-12-29 21:42:35.550 DEBUG: Loss 3: {'policy_loss': 0.04869540251975565, 'entropy_loss': -0.038556454703211784, 'vf_loss': 0.029504365615468965, 'total_loss': 0.039643313432012835, 'approx_kl': -0.00850676093250513, 'clip_fraction': 0.057291666977107525, 'grad_norm': 32.54407501220703}
2022-12-29 21:42:39.143 DEBUG: Taking gradient step
2022-12-29 21:42:39.151 DEBUG: Loss 4: {'policy_loss': -0.03325740414741816, 'entropy_loss': -0.040022759698331356, 'vf_loss': 0.0258342191251002, 'total_loss': -0.04744594472064931, 'approx_kl': -0.003208124078810215, 'clip_fraction': 0.0703125, 'grad_norm': 10.028305053710938}
2022-12-29 21:42:42.710 DEBUG: Taking gradient step
2022-12-29 21:42:42.717 DEBUG: Loss 5: {'policy_loss': -0.056307939560482016, 'entropy_loss': -0.039686763659119606, 'vf_loss': 0.0231487064066732, 'total_loss': -0.07284599681292843, 'approx_kl': 0.01762223499827087, 'clip_fraction': 0.1888020858168602, 'grad_norm': 11.45862865447998}
2022-12-29 21:42:46.069 DEBUG: Taking gradient step
2022-12-29 21:42:46.077 DEBUG: Loss 6: {'policy_loss': -0.04398425446798421, 'entropy_loss': -0.03883463703095913, 'vf_loss': 0.025026901100463708, 'total_loss': -0.057791990398479626, 'approx_kl': 0.02115854946896434, 'clip_fraction': 0.2513020858168602, 'grad_norm': 12.404172897338867}
2022-12-29 21:42:49.384 DEBUG: Taking gradient step
2022-12-29 21:42:49.391 DEBUG: Loss 7: {'policy_loss': -0.03515720832630421, 'entropy_loss': -0.039598288014531136, 'vf_loss': 0.025081639908038966, 'total_loss': -0.04967385643279638, 'approx_kl': 0.010489373467862606, 'clip_fraction': 0.23046875, 'grad_norm': 5.285828590393066}
2022-12-29 21:42:52.835 DEBUG: Taking gradient step
2022-12-29 21:42:52.845 DEBUG: Loss 8: {'policy_loss': 0.04047962482329515, 'entropy_loss': -0.036080153193324804, 'vf_loss': 0.0288638950820083, 'total_loss': 0.03326336671197866, 'approx_kl': 0.016949097625911236, 'clip_fraction': 0.2044270858168602, 'grad_norm': 8.277178764343262}
2022-12-29 21:42:56.382 DEBUG: Taking gradient step
2022-12-29 21:42:56.393 DEBUG: Loss 9: {'policy_loss': -0.06431446228274157, 'entropy_loss': -0.03806643187999725, 'vf_loss': 0.024346501614733604, 'total_loss': -0.07803439254800523, 'approx_kl': 0.013559500919654965, 'clip_fraction': 0.2356770858168602, 'grad_norm': 9.627071380615234}
2022-12-29 21:42:56.393 INFO: Optimization: policy loss=-0.064, vf loss=0.024, entropy loss=-0.038, total loss=-0.078, num steps=10
2022-12-29 21:42:56.399 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 21:42:57.762 INFO: Evaluation rollout: return=0.634 (0.0), episode length=5.0
2022-12-29 21:42:57.764 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 21:42:57.767 INFO: Iteration: 12/137, steps: 2592
2022-12-29 21:43:56.375 INFO: Training rollout: return=0.497 (0.1), episode length=5.0
2022-12-29 21:43:56.377 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 21:43:56.380 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-2592_train.pkl
2022-12-29 21:43:59.877 DEBUG: Taking gradient step
2022-12-29 21:43:59.885 DEBUG: Loss 0: {'policy_loss': -0.005434304725276404, 'entropy_loss': -0.036543991416692734, 'vf_loss': 0.0033798983758693856, 'total_loss': -0.038598397766099746, 'approx_kl': 9.313225746154785e-09, 'clip_fraction': 0.0, 'grad_norm': 12.524489402770996}
2022-12-29 21:44:03.500 DEBUG: Taking gradient step
2022-12-29 21:44:03.508 DEBUG: Loss 1: {'policy_loss': 0.007146217957780469, 'entropy_loss': -0.036206237971782684, 'vf_loss': 0.0030636607557783043, 'total_loss': -0.02599635925822391, 'approx_kl': -1.1801370419561863e-05, 'clip_fraction': 0.05859375, 'grad_norm': 9.938026428222656}
2022-12-29 21:44:06.975 DEBUG: Taking gradient step
2022-12-29 21:44:06.983 DEBUG: Loss 2: {'policy_loss': 0.0003424296735810425, 'entropy_loss': -0.03667649906128645, 'vf_loss': 0.0028394817934969015, 'total_loss': -0.0334945875942085, 'approx_kl': 0.0035180920967832208, 'clip_fraction': 0.234375, 'grad_norm': 9.954416275024414}
2022-12-29 21:44:10.647 DEBUG: Taking gradient step
2022-12-29 21:44:10.654 DEBUG: Loss 3: {'policy_loss': -0.037173165802720814, 'entropy_loss': -0.036580669693648815, 'vf_loss': 0.002640592092454086, 'total_loss': -0.07111324340391555, 'approx_kl': -0.010239900322631001, 'clip_fraction': 0.2604166679084301, 'grad_norm': 11.555471420288086}
2022-12-29 21:44:14.248 DEBUG: Taking gradient step
2022-12-29 21:44:14.259 DEBUG: Loss 4: {'policy_loss': -0.005761524154680446, 'entropy_loss': -0.03768148459494114, 'vf_loss': 0.0023767291459397683, 'total_loss': -0.041066279603681824, 'approx_kl': -0.006562454858794808, 'clip_fraction': 0.2369791716337204, 'grad_norm': 11.50778865814209}
2022-12-29 21:44:17.778 DEBUG: Taking gradient step
2022-12-29 21:44:17.789 DEBUG: Loss 5: {'policy_loss': -0.06326929904088908, 'entropy_loss': -0.038874877616763115, 'vf_loss': 0.0021837388647209183, 'total_loss': -0.09996043779293128, 'approx_kl': -0.020487311528995633, 'clip_fraction': 0.20703125, 'grad_norm': 9.235940933227539}
2022-12-29 21:44:21.379 DEBUG: Taking gradient step
2022-12-29 21:44:21.386 DEBUG: Loss 6: {'policy_loss': 0.05004491598984161, 'entropy_loss': -0.03703330922871828, 'vf_loss': 0.0019083039484649312, 'total_loss': 0.014919910709588272, 'approx_kl': -0.020133825950324535, 'clip_fraction': 0.2018229216337204, 'grad_norm': 11.773365020751953}
2022-12-29 21:44:24.804 DEBUG: Taking gradient step
2022-12-29 21:44:24.813 DEBUG: Loss 7: {'policy_loss': 0.004569405137173639, 'entropy_loss': -0.03724485356360674, 'vf_loss': 0.0018063444298688177, 'total_loss': -0.030869103996564284, 'approx_kl': -0.02749814558774233, 'clip_fraction': 0.21484375, 'grad_norm': 16.22252655029297}
2022-12-29 21:44:28.349 DEBUG: Taking gradient step
2022-12-29 21:44:28.360 DEBUG: Loss 8: {'policy_loss': -0.05071115051245759, 'entropy_loss': -0.03822445124387741, 'vf_loss': 0.0016433033174165226, 'total_loss': -0.08729229843891848, 'approx_kl': -0.04258054215461016, 'clip_fraction': 0.28515625, 'grad_norm': 6.665004730224609}
2022-12-29 21:44:31.848 DEBUG: Taking gradient step
2022-12-29 21:44:31.855 DEBUG: Loss 9: {'policy_loss': 0.014538103221704811, 'entropy_loss': -0.03555443370714784, 'vf_loss': 0.0015092857252238564, 'total_loss': -0.01950704476021916, 'approx_kl': -0.03010399080812931, 'clip_fraction': 0.2760416679084301, 'grad_norm': 9.987086296081543}
2022-12-29 21:44:31.855 INFO: Optimization: policy loss=0.015, vf loss=0.002, entropy loss=-0.036, total loss=-0.020, num steps=10
2022-12-29 21:44:31.861 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 21:44:33.333 INFO: Evaluation rollout: return=0.647 (0.0), episode length=5.0
2022-12-29 21:44:33.334 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 21:44:33.337 INFO: Iteration: 13/137, steps: 2808
2022-12-29 21:44:46.252 DEBUG: There is a single atom floating around
2022-12-29 21:45:31.685 INFO: Training rollout: return=-0.060 (3.3), episode length=5.0
2022-12-29 21:45:31.687 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 21:45:31.690 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-2808_train.pkl
2022-12-29 21:45:35.181 DEBUG: Taking gradient step
2022-12-29 21:45:35.189 DEBUG: Loss 0: {'policy_loss': -0.01838400848268154, 'entropy_loss': -0.037344309501349926, 'vf_loss': 0.008263704688150058, 'total_loss': -0.04746461329588141, 'approx_kl': -1.9363748521294966e-08, 'clip_fraction': 0.0, 'grad_norm': 4.221447467803955}
2022-12-29 21:45:38.712 DEBUG: Taking gradient step
2022-12-29 21:45:38.723 DEBUG: Loss 1: {'policy_loss': -0.0009441720162064286, 'entropy_loss': -0.035200719721615314, 'vf_loss': 0.01061089028437032, 'total_loss': -0.02553400145345142, 'approx_kl': 0.0038956963107921183, 'clip_fraction': 0.041666666977107525, 'grad_norm': 7.077445030212402}
2022-12-29 21:45:42.579 DEBUG: Taking gradient step
2022-12-29 21:45:42.587 DEBUG: Loss 2: {'policy_loss': -0.006114884790535211, 'entropy_loss': -0.033291881904006004, 'vf_loss': 0.010589474938184571, 'total_loss': -0.028817291756356646, 'approx_kl': 0.016686241142451763, 'clip_fraction': 0.2252604216337204, 'grad_norm': 2.488388776779175}
2022-12-29 21:45:45.959 DEBUG: Taking gradient step
2022-12-29 21:45:45.966 DEBUG: Loss 3: {'policy_loss': 0.04398584419965965, 'entropy_loss': -0.03140580374747515, 'vf_loss': 0.012793497494945193, 'total_loss': 0.025373537947129696, 'approx_kl': 0.037402515299618244, 'clip_fraction': 0.30078125, 'grad_norm': 2.7641654014587402}
2022-12-29 21:45:49.454 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-29 21:45:49.455 INFO: Optimization: policy loss=0.044, vf loss=0.013, entropy loss=-0.031, total loss=0.025, num steps=4
2022-12-29 21:45:49.461 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 21:45:50.938 INFO: Evaluation rollout: return=0.643 (0.0), episode length=5.0
2022-12-29 21:45:50.939 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 21:45:50.942 INFO: Iteration: 14/137, steps: 3024
2022-12-29 21:46:37.557 DEBUG: Atoms are too close
2022-12-29 21:46:49.118 INFO: Training rollout: return=-0.040 (3.3), episode length=5.0
2022-12-29 21:46:49.120 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 21:46:49.122 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-3024_train.pkl
2022-12-29 21:46:52.621 DEBUG: Taking gradient step
2022-12-29 21:46:52.630 DEBUG: Loss 0: {'policy_loss': 0.02006614140430029, 'entropy_loss': -0.029579787515103817, 'vf_loss': 0.01032738861537454, 'total_loss': 0.0008137425045710196, 'approx_kl': -1.1917048681198139e-07, 'clip_fraction': 0.0, 'grad_norm': 6.314845561981201}
2022-12-29 21:46:55.997 DEBUG: Taking gradient step
2022-12-29 21:46:56.004 DEBUG: Loss 1: {'policy_loss': 0.009086983863175711, 'entropy_loss': -0.030275906901806593, 'vf_loss': 0.010304431819438045, 'total_loss': -0.010884491219192834, 'approx_kl': 0.013286258792504668, 'clip_fraction': 0.06770833395421505, 'grad_norm': 6.648807048797607}
2022-12-29 21:46:59.648 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-29 21:46:59.648 INFO: Optimization: policy loss=0.009, vf loss=0.010, entropy loss=-0.030, total loss=-0.011, num steps=2
2022-12-29 21:46:59.655 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 21:47:01.018 INFO: Evaluation rollout: return=0.632 (0.0), episode length=5.0
2022-12-29 21:47:01.019 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 21:47:01.021 INFO: Iteration: 15/137, steps: 3240
2022-12-29 21:47:29.835 DEBUG: Atoms are too close
2022-12-29 21:47:57.978 INFO: Training rollout: return=-0.061 (3.3), episode length=5.0
2022-12-29 21:47:57.980 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 21:47:57.983 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-3240_train.pkl
2022-12-29 21:48:01.540 DEBUG: Taking gradient step
2022-12-29 21:48:01.548 DEBUG: Loss 0: {'policy_loss': 0.02079409353228954, 'entropy_loss': -0.029827465303242207, 'vf_loss': 0.010450169647545322, 'total_loss': 0.00141679787659265, 'approx_kl': 1.05355866253376e-08, 'clip_fraction': 0.0, 'grad_norm': 15.814221382141113}
2022-12-29 21:48:04.948 DEBUG: Taking gradient step
2022-12-29 21:48:04.959 DEBUG: Loss 1: {'policy_loss': -0.028841955468622824, 'entropy_loss': -0.030510852579027414, 'vf_loss': 0.007908159316558356, 'total_loss': -0.05144464873109188, 'approx_kl': 0.0053319226717576385, 'clip_fraction': 0.02734375, 'grad_norm': 6.134354114532471}
2022-12-29 21:48:08.498 DEBUG: Taking gradient step
2022-12-29 21:48:08.505 DEBUG: Loss 2: {'policy_loss': 0.009593682600062, 'entropy_loss': -0.030202838126569986, 'vf_loss': 0.01021745473326307, 'total_loss': -0.010391700793244918, 'approx_kl': 0.018511432921513915, 'clip_fraction': 0.1927083358168602, 'grad_norm': 4.210483551025391}
2022-12-29 21:48:11.715 DEBUG: Taking gradient step
2022-12-29 21:48:11.723 DEBUG: Loss 3: {'policy_loss': -0.027935464020205525, 'entropy_loss': -0.03112226538360119, 'vf_loss': 0.007838148921258923, 'total_loss': -0.051219580482547794, 'approx_kl': 0.035184041247703135, 'clip_fraction': 0.1953125, 'grad_norm': 3.8566548824310303}
2022-12-29 21:48:14.916 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-29 21:48:14.917 INFO: Optimization: policy loss=-0.028, vf loss=0.008, entropy loss=-0.031, total loss=-0.051, num steps=4
2022-12-29 21:48:14.922 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 21:48:16.357 INFO: Evaluation rollout: return=0.663 (0.0), episode length=5.0
2022-12-29 21:48:16.359 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 21:48:16.361 INFO: Iteration: 16/137, steps: 3456
2022-12-29 21:49:07.045 DEBUG: There is a single atom floating around
2022-12-29 21:49:13.166 INFO: Training rollout: return=-0.031 (3.3), episode length=4.9
2022-12-29 21:49:13.168 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 21:49:13.171 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-3456_train.pkl
2022-12-29 21:49:16.582 DEBUG: Taking gradient step
2022-12-29 21:49:16.590 DEBUG: Loss 0: {'policy_loss': -0.02024185405039764, 'entropy_loss': -0.03087555058300495, 'vf_loss': 0.0035907742907101223, 'total_loss': -0.04752663034269247, 'approx_kl': -5.180481821298599e-09, 'clip_fraction': 0.0, 'grad_norm': 3.1366796493530273}
2022-12-29 21:49:19.820 DEBUG: Taking gradient step
2022-12-29 21:49:19.828 DEBUG: Loss 1: {'policy_loss': -0.01260394056611536, 'entropy_loss': -0.03239175025373697, 'vf_loss': 0.0035130885493427845, 'total_loss': -0.041482602270509546, 'approx_kl': 0.0043322204146534204, 'clip_fraction': 0.11848958395421505, 'grad_norm': 3.0279622077941895}
2022-12-29 21:49:23.129 DEBUG: Taking gradient step
2022-12-29 21:49:23.136 DEBUG: Loss 2: {'policy_loss': -0.020473401674361756, 'entropy_loss': -0.03223801637068391, 'vf_loss': 0.00347950751550054, 'total_loss': -0.04923191052954512, 'approx_kl': 0.0231844624504447, 'clip_fraction': 0.3463541716337204, 'grad_norm': 2.033843517303467}
2022-12-29 21:49:26.322 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-29 21:49:26.323 INFO: Optimization: policy loss=-0.020, vf loss=0.003, entropy loss=-0.032, total loss=-0.049, num steps=3
2022-12-29 21:49:26.330 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 21:49:27.775 INFO: Evaluation rollout: return=0.701 (0.0), episode length=5.0
2022-12-29 21:49:27.776 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 21:49:27.779 INFO: Iteration: 17/137, steps: 3672
2022-12-29 21:49:36.336 DEBUG: Atoms are too close
2022-12-29 21:49:57.994 DEBUG: Atoms are too close
2022-12-29 21:50:05.986 DEBUG: Atoms are too close
2022-12-29 21:50:08.648 DEBUG: Atoms are too close
2022-12-29 21:50:08.649 DEBUG: Atoms are too close
2022-12-29 21:50:23.481 INFO: Training rollout: return=-2.171 (6.9), episode length=4.8
2022-12-29 21:50:23.483 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 21:50:23.486 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-3672_train.pkl
2022-12-29 21:50:27.136 DEBUG: Taking gradient step
2022-12-29 21:50:27.144 DEBUG: Loss 0: {'policy_loss': -0.023599785639413968, 'entropy_loss': -0.03189094550907612, 'vf_loss': 0.031390501717102774, 'total_loss': -0.02410022943138731, 'approx_kl': -3.4672364535026645e-08, 'clip_fraction': 0.0, 'grad_norm': 20.873327255249023}
2022-12-29 21:50:30.465 DEBUG: Taking gradient step
2022-12-29 21:50:30.472 DEBUG: Loss 1: {'policy_loss': -0.00614398805526257, 'entropy_loss': -0.0327445175498724, 'vf_loss': 0.0339054544786786, 'total_loss': -0.004983051126456372, 'approx_kl': 0.002779534552246332, 'clip_fraction': 0.08854166697710752, 'grad_norm': 12.180545806884766}
2022-12-29 21:50:33.896 DEBUG: Taking gradient step
2022-12-29 21:50:33.904 DEBUG: Loss 2: {'policy_loss': -0.066644042496735, 'entropy_loss': -0.03091814136132598, 'vf_loss': 0.028924653435343235, 'total_loss': -0.06863753042271772, 'approx_kl': 0.011142630130052567, 'clip_fraction': 0.2109375, 'grad_norm': 9.826231002807617}
2022-12-29 21:50:37.406 DEBUG: Taking gradient step
2022-12-29 21:50:37.417 DEBUG: Loss 3: {'policy_loss': 0.03240493106712619, 'entropy_loss': -0.02996250009164214, 'vf_loss': 0.041466255026897096, 'total_loss': 0.04390868600238114, 'approx_kl': 0.028201451059430838, 'clip_fraction': 0.2513020858168602, 'grad_norm': 5.078715801239014}
2022-12-29 21:50:40.909 DEBUG: Taking gradient step
2022-12-29 21:50:40.916 DEBUG: Loss 4: {'policy_loss': -0.051166260061539015, 'entropy_loss': -0.03010735334828496, 'vf_loss': 0.03139503761859034, 'total_loss': -0.049878575791233636, 'approx_kl': 0.031941550783813, 'clip_fraction': 0.28515625, 'grad_norm': 5.017468452453613}
2022-12-29 21:50:44.220 DEBUG: Taking gradient step
2022-12-29 21:50:44.231 DEBUG: Loss 5: {'policy_loss': -0.03768927603766682, 'entropy_loss': -0.02949690306559205, 'vf_loss': 0.03387114591393612, 'total_loss': -0.03331503318932275, 'approx_kl': 0.028019568882882595, 'clip_fraction': 0.3072916716337204, 'grad_norm': 6.173816204071045}
2022-12-29 21:50:47.753 DEBUG: Taking gradient step
2022-12-29 21:50:47.761 DEBUG: Loss 6: {'policy_loss': -0.020797812293476395, 'entropy_loss': -0.02838221611455083, 'vf_loss': 0.03615746800942347, 'total_loss': -0.013022560398603764, 'approx_kl': 0.03143380116671324, 'clip_fraction': 0.2838541716337204, 'grad_norm': 5.142210960388184}
2022-12-29 21:50:51.357 DEBUG: Early stopping at step 7 for reaching max KL.
2022-12-29 21:50:51.358 INFO: Optimization: policy loss=-0.021, vf loss=0.036, entropy loss=-0.028, total loss=-0.013, num steps=7
2022-12-29 21:50:51.364 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 21:50:52.792 INFO: Evaluation rollout: return=0.701 (0.0), episode length=5.0
2022-12-29 21:50:52.793 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 21:50:52.795 INFO: Iteration: 18/137, steps: 3888
2022-12-29 21:51:10.883 DEBUG: Atoms are too close
2022-12-29 21:51:49.991 INFO: Training rollout: return=0.004 (3.3), episode length=4.9
2022-12-29 21:51:49.995 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 21:51:49.997 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-3888_train.pkl
2022-12-29 21:51:53.403 DEBUG: Taking gradient step
2022-12-29 21:51:53.412 DEBUG: Loss 0: {'policy_loss': -0.01663760274289044, 'entropy_loss': -0.028929231222718954, 'vf_loss': 0.0034603391723243065, 'total_loss': -0.042106494793285085, 'approx_kl': -1.794736093074789e-08, 'clip_fraction': 0.0, 'grad_norm': 6.878684043884277}
2022-12-29 21:51:56.793 DEBUG: Taking gradient step
2022-12-29 21:51:56.808 DEBUG: Loss 1: {'policy_loss': 0.026405212076160672, 'entropy_loss': -0.02884455630555749, 'vf_loss': 0.005986416807942344, 'total_loss': 0.0035470725785455293, 'approx_kl': 0.013275043165776879, 'clip_fraction': 0.0924479179084301, 'grad_norm': 2.0693087577819824}
2022-12-29 21:52:00.415 DEBUG: Taking gradient step
2022-12-29 21:52:00.423 DEBUG: Loss 2: {'policy_loss': -0.03240391001344568, 'entropy_loss': -0.02769803535193205, 'vf_loss': 0.0034910757517436345, 'total_loss': -0.056610869613634096, 'approx_kl': 0.028997270856052637, 'clip_fraction': 0.1653645858168602, 'grad_norm': 1.9765994548797607}
2022-12-29 21:52:04.072 DEBUG: Taking gradient step
2022-12-29 21:52:04.083 DEBUG: Loss 3: {'policy_loss': -0.030833929294255435, 'entropy_loss': -0.02824280969798565, 'vf_loss': 0.003473111597260088, 'total_loss': -0.055603627394981, 'approx_kl': 0.04298308631405234, 'clip_fraction': 0.20703125, 'grad_norm': 1.5467427968978882}
2022-12-29 21:52:07.741 DEBUG: Taking gradient step
2022-12-29 21:52:07.749 DEBUG: Loss 4: {'policy_loss': -0.0457097908596855, 'entropy_loss': -0.028564408887177706, 'vf_loss': 0.0034984258815283138, 'total_loss': -0.0707757738653349, 'approx_kl': 0.035891730803996325, 'clip_fraction': 0.27734375, 'grad_norm': 1.2762565612792969}
2022-12-29 21:52:11.392 DEBUG: Early stopping at step 5 for reaching max KL.
2022-12-29 21:52:11.393 INFO: Optimization: policy loss=-0.046, vf loss=0.003, entropy loss=-0.029, total loss=-0.071, num steps=5
2022-12-29 21:52:11.398 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 21:52:12.781 INFO: Evaluation rollout: return=0.711 (0.0), episode length=5.0
2022-12-29 21:52:12.782 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 21:52:12.784 INFO: Iteration: 19/137, steps: 4104
2022-12-29 21:53:10.361 INFO: Training rollout: return=0.555 (0.1), episode length=5.0
2022-12-29 21:53:10.365 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 21:53:10.367 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-4104_train.pkl
2022-12-29 21:53:13.764 DEBUG: Taking gradient step
2022-12-29 21:53:13.776 DEBUG: Loss 0: {'policy_loss': 0.010990995578114525, 'entropy_loss': -0.030253220815211535, 'vf_loss': 0.0004751708745272158, 'total_loss': -0.01878705436256979, 'approx_kl': 5.98374754190445e-08, 'clip_fraction': 0.0, 'grad_norm': 16.791091918945312}
2022-12-29 21:53:17.177 DEBUG: Taking gradient step
2022-12-29 21:53:17.185 DEBUG: Loss 1: {'policy_loss': -0.022986470294307903, 'entropy_loss': -0.03205348504707217, 'vf_loss': 0.00046640242056418004, 'total_loss': -0.05457355292081589, 'approx_kl': 0.030668706400319934, 'clip_fraction': 0.1888020858168602, 'grad_norm': 13.103836059570312}
2022-12-29 21:53:20.688 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-29 21:53:20.689 INFO: Optimization: policy loss=-0.023, vf loss=0.000, entropy loss=-0.032, total loss=-0.055, num steps=2
2022-12-29 21:53:20.695 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 21:53:22.070 INFO: Evaluation rollout: return=0.720 (0.0), episode length=5.0
2022-12-29 21:53:22.072 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 21:53:22.074 INFO: Iteration: 20/137, steps: 4320
2022-12-29 21:54:19.982 INFO: Training rollout: return=0.553 (0.1), episode length=5.0
2022-12-29 21:54:19.984 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 21:54:19.987 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-4320_train.pkl
2022-12-29 21:54:23.396 DEBUG: Taking gradient step
2022-12-29 21:54:23.404 DEBUG: Loss 0: {'policy_loss': 0.004613019449120952, 'entropy_loss': -0.03209587465971708, 'vf_loss': 0.0004244793961576914, 'total_loss': -0.02705837581443844, 'approx_kl': 2.3399479687213898e-08, 'clip_fraction': 0.0, 'grad_norm': 15.732478141784668}
2022-12-29 21:54:26.840 DEBUG: Early stopping at step 1 for reaching max KL.
2022-12-29 21:54:26.841 INFO: Optimization: policy loss=0.005, vf loss=0.000, entropy loss=-0.032, total loss=-0.027, num steps=1
2022-12-29 21:54:26.846 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 21:54:28.232 INFO: Evaluation rollout: return=0.715 (0.0), episode length=5.0
2022-12-29 21:54:28.233 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 21:54:28.236 DEBUG: Deleting old model: runs/CH4_int/models/CH4_int_run-1_steps-2376.model
2022-12-29 21:54:28.238 DEBUG: Saving model: runs/CH4_int/models/CH4_int_run-1_steps-4536.model
2022-12-29 21:54:28.260 INFO: Iteration: 21/137, steps: 4536
2022-12-29 21:55:25.219 INFO: Training rollout: return=0.556 (0.1), episode length=5.0
2022-12-29 21:55:25.221 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 21:55:25.223 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-4536_train.pkl
2022-12-29 21:55:28.624 DEBUG: Taking gradient step
2022-12-29 21:55:28.631 DEBUG: Loss 0: {'policy_loss': 0.030308511174541475, 'entropy_loss': -0.03387761441990733, 'vf_loss': 0.0004081586325602641, 'total_loss': -0.00316094461280559, 'approx_kl': 1.4551915228366852e-08, 'clip_fraction': 0.0, 'grad_norm': 7.251195430755615}
2022-12-29 21:55:32.072 DEBUG: Taking gradient step
2022-12-29 21:55:32.080 DEBUG: Loss 1: {'policy_loss': 0.02955083826263958, 'entropy_loss': -0.034329918678849936, 'vf_loss': 0.0003907303189713068, 'total_loss': -0.004388350097239049, 'approx_kl': 0.01811548275873065, 'clip_fraction': 0.2330729216337204, 'grad_norm': 16.43853187561035}
2022-12-29 21:55:35.387 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-29 21:55:35.389 INFO: Optimization: policy loss=0.030, vf loss=0.000, entropy loss=-0.034, total loss=-0.004, num steps=2
2022-12-29 21:55:35.395 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 21:55:36.801 INFO: Evaluation rollout: return=0.713 (0.0), episode length=5.0
2022-12-29 21:55:36.802 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 21:55:36.805 INFO: Iteration: 22/137, steps: 4752
2022-12-29 21:56:34.004 INFO: Training rollout: return=0.513 (0.1), episode length=5.0
2022-12-29 21:56:34.006 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 21:56:34.009 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-4752_train.pkl
2022-12-29 21:56:37.495 DEBUG: Taking gradient step
2022-12-29 21:56:37.506 DEBUG: Loss 0: {'policy_loss': 0.031508108349872554, 'entropy_loss': -0.035055074375122786, 'vf_loss': 0.00032309407691866215, 'total_loss': -0.003223871948331569, 'approx_kl': -2.444721758365631e-08, 'clip_fraction': 0.0, 'grad_norm': 13.97437572479248}
2022-12-29 21:56:40.979 DEBUG: Early stopping at step 1 for reaching max KL.
2022-12-29 21:56:40.980 INFO: Optimization: policy loss=0.032, vf loss=0.000, entropy loss=-0.035, total loss=-0.003, num steps=1
2022-12-29 21:56:40.986 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 21:56:42.372 INFO: Evaluation rollout: return=0.720 (0.0), episode length=5.0
2022-12-29 21:56:42.373 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 21:56:42.376 INFO: Iteration: 23/137, steps: 4968
2022-12-29 21:56:57.751 DEBUG: There is a single atom floating around
2022-12-29 21:57:13.522 DEBUG: Atoms are too close
2022-12-29 21:57:39.241 INFO: Training rollout: return=-0.569 (4.6), episode length=5.0
2022-12-29 21:57:39.243 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 21:57:39.245 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-4968_train.pkl
2022-12-29 21:57:42.733 DEBUG: Taking gradient step
2022-12-29 21:57:42.741 DEBUG: Loss 0: {'policy_loss': -0.0018358880150151774, 'entropy_loss': -0.034123378805816174, 'vf_loss': 0.01763822267631654, 'total_loss': -0.01832104414451481, 'approx_kl': 2.041148761122713e-08, 'clip_fraction': 0.0, 'grad_norm': 18.800439834594727}
2022-12-29 21:57:46.244 DEBUG: Taking gradient step
2022-12-29 21:57:46.252 DEBUG: Loss 1: {'policy_loss': -0.012078275238080246, 'entropy_loss': -0.03395499614998698, 'vf_loss': 0.017666050585391578, 'total_loss': -0.028367220802675654, 'approx_kl': 0.004580243956297636, 'clip_fraction': 0.1744791679084301, 'grad_norm': 5.749624252319336}
2022-12-29 21:57:49.634 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-29 21:57:49.634 INFO: Optimization: policy loss=-0.012, vf loss=0.018, entropy loss=-0.034, total loss=-0.028, num steps=2
2022-12-29 21:57:49.639 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 21:57:51.024 INFO: Evaluation rollout: return=0.741 (0.0), episode length=5.0
2022-12-29 21:57:51.025 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 21:57:51.027 INFO: Iteration: 24/137, steps: 5184
2022-12-29 21:58:38.867 DEBUG: There is a single atom floating around
2022-12-29 21:58:48.306 INFO: Training rollout: return=-0.016 (3.3), episode length=5.0
2022-12-29 21:58:48.308 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 21:58:48.311 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-5184_train.pkl
2022-12-29 21:58:51.918 DEBUG: Taking gradient step
2022-12-29 21:58:51.929 DEBUG: Loss 0: {'policy_loss': 0.06254560859535174, 'entropy_loss': -0.0340126003138721, 'vf_loss': 0.01303179307448995, 'total_loss': 0.04156480135596958, 'approx_kl': -3.4924596548080444e-09, 'clip_fraction': 0.0, 'grad_norm': 12.902555465698242}
2022-12-29 21:58:55.415 DEBUG: Taking gradient step
2022-12-29 21:58:55.422 DEBUG: Loss 1: {'policy_loss': 0.042409279467416926, 'entropy_loss': -0.03488348284736276, 'vf_loss': 0.010445325666636564, 'total_loss': 0.017971122286690726, 'approx_kl': 0.028371624182909727, 'clip_fraction': 0.2447916716337204, 'grad_norm': 22.16777229309082}
2022-12-29 21:58:58.765 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-29 21:58:58.765 INFO: Optimization: policy loss=0.042, vf loss=0.010, entropy loss=-0.035, total loss=0.018, num steps=2
2022-12-29 21:58:58.772 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 21:59:00.123 INFO: Evaluation rollout: return=0.756 (0.0), episode length=5.0
2022-12-29 21:59:00.124 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 21:59:00.127 INFO: Iteration: 25/137, steps: 5400
2022-12-29 21:59:57.499 INFO: Training rollout: return=0.551 (0.1), episode length=5.0
2022-12-29 21:59:57.501 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 21:59:57.504 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-5400_train.pkl
2022-12-29 22:00:01.010 DEBUG: Taking gradient step
2022-12-29 22:00:01.018 DEBUG: Loss 0: {'policy_loss': -0.04977202190926448, 'entropy_loss': -0.03294215118512511, 'vf_loss': 0.00030686447662972593, 'total_loss': -0.08240730861775987, 'approx_kl': -9.580980986356735e-08, 'clip_fraction': 0.0, 'grad_norm': 6.446650981903076}
2022-12-29 22:00:04.286 DEBUG: Taking gradient step
2022-12-29 22:00:04.294 DEBUG: Loss 1: {'policy_loss': -0.02395104412139725, 'entropy_loss': -0.03414984606206417, 'vf_loss': 0.00028775088177659177, 'total_loss': -0.05781313930168483, 'approx_kl': 0.025498067494481802, 'clip_fraction': 0.12630208395421505, 'grad_norm': 7.249317169189453}
2022-12-29 22:00:07.629 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-29 22:00:07.630 INFO: Optimization: policy loss=-0.024, vf loss=0.000, entropy loss=-0.034, total loss=-0.058, num steps=2
2022-12-29 22:00:07.635 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 22:00:09.063 INFO: Evaluation rollout: return=0.764 (0.0), episode length=5.0
2022-12-29 22:00:09.064 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 22:00:09.067 INFO: Iteration: 26/137, steps: 5616
2022-12-29 22:00:39.062 DEBUG: Atoms are too close
2022-12-29 22:01:06.746 INFO: Training rollout: return=-0.010 (3.3), episode length=5.0
2022-12-29 22:01:06.748 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 22:01:06.750 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-5616_train.pkl
2022-12-29 22:01:10.122 DEBUG: Taking gradient step
2022-12-29 22:01:10.133 DEBUG: Loss 0: {'policy_loss': 0.10165537152835841, 'entropy_loss': -0.034075960516929626, 'vf_loss': 0.015535573257880126, 'total_loss': 0.0831149842693089, 'approx_kl': 1.501757651567459e-08, 'clip_fraction': 0.0, 'grad_norm': 27.7484188079834}
2022-12-29 22:01:13.854 DEBUG: Taking gradient step
2022-12-29 22:01:13.862 DEBUG: Loss 1: {'policy_loss': -0.030376507630554765, 'entropy_loss': -0.0347068952396512, 'vf_loss': 0.007837476282245563, 'total_loss': -0.0572459265879604, 'approx_kl': 0.01792632881551981, 'clip_fraction': 0.12369791697710752, 'grad_norm': 10.490987777709961}
2022-12-29 22:01:17.340 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-29 22:01:17.340 INFO: Optimization: policy loss=-0.030, vf loss=0.008, entropy loss=-0.035, total loss=-0.057, num steps=2
2022-12-29 22:01:17.346 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 22:01:18.791 INFO: Evaluation rollout: return=0.770 (0.0), episode length=5.0
2022-12-29 22:01:18.792 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 22:01:18.794 INFO: Iteration: 27/137, steps: 5832
2022-12-29 22:01:40.660 DEBUG: Atoms are too close
2022-12-29 22:02:12.042 DEBUG: Atoms are too close
2022-12-29 22:02:15.241 INFO: Training rollout: return=-0.513 (4.5), episode length=4.9
2022-12-29 22:02:15.243 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 22:02:15.246 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-5832_train.pkl
2022-12-29 22:02:18.864 DEBUG: Taking gradient step
2022-12-29 22:02:18.877 DEBUG: Loss 0: {'policy_loss': -0.022669335990657673, 'entropy_loss': -0.03389064269140363, 'vf_loss': 0.009428435391130653, 'total_loss': -0.04713154329093065, 'approx_kl': -3.7175293066127324e-08, 'clip_fraction': 0.0, 'grad_norm': 16.509910583496094}
2022-12-29 22:02:22.296 DEBUG: Taking gradient step
2022-12-29 22:02:22.303 DEBUG: Loss 1: {'policy_loss': -0.022909548709108718, 'entropy_loss': -0.032226632349193096, 'vf_loss': 0.009447656082965772, 'total_loss': -0.04568852497533604, 'approx_kl': 0.02138144848868251, 'clip_fraction': 0.057291666977107525, 'grad_norm': 16.623334884643555}
2022-12-29 22:02:25.800 DEBUG: Taking gradient step
2022-12-29 22:02:25.809 DEBUG: Loss 2: {'policy_loss': 0.005703529605687711, 'entropy_loss': -0.031908121425658464, 'vf_loss': 0.012051800370419165, 'total_loss': -0.014152791449551588, 'approx_kl': 0.042883502785116434, 'clip_fraction': 0.2213541679084301, 'grad_norm': 2.150522232055664}
2022-12-29 22:02:29.183 DEBUG: Taking gradient step
2022-12-29 22:02:29.190 DEBUG: Loss 3: {'policy_loss': 0.004129985709925092, 'entropy_loss': -0.032346478663384914, 'vf_loss': 0.01191060645308194, 'total_loss': -0.01630588650037788, 'approx_kl': 0.030742931179702282, 'clip_fraction': 0.3059895858168602, 'grad_norm': 2.0020101070404053}
2022-12-29 22:02:32.619 DEBUG: Taking gradient step
2022-12-29 22:02:32.627 DEBUG: Loss 4: {'policy_loss': -0.03895025747111766, 'entropy_loss': -0.03003507014364004, 'vf_loss': 0.009451566643060842, 'total_loss': -0.05953376097169687, 'approx_kl': 0.02311914972960949, 'clip_fraction': 0.3346354216337204, 'grad_norm': 1.785967230796814}
2022-12-29 22:02:36.033 DEBUG: Taking gradient step
2022-12-29 22:02:36.041 DEBUG: Loss 5: {'policy_loss': -0.03709156863701874, 'entropy_loss': -0.0308257844299078, 'vf_loss': 0.009431958078799015, 'total_loss': -0.05848539498812753, 'approx_kl': 0.024597021751105785, 'clip_fraction': 0.34765625, 'grad_norm': 1.7922186851501465}
2022-12-29 22:02:39.581 DEBUG: Taking gradient step
2022-12-29 22:02:39.592 DEBUG: Loss 6: {'policy_loss': -0.0012855317356713983, 'entropy_loss': -0.03233426297083497, 'vf_loss': 0.012022427946092904, 'total_loss': -0.021597366760413465, 'approx_kl': 0.005088113248348236, 'clip_fraction': 0.3841145858168602, 'grad_norm': 1.1532893180847168}
2022-12-29 22:02:43.141 DEBUG: Taking gradient step
2022-12-29 22:02:43.149 DEBUG: Loss 7: {'policy_loss': -0.03648948733761476, 'entropy_loss': -0.0324309472925961, 'vf_loss': 0.009419774463460392, 'total_loss': -0.05950066016675047, 'approx_kl': 0.03132157260552049, 'clip_fraction': 0.4049479216337204, 'grad_norm': 1.3377840518951416}
2022-12-29 22:02:46.391 DEBUG: Taking gradient step
2022-12-29 22:02:46.399 DEBUG: Loss 8: {'policy_loss': -0.036733635797375215, 'entropy_loss': -0.03501599095761776, 'vf_loss': 0.009400766072248802, 'total_loss': -0.06234886068274418, 'approx_kl': 0.01031732838600874, 'clip_fraction': 0.4153645858168602, 'grad_norm': 1.3263015747070312}
2022-12-29 22:02:49.896 DEBUG: Taking gradient step
2022-12-29 22:02:49.905 DEBUG: Loss 9: {'policy_loss': -0.007942173343757108, 'entropy_loss': -0.034308033995330334, 'vf_loss': 0.011982589088112134, 'total_loss': -0.03026761825097531, 'approx_kl': 0.012681859952863306, 'clip_fraction': 0.4283854216337204, 'grad_norm': 1.12600839138031}
2022-12-29 22:02:49.905 INFO: Optimization: policy loss=-0.008, vf loss=0.012, entropy loss=-0.034, total loss=-0.030, num steps=10
2022-12-29 22:02:49.913 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 22:02:51.275 INFO: Evaluation rollout: return=0.640 (0.0), episode length=5.0
2022-12-29 22:02:51.276 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 22:02:51.280 INFO: Iteration: 28/137, steps: 6048
2022-12-29 22:03:38.324 DEBUG: Atoms are too close
2022-12-29 22:03:48.241 INFO: Training rollout: return=-0.045 (3.3), episode length=5.0
2022-12-29 22:03:48.243 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 22:03:48.246 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-6048_train.pkl
2022-12-29 22:03:51.510 DEBUG: Taking gradient step
2022-12-29 22:03:51.518 DEBUG: Loss 0: {'policy_loss': -0.02370558850976013, 'entropy_loss': -0.03415358951315284, 'vf_loss': 0.007895196096443525, 'total_loss': -0.04996398192646945, 'approx_kl': -3.0617229640483856e-08, 'clip_fraction': 0.0, 'grad_norm': 10.042688369750977}
2022-12-29 22:03:54.986 DEBUG: Taking gradient step
2022-12-29 22:03:54.993 DEBUG: Loss 1: {'policy_loss': -0.02937070230625903, 'entropy_loss': -0.03595917718484998, 'vf_loss': 0.007899330053211915, 'total_loss': -0.05743054943789709, 'approx_kl': 0.01521777082234621, 'clip_fraction': 0.140625, 'grad_norm': 6.842409133911133}
2022-12-29 22:03:58.292 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-29 22:03:58.292 INFO: Optimization: policy loss=-0.029, vf loss=0.008, entropy loss=-0.036, total loss=-0.057, num steps=2
2022-12-29 22:03:58.299 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 22:03:59.758 INFO: Evaluation rollout: return=0.647 (0.0), episode length=5.0
2022-12-29 22:03:59.759 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 22:03:59.762 INFO: Iteration: 29/137, steps: 6264
2022-12-29 22:04:23.489 DEBUG: Atoms are too close
2022-12-29 22:04:42.907 DEBUG: Atoms are too close
2022-12-29 22:04:56.106 INFO: Training rollout: return=-0.583 (4.6), episode length=4.9
2022-12-29 22:04:56.108 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 22:04:56.111 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-6264_train.pkl
2022-12-29 22:04:59.455 DEBUG: Taking gradient step
2022-12-29 22:04:59.462 DEBUG: Loss 0: {'policy_loss': 0.08147432089694553, 'entropy_loss': -0.03549239505082369, 'vf_loss': 0.01859655947382953, 'total_loss': 0.06457848531995136, 'approx_kl': 5.234809208332081e-08, 'clip_fraction': 0.0, 'grad_norm': 38.27579116821289}
2022-12-29 22:05:02.844 DEBUG: Taking gradient step
2022-12-29 22:05:02.852 DEBUG: Loss 1: {'policy_loss': -0.025381035209855116, 'entropy_loss': -0.03424343978986144, 'vf_loss': 0.010916985331291516, 'total_loss': -0.04870748966842504, 'approx_kl': 0.016572208609431982, 'clip_fraction': 0.029947916977107525, 'grad_norm': 15.239828109741211}
2022-12-29 22:05:06.141 DEBUG: Taking gradient step
2022-12-29 22:05:06.149 DEBUG: Loss 2: {'policy_loss': 0.01463975400648099, 'entropy_loss': -0.03615208435803652, 'vf_loss': 0.013427308671988684, 'total_loss': -0.008085021679566845, 'approx_kl': 0.03912446554750204, 'clip_fraction': 0.1809895858168602, 'grad_norm': 9.640377044677734}
2022-12-29 22:05:09.614 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-29 22:05:09.615 INFO: Optimization: policy loss=0.015, vf loss=0.013, entropy loss=-0.036, total loss=-0.008, num steps=3
2022-12-29 22:05:09.622 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 22:05:10.942 INFO: Evaluation rollout: return=0.635 (0.0), episode length=5.0
2022-12-29 22:05:10.943 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 22:05:10.945 INFO: Iteration: 30/137, steps: 6480
2022-12-29 22:05:25.675 DEBUG: Atoms are too close
2022-12-29 22:05:57.022 DEBUG: There is a single atom floating around
2022-12-29 22:05:57.576 DEBUG: There is a single atom floating around
2022-12-29 22:06:07.534 INFO: Training rollout: return=-1.146 (5.6), episode length=5.0
2022-12-29 22:06:07.535 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 22:06:07.537 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-6480_train.pkl
2022-12-29 22:06:10.868 DEBUG: Taking gradient step
2022-12-29 22:06:10.875 DEBUG: Loss 0: {'policy_loss': 0.008554175128001567, 'entropy_loss': -0.03590864967554808, 'vf_loss': 0.02819566999437493, 'total_loss': 0.0008411954468284175, 'approx_kl': 5.4249539971351624e-08, 'clip_fraction': 0.0, 'grad_norm': 15.063359260559082}
2022-12-29 22:06:14.166 DEBUG: Taking gradient step
2022-12-29 22:06:14.173 DEBUG: Loss 1: {'policy_loss': -0.023102644892022607, 'entropy_loss': -0.0350634939968586, 'vf_loss': 0.025726383971987385, 'total_loss': -0.03243975491689382, 'approx_kl': 5.5343902204185724e-05, 'clip_fraction': 0.03515625, 'grad_norm': 11.919190406799316}
2022-12-29 22:06:17.690 DEBUG: Taking gradient step
2022-12-29 22:06:17.697 DEBUG: Loss 2: {'policy_loss': -0.05680107817624533, 'entropy_loss': -0.03405058663338423, 'vf_loss': 0.02314503112119574, 'total_loss': -0.06770663368843381, 'approx_kl': 0.009812581003643572, 'clip_fraction': 0.15625, 'grad_norm': 10.558564186096191}
2022-12-29 22:06:21.106 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-29 22:06:21.107 INFO: Optimization: policy loss=-0.057, vf loss=0.023, entropy loss=-0.034, total loss=-0.068, num steps=3
2022-12-29 22:06:21.113 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 22:06:22.495 INFO: Evaluation rollout: return=0.729 (0.0), episode length=5.0
2022-12-29 22:06:22.496 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 22:06:22.498 DEBUG: Deleting old model: runs/CH4_int/models/CH4_int_run-1_steps-4536.model
2022-12-29 22:06:22.503 DEBUG: Saving model: runs/CH4_int/models/CH4_int_run-1_steps-6696.model
2022-12-29 22:06:22.524 INFO: Iteration: 31/137, steps: 6696
2022-12-29 22:07:20.006 INFO: Training rollout: return=0.539 (0.1), episode length=5.0
2022-12-29 22:07:20.008 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 22:07:20.011 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-6696_train.pkl
2022-12-29 22:07:23.337 DEBUG: Taking gradient step
2022-12-29 22:07:23.345 DEBUG: Loss 0: {'policy_loss': 0.005213615133773811, 'entropy_loss': -0.03537801560014486, 'vf_loss': 0.00032289093349975226, 'total_loss': -0.029841509532871298, 'approx_kl': -4.035731127061126e-08, 'clip_fraction': 0.0, 'grad_norm': 19.205080032348633}
2022-12-29 22:07:26.657 DEBUG: Taking gradient step
2022-12-29 22:07:26.664 DEBUG: Loss 1: {'policy_loss': 0.010470220261898405, 'entropy_loss': -0.03526660054922104, 'vf_loss': 0.00033800626736305754, 'total_loss': -0.024458374019959574, 'approx_kl': 0.02644786238670349, 'clip_fraction': 0.1588541679084301, 'grad_norm': 11.621099472045898}
2022-12-29 22:07:30.047 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-29 22:07:30.047 INFO: Optimization: policy loss=0.010, vf loss=0.000, entropy loss=-0.035, total loss=-0.024, num steps=2
2022-12-29 22:07:30.053 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 22:07:31.463 INFO: Evaluation rollout: return=0.723 (0.0), episode length=5.0
2022-12-29 22:07:31.464 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 22:07:31.467 INFO: Iteration: 32/137, steps: 6912
2022-12-29 22:08:11.174 DEBUG: Atoms are too close
2022-12-29 22:08:13.096 DEBUG: Atoms are too close
2022-12-29 22:08:27.757 INFO: Training rollout: return=-0.527 (4.6), episode length=4.9
2022-12-29 22:08:27.759 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 22:08:27.762 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-6912_train.pkl
2022-12-29 22:08:31.067 DEBUG: Taking gradient step
2022-12-29 22:08:31.075 DEBUG: Loss 0: {'policy_loss': -0.026331176900430204, 'entropy_loss': -0.03404331672936678, 'vf_loss': 0.010887820280943308, 'total_loss': -0.04948667334885367, 'approx_kl': 3.2208238742725825e-08, 'clip_fraction': 0.0, 'grad_norm': 11.97008228302002}
2022-12-29 22:08:34.444 DEBUG: Taking gradient step
2022-12-29 22:08:34.451 DEBUG: Loss 1: {'policy_loss': 0.0025834432571680242, 'entropy_loss': -0.03419043589383364, 'vf_loss': 0.013347828232318955, 'total_loss': -0.018259164404346655, 'approx_kl': -0.002771638799458742, 'clip_fraction': 0.1471354216337204, 'grad_norm': 5.3648786544799805}
2022-12-29 22:08:37.801 DEBUG: Taking gradient step
2022-12-29 22:08:37.808 DEBUG: Loss 2: {'policy_loss': -0.003741614572585421, 'entropy_loss': -0.03236428927630186, 'vf_loss': 0.013350080770742437, 'total_loss': -0.022755823078144846, 'approx_kl': -0.00039585470221936703, 'clip_fraction': 0.2513020858168602, 'grad_norm': 5.069247722625732}
2022-12-29 22:08:41.110 DEBUG: Taking gradient step
2022-12-29 22:08:41.118 DEBUG: Loss 3: {'policy_loss': 0.029618573871637126, 'entropy_loss': -0.0303229414857924, 'vf_loss': 0.015920703299125035, 'total_loss': 0.015216335684969766, 'approx_kl': 0.01780451461672783, 'clip_fraction': 0.28125, 'grad_norm': 23.20197296142578}
2022-12-29 22:08:44.597 DEBUG: Taking gradient step
2022-12-29 22:08:44.604 DEBUG: Loss 4: {'policy_loss': -0.04549928314179074, 'entropy_loss': -0.029441041871905327, 'vf_loss': 0.01091920978151262, 'total_loss': -0.06402111523218344, 'approx_kl': 0.029916096245869994, 'clip_fraction': 0.3072916679084301, 'grad_norm': 2.9852795600891113}
2022-12-29 22:08:47.954 DEBUG: Taking gradient step
2022-12-29 22:08:47.961 DEBUG: Loss 5: {'policy_loss': -0.0023636366578592694, 'entropy_loss': -0.02986840484663844, 'vf_loss': 0.013357505243593257, 'total_loss': -0.018874536260904455, 'approx_kl': 0.04343150556087494, 'clip_fraction': 0.328125, 'grad_norm': 1.7205049991607666}
2022-12-29 22:08:51.345 DEBUG: Taking gradient step
2022-12-29 22:08:51.353 DEBUG: Loss 6: {'policy_loss': -0.0012920298669909618, 'entropy_loss': -0.03188979625701904, 'vf_loss': 0.013353678889454382, 'total_loss': -0.019828147234555626, 'approx_kl': 0.012685523368418217, 'clip_fraction': 0.3046875, 'grad_norm': 2.3533334732055664}
2022-12-29 22:08:54.909 DEBUG: Taking gradient step
2022-12-29 22:08:54.917 DEBUG: Loss 7: {'policy_loss': -0.012436295014858868, 'entropy_loss': -0.03120781434699893, 'vf_loss': 0.013449907116917266, 'total_loss': -0.030194202244940536, 'approx_kl': -0.0010013086721301079, 'clip_fraction': 0.3307291716337204, 'grad_norm': 1.6879249811172485}
2022-12-29 22:08:58.265 DEBUG: Taking gradient step
2022-12-29 22:08:58.272 DEBUG: Loss 8: {'policy_loss': -0.04404948598799266, 'entropy_loss': -0.031040276400744915, 'vf_loss': 0.010898384516280862, 'total_loss': -0.06419137787245671, 'approx_kl': -0.0021844678558409214, 'clip_fraction': 0.3190104179084301, 'grad_norm': 2.5907363891601562}
2022-12-29 22:09:01.696 DEBUG: Taking gradient step
2022-12-29 22:09:01.704 DEBUG: Loss 9: {'policy_loss': -0.041870774923217835, 'entropy_loss': -0.03280910896137357, 'vf_loss': 0.010887616875767218, 'total_loss': -0.06379226700882419, 'approx_kl': -0.021294722333550453, 'clip_fraction': 0.3541666716337204, 'grad_norm': 5.73769474029541}
2022-12-29 22:09:01.704 INFO: Optimization: policy loss=-0.042, vf loss=0.011, entropy loss=-0.033, total loss=-0.064, num steps=10
2022-12-29 22:09:01.711 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 22:09:03.110 INFO: Evaluation rollout: return=0.713 (0.0), episode length=5.0
2022-12-29 22:09:03.112 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 22:09:03.115 INFO: Iteration: 33/137, steps: 7128
2022-12-29 22:09:43.056 DEBUG: Atoms are too close
2022-12-29 22:10:00.621 INFO: Training rollout: return=-0.012 (3.3), episode length=4.9
2022-12-29 22:10:00.623 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 22:10:00.625 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-7128_train.pkl
2022-12-29 22:10:04.152 DEBUG: Taking gradient step
2022-12-29 22:10:04.160 DEBUG: Loss 0: {'policy_loss': -0.022952629302577673, 'entropy_loss': -0.032801943365484476, 'vf_loss': 0.004891068006799108, 'total_loss': -0.05086350466126304, 'approx_kl': 1.1777350206187975e-08, 'clip_fraction': 0.0, 'grad_norm': 13.562253952026367}
2022-12-29 22:10:07.444 DEBUG: Taking gradient step
2022-12-29 22:10:07.452 DEBUG: Loss 1: {'policy_loss': 0.029049940641810323, 'entropy_loss': -0.034091252367943525, 'vf_loss': 0.007346933727014317, 'total_loss': 0.002305622000881108, 'approx_kl': -0.0015122393378987908, 'clip_fraction': 0.10286458395421505, 'grad_norm': 8.29184627532959}
2022-12-29 22:10:10.760 DEBUG: Taking gradient step
2022-12-29 22:10:10.771 DEBUG: Loss 2: {'policy_loss': -0.02012067993461345, 'entropy_loss': -0.036173874512314796, 'vf_loss': 0.0048691563115552715, 'total_loss': -0.051425398135372974, 'approx_kl': -0.0041263289749622345, 'clip_fraction': 0.27734375, 'grad_norm': 2.9563231468200684}
2022-12-29 22:10:14.271 DEBUG: Taking gradient step
2022-12-29 22:10:14.278 DEBUG: Loss 3: {'policy_loss': -0.030954186266517084, 'entropy_loss': -0.03329335059970617, 'vf_loss': 0.004884871574405757, 'total_loss': -0.059362665291817496, 'approx_kl': 0.03536830563098192, 'clip_fraction': 0.4453125, 'grad_norm': 1.8627516031265259}
2022-12-29 22:10:17.748 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-29 22:10:17.748 INFO: Optimization: policy loss=-0.031, vf loss=0.005, entropy loss=-0.033, total loss=-0.059, num steps=4
2022-12-29 22:10:17.753 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 22:10:19.115 INFO: Evaluation rollout: return=0.712 (0.0), episode length=5.0
2022-12-29 22:10:19.116 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 22:10:19.118 INFO: Iteration: 34/137, steps: 7344
2022-12-29 22:11:16.493 INFO: Training rollout: return=0.543 (0.1), episode length=5.0
2022-12-29 22:11:16.495 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 22:11:16.498 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-7344_train.pkl
2022-12-29 22:11:19.957 DEBUG: Taking gradient step
2022-12-29 22:11:19.965 DEBUG: Loss 0: {'policy_loss': 0.004707283244419103, 'entropy_loss': -0.03599363844841719, 'vf_loss': 0.000411280377441913, 'total_loss': -0.03087507482655618, 'approx_kl': -5.636440647549534e-09, 'clip_fraction': 0.0, 'grad_norm': 6.942483901977539}
2022-12-29 22:11:23.407 DEBUG: Taking gradient step
2022-12-29 22:11:23.415 DEBUG: Loss 1: {'policy_loss': -0.017977456816127203, 'entropy_loss': -0.03558578435331583, 'vf_loss': 0.00039822920416275544, 'total_loss': -0.053165011965280284, 'approx_kl': 0.006197590730153024, 'clip_fraction': 0.0, 'grad_norm': 9.39822006225586}
2022-12-29 22:11:26.816 DEBUG: Taking gradient step
2022-12-29 22:11:26.827 DEBUG: Loss 2: {'policy_loss': -0.045670316713159964, 'entropy_loss': -0.0356808016076684, 'vf_loss': 0.0003910223542450889, 'total_loss': -0.08096009596658327, 'approx_kl': 0.025133274029940367, 'clip_fraction': 0.046875, 'grad_norm': 11.565720558166504}
2022-12-29 22:11:30.264 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-29 22:11:30.264 INFO: Optimization: policy loss=-0.046, vf loss=0.000, entropy loss=-0.036, total loss=-0.081, num steps=3
2022-12-29 22:11:30.268 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 22:11:31.696 INFO: Evaluation rollout: return=0.694 (0.0), episode length=5.0
2022-12-29 22:11:31.697 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 22:11:31.699 INFO: Iteration: 35/137, steps: 7560
2022-12-29 22:11:33.673 DEBUG: Atoms are too close
2022-12-29 22:11:43.403 DEBUG: There is a single atom floating around
2022-12-29 22:12:28.150 INFO: Training rollout: return=-0.559 (4.6), episode length=4.9
2022-12-29 22:12:28.153 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 22:12:28.155 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-7560_train.pkl
2022-12-29 22:12:31.627 DEBUG: Taking gradient step
2022-12-29 22:12:31.634 DEBUG: Loss 0: {'policy_loss': -0.023778837039046874, 'entropy_loss': -0.03549567982554436, 'vf_loss': 0.009374480017938731, 'total_loss': -0.04990003684665251, 'approx_kl': -4.190951585769653e-09, 'clip_fraction': 0.0, 'grad_norm': 11.564557075500488}
2022-12-29 22:12:34.972 DEBUG: Taking gradient step
2022-12-29 22:12:34.980 DEBUG: Loss 1: {'policy_loss': 0.033161266193310286, 'entropy_loss': -0.033871141728013754, 'vf_loss': 0.014426037898471255, 'total_loss': 0.013716162363767784, 'approx_kl': 0.02001231478061527, 'clip_fraction': 0.07421875, 'grad_norm': 26.94234275817871}
2022-12-29 22:12:38.514 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-29 22:12:38.514 INFO: Optimization: policy loss=0.033, vf loss=0.014, entropy loss=-0.034, total loss=0.014, num steps=2
2022-12-29 22:12:38.518 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 22:12:39.849 INFO: Evaluation rollout: return=0.669 (0.0), episode length=5.0
2022-12-29 22:12:39.852 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 22:12:39.855 INFO: Iteration: 36/137, steps: 7776
2022-12-29 22:12:52.929 DEBUG: There is a single atom floating around
2022-12-29 22:13:08.583 DEBUG: There is a single atom floating around
2022-12-29 22:13:37.007 INFO: Training rollout: return=-0.548 (4.6), episode length=5.0
2022-12-29 22:13:37.010 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 22:13:37.012 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-7776_train.pkl
2022-12-29 22:13:40.237 DEBUG: Taking gradient step
2022-12-29 22:13:40.245 DEBUG: Loss 0: {'policy_loss': -0.004719418283577579, 'entropy_loss': -0.03476123046129942, 'vf_loss': 0.01774869030895959, 'total_loss': -0.021731958435917405, 'approx_kl': -5.22510781308938e-08, 'clip_fraction': 0.0, 'grad_norm': 18.732704162597656}
2022-12-29 22:13:43.498 DEBUG: Taking gradient step
2022-12-29 22:13:43.507 DEBUG: Loss 1: {'policy_loss': -0.046854309457349946, 'entropy_loss': -0.03324345126748085, 'vf_loss': 0.015387211923607456, 'total_loss': -0.06471054880122333, 'approx_kl': 0.01696782768703997, 'clip_fraction': 0.140625, 'grad_norm': 5.000345230102539}
2022-12-29 22:13:46.760 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-29 22:13:46.761 INFO: Optimization: policy loss=-0.047, vf loss=0.015, entropy loss=-0.033, total loss=-0.065, num steps=2
2022-12-29 22:13:46.766 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 22:13:48.068 INFO: Evaluation rollout: return=0.654 (0.0), episode length=5.0
2022-12-29 22:13:48.070 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 22:13:48.073 INFO: Iteration: 37/137, steps: 7992
2022-12-29 22:14:44.783 INFO: Training rollout: return=0.515 (0.1), episode length=5.0
2022-12-29 22:14:44.785 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 22:14:44.788 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-7992_train.pkl
2022-12-29 22:14:47.989 DEBUG: Taking gradient step
2022-12-29 22:14:48.007 DEBUG: Loss 0: {'policy_loss': -0.023427067588999324, 'entropy_loss': -0.03359245881438255, 'vf_loss': 0.00033737939475941587, 'total_loss': -0.05668214700862246, 'approx_kl': -3.504101186990738e-08, 'clip_fraction': 0.0, 'grad_norm': 11.852465629577637}
2022-12-29 22:14:51.450 DEBUG: Taking gradient step
2022-12-29 22:14:51.457 DEBUG: Loss 1: {'policy_loss': -0.043152425199494526, 'entropy_loss': -0.03341002995148301, 'vf_loss': 0.0003364279035390887, 'total_loss': -0.07622602724743845, 'approx_kl': 0.030553971300832927, 'clip_fraction': 0.1640625, 'grad_norm': 13.163605690002441}
2022-12-29 22:14:54.772 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-29 22:14:54.773 INFO: Optimization: policy loss=-0.043, vf loss=0.000, entropy loss=-0.033, total loss=-0.076, num steps=2
2022-12-29 22:14:54.777 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 22:14:56.222 INFO: Evaluation rollout: return=0.649 (0.0), episode length=5.0
2022-12-29 22:14:56.223 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 22:14:56.227 INFO: Iteration: 38/137, steps: 8208
2022-12-29 22:15:05.708 DEBUG: Atoms are too close
2022-12-29 22:15:19.580 DEBUG: Atoms are too close
2022-12-29 22:15:27.288 DEBUG: Atoms are too close
2022-12-29 22:15:53.260 INFO: Training rollout: return=-1.102 (5.5), episode length=4.9
2022-12-29 22:15:53.263 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 22:15:53.265 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-8208_train.pkl
2022-12-29 22:15:56.575 DEBUG: Taking gradient step
2022-12-29 22:15:56.583 DEBUG: Loss 0: {'policy_loss': -0.009874012064218712, 'entropy_loss': -0.03453223127871752, 'vf_loss': 0.020787116003202308, 'total_loss': -0.02361912733973393, 'approx_kl': -4.194832214921007e-08, 'clip_fraction': 0.0, 'grad_norm': 13.901619911193848}
2022-12-29 22:15:59.966 DEBUG: Taking gradient step
2022-12-29 22:15:59.973 DEBUG: Loss 1: {'policy_loss': -0.013526355745824756, 'entropy_loss': -0.0343747790902853, 'vf_loss': 0.020990271927246923, 'total_loss': -0.026910862908863138, 'approx_kl': 0.007209777133539319, 'clip_fraction': 0.05989583395421505, 'grad_norm': 20.341459274291992}
2022-12-29 22:16:03.505 DEBUG: Taking gradient step
2022-12-29 22:16:03.513 DEBUG: Loss 2: {'policy_loss': -0.01496059156406763, 'entropy_loss': -0.034442656207829714, 'vf_loss': 0.020821087013349796, 'total_loss': -0.028582160758547547, 'approx_kl': 0.037839703261852264, 'clip_fraction': 0.1809895858168602, 'grad_norm': 4.280944347381592}
2022-12-29 22:16:06.995 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-29 22:16:06.995 INFO: Optimization: policy loss=-0.015, vf loss=0.021, entropy loss=-0.034, total loss=-0.029, num steps=3
2022-12-29 22:16:06.999 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 22:16:08.432 INFO: Evaluation rollout: return=0.653 (0.0), episode length=5.0
2022-12-29 22:16:08.434 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 22:16:08.437 INFO: Iteration: 39/137, steps: 8424
2022-12-29 22:16:36.138 DEBUG: There is a single atom floating around
2022-12-29 22:16:53.580 DEBUG: Atoms are too close
2022-12-29 22:17:05.177 INFO: Training rollout: return=-0.575 (4.6), episode length=5.0
2022-12-29 22:17:05.178 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 22:17:05.181 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-8424_train.pkl
2022-12-29 22:17:08.459 DEBUG: Taking gradient step
2022-12-29 22:17:08.466 DEBUG: Loss 0: {'policy_loss': 0.09963915050188588, 'entropy_loss': -0.03534979186952114, 'vf_loss': 0.023887824552938364, 'total_loss': 0.0881771831853031, 'approx_kl': 8.440110832452774e-09, 'clip_fraction': 0.0, 'grad_norm': 17.773746490478516}
2022-12-29 22:17:11.857 DEBUG: Taking gradient step
2022-12-29 22:17:11.864 DEBUG: Loss 1: {'policy_loss': -0.03453480165327539, 'entropy_loss': -0.03535942081362009, 'vf_loss': 0.013793139882310563, 'total_loss': -0.05610108258458492, 'approx_kl': -0.028024204075336456, 'clip_fraction': 0.1184895858168602, 'grad_norm': 16.185653686523438}
2022-12-29 22:17:15.446 DEBUG: Taking gradient step
2022-12-29 22:17:15.453 DEBUG: Loss 2: {'policy_loss': -0.0437850675147574, 'entropy_loss': -0.03580768313258886, 'vf_loss': 0.013783200080746561, 'total_loss': -0.0658095505665997, 'approx_kl': -0.014565632678568363, 'clip_fraction': 0.1705729179084301, 'grad_norm': 10.652251243591309}
2022-12-29 22:17:18.957 DEBUG: Taking gradient step
2022-12-29 22:17:18.965 DEBUG: Loss 3: {'policy_loss': -0.044988266820450276, 'entropy_loss': -0.03549849893897772, 'vf_loss': 0.013774618727345029, 'total_loss': -0.06671214703208296, 'approx_kl': 0.01976403233129531, 'clip_fraction': 0.3489583358168602, 'grad_norm': 4.295002460479736}
2022-12-29 22:17:22.273 DEBUG: Taking gradient step
2022-12-29 22:17:22.281 DEBUG: Loss 4: {'policy_loss': -0.018735239418215675, 'entropy_loss': -0.03647032147273421, 'vf_loss': 0.016211374582796652, 'total_loss': -0.03899418630815324, 'approx_kl': 0.04120535962283611, 'clip_fraction': 0.4283854216337204, 'grad_norm': 4.13431978225708}
2022-12-29 22:17:25.712 DEBUG: Taking gradient step
2022-12-29 22:17:25.720 DEBUG: Loss 5: {'policy_loss': 0.01309960716334889, 'entropy_loss': -0.03619726933538914, 'vf_loss': 0.018753988077303427, 'total_loss': -0.004343674094736814, 'approx_kl': 0.036186437122523785, 'clip_fraction': 0.36328125, 'grad_norm': 5.142880439758301}
2022-12-29 22:17:29.131 DEBUG: Taking gradient step
2022-12-29 22:17:29.138 DEBUG: Loss 6: {'policy_loss': -0.0495136338581229, 'entropy_loss': -0.03737421799451113, 'vf_loss': 0.013751548342136826, 'total_loss': -0.0731363035104972, 'approx_kl': 0.03201342443935573, 'clip_fraction': 0.3502604216337204, 'grad_norm': 2.869084358215332}
2022-12-29 22:17:32.511 DEBUG: Taking gradient step
2022-12-29 22:17:32.518 DEBUG: Loss 7: {'policy_loss': -0.014773485349206566, 'entropy_loss': -0.03799228835850954, 'vf_loss': 0.016153547969673242, 'total_loss': -0.03661222573804287, 'approx_kl': 0.019961613230407238, 'clip_fraction': 0.2838541679084301, 'grad_norm': 12.518919944763184}
2022-12-29 22:17:36.152 DEBUG: Taking gradient step
2022-12-29 22:17:36.159 DEBUG: Loss 8: {'policy_loss': -0.008842770558680539, 'entropy_loss': -0.038834004662930965, 'vf_loss': 0.016191522253805664, 'total_loss': -0.03148525296780584, 'approx_kl': 0.02346513280645013, 'clip_fraction': 0.328125, 'grad_norm': 16.268556594848633}
2022-12-29 22:17:39.517 DEBUG: Early stopping at step 9 for reaching max KL.
2022-12-29 22:17:39.518 INFO: Optimization: policy loss=-0.009, vf loss=0.016, entropy loss=-0.039, total loss=-0.031, num steps=9
2022-12-29 22:17:39.528 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 22:17:40.909 INFO: Evaluation rollout: return=0.671 (0.0), episode length=5.0
2022-12-29 22:17:40.910 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 22:17:40.913 INFO: Iteration: 40/137, steps: 8640
2022-12-29 22:17:56.258 DEBUG: There is a single atom floating around
2022-12-29 22:18:37.678 INFO: Training rollout: return=-0.023 (3.3), episode length=5.0
2022-12-29 22:18:37.680 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 22:18:37.683 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-8640_train.pkl
2022-12-29 22:18:41.133 DEBUG: Taking gradient step
2022-12-29 22:18:41.141 DEBUG: Loss 0: {'policy_loss': -0.02612567338281372, 'entropy_loss': -0.03906007017940283, 'vf_loss': 0.007844756178369168, 'total_loss': -0.05734098738384738, 'approx_kl': 6.977158406584749e-08, 'clip_fraction': 0.0, 'grad_norm': 7.213392734527588}
2022-12-29 22:18:44.720 DEBUG: Taking gradient step
2022-12-29 22:18:44.727 DEBUG: Loss 1: {'policy_loss': -0.0005250864652347042, 'entropy_loss': -0.03630038816481829, 'vf_loss': 0.010349263148572282, 'total_loss': -0.02647621148148071, 'approx_kl': 0.005528939189389348, 'clip_fraction': 0.018229166977107525, 'grad_norm': 12.334433555603027}
2022-12-29 22:18:47.978 DEBUG: Taking gradient step
2022-12-29 22:18:47.985 DEBUG: Loss 2: {'policy_loss': -0.04195279652777491, 'entropy_loss': -0.03836674336344004, 'vf_loss': 0.007850440571465302, 'total_loss': -0.07246909931974965, 'approx_kl': 0.00979369948618114, 'clip_fraction': 0.07682291697710752, 'grad_norm': 9.2559814453125}
2022-12-29 22:18:51.295 DEBUG: Taking gradient step
2022-12-29 22:18:51.306 DEBUG: Loss 3: {'policy_loss': -0.041080306445824256, 'entropy_loss': -0.03950790408998728, 'vf_loss': 0.007848052610962842, 'total_loss': -0.0727401579248487, 'approx_kl': 0.022452051052823663, 'clip_fraction': 0.15364583395421505, 'grad_norm': 1.7146073579788208}
2022-12-29 22:18:54.965 DEBUG: Taking gradient step
2022-12-29 22:18:54.975 DEBUG: Loss 4: {'policy_loss': -0.04484291708872737, 'entropy_loss': -0.03768359124660492, 'vf_loss': 0.00785210465010511, 'total_loss': -0.0746744036852272, 'approx_kl': 0.03330952022224665, 'clip_fraction': 0.2252604216337204, 'grad_norm': 1.4739121198654175}
2022-12-29 22:18:58.308 DEBUG: Taking gradient step
2022-12-29 22:18:58.318 DEBUG: Loss 5: {'policy_loss': -0.008316479381356396, 'entropy_loss': -0.039074916392564774, 'vf_loss': 0.01031070615725116, 'total_loss': -0.03708068961667001, 'approx_kl': 0.03691487107425928, 'clip_fraction': 0.3216145858168602, 'grad_norm': 9.397926330566406}
2022-12-29 22:19:01.873 DEBUG: Taking gradient step
2022-12-29 22:19:01.881 DEBUG: Loss 6: {'policy_loss': -0.002568361334014821, 'entropy_loss': -0.03788311779499054, 'vf_loss': 0.010325691934546596, 'total_loss': -0.030125787194458773, 'approx_kl': 0.03913316875696182, 'clip_fraction': 0.4231770858168602, 'grad_norm': 3.0716867446899414}
2022-12-29 22:19:05.212 DEBUG: Taking gradient step
2022-12-29 22:19:05.220 DEBUG: Loss 7: {'policy_loss': -0.01045774492525857, 'entropy_loss': -0.0384319294244051, 'vf_loss': 0.010266284955776401, 'total_loss': -0.038623389393887264, 'approx_kl': 0.036356852389872074, 'clip_fraction': 0.4244791716337204, 'grad_norm': 2.920886754989624}
2022-12-29 22:19:08.882 DEBUG: Taking gradient step
2022-12-29 22:19:08.889 DEBUG: Loss 8: {'policy_loss': -0.04664532369745989, 'entropy_loss': -0.037186858244240284, 'vf_loss': 0.0078050534380901355, 'total_loss': -0.07602712850361004, 'approx_kl': 0.03111061593517661, 'clip_fraction': 0.3776041716337204, 'grad_norm': 1.714718222618103}
2022-12-29 22:19:12.452 DEBUG: Taking gradient step
2022-12-29 22:19:12.463 DEBUG: Loss 9: {'policy_loss': -0.01687649175313063, 'entropy_loss': -0.0364660769701004, 'vf_loss': 0.010202513629092691, 'total_loss': -0.043140055094138346, 'approx_kl': 0.020591462031006813, 'clip_fraction': 0.359375, 'grad_norm': 3.68945050239563}
2022-12-29 22:19:12.463 INFO: Optimization: policy loss=-0.017, vf loss=0.010, entropy loss=-0.036, total loss=-0.043, num steps=10
2022-12-29 22:19:12.468 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 22:19:13.873 INFO: Evaluation rollout: return=0.664 (0.0), episode length=5.0
2022-12-29 22:19:13.874 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 22:19:13.876 DEBUG: Deleting old model: runs/CH4_int/models/CH4_int_run-1_steps-6696.model
2022-12-29 22:19:13.878 DEBUG: Saving model: runs/CH4_int/models/CH4_int_run-1_steps-8856.model
2022-12-29 22:19:13.900 INFO: Iteration: 41/137, steps: 8856
2022-12-29 22:19:28.405 DEBUG: Atoms are too close
2022-12-29 22:20:10.858 INFO: Training rollout: return=-0.030 (3.3), episode length=5.0
2022-12-29 22:20:10.860 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 22:20:10.862 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-8856_train.pkl
2022-12-29 22:20:14.351 DEBUG: Taking gradient step
2022-12-29 22:20:14.359 DEBUG: Loss 0: {'policy_loss': -0.026114098958554845, 'entropy_loss': -0.03543322253972292, 'vf_loss': 0.007765881575479048, 'total_loss': -0.05378143992279873, 'approx_kl': -1.523100578992853e-08, 'clip_fraction': 0.0, 'grad_norm': 13.936336517333984}
2022-12-29 22:20:17.692 DEBUG: Taking gradient step
2022-12-29 22:20:17.704 DEBUG: Loss 1: {'policy_loss': -0.03197608750642896, 'entropy_loss': -0.03699223883450031, 'vf_loss': 0.00774952105236213, 'total_loss': -0.06121880528856714, 'approx_kl': 0.011130052560474724, 'clip_fraction': 0.05859375, 'grad_norm': 4.232429027557373}
2022-12-29 22:20:21.104 DEBUG: Taking gradient step
2022-12-29 22:20:21.112 DEBUG: Loss 2: {'policy_loss': 0.04083403379494986, 'entropy_loss': -0.03529048338532448, 'vf_loss': 0.012675130755137667, 'total_loss': 0.01821868116476305, 'approx_kl': 0.004424791783094406, 'clip_fraction': 0.1536458358168602, 'grad_norm': 3.8245182037353516}
2022-12-29 22:20:24.453 DEBUG: Taking gradient step
2022-12-29 22:20:24.461 DEBUG: Loss 3: {'policy_loss': 0.0011556211668170106, 'entropy_loss': -0.034441699739545584, 'vf_loss': 0.0102098105134334, 'total_loss': -0.023076268059295173, 'approx_kl': 0.013808955205604434, 'clip_fraction': 0.2760416716337204, 'grad_norm': 3.353184938430786}
2022-12-29 22:20:27.952 DEBUG: Taking gradient step
2022-12-29 22:20:27.959 DEBUG: Loss 4: {'policy_loss': -0.03929411538179635, 'entropy_loss': -0.034571433905512094, 'vf_loss': 0.007749615755705738, 'total_loss': -0.06611593353160272, 'approx_kl': 0.011427628342062235, 'clip_fraction': 0.2734375, 'grad_norm': 2.6351916790008545}
2022-12-29 22:20:31.170 DEBUG: Taking gradient step
2022-12-29 22:20:31.177 DEBUG: Loss 5: {'policy_loss': -0.038687656569513076, 'entropy_loss': -0.032888563349843025, 'vf_loss': 0.007743409678793811, 'total_loss': -0.06383281024056228, 'approx_kl': 0.005168046802282333, 'clip_fraction': 0.3268229216337204, 'grad_norm': 1.9740982055664062}
2022-12-29 22:20:34.380 DEBUG: Taking gradient step
2022-12-29 22:20:34.387 DEBUG: Loss 6: {'policy_loss': -0.040218708258792896, 'entropy_loss': -0.034259915351867676, 'vf_loss': 0.007736978184731563, 'total_loss': -0.066741645425929, 'approx_kl': 0.006601245608180761, 'clip_fraction': 0.3229166716337204, 'grad_norm': 1.138771891593933}
2022-12-29 22:20:37.746 DEBUG: Taking gradient step
2022-12-29 22:20:37.753 DEBUG: Loss 7: {'policy_loss': -0.04278270374707775, 'entropy_loss': -0.035074541345238686, 'vf_loss': 0.007735239041302799, 'total_loss': -0.07012200605101364, 'approx_kl': 0.008666843641549349, 'clip_fraction': 0.3268229216337204, 'grad_norm': 3.216066837310791}
2022-12-29 22:20:41.350 DEBUG: Taking gradient step
2022-12-29 22:20:41.358 DEBUG: Loss 8: {'policy_loss': -0.04273952208302097, 'entropy_loss': -0.032289606519043446, 'vf_loss': 0.007732475553667743, 'total_loss': -0.06729665304839669, 'approx_kl': 0.004245105432346463, 'clip_fraction': 0.3216145858168602, 'grad_norm': 4.01659631729126}
2022-12-29 22:20:44.679 DEBUG: Taking gradient step
2022-12-29 22:20:44.687 DEBUG: Loss 9: {'policy_loss': -0.006306879234844132, 'entropy_loss': -0.03407706134021282, 'vf_loss': 0.010163805841099561, 'total_loss': -0.03022013473395739, 'approx_kl': -0.013464034767821431, 'clip_fraction': 0.31640625, 'grad_norm': 9.346756935119629}
2022-12-29 22:20:44.688 INFO: Optimization: policy loss=-0.006, vf loss=0.010, entropy loss=-0.034, total loss=-0.030, num steps=10
2022-12-29 22:20:44.692 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 22:20:46.089 INFO: Evaluation rollout: return=0.675 (0.0), episode length=5.0
2022-12-29 22:20:46.090 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 22:20:46.092 INFO: Iteration: 42/137, steps: 9072
2022-12-29 22:21:43.587 INFO: Training rollout: return=0.558 (0.1), episode length=5.0
2022-12-29 22:21:43.589 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 22:21:43.592 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-9072_train.pkl
2022-12-29 22:21:47.073 DEBUG: Taking gradient step
2022-12-29 22:21:47.084 DEBUG: Loss 0: {'policy_loss': 0.04404930221916487, 'entropy_loss': -0.034120816737413406, 'vf_loss': 0.00032225080529568924, 'total_loss': 0.01025073628704716, 'approx_kl': 4.908846051865368e-09, 'clip_fraction': 0.0, 'grad_norm': 8.225813865661621}
2022-12-29 22:21:50.757 DEBUG: Taking gradient step
2022-12-29 22:21:50.764 DEBUG: Loss 1: {'policy_loss': -0.036343586339586335, 'entropy_loss': -0.03540495317429304, 'vf_loss': 0.0003104016496918268, 'total_loss': -0.07143813786418755, 'approx_kl': 0.0004194857319816947, 'clip_fraction': 0.1614583358168602, 'grad_norm': 5.6878814697265625}
2022-12-29 22:21:53.948 DEBUG: Taking gradient step
2022-12-29 22:21:53.956 DEBUG: Loss 2: {'policy_loss': -0.03898364453813668, 'entropy_loss': -0.03596360981464386, 'vf_loss': 0.0002903393344959232, 'total_loss': -0.07465691501828461, 'approx_kl': 0.013567752670496702, 'clip_fraction': 0.2890625, 'grad_norm': 11.283387184143066}
2022-12-29 22:21:57.160 DEBUG: Taking gradient step
2022-12-29 22:21:57.167 DEBUG: Loss 3: {'policy_loss': -0.04563895888651873, 'entropy_loss': -0.03483072016388178, 'vf_loss': 0.00026590510316118585, 'total_loss': -0.08020377394723932, 'approx_kl': -0.006513010943308473, 'clip_fraction': 0.2604166716337204, 'grad_norm': 8.140331268310547}
2022-12-29 22:22:00.491 DEBUG: Taking gradient step
2022-12-29 22:22:00.499 DEBUG: Loss 4: {'policy_loss': 0.027565306350133753, 'entropy_loss': -0.03320247819647193, 'vf_loss': 0.00023798132997126896, 'total_loss': -0.005399190516366913, 'approx_kl': 0.00708898575976491, 'clip_fraction': 0.18098958395421505, 'grad_norm': 6.070374965667725}
2022-12-29 22:22:04.049 DEBUG: Taking gradient step
2022-12-29 22:22:04.060 DEBUG: Loss 5: {'policy_loss': -0.03551513879411057, 'entropy_loss': -0.03486827481538057, 'vf_loss': 0.00021768186640703594, 'total_loss': -0.0701657317430841, 'approx_kl': 0.015494202147237957, 'clip_fraction': 0.2265625, 'grad_norm': 10.0040283203125}
2022-12-29 22:22:07.676 DEBUG: Taking gradient step
2022-12-29 22:22:07.684 DEBUG: Loss 6: {'policy_loss': 0.016870840896005698, 'entropy_loss': -0.0342940678820014, 'vf_loss': 0.00019481876158963552, 'total_loss': -0.017228408224406064, 'approx_kl': 0.009841272916673915, 'clip_fraction': 0.2473958358168602, 'grad_norm': 14.609966278076172}
2022-12-29 22:22:11.449 DEBUG: Taking gradient step
2022-12-29 22:22:11.456 DEBUG: Loss 7: {'policy_loss': 0.015549787917522075, 'entropy_loss': -0.034212189726531506, 'vf_loss': 0.00017676017175958933, 'total_loss': -0.01848564163724984, 'approx_kl': 0.024545450694859028, 'clip_fraction': 0.3216145858168602, 'grad_norm': 9.017048835754395}
2022-12-29 22:22:14.899 DEBUG: Taking gradient step
2022-12-29 22:22:14.906 DEBUG: Loss 8: {'policy_loss': -0.007135595669947979, 'entropy_loss': -0.034086001105606556, 'vf_loss': 0.00016281296183558454, 'total_loss': -0.04105878381371895, 'approx_kl': 0.02792064705863595, 'clip_fraction': 0.3854166716337204, 'grad_norm': 12.19302749633789}
2022-12-29 22:22:18.193 DEBUG: Taking gradient step
2022-12-29 22:22:18.201 DEBUG: Loss 9: {'policy_loss': -0.08246960679682103, 'entropy_loss': -0.033026580698788166, 'vf_loss': 0.00016308481861097477, 'total_loss': -0.11533310267699823, 'approx_kl': 0.008169780485332012, 'clip_fraction': 0.30078125, 'grad_norm': 9.844219207763672}
2022-12-29 22:22:18.201 INFO: Optimization: policy loss=-0.082, vf loss=0.000, entropy loss=-0.033, total loss=-0.115, num steps=10
2022-12-29 22:22:18.206 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 22:22:19.637 INFO: Evaluation rollout: return=0.685 (0.0), episode length=5.0
2022-12-29 22:22:19.638 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 22:22:19.640 INFO: Iteration: 43/137, steps: 9288
2022-12-29 22:23:17.308 INFO: Training rollout: return=0.555 (0.2), episode length=5.0
2022-12-29 22:23:17.311 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 22:23:17.314 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-9288_train.pkl
2022-12-29 22:23:20.879 DEBUG: Taking gradient step
2022-12-29 22:23:20.886 DEBUG: Loss 0: {'policy_loss': 0.007163215481255668, 'entropy_loss': -0.03404244128614664, 'vf_loss': 0.00017364884128945803, 'total_loss': -0.026705576963601516, 'approx_kl': 3.3760443329811096e-08, 'clip_fraction': 0.0, 'grad_norm': 13.143244743347168}
2022-12-29 22:23:24.465 DEBUG: Taking gradient step
2022-12-29 22:23:24.475 DEBUG: Loss 1: {'policy_loss': -0.05564727293856535, 'entropy_loss': -0.03279204200953245, 'vf_loss': 0.0001714897775967766, 'total_loss': -0.08826782517050102, 'approx_kl': 0.02137505286373198, 'clip_fraction': 0.13671875, 'grad_norm': 11.661924362182617}
2022-12-29 22:23:28.170 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-29 22:23:28.171 INFO: Optimization: policy loss=-0.056, vf loss=0.000, entropy loss=-0.033, total loss=-0.088, num steps=2
2022-12-29 22:23:28.174 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 22:23:29.536 INFO: Evaluation rollout: return=0.575 (0.0), episode length=5.0
2022-12-29 22:23:29.537 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 22:23:29.540 INFO: Iteration: 44/137, steps: 9504
2022-12-29 22:23:59.636 DEBUG: Atoms are too close
2022-12-29 22:24:14.937 DEBUG: Atoms are too close
2022-12-29 22:24:26.271 INFO: Training rollout: return=-0.573 (4.6), episode length=5.0
2022-12-29 22:24:26.273 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 22:24:26.276 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-9504_train.pkl
2022-12-29 22:24:29.646 DEBUG: Taking gradient step
2022-12-29 22:24:29.654 DEBUG: Loss 0: {'policy_loss': -0.004620000164336934, 'entropy_loss': -0.03334712842479348, 'vf_loss': 0.018014040662257095, 'total_loss': -0.01995308792687332, 'approx_kl': -2.4835269840650653e-08, 'clip_fraction': 0.0, 'grad_norm': 10.955126762390137}
2022-12-29 22:24:33.110 DEBUG: Taking gradient step
2022-12-29 22:24:33.117 DEBUG: Loss 1: {'policy_loss': -0.04802405175574346, 'entropy_loss': -0.032153273932635784, 'vf_loss': 0.015546979297629084, 'total_loss': -0.06463034639075016, 'approx_kl': 0.00503411958925426, 'clip_fraction': 0.1171875, 'grad_norm': 7.418816089630127}
2022-12-29 22:24:36.560 DEBUG: Taking gradient step
2022-12-29 22:24:36.571 DEBUG: Loss 2: {'policy_loss': -0.01754842588847934, 'entropy_loss': -0.03314524842426181, 'vf_loss': 0.018058627597313765, 'total_loss': -0.032635046715427385, 'approx_kl': 0.022102082846686244, 'clip_fraction': 0.3138020858168602, 'grad_norm': 4.721435070037842}
2022-12-29 22:24:39.896 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-29 22:24:39.896 INFO: Optimization: policy loss=-0.018, vf loss=0.018, entropy loss=-0.033, total loss=-0.033, num steps=3
2022-12-29 22:24:39.900 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 22:24:41.274 INFO: Evaluation rollout: return=0.491 (0.0), episode length=5.0
2022-12-29 22:24:41.275 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 22:24:41.278 INFO: Iteration: 45/137, steps: 9720
2022-12-29 22:25:13.054 DEBUG: Atoms are too close
2022-12-29 22:25:38.557 INFO: Training rollout: return=-0.023 (3.3), episode length=5.0
2022-12-29 22:25:38.559 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 22:25:38.562 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-9720_train.pkl
2022-12-29 22:25:42.208 DEBUG: Taking gradient step
2022-12-29 22:25:42.216 DEBUG: Loss 0: {'policy_loss': 0.02335743468986369, 'entropy_loss': -0.03261938551440835, 'vf_loss': 0.010477861395886016, 'total_loss': 0.0012159105713413568, 'approx_kl': -3.372163703829756e-08, 'clip_fraction': 0.0, 'grad_norm': 18.977750778198242}
2022-12-29 22:25:45.798 DEBUG: Taking gradient step
2022-12-29 22:25:45.805 DEBUG: Loss 1: {'policy_loss': 0.0045212308775892905, 'entropy_loss': -0.031766821164637804, 'vf_loss': 0.010459667559779708, 'total_loss': -0.01678592272726881, 'approx_kl': 0.02386878669494763, 'clip_fraction': 0.14453125, 'grad_norm': 4.030720233917236}
2022-12-29 22:25:49.316 DEBUG: Taking gradient step
2022-12-29 22:25:49.324 DEBUG: Loss 2: {'policy_loss': -0.030584053920245078, 'entropy_loss': -0.03175751306116581, 'vf_loss': 0.007778995543424319, 'total_loss': -0.05456257143798657, 'approx_kl': 0.04226012900471687, 'clip_fraction': 0.20052083395421505, 'grad_norm': 3.0187692642211914}
2022-12-29 22:25:52.857 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-29 22:25:52.858 INFO: Optimization: policy loss=-0.031, vf loss=0.008, entropy loss=-0.032, total loss=-0.055, num steps=3
2022-12-29 22:25:52.861 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 22:25:54.218 INFO: Evaluation rollout: return=0.473 (0.0), episode length=5.0
2022-12-29 22:25:54.219 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 22:25:54.221 INFO: Iteration: 46/137, steps: 9936
2022-12-29 22:26:36.889 DEBUG: Atoms are too close
2022-12-29 22:26:42.016 DEBUG: Atoms are too close
2022-12-29 22:26:51.472 INFO: Training rollout: return=-0.564 (4.6), episode length=5.0
2022-12-29 22:26:51.474 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 22:26:51.477 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-9936_train.pkl
2022-12-29 22:26:54.830 DEBUG: Taking gradient step
2022-12-29 22:26:54.837 DEBUG: Loss 0: {'policy_loss': -0.0002835668034485682, 'entropy_loss': -0.03187958989292383, 'vf_loss': 0.016419888980782605, 'total_loss': -0.015743267715589794, 'approx_kl': -4.1657283844642734e-08, 'clip_fraction': 0.0, 'grad_norm': 7.632811546325684}
2022-12-29 22:26:58.182 DEBUG: Taking gradient step
2022-12-29 22:26:58.190 DEBUG: Loss 1: {'policy_loss': -0.005634415327335015, 'entropy_loss': -0.03156038699671626, 'vf_loss': 0.01645897258153834, 'total_loss': -0.020735829742512934, 'approx_kl': 0.01033807807834819, 'clip_fraction': 0.15625, 'grad_norm': 12.398475646972656}
2022-12-29 22:27:01.506 DEBUG: Taking gradient step
2022-12-29 22:27:01.514 DEBUG: Loss 2: {'policy_loss': 0.03362685921014362, 'entropy_loss': -0.0323296831920743, 'vf_loss': 0.01890501545249962, 'total_loss': 0.02020219147056894, 'approx_kl': 0.04087668005377054, 'clip_fraction': 0.3072916716337204, 'grad_norm': 13.240285873413086}
2022-12-29 22:27:04.962 DEBUG: Taking gradient step
2022-12-29 22:27:04.970 DEBUG: Loss 3: {'policy_loss': 0.004618474718268983, 'entropy_loss': -0.034889656119048595, 'vf_loss': 0.016343244461249545, 'total_loss': -0.013927936939530065, 'approx_kl': 0.02685707714408636, 'clip_fraction': 0.3359375, 'grad_norm': 10.79683780670166}
2022-12-29 22:27:08.360 DEBUG: Taking gradient step
2022-12-29 22:27:08.368 DEBUG: Loss 4: {'policy_loss': 0.0201579108635848, 'entropy_loss': -0.03349991701543331, 'vf_loss': 0.018832240817380427, 'total_loss': 0.005490234665531925, 'approx_kl': 0.040239440044388175, 'clip_fraction': 0.26953125, 'grad_norm': 5.659369945526123}
2022-12-29 22:27:11.658 DEBUG: Taking gradient step
2022-12-29 22:27:11.666 DEBUG: Loss 5: {'policy_loss': -0.003953041536251039, 'entropy_loss': -0.03487918432801962, 'vf_loss': 0.016257014844285225, 'total_loss': -0.02257521101998543, 'approx_kl': 0.03928108932450414, 'clip_fraction': 0.2591145858168602, 'grad_norm': 5.58706521987915}
2022-12-29 22:27:14.965 DEBUG: Taking gradient step
2022-12-29 22:27:14.973 DEBUG: Loss 6: {'policy_loss': -0.010896155681664884, 'entropy_loss': -0.03575936984270811, 'vf_loss': 0.016277205783690976, 'total_loss': -0.030378319740682024, 'approx_kl': 0.043141347356140614, 'clip_fraction': 0.3151041716337204, 'grad_norm': 8.489439010620117}
2022-12-29 22:27:18.276 DEBUG: Taking gradient step
2022-12-29 22:27:18.283 DEBUG: Loss 7: {'policy_loss': -0.04703384321221926, 'entropy_loss': -0.035866208374500275, 'vf_loss': 0.013757639086405397, 'total_loss': -0.06914241250031414, 'approx_kl': 0.029385078698396683, 'clip_fraction': 0.3841145858168602, 'grad_norm': 4.770965576171875}
2022-12-29 22:27:21.541 DEBUG: Early stopping at step 8 for reaching max KL.
2022-12-29 22:27:21.542 INFO: Optimization: policy loss=-0.047, vf loss=0.014, entropy loss=-0.036, total loss=-0.069, num steps=8
2022-12-29 22:27:21.546 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 22:27:22.936 INFO: Evaluation rollout: return=0.594 (0.0), episode length=5.0
2022-12-29 22:27:22.938 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 22:27:22.940 INFO: Iteration: 47/137, steps: 10152
2022-12-29 22:28:20.563 INFO: Training rollout: return=0.533 (0.1), episode length=5.0
2022-12-29 22:28:20.566 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 22:28:20.569 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-10152_train.pkl
2022-12-29 22:28:24.009 DEBUG: Taking gradient step
2022-12-29 22:28:24.018 DEBUG: Loss 0: {'policy_loss': -0.021919666274008414, 'entropy_loss': -0.03474942967295647, 'vf_loss': 0.000284495511945405, 'total_loss': -0.05638460043501947, 'approx_kl': -1.2068388599573154e-07, 'clip_fraction': 0.0, 'grad_norm': 14.663536071777344}
2022-12-29 22:28:27.315 DEBUG: Taking gradient step
2022-12-29 22:28:27.322 DEBUG: Loss 1: {'policy_loss': 0.05478202549587238, 'entropy_loss': -0.033610493410378695, 'vf_loss': 0.00028551682897612395, 'total_loss': 0.021457048914469826, 'approx_kl': -0.0008785293903201818, 'clip_fraction': 0.2213541679084301, 'grad_norm': 7.7901611328125}
2022-12-29 22:28:30.845 DEBUG: Taking gradient step
2022-12-29 22:28:30.856 DEBUG: Loss 2: {'policy_loss': -0.044094044534050386, 'entropy_loss': -0.03650238458067179, 'vf_loss': 0.0003280465345248002, 'total_loss': -0.08026838258019736, 'approx_kl': 0.007888233289122581, 'clip_fraction': 0.4036458358168602, 'grad_norm': 8.372374534606934}
2022-12-29 22:28:34.316 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-29 22:28:34.317 INFO: Optimization: policy loss=-0.044, vf loss=0.000, entropy loss=-0.037, total loss=-0.080, num steps=3
2022-12-29 22:28:34.322 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 22:28:35.702 INFO: Evaluation rollout: return=0.587 (0.0), episode length=5.0
2022-12-29 22:28:35.703 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 22:28:35.706 INFO: Iteration: 48/137, steps: 10368
2022-12-29 22:29:33.382 INFO: Training rollout: return=0.529 (0.1), episode length=5.0
2022-12-29 22:29:33.385 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 22:29:33.388 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-10368_train.pkl
2022-12-29 22:29:36.927 DEBUG: Taking gradient step
2022-12-29 22:29:36.934 DEBUG: Loss 0: {'policy_loss': 0.030726384695908562, 'entropy_loss': -0.034852937795221806, 'vf_loss': 0.00031052158766783103, 'total_loss': -0.003816031511645411, 'approx_kl': 3.395447123466511e-08, 'clip_fraction': 0.0, 'grad_norm': 8.114715576171875}
2022-12-29 22:29:40.306 DEBUG: Taking gradient step
2022-12-29 22:29:40.313 DEBUG: Loss 1: {'policy_loss': -0.01841640098979741, 'entropy_loss': -0.034376999363303185, 'vf_loss': 0.00032418926358714626, 'total_loss': -0.052469211089513454, 'approx_kl': 0.005854037241078913, 'clip_fraction': 0.140625, 'grad_norm': 5.262155532836914}
2022-12-29 22:29:43.655 DEBUG: Taking gradient step
2022-12-29 22:29:43.662 DEBUG: Loss 2: {'policy_loss': -0.0067712501717407, 'entropy_loss': -0.032918337266892195, 'vf_loss': 0.0003139992027584419, 'total_loss': -0.03937558823587445, 'approx_kl': 0.0066271519754081964, 'clip_fraction': 0.2486979179084301, 'grad_norm': 9.34342098236084}
2022-12-29 22:29:47.240 DEBUG: Taking gradient step
2022-12-29 22:29:47.252 DEBUG: Loss 3: {'policy_loss': -0.037456765319067616, 'entropy_loss': -0.03595099551603198, 'vf_loss': 0.0003141952683817362, 'total_loss': -0.07309356556671785, 'approx_kl': -0.0014921718393452466, 'clip_fraction': 0.29296875, 'grad_norm': 11.890251159667969}
2022-12-29 22:29:50.707 DEBUG: Taking gradient step
2022-12-29 22:29:50.715 DEBUG: Loss 4: {'policy_loss': 0.022805123266509755, 'entropy_loss': -0.0334577769972384, 'vf_loss': 0.00029301866157191263, 'total_loss': -0.010359635069156728, 'approx_kl': -0.017501496011391282, 'clip_fraction': 0.28125, 'grad_norm': 11.732503890991211}
2022-12-29 22:29:54.145 DEBUG: Taking gradient step
2022-12-29 22:29:54.153 DEBUG: Loss 5: {'policy_loss': -0.03931094528166344, 'entropy_loss': -0.03482342651113868, 'vf_loss': 0.0002834667560474031, 'total_loss': -0.07385090503675472, 'approx_kl': -0.02383596496656537, 'clip_fraction': 0.25390625, 'grad_norm': 7.24983024597168}
2022-12-29 22:29:57.725 DEBUG: Taking gradient step
2022-12-29 22:29:57.732 DEBUG: Loss 6: {'policy_loss': -0.033027115372847166, 'entropy_loss': -0.03307573823258281, 'vf_loss': 0.0002614861891874753, 'total_loss': -0.0658413674162425, 'approx_kl': -0.0154573037289083, 'clip_fraction': 0.14322916697710752, 'grad_norm': 8.203987121582031}
2022-12-29 22:30:01.361 DEBUG: Taking gradient step
2022-12-29 22:30:01.369 DEBUG: Loss 7: {'policy_loss': -0.022041897667530893, 'entropy_loss': -0.03232690179720521, 'vf_loss': 0.00024300012851272214, 'total_loss': -0.054125799336223385, 'approx_kl': -0.014952353900298476, 'clip_fraction': 0.21223958395421505, 'grad_norm': 9.117342948913574}
2022-12-29 22:30:04.912 DEBUG: Taking gradient step
2022-12-29 22:30:04.921 DEBUG: Loss 8: {'policy_loss': -0.023403436967125515, 'entropy_loss': -0.03309263940900564, 'vf_loss': 0.00022602489258719506, 'total_loss': -0.05627005148354396, 'approx_kl': -0.011333194561302662, 'clip_fraction': 0.2513020858168602, 'grad_norm': 8.680581092834473}
2022-12-29 22:30:08.424 DEBUG: Taking gradient step
2022-12-29 22:30:08.432 DEBUG: Loss 9: {'policy_loss': -0.00909682086597463, 'entropy_loss': -0.032234241254627705, 'vf_loss': 0.0002034536107089092, 'total_loss': -0.04112760850989343, 'approx_kl': -0.012849624268710613, 'clip_fraction': 0.2513020858168602, 'grad_norm': 7.391429424285889}
2022-12-29 22:30:08.432 INFO: Optimization: policy loss=-0.009, vf loss=0.000, entropy loss=-0.032, total loss=-0.041, num steps=10
2022-12-29 22:30:08.436 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 22:30:09.781 INFO: Evaluation rollout: return=0.591 (0.0), episode length=5.0
2022-12-29 22:30:09.782 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 22:30:09.784 INFO: Iteration: 49/137, steps: 10584
2022-12-29 22:30:38.889 DEBUG: There is a single atom floating around
2022-12-29 22:31:06.994 INFO: Training rollout: return=0.002 (3.3), episode length=5.0
2022-12-29 22:31:06.996 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 22:31:06.999 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-10584_train.pkl
2022-12-29 22:31:10.436 DEBUG: Taking gradient step
2022-12-29 22:31:10.447 DEBUG: Loss 0: {'policy_loss': -0.025035489929539856, 'entropy_loss': -0.032847825437784195, 'vf_loss': 0.00771487497705363, 'total_loss': -0.05016844039027042, 'approx_kl': -7.675650692817726e-08, 'clip_fraction': 0.0, 'grad_norm': 11.042764663696289}
2022-12-29 22:31:13.796 DEBUG: Taking gradient step
2022-12-29 22:31:13.807 DEBUG: Loss 1: {'policy_loss': -0.03093418898718228, 'entropy_loss': -0.032582640647888184, 'vf_loss': 0.007713298934282542, 'total_loss': -0.05580353070078792, 'approx_kl': 0.007243722444400191, 'clip_fraction': 0.0859375, 'grad_norm': 9.775532722473145}
2022-12-29 22:31:17.160 DEBUG: Taking gradient step
2022-12-29 22:31:17.168 DEBUG: Loss 2: {'policy_loss': 0.0017931414753637985, 'entropy_loss': -0.03288375725969672, 'vf_loss': 0.010285651276973326, 'total_loss': -0.020804964507359597, 'approx_kl': 0.04252954991534352, 'clip_fraction': 0.2513020858168602, 'grad_norm': 3.4776172637939453}
2022-12-29 22:31:20.671 DEBUG: Taking gradient step
2022-12-29 22:31:20.679 DEBUG: Loss 3: {'policy_loss': -0.036142052220124066, 'entropy_loss': -0.03168168291449547, 'vf_loss': 0.0077253073566806215, 'total_loss': -0.06009842777793891, 'approx_kl': 0.04427395039238036, 'clip_fraction': 0.30078125, 'grad_norm': 3.532299280166626}
2022-12-29 22:31:24.202 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-29 22:31:24.203 INFO: Optimization: policy loss=-0.036, vf loss=0.008, entropy loss=-0.032, total loss=-0.060, num steps=4
2022-12-29 22:31:24.208 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 22:31:25.611 INFO: Evaluation rollout: return=0.571 (0.0), episode length=5.0
2022-12-29 22:31:25.614 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 22:31:25.616 INFO: Iteration: 50/137, steps: 10800
2022-12-29 22:32:22.305 INFO: Training rollout: return=0.526 (0.1), episode length=5.0
2022-12-29 22:32:22.307 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 22:32:22.309 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-10800_train.pkl
2022-12-29 22:32:25.765 DEBUG: Taking gradient step
2022-12-29 22:32:25.773 DEBUG: Loss 0: {'policy_loss': 0.06836815328748475, 'entropy_loss': -0.03282025456428528, 'vf_loss': 0.0001654172854405533, 'total_loss': 0.03571331600864003, 'approx_kl': -4.538257325492623e-08, 'clip_fraction': 0.0, 'grad_norm': 14.529887199401855}
2022-12-29 22:32:29.292 DEBUG: Taking gradient step
2022-12-29 22:32:29.299 DEBUG: Loss 1: {'policy_loss': -0.006436495163492263, 'entropy_loss': -0.0322471815161407, 'vf_loss': 0.00016628887760818033, 'total_loss': -0.03851738780202478, 'approx_kl': 0.00034308264730498195, 'clip_fraction': 0.07552083395421505, 'grad_norm': 7.343439102172852}
2022-12-29 22:32:32.558 DEBUG: Taking gradient step
2022-12-29 22:32:32.569 DEBUG: Loss 2: {'policy_loss': -0.0519101772390929, 'entropy_loss': -0.03239270579069853, 'vf_loss': 0.00016405054015302865, 'total_loss': -0.0841388324896384, 'approx_kl': 0.01088291173800826, 'clip_fraction': 0.1901041679084301, 'grad_norm': 7.025492191314697}
2022-12-29 22:32:35.937 DEBUG: Taking gradient step
2022-12-29 22:32:35.944 DEBUG: Loss 3: {'policy_loss': 0.04567825343219179, 'entropy_loss': -0.03300009202212095, 'vf_loss': 0.0001458688494761373, 'total_loss': 0.012824030259546981, 'approx_kl': 0.03243296779692173, 'clip_fraction': 0.1979166679084301, 'grad_norm': 6.6591796875}
2022-12-29 22:32:39.354 DEBUG: Taking gradient step
2022-12-29 22:32:39.362 DEBUG: Loss 4: {'policy_loss': -0.0214232620115589, 'entropy_loss': -0.03359941067174077, 'vf_loss': 0.00014094736662357104, 'total_loss': -0.05488172531667611, 'approx_kl': 0.034845147747546434, 'clip_fraction': 0.1940104179084301, 'grad_norm': 4.249342441558838}
2022-12-29 22:32:42.819 DEBUG: Early stopping at step 5 for reaching max KL.
2022-12-29 22:32:42.820 INFO: Optimization: policy loss=-0.021, vf loss=0.000, entropy loss=-0.034, total loss=-0.055, num steps=5
2022-12-29 22:32:42.829 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 22:32:44.144 INFO: Evaluation rollout: return=0.574 (0.0), episode length=5.0
2022-12-29 22:32:44.145 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 22:32:44.148 DEBUG: Deleting old model: runs/CH4_int/models/CH4_int_run-1_steps-8856.model
2022-12-29 22:32:44.153 DEBUG: Saving model: runs/CH4_int/models/CH4_int_run-1_steps-11016.model
2022-12-29 22:32:44.175 INFO: Iteration: 51/137, steps: 11016
2022-12-29 22:32:55.193 DEBUG: Atoms are too close
2022-12-29 22:33:14.640 DEBUG: Atoms are too close
2022-12-29 22:33:40.977 INFO: Training rollout: return=-0.592 (4.6), episode length=5.0
2022-12-29 22:33:40.980 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 22:33:40.982 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-11016_train.pkl
2022-12-29 22:33:44.287 DEBUG: Taking gradient step
2022-12-29 22:33:44.294 DEBUG: Loss 0: {'policy_loss': 0.033331483195485186, 'entropy_loss': -0.03378666425123811, 'vf_loss': 0.018934660873170125, 'total_loss': 0.01847947981741721, 'approx_kl': -4.313187673687935e-08, 'clip_fraction': 0.0, 'grad_norm': 21.15884780883789}
2022-12-29 22:33:47.627 DEBUG: Taking gradient step
2022-12-29 22:33:47.635 DEBUG: Loss 1: {'policy_loss': 0.01459100408975645, 'entropy_loss': -0.033986872527748346, 'vf_loss': 0.019029947403927522, 'total_loss': -0.0003659210340643815, 'approx_kl': 0.04095521569252014, 'clip_fraction': 0.2395833358168602, 'grad_norm': 4.652372360229492}
2022-12-29 22:33:51.014 DEBUG: Taking gradient step
2022-12-29 22:33:51.021 DEBUG: Loss 2: {'policy_loss': 0.051793900863848025, 'entropy_loss': -0.0322126355022192, 'vf_loss': 0.021488340321321617, 'total_loss': 0.04106960568295044, 'approx_kl': 0.04358031740412116, 'clip_fraction': 0.3072916716337204, 'grad_norm': 6.3366241455078125}
2022-12-29 22:33:54.496 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-29 22:33:54.497 INFO: Optimization: policy loss=0.052, vf loss=0.021, entropy loss=-0.032, total loss=0.041, num steps=3
2022-12-29 22:33:54.506 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 22:33:55.898 INFO: Evaluation rollout: return=0.563 (0.0), episode length=5.0
2022-12-29 22:33:55.899 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 22:33:55.901 INFO: Iteration: 52/137, steps: 11232
2022-12-29 22:34:35.889 DEBUG: There is a single atom floating around
2022-12-29 22:34:52.950 INFO: Training rollout: return=-0.025 (3.3), episode length=4.9
2022-12-29 22:34:52.952 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 22:34:52.954 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-11232_train.pkl
2022-12-29 22:34:56.283 DEBUG: Taking gradient step
2022-12-29 22:34:56.290 DEBUG: Loss 0: {'policy_loss': -0.019954850800674752, 'entropy_loss': -0.03343051951378584, 'vf_loss': 0.004798135668409091, 'total_loss': -0.0485872346460515, 'approx_kl': -7.27983824333478e-08, 'clip_fraction': 0.0, 'grad_norm': 12.38797664642334}
2022-12-29 22:34:59.638 DEBUG: Taking gradient step
2022-12-29 22:34:59.645 DEBUG: Loss 1: {'policy_loss': -0.027147524885882915, 'entropy_loss': -0.03239422291517258, 'vf_loss': 0.004798895424531603, 'total_loss': -0.05474285237652389, 'approx_kl': 0.0057020115200430155, 'clip_fraction': 0.04817708395421505, 'grad_norm': 5.825604438781738}
2022-12-29 22:35:03.294 DEBUG: Taking gradient step
2022-12-29 22:35:03.306 DEBUG: Loss 2: {'policy_loss': -0.03221561348929499, 'entropy_loss': -0.033446808345615864, 'vf_loss': 0.004800730774956273, 'total_loss': -0.06086169105995458, 'approx_kl': 0.019416221999563277, 'clip_fraction': 0.1080729179084301, 'grad_norm': 4.529104709625244}
2022-12-29 22:35:06.757 DEBUG: Taking gradient step
2022-12-29 22:35:06.768 DEBUG: Loss 3: {'policy_loss': 0.015985826796478884, 'entropy_loss': -0.03350804839283228, 'vf_loss': 0.007386179187882334, 'total_loss': -0.010136042408471067, 'approx_kl': 0.03467750549316406, 'clip_fraction': 0.3294270858168602, 'grad_norm': 2.4000496864318848}
2022-12-29 22:35:10.169 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-29 22:35:10.169 INFO: Optimization: policy loss=0.016, vf loss=0.007, entropy loss=-0.034, total loss=-0.010, num steps=4
2022-12-29 22:35:10.173 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 22:35:11.505 INFO: Evaluation rollout: return=0.561 (0.0), episode length=5.0
2022-12-29 22:35:11.507 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 22:35:11.509 INFO: Iteration: 53/137, steps: 11448
2022-12-29 22:35:20.419 DEBUG: There is a single atom floating around
2022-12-29 22:35:26.023 DEBUG: Atoms are too close
2022-12-29 22:35:54.949 DEBUG: There is a single atom floating around
2022-12-29 22:36:07.757 INFO: Training rollout: return=-1.157 (5.6), episode length=4.9
2022-12-29 22:36:07.760 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 22:36:07.762 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-11448_train.pkl
2022-12-29 22:36:11.139 DEBUG: Taking gradient step
2022-12-29 22:36:11.149 DEBUG: Loss 0: {'policy_loss': -0.037889035145971896, 'entropy_loss': -0.03568866103887558, 'vf_loss': 0.019987575520961344, 'total_loss': -0.05359012066388613, 'approx_kl': 1.3050157576799393e-07, 'clip_fraction': 0.0, 'grad_norm': 19.28632926940918}
2022-12-29 22:36:14.488 DEBUG: Taking gradient step
2022-12-29 22:36:14.495 DEBUG: Loss 1: {'policy_loss': -0.02825461934852251, 'entropy_loss': -0.0341613469645381, 'vf_loss': 0.022579340516785937, 'total_loss': -0.03983662579627468, 'approx_kl': 0.005196798301767558, 'clip_fraction': 0.026041666977107525, 'grad_norm': 8.473589897155762}
2022-12-29 22:36:17.786 DEBUG: Taking gradient step
2022-12-29 22:36:17.796 DEBUG: Loss 2: {'policy_loss': -0.025649434893837968, 'entropy_loss': -0.03495414648205042, 'vf_loss': 0.022525287333760947, 'total_loss': -0.03807829404212744, 'approx_kl': 0.01938325329683721, 'clip_fraction': 0.2552083358168602, 'grad_norm': 4.9497246742248535}
2022-12-29 22:36:21.384 DEBUG: Taking gradient step
2022-12-29 22:36:21.391 DEBUG: Loss 3: {'policy_loss': -0.02019185224003648, 'entropy_loss': -0.03402603883296251, 'vf_loss': 0.02251335158999136, 'total_loss': -0.03170453948300764, 'approx_kl': 0.035063634626567364, 'clip_fraction': 0.421875, 'grad_norm': 6.562014579772949}
2022-12-29 22:36:24.762 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-29 22:36:24.763 INFO: Optimization: policy loss=-0.020, vf loss=0.023, entropy loss=-0.034, total loss=-0.032, num steps=4
2022-12-29 22:36:24.767 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 22:36:26.216 INFO: Evaluation rollout: return=0.565 (0.0), episode length=5.0
2022-12-29 22:36:26.217 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 22:36:26.220 INFO: Iteration: 54/137, steps: 11664
2022-12-29 22:37:24.092 INFO: Training rollout: return=0.529 (0.1), episode length=5.0
2022-12-29 22:37:24.094 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 22:37:24.096 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-11664_train.pkl
2022-12-29 22:37:27.492 DEBUG: Taking gradient step
2022-12-29 22:37:27.501 DEBUG: Loss 0: {'policy_loss': -0.009071758753945319, 'entropy_loss': -0.032961501739919186, 'vf_loss': 0.00014121715978039542, 'total_loss': -0.04189204333408411, 'approx_kl': 1.7617519887380695e-08, 'clip_fraction': 0.0, 'grad_norm': 15.882883071899414}
2022-12-29 22:37:30.998 DEBUG: Taking gradient step
2022-12-29 22:37:31.008 DEBUG: Loss 1: {'policy_loss': -0.0501139324560045, 'entropy_loss': -0.0330976783297956, 'vf_loss': 0.00015418477180796799, 'total_loss': -0.08305742601399213, 'approx_kl': 0.016862977179698646, 'clip_fraction': 0.046875, 'grad_norm': 12.78691291809082}
2022-12-29 22:37:34.444 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-29 22:37:34.445 INFO: Optimization: policy loss=-0.050, vf loss=0.000, entropy loss=-0.033, total loss=-0.083, num steps=2
2022-12-29 22:37:34.449 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 22:37:35.859 INFO: Evaluation rollout: return=0.599 (0.0), episode length=5.0
2022-12-29 22:37:35.861 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 22:37:35.863 INFO: Iteration: 55/137, steps: 11880
2022-12-29 22:38:32.905 INFO: Training rollout: return=0.541 (0.1), episode length=5.0
2022-12-29 22:38:32.907 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 22:38:32.910 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-11880_train.pkl
2022-12-29 22:38:36.244 DEBUG: Taking gradient step
2022-12-29 22:38:36.251 DEBUG: Loss 0: {'policy_loss': -0.053900733367483813, 'entropy_loss': -0.03218792099505663, 'vf_loss': 0.00016429660870692728, 'total_loss': -0.08592435775383352, 'approx_kl': -4.0105078369379044e-08, 'clip_fraction': 0.0, 'grad_norm': 10.940808296203613}
2022-12-29 22:38:39.548 DEBUG: Taking gradient step
2022-12-29 22:38:39.556 DEBUG: Loss 1: {'policy_loss': -0.03415125521049711, 'entropy_loss': -0.03328038798645139, 'vf_loss': 0.00016727758188515374, 'total_loss': -0.06726436561506334, 'approx_kl': 0.03309394791722298, 'clip_fraction': 0.11067708395421505, 'grad_norm': 12.768795013427734}
2022-12-29 22:38:42.962 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-29 22:38:42.962 INFO: Optimization: policy loss=-0.034, vf loss=0.000, entropy loss=-0.033, total loss=-0.067, num steps=2
2022-12-29 22:38:42.967 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 22:38:44.421 INFO: Evaluation rollout: return=0.611 (0.0), episode length=5.0
2022-12-29 22:38:44.423 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 22:38:44.426 INFO: Iteration: 56/137, steps: 12096
2022-12-29 22:38:58.946 DEBUG: Atoms are too close
2022-12-29 22:39:41.348 INFO: Training rollout: return=-0.025 (3.3), episode length=5.0
2022-12-29 22:39:41.350 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 22:39:41.353 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-12096_train.pkl
2022-12-29 22:39:44.680 DEBUG: Taking gradient step
2022-12-29 22:39:44.688 DEBUG: Loss 0: {'policy_loss': -0.027123653491336837, 'entropy_loss': -0.03125385567545891, 'vf_loss': 0.007657991141427177, 'total_loss': -0.05071951802536856, 'approx_kl': -6.965516718970832e-09, 'clip_fraction': 0.0, 'grad_norm': 15.984758377075195}
2022-12-29 22:39:48.008 DEBUG: Taking gradient step
2022-12-29 22:39:48.017 DEBUG: Loss 1: {'policy_loss': 0.06448988991856525, 'entropy_loss': -0.03174315998330712, 'vf_loss': 0.012556424372723122, 'total_loss': 0.045303154307981236, 'approx_kl': 0.0006714941700920463, 'clip_fraction': 0.10677083395421505, 'grad_norm': 17.76439094543457}
2022-12-29 22:39:51.499 DEBUG: Taking gradient step
2022-12-29 22:39:51.507 DEBUG: Loss 2: {'policy_loss': -0.036121899257566134, 'entropy_loss': -0.030322327744215727, 'vf_loss': 0.007653854938237683, 'total_loss': -0.05879037206354418, 'approx_kl': 0.006908901181304827, 'clip_fraction': 0.2109375, 'grad_norm': 7.232336521148682}
2022-12-29 22:39:55.023 DEBUG: Taking gradient step
2022-12-29 22:39:55.030 DEBUG: Loss 3: {'policy_loss': -0.002183654781479527, 'entropy_loss': -0.03008863003924489, 'vf_loss': 0.010214225435119777, 'total_loss': -0.02205805938560464, 'approx_kl': 0.021248661912977695, 'clip_fraction': 0.2981770858168602, 'grad_norm': 2.4714694023132324}
2022-12-29 22:39:58.347 DEBUG: Taking gradient step
2022-12-29 22:39:58.355 DEBUG: Loss 4: {'policy_loss': -0.03792055965665292, 'entropy_loss': -0.02885314216837287, 'vf_loss': 0.007648566691825881, 'total_loss': -0.05912513513319991, 'approx_kl': 0.029135263059288263, 'clip_fraction': 0.3333333358168602, 'grad_norm': 2.888566017150879}
2022-12-29 22:40:01.964 DEBUG: Taking gradient step
2022-12-29 22:40:01.973 DEBUG: Loss 5: {'policy_loss': -0.03661519422911266, 'entropy_loss': -0.029880406334996223, 'vf_loss': 0.007638181432288545, 'total_loss': -0.05885741913182034, 'approx_kl': 0.033185744658112526, 'clip_fraction': 0.3424479216337204, 'grad_norm': 2.730029821395874}
2022-12-29 22:40:05.355 DEBUG: Taking gradient step
2022-12-29 22:40:05.362 DEBUG: Loss 6: {'policy_loss': -0.00850589965180224, 'entropy_loss': -0.028678982984274626, 'vf_loss': 0.010138301187884866, 'total_loss': -0.027046581448192, 'approx_kl': 0.02948002121411264, 'clip_fraction': 0.33203125, 'grad_norm': 2.261834144592285}
2022-12-29 22:40:08.709 DEBUG: Taking gradient step
2022-12-29 22:40:08.717 DEBUG: Loss 7: {'policy_loss': -0.00860402944178769, 'entropy_loss': -0.02965673292055726, 'vf_loss': 0.010111397087660824, 'total_loss': -0.028149365274684122, 'approx_kl': 0.0047506652772426605, 'clip_fraction': 0.3997395858168602, 'grad_norm': 2.384644031524658}
2022-12-29 22:40:12.366 DEBUG: Taking gradient step
2022-12-29 22:40:12.373 DEBUG: Loss 8: {'policy_loss': -0.038365326036728056, 'entropy_loss': -0.0315101626329124, 'vf_loss': 0.0076289055397642785, 'total_loss': -0.06224658312987617, 'approx_kl': 0.004341518972069025, 'clip_fraction': 0.3971354216337204, 'grad_norm': 6.978525638580322}
2022-12-29 22:40:15.839 DEBUG: Taking gradient step
2022-12-29 22:40:15.847 DEBUG: Loss 9: {'policy_loss': 0.06533623471647815, 'entropy_loss': -0.029799087904393673, 'vf_loss': 0.015053633072015262, 'total_loss': 0.05059077988409974, 'approx_kl': 0.0011093057692050934, 'clip_fraction': 0.38671875, 'grad_norm': 5.442657470703125}
2022-12-29 22:40:15.847 INFO: Optimization: policy loss=0.065, vf loss=0.015, entropy loss=-0.030, total loss=0.051, num steps=10
2022-12-29 22:40:15.852 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 22:40:17.228 INFO: Evaluation rollout: return=0.691 (0.0), episode length=5.0
2022-12-29 22:40:17.229 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 22:40:17.231 INFO: Iteration: 57/137, steps: 12312
2022-12-29 22:40:45.085 DEBUG: Atoms are too close
2022-12-29 22:41:14.034 INFO: Training rollout: return=-0.012 (3.3), episode length=5.0
2022-12-29 22:41:14.037 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 22:41:14.039 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-12312_train.pkl
2022-12-29 22:41:17.362 DEBUG: Taking gradient step
2022-12-29 22:41:17.370 DEBUG: Loss 0: {'policy_loss': 0.025643754203624063, 'entropy_loss': -0.030129280406981707, 'vf_loss': 0.008847932317495932, 'total_loss': 0.004362406114138295, 'approx_kl': -4.284083843231201e-08, 'clip_fraction': 0.0, 'grad_norm': 17.597929000854492}
2022-12-29 22:41:20.603 DEBUG: Taking gradient step
2022-12-29 22:41:20.611 DEBUG: Loss 1: {'policy_loss': 0.021075051850010598, 'entropy_loss': -0.031242272350937128, 'vf_loss': 0.008838794338656392, 'total_loss': -0.0013284261622701424, 'approx_kl': 0.012391133466735482, 'clip_fraction': 0.04817708395421505, 'grad_norm': 12.628569602966309}
2022-12-29 22:41:23.985 DEBUG: Taking gradient step
2022-12-29 22:41:23.993 DEBUG: Loss 2: {'policy_loss': 0.00662043068899288, 'entropy_loss': -0.03046065801754594, 'vf_loss': 0.00887445432655295, 'total_loss': -0.01496577300200011, 'approx_kl': 0.026407106197439134, 'clip_fraction': 0.265625, 'grad_norm': 2.621263027191162}
2022-12-29 22:41:27.314 DEBUG: Taking gradient step
2022-12-29 22:41:27.322 DEBUG: Loss 3: {'policy_loss': -0.029378320240243234, 'entropy_loss': -0.031267482321709394, 'vf_loss': 0.006334160558164744, 'total_loss': -0.05431164200378788, 'approx_kl': 0.03601534882909618, 'clip_fraction': 0.3971354216337204, 'grad_norm': 2.799802303314209}
2022-12-29 22:41:30.795 DEBUG: Taking gradient step
2022-12-29 22:41:30.802 DEBUG: Loss 4: {'policy_loss': 0.00899669113961737, 'entropy_loss': -0.03162473673000932, 'vf_loss': 0.00886738999943828, 'total_loss': -0.013760655590953668, 'approx_kl': 0.03180782310664654, 'clip_fraction': 0.4361979216337204, 'grad_norm': 3.515617847442627}
2022-12-29 22:41:34.281 DEBUG: Taking gradient step
2022-12-29 22:41:34.288 DEBUG: Loss 5: {'policy_loss': 0.0076944874188301475, 'entropy_loss': -0.032158670015633106, 'vf_loss': 0.008818065442488237, 'total_loss': -0.015646117154314722, 'approx_kl': 0.04039802751503885, 'clip_fraction': 0.4088541716337204, 'grad_norm': 6.462974548339844}
2022-12-29 22:41:38.161 DEBUG: Taking gradient step
2022-12-29 22:41:38.168 DEBUG: Loss 6: {'policy_loss': 0.005331169215207269, 'entropy_loss': -0.0328531083650887, 'vf_loss': 0.008871492631785351, 'total_loss': -0.018650446518096084, 'approx_kl': 0.03620085120201111, 'clip_fraction': 0.4583333432674408, 'grad_norm': 3.588768243789673}
2022-12-29 22:41:41.628 DEBUG: Taking gradient step
2022-12-29 22:41:41.636 DEBUG: Loss 7: {'policy_loss': -0.03130124587700388, 'entropy_loss': -0.03303424082696438, 'vf_loss': 0.0063176189150802664, 'total_loss': -0.05801786778888798, 'approx_kl': 0.037161449901759624, 'clip_fraction': 0.3893229216337204, 'grad_norm': 3.386472463607788}
2022-12-29 22:41:45.349 DEBUG: Taking gradient step
2022-12-29 22:41:45.359 DEBUG: Loss 8: {'policy_loss': -0.037588146655572544, 'entropy_loss': -0.03336407104507089, 'vf_loss': 0.006309982890556772, 'total_loss': -0.06464223481008666, 'approx_kl': 0.0015034093521535397, 'clip_fraction': 0.2786458358168602, 'grad_norm': 3.0723888874053955}
2022-12-29 22:41:49.001 DEBUG: Taking gradient step
2022-12-29 22:41:49.009 DEBUG: Loss 9: {'policy_loss': -0.022817632934572132, 'entropy_loss': -0.0340882265008986, 'vf_loss': 0.006297224485312239, 'total_loss': -0.05060863495015849, 'approx_kl': -0.01275075162993744, 'clip_fraction': 0.2877604216337204, 'grad_norm': 15.965270042419434}
2022-12-29 22:41:49.009 INFO: Optimization: policy loss=-0.023, vf loss=0.006, entropy loss=-0.034, total loss=-0.051, num steps=10
2022-12-29 22:41:49.013 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 22:41:50.524 INFO: Evaluation rollout: return=0.600 (0.0), episode length=5.0
2022-12-29 22:41:50.525 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 22:41:50.528 INFO: Iteration: 58/137, steps: 12528
2022-12-29 22:42:18.284 DEBUG: Atoms are too close
2022-12-29 22:42:34.236 DEBUG: Atoms are too close
2022-12-29 22:42:35.463 DEBUG: Atoms are too close
2022-12-29 22:42:46.706 INFO: Training rollout: return=-1.158 (5.6), episode length=4.9
2022-12-29 22:42:46.708 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 22:42:46.711 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-12528_train.pkl
2022-12-29 22:42:50.191 DEBUG: Taking gradient step
2022-12-29 22:42:50.199 DEBUG: Loss 0: {'policy_loss': 0.01568276326422362, 'entropy_loss': -0.03202804131433368, 'vf_loss': 0.02482564037440966, 'total_loss': 0.0084803623242996, 'approx_kl': -6.28642737865448e-09, 'clip_fraction': 0.0, 'grad_norm': 16.873306274414062}
2022-12-29 22:42:53.602 DEBUG: Taking gradient step
2022-12-29 22:42:53.609 DEBUG: Loss 1: {'policy_loss': 0.01526363967983914, 'entropy_loss': -0.03250299021601677, 'vf_loss': 0.02485399001531658, 'total_loss': 0.00761463947913895, 'approx_kl': 0.0016807785723358393, 'clip_fraction': 0.03515625, 'grad_norm': 13.10977554321289}
2022-12-29 22:42:57.220 DEBUG: Taking gradient step
2022-12-29 22:42:57.228 DEBUG: Loss 2: {'policy_loss': -0.016045458750052463, 'entropy_loss': -0.03370481776073575, 'vf_loss': 0.02232051087330446, 'total_loss': -0.027429765637483755, 'approx_kl': 0.0004364933120086789, 'clip_fraction': 0.1692708358168602, 'grad_norm': 8.365827560424805}
2022-12-29 22:43:00.605 DEBUG: Taking gradient step
2022-12-29 22:43:00.612 DEBUG: Loss 3: {'policy_loss': 0.02845966612342211, 'entropy_loss': -0.03420956991612911, 'vf_loss': 0.02723593818452498, 'total_loss': 0.021486034391817975, 'approx_kl': 0.012481873854994774, 'clip_fraction': 0.2122395858168602, 'grad_norm': 7.9574995040893555}
2022-12-29 22:43:03.929 DEBUG: Taking gradient step
2022-12-29 22:43:03.940 DEBUG: Loss 4: {'policy_loss': -0.003926890826033326, 'entropy_loss': -0.032397350296378136, 'vf_loss': 0.024835067666190057, 'total_loss': -0.011489173456221408, 'approx_kl': 0.029014696832746267, 'clip_fraction': 0.2356770858168602, 'grad_norm': 13.235129356384277}
2022-12-29 22:43:07.505 DEBUG: Taking gradient step
2022-12-29 22:43:07.516 DEBUG: Loss 5: {'policy_loss': 0.016413640782142927, 'entropy_loss': -0.03063491592183709, 'vf_loss': 0.027279930156694915, 'total_loss': 0.01305865501700075, 'approx_kl': 0.04045072291046381, 'clip_fraction': 0.3463541716337204, 'grad_norm': 4.7365875244140625}
2022-12-29 22:43:11.042 DEBUG: Early stopping at step 6 for reaching max KL.
2022-12-29 22:43:11.043 INFO: Optimization: policy loss=0.016, vf loss=0.027, entropy loss=-0.031, total loss=0.013, num steps=6
2022-12-29 22:43:11.047 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 22:43:12.453 INFO: Evaluation rollout: return=0.613 (0.0), episode length=5.0
2022-12-29 22:43:12.454 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 22:43:12.457 INFO: Iteration: 59/137, steps: 12744
2022-12-29 22:43:58.346 DEBUG: Atoms are too close
2022-12-29 22:44:10.219 INFO: Training rollout: return=-0.037 (3.3), episode length=5.0
2022-12-29 22:44:10.221 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 22:44:10.224 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-12744_train.pkl
2022-12-29 22:44:13.890 DEBUG: Taking gradient step
2022-12-29 22:44:13.897 DEBUG: Loss 0: {'policy_loss': -0.02205730113274302, 'entropy_loss': -0.030673228204250336, 'vf_loss': 0.00773440779131949, 'total_loss': -0.04499612154567387, 'approx_kl': 1.0632598801407767e-08, 'clip_fraction': 0.0, 'grad_norm': 12.154082298278809}
2022-12-29 22:44:17.356 DEBUG: Taking gradient step
2022-12-29 22:44:17.363 DEBUG: Loss 1: {'policy_loss': 0.04685560569770239, 'entropy_loss': -0.030890359543263912, 'vf_loss': 0.012663152873609414, 'total_loss': 0.02862839902804789, 'approx_kl': 0.01515427348203957, 'clip_fraction': 0.15234375, 'grad_norm': 5.344799041748047}
2022-12-29 22:44:20.572 DEBUG: Taking gradient step
2022-12-29 22:44:20.580 DEBUG: Loss 2: {'policy_loss': -0.03373684776369301, 'entropy_loss': -0.031170815229415894, 'vf_loss': 0.0077495078685513455, 'total_loss': -0.05715815512455756, 'approx_kl': 0.03973068203777075, 'clip_fraction': 0.2825520858168602, 'grad_norm': 4.469475269317627}
2022-12-29 22:44:23.941 DEBUG: Taking gradient step
2022-12-29 22:44:23.949 DEBUG: Loss 3: {'policy_loss': 0.006899301672558578, 'entropy_loss': -0.030442555900663137, 'vf_loss': 0.010224564332960737, 'total_loss': -0.013318689895143818, 'approx_kl': 0.042142986319959164, 'clip_fraction': 0.26692708395421505, 'grad_norm': 5.162377834320068}
2022-12-29 22:44:27.328 DEBUG: Taking gradient step
2022-12-29 22:44:27.336 DEBUG: Loss 4: {'policy_loss': -0.03551239123086013, 'entropy_loss': -0.03166878782212734, 'vf_loss': 0.007751087319555628, 'total_loss': -0.059430091733431833, 'approx_kl': 0.023061679676175117, 'clip_fraction': 0.2942708358168602, 'grad_norm': 3.8864500522613525}
2022-12-29 22:44:30.780 DEBUG: Taking gradient step
2022-12-29 22:44:30.787 DEBUG: Loss 5: {'policy_loss': -0.03552893209893082, 'entropy_loss': -0.03195799281820655, 'vf_loss': 0.007758360109999911, 'total_loss': -0.05972856480713745, 'approx_kl': 0.02553987188730389, 'clip_fraction': 0.3098958358168602, 'grad_norm': 10.226305961608887}
2022-12-29 22:44:34.220 DEBUG: Taking gradient step
2022-12-29 22:44:34.228 DEBUG: Loss 6: {'policy_loss': -0.03669752162770857, 'entropy_loss': -0.031231903471052647, 'vf_loss': 0.0077422793694038325, 'total_loss': -0.060187145729357384, 'approx_kl': 0.0038959237281233072, 'clip_fraction': 0.3359375, 'grad_norm': 4.708160877227783}
2022-12-29 22:44:37.756 DEBUG: Taking gradient step
2022-12-29 22:44:37.764 DEBUG: Loss 7: {'policy_loss': -0.005006040349093549, 'entropy_loss': -0.03206430980935693, 'vf_loss': 0.010250397088611973, 'total_loss': -0.0268199530698385, 'approx_kl': 0.03223773278295994, 'clip_fraction': 0.3515625, 'grad_norm': 3.6023173332214355}
2022-12-29 22:44:41.306 DEBUG: Taking gradient step
2022-12-29 22:44:41.313 DEBUG: Loss 8: {'policy_loss': 0.005166214569561706, 'entropy_loss': -0.03251423500478268, 'vf_loss': 0.010194459588006473, 'total_loss': -0.017153560847214498, 'approx_kl': 0.007325737737119198, 'clip_fraction': 0.4348958358168602, 'grad_norm': 2.5248634815216064}
2022-12-29 22:44:44.646 DEBUG: Taking gradient step
2022-12-29 22:44:44.654 DEBUG: Loss 9: {'policy_loss': -0.04089327042558149, 'entropy_loss': -0.03389360476285219, 'vf_loss': 0.007743386546720805, 'total_loss': -0.06704348864171288, 'approx_kl': 0.00236705644056201, 'clip_fraction': 0.4609375, 'grad_norm': 2.1223385334014893}
2022-12-29 22:44:44.654 INFO: Optimization: policy loss=-0.041, vf loss=0.008, entropy loss=-0.034, total loss=-0.067, num steps=10
2022-12-29 22:44:44.658 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 22:44:46.048 INFO: Evaluation rollout: return=0.591 (0.0), episode length=5.0
2022-12-29 22:44:46.049 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 22:44:46.052 INFO: Iteration: 60/137, steps: 12960
2022-12-29 22:45:11.508 DEBUG: Atoms are too close
2022-12-29 22:45:26.288 DEBUG: Atoms are too close
2022-12-29 22:45:42.529 INFO: Training rollout: return=-0.580 (4.6), episode length=4.9
2022-12-29 22:45:42.531 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 22:45:42.534 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-12960_train.pkl
2022-12-29 22:45:46.103 DEBUG: Taking gradient step
2022-12-29 22:45:46.110 DEBUG: Loss 0: {'policy_loss': 0.046241690155227666, 'entropy_loss': -0.03348528919741511, 'vf_loss': 0.015845586352759296, 'total_loss': 0.02860198731057185, 'approx_kl': -1.241763456505396e-07, 'clip_fraction': 0.0, 'grad_norm': 33.5384635925293}
2022-12-29 22:45:49.387 DEBUG: Taking gradient step
2022-12-29 22:45:49.394 DEBUG: Loss 1: {'policy_loss': -0.0008032988463175725, 'entropy_loss': -0.03426170255988836, 'vf_loss': 0.013324069061647119, 'total_loss': -0.021740932344558813, 'approx_kl': 0.007338259485550225, 'clip_fraction': 0.109375, 'grad_norm': 9.830309867858887}
2022-12-29 22:45:52.781 DEBUG: Taking gradient step
2022-12-29 22:45:52.788 DEBUG: Loss 2: {'policy_loss': -0.04028945738536675, 'entropy_loss': -0.03682560566812754, 'vf_loss': 0.010836604120797606, 'total_loss': -0.0662784589326967, 'approx_kl': 0.013116397429257631, 'clip_fraction': 0.28515625, 'grad_norm': 4.448055267333984}
2022-12-29 22:45:56.122 DEBUG: Taking gradient step
2022-12-29 22:45:56.131 DEBUG: Loss 3: {'policy_loss': -0.003137018518328436, 'entropy_loss': -0.03570831287652254, 'vf_loss': 0.013357433808658585, 'total_loss': -0.025487897586192396, 'approx_kl': 0.02688645478338003, 'clip_fraction': 0.3125, 'grad_norm': 4.481131553649902}
2022-12-29 22:45:59.913 DEBUG: Taking gradient step
2022-12-29 22:45:59.924 DEBUG: Loss 4: {'policy_loss': 0.01935118203438667, 'entropy_loss': -0.03548413794487715, 'vf_loss': 0.01582808783420482, 'total_loss': -0.0003048680762856651, 'approx_kl': 0.013329688925296068, 'clip_fraction': 0.3424479216337204, 'grad_norm': 4.008369445800781}
2022-12-29 22:46:03.691 DEBUG: Taking gradient step
2022-12-29 22:46:03.699 DEBUG: Loss 5: {'policy_loss': -0.014892747077352775, 'entropy_loss': -0.03568619955331087, 'vf_loss': 0.01081168714057094, 'total_loss': -0.0397672594900927, 'approx_kl': 0.0021093948744237423, 'clip_fraction': 0.3658854216337204, 'grad_norm': 33.35487747192383}
2022-12-29 22:46:07.014 DEBUG: Taking gradient step
2022-12-29 22:46:07.021 DEBUG: Loss 6: {'policy_loss': 0.06528760337757088, 'entropy_loss': -0.03587946854531765, 'vf_loss': 0.015803053560671347, 'total_loss': 0.04521118839292458, 'approx_kl': 0.017334423726424575, 'clip_fraction': 0.4466145858168602, 'grad_norm': 37.142215728759766}
2022-12-29 22:46:10.512 DEBUG: Taking gradient step
2022-12-29 22:46:10.523 DEBUG: Loss 7: {'policy_loss': -0.02355797636737477, 'entropy_loss': -0.03791017970070243, 'vf_loss': 0.01080360151044377, 'total_loss': -0.050664554557633426, 'approx_kl': 0.005834791576489806, 'clip_fraction': 0.4986979216337204, 'grad_norm': 25.94766616821289}
2022-12-29 22:46:13.996 DEBUG: Taking gradient step
2022-12-29 22:46:14.003 DEBUG: Loss 8: {'policy_loss': -0.00896234093260157, 'entropy_loss': -0.03784968703985214, 'vf_loss': 0.013280534175832604, 'total_loss': -0.033531493796621105, 'approx_kl': 0.01221813471056521, 'clip_fraction': 0.5052083358168602, 'grad_norm': 6.796292304992676}
2022-12-29 22:46:17.293 DEBUG: Early stopping at step 9 for reaching max KL.
2022-12-29 22:46:17.294 INFO: Optimization: policy loss=-0.009, vf loss=0.013, entropy loss=-0.038, total loss=-0.034, num steps=9
2022-12-29 22:46:17.298 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 22:46:18.714 INFO: Evaluation rollout: return=0.584 (0.0), episode length=5.0
2022-12-29 22:46:18.715 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 22:46:18.718 DEBUG: Deleting old model: runs/CH4_int/models/CH4_int_run-1_steps-11016.model
2022-12-29 22:46:18.723 DEBUG: Saving model: runs/CH4_int/models/CH4_int_run-1_steps-13176.model
2022-12-29 22:46:18.745 INFO: Iteration: 61/137, steps: 13176
2022-12-29 22:46:47.841 DEBUG: There is a single atom floating around
2022-12-29 22:47:15.492 INFO: Training rollout: return=-0.050 (3.3), episode length=5.0
2022-12-29 22:47:15.495 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 22:47:15.497 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-13176_train.pkl
2022-12-29 22:47:19.006 DEBUG: Taking gradient step
2022-12-29 22:47:19.013 DEBUG: Loss 0: {'policy_loss': 0.02090832318708688, 'entropy_loss': -0.037382726557552814, 'vf_loss': 0.010191064188237632, 'total_loss': -0.006283339182228297, 'approx_kl': -1.1951972744839168e-08, 'clip_fraction': 0.0, 'grad_norm': 19.039724349975586}
2022-12-29 22:47:22.435 DEBUG: Taking gradient step
2022-12-29 22:47:22.443 DEBUG: Loss 1: {'policy_loss': 0.022671450495554378, 'entropy_loss': -0.03818617668002844, 'vf_loss': 0.010197286925357391, 'total_loss': -0.005317439259116666, 'approx_kl': -0.007038291543722153, 'clip_fraction': 0.1276041679084301, 'grad_norm': 26.999643325805664}
2022-12-29 22:47:26.057 DEBUG: Taking gradient step
2022-12-29 22:47:26.064 DEBUG: Loss 2: {'policy_loss': 0.06218920571823296, 'entropy_loss': -0.03666548151522875, 'vf_loss': 0.012585227699550283, 'total_loss': 0.03810895190255449, 'approx_kl': -0.00531407818198204, 'clip_fraction': 0.1927083358168602, 'grad_norm': 22.95514678955078}
2022-12-29 22:47:29.455 DEBUG: Taking gradient step
2022-12-29 22:47:29.462 DEBUG: Loss 3: {'policy_loss': -0.001374767773092339, 'entropy_loss': -0.03645296022295952, 'vf_loss': 0.010269706524932906, 'total_loss': -0.02755802147111895, 'approx_kl': 0.023007998010143638, 'clip_fraction': 0.19921875, 'grad_norm': 1.8727388381958008}
2022-12-29 22:47:32.916 DEBUG: Taking gradient step
2022-12-29 22:47:32.924 DEBUG: Loss 4: {'policy_loss': 0.0047764281964848, 'entropy_loss': -0.03582956874743104, 'vf_loss': 0.010154039800877365, 'total_loss': -0.020899100750068872, 'approx_kl': 0.02322684897808358, 'clip_fraction': 0.20052083395421505, 'grad_norm': 1.2647972106933594}
2022-12-29 22:47:36.470 DEBUG: Taking gradient step
2022-12-29 22:47:36.478 DEBUG: Loss 5: {'policy_loss': -0.037418977077051316, 'entropy_loss': -0.03689274284988642, 'vf_loss': 0.0077075402635521486, 'total_loss': -0.06660417966338558, 'approx_kl': 0.02074171171989292, 'clip_fraction': 0.16666666697710752, 'grad_norm': 1.8184551000595093}
2022-12-29 22:47:39.797 DEBUG: Taking gradient step
2022-12-29 22:47:39.805 DEBUG: Loss 6: {'policy_loss': -0.04074363081118085, 'entropy_loss': -0.03646194748580456, 'vf_loss': 0.00770950257943472, 'total_loss': -0.06949607571755068, 'approx_kl': 0.011799224419519305, 'clip_fraction': 0.15494791697710752, 'grad_norm': 1.4069243669509888}
2022-12-29 22:47:43.440 DEBUG: Taking gradient step
2022-12-29 22:47:43.448 DEBUG: Loss 7: {'policy_loss': -0.005595590430599116, 'entropy_loss': -0.036559305153787136, 'vf_loss': 0.010153076066021333, 'total_loss': -0.032001819518364914, 'approx_kl': -0.0023439843207597733, 'clip_fraction': 0.1861979179084301, 'grad_norm': 5.978572845458984}
2022-12-29 22:47:47.082 DEBUG: Taking gradient step
2022-12-29 22:47:47.089 DEBUG: Loss 8: {'policy_loss': -0.002501595067004682, 'entropy_loss': -0.038259467110037804, 'vf_loss': 0.01021870228087583, 'total_loss': -0.030542359896166656, 'approx_kl': 0.009646384743973613, 'clip_fraction': 0.2395833358168602, 'grad_norm': 6.261414527893066}
2022-12-29 22:47:50.515 DEBUG: Taking gradient step
2022-12-29 22:47:50.526 DEBUG: Loss 9: {'policy_loss': -0.04165714386926554, 'entropy_loss': -0.03640540549531579, 'vf_loss': 0.007703402192734993, 'total_loss': -0.07035914717184634, 'approx_kl': -0.0029723206534981728, 'clip_fraction': 0.3072916716337204, 'grad_norm': 1.7015860080718994}
2022-12-29 22:47:50.526 INFO: Optimization: policy loss=-0.042, vf loss=0.008, entropy loss=-0.036, total loss=-0.070, num steps=10
2022-12-29 22:47:50.530 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 22:47:51.922 INFO: Evaluation rollout: return=0.577 (0.0), episode length=5.0
2022-12-29 22:47:51.923 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 22:47:51.926 INFO: Iteration: 62/137, steps: 13392
2022-12-29 22:48:49.583 INFO: Training rollout: return=0.508 (0.1), episode length=5.0
2022-12-29 22:48:49.585 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 22:48:49.588 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-13392_train.pkl
2022-12-29 22:48:53.095 DEBUG: Taking gradient step
2022-12-29 22:48:53.108 DEBUG: Loss 0: {'policy_loss': 0.0004781530227209417, 'entropy_loss': -0.037295568734407425, 'vf_loss': 0.0003296560005667762, 'total_loss': -0.036487759711119706, 'approx_kl': 7.993852246812594e-09, 'clip_fraction': 0.0, 'grad_norm': 9.306589126586914}
2022-12-29 22:48:56.692 DEBUG: Taking gradient step
2022-12-29 22:48:56.699 DEBUG: Loss 1: {'policy_loss': 0.01700079178549528, 'entropy_loss': -0.037789223715662956, 'vf_loss': 0.0003250557781067793, 'total_loss': -0.020463376152060897, 'approx_kl': 0.007200800348073244, 'clip_fraction': 0.11979166697710752, 'grad_norm': 9.99188232421875}
2022-12-29 22:49:00.212 DEBUG: Taking gradient step
2022-12-29 22:49:00.223 DEBUG: Loss 2: {'policy_loss': -0.0455646096506537, 'entropy_loss': -0.03742574714124203, 'vf_loss': 0.00032909103107648475, 'total_loss': -0.08266126576081924, 'approx_kl': 0.02365639340132475, 'clip_fraction': 0.2552083358168602, 'grad_norm': 12.761188507080078}
2022-12-29 22:49:03.517 DEBUG: Taking gradient step
2022-12-29 22:49:03.524 DEBUG: Loss 3: {'policy_loss': -0.03120985832108191, 'entropy_loss': -0.03630699776113033, 'vf_loss': 0.00031972418350455835, 'total_loss': -0.06719713189870768, 'approx_kl': 0.041189899668097496, 'clip_fraction': 0.3151041716337204, 'grad_norm': 10.776535987854004}
2022-12-29 22:49:06.900 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-29 22:49:06.901 INFO: Optimization: policy loss=-0.031, vf loss=0.000, entropy loss=-0.036, total loss=-0.067, num steps=4
2022-12-29 22:49:06.904 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 22:49:08.315 INFO: Evaluation rollout: return=0.593 (0.0), episode length=5.0
2022-12-29 22:49:08.317 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 22:49:08.320 INFO: Iteration: 63/137, steps: 13608
2022-12-29 22:50:05.688 INFO: Training rollout: return=0.510 (0.1), episode length=5.0
2022-12-29 22:50:05.691 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 22:50:05.693 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-13608_train.pkl
2022-12-29 22:50:09.123 DEBUG: Taking gradient step
2022-12-29 22:50:09.131 DEBUG: Loss 0: {'policy_loss': 0.021920556079993863, 'entropy_loss': -0.037096609361469746, 'vf_loss': 0.0002986655349609611, 'total_loss': -0.014877387746514925, 'approx_kl': 2.2506961627755118e-08, 'clip_fraction': 0.0, 'grad_norm': 5.59976863861084}
2022-12-29 22:50:12.532 DEBUG: Taking gradient step
2022-12-29 22:50:12.543 DEBUG: Loss 1: {'policy_loss': 0.02156999766001764, 'entropy_loss': -0.03743935562670231, 'vf_loss': 0.00028594904114675215, 'total_loss': -0.015583408925537907, 'approx_kl': 0.0017750870902091265, 'clip_fraction': 0.10546875, 'grad_norm': 11.366127014160156}
2022-12-29 22:50:16.291 DEBUG: Taking gradient step
2022-12-29 22:50:16.301 DEBUG: Loss 2: {'policy_loss': -0.03292849596189774, 'entropy_loss': -0.03698471235111356, 'vf_loss': 0.00027789930698939627, 'total_loss': -0.0696353090060219, 'approx_kl': 0.00715031661093235, 'clip_fraction': 0.19921875, 'grad_norm': 11.93208122253418}
2022-12-29 22:50:19.873 DEBUG: Taking gradient step
2022-12-29 22:50:19.884 DEBUG: Loss 3: {'policy_loss': 0.0013357517216947648, 'entropy_loss': -0.034232492092996836, 'vf_loss': 0.0002626682849590405, 'total_loss': -0.03263407208634303, 'approx_kl': -0.0005732378922402859, 'clip_fraction': 0.2265625, 'grad_norm': 11.868692398071289}
2022-12-29 22:50:23.191 DEBUG: Taking gradient step
2022-12-29 22:50:23.199 DEBUG: Loss 4: {'policy_loss': 0.008639052337191578, 'entropy_loss': -0.034709612373262644, 'vf_loss': 0.00024216279902691338, 'total_loss': -0.02582839723704415, 'approx_kl': 0.016933216946199536, 'clip_fraction': 0.2552083358168602, 'grad_norm': 9.194825172424316}
2022-12-29 22:50:26.585 DEBUG: Taking gradient step
2022-12-29 22:50:26.592 DEBUG: Loss 5: {'policy_loss': 0.0028303545452735973, 'entropy_loss': -0.036375788040459156, 'vf_loss': 0.00022379339483393865, 'total_loss': -0.03332164010035162, 'approx_kl': -0.003366154618561268, 'clip_fraction': 0.2395833358168602, 'grad_norm': 8.953364372253418}
2022-12-29 22:50:30.123 DEBUG: Taking gradient step
2022-12-29 22:50:30.130 DEBUG: Loss 6: {'policy_loss': -0.03305091183416725, 'entropy_loss': -0.03437420912086964, 'vf_loss': 0.00021625713281663055, 'total_loss': -0.06720886382222026, 'approx_kl': 0.02070004551205784, 'clip_fraction': 0.2434895858168602, 'grad_norm': 6.645942211151123}
2022-12-29 22:50:33.679 DEBUG: Taking gradient step
2022-12-29 22:50:33.687 DEBUG: Loss 7: {'policy_loss': -0.01766142319556803, 'entropy_loss': -0.035184165462851524, 'vf_loss': 0.00019841175302439908, 'total_loss': -0.05264717690539515, 'approx_kl': 0.03421980468556285, 'clip_fraction': 0.25911458395421505, 'grad_norm': 6.547966957092285}
2022-12-29 22:50:37.150 DEBUG: Early stopping at step 8 for reaching max KL.
2022-12-29 22:50:37.151 INFO: Optimization: policy loss=-0.018, vf loss=0.000, entropy loss=-0.035, total loss=-0.053, num steps=8
2022-12-29 22:50:37.154 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 22:50:38.511 INFO: Evaluation rollout: return=0.596 (0.0), episode length=5.0
2022-12-29 22:50:38.512 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 22:50:38.515 INFO: Iteration: 64/137, steps: 13824
2022-12-29 22:50:51.414 DEBUG: There is a single atom floating around
2022-12-29 22:51:35.149 INFO: Training rollout: return=-0.024 (3.3), episode length=5.0
2022-12-29 22:51:35.151 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 22:51:35.154 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-13824_train.pkl
2022-12-29 22:51:38.395 DEBUG: Taking gradient step
2022-12-29 22:51:38.403 DEBUG: Loss 0: {'policy_loss': -0.024689020775325924, 'entropy_loss': -0.03755198325961828, 'vf_loss': 0.007717247726112873, 'total_loss': -0.05452375630883133, 'approx_kl': -1.6899624810662317e-08, 'clip_fraction': 0.0, 'grad_norm': 13.483549118041992}
2022-12-29 22:51:42.065 DEBUG: Taking gradient step
2022-12-29 22:51:42.072 DEBUG: Loss 1: {'policy_loss': 0.01365602560817012, 'entropy_loss': -0.03739514108747244, 'vf_loss': 0.010255806318804649, 'total_loss': -0.01348330916049767, 'approx_kl': 0.001052948588039726, 'clip_fraction': 0.015625, 'grad_norm': 11.365022659301758}
2022-12-29 22:51:45.355 DEBUG: Taking gradient step
2022-12-29 22:51:45.365 DEBUG: Loss 2: {'policy_loss': -0.03469228643664088, 'entropy_loss': -0.03595998231321573, 'vf_loss': 0.007714625031064958, 'total_loss': -0.06293764371879165, 'approx_kl': 0.01060307223815471, 'clip_fraction': 0.08072916697710752, 'grad_norm': 3.34761118888855}
2022-12-29 22:51:48.929 DEBUG: Taking gradient step
2022-12-29 22:51:48.937 DEBUG: Loss 3: {'policy_loss': -0.04538091292718104, 'entropy_loss': -0.03603220544755459, 'vf_loss': 0.007729014423530301, 'total_loss': -0.07368410395120532, 'approx_kl': 0.005531264003366232, 'clip_fraction': 0.2330729216337204, 'grad_norm': 3.804861307144165}
2022-12-29 22:51:52.555 DEBUG: Taking gradient step
2022-12-29 22:51:52.563 DEBUG: Loss 4: {'policy_loss': -0.04305538098016018, 'entropy_loss': -0.03743323124945164, 'vf_loss': 0.007725031622312542, 'total_loss': -0.07276358060729926, 'approx_kl': 0.03477266733534634, 'clip_fraction': 0.3424479216337204, 'grad_norm': 2.581045627593994}
2022-12-29 22:51:55.850 DEBUG: Early stopping at step 5 for reaching max KL.
2022-12-29 22:51:55.851 INFO: Optimization: policy loss=-0.043, vf loss=0.008, entropy loss=-0.037, total loss=-0.073, num steps=5
2022-12-29 22:51:55.855 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 22:51:57.301 INFO: Evaluation rollout: return=0.603 (0.0), episode length=5.0
2022-12-29 22:51:57.302 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 22:51:57.305 INFO: Iteration: 65/137, steps: 14040
2022-12-29 22:52:54.653 INFO: Training rollout: return=0.534 (0.1), episode length=5.0
2022-12-29 22:52:54.655 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 22:52:54.658 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-14040_train.pkl
2022-12-29 22:52:58.077 DEBUG: Taking gradient step
2022-12-29 22:52:58.088 DEBUG: Loss 0: {'policy_loss': -0.0026861518566334685, 'entropy_loss': -0.0383144561201334, 'vf_loss': 0.0001674371900564813, 'total_loss': -0.040833170786710386, 'approx_kl': -3.7563344434943247e-08, 'clip_fraction': 0.0, 'grad_norm': 16.751970291137695}
2022-12-29 22:53:01.847 DEBUG: Taking gradient step
2022-12-29 22:53:01.855 DEBUG: Loss 1: {'policy_loss': 0.006771546706110141, 'entropy_loss': -0.037235911935567856, 'vf_loss': 0.00016156033107153322, 'total_loss': -0.03030280489838618, 'approx_kl': 0.014824349898844957, 'clip_fraction': 0.13802083395421505, 'grad_norm': 12.31088638305664}
2022-12-29 22:53:05.295 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-29 22:53:05.296 INFO: Optimization: policy loss=0.007, vf loss=0.000, entropy loss=-0.037, total loss=-0.030, num steps=2
2022-12-29 22:53:05.300 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 22:53:06.671 INFO: Evaluation rollout: return=0.552 (0.0), episode length=5.0
2022-12-29 22:53:06.672 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 22:53:06.674 INFO: Iteration: 66/137, steps: 14256
2022-12-29 22:54:03.812 INFO: Training rollout: return=0.535 (0.1), episode length=5.0
2022-12-29 22:54:03.814 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 22:54:03.817 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-14256_train.pkl
2022-12-29 22:54:07.181 DEBUG: Taking gradient step
2022-12-29 22:54:07.189 DEBUG: Loss 0: {'policy_loss': -0.018173324818059576, 'entropy_loss': -0.037457515485584736, 'vf_loss': 0.00016042968661593307, 'total_loss': -0.05547041061702837, 'approx_kl': 8.292651543229113e-08, 'clip_fraction': 0.0, 'grad_norm': 12.30469799041748}
2022-12-29 22:54:10.589 DEBUG: Taking gradient step
2022-12-29 22:54:10.600 DEBUG: Loss 1: {'policy_loss': -0.0017270655440309, 'entropy_loss': -0.038745418190956116, 'vf_loss': 0.00015037936776515515, 'total_loss': -0.04032210436722186, 'approx_kl': 0.010518904658965766, 'clip_fraction': 0.01953125, 'grad_norm': 12.723634719848633}
2022-12-29 22:54:14.252 DEBUG: Taking gradient step
2022-12-29 22:54:14.259 DEBUG: Loss 2: {'policy_loss': -0.010903106492606328, 'entropy_loss': -0.03802375588566065, 'vf_loss': 0.00014515507934773845, 'total_loss': -0.04878170729891924, 'approx_kl': 0.028725632466375828, 'clip_fraction': 0.20052083395421505, 'grad_norm': 15.407600402832031}
2022-12-29 22:54:17.585 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-29 22:54:17.585 INFO: Optimization: policy loss=-0.011, vf loss=0.000, entropy loss=-0.038, total loss=-0.049, num steps=3
2022-12-29 22:54:17.589 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 22:54:18.908 INFO: Evaluation rollout: return=0.610 (0.0), episode length=5.0
2022-12-29 22:54:18.910 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 22:54:18.912 INFO: Iteration: 67/137, steps: 14472
2022-12-29 22:55:16.072 INFO: Training rollout: return=0.530 (0.1), episode length=5.0
2022-12-29 22:55:16.074 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 22:55:16.076 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-14472_train.pkl
2022-12-29 22:55:19.501 DEBUG: Taking gradient step
2022-12-29 22:55:19.509 DEBUG: Loss 0: {'policy_loss': 0.031219408836744258, 'entropy_loss': -0.03905355464667082, 'vf_loss': 0.00012953891314813217, 'total_loss': -0.007704606896778425, 'approx_kl': -2.0605511963367462e-08, 'clip_fraction': 0.0, 'grad_norm': 16.95109748840332}
2022-12-29 22:55:23.171 DEBUG: Taking gradient step
2022-12-29 22:55:23.178 DEBUG: Loss 1: {'policy_loss': -0.02090715634948512, 'entropy_loss': -0.038103300146758556, 'vf_loss': 0.0001284041626339381, 'total_loss': -0.058882052333609734, 'approx_kl': 0.02567907329648733, 'clip_fraction': 0.14583333395421505, 'grad_norm': 13.830782890319824}
2022-12-29 22:55:26.472 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-29 22:55:26.472 INFO: Optimization: policy loss=-0.021, vf loss=0.000, entropy loss=-0.038, total loss=-0.059, num steps=2
2022-12-29 22:55:26.476 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 22:55:27.860 INFO: Evaluation rollout: return=0.622 (0.0), episode length=5.0
2022-12-29 22:55:27.861 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 22:55:27.864 INFO: Iteration: 68/137, steps: 14688
2022-12-29 22:56:24.945 INFO: Training rollout: return=0.481 (0.1), episode length=5.0
2022-12-29 22:56:24.947 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 22:56:24.949 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-14688_train.pkl
2022-12-29 22:56:28.452 DEBUG: Taking gradient step
2022-12-29 22:56:28.460 DEBUG: Loss 0: {'policy_loss': -0.02103946504659479, 'entropy_loss': -0.0377981923520565, 'vf_loss': 0.00011651158675150106, 'total_loss': -0.0587211458118998, 'approx_kl': 4.0318507643632984e-08, 'clip_fraction': 0.0, 'grad_norm': 14.126442909240723}
2022-12-29 22:56:31.799 DEBUG: Taking gradient step
2022-12-29 22:56:31.807 DEBUG: Loss 1: {'policy_loss': 0.005943966127181996, 'entropy_loss': -0.03689835872501135, 'vf_loss': 0.0001049071514422694, 'total_loss': -0.030849485446387086, 'approx_kl': 0.018046155688352883, 'clip_fraction': 0.07942708395421505, 'grad_norm': 20.938583374023438}
2022-12-29 22:56:35.136 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-29 22:56:35.136 INFO: Optimization: policy loss=0.006, vf loss=0.000, entropy loss=-0.037, total loss=-0.031, num steps=2
2022-12-29 22:56:35.141 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 22:56:36.513 INFO: Evaluation rollout: return=0.603 (0.0), episode length=5.0
2022-12-29 22:56:36.514 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 22:56:36.516 INFO: Iteration: 69/137, steps: 14904
2022-12-29 22:57:33.920 INFO: Training rollout: return=0.562 (0.1), episode length=5.0
2022-12-29 22:57:33.923 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 22:57:33.926 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-14904_train.pkl
2022-12-29 22:57:37.282 DEBUG: Taking gradient step
2022-12-29 22:57:37.289 DEBUG: Loss 0: {'policy_loss': -0.027751059442788356, 'entropy_loss': -0.035184239968657494, 'vf_loss': 0.00014479538964627474, 'total_loss': -0.06279050402179957, 'approx_kl': 2.110997954218874e-08, 'clip_fraction': 0.0, 'grad_norm': 15.407794952392578}
2022-12-29 22:57:40.637 DEBUG: Taking gradient step
2022-12-29 22:57:40.645 DEBUG: Loss 1: {'policy_loss': 0.024021865171840226, 'entropy_loss': -0.0365478852763772, 'vf_loss': 0.0001299704973694903, 'total_loss': -0.012396049607167482, 'approx_kl': 0.016379630658775568, 'clip_fraction': 0.12890625, 'grad_norm': 13.168819427490234}
2022-12-29 22:57:44.116 DEBUG: Taking gradient step
2022-12-29 22:57:44.124 DEBUG: Loss 2: {'policy_loss': 0.001219867640633563, 'entropy_loss': -0.03522448614239693, 'vf_loss': 0.00013089948393162415, 'total_loss': -0.03387371901783174, 'approx_kl': 0.04176622210070491, 'clip_fraction': 0.2239583358168602, 'grad_norm': 10.933086395263672}
2022-12-29 22:57:47.775 DEBUG: Taking gradient step
2022-12-29 22:57:47.783 DEBUG: Loss 3: {'policy_loss': 0.010635241738200806, 'entropy_loss': -0.03486110549420118, 'vf_loss': 0.00012040879047003431, 'total_loss': -0.024105454965530345, 'approx_kl': 0.03767382679507136, 'clip_fraction': 0.2643229216337204, 'grad_norm': 6.832533359527588}
2022-12-29 22:57:51.011 DEBUG: Taking gradient step
2022-12-29 22:57:51.019 DEBUG: Loss 4: {'policy_loss': 0.053884825737529174, 'entropy_loss': -0.03633344592526555, 'vf_loss': 0.00011176046342416252, 'total_loss': 0.017663140275687786, 'approx_kl': 0.04318737657740712, 'clip_fraction': 0.2903645858168602, 'grad_norm': 18.665855407714844}
2022-12-29 22:57:54.397 DEBUG: Early stopping at step 5 for reaching max KL.
2022-12-29 22:57:54.397 INFO: Optimization: policy loss=0.054, vf loss=0.000, entropy loss=-0.036, total loss=0.018, num steps=5
2022-12-29 22:57:54.402 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 22:57:55.724 INFO: Evaluation rollout: return=0.708 (0.0), episode length=5.0
2022-12-29 22:57:55.725 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 22:57:55.727 INFO: Iteration: 70/137, steps: 15120
2022-12-29 22:58:37.092 DEBUG: There is a single atom floating around
2022-12-29 22:58:53.552 INFO: Training rollout: return=0.034 (3.3), episode length=4.9
2022-12-29 22:58:53.554 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 22:58:53.557 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-15120_train.pkl
2022-12-29 22:58:57.171 DEBUG: Taking gradient step
2022-12-29 22:58:57.181 DEBUG: Loss 0: {'policy_loss': 0.03488841474884761, 'entropy_loss': -0.0361415995284915, 'vf_loss': 0.007371918487970601, 'total_loss': 0.006118733708326711, 'approx_kl': -1.660858472973814e-08, 'clip_fraction': 0.0, 'grad_norm': 14.45016098022461}
2022-12-29 22:59:00.804 DEBUG: Taking gradient step
2022-12-29 22:59:00.811 DEBUG: Loss 1: {'policy_loss': 0.03145793655764182, 'entropy_loss': -0.03465767437592149, 'vf_loss': 0.007403378575495565, 'total_loss': 0.004203640757215903, 'approx_kl': 0.0051352885202504694, 'clip_fraction': 0.015625, 'grad_norm': 9.5130033493042}
2022-12-29 22:59:04.442 DEBUG: Taking gradient step
2022-12-29 22:59:04.451 DEBUG: Loss 2: {'policy_loss': -0.021453806498640794, 'entropy_loss': -0.037567450664937496, 'vf_loss': 0.004788970330589718, 'total_loss': -0.05423228683298857, 'approx_kl': 0.02696170483250171, 'clip_fraction': 0.109375, 'grad_norm': 2.630113363265991}
2022-12-29 22:59:07.952 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-29 22:59:07.952 INFO: Optimization: policy loss=-0.021, vf loss=0.005, entropy loss=-0.038, total loss=-0.054, num steps=3
2022-12-29 22:59:07.956 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 22:59:09.318 INFO: Evaluation rollout: return=0.609 (0.0), episode length=5.0
2022-12-29 22:59:09.319 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 22:59:09.322 DEBUG: Deleting old model: runs/CH4_int/models/CH4_int_run-1_steps-13176.model
2022-12-29 22:59:09.324 DEBUG: Saving model: runs/CH4_int/models/CH4_int_run-1_steps-15336.model
2022-12-29 22:59:09.346 INFO: Iteration: 71/137, steps: 15336
2022-12-29 23:00:06.376 INFO: Training rollout: return=0.542 (0.1), episode length=5.0
2022-12-29 23:00:06.378 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 23:00:06.381 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-15336_train.pkl
2022-12-29 23:00:09.626 DEBUG: Taking gradient step
2022-12-29 23:00:09.634 DEBUG: Loss 0: {'policy_loss': 0.0033981333771111646, 'entropy_loss': -0.03666902985423803, 'vf_loss': 9.665109644093765e-05, 'total_loss': -0.03317424538068593, 'approx_kl': -8.880548918455133e-08, 'clip_fraction': 0.0, 'grad_norm': 23.82427978515625}
2022-12-29 23:00:13.107 DEBUG: Taking gradient step
2022-12-29 23:00:13.114 DEBUG: Loss 1: {'policy_loss': -0.022911804453573187, 'entropy_loss': -0.03649646230041981, 'vf_loss': 9.665516793057846e-05, 'total_loss': -0.05931161158606242, 'approx_kl': 0.02809727704152465, 'clip_fraction': 0.12630208395421505, 'grad_norm': 8.175897598266602}
2022-12-29 23:00:16.379 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-29 23:00:16.380 INFO: Optimization: policy loss=-0.023, vf loss=0.000, entropy loss=-0.036, total loss=-0.059, num steps=2
2022-12-29 23:00:16.383 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 23:00:17.817 INFO: Evaluation rollout: return=0.637 (0.0), episode length=5.0
2022-12-29 23:00:17.818 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 23:00:17.823 INFO: Iteration: 72/137, steps: 15552
2022-12-29 23:01:15.316 INFO: Training rollout: return=0.531 (0.1), episode length=5.0
2022-12-29 23:01:15.319 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 23:01:15.321 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-15552_train.pkl
2022-12-29 23:01:18.708 DEBUG: Taking gradient step
2022-12-29 23:01:18.716 DEBUG: Loss 0: {'policy_loss': 0.05798097720565058, 'entropy_loss': -0.03846331313252449, 'vf_loss': 9.058424091156001e-05, 'total_loss': 0.019608248314037638, 'approx_kl': -2.8405338525772095e-08, 'clip_fraction': 0.0, 'grad_norm': 17.190567016601562}
2022-12-29 23:01:22.389 DEBUG: Taking gradient step
2022-12-29 23:01:22.397 DEBUG: Loss 1: {'policy_loss': -0.02948033113813181, 'entropy_loss': -0.03748266212642193, 'vf_loss': 9.486876713452142e-05, 'total_loss': -0.06686812449741922, 'approx_kl': 0.01772112539038062, 'clip_fraction': 0.046875, 'grad_norm': 14.353372573852539}
2022-12-29 23:01:25.866 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-29 23:01:25.867 INFO: Optimization: policy loss=-0.029, vf loss=0.000, entropy loss=-0.037, total loss=-0.067, num steps=2
2022-12-29 23:01:25.871 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 23:01:27.260 INFO: Evaluation rollout: return=0.612 (0.0), episode length=5.0
2022-12-29 23:01:27.261 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 23:01:27.264 INFO: Iteration: 73/137, steps: 15768
2022-12-29 23:02:24.362 INFO: Training rollout: return=0.547 (0.1), episode length=5.0
2022-12-29 23:02:24.365 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 23:02:24.367 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-15768_train.pkl
2022-12-29 23:02:27.615 DEBUG: Taking gradient step
2022-12-29 23:02:27.624 DEBUG: Loss 0: {'policy_loss': 0.014161730007501238, 'entropy_loss': -0.03824172355234623, 'vf_loss': 9.763029283511468e-05, 'total_loss': -0.023982363252009878, 'approx_kl': -2.9744114726781845e-08, 'clip_fraction': 0.0, 'grad_norm': 21.94864845275879}
2022-12-29 23:02:31.095 DEBUG: Taking gradient step
2022-12-29 23:02:31.103 DEBUG: Loss 1: {'policy_loss': -0.005087456603098072, 'entropy_loss': -0.036968535743653774, 'vf_loss': 9.33994754606139e-05, 'total_loss': -0.041962592871291234, 'approx_kl': 0.026817343605216593, 'clip_fraction': 0.2252604179084301, 'grad_norm': 18.135143280029297}
2022-12-29 23:02:34.491 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-29 23:02:34.492 INFO: Optimization: policy loss=-0.005, vf loss=0.000, entropy loss=-0.037, total loss=-0.042, num steps=2
2022-12-29 23:02:34.496 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 23:02:35.897 INFO: Evaluation rollout: return=0.613 (0.0), episode length=5.0
2022-12-29 23:02:35.899 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 23:02:35.901 INFO: Iteration: 74/137, steps: 15984
2022-12-29 23:03:33.276 INFO: Training rollout: return=0.555 (0.1), episode length=5.0
2022-12-29 23:03:33.278 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 23:03:33.280 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-15984_train.pkl
2022-12-29 23:03:36.771 DEBUG: Taking gradient step
2022-12-29 23:03:36.779 DEBUG: Loss 0: {'policy_loss': 0.023769913723488825, 'entropy_loss': -0.03852402791380882, 'vf_loss': 9.015007381089309e-05, 'total_loss': -0.014663964116509103, 'approx_kl': -9.584861571099168e-09, 'clip_fraction': 0.0, 'grad_norm': 17.62053871154785}
2022-12-29 23:03:40.033 DEBUG: Taking gradient step
2022-12-29 23:03:40.040 DEBUG: Loss 1: {'policy_loss': 0.0018164979359723277, 'entropy_loss': -0.03771959897130728, 'vf_loss': 8.562500484533313e-05, 'total_loss': -0.035817476030489626, 'approx_kl': 0.04051055002491921, 'clip_fraction': 0.18098958395421505, 'grad_norm': 12.606874465942383}
2022-12-29 23:03:43.441 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-29 23:03:43.442 INFO: Optimization: policy loss=0.002, vf loss=0.000, entropy loss=-0.038, total loss=-0.036, num steps=2
2022-12-29 23:03:43.446 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 23:03:44.904 INFO: Evaluation rollout: return=0.635 (0.0), episode length=5.0
2022-12-29 23:03:44.905 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 23:03:44.908 INFO: Iteration: 75/137, steps: 16200
2022-12-29 23:04:30.858 DEBUG: There is a single atom floating around
2022-12-29 23:04:42.199 INFO: Training rollout: return=0.029 (3.3), episode length=5.0
2022-12-29 23:04:42.202 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 23:04:42.204 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-16200_train.pkl
2022-12-29 23:04:45.692 DEBUG: Taking gradient step
2022-12-29 23:04:45.700 DEBUG: Loss 0: {'policy_loss': 0.023564632298848615, 'entropy_loss': -0.03931126371026039, 'vf_loss': 0.010657145040353571, 'total_loss': -0.005089486371058202, 'approx_kl': -3.370223566889763e-08, 'clip_fraction': 0.0, 'grad_norm': 34.09999084472656}
2022-12-29 23:04:49.154 DEBUG: Taking gradient step
2022-12-29 23:04:49.164 DEBUG: Loss 1: {'policy_loss': -0.037535754898244775, 'entropy_loss': -0.038246722891926765, 'vf_loss': 0.007948927970547057, 'total_loss': -0.06783354981962447, 'approx_kl': 0.0054913252824917436, 'clip_fraction': 0.1276041679084301, 'grad_norm': 6.734446048736572}
2022-12-29 23:04:52.456 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-29 23:04:52.457 INFO: Optimization: policy loss=-0.038, vf loss=0.008, entropy loss=-0.038, total loss=-0.068, num steps=2
2022-12-29 23:04:52.461 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 23:04:53.964 INFO: Evaluation rollout: return=0.640 (0.0), episode length=5.0
2022-12-29 23:04:53.965 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 23:04:53.968 INFO: Iteration: 76/137, steps: 16416
2022-12-29 23:05:37.978 DEBUG: There is a single atom floating around
2022-12-29 23:05:51.035 INFO: Training rollout: return=0.031 (3.3), episode length=5.0
2022-12-29 23:05:51.037 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 23:05:51.040 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-16416_train.pkl
2022-12-29 23:05:54.528 DEBUG: Taking gradient step
2022-12-29 23:05:54.535 DEBUG: Loss 0: {'policy_loss': -0.022822384194508633, 'entropy_loss': -0.037129106000065804, 'vf_loss': 0.006288823262765619, 'total_loss': -0.053662666931808815, 'approx_kl': 6.73268729656229e-09, 'clip_fraction': 0.0, 'grad_norm': 21.710317611694336}
2022-12-29 23:05:58.087 DEBUG: Taking gradient step
2022-12-29 23:05:58.098 DEBUG: Loss 1: {'policy_loss': 0.01828752456321501, 'entropy_loss': -0.03597120335325599, 'vf_loss': 0.00884507207272157, 'total_loss': -0.008838606717319411, 'approx_kl': 0.011030102265067399, 'clip_fraction': 0.14192708395421505, 'grad_norm': 4.9988789558410645}
2022-12-29 23:06:01.564 DEBUG: Taking gradient step
2022-12-29 23:06:01.572 DEBUG: Loss 2: {'policy_loss': 0.024314922328331476, 'entropy_loss': -0.03689075820147991, 'vf_loss': 0.008883482525258616, 'total_loss': -0.0036923533478898166, 'approx_kl': 0.03864715155214071, 'clip_fraction': 0.2578125, 'grad_norm': 10.759980201721191}
2022-12-29 23:06:04.940 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-29 23:06:04.941 INFO: Optimization: policy loss=0.024, vf loss=0.009, entropy loss=-0.037, total loss=-0.004, num steps=3
2022-12-29 23:06:04.946 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 23:06:06.304 INFO: Evaluation rollout: return=0.649 (0.0), episode length=5.0
2022-12-29 23:06:06.305 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 23:06:06.307 INFO: Iteration: 77/137, steps: 16632
2022-12-29 23:06:37.237 DEBUG: Atoms are too close
2022-12-29 23:07:02.889 INFO: Training rollout: return=0.034 (3.3), episode length=5.0
2022-12-29 23:07:02.893 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 23:07:02.896 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-16632_train.pkl
2022-12-29 23:07:06.183 DEBUG: Taking gradient step
2022-12-29 23:07:06.191 DEBUG: Loss 0: {'policy_loss': -0.026543673601732473, 'entropy_loss': -0.03698933217674494, 'vf_loss': 0.007920202967856534, 'total_loss': -0.05561280281062088, 'approx_kl': 1.5444432399647212e-08, 'clip_fraction': 0.0, 'grad_norm': 14.710391998291016}
2022-12-29 23:07:09.833 DEBUG: Taking gradient step
2022-12-29 23:07:09.840 DEBUG: Loss 1: {'policy_loss': 0.089435786206124, 'entropy_loss': -0.03789251670241356, 'vf_loss': 0.015691048747980576, 'total_loss': 0.06723431825169102, 'approx_kl': 0.0025198941584676504, 'clip_fraction': 0.2395833358168602, 'grad_norm': 21.219226837158203}
2022-12-29 23:07:13.222 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-29 23:07:13.223 INFO: Optimization: policy loss=0.089, vf loss=0.016, entropy loss=-0.038, total loss=0.067, num steps=2
2022-12-29 23:07:13.227 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 23:07:14.543 INFO: Evaluation rollout: return=0.751 (0.0), episode length=5.0
2022-12-29 23:07:14.543 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 23:07:14.546 INFO: Iteration: 78/137, steps: 16848
2022-12-29 23:07:27.209 DEBUG: Atoms are too close
2022-12-29 23:07:29.144 DEBUG: Atoms are too close
2022-12-29 23:08:00.374 DEBUG: There is a single atom floating around
2022-12-29 23:08:00.375 DEBUG: There is a single atom floating around
2022-12-29 23:08:10.485 INFO: Training rollout: return=-1.652 (6.3), episode length=5.0
2022-12-29 23:08:10.487 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 23:08:10.489 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-16848_train.pkl
2022-12-29 23:08:13.763 DEBUG: Taking gradient step
2022-12-29 23:08:13.771 DEBUG: Loss 0: {'policy_loss': -0.003802314919495258, 'entropy_loss': -0.0396830877289176, 'vf_loss': 0.036185436382594395, 'total_loss': -0.007299966265818459, 'approx_kl': 2.2080104855604077e-08, 'clip_fraction': 0.0, 'grad_norm': 13.08938217163086}
2022-12-29 23:08:17.173 DEBUG: Taking gradient step
2022-12-29 23:08:17.180 DEBUG: Loss 1: {'policy_loss': -0.033730153721301656, 'entropy_loss': -0.03760195150971413, 'vf_loss': 0.03350507851263591, 'total_loss': -0.03782702671837987, 'approx_kl': 0.002520620357245207, 'clip_fraction': 0.08203125, 'grad_norm': 14.415416717529297}
2022-12-29 23:08:20.673 DEBUG: Taking gradient step
2022-12-29 23:08:20.681 DEBUG: Loss 2: {'policy_loss': -0.04602387090916877, 'entropy_loss': -0.03845101408660412, 'vf_loss': 0.03340840594549523, 'total_loss': -0.05106647905027765, 'approx_kl': 0.010773697518743575, 'clip_fraction': 0.2486979216337204, 'grad_norm': 10.556411743164062}
2022-12-29 23:08:24.469 DEBUG: Taking gradient step
2022-12-29 23:08:24.476 DEBUG: Loss 3: {'policy_loss': 0.04221586466742944, 'entropy_loss': -0.03759722039103508, 'vf_loss': 0.04346124244500364, 'total_loss': 0.048079886721398, 'approx_kl': 0.009597640950232744, 'clip_fraction': 0.2591145858168602, 'grad_norm': 6.970787525177002}
2022-12-29 23:08:27.926 DEBUG: Taking gradient step
2022-12-29 23:08:27.933 DEBUG: Loss 4: {'policy_loss': 0.030553642182868816, 'entropy_loss': -0.038132062181830406, 'vf_loss': 0.04323323715497539, 'total_loss': 0.03565481715601379, 'approx_kl': 0.03961268067359924, 'clip_fraction': 0.3046875, 'grad_norm': 3.115354537963867}
2022-12-29 23:08:31.246 DEBUG: Early stopping at step 5 for reaching max KL.
2022-12-29 23:08:31.246 INFO: Optimization: policy loss=0.031, vf loss=0.043, entropy loss=-0.038, total loss=0.036, num steps=5
2022-12-29 23:08:31.251 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 23:08:32.681 INFO: Evaluation rollout: return=0.743 (0.0), episode length=5.0
2022-12-29 23:08:32.682 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 23:08:32.685 INFO: Iteration: 79/137, steps: 17064
2022-12-29 23:08:46.994 DEBUG: There is a single atom floating around
2022-12-29 23:09:30.461 INFO: Training rollout: return=0.026 (3.3), episode length=5.0
2022-12-29 23:09:30.463 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 23:09:30.466 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-17064_train.pkl
2022-12-29 23:09:33.862 DEBUG: Taking gradient step
2022-12-29 23:09:33.870 DEBUG: Loss 0: {'policy_loss': -0.024927192299301685, 'entropy_loss': -0.03716250974684954, 'vf_loss': 0.00776554385014151, 'total_loss': -0.05432415819600971, 'approx_kl': -3.725290298461914e-08, 'clip_fraction': 0.0, 'grad_norm': 8.814519882202148}
2022-12-29 23:09:37.437 DEBUG: Taking gradient step
2022-12-29 23:09:37.445 DEBUG: Loss 1: {'policy_loss': -0.0361356283302349, 'entropy_loss': -0.03879567235708237, 'vf_loss': 0.007786576696223711, 'total_loss': -0.06714472399109356, 'approx_kl': 0.00925521831959486, 'clip_fraction': 0.1171875, 'grad_norm': 3.0399301052093506}
2022-12-29 23:09:40.800 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-29 23:09:40.800 INFO: Optimization: policy loss=-0.036, vf loss=0.008, entropy loss=-0.039, total loss=-0.067, num steps=2
2022-12-29 23:09:40.805 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 23:09:42.232 INFO: Evaluation rollout: return=0.747 (0.0), episode length=5.0
2022-12-29 23:09:42.233 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 23:09:42.236 INFO: Iteration: 80/137, steps: 17280
2022-12-29 23:10:39.380 INFO: Training rollout: return=0.579 (0.1), episode length=5.0
2022-12-29 23:10:39.382 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 23:10:39.385 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-17280_train.pkl
2022-12-29 23:10:42.785 DEBUG: Taking gradient step
2022-12-29 23:10:42.792 DEBUG: Loss 0: {'policy_loss': -0.011041712030964216, 'entropy_loss': -0.03811259847134352, 'vf_loss': 0.0003430128262645178, 'total_loss': -0.04881129767604321, 'approx_kl': 8.06564166566659e-08, 'clip_fraction': 0.0, 'grad_norm': 12.453105926513672}
2022-12-29 23:10:46.103 DEBUG: Taking gradient step
2022-12-29 23:10:46.114 DEBUG: Loss 1: {'policy_loss': -0.027128546692370692, 'entropy_loss': -0.03743440564721823, 'vf_loss': 0.00039915322416957404, 'total_loss': -0.06416379911541933, 'approx_kl': -0.0010058096377179027, 'clip_fraction': 0.0546875, 'grad_norm': 8.661110877990723}
2022-12-29 23:10:49.653 DEBUG: Taking gradient step
2022-12-29 23:10:49.660 DEBUG: Loss 2: {'policy_loss': 0.014172768275531544, 'entropy_loss': -0.036194100975990295, 'vf_loss': 0.00043426500301914226, 'total_loss': -0.021587067697439614, 'approx_kl': 0.0009387035388499498, 'clip_fraction': 0.1861979179084301, 'grad_norm': 10.777103424072266}
2022-12-29 23:10:52.965 DEBUG: Taking gradient step
2022-12-29 23:10:52.973 DEBUG: Loss 3: {'policy_loss': -0.012499390522626773, 'entropy_loss': -0.03652864973992109, 'vf_loss': 0.0004790652771010964, 'total_loss': -0.04854897498544677, 'approx_kl': 0.009142064955085516, 'clip_fraction': 0.2591145858168602, 'grad_norm': 10.542134284973145}
2022-12-29 23:10:56.384 DEBUG: Taking gradient step
2022-12-29 23:10:56.392 DEBUG: Loss 4: {'policy_loss': -0.02224200131991045, 'entropy_loss': -0.0366749232634902, 'vf_loss': 0.0005142935500204296, 'total_loss': -0.05840263103338022, 'approx_kl': 0.014946014620363712, 'clip_fraction': 0.3111979216337204, 'grad_norm': 7.125174045562744}
2022-12-29 23:10:59.745 DEBUG: Taking gradient step
2022-12-29 23:10:59.753 DEBUG: Loss 5: {'policy_loss': -0.03983876346936975, 'entropy_loss': -0.036597687751054764, 'vf_loss': 0.0005478754384136622, 'total_loss': -0.07588857578201086, 'approx_kl': 0.013596639735624194, 'clip_fraction': 0.3046875, 'grad_norm': 8.497719764709473}
2022-12-29 23:11:03.543 DEBUG: Taking gradient step
2022-12-29 23:11:03.551 DEBUG: Loss 6: {'policy_loss': -0.06491866800176177, 'entropy_loss': -0.03679246734827757, 'vf_loss': 0.0005546436632696342, 'total_loss': -0.10115649168676973, 'approx_kl': 0.014087719027884305, 'clip_fraction': 0.328125, 'grad_norm': 6.109272003173828}
2022-12-29 23:11:06.976 DEBUG: Taking gradient step
2022-12-29 23:11:06.984 DEBUG: Loss 7: {'policy_loss': 0.02488566682291292, 'entropy_loss': -0.035483008716255426, 'vf_loss': 0.0005022457890985066, 'total_loss': -0.010095096104244, 'approx_kl': 0.023150996770709753, 'clip_fraction': 0.34375, 'grad_norm': 10.628087997436523}
2022-12-29 23:11:10.331 DEBUG: Taking gradient step
2022-12-29 23:11:10.340 DEBUG: Loss 8: {'policy_loss': -0.043112960932938496, 'entropy_loss': -0.036665418185293674, 'vf_loss': 0.0005132118652817404, 'total_loss': -0.07926516725295044, 'approx_kl': 0.011377764865756035, 'clip_fraction': 0.3671875, 'grad_norm': 10.873068809509277}
2022-12-29 23:11:13.867 DEBUG: Taking gradient step
2022-12-29 23:11:13.873 DEBUG: Loss 9: {'policy_loss': -0.01990903585036955, 'entropy_loss': -0.03735312633216381, 'vf_loss': 0.0004870455996460545, 'total_loss': -0.0567751165828873, 'approx_kl': 0.0049524977803230286, 'clip_fraction': 0.3697916716337204, 'grad_norm': 7.499626636505127}
2022-12-29 23:11:13.874 INFO: Optimization: policy loss=-0.020, vf loss=0.000, entropy loss=-0.037, total loss=-0.057, num steps=10
2022-12-29 23:11:13.878 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 23:11:15.302 INFO: Evaluation rollout: return=0.749 (0.0), episode length=5.0
2022-12-29 23:11:15.303 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 23:11:15.306 DEBUG: Deleting old model: runs/CH4_int/models/CH4_int_run-1_steps-15336.model
2022-12-29 23:11:15.311 DEBUG: Saving model: runs/CH4_int/models/CH4_int_run-1_steps-17496.model
2022-12-29 23:11:15.334 INFO: Iteration: 81/137, steps: 17496
2022-12-29 23:11:45.945 DEBUG: There is a single atom floating around
2022-12-29 23:11:46.504 DEBUG: Atoms are too close
2022-12-29 23:12:11.695 INFO: Training rollout: return=-0.508 (4.6), episode length=5.0
2022-12-29 23:12:11.698 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 23:12:11.700 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-17496_train.pkl
2022-12-29 23:12:14.957 DEBUG: Taking gradient step
2022-12-29 23:12:14.965 DEBUG: Loss 0: {'policy_loss': -0.030845487281088026, 'entropy_loss': -0.03706251736730337, 'vf_loss': 0.015108889615313703, 'total_loss': -0.052799115033077694, 'approx_kl': 1.6899624200039653e-08, 'clip_fraction': 0.0, 'grad_norm': 9.78468132019043}
2022-12-29 23:12:18.219 DEBUG: Taking gradient step
2022-12-29 23:12:18.227 DEBUG: Loss 1: {'policy_loss': -0.017336364999035223, 'entropy_loss': -0.03701883368194103, 'vf_loss': 0.017643252589446067, 'total_loss': -0.03671194609153019, 'approx_kl': -0.0027220367919653654, 'clip_fraction': 0.12239583395421505, 'grad_norm': 6.53228235244751}
2022-12-29 23:12:21.579 DEBUG: Taking gradient step
2022-12-29 23:12:21.587 DEBUG: Loss 2: {'policy_loss': 0.009137941209306204, 'entropy_loss': -0.036125976126641035, 'vf_loss': 0.0198995939665179, 'total_loss': -0.007088440950816927, 'approx_kl': 0.019418480340391397, 'clip_fraction': 0.28515625, 'grad_norm': 4.381323337554932}
2022-12-29 23:12:24.944 DEBUG: Taking gradient step
2022-12-29 23:12:24.955 DEBUG: Loss 3: {'policy_loss': -0.016226773023837127, 'entropy_loss': -0.036384823732078075, 'vf_loss': 0.01758402959597846, 'total_loss': -0.035027567159936754, 'approx_kl': 0.03758555743843317, 'clip_fraction': 0.3203125, 'grad_norm': 3.731494426727295}
2022-12-29 23:12:28.565 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-29 23:12:28.566 INFO: Optimization: policy loss=-0.016, vf loss=0.018, entropy loss=-0.036, total loss=-0.035, num steps=4
2022-12-29 23:12:28.571 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 23:12:29.964 INFO: Evaluation rollout: return=0.754 (0.0), episode length=5.0
2022-12-29 23:12:29.965 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 23:12:29.968 INFO: Iteration: 82/137, steps: 17712
2022-12-29 23:13:27.216 INFO: Training rollout: return=0.585 (0.1), episode length=5.0
2022-12-29 23:13:27.218 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 23:13:27.221 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-17712_train.pkl
2022-12-29 23:13:30.765 DEBUG: Taking gradient step
2022-12-29 23:13:30.773 DEBUG: Loss 0: {'policy_loss': 0.013839299000926914, 'entropy_loss': -0.03735519107431173, 'vf_loss': 0.0004414980175724128, 'total_loss': -0.023074394055812415, 'approx_kl': -2.8463546186685562e-08, 'clip_fraction': 0.0, 'grad_norm': 11.238678932189941}
2022-12-29 23:13:34.259 DEBUG: Taking gradient step
2022-12-29 23:13:34.266 DEBUG: Loss 1: {'policy_loss': -0.005545583121094877, 'entropy_loss': -0.03676794469356537, 'vf_loss': 0.00044565931045723386, 'total_loss': -0.04186786850420301, 'approx_kl': -0.007730797049589455, 'clip_fraction': 0.08854166697710752, 'grad_norm': 13.95982551574707}
2022-12-29 23:13:37.640 DEBUG: Taking gradient step
2022-12-29 23:13:37.647 DEBUG: Loss 2: {'policy_loss': -0.03703679301560058, 'entropy_loss': -0.03641678113490343, 'vf_loss': 0.0004472011204178271, 'total_loss': -0.07300637303008618, 'approx_kl': -0.014986566733568907, 'clip_fraction': 0.2057291716337204, 'grad_norm': 9.834009170532227}
2022-12-29 23:13:40.880 DEBUG: Taking gradient step
2022-12-29 23:13:40.887 DEBUG: Loss 3: {'policy_loss': -0.05202962880213962, 'entropy_loss': -0.0362485321238637, 'vf_loss': 0.000452067028417163, 'total_loss': -0.08782609389758615, 'approx_kl': -0.006544359959661961, 'clip_fraction': 0.328125, 'grad_norm': 14.850022315979004}
2022-12-29 23:13:44.283 DEBUG: Taking gradient step
2022-12-29 23:13:44.291 DEBUG: Loss 4: {'policy_loss': 0.04976827316084269, 'entropy_loss': -0.03455572482198477, 'vf_loss': 0.00042174260582147715, 'total_loss': 0.015634290944679406, 'approx_kl': 0.01350256396108307, 'clip_fraction': 0.3815104216337204, 'grad_norm': 24.080503463745117}
2022-12-29 23:13:47.584 DEBUG: Taking gradient step
2022-12-29 23:13:47.592 DEBUG: Loss 5: {'policy_loss': -0.004302621966059807, 'entropy_loss': -0.0351450452581048, 'vf_loss': 0.0004138023958052207, 'total_loss': -0.03903386482835939, 'approx_kl': 0.011282586958259344, 'clip_fraction': 0.3697916716337204, 'grad_norm': 14.188446044921875}
2022-12-29 23:13:50.812 DEBUG: Taking gradient step
2022-12-29 23:13:50.819 DEBUG: Loss 6: {'policy_loss': -0.012549403490983161, 'entropy_loss': -0.034361441154032946, 'vf_loss': 0.00039673875239116505, 'total_loss': -0.046514105892624946, 'approx_kl': 0.01961688231676817, 'clip_fraction': 0.36328125, 'grad_norm': 16.728755950927734}
2022-12-29 23:13:54.185 DEBUG: Taking gradient step
2022-12-29 23:13:54.193 DEBUG: Loss 7: {'policy_loss': 0.019456731791091482, 'entropy_loss': -0.03464013338088989, 'vf_loss': 0.0003804485125523594, 'total_loss': -0.014802953077246054, 'approx_kl': 0.027879139874130487, 'clip_fraction': 0.3619791716337204, 'grad_norm': 24.021039962768555}
2022-12-29 23:13:57.653 DEBUG: Taking gradient step
2022-12-29 23:13:57.661 DEBUG: Loss 8: {'policy_loss': 0.02529844876724773, 'entropy_loss': -0.032100864220410585, 'vf_loss': 0.00036314239069869584, 'total_loss': -0.006439273062464161, 'approx_kl': 0.04120644507929683, 'clip_fraction': 0.33984375, 'grad_norm': 18.278244018554688}
2022-12-29 23:14:01.119 DEBUG: Taking gradient step
2022-12-29 23:14:01.127 DEBUG: Loss 9: {'policy_loss': -0.026751049866974987, 'entropy_loss': -0.033970730379223824, 'vf_loss': 0.0003539027743853398, 'total_loss': -0.06036787747181348, 'approx_kl': 0.024774657795205712, 'clip_fraction': 0.2955729216337204, 'grad_norm': 9.572059631347656}
2022-12-29 23:14:01.127 INFO: Optimization: policy loss=-0.027, vf loss=0.000, entropy loss=-0.034, total loss=-0.060, num steps=10
2022-12-29 23:14:01.132 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 23:14:02.532 INFO: Evaluation rollout: return=0.754 (0.0), episode length=5.0
2022-12-29 23:14:02.533 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 23:14:02.535 INFO: Iteration: 83/137, steps: 17928
2022-12-29 23:14:59.696 INFO: Training rollout: return=0.608 (0.1), episode length=5.0
2022-12-29 23:14:59.699 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 23:14:59.702 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-17928_train.pkl
2022-12-29 23:15:03.234 DEBUG: Taking gradient step
2022-12-29 23:15:03.242 DEBUG: Loss 0: {'policy_loss': 0.039558880537430036, 'entropy_loss': -0.0331807597540319, 'vf_loss': 0.00034270872576878594, 'total_loss': 0.006720829509166935, 'approx_kl': 1.594889909029007e-08, 'clip_fraction': 0.0, 'grad_norm': 19.37869644165039}
2022-12-29 23:15:06.640 DEBUG: Taking gradient step
2022-12-29 23:15:06.647 DEBUG: Loss 1: {'policy_loss': 0.07440331408816284, 'entropy_loss': -0.034360687248408794, 'vf_loss': 0.00032239624644743486, 'total_loss': 0.04036502308620146, 'approx_kl': 0.007792997406795621, 'clip_fraction': 0.2174479179084301, 'grad_norm': 10.548121452331543}
2022-12-29 23:15:10.130 DEBUG: Taking gradient step
2022-12-29 23:15:10.141 DEBUG: Loss 2: {'policy_loss': -0.012113203185754482, 'entropy_loss': -0.03439471498131752, 'vf_loss': 0.00032216153662616343, 'total_loss': -0.046185756630445836, 'approx_kl': 0.010521417018026114, 'clip_fraction': 0.2838541679084301, 'grad_norm': 9.120007514953613}
2022-12-29 23:15:13.773 DEBUG: Taking gradient step
2022-12-29 23:15:13.780 DEBUG: Loss 3: {'policy_loss': -0.06355737161940125, 'entropy_loss': -0.03500933153554797, 'vf_loss': 0.0003138222797787549, 'total_loss': -0.09825288087517046, 'approx_kl': 0.0247643468901515, 'clip_fraction': 0.3424479216337204, 'grad_norm': 7.863090991973877}
2022-12-29 23:15:17.060 DEBUG: Taking gradient step
2022-12-29 23:15:17.067 DEBUG: Loss 4: {'policy_loss': 0.004967378958962383, 'entropy_loss': -0.0338909262791276, 'vf_loss': 0.0002794056373181156, 'total_loss': -0.028644141682847096, 'approx_kl': 0.014492533635348082, 'clip_fraction': 0.3359375, 'grad_norm': 7.470790386199951}
2022-12-29 23:15:20.434 DEBUG: Taking gradient step
2022-12-29 23:15:20.443 DEBUG: Loss 5: {'policy_loss': -0.05078437784754633, 'entropy_loss': -0.03452659584581852, 'vf_loss': 0.0002707858469205082, 'total_loss': -0.08504018784644435, 'approx_kl': 0.00544011895544827, 'clip_fraction': 0.2278645858168602, 'grad_norm': 4.177247524261475}
2022-12-29 23:15:23.693 DEBUG: Taking gradient step
2022-12-29 23:15:23.701 DEBUG: Loss 6: {'policy_loss': -0.0259803674535725, 'entropy_loss': -0.03371160803362727, 'vf_loss': 0.00024650273295193136, 'total_loss': -0.059445472754247844, 'approx_kl': 0.0015014318050816655, 'clip_fraction': 0.140625, 'grad_norm': 15.50287914276123}
2022-12-29 23:15:26.995 DEBUG: Taking gradient step
2022-12-29 23:15:27.003 DEBUG: Loss 7: {'policy_loss': -0.03528954466321812, 'entropy_loss': -0.03172805067151785, 'vf_loss': 0.00022934187839793158, 'total_loss': -0.06678825345633804, 'approx_kl': 0.004623834043741226, 'clip_fraction': 0.2447916716337204, 'grad_norm': 9.679903030395508}
2022-12-29 23:15:30.422 DEBUG: Taking gradient step
2022-12-29 23:15:30.429 DEBUG: Loss 8: {'policy_loss': 0.008536570954885393, 'entropy_loss': -0.03160292888060212, 'vf_loss': 0.00020711571261314616, 'total_loss': -0.02285924221310358, 'approx_kl': 0.012486301828175783, 'clip_fraction': 0.3359375, 'grad_norm': 4.093900680541992}
2022-12-29 23:15:33.707 DEBUG: Taking gradient step
2022-12-29 23:15:33.714 DEBUG: Loss 9: {'policy_loss': -0.05159622531763329, 'entropy_loss': -0.030865916050970554, 'vf_loss': 0.00019432585898760215, 'total_loss': -0.08226781550961625, 'approx_kl': -0.0009825544257182628, 'clip_fraction': 0.3684895858168602, 'grad_norm': 5.1425981521606445}
2022-12-29 23:15:33.714 INFO: Optimization: policy loss=-0.052, vf loss=0.000, entropy loss=-0.031, total loss=-0.082, num steps=10
2022-12-29 23:15:33.719 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 23:15:35.133 INFO: Evaluation rollout: return=0.758 (0.0), episode length=5.0
2022-12-29 23:15:35.134 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 23:15:35.137 INFO: Iteration: 84/137, steps: 18144
2022-12-29 23:15:50.906 DEBUG: There is a single atom floating around
2022-12-29 23:16:01.532 DEBUG: There is a single atom floating around
2022-12-29 23:16:31.689 INFO: Training rollout: return=-0.514 (4.6), episode length=5.0
2022-12-29 23:16:31.691 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 23:16:31.693 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-18144_train.pkl
2022-12-29 23:16:35.350 DEBUG: Taking gradient step
2022-12-29 23:16:35.358 DEBUG: Loss 0: {'policy_loss': 0.031090895574612656, 'entropy_loss': -0.031174448784440756, 'vf_loss': 0.019033161179089875, 'total_loss': 0.018949607969261775, 'approx_kl': -9.701278003149127e-09, 'clip_fraction': 0.0, 'grad_norm': 19.447101593017578}
2022-12-29 23:16:38.952 DEBUG: Taking gradient step
2022-12-29 23:16:38.960 DEBUG: Loss 1: {'policy_loss': -0.04028604008093092, 'entropy_loss': -0.03252456430345774, 'vf_loss': 0.013927231290804249, 'total_loss': -0.05888337309358439, 'approx_kl': -0.0016155221965163946, 'clip_fraction': 0.05078125, 'grad_norm': 4.309978008270264}
2022-12-29 23:16:42.231 DEBUG: Taking gradient step
2022-12-29 23:16:42.238 DEBUG: Loss 2: {'policy_loss': -0.008826473205385904, 'entropy_loss': -0.03226974280551076, 'vf_loss': 0.016499593222028187, 'total_loss': -0.024596622788868473, 'approx_kl': -0.0020775921875610948, 'clip_fraction': 0.1627604179084301, 'grad_norm': 8.498940467834473}
2022-12-29 23:16:45.890 DEBUG: Taking gradient step
2022-12-29 23:16:45.898 DEBUG: Loss 3: {'policy_loss': -0.020081919932187314, 'entropy_loss': -0.03307779459282756, 'vf_loss': 0.016511367745158104, 'total_loss': -0.03664834677985677, 'approx_kl': 0.008284145034849644, 'clip_fraction': 0.2981770858168602, 'grad_norm': 4.285617351531982}
2022-12-29 23:16:49.309 DEBUG: Taking gradient step
2022-12-29 23:16:49.317 DEBUG: Loss 4: {'policy_loss': -0.021946308083020054, 'entropy_loss': -0.032298983074724674, 'vf_loss': 0.016524090259966522, 'total_loss': -0.0377212008977782, 'approx_kl': 0.018863352364860475, 'clip_fraction': 0.3177083358168602, 'grad_norm': 4.33668851852417}
2022-12-29 23:16:52.668 DEBUG: Taking gradient step
2022-12-29 23:16:52.676 DEBUG: Loss 5: {'policy_loss': -0.0449703574067951, 'entropy_loss': -0.03419163404032588, 'vf_loss': 0.013940258130065414, 'total_loss': -0.06522173331705555, 'approx_kl': 0.04329798463732004, 'clip_fraction': 0.3020833358168602, 'grad_norm': 2.8192012310028076}
2022-12-29 23:16:56.041 DEBUG: Taking gradient step
2022-12-29 23:16:56.050 DEBUG: Loss 6: {'policy_loss': -0.0175134998077873, 'entropy_loss': -0.03337531629949808, 'vf_loss': 0.016474496404824575, 'total_loss': -0.034414319702460804, 'approx_kl': 0.022360040806233883, 'clip_fraction': 0.2786458358168602, 'grad_norm': 5.483223915100098}
2022-12-29 23:16:59.648 DEBUG: Taking gradient step
2022-12-29 23:16:59.659 DEBUG: Loss 7: {'policy_loss': -0.021934057500684605, 'entropy_loss': -0.03498654626309872, 'vf_loss': 0.016516189541163948, 'total_loss': -0.040404414222619374, 'approx_kl': 0.03953017620369792, 'clip_fraction': 0.3268229216337204, 'grad_norm': 1.6752723455429077}
2022-12-29 23:17:03.278 DEBUG: Taking gradient step
2022-12-29 23:17:03.286 DEBUG: Loss 8: {'policy_loss': -0.024471513095900718, 'entropy_loss': -0.03547327034175396, 'vf_loss': 0.016491793923958963, 'total_loss': -0.043452989513695715, 'approx_kl': 0.03782445122487843, 'clip_fraction': 0.2877604216337204, 'grad_norm': 2.115473508834839}
2022-12-29 23:17:06.701 DEBUG: Early stopping at step 9 for reaching max KL.
2022-12-29 23:17:06.702 INFO: Optimization: policy loss=-0.024, vf loss=0.016, entropy loss=-0.035, total loss=-0.043, num steps=9
2022-12-29 23:17:06.707 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 23:17:08.101 INFO: Evaluation rollout: return=0.768 (0.0), episode length=5.0
2022-12-29 23:17:08.102 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 23:17:08.104 INFO: Iteration: 85/137, steps: 18360
2022-12-29 23:17:39.025 DEBUG: Atoms are too close
2022-12-29 23:18:04.788 INFO: Training rollout: return=0.029 (3.3), episode length=5.0
2022-12-29 23:18:04.789 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 23:18:04.791 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-18360_train.pkl
2022-12-29 23:18:08.029 DEBUG: Taking gradient step
2022-12-29 23:18:08.036 DEBUG: Loss 0: {'policy_loss': 0.0218525214841527, 'entropy_loss': -0.03486650995910168, 'vf_loss': 0.010281734739182858, 'total_loss': -0.0027322537357661082, 'approx_kl': 7.52237028223135e-08, 'clip_fraction': 0.0, 'grad_norm': 33.550846099853516}
2022-12-29 23:18:11.254 DEBUG: Taking gradient step
2022-12-29 23:18:11.262 DEBUG: Loss 1: {'policy_loss': 0.08948552484311756, 'entropy_loss': -0.035050963051617146, 'vf_loss': 0.015284072214475388, 'total_loss': 0.06971863400597579, 'approx_kl': -0.011600170284509659, 'clip_fraction': 0.1770833358168602, 'grad_norm': 7.002561569213867}
2022-12-29 23:18:14.844 DEBUG: Taking gradient step
2022-12-29 23:18:14.851 DEBUG: Loss 2: {'policy_loss': 0.006410062610687713, 'entropy_loss': -0.0342112984508276, 'vf_loss': 0.01025905518754181, 'total_loss': -0.017542180652598067, 'approx_kl': 0.019231260754168034, 'clip_fraction': 0.28125, 'grad_norm': 2.3252766132354736}
2022-12-29 23:18:18.520 DEBUG: Taking gradient step
2022-12-29 23:18:18.531 DEBUG: Loss 3: {'policy_loss': -0.03714667905628962, 'entropy_loss': -0.0350479269400239, 'vf_loss': 0.0077536794644078606, 'total_loss': -0.06444092653190567, 'approx_kl': 0.02908161049708724, 'clip_fraction': 0.3971354216337204, 'grad_norm': 2.783994436264038}
2022-12-29 23:18:21.985 DEBUG: Taking gradient step
2022-12-29 23:18:21.993 DEBUG: Loss 4: {'policy_loss': -0.0376721429567862, 'entropy_loss': -0.03637267183512449, 'vf_loss': 0.007752531498653444, 'total_loss': -0.06629228329325725, 'approx_kl': 0.031233868096023798, 'clip_fraction': 0.4166666716337204, 'grad_norm': 2.614091634750366}
2022-12-29 23:18:25.331 DEBUG: Taking gradient step
2022-12-29 23:18:25.338 DEBUG: Loss 5: {'policy_loss': -0.000999413330081446, 'entropy_loss': -0.03755417373031378, 'vf_loss': 0.010260861384689308, 'total_loss': -0.028292725675705916, 'approx_kl': 0.007110083010047674, 'clip_fraction': 0.4166666716337204, 'grad_norm': 2.2932844161987305}
2022-12-29 23:18:28.804 DEBUG: Taking gradient step
2022-12-29 23:18:28.815 DEBUG: Loss 6: {'policy_loss': -0.04080540949817906, 'entropy_loss': -0.03768619056791067, 'vf_loss': 0.007750616599689208, 'total_loss': -0.07074098346640052, 'approx_kl': -0.004211094928905368, 'clip_fraction': 0.375, 'grad_norm': 4.057183265686035}
2022-12-29 23:18:32.608 DEBUG: Taking gradient step
2022-12-29 23:18:32.616 DEBUG: Loss 7: {'policy_loss': -0.004471796495701258, 'entropy_loss': -0.03910963889211416, 'vf_loss': 0.010245887156936796, 'total_loss': -0.033335548230878614, 'approx_kl': -0.007867186097428203, 'clip_fraction': 0.4401041716337204, 'grad_norm': 10.882793426513672}
2022-12-29 23:18:36.100 DEBUG: Taking gradient step
2022-12-29 23:18:36.107 DEBUG: Loss 8: {'policy_loss': -0.04288539683372147, 'entropy_loss': -0.039447128772735596, 'vf_loss': 0.007753957360494918, 'total_loss': -0.07457856824596215, 'approx_kl': 0.00631368812173605, 'clip_fraction': 0.4661458358168602, 'grad_norm': 1.3659696578979492}
2022-12-29 23:18:39.549 DEBUG: Taking gradient step
2022-12-29 23:18:39.556 DEBUG: Loss 9: {'policy_loss': -0.04259194093131327, 'entropy_loss': -0.040447624400258064, 'vf_loss': 0.007753890157836735, 'total_loss': -0.0752856751737346, 'approx_kl': 0.006557609420269728, 'clip_fraction': 0.4544270858168602, 'grad_norm': 6.335928440093994}
2022-12-29 23:18:39.556 INFO: Optimization: policy loss=-0.043, vf loss=0.008, entropy loss=-0.040, total loss=-0.075, num steps=10
2022-12-29 23:18:39.560 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 23:18:40.964 INFO: Evaluation rollout: return=0.753 (0.0), episode length=5.0
2022-12-29 23:18:40.966 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 23:18:40.968 INFO: Iteration: 86/137, steps: 18576
2022-12-29 23:19:37.953 INFO: Training rollout: return=0.567 (0.1), episode length=5.0
2022-12-29 23:19:37.956 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 23:19:37.958 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-18576_train.pkl
2022-12-29 23:19:41.536 DEBUG: Taking gradient step
2022-12-29 23:19:41.547 DEBUG: Loss 0: {'policy_loss': -0.0257900076731135, 'entropy_loss': -0.03955170139670372, 'vf_loss': 0.0003223528618649063, 'total_loss': -0.06501935620795231, 'approx_kl': -1.043081283569336e-07, 'clip_fraction': 0.0, 'grad_norm': 16.125913619995117}
2022-12-29 23:19:45.179 DEBUG: Taking gradient step
2022-12-29 23:19:45.186 DEBUG: Loss 1: {'policy_loss': -0.02613201442562311, 'entropy_loss': -0.03845985606312752, 'vf_loss': 0.00032259738000806954, 'total_loss': -0.06426927310874256, 'approx_kl': 0.010634818812832236, 'clip_fraction': 0.05989583395421505, 'grad_norm': 7.677018642425537}
2022-12-29 23:19:48.637 DEBUG: Taking gradient step
2022-12-29 23:19:48.645 DEBUG: Loss 2: {'policy_loss': -0.01579773208311755, 'entropy_loss': -0.040222182869911194, 'vf_loss': 0.00032128565032028177, 'total_loss': -0.05569862930270846, 'approx_kl': 0.02037528110668063, 'clip_fraction': 0.2161458358168602, 'grad_norm': 7.375842571258545}
2022-12-29 23:19:52.233 DEBUG: Taking gradient step
2022-12-29 23:19:52.244 DEBUG: Loss 3: {'policy_loss': -0.028154285479039993, 'entropy_loss': -0.03928832616657019, 'vf_loss': 0.0003134467788278904, 'total_loss': -0.06712916486678228, 'approx_kl': 0.006450478686019778, 'clip_fraction': 0.2682291679084301, 'grad_norm': 8.273940086364746}
2022-12-29 23:19:55.946 DEBUG: Taking gradient step
2022-12-29 23:19:55.954 DEBUG: Loss 4: {'policy_loss': 0.023108043152149177, 'entropy_loss': -0.037476660683751106, 'vf_loss': 0.0002968855927448005, 'total_loss': -0.014071731938857128, 'approx_kl': 0.01841807458549738, 'clip_fraction': 0.2643229179084301, 'grad_norm': 12.956558227539062}
2022-12-29 23:19:59.470 DEBUG: Taking gradient step
2022-12-29 23:19:59.478 DEBUG: Loss 5: {'policy_loss': -0.07239761098702843, 'entropy_loss': -0.036936813965439796, 'vf_loss': 0.0003003159911141301, 'total_loss': -0.10903410896135411, 'approx_kl': 0.028175669722259045, 'clip_fraction': 0.3619791716337204, 'grad_norm': 6.538666725158691}
2022-12-29 23:20:02.794 DEBUG: Taking gradient step
2022-12-29 23:20:02.802 DEBUG: Loss 6: {'policy_loss': -0.055647469776279754, 'entropy_loss': -0.03558323811739683, 'vf_loss': 0.00028322447467905143, 'total_loss': -0.09094748341899753, 'approx_kl': 0.029564999975264072, 'clip_fraction': 0.3385416679084301, 'grad_norm': 11.37402629852295}
2022-12-29 23:20:06.279 DEBUG: Early stopping at step 7 for reaching max KL.
2022-12-29 23:20:06.280 INFO: Optimization: policy loss=-0.056, vf loss=0.000, entropy loss=-0.036, total loss=-0.091, num steps=7
2022-12-29 23:20:06.285 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 23:20:07.715 INFO: Evaluation rollout: return=0.742 (0.0), episode length=5.0
2022-12-29 23:20:07.716 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 23:20:07.718 INFO: Iteration: 87/137, steps: 18792
2022-12-29 23:20:49.817 DEBUG: Atoms are too close
2022-12-29 23:20:52.048 DEBUG: Atoms are too close
2022-12-29 23:21:04.179 INFO: Training rollout: return=-0.511 (4.6), episode length=5.0
2022-12-29 23:21:04.182 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 23:21:04.185 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-18792_train.pkl
2022-12-29 23:21:07.510 DEBUG: Taking gradient step
2022-12-29 23:21:07.518 DEBUG: Loss 0: {'policy_loss': 0.0017435528518707864, 'entropy_loss': -0.03610656876116991, 'vf_loss': 0.016283619664255983, 'total_loss': -0.018079396245043147, 'approx_kl': 7.101334631443024e-08, 'clip_fraction': 0.0, 'grad_norm': 7.988851070404053}
2022-12-29 23:21:10.910 DEBUG: Taking gradient step
2022-12-29 23:21:10.917 DEBUG: Loss 1: {'policy_loss': 0.021622642659758974, 'entropy_loss': -0.034962103702127934, 'vf_loss': 0.018770767570543086, 'total_loss': 0.005431306528174133, 'approx_kl': -0.008657972910441458, 'clip_fraction': 0.037760416977107525, 'grad_norm': 8.683364868164062}
2022-12-29 23:21:14.218 DEBUG: Taking gradient step
2022-12-29 23:21:14.229 DEBUG: Loss 2: {'policy_loss': -0.010168868003997909, 'entropy_loss': -0.03374993009492755, 'vf_loss': 0.016277320836383315, 'total_loss': -0.027641477262542145, 'approx_kl': -0.013689122628420591, 'clip_fraction': 0.28125, 'grad_norm': 4.902990818023682}
2022-12-29 23:21:17.801 DEBUG: Taking gradient step
2022-12-29 23:21:17.808 DEBUG: Loss 3: {'policy_loss': 0.016034911169621968, 'entropy_loss': -0.03394790831953287, 'vf_loss': 0.01875704151641425, 'total_loss': 0.0008440443665033437, 'approx_kl': -0.016619295347481966, 'clip_fraction': 0.328125, 'grad_norm': 6.385010719299316}
2022-12-29 23:21:21.125 DEBUG: Taking gradient step
2022-12-29 23:21:21.132 DEBUG: Loss 4: {'policy_loss': 0.008888044971804225, 'entropy_loss': -0.0343422582373023, 'vf_loss': 0.01874538647769523, 'total_loss': -0.006708826787802838, 'approx_kl': -0.00023531937040388584, 'clip_fraction': 0.3098958358168602, 'grad_norm': 2.976393699645996}
2022-12-29 23:21:24.502 DEBUG: Taking gradient step
2022-12-29 23:21:24.510 DEBUG: Loss 5: {'policy_loss': -0.02036178156320686, 'entropy_loss': -0.033209309447556734, 'vf_loss': 0.016247546592946437, 'total_loss': -0.03732354441781715, 'approx_kl': -0.004104876425117254, 'clip_fraction': 0.3450520858168602, 'grad_norm': 2.5387229919433594}
2022-12-29 23:21:27.844 DEBUG: Taking gradient step
2022-12-29 23:21:27.851 DEBUG: Loss 6: {'policy_loss': 0.010939298259020805, 'entropy_loss': -0.03402610123157501, 'vf_loss': 0.018717338850300837, 'total_loss': -0.004369464122253371, 'approx_kl': 0.0003381287679076195, 'clip_fraction': 0.3268229216337204, 'grad_norm': 3.5299084186553955}
2022-12-29 23:21:31.133 DEBUG: Taking gradient step
2022-12-29 23:21:31.140 DEBUG: Loss 7: {'policy_loss': -0.055759655833322416, 'entropy_loss': -0.035727426409721375, 'vf_loss': 0.013744295781194417, 'total_loss': -0.07774278646184937, 'approx_kl': -0.018311863765120506, 'clip_fraction': 0.3971354216337204, 'grad_norm': 2.253856897354126}
2022-12-29 23:21:34.535 DEBUG: Taking gradient step
2022-12-29 23:21:34.545 DEBUG: Loss 8: {'policy_loss': -0.02832168833821977, 'entropy_loss': -0.037580838426947594, 'vf_loss': 0.016205011680189986, 'total_loss': -0.04969751508497738, 'approx_kl': 0.0018825015285983682, 'clip_fraction': 0.43359375, 'grad_norm': 6.627630710601807}
2022-12-29 23:21:37.981 DEBUG: Taking gradient step
2022-12-29 23:21:37.988 DEBUG: Loss 9: {'policy_loss': -0.054883100612261926, 'entropy_loss': -0.03762805834412575, 'vf_loss': 0.013732124203760607, 'total_loss': -0.07877903475262707, 'approx_kl': 0.01066460320726037, 'clip_fraction': 0.57421875, 'grad_norm': 5.19087553024292}
2022-12-29 23:21:37.989 INFO: Optimization: policy loss=-0.055, vf loss=0.014, entropy loss=-0.038, total loss=-0.079, num steps=10
2022-12-29 23:21:37.993 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 23:21:39.311 INFO: Evaluation rollout: return=0.737 (0.0), episode length=5.0
2022-12-29 23:21:39.312 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 23:21:39.314 INFO: Iteration: 88/137, steps: 19008
2022-12-29 23:22:26.648 DEBUG: Atoms are too close
2022-12-29 23:22:36.112 INFO: Training rollout: return=0.025 (3.3), episode length=5.0
2022-12-29 23:22:36.114 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 23:22:36.117 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-19008_train.pkl
2022-12-29 23:22:39.549 DEBUG: Taking gradient step
2022-12-29 23:22:39.556 DEBUG: Loss 0: {'policy_loss': -0.02509594533407559, 'entropy_loss': -0.0381481209769845, 'vf_loss': 0.007741475880647474, 'total_loss': -0.05550259043041262, 'approx_kl': -1.6104113598203185e-09, 'clip_fraction': 0.0, 'grad_norm': 10.951835632324219}
2022-12-29 23:22:42.827 DEBUG: Taking gradient step
2022-12-29 23:22:42.834 DEBUG: Loss 1: {'policy_loss': -0.03185632090554191, 'entropy_loss': -0.03860402386635542, 'vf_loss': 0.007733144619007954, 'total_loss': -0.06272720015288938, 'approx_kl': 0.017630686750635505, 'clip_fraction': 0.1276041679084301, 'grad_norm': 3.494307279586792}
2022-12-29 23:22:46.251 DEBUG: Taking gradient step
2022-12-29 23:22:46.259 DEBUG: Loss 2: {'policy_loss': 0.003895219302063272, 'entropy_loss': -0.038136716932058334, 'vf_loss': 0.010216173234713896, 'total_loss': -0.024025324395281166, 'approx_kl': 0.0394402383826673, 'clip_fraction': 0.3580729216337204, 'grad_norm': 3.800261974334717}
2022-12-29 23:22:49.578 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-29 23:22:49.578 INFO: Optimization: policy loss=0.004, vf loss=0.010, entropy loss=-0.038, total loss=-0.024, num steps=3
2022-12-29 23:22:49.582 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 23:22:50.966 INFO: Evaluation rollout: return=0.728 (0.0), episode length=5.0
2022-12-29 23:22:50.967 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 23:22:50.970 INFO: Iteration: 89/137, steps: 19224
2022-12-29 23:23:00.399 DEBUG: There is a single atom floating around
2022-12-29 23:23:46.085 DEBUG: There is a single atom floating around
2022-12-29 23:23:47.036 INFO: Training rollout: return=-0.531 (4.6), episode length=4.9
2022-12-29 23:23:47.038 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 23:23:47.041 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-19224_train.pkl
2022-12-29 23:23:50.655 DEBUG: Taking gradient step
2022-12-29 23:23:50.666 DEBUG: Loss 0: {'policy_loss': -0.03044829720618393, 'entropy_loss': -0.037594638764858246, 'vf_loss': 0.01089422206124378, 'total_loss': -0.0571487139097984, 'approx_kl': 3.011276383801942e-08, 'clip_fraction': 0.0, 'grad_norm': 17.558847427368164}
2022-12-29 23:23:54.190 DEBUG: Taking gradient step
2022-12-29 23:23:54.197 DEBUG: Loss 1: {'policy_loss': 0.07516978451029811, 'entropy_loss': -0.037464408203959465, 'vf_loss': 0.01843837350277189, 'total_loss': 0.05614374980911052, 'approx_kl': -0.00523168541258201, 'clip_fraction': 0.0234375, 'grad_norm': 25.496456146240234}
2022-12-29 23:23:57.700 DEBUG: Taking gradient step
2022-12-29 23:23:57.707 DEBUG: Loss 2: {'policy_loss': -0.036623376877801594, 'entropy_loss': -0.03838498890399933, 'vf_loss': 0.010877675135122446, 'total_loss': -0.06413069064667848, 'approx_kl': 0.008876248728483915, 'clip_fraction': 0.27734375, 'grad_norm': 5.15659236907959}
2022-12-29 23:24:01.204 DEBUG: Taking gradient step
2022-12-29 23:24:01.212 DEBUG: Loss 3: {'policy_loss': -0.00949699701919038, 'entropy_loss': -0.036770498380064964, 'vf_loss': 0.01336650094212901, 'total_loss': -0.03290099445712633, 'approx_kl': 0.007254672062117606, 'clip_fraction': 0.3385416716337204, 'grad_norm': 5.11007833480835}
2022-12-29 23:24:04.773 DEBUG: Taking gradient step
2022-12-29 23:24:04.780 DEBUG: Loss 4: {'policy_loss': -0.04263880675962334, 'entropy_loss': -0.036799199879169464, 'vf_loss': 0.010868554231973115, 'total_loss': -0.06856945240681969, 'approx_kl': 0.003659676411189139, 'clip_fraction': 0.3372395858168602, 'grad_norm': 4.595156192779541}
2022-12-29 23:24:08.029 DEBUG: Taking gradient step
2022-12-29 23:24:08.037 DEBUG: Loss 5: {'policy_loss': 0.022265534113379212, 'entropy_loss': -0.03650897787883878, 'vf_loss': 0.015794461538230446, 'total_loss': 0.0015510177727708907, 'approx_kl': 0.011502601555548608, 'clip_fraction': 0.30859375, 'grad_norm': 3.452260971069336}
2022-12-29 23:24:11.420 DEBUG: Taking gradient step
2022-12-29 23:24:11.431 DEBUG: Loss 6: {'policy_loss': -0.019647260816538573, 'entropy_loss': -0.03772416338324547, 'vf_loss': 0.013376813675434874, 'total_loss': -0.04399461052434917, 'approx_kl': 0.019141320139169693, 'clip_fraction': 0.2369791679084301, 'grad_norm': 4.4343156814575195}
2022-12-29 23:24:15.069 DEBUG: Taking gradient step
2022-12-29 23:24:15.077 DEBUG: Loss 7: {'policy_loss': -0.04079326114684471, 'entropy_loss': -0.038995920680463314, 'vf_loss': 0.010828978523686498, 'total_loss': -0.06896020330362153, 'approx_kl': 0.04444992262870073, 'clip_fraction': 0.3671875, 'grad_norm': 16.493358612060547}
2022-12-29 23:24:18.498 DEBUG: Early stopping at step 8 for reaching max KL.
2022-12-29 23:24:18.499 INFO: Optimization: policy loss=-0.041, vf loss=0.011, entropy loss=-0.039, total loss=-0.069, num steps=8
2022-12-29 23:24:18.503 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 23:24:19.886 INFO: Evaluation rollout: return=0.725 (0.0), episode length=5.0
2022-12-29 23:24:19.888 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 23:24:19.890 INFO: Iteration: 90/137, steps: 19440
2022-12-29 23:25:17.103 INFO: Training rollout: return=0.553 (0.1), episode length=5.0
2022-12-29 23:25:17.105 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 23:25:17.107 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-19440_train.pkl
2022-12-29 23:25:20.588 DEBUG: Taking gradient step
2022-12-29 23:25:20.597 DEBUG: Loss 0: {'policy_loss': 0.02516333046663488, 'entropy_loss': -0.03750817570835352, 'vf_loss': 0.0003349979159269804, 'total_loss': -0.012009847325791658, 'approx_kl': 4.3248292058706284e-08, 'clip_fraction': 0.0, 'grad_norm': 5.988159656524658}
2022-12-29 23:25:23.861 DEBUG: Taking gradient step
2022-12-29 23:25:23.869 DEBUG: Loss 1: {'policy_loss': -0.033345205278228936, 'entropy_loss': -0.03760269843041897, 'vf_loss': 0.00033511223287492587, 'total_loss': -0.07061279147577298, 'approx_kl': -0.004043669672682881, 'clip_fraction': 0.041666666977107525, 'grad_norm': 6.032311916351318}
2022-12-29 23:25:27.561 DEBUG: Taking gradient step
2022-12-29 23:25:27.569 DEBUG: Loss 2: {'policy_loss': 0.026058566315368965, 'entropy_loss': -0.03741405066102743, 'vf_loss': 0.00031544992264178414, 'total_loss': -0.011040034423016681, 'approx_kl': -0.001151297241449356, 'clip_fraction': 0.2135416716337204, 'grad_norm': 8.049161911010742}
2022-12-29 23:25:31.022 DEBUG: Taking gradient step
2022-12-29 23:25:31.030 DEBUG: Loss 3: {'policy_loss': 0.020069487681363192, 'entropy_loss': -0.03504845546558499, 'vf_loss': 0.0003146770698539366, 'total_loss': -0.01466429071436786, 'approx_kl': 0.011637773597612977, 'clip_fraction': 0.2877604179084301, 'grad_norm': 8.842909812927246}
2022-12-29 23:25:34.321 DEBUG: Taking gradient step
2022-12-29 23:25:34.329 DEBUG: Loss 4: {'policy_loss': -0.0458288385011988, 'entropy_loss': -0.03584228968247771, 'vf_loss': 0.00030741275445300226, 'total_loss': -0.08136371542922351, 'approx_kl': 0.022902597673237324, 'clip_fraction': 0.3463541716337204, 'grad_norm': 6.817276954650879}
2022-12-29 23:25:37.622 DEBUG: Early stopping at step 5 for reaching max KL.
2022-12-29 23:25:37.622 INFO: Optimization: policy loss=-0.046, vf loss=0.000, entropy loss=-0.036, total loss=-0.081, num steps=5
2022-12-29 23:25:37.626 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 23:25:39.016 INFO: Evaluation rollout: return=0.742 (0.0), episode length=5.0
2022-12-29 23:25:39.017 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 23:25:39.020 DEBUG: Deleting old model: runs/CH4_int/models/CH4_int_run-1_steps-17496.model
2022-12-29 23:25:39.024 DEBUG: Saving model: runs/CH4_int/models/CH4_int_run-1_steps-19656.model
2022-12-29 23:25:39.047 INFO: Iteration: 91/137, steps: 19656
2022-12-29 23:25:43.703 DEBUG: There is a single atom floating around
2022-12-29 23:25:58.985 DEBUG: There is a single atom floating around
2022-12-29 23:26:08.381 DEBUG: There is a single atom floating around
2022-12-29 23:26:09.230 DEBUG: There is a single atom floating around
2022-12-29 23:26:16.700 DEBUG: There is a single atom floating around
2022-12-29 23:26:34.013 INFO: Training rollout: return=-2.030 (6.8), episode length=4.7
2022-12-29 23:26:34.016 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 23:26:34.018 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-19656_train.pkl
2022-12-29 23:26:37.382 DEBUG: Taking gradient step
2022-12-29 23:26:37.390 DEBUG: Loss 0: {'policy_loss': -0.016703918423025148, 'entropy_loss': -0.03355870395898819, 'vf_loss': 0.0256698386949267, 'total_loss': -0.02459278368708663, 'approx_kl': 1.3737007975578308e-08, 'clip_fraction': 0.0, 'grad_norm': 17.11376190185547}
2022-12-29 23:26:40.775 DEBUG: Taking gradient step
2022-12-29 23:26:40.783 DEBUG: Loss 1: {'policy_loss': -0.015603964466087174, 'entropy_loss': -0.03264940343797207, 'vf_loss': 0.025678134616815392, 'total_loss': -0.022575233287243847, 'approx_kl': 0.015556946978904307, 'clip_fraction': 0.06770833395421505, 'grad_norm': 13.583152770996094}
2022-12-29 23:26:44.060 DEBUG: Taking gradient step
2022-12-29 23:26:44.068 DEBUG: Loss 2: {'policy_loss': 0.04277678677544499, 'entropy_loss': -0.030594439711421728, 'vf_loss': 0.03341415093467125, 'total_loss': 0.0455964979986945, 'approx_kl': 0.029346370021812618, 'clip_fraction': 0.2005208358168602, 'grad_norm': 15.202962875366211}
2022-12-29 23:26:47.513 DEBUG: Taking gradient step
2022-12-29 23:26:47.520 DEBUG: Loss 3: {'policy_loss': 0.02603635133779356, 'entropy_loss': -0.031342356000095606, 'vf_loss': 0.03065139671197278, 'total_loss': 0.025345392049670738, 'approx_kl': 0.03570222947746515, 'clip_fraction': 0.3346354216337204, 'grad_norm': 8.36197566986084}
2022-12-29 23:26:51.137 DEBUG: Taking gradient step
2022-12-29 23:26:51.145 DEBUG: Loss 4: {'policy_loss': -0.05768356535682967, 'entropy_loss': -0.030215999111533165, 'vf_loss': 0.02316174379368458, 'total_loss': -0.06473782067467826, 'approx_kl': 0.02308052871376276, 'clip_fraction': 0.3763020858168602, 'grad_norm': 5.479974269866943}
2022-12-29 23:26:54.702 DEBUG: Early stopping at step 5 for reaching max KL.
2022-12-29 23:26:54.703 INFO: Optimization: policy loss=-0.058, vf loss=0.023, entropy loss=-0.030, total loss=-0.065, num steps=5
2022-12-29 23:26:54.708 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 23:26:56.045 INFO: Evaluation rollout: return=0.734 (0.0), episode length=5.0
2022-12-29 23:26:56.046 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 23:26:56.048 INFO: Iteration: 92/137, steps: 19872
2022-12-29 23:27:11.023 DEBUG: There is a single atom floating around
2022-12-29 23:27:16.592 DEBUG: There is a single atom floating around
2022-12-29 23:27:30.052 DEBUG: There is a single atom floating around
2022-12-29 23:27:51.679 INFO: Training rollout: return=-1.008 (5.5), episode length=4.8
2022-12-29 23:27:51.681 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 23:27:51.684 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-19872_train.pkl
2022-12-29 23:27:55.257 DEBUG: Taking gradient step
2022-12-29 23:27:55.268 DEBUG: Loss 0: {'policy_loss': -2.511957753376671e-05, 'entropy_loss': -0.030033044051378965, 'vf_loss': 0.016571477032937224, 'total_loss': -0.013486686595975506, 'approx_kl': 6.897607818245888e-09, 'clip_fraction': 0.0, 'grad_norm': 14.143898010253906}
2022-12-29 23:27:58.619 DEBUG: Taking gradient step
2022-12-29 23:27:58.627 DEBUG: Loss 1: {'policy_loss': 0.032363847652805915, 'entropy_loss': -0.02893117628991604, 'vf_loss': 0.019033387243308962, 'total_loss': 0.022466058606198838, 'approx_kl': 0.006496049812994897, 'clip_fraction': 0.06901041697710752, 'grad_norm': 20.623075485229492}
2022-12-29 23:28:01.934 DEBUG: Taking gradient step
2022-12-29 23:28:01.941 DEBUG: Loss 2: {'policy_loss': -0.0372020841294577, 'entropy_loss': -0.028894266579300165, 'vf_loss': 0.013959410150770618, 'total_loss': -0.05213694055798724, 'approx_kl': 0.021362630068324506, 'clip_fraction': 0.1627604179084301, 'grad_norm': 13.636103630065918}
2022-12-29 23:28:05.557 DEBUG: Taking gradient step
2022-12-29 23:28:05.564 DEBUG: Loss 3: {'policy_loss': 0.004504791585366361, 'entropy_loss': -0.02914599608629942, 'vf_loss': 0.019098296540438667, 'total_loss': -0.005542907960494385, 'approx_kl': 0.03139359527267516, 'clip_fraction': 0.26171875, 'grad_norm': 4.7522077560424805}
2022-12-29 23:28:08.896 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-29 23:28:08.897 INFO: Optimization: policy loss=0.005, vf loss=0.019, entropy loss=-0.029, total loss=-0.006, num steps=4
2022-12-29 23:28:08.904 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 23:28:10.312 INFO: Evaluation rollout: return=0.742 (0.0), episode length=5.0
2022-12-29 23:28:10.313 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 23:28:10.316 INFO: Iteration: 93/137, steps: 20088
2022-12-29 23:28:22.416 DEBUG: There is a single atom floating around
2022-12-29 23:28:41.565 DEBUG: There is a single atom floating around
2022-12-29 23:29:07.669 INFO: Training rollout: return=-0.515 (4.6), episode length=5.0
2022-12-29 23:29:07.673 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 23:29:07.677 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-20088_train.pkl
2022-12-29 23:29:11.293 DEBUG: Taking gradient step
2022-12-29 23:29:11.300 DEBUG: Loss 0: {'policy_loss': -0.0010038328904482887, 'entropy_loss': -0.02946476498618722, 'vf_loss': 0.016258248736605283, 'total_loss': -0.014210349140030228, 'approx_kl': -6.858802947817821e-08, 'clip_fraction': 0.0, 'grad_norm': 17.77146339416504}
2022-12-29 23:29:14.863 DEBUG: Taking gradient step
2022-12-29 23:29:14.870 DEBUG: Loss 1: {'policy_loss': 0.02216561392642369, 'entropy_loss': -0.02834525192156434, 'vf_loss': 0.01881482207387438, 'total_loss': 0.012635184078733732, 'approx_kl': 0.014569502556696534, 'clip_fraction': 0.2473958358168602, 'grad_norm': 9.781984329223633}
2022-12-29 23:29:18.135 DEBUG: Taking gradient step
2022-12-29 23:29:18.142 DEBUG: Loss 2: {'policy_loss': 0.06773273278506095, 'entropy_loss': -0.028519497253000736, 'vf_loss': 0.02112492396170843, 'total_loss': 0.06033815949376864, 'approx_kl': 0.03880404506344348, 'clip_fraction': 0.359375, 'grad_norm': 11.091196060180664}
2022-12-29 23:29:21.354 DEBUG: Taking gradient step
2022-12-29 23:29:21.362 DEBUG: Loss 3: {'policy_loss': -0.03266112007459464, 'entropy_loss': -0.029149667359888554, 'vf_loss': 0.013764391563117291, 'total_loss': -0.04804639587136591, 'approx_kl': 0.04078653221949935, 'clip_fraction': 0.3424479216337204, 'grad_norm': 9.20806884765625}
2022-12-29 23:29:24.900 DEBUG: Taking gradient step
2022-12-29 23:29:24.908 DEBUG: Loss 4: {'policy_loss': -0.044628736273021, 'entropy_loss': -0.028691269923001528, 'vf_loss': 0.01376809556036062, 'total_loss': -0.0595519106356619, 'approx_kl': 0.019815334118902683, 'clip_fraction': 0.2526041679084301, 'grad_norm': 8.71583366394043}
2022-12-29 23:29:28.256 DEBUG: Taking gradient step
2022-12-29 23:29:28.264 DEBUG: Loss 5: {'policy_loss': -0.04930652965707245, 'entropy_loss': -0.029120939783751965, 'vf_loss': 0.013761373207284204, 'total_loss': -0.06466609623354021, 'approx_kl': 0.017475999891757965, 'clip_fraction': 0.2864583358168602, 'grad_norm': 5.480321407318115}
2022-12-29 23:29:31.543 DEBUG: Taking gradient step
2022-12-29 23:29:31.550 DEBUG: Loss 6: {'policy_loss': 0.012626686478707398, 'entropy_loss': -0.03088002884760499, 'vf_loss': 0.018684739936646443, 'total_loss': 0.0004313975677488549, 'approx_kl': 0.03991016652435064, 'clip_fraction': 0.4283854216337204, 'grad_norm': 3.908134698867798}
2022-12-29 23:29:34.954 DEBUG: Early stopping at step 7 for reaching max KL.
2022-12-29 23:29:34.954 INFO: Optimization: policy loss=0.013, vf loss=0.019, entropy loss=-0.031, total loss=0.000, num steps=7
2022-12-29 23:29:34.958 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 23:29:36.295 INFO: Evaluation rollout: return=0.739 (0.0), episode length=5.0
2022-12-29 23:29:36.295 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 23:29:36.299 INFO: Iteration: 94/137, steps: 20304
2022-12-29 23:30:33.717 INFO: Training rollout: return=0.603 (0.1), episode length=5.0
2022-12-29 23:30:33.720 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 23:30:33.722 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-20304_train.pkl
2022-12-29 23:30:37.289 DEBUG: Taking gradient step
2022-12-29 23:30:37.296 DEBUG: Loss 0: {'policy_loss': 0.0030585306393175332, 'entropy_loss': -0.03126129321753979, 'vf_loss': 0.00046946176887813066, 'total_loss': -0.027733300809344122, 'approx_kl': 2.2099506225004006e-08, 'clip_fraction': 0.0, 'grad_norm': 9.018905639648438}
2022-12-29 23:30:40.668 DEBUG: Taking gradient step
2022-12-29 23:30:40.676 DEBUG: Loss 1: {'policy_loss': -0.04907942273963341, 'entropy_loss': -0.030607761349529028, 'vf_loss': 0.0004968842854231144, 'total_loss': -0.07919029980373932, 'approx_kl': 0.009943896904587746, 'clip_fraction': 0.05989583395421505, 'grad_norm': 9.072047233581543}
2022-12-29 23:30:44.266 DEBUG: Taking gradient step
2022-12-29 23:30:44.274 DEBUG: Loss 2: {'policy_loss': -0.02635600257353881, 'entropy_loss': -0.030891066417098045, 'vf_loss': 0.0004958469918042607, 'total_loss': -0.05675122199883259, 'approx_kl': 0.02312065102159977, 'clip_fraction': 0.125, 'grad_norm': 8.570444107055664}
2022-12-29 23:30:47.546 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-29 23:30:47.546 INFO: Optimization: policy loss=-0.026, vf loss=0.000, entropy loss=-0.031, total loss=-0.057, num steps=3
2022-12-29 23:30:47.550 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 23:30:48.900 INFO: Evaluation rollout: return=0.746 (0.0), episode length=5.0
2022-12-29 23:30:48.901 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 23:30:48.903 INFO: Iteration: 95/137, steps: 20520
2022-12-29 23:31:46.587 INFO: Training rollout: return=0.586 (0.1), episode length=5.0
2022-12-29 23:31:46.590 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 23:31:46.592 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-20520_train.pkl
2022-12-29 23:31:49.979 DEBUG: Taking gradient step
2022-12-29 23:31:49.987 DEBUG: Loss 0: {'policy_loss': -0.044492233820936464, 'entropy_loss': -0.029820952098816633, 'vf_loss': 0.00046458704235661206, 'total_loss': -0.07384859887739649, 'approx_kl': 3.90379391035367e-08, 'clip_fraction': 0.0, 'grad_norm': 9.80648422241211}
2022-12-29 23:31:53.366 DEBUG: Taking gradient step
2022-12-29 23:31:53.374 DEBUG: Loss 1: {'policy_loss': 0.016121801900179263, 'entropy_loss': -0.030585561878979206, 'vf_loss': 0.00044220293283829645, 'total_loss': -0.014021557045961638, 'approx_kl': 0.02133735967800021, 'clip_fraction': 0.09765625, 'grad_norm': 9.33304214477539}
2022-12-29 23:31:56.798 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-29 23:31:56.798 INFO: Optimization: policy loss=0.016, vf loss=0.000, entropy loss=-0.031, total loss=-0.014, num steps=2
2022-12-29 23:31:56.803 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 23:31:58.217 INFO: Evaluation rollout: return=0.754 (0.0), episode length=5.0
2022-12-29 23:31:58.218 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 23:31:58.221 INFO: Iteration: 96/137, steps: 20736
2022-12-29 23:32:55.917 INFO: Training rollout: return=0.607 (0.1), episode length=5.0
2022-12-29 23:32:55.919 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 23:32:55.921 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-20736_train.pkl
2022-12-29 23:32:59.217 DEBUG: Taking gradient step
2022-12-29 23:32:59.224 DEBUG: Loss 0: {'policy_loss': 0.012795682752978826, 'entropy_loss': -0.03149086283519864, 'vf_loss': 0.0004592166568432884, 'total_loss': -0.018235963425376527, 'approx_kl': -1.3834020151648474e-08, 'clip_fraction': 0.0, 'grad_norm': 11.10840892791748}
2022-12-29 23:33:02.683 DEBUG: Taking gradient step
2022-12-29 23:33:02.691 DEBUG: Loss 1: {'policy_loss': 0.039891362368787216, 'entropy_loss': -0.03174052620306611, 'vf_loss': 0.00044354341974101865, 'total_loss': 0.008594379585462116, 'approx_kl': -0.008768384344875813, 'clip_fraction': 0.07942708395421505, 'grad_norm': 8.174473762512207}
2022-12-29 23:33:06.087 DEBUG: Taking gradient step
2022-12-29 23:33:06.095 DEBUG: Loss 2: {'policy_loss': -0.010652605433346132, 'entropy_loss': -0.03202719008550048, 'vf_loss': 0.00044043492797229944, 'total_loss': -0.04223936059087431, 'approx_kl': 0.02521322714164853, 'clip_fraction': 0.2734375, 'grad_norm': 8.947001457214355}
2022-12-29 23:33:09.405 DEBUG: Taking gradient step
2022-12-29 23:33:09.412 DEBUG: Loss 3: {'policy_loss': 0.022301128908208616, 'entropy_loss': -0.031871593091636896, 'vf_loss': 0.00041794599395934205, 'total_loss': -0.009152518189468939, 'approx_kl': 0.037331792525947094, 'clip_fraction': 0.3098958358168602, 'grad_norm': 8.951242446899414}
2022-12-29 23:33:12.802 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-29 23:33:12.802 INFO: Optimization: policy loss=0.022, vf loss=0.000, entropy loss=-0.032, total loss=-0.009, num steps=4
2022-12-29 23:33:12.807 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 23:33:14.194 INFO: Evaluation rollout: return=0.763 (0.0), episode length=5.0
2022-12-29 23:33:14.195 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 23:33:14.197 INFO: Iteration: 97/137, steps: 20952
2022-12-29 23:33:45.357 DEBUG: Atoms are too close
2022-12-29 23:34:12.253 INFO: Training rollout: return=0.030 (3.3), episode length=5.0
2022-12-29 23:34:12.255 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 23:34:12.257 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-20952_train.pkl
2022-12-29 23:34:15.541 DEBUG: Taking gradient step
2022-12-29 23:34:15.548 DEBUG: Loss 0: {'policy_loss': 0.06387336999120503, 'entropy_loss': -0.03267273074015975, 'vf_loss': 0.012688573278941576, 'total_loss': 0.04388921252998686, 'approx_kl': 4.113341489642153e-08, 'clip_fraction': 0.0, 'grad_norm': 31.115983963012695}
2022-12-29 23:34:18.930 DEBUG: Taking gradient step
2022-12-29 23:34:18.937 DEBUG: Loss 1: {'policy_loss': -0.04038899305435839, 'entropy_loss': -0.030709206126630306, 'vf_loss': 0.007785626874828234, 'total_loss': -0.06331257230616046, 'approx_kl': 0.011968367267400026, 'clip_fraction': 0.07682291697710752, 'grad_norm': 13.593997955322266}
2022-12-29 23:34:22.434 DEBUG: Taking gradient step
2022-12-29 23:34:22.444 DEBUG: Loss 2: {'policy_loss': -0.03525361590733112, 'entropy_loss': -0.03182775713503361, 'vf_loss': 0.007760448920682504, 'total_loss': -0.059320924121682224, 'approx_kl': 0.031776900636032224, 'clip_fraction': 0.2513020858168602, 'grad_norm': 2.9113917350769043}
2022-12-29 23:34:25.910 DEBUG: Taking gradient step
2022-12-29 23:34:25.918 DEBUG: Loss 3: {'policy_loss': -0.03269058506058472, 'entropy_loss': -0.031743552070111036, 'vf_loss': 0.007747444685824046, 'total_loss': -0.05668669244487171, 'approx_kl': 0.03869553981348872, 'clip_fraction': 0.2473958358168602, 'grad_norm': 3.211747169494629}
2022-12-29 23:34:29.408 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-29 23:34:29.409 INFO: Optimization: policy loss=-0.033, vf loss=0.008, entropy loss=-0.032, total loss=-0.057, num steps=4
2022-12-29 23:34:29.413 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 23:34:30.756 INFO: Evaluation rollout: return=0.758 (0.0), episode length=5.0
2022-12-29 23:34:30.757 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 23:34:30.760 INFO: Iteration: 98/137, steps: 21168
2022-12-29 23:35:01.336 DEBUG: There is a single atom floating around
2022-12-29 23:35:28.431 INFO: Training rollout: return=0.023 (3.3), episode length=5.0
2022-12-29 23:35:28.433 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 23:35:28.436 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-21168_train.pkl
2022-12-29 23:35:32.019 DEBUG: Taking gradient step
2022-12-29 23:35:32.027 DEBUG: Loss 0: {'policy_loss': -0.024470898611568224, 'entropy_loss': -0.03145621297881007, 'vf_loss': 0.007766880169976897, 'total_loss': -0.0481602314204014, 'approx_kl': -1.932494342327118e-08, 'clip_fraction': 0.0, 'grad_norm': 15.462458610534668}
2022-12-29 23:35:35.630 DEBUG: Taking gradient step
2022-12-29 23:35:35.637 DEBUG: Loss 1: {'policy_loss': 0.004286055558494284, 'entropy_loss': -0.03221188299357891, 'vf_loss': 0.010220598253536686, 'total_loss': -0.01770522918154794, 'approx_kl': 0.010417447658255696, 'clip_fraction': 0.1471354179084301, 'grad_norm': 13.398846626281738}
2022-12-29 23:35:39.090 DEBUG: Taking gradient step
2022-12-29 23:35:39.098 DEBUG: Loss 2: {'policy_loss': -0.03892042328652579, 'entropy_loss': -0.03081249399110675, 'vf_loss': 0.00778144897195954, 'total_loss': -0.061951468305672996, 'approx_kl': 0.02575238374993205, 'clip_fraction': 0.2981770858168602, 'grad_norm': 4.774790287017822}
2022-12-29 23:35:42.381 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-29 23:35:42.382 INFO: Optimization: policy loss=-0.039, vf loss=0.008, entropy loss=-0.031, total loss=-0.062, num steps=3
2022-12-29 23:35:42.386 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 23:35:43.779 INFO: Evaluation rollout: return=0.751 (0.0), episode length=5.0
2022-12-29 23:35:43.780 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 23:35:43.783 INFO: Iteration: 99/137, steps: 21384
2022-12-29 23:35:54.152 DEBUG: There is a single atom floating around
2022-12-29 23:36:40.408 INFO: Training rollout: return=0.029 (3.3), episode length=5.0
2022-12-29 23:36:40.411 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 23:36:40.413 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-21384_train.pkl
2022-12-29 23:36:43.674 DEBUG: Taking gradient step
2022-12-29 23:36:43.682 DEBUG: Loss 0: {'policy_loss': -0.020048369887578812, 'entropy_loss': -0.031625306233763695, 'vf_loss': 0.006341318525582993, 'total_loss': -0.04533235759575952, 'approx_kl': -4.460647085036129e-08, 'clip_fraction': 0.0, 'grad_norm': 9.414295196533203}
2022-12-29 23:36:47.166 DEBUG: Taking gradient step
2022-12-29 23:36:47.174 DEBUG: Loss 1: {'policy_loss': -0.02627623997942531, 'entropy_loss': -0.030981186311692, 'vf_loss': 0.006340852954040577, 'total_loss': -0.050916573337076734, 'approx_kl': 0.0045883923303335905, 'clip_fraction': 0.1276041679084301, 'grad_norm': 3.6940183639526367}
2022-12-29 23:36:50.665 DEBUG: Taking gradient step
2022-12-29 23:36:50.675 DEBUG: Loss 2: {'policy_loss': -0.02735906398155677, 'entropy_loss': -0.03164281602948904, 'vf_loss': 0.006335441554158214, 'total_loss': -0.05266643845688759, 'approx_kl': 0.018991014221683145, 'clip_fraction': 0.28515625, 'grad_norm': 2.846726655960083}
2022-12-29 23:36:54.233 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-29 23:36:54.234 INFO: Optimization: policy loss=-0.027, vf loss=0.006, entropy loss=-0.032, total loss=-0.053, num steps=3
2022-12-29 23:36:54.237 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 23:36:55.596 INFO: Evaluation rollout: return=0.747 (0.0), episode length=5.0
2022-12-29 23:36:55.597 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 23:36:55.599 INFO: Iteration: 100/137, steps: 21600
2022-12-29 23:37:24.346 DEBUG: There is a single atom floating around
2022-12-29 23:37:52.845 INFO: Training rollout: return=0.041 (3.3), episode length=5.0
2022-12-29 23:37:52.846 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 23:37:52.848 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-21600_train.pkl
2022-12-29 23:37:56.500 DEBUG: Taking gradient step
2022-12-29 23:37:56.507 DEBUG: Loss 0: {'policy_loss': -0.024754478471898555, 'entropy_loss': -0.03255016542971134, 'vf_loss': 0.0077710773507493665, 'total_loss': -0.04953356655086053, 'approx_kl': -3.612755605786333e-08, 'clip_fraction': 0.0, 'grad_norm': 14.030524253845215}
2022-12-29 23:37:59.797 DEBUG: Taking gradient step
2022-12-29 23:37:59.804 DEBUG: Loss 1: {'policy_loss': -0.034353926446284176, 'entropy_loss': -0.031398600433021784, 'vf_loss': 0.007769205848432428, 'total_loss': -0.05798332103087353, 'approx_kl': -0.00015556288417428732, 'clip_fraction': 0.03515625, 'grad_norm': 6.269222736358643}
2022-12-29 23:38:03.196 DEBUG: Taking gradient step
2022-12-29 23:38:03.203 DEBUG: Loss 2: {'policy_loss': -0.03841449455885683, 'entropy_loss': -0.03212692588567734, 'vf_loss': 0.0077584042546956404, 'total_loss': -0.06278301618983853, 'approx_kl': 0.018743761349469423, 'clip_fraction': 0.2135416679084301, 'grad_norm': 2.676598310470581}
2022-12-29 23:38:06.798 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-29 23:38:06.798 INFO: Optimization: policy loss=-0.038, vf loss=0.008, entropy loss=-0.032, total loss=-0.063, num steps=3
2022-12-29 23:38:06.803 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 23:38:08.161 INFO: Evaluation rollout: return=0.711 (0.0), episode length=5.0
2022-12-29 23:38:08.162 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 23:38:08.164 DEBUG: Deleting old model: runs/CH4_int/models/CH4_int_run-1_steps-19656.model
2022-12-29 23:38:08.166 DEBUG: Saving model: runs/CH4_int/models/CH4_int_run-1_steps-21816.model
2022-12-29 23:38:08.188 INFO: Iteration: 101/137, steps: 21816
2022-12-29 23:38:35.767 DEBUG: Atoms are too close
2022-12-29 23:38:36.720 DEBUG: There is a single atom floating around
2022-12-29 23:39:04.855 INFO: Training rollout: return=-0.577 (4.6), episode length=5.0
2022-12-29 23:39:04.857 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 23:39:04.860 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-21816_train.pkl
2022-12-29 23:39:08.422 DEBUG: Taking gradient step
2022-12-29 23:39:08.429 DEBUG: Loss 0: {'policy_loss': -0.0307496296915512, 'entropy_loss': -0.03313256474211812, 'vf_loss': 0.013844759254415149, 'total_loss': -0.05003743517925417, 'approx_kl': -2.1614445344653177e-08, 'clip_fraction': 0.0, 'grad_norm': 14.784812927246094}
2022-12-29 23:39:11.875 DEBUG: Taking gradient step
2022-12-29 23:39:11.886 DEBUG: Loss 1: {'policy_loss': -0.04583600594904864, 'entropy_loss': -0.03268899954855442, 'vf_loss': 0.013861316630937362, 'total_loss': -0.0646636888666657, 'approx_kl': 0.009592885384336114, 'clip_fraction': 0.20833333395421505, 'grad_norm': 5.342525482177734}
2022-12-29 23:39:15.557 DEBUG: Taking gradient step
2022-12-29 23:39:15.565 DEBUG: Loss 2: {'policy_loss': -0.014910645260051146, 'entropy_loss': -0.03264035889878869, 'vf_loss': 0.01633767647909792, 'total_loss': -0.031213327679741915, 'approx_kl': 0.03264246229082346, 'clip_fraction': 0.3463541716337204, 'grad_norm': 6.557873725891113}
2022-12-29 23:39:18.919 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-29 23:39:18.920 INFO: Optimization: policy loss=-0.015, vf loss=0.016, entropy loss=-0.033, total loss=-0.031, num steps=3
2022-12-29 23:39:18.923 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 23:39:20.281 INFO: Evaluation rollout: return=0.685 (0.0), episode length=5.0
2022-12-29 23:39:20.282 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 23:39:20.284 INFO: Iteration: 102/137, steps: 22032
2022-12-29 23:39:57.994 DEBUG: Atoms are too close
2022-12-29 23:40:13.976 DEBUG: Atoms are too close
2022-12-29 23:40:17.253 INFO: Training rollout: return=-0.562 (4.6), episode length=4.9
2022-12-29 23:40:17.255 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 23:40:17.258 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-22032_train.pkl
2022-12-29 23:40:20.753 DEBUG: Taking gradient step
2022-12-29 23:40:20.761 DEBUG: Loss 0: {'policy_loss': 0.0033261502052322964, 'entropy_loss': -0.034690641798079014, 'vf_loss': 0.014695963861702075, 'total_loss': -0.016668527731144637, 'approx_kl': -1.8121985689845133e-08, 'clip_fraction': 0.0, 'grad_norm': 23.572460174560547}
2022-12-29 23:40:24.009 DEBUG: Taking gradient step
2022-12-29 23:40:24.017 DEBUG: Loss 1: {'policy_loss': -0.013369401005711164, 'entropy_loss': -0.03521315939724445, 'vf_loss': 0.0147924210489753, 'total_loss': -0.03379013935398033, 'approx_kl': 8.781549331615679e-05, 'clip_fraction': 0.01171875, 'grad_norm': 11.630349159240723}
2022-12-29 23:40:27.426 DEBUG: Taking gradient step
2022-12-29 23:40:27.433 DEBUG: Loss 2: {'policy_loss': -0.04590130831939201, 'entropy_loss': -0.035684327594935894, 'vf_loss': 0.012303303970707434, 'total_loss': -0.06928233194362046, 'approx_kl': 0.019219872541725636, 'clip_fraction': 0.2356770858168602, 'grad_norm': 3.6143078804016113}
2022-12-29 23:40:30.782 DEBUG: Taking gradient step
2022-12-29 23:40:30.789 DEBUG: Loss 3: {'policy_loss': -0.05008143046213518, 'entropy_loss': -0.035138812847435474, 'vf_loss': 0.012310282673057468, 'total_loss': -0.07290996063651319, 'approx_kl': 0.02741749701090157, 'clip_fraction': 0.3268229216337204, 'grad_norm': 3.0579495429992676}
2022-12-29 23:40:34.043 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-29 23:40:34.044 INFO: Optimization: policy loss=-0.050, vf loss=0.012, entropy loss=-0.035, total loss=-0.073, num steps=4
2022-12-29 23:40:34.048 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 23:40:35.417 INFO: Evaluation rollout: return=0.702 (0.0), episode length=5.0
2022-12-29 23:40:35.418 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 23:40:35.422 INFO: Iteration: 103/137, steps: 22248
2022-12-29 23:40:45.027 DEBUG: Atoms are too close
2022-12-29 23:41:32.393 INFO: Training rollout: return=-0.006 (3.3), episode length=5.0
2022-12-29 23:41:32.395 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 23:41:32.398 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-22248_train.pkl
2022-12-29 23:41:35.817 DEBUG: Taking gradient step
2022-12-29 23:41:35.825 DEBUG: Loss 0: {'policy_loss': -0.021744745138087693, 'entropy_loss': -0.036027874797582626, 'vf_loss': 0.006216341481765006, 'total_loss': -0.05155627845390531, 'approx_kl': 2.0372681319713593e-08, 'clip_fraction': 0.0, 'grad_norm': 13.626628875732422}
2022-12-29 23:41:39.067 DEBUG: Taking gradient step
2022-12-29 23:41:39.075 DEBUG: Loss 1: {'policy_loss': -0.028216393316185605, 'entropy_loss': -0.03452441608533263, 'vf_loss': 0.006217781824742342, 'total_loss': -0.05652302757677589, 'approx_kl': 0.0007520497892983258, 'clip_fraction': 0.00390625, 'grad_norm': 3.273888111114502}
2022-12-29 23:41:42.311 DEBUG: Taking gradient step
2022-12-29 23:41:42.318 DEBUG: Loss 2: {'policy_loss': -0.029191767222372902, 'entropy_loss': -0.034229975659400225, 'vf_loss': 0.006212028876747803, 'total_loss': -0.05720971400502532, 'approx_kl': -0.0019300945568829775, 'clip_fraction': 0.09895833395421505, 'grad_norm': 1.7003463506698608}
2022-12-29 23:41:45.649 DEBUG: Taking gradient step
2022-12-29 23:41:45.656 DEBUG: Loss 3: {'policy_loss': -0.03170589215725246, 'entropy_loss': -0.03494353871792555, 'vf_loss': 0.006221564311273176, 'total_loss': -0.060427866563904836, 'approx_kl': 0.01734675222542137, 'clip_fraction': 0.21484375, 'grad_norm': 2.217961549758911}
2022-12-29 23:41:49.151 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-29 23:41:49.152 INFO: Optimization: policy loss=-0.032, vf loss=0.006, entropy loss=-0.035, total loss=-0.060, num steps=4
2022-12-29 23:41:49.156 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 23:41:50.539 INFO: Evaluation rollout: return=0.678 (0.0), episode length=5.0
2022-12-29 23:41:50.540 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 23:41:50.543 INFO: Iteration: 104/137, steps: 22464
2022-12-29 23:42:47.998 INFO: Training rollout: return=0.531 (0.1), episode length=5.0
2022-12-29 23:42:48.000 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 23:42:48.003 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-22464_train.pkl
2022-12-29 23:42:51.236 DEBUG: Taking gradient step
2022-12-29 23:42:51.244 DEBUG: Loss 0: {'policy_loss': -0.022540342555749875, 'entropy_loss': -0.03425554744899273, 'vf_loss': 0.00024875448724782836, 'total_loss': -0.05654713551749477, 'approx_kl': 2.196369131013398e-08, 'clip_fraction': 0.0, 'grad_norm': 7.687215328216553}
2022-12-29 23:42:54.740 DEBUG: Taking gradient step
2022-12-29 23:42:54.750 DEBUG: Loss 1: {'policy_loss': 0.013714027181804887, 'entropy_loss': -0.03526997193694115, 'vf_loss': 0.00023916620526654453, 'total_loss': -0.02131677854986971, 'approx_kl': 0.009048988344147801, 'clip_fraction': 0.00390625, 'grad_norm': 13.21303653717041}
2022-12-29 23:42:58.328 DEBUG: Taking gradient step
2022-12-29 23:42:58.336 DEBUG: Loss 2: {'policy_loss': -0.013409947095665313, 'entropy_loss': -0.03656179644167423, 'vf_loss': 0.0002382322504205067, 'total_loss': -0.04973351128691903, 'approx_kl': 0.03376835631206632, 'clip_fraction': 0.16015625, 'grad_norm': 6.915903568267822}
2022-12-29 23:43:01.945 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-29 23:43:01.946 INFO: Optimization: policy loss=-0.013, vf loss=0.000, entropy loss=-0.037, total loss=-0.050, num steps=3
2022-12-29 23:43:01.951 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 23:43:03.351 INFO: Evaluation rollout: return=0.709 (0.0), episode length=5.0
2022-12-29 23:43:03.353 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 23:43:03.356 INFO: Iteration: 105/137, steps: 22680
2022-12-29 23:44:00.727 INFO: Training rollout: return=0.547 (0.1), episode length=5.0
2022-12-29 23:44:00.729 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 23:44:00.731 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-22680_train.pkl
2022-12-29 23:44:04.234 DEBUG: Taking gradient step
2022-12-29 23:44:04.246 DEBUG: Loss 0: {'policy_loss': -0.004065051173697977, 'entropy_loss': -0.0358953857794404, 'vf_loss': 0.0002273573714326833, 'total_loss': -0.039733079581705695, 'approx_kl': 5.995389074087143e-09, 'clip_fraction': 0.0, 'grad_norm': 16.935930252075195}
2022-12-29 23:44:07.617 DEBUG: Taking gradient step
2022-12-29 23:44:07.624 DEBUG: Loss 1: {'policy_loss': 0.03136284408685863, 'entropy_loss': -0.036695114336907864, 'vf_loss': 0.00021326443421937428, 'total_loss': -0.005119005815829858, 'approx_kl': 0.029170837020501494, 'clip_fraction': 0.1315104179084301, 'grad_norm': 10.726880073547363}
2022-12-29 23:44:11.229 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-29 23:44:11.230 INFO: Optimization: policy loss=0.031, vf loss=0.000, entropy loss=-0.037, total loss=-0.005, num steps=2
2022-12-29 23:44:11.237 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 23:44:12.578 INFO: Evaluation rollout: return=0.740 (0.0), episode length=5.0
2022-12-29 23:44:12.579 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 23:44:12.582 INFO: Iteration: 106/137, steps: 22896
2022-12-29 23:44:24.780 DEBUG: Atoms are too close
2022-12-29 23:45:09.602 INFO: Training rollout: return=-0.017 (3.3), episode length=5.0
2022-12-29 23:45:09.605 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 23:45:09.607 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-22896_train.pkl
2022-12-29 23:45:12.965 DEBUG: Taking gradient step
2022-12-29 23:45:12.972 DEBUG: Loss 0: {'policy_loss': 0.07431514389146507, 'entropy_loss': -0.0349816745147109, 'vf_loss': 0.011329457675493922, 'total_loss': 0.05066292705224809, 'approx_kl': 8.84368418496706e-08, 'clip_fraction': 0.0, 'grad_norm': 30.420513153076172}
2022-12-29 23:45:16.344 DEBUG: Taking gradient step
2022-12-29 23:45:16.351 DEBUG: Loss 1: {'policy_loss': -0.024654543537569962, 'entropy_loss': -0.036423235200345516, 'vf_loss': 0.0062629047691881885, 'total_loss': -0.054814873968727286, 'approx_kl': -0.004882374836597592, 'clip_fraction': 0.1393229179084301, 'grad_norm': 6.361599445343018}
2022-12-29 23:45:19.855 DEBUG: Taking gradient step
2022-12-29 23:45:19.865 DEBUG: Loss 2: {'policy_loss': 0.03195812800356029, 'entropy_loss': -0.03530731052160263, 'vf_loss': 0.008785849733784629, 'total_loss': 0.005436667215742284, 'approx_kl': 0.00808294105809182, 'clip_fraction': 0.20442708395421505, 'grad_norm': 9.828814506530762}
2022-12-29 23:45:23.330 DEBUG: Taking gradient step
2022-12-29 23:45:23.338 DEBUG: Loss 3: {'policy_loss': 0.02303294334034196, 'entropy_loss': -0.03506674990057945, 'vf_loss': 0.008771307172741886, 'total_loss': -0.003262499387495614, 'approx_kl': 0.022002791985869408, 'clip_fraction': 0.2942708358168602, 'grad_norm': 4.887566566467285}
2022-12-29 23:45:26.764 DEBUG: Taking gradient step
2022-12-29 23:45:26.772 DEBUG: Loss 4: {'policy_loss': -0.02457629787301868, 'entropy_loss': -0.03591345902532339, 'vf_loss': 0.0062563597851055565, 'total_loss': -0.05423339711323652, 'approx_kl': 0.03488190798088908, 'clip_fraction': 0.2994791716337204, 'grad_norm': 4.326478958129883}
2022-12-29 23:45:30.185 DEBUG: Taking gradient step
2022-12-29 23:45:30.192 DEBUG: Loss 5: {'policy_loss': -0.030583155328432924, 'entropy_loss': -0.035349336452782154, 'vf_loss': 0.006254911148075031, 'total_loss': -0.05967758063314005, 'approx_kl': 0.007358224131166935, 'clip_fraction': 0.2591145858168602, 'grad_norm': 3.1389408111572266}
2022-12-29 23:45:33.760 DEBUG: Taking gradient step
2022-12-29 23:45:33.768 DEBUG: Loss 6: {'policy_loss': -0.028506042008955006, 'entropy_loss': -0.03496352909132838, 'vf_loss': 0.006263105468180576, 'total_loss': -0.05720646563210281, 'approx_kl': 0.027890009805560112, 'clip_fraction': 0.3177083358168602, 'grad_norm': 10.337778091430664}
2022-12-29 23:45:37.242 DEBUG: Early stopping at step 7 for reaching max KL.
2022-12-29 23:45:37.243 INFO: Optimization: policy loss=-0.029, vf loss=0.006, entropy loss=-0.035, total loss=-0.057, num steps=7
2022-12-29 23:45:37.247 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 23:45:38.615 INFO: Evaluation rollout: return=0.733 (0.0), episode length=5.0
2022-12-29 23:45:38.616 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 23:45:38.618 INFO: Iteration: 107/137, steps: 23112
2022-12-29 23:46:14.726 DEBUG: There is a single atom floating around
2022-12-29 23:46:35.048 INFO: Training rollout: return=0.006 (3.3), episode length=4.9
2022-12-29 23:46:35.050 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 23:46:35.053 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-23112_train.pkl
2022-12-29 23:46:38.558 DEBUG: Taking gradient step
2022-12-29 23:46:38.566 DEBUG: Loss 0: {'policy_loss': -0.01135855360262995, 'entropy_loss': -0.03646217565983534, 'vf_loss': 0.0033324860143299816, 'total_loss': -0.044488243248135315, 'approx_kl': 1.7384689243726825e-08, 'clip_fraction': 0.0, 'grad_norm': 3.381284713745117}
2022-12-29 23:46:41.880 DEBUG: Taking gradient step
2022-12-29 23:46:41.888 DEBUG: Loss 1: {'policy_loss': -0.025944719514430746, 'entropy_loss': -0.03467559861019254, 'vf_loss': 0.0033392313530699134, 'total_loss': -0.05728108677155337, 'approx_kl': 0.008071746386121958, 'clip_fraction': 0.01953125, 'grad_norm': 1.4533568620681763}
2022-12-29 23:46:45.328 DEBUG: Taking gradient step
2022-12-29 23:46:45.336 DEBUG: Loss 2: {'policy_loss': 0.0386208024254361, 'entropy_loss': -0.03537354851141572, 'vf_loss': 0.005940687681116389, 'total_loss': 0.009187941595136778, 'approx_kl': 0.028080848627723753, 'clip_fraction': 0.17708333395421505, 'grad_norm': 1.4164819717407227}
2022-12-29 23:46:48.741 DEBUG: Taking gradient step
2022-12-29 23:46:48.748 DEBUG: Loss 3: {'policy_loss': -0.02882070962895398, 'entropy_loss': -0.036940778605639935, 'vf_loss': 0.0033278085707753756, 'total_loss': -0.062433679663818534, 'approx_kl': 0.03247940819710493, 'clip_fraction': 0.2877604216337204, 'grad_norm': 1.7938860654830933}
2022-12-29 23:46:52.390 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-29 23:46:52.391 INFO: Optimization: policy loss=-0.029, vf loss=0.003, entropy loss=-0.037, total loss=-0.062, num steps=4
2022-12-29 23:46:52.394 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 23:46:53.804 INFO: Evaluation rollout: return=0.732 (0.0), episode length=5.0
2022-12-29 23:46:53.805 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 23:46:53.808 INFO: Iteration: 108/137, steps: 23328
2022-12-29 23:47:41.869 DEBUG: There is a single atom floating around
2022-12-29 23:47:50.754 INFO: Training rollout: return=-0.030 (3.3), episode length=5.0
2022-12-29 23:47:50.756 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 23:47:50.759 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-23328_train.pkl
2022-12-29 23:47:54.113 DEBUG: Taking gradient step
2022-12-29 23:47:54.121 DEBUG: Loss 0: {'policy_loss': -0.02595004621752746, 'entropy_loss': -0.03687737416476011, 'vf_loss': 0.007938034620279885, 'total_loss': -0.05488938576200769, 'approx_kl': 1.777273883618591e-08, 'clip_fraction': 0.0, 'grad_norm': 14.023472785949707}
2022-12-29 23:47:57.683 DEBUG: Taking gradient step
2022-12-29 23:47:57.690 DEBUG: Loss 1: {'policy_loss': -0.03641185284121607, 'entropy_loss': -0.03831000532954931, 'vf_loss': 0.007935256155918361, 'total_loss': -0.06678660201484703, 'approx_kl': -0.004339786828495562, 'clip_fraction': 0.04817708395421505, 'grad_norm': 7.060577392578125}
2022-12-29 23:48:01.056 DEBUG: Taking gradient step
2022-12-29 23:48:01.064 DEBUG: Loss 2: {'policy_loss': 0.0029878708843672566, 'entropy_loss': -0.03849218878895044, 'vf_loss': 0.010506373087293849, 'total_loss': -0.024997944817289338, 'approx_kl': 0.007129387464374304, 'clip_fraction': 0.1861979216337204, 'grad_norm': 5.138950347900391}
2022-12-29 23:48:04.670 DEBUG: Taking gradient step
2022-12-29 23:48:04.678 DEBUG: Loss 3: {'policy_loss': -0.04459707901766645, 'entropy_loss': -0.03760920558124781, 'vf_loss': 0.007944454130462547, 'total_loss': -0.07426183046845171, 'approx_kl': 0.018732979777269065, 'clip_fraction': 0.2838541716337204, 'grad_norm': 3.0063014030456543}
2022-12-29 23:48:08.364 DEBUG: Taking gradient step
2022-12-29 23:48:08.374 DEBUG: Loss 4: {'policy_loss': -0.04468596944627676, 'entropy_loss': -0.0380033515393734, 'vf_loss': 0.007940968424720142, 'total_loss': -0.07474835256093001, 'approx_kl': 0.01822727732360363, 'clip_fraction': 0.3098958358168602, 'grad_norm': 2.166714906692505}
2022-12-29 23:48:11.955 DEBUG: Taking gradient step
2022-12-29 23:48:11.968 DEBUG: Loss 5: {'policy_loss': -0.049760025196201936, 'entropy_loss': -0.037443031556904316, 'vf_loss': 0.007940755022694456, 'total_loss': -0.0792623017304118, 'approx_kl': 0.028247793670743704, 'clip_fraction': 0.3372395858168602, 'grad_norm': 1.5398105382919312}
2022-12-29 23:48:15.205 DEBUG: Taking gradient step
2022-12-29 23:48:15.212 DEBUG: Loss 6: {'policy_loss': -0.04542748381192014, 'entropy_loss': -0.03848583158105612, 'vf_loss': 0.007923590332595914, 'total_loss': -0.07598972506038035, 'approx_kl': 0.026002868078649044, 'clip_fraction': 0.2760416679084301, 'grad_norm': 1.2240681648254395}
2022-12-29 23:48:18.461 DEBUG: Early stopping at step 7 for reaching max KL.
2022-12-29 23:48:18.461 INFO: Optimization: policy loss=-0.045, vf loss=0.008, entropy loss=-0.038, total loss=-0.076, num steps=7
2022-12-29 23:48:18.465 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 23:48:19.794 INFO: Evaluation rollout: return=0.709 (0.0), episode length=5.0
2022-12-29 23:48:19.796 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 23:48:19.799 INFO: Iteration: 109/137, steps: 23544
2022-12-29 23:49:16.917 INFO: Training rollout: return=0.508 (0.1), episode length=5.0
2022-12-29 23:49:16.919 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 23:49:16.922 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-23544_train.pkl
2022-12-29 23:49:20.377 DEBUG: Taking gradient step
2022-12-29 23:49:20.385 DEBUG: Loss 0: {'policy_loss': 0.02219295691747506, 'entropy_loss': -0.039358627051115036, 'vf_loss': 0.0001336010499423543, 'total_loss': -0.017032069083697626, 'approx_kl': 7.81534872373868e-08, 'clip_fraction': 0.0, 'grad_norm': 7.659232139587402}
2022-12-29 23:49:23.771 DEBUG: Taking gradient step
2022-12-29 23:49:23.778 DEBUG: Loss 1: {'policy_loss': 0.027167800392344166, 'entropy_loss': -0.03961954731494188, 'vf_loss': 0.00013328589128190578, 'total_loss': -0.01231846103131581, 'approx_kl': -0.004890142008662224, 'clip_fraction': 0.1809895858168602, 'grad_norm': 26.434659957885742}
2022-12-29 23:49:26.992 DEBUG: Taking gradient step
2022-12-29 23:49:27.000 DEBUG: Loss 2: {'policy_loss': 0.03574313095800456, 'entropy_loss': -0.039245336316525936, 'vf_loss': 0.00013722565905317097, 'total_loss': -0.0033649796994682027, 'approx_kl': 0.00493982364423573, 'clip_fraction': 0.2591145858168602, 'grad_norm': 27.34819793701172}
2022-12-29 23:49:30.585 DEBUG: Taking gradient step
2022-12-29 23:49:30.592 DEBUG: Loss 3: {'policy_loss': 0.04047773354945796, 'entropy_loss': -0.03882525488734245, 'vf_loss': 0.00013421782673607555, 'total_loss': 0.0017866964888515746, 'approx_kl': 0.017337437951937318, 'clip_fraction': 0.296875, 'grad_norm': 24.369279861450195}
2022-12-29 23:49:34.066 DEBUG: Taking gradient step
2022-12-29 23:49:34.074 DEBUG: Loss 4: {'policy_loss': -0.036847947680696935, 'entropy_loss': -0.03711376618593931, 'vf_loss': 0.00014312593995448284, 'total_loss': -0.07381858792668175, 'approx_kl': 0.02197159011848271, 'clip_fraction': 0.2734375, 'grad_norm': 9.965331077575684}
2022-12-29 23:49:37.472 DEBUG: Taking gradient step
2022-12-29 23:49:37.479 DEBUG: Loss 5: {'policy_loss': 0.009095301575560835, 'entropy_loss': -0.037057275883853436, 'vf_loss': 0.00014148453569378167, 'total_loss': -0.02782048977259882, 'approx_kl': 0.03791104629635811, 'clip_fraction': 0.3359375, 'grad_norm': 13.40117073059082}
2022-12-29 23:49:40.860 DEBUG: Early stopping at step 6 for reaching max KL.
2022-12-29 23:49:40.861 INFO: Optimization: policy loss=0.009, vf loss=0.000, entropy loss=-0.037, total loss=-0.028, num steps=6
2022-12-29 23:49:40.865 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 23:49:42.256 INFO: Evaluation rollout: return=0.726 (0.0), episode length=5.0
2022-12-29 23:49:42.258 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 23:49:42.261 INFO: Iteration: 110/137, steps: 23760
2022-12-29 23:50:20.020 DEBUG: Atoms are too close
2022-12-29 23:50:39.459 INFO: Training rollout: return=-0.040 (3.3), episode length=4.9
2022-12-29 23:50:39.461 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 23:50:39.464 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-23760_train.pkl
2022-12-29 23:50:43.170 DEBUG: Taking gradient step
2022-12-29 23:50:43.178 DEBUG: Loss 0: {'policy_loss': -0.020238645766034232, 'entropy_loss': -0.03717398922890425, 'vf_loss': 0.004792765932098135, 'total_loss': -0.052619869062840344, 'approx_kl': -1.83936208486557e-08, 'clip_fraction': 0.0, 'grad_norm': 14.167450904846191}
2022-12-29 23:50:46.528 DEBUG: Taking gradient step
2022-12-29 23:50:46.535 DEBUG: Loss 1: {'policy_loss': 0.030006680787141173, 'entropy_loss': -0.03605523984879255, 'vf_loss': 0.007357856612599878, 'total_loss': 0.001309297550948496, 'approx_kl': 0.007091548352036625, 'clip_fraction': 0.09375, 'grad_norm': 1.6459306478500366}
2022-12-29 23:50:49.944 DEBUG: Taking gradient step
2022-12-29 23:50:49.951 DEBUG: Loss 2: {'policy_loss': 0.031045913754481385, 'entropy_loss': -0.03816401166841388, 'vf_loss': 0.007352560101068855, 'total_loss': 0.00023446218713635975, 'approx_kl': 0.003810796421021223, 'clip_fraction': 0.2278645858168602, 'grad_norm': 1.2976858615875244}
2022-12-29 23:50:53.315 DEBUG: Taking gradient step
2022-12-29 23:50:53.322 DEBUG: Loss 3: {'policy_loss': 0.013820730000873277, 'entropy_loss': -0.03677765931934118, 'vf_loss': 0.007387897876210337, 'total_loss': -0.015569031442257568, 'approx_kl': -0.0017767400713637471, 'clip_fraction': 0.2057291679084301, 'grad_norm': 1.167802333831787}
2022-12-29 23:50:56.974 DEBUG: Taking gradient step
2022-12-29 23:50:56.981 DEBUG: Loss 4: {'policy_loss': -0.029308645973432912, 'entropy_loss': -0.03792084380984306, 'vf_loss': 0.004790931290183236, 'total_loss': -0.06243855849309274, 'approx_kl': -0.01978929666802287, 'clip_fraction': 0.2044270858168602, 'grad_norm': 0.7185729146003723}
2022-12-29 23:51:00.357 DEBUG: Taking gradient step
2022-12-29 23:51:00.364 DEBUG: Loss 5: {'policy_loss': -0.027946662481222607, 'entropy_loss': -0.03846905846148729, 'vf_loss': 0.004784296673666438, 'total_loss': -0.06163142426904345, 'approx_kl': -0.017670817440375686, 'clip_fraction': 0.2747395858168602, 'grad_norm': 0.7750781178474426}
2022-12-29 23:51:03.639 DEBUG: Taking gradient step
2022-12-29 23:51:03.646 DEBUG: Loss 6: {'policy_loss': -0.01347854501936208, 'entropy_loss': -0.038304904475808144, 'vf_loss': 0.0047819118209532835, 'total_loss': -0.04700153767421694, 'approx_kl': -0.032890682108700275, 'clip_fraction': 0.2994791716337204, 'grad_norm': 17.416217803955078}
2022-12-29 23:51:06.866 DEBUG: Taking gradient step
2022-12-29 23:51:06.873 DEBUG: Loss 7: {'policy_loss': 0.054758078720408526, 'entropy_loss': -0.03859569039195776, 'vf_loss': 0.00738371479159826, 'total_loss': 0.023546103120049025, 'approx_kl': -0.02123410953208804, 'clip_fraction': 0.29296875, 'grad_norm': 45.00646209716797}
2022-12-29 23:51:10.101 DEBUG: Taking gradient step
2022-12-29 23:51:10.110 DEBUG: Loss 8: {'policy_loss': -0.025632373011074617, 'entropy_loss': -0.040274263359606266, 'vf_loss': 0.004773450033251957, 'total_loss': -0.061133186337428924, 'approx_kl': -0.012967819347977638, 'clip_fraction': 0.35546875, 'grad_norm': 11.904244422912598}
2022-12-29 23:51:13.817 DEBUG: Taking gradient step
2022-12-29 23:51:13.824 DEBUG: Loss 9: {'policy_loss': 0.020428413012502134, 'entropy_loss': -0.040109165012836456, 'vf_loss': 0.007380318276343438, 'total_loss': -0.012300433723990888, 'approx_kl': 0.02583910897374153, 'clip_fraction': 0.41015625, 'grad_norm': 1.1894679069519043}
2022-12-29 23:51:13.824 INFO: Optimization: policy loss=0.020, vf loss=0.007, entropy loss=-0.040, total loss=-0.012, num steps=10
2022-12-29 23:51:13.829 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 23:51:15.178 INFO: Evaluation rollout: return=0.745 (0.0), episode length=5.0
2022-12-29 23:51:15.178 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 23:51:15.181 DEBUG: Deleting old model: runs/CH4_int/models/CH4_int_run-1_steps-21816.model
2022-12-29 23:51:15.186 DEBUG: Saving model: runs/CH4_int/models/CH4_int_run-1_steps-23976.model
2022-12-29 23:51:15.208 INFO: Iteration: 111/137, steps: 23976
2022-12-29 23:52:11.619 INFO: Training rollout: return=0.548 (0.1), episode length=5.0
2022-12-29 23:52:11.621 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 23:52:11.624 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-23976_train.pkl
2022-12-29 23:52:15.043 DEBUG: Taking gradient step
2022-12-29 23:52:15.051 DEBUG: Loss 0: {'policy_loss': 0.00696464127264143, 'entropy_loss': -0.04043920710682869, 'vf_loss': 0.00015080553934045061, 'total_loss': -0.03332376029484681, 'approx_kl': 1.928613846402527e-08, 'clip_fraction': 0.0, 'grad_norm': 10.347819328308105}
2022-12-29 23:52:18.436 DEBUG: Taking gradient step
2022-12-29 23:52:18.444 DEBUG: Loss 1: {'policy_loss': -0.03069962882884588, 'entropy_loss': -0.039677406661212444, 'vf_loss': 0.00015369044612342783, 'total_loss': -0.0702233450439349, 'approx_kl': 0.010577379376627505, 'clip_fraction': 0.08333333395421505, 'grad_norm': 7.103199005126953}
2022-12-29 23:52:21.876 DEBUG: Taking gradient step
2022-12-29 23:52:21.883 DEBUG: Loss 2: {'policy_loss': -0.0333010276159945, 'entropy_loss': -0.03992314636707306, 'vf_loss': 0.0001528187800535117, 'total_loss': -0.07307135520301405, 'approx_kl': 0.02705572359263897, 'clip_fraction': 0.171875, 'grad_norm': 7.299768447875977}
2022-12-29 23:52:25.250 DEBUG: Taking gradient step
2022-12-29 23:52:25.261 DEBUG: Loss 3: {'policy_loss': 0.021035441130491786, 'entropy_loss': -0.04164142720401287, 'vf_loss': 0.0001419545645866512, 'total_loss': -0.020464031508934437, 'approx_kl': 0.04346920736134052, 'clip_fraction': 0.2174479179084301, 'grad_norm': 10.40340805053711}
2022-12-29 23:52:28.797 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-29 23:52:28.797 INFO: Optimization: policy loss=0.021, vf loss=0.000, entropy loss=-0.042, total loss=-0.020, num steps=4
2022-12-29 23:52:28.801 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 23:52:30.131 INFO: Evaluation rollout: return=0.758 (0.0), episode length=5.0
2022-12-29 23:52:30.132 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 23:52:30.135 INFO: Iteration: 112/137, steps: 24192
2022-12-29 23:53:26.941 INFO: Training rollout: return=0.560 (0.1), episode length=5.0
2022-12-29 23:53:26.944 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 23:53:26.946 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-24192_train.pkl
2022-12-29 23:53:30.443 DEBUG: Taking gradient step
2022-12-29 23:53:30.450 DEBUG: Loss 0: {'policy_loss': 0.0013637852228416784, 'entropy_loss': -0.04042530059814453, 'vf_loss': 0.0001612737332341477, 'total_loss': -0.0389002416420687, 'approx_kl': 5.506444722414017e-08, 'clip_fraction': 0.0, 'grad_norm': 16.38967514038086}
2022-12-29 23:53:33.945 DEBUG: Taking gradient step
2022-12-29 23:53:33.953 DEBUG: Loss 1: {'policy_loss': -0.07451359931471159, 'entropy_loss': -0.03838829416781664, 'vf_loss': 0.0001673315470402736, 'total_loss': -0.11273456193548795, 'approx_kl': 0.025445010047405958, 'clip_fraction': 0.08984375, 'grad_norm': 9.406149864196777}
2022-12-29 23:53:37.546 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-29 23:53:37.547 INFO: Optimization: policy loss=-0.075, vf loss=0.000, entropy loss=-0.038, total loss=-0.113, num steps=2
2022-12-29 23:53:37.551 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 23:53:38.981 INFO: Evaluation rollout: return=0.757 (0.0), episode length=5.0
2022-12-29 23:53:38.982 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 23:53:38.984 INFO: Iteration: 113/137, steps: 24408
2022-12-29 23:54:36.184 INFO: Training rollout: return=0.567 (0.1), episode length=5.0
2022-12-29 23:54:36.186 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 23:54:36.189 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-24408_train.pkl
2022-12-29 23:54:39.511 DEBUG: Taking gradient step
2022-12-29 23:54:39.519 DEBUG: Loss 0: {'policy_loss': -0.0375796712012671, 'entropy_loss': -0.03811086714267731, 'vf_loss': 0.0001578322542251059, 'total_loss': -0.07553270608971929, 'approx_kl': -3.3372392405084383e-08, 'clip_fraction': 0.0, 'grad_norm': 12.55812931060791}
2022-12-29 23:54:42.920 DEBUG: Taking gradient step
2022-12-29 23:54:42.927 DEBUG: Loss 1: {'policy_loss': -0.019927865510759236, 'entropy_loss': -0.039713405072689056, 'vf_loss': 0.00015472346061559217, 'total_loss': -0.0594865471228327, 'approx_kl': 0.031921950401738286, 'clip_fraction': 0.1263020858168602, 'grad_norm': 10.218351364135742}
2022-12-29 23:54:46.438 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-29 23:54:46.439 INFO: Optimization: policy loss=-0.020, vf loss=0.000, entropy loss=-0.040, total loss=-0.059, num steps=2
2022-12-29 23:54:46.444 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 23:54:47.829 INFO: Evaluation rollout: return=0.749 (0.0), episode length=5.0
2022-12-29 23:54:47.830 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 23:54:47.833 INFO: Iteration: 114/137, steps: 24624
2022-12-29 23:55:00.984 DEBUG: Atoms are too close
2022-12-29 23:55:44.223 INFO: Training rollout: return=-0.047 (3.3), episode length=5.0
2022-12-29 23:55:44.227 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 23:55:44.230 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-24624_train.pkl
2022-12-29 23:55:47.453 DEBUG: Taking gradient step
2022-12-29 23:55:47.463 DEBUG: Loss 0: {'policy_loss': -0.023107518630969777, 'entropy_loss': -0.03893663082271814, 'vf_loss': 0.007830624449393695, 'total_loss': -0.05421352500429422, 'approx_kl': 4.49751169639967e-08, 'clip_fraction': 0.0, 'grad_norm': 13.890922546386719}
2022-12-29 23:55:50.962 DEBUG: Taking gradient step
2022-12-29 23:55:50.969 DEBUG: Loss 1: {'policy_loss': 0.01681664012890488, 'entropy_loss': -0.03736970806494355, 'vf_loss': 0.010456230652993443, 'total_loss': -0.01009683728304523, 'approx_kl': 0.0015551972901448607, 'clip_fraction': 0.078125, 'grad_norm': 14.375816345214844}
2022-12-29 23:55:54.460 DEBUG: Taking gradient step
2022-12-29 23:55:54.467 DEBUG: Loss 2: {'policy_loss': 0.010411517348729901, 'entropy_loss': -0.03974682651460171, 'vf_loss': 0.010488604496068425, 'total_loss': -0.01884670466980338, 'approx_kl': 0.027574168401770294, 'clip_fraction': 0.25390625, 'grad_norm': 9.065691947937012}
2022-12-29 23:55:57.735 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-29 23:55:57.736 INFO: Optimization: policy loss=0.010, vf loss=0.010, entropy loss=-0.040, total loss=-0.019, num steps=3
2022-12-29 23:55:57.740 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 23:55:59.175 INFO: Evaluation rollout: return=0.766 (0.0), episode length=5.0
2022-12-29 23:55:59.177 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 23:55:59.179 INFO: Iteration: 115/137, steps: 24840
2022-12-29 23:56:58.844 INFO: Training rollout: return=0.530 (0.1), episode length=5.0
2022-12-29 23:56:58.846 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 23:56:58.848 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-24840_train.pkl
2022-12-29 23:57:02.173 DEBUG: Taking gradient step
2022-12-29 23:57:02.185 DEBUG: Loss 0: {'policy_loss': 0.024172639128534717, 'entropy_loss': -0.03902097325772047, 'vf_loss': 0.00013502705880295596, 'total_loss': -0.014713307070382799, 'approx_kl': 7.400134194313068e-08, 'clip_fraction': 0.0, 'grad_norm': 14.50858211517334}
2022-12-29 23:57:05.586 DEBUG: Taking gradient step
2022-12-29 23:57:05.594 DEBUG: Loss 1: {'policy_loss': -0.008438888675599204, 'entropy_loss': -0.038320887833833694, 'vf_loss': 0.00014106800951882426, 'total_loss': -0.04661870849991408, 'approx_kl': 0.027442267746664584, 'clip_fraction': 0.14192708395421505, 'grad_norm': 12.681320190429688}
2022-12-29 23:57:09.012 DEBUG: Taking gradient step
2022-12-29 23:57:09.020 DEBUG: Loss 2: {'policy_loss': -0.03217393236331911, 'entropy_loss': -0.03737080842256546, 'vf_loss': 0.00014409689375917596, 'total_loss': -0.0694006438921254, 'approx_kl': 0.04333028639666736, 'clip_fraction': 0.2330729179084301, 'grad_norm': 16.000858306884766}
2022-12-29 23:57:12.631 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-29 23:57:12.631 INFO: Optimization: policy loss=-0.032, vf loss=0.000, entropy loss=-0.037, total loss=-0.069, num steps=3
2022-12-29 23:57:12.635 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 23:57:14.070 INFO: Evaluation rollout: return=0.768 (0.0), episode length=5.0
2022-12-29 23:57:14.071 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 23:57:14.074 INFO: Iteration: 116/137, steps: 25056
2022-12-29 23:58:14.462 INFO: Training rollout: return=0.526 (0.1), episode length=5.0
2022-12-29 23:58:14.464 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 23:58:14.467 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-25056_train.pkl
2022-12-29 23:58:17.714 DEBUG: Taking gradient step
2022-12-29 23:58:17.721 DEBUG: Loss 0: {'policy_loss': 0.05476327412862074, 'entropy_loss': -0.037751696072518826, 'vf_loss': 0.00013197831413370596, 'total_loss': 0.017143556370235617, 'approx_kl': -2.403976395726204e-08, 'clip_fraction': 0.0, 'grad_norm': 15.635839462280273}
2022-12-29 23:58:21.139 DEBUG: Taking gradient step
2022-12-29 23:58:21.146 DEBUG: Loss 1: {'policy_loss': -0.03372528943001943, 'entropy_loss': -0.03569386247545481, 'vf_loss': 0.0001400063046474977, 'total_loss': -0.06927914560082674, 'approx_kl': 0.006786759244278073, 'clip_fraction': 0.05598958395421505, 'grad_norm': 12.803145408630371}
2022-12-29 23:58:24.685 DEBUG: Taking gradient step
2022-12-29 23:58:24.693 DEBUG: Loss 2: {'policy_loss': -0.008188344344693949, 'entropy_loss': -0.03582508722320199, 'vf_loss': 0.00013460786436863366, 'total_loss': -0.0438788237035273, 'approx_kl': 0.01812469377182424, 'clip_fraction': 0.12630208395421505, 'grad_norm': 13.009730339050293}
2022-12-29 23:58:28.027 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-29 23:58:28.027 INFO: Optimization: policy loss=-0.008, vf loss=0.000, entropy loss=-0.036, total loss=-0.044, num steps=3
2022-12-29 23:58:28.031 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 23:58:29.456 INFO: Evaluation rollout: return=0.761 (0.0), episode length=5.0
2022-12-29 23:58:29.457 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 23:58:29.460 INFO: Iteration: 117/137, steps: 25272
2022-12-29 23:59:27.294 INFO: Training rollout: return=0.544 (0.1), episode length=5.0
2022-12-29 23:59:27.296 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-29 23:59:27.299 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-25272_train.pkl
2022-12-29 23:59:30.622 DEBUG: Taking gradient step
2022-12-29 23:59:30.630 DEBUG: Loss 0: {'policy_loss': -0.002179020669738118, 'entropy_loss': -0.03439129237085581, 'vf_loss': 0.0001412477420056645, 'total_loss': -0.03642906529858826, 'approx_kl': 2.01786587439301e-09, 'clip_fraction': 0.0, 'grad_norm': 22.150205612182617}
2022-12-29 23:59:33.947 DEBUG: Taking gradient step
2022-12-29 23:59:33.953 DEBUG: Loss 1: {'policy_loss': -0.04202401273832619, 'entropy_loss': -0.03305196575820446, 'vf_loss': 0.00013925283191285325, 'total_loss': -0.07493672566461779, 'approx_kl': 0.025674034375697374, 'clip_fraction': 0.0390625, 'grad_norm': 11.960904121398926}
2022-12-29 23:59:37.550 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-29 23:59:37.551 INFO: Optimization: policy loss=-0.042, vf loss=0.000, entropy loss=-0.033, total loss=-0.075, num steps=2
2022-12-29 23:59:37.555 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-29 23:59:38.937 INFO: Evaluation rollout: return=0.753 (0.0), episode length=5.0
2022-12-29 23:59:38.938 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-29 23:59:38.941 INFO: Iteration: 118/137, steps: 25488
2022-12-30 00:00:35.031 INFO: Training rollout: return=0.577 (0.1), episode length=5.0
2022-12-30 00:00:35.034 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-30 00:00:35.037 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-25488_train.pkl
2022-12-30 00:00:38.308 DEBUG: Taking gradient step
2022-12-30 00:00:38.316 DEBUG: Loss 0: {'policy_loss': -0.025183773911937424, 'entropy_loss': -0.03230022266507149, 'vf_loss': 0.0001488969173257518, 'total_loss': -0.05733509965968316, 'approx_kl': -1.234002411365509e-08, 'clip_fraction': 0.0, 'grad_norm': 16.93260955810547}
2022-12-30 00:00:41.528 DEBUG: Taking gradient step
2022-12-30 00:00:41.535 DEBUG: Loss 1: {'policy_loss': 0.0017171263477640634, 'entropy_loss': -0.03258704161271453, 'vf_loss': 0.00014598902165251142, 'total_loss': -0.03072392624329796, 'approx_kl': 0.014624571544118226, 'clip_fraction': 0.045572916977107525, 'grad_norm': 15.802236557006836}
2022-12-30 00:00:45.110 DEBUG: Taking gradient step
2022-12-30 00:00:45.119 DEBUG: Loss 2: {'policy_loss': 0.014925716891360657, 'entropy_loss': -0.03180562797933817, 'vf_loss': 0.0001406606251312924, 'total_loss': -0.016739250462846217, 'approx_kl': 0.04123448580503464, 'clip_fraction': 0.1901041679084301, 'grad_norm': 11.507344245910645}
2022-12-30 00:00:48.340 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-30 00:00:48.340 INFO: Optimization: policy loss=0.015, vf loss=0.000, entropy loss=-0.032, total loss=-0.017, num steps=3
2022-12-30 00:00:48.347 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-30 00:00:49.740 INFO: Evaluation rollout: return=0.754 (0.0), episode length=5.0
2022-12-30 00:00:49.741 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-30 00:00:49.744 INFO: Iteration: 119/137, steps: 25704
2022-12-30 00:01:46.711 INFO: Training rollout: return=0.606 (0.1), episode length=5.0
2022-12-30 00:01:46.712 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-30 00:01:46.715 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-25704_train.pkl
2022-12-30 00:01:49.982 DEBUG: Taking gradient step
2022-12-30 00:01:49.989 DEBUG: Loss 0: {'policy_loss': -0.006669615248758696, 'entropy_loss': -0.02962517598643899, 'vf_loss': 0.00015634645786453152, 'total_loss': -0.036138444777333155, 'approx_kl': -2.6193447411060333e-10, 'clip_fraction': 0.0, 'grad_norm': 13.31820011138916}
2022-12-30 00:01:53.291 DEBUG: Taking gradient step
2022-12-30 00:01:53.298 DEBUG: Loss 1: {'policy_loss': -0.008557827149656798, 'entropy_loss': -0.02911913488060236, 'vf_loss': 0.00015165581447279284, 'total_loss': -0.03752530621578636, 'approx_kl': 0.031075550243258476, 'clip_fraction': 0.14453125, 'grad_norm': 13.959471702575684}
2022-12-30 00:01:56.518 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-30 00:01:56.518 INFO: Optimization: policy loss=-0.009, vf loss=0.000, entropy loss=-0.029, total loss=-0.038, num steps=2
2022-12-30 00:01:56.522 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-30 00:01:57.932 INFO: Evaluation rollout: return=0.761 (0.0), episode length=5.0
2022-12-30 00:01:57.934 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-30 00:01:57.937 INFO: Iteration: 120/137, steps: 25920
2022-12-30 00:02:55.389 INFO: Training rollout: return=0.623 (0.1), episode length=5.0
2022-12-30 00:02:55.391 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-30 00:02:55.394 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-25920_train.pkl
2022-12-30 00:02:58.926 DEBUG: Taking gradient step
2022-12-30 00:02:58.933 DEBUG: Loss 0: {'policy_loss': -0.010030342511945026, 'entropy_loss': -0.027674490585923195, 'vf_loss': 0.00016523567490356065, 'total_loss': -0.03753959742296466, 'approx_kl': -3.857227603987212e-08, 'clip_fraction': 0.0, 'grad_norm': 9.659415245056152}
2022-12-30 00:03:02.489 DEBUG: Taking gradient step
2022-12-30 00:03:02.500 DEBUG: Loss 1: {'policy_loss': 0.003689901354937554, 'entropy_loss': -0.02756805857643485, 'vf_loss': 0.00015862608151330295, 'total_loss': -0.023719531139983995, 'approx_kl': 0.006313144229352474, 'clip_fraction': 0.1015625, 'grad_norm': 8.815468788146973}
2022-12-30 00:03:05.889 DEBUG: Taking gradient step
2022-12-30 00:03:05.896 DEBUG: Loss 2: {'policy_loss': -0.019550871234857388, 'entropy_loss': -0.026273646391928196, 'vf_loss': 0.00016410153257101403, 'total_loss': -0.04566041609421457, 'approx_kl': 0.0349442851729691, 'clip_fraction': 0.3671875, 'grad_norm': 8.694591522216797}
2022-12-30 00:03:09.103 DEBUG: Taking gradient step
2022-12-30 00:03:09.111 DEBUG: Loss 3: {'policy_loss': -0.032032812246946096, 'entropy_loss': -0.026454920880496502, 'vf_loss': 0.0001596991031023887, 'total_loss': -0.05832803402434021, 'approx_kl': 0.034961204044520855, 'clip_fraction': 0.4140625, 'grad_norm': 9.015589714050293}
2022-12-30 00:03:12.402 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-30 00:03:12.403 INFO: Optimization: policy loss=-0.032, vf loss=0.000, entropy loss=-0.026, total loss=-0.058, num steps=4
2022-12-30 00:03:12.406 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-30 00:03:13.773 INFO: Evaluation rollout: return=0.746 (0.0), episode length=5.0
2022-12-30 00:03:13.774 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-30 00:03:13.777 DEBUG: Deleting old model: runs/CH4_int/models/CH4_int_run-1_steps-23976.model
2022-12-30 00:03:13.782 DEBUG: Saving model: runs/CH4_int/models/CH4_int_run-1_steps-26136.model
2022-12-30 00:03:13.804 INFO: Iteration: 121/137, steps: 26136
2022-12-30 00:04:09.749 INFO: Training rollout: return=0.618 (0.1), episode length=5.0
2022-12-30 00:04:09.751 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-30 00:04:09.753 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-26136_train.pkl
2022-12-30 00:04:13.424 DEBUG: Taking gradient step
2022-12-30 00:04:13.435 DEBUG: Loss 0: {'policy_loss': 0.006242549789314378, 'entropy_loss': -0.026356440037488937, 'vf_loss': 0.0001540186031607226, 'total_loss': -0.01995987164501383, 'approx_kl': -3.5797711461782455e-09, 'clip_fraction': 0.0, 'grad_norm': 14.829769134521484}
2022-12-30 00:04:16.992 DEBUG: Taking gradient step
2022-12-30 00:04:17.000 DEBUG: Loss 1: {'policy_loss': 0.038453082078390266, 'entropy_loss': -0.02613381575793028, 'vf_loss': 0.0001508960635373716, 'total_loss': 0.012470162383997362, 'approx_kl': 0.01189279556274414, 'clip_fraction': 0.1145833358168602, 'grad_norm': 8.227883338928223}
2022-12-30 00:04:20.240 DEBUG: Taking gradient step
2022-12-30 00:04:20.247 DEBUG: Loss 2: {'policy_loss': -0.019331787225041655, 'entropy_loss': -0.025196760892868042, 'vf_loss': 0.0001534634101353545, 'total_loss': -0.044375084707774334, 'approx_kl': 0.020620641764253378, 'clip_fraction': 0.24609375, 'grad_norm': 19.202627182006836}
2022-12-30 00:04:23.686 DEBUG: Taking gradient step
2022-12-30 00:04:23.694 DEBUG: Loss 3: {'policy_loss': 0.010137785995971014, 'entropy_loss': -0.02388671226799488, 'vf_loss': 0.00014605545335887783, 'total_loss': -0.01360287081866499, 'approx_kl': 0.03463795781135559, 'clip_fraction': 0.3072916716337204, 'grad_norm': 11.138104438781738}
2022-12-30 00:04:26.855 DEBUG: Taking gradient step
2022-12-30 00:04:26.862 DEBUG: Loss 4: {'policy_loss': -0.0010454483991431396, 'entropy_loss': -0.023803272284567356, 'vf_loss': 0.00014164308471042162, 'total_loss': -0.024707077599000076, 'approx_kl': 0.04227027203887701, 'clip_fraction': 0.3216145858168602, 'grad_norm': 6.532883644104004}
2022-12-30 00:04:30.376 DEBUG: Taking gradient step
2022-12-30 00:04:30.383 DEBUG: Loss 5: {'policy_loss': -0.03200700627311325, 'entropy_loss': -0.022972027771174908, 'vf_loss': 0.00014244622465460602, 'total_loss': -0.054836587819633555, 'approx_kl': 0.024087390396744013, 'clip_fraction': 0.24609375, 'grad_norm': 10.875285148620605}
2022-12-30 00:04:33.700 DEBUG: Taking gradient step
2022-12-30 00:04:33.710 DEBUG: Loss 6: {'policy_loss': -0.06897784777554829, 'entropy_loss': -0.022864660248160362, 'vf_loss': 0.00014457332583149603, 'total_loss': -0.09169793469787715, 'approx_kl': 0.03495743416715413, 'clip_fraction': 0.1979166679084301, 'grad_norm': 10.563797950744629}
2022-12-30 00:04:36.878 DEBUG: Early stopping at step 7 for reaching max KL.
2022-12-30 00:04:36.879 INFO: Optimization: policy loss=-0.069, vf loss=0.000, entropy loss=-0.023, total loss=-0.092, num steps=7
2022-12-30 00:04:36.884 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-30 00:04:38.261 INFO: Evaluation rollout: return=0.760 (0.0), episode length=5.0
2022-12-30 00:04:38.263 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-30 00:04:38.266 INFO: Iteration: 122/137, steps: 26352
2022-12-30 00:05:25.331 DEBUG: Atoms are too close
2022-12-30 00:05:34.419 INFO: Training rollout: return=0.069 (3.3), episode length=5.0
2022-12-30 00:05:34.421 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-30 00:05:34.424 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-26352_train.pkl
2022-12-30 00:05:38.023 DEBUG: Taking gradient step
2022-12-30 00:05:38.032 DEBUG: Loss 0: {'policy_loss': -0.021035261959726964, 'entropy_loss': -0.023699805606156588, 'vf_loss': 0.00792586148983622, 'total_loss': -0.03680920607604733, 'approx_kl': -5.1067523543224524e-08, 'clip_fraction': 0.0, 'grad_norm': 13.0377836227417}
2022-12-30 00:05:41.266 DEBUG: Taking gradient step
2022-12-30 00:05:41.273 DEBUG: Loss 1: {'policy_loss': 0.0035737880105352893, 'entropy_loss': -0.023563829716295004, 'vf_loss': 0.010632912708326656, 'total_loss': -0.009357128997433063, 'approx_kl': 0.006783646764233708, 'clip_fraction': 0.03125, 'grad_norm': 22.654422760009766}
2022-12-30 00:05:44.675 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-30 00:05:44.676 INFO: Optimization: policy loss=0.004, vf loss=0.011, entropy loss=-0.024, total loss=-0.009, num steps=2
2022-12-30 00:05:44.679 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-30 00:05:46.001 INFO: Evaluation rollout: return=0.776 (0.0), episode length=5.0
2022-12-30 00:05:46.002 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-30 00:05:46.005 INFO: Iteration: 123/137, steps: 26568
2022-12-30 00:06:41.863 INFO: Training rollout: return=0.655 (0.1), episode length=5.0
2022-12-30 00:06:41.865 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-30 00:06:41.868 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-26568_train.pkl
2022-12-30 00:06:45.246 DEBUG: Taking gradient step
2022-12-30 00:06:45.253 DEBUG: Loss 0: {'policy_loss': -0.020213315484136376, 'entropy_loss': -0.02322119940072298, 'vf_loss': 0.00016394180757640453, 'total_loss': -0.04327057307728295, 'approx_kl': 1.785034897672233e-09, 'clip_fraction': 0.0, 'grad_norm': 17.97289276123047}
2022-12-30 00:06:48.502 DEBUG: Taking gradient step
2022-12-30 00:06:48.509 DEBUG: Loss 1: {'policy_loss': 0.005402537435542658, 'entropy_loss': -0.02339710807427764, 'vf_loss': 0.00015979329059830354, 'total_loss': -0.017834777348136675, 'approx_kl': -0.0021903502056375146, 'clip_fraction': 0.01953125, 'grad_norm': 15.18128776550293}
2022-12-30 00:06:52.001 DEBUG: Taking gradient step
2022-12-30 00:06:52.008 DEBUG: Loss 2: {'policy_loss': 0.0033786886244492817, 'entropy_loss': -0.022832532413303852, 'vf_loss': 0.00015082471670306176, 'total_loss': -0.0193030190721515, 'approx_kl': 0.009213735407683998, 'clip_fraction': 0.08984375, 'grad_norm': 12.605730056762695}
2022-12-30 00:06:55.200 DEBUG: Taking gradient step
2022-12-30 00:06:55.208 DEBUG: Loss 3: {'policy_loss': -0.02108093432362479, 'entropy_loss': -0.023928466252982616, 'vf_loss': 0.00015731970104331734, 'total_loss': -0.04485208087556409, 'approx_kl': 0.02272242517210543, 'clip_fraction': 0.1171875, 'grad_norm': 10.724724769592285}
2022-12-30 00:06:58.507 DEBUG: Taking gradient step
2022-12-30 00:06:58.518 DEBUG: Loss 4: {'policy_loss': -0.00371819944750474, 'entropy_loss': -0.02382131014019251, 'vf_loss': 0.0001484083570770877, 'total_loss': -0.02739110123062016, 'approx_kl': 0.04254531330661848, 'clip_fraction': 0.2135416679084301, 'grad_norm': 9.57917594909668}
2022-12-30 00:07:01.905 DEBUG: Early stopping at step 5 for reaching max KL.
2022-12-30 00:07:01.906 INFO: Optimization: policy loss=-0.004, vf loss=0.000, entropy loss=-0.024, total loss=-0.027, num steps=5
2022-12-30 00:07:01.911 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-30 00:07:03.265 INFO: Evaluation rollout: return=0.755 (0.0), episode length=5.0
2022-12-30 00:07:03.267 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-30 00:07:03.269 INFO: Iteration: 124/137, steps: 26784
2022-12-30 00:07:59.136 INFO: Training rollout: return=0.644 (0.1), episode length=5.0
2022-12-30 00:07:59.138 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-30 00:07:59.141 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-26784_train.pkl
2022-12-30 00:08:02.539 DEBUG: Taking gradient step
2022-12-30 00:08:02.549 DEBUG: Loss 0: {'policy_loss': 0.01381725068044503, 'entropy_loss': -0.024904185440391302, 'vf_loss': 0.00013428715384939576, 'total_loss': -0.010952647606096877, 'approx_kl': 2.219652139867634e-08, 'clip_fraction': 0.0, 'grad_norm': 15.094257354736328}
2022-12-30 00:08:05.796 DEBUG: Taking gradient step
2022-12-30 00:08:05.804 DEBUG: Loss 1: {'policy_loss': 0.04376252096377037, 'entropy_loss': -0.02527918154373765, 'vf_loss': 0.00012943118203668984, 'total_loss': 0.018612770602069402, 'approx_kl': 0.007031528977677226, 'clip_fraction': 0.1041666679084301, 'grad_norm': 13.061114311218262}
2022-12-30 00:08:09.335 DEBUG: Taking gradient step
2022-12-30 00:08:09.342 DEBUG: Loss 2: {'policy_loss': 0.02509034156294734, 'entropy_loss': -0.024799681268632412, 'vf_loss': 0.00013014888523252787, 'total_loss': 0.00042080917954745445, 'approx_kl': 0.004844338167458773, 'clip_fraction': 0.15364583395421505, 'grad_norm': 17.60196304321289}
2022-12-30 00:08:12.746 DEBUG: Taking gradient step
2022-12-30 00:08:12.754 DEBUG: Loss 3: {'policy_loss': -0.006530042744221526, 'entropy_loss': -0.024613542947918177, 'vf_loss': 0.000127273165549034, 'total_loss': -0.031016312526590664, 'approx_kl': 0.014064356684684753, 'clip_fraction': 0.24609375, 'grad_norm': 8.936659812927246}
2022-12-30 00:08:15.951 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-30 00:08:15.952 INFO: Optimization: policy loss=-0.007, vf loss=0.000, entropy loss=-0.025, total loss=-0.031, num steps=4
2022-12-30 00:08:15.957 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-30 00:08:17.357 INFO: Evaluation rollout: return=0.773 (0.0), episode length=5.0
2022-12-30 00:08:17.359 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-30 00:08:17.362 INFO: Iteration: 125/137, steps: 27000
2022-12-30 00:09:13.360 INFO: Training rollout: return=0.648 (0.1), episode length=5.0
2022-12-30 00:09:13.362 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-30 00:09:13.364 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-27000_train.pkl
2022-12-30 00:09:16.742 DEBUG: Taking gradient step
2022-12-30 00:09:16.752 DEBUG: Loss 0: {'policy_loss': 0.01384313120859746, 'entropy_loss': -0.023999734316021204, 'vf_loss': 0.00013371246344615038, 'total_loss': -0.010022890643977593, 'approx_kl': -1.658918336033821e-08, 'clip_fraction': 0.0, 'grad_norm': 7.906064510345459}
2022-12-30 00:09:19.959 DEBUG: Taking gradient step
2022-12-30 00:09:19.966 DEBUG: Loss 1: {'policy_loss': -0.047251949390451645, 'entropy_loss': -0.023699083365499973, 'vf_loss': 0.00013538177474507827, 'total_loss': -0.07081565098120654, 'approx_kl': 0.022286737337708473, 'clip_fraction': 0.1484375, 'grad_norm': 10.247516632080078}
2022-12-30 00:09:23.311 DEBUG: Taking gradient step
2022-12-30 00:09:23.319 DEBUG: Loss 2: {'policy_loss': -0.05411890088298947, 'entropy_loss': -0.02476791711524129, 'vf_loss': 0.00013476491126411565, 'total_loss': -0.07875205308696664, 'approx_kl': 0.04397506779059768, 'clip_fraction': 0.2057291679084301, 'grad_norm': 11.905969619750977}
2022-12-30 00:09:26.654 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-30 00:09:26.655 INFO: Optimization: policy loss=-0.054, vf loss=0.000, entropy loss=-0.025, total loss=-0.079, num steps=3
2022-12-30 00:09:26.658 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-30 00:09:28.085 INFO: Evaluation rollout: return=0.779 (0.0), episode length=5.0
2022-12-30 00:09:28.086 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-30 00:09:28.089 INFO: Iteration: 126/137, steps: 27216
2022-12-30 00:10:13.623 DEBUG: Atoms are too close
2022-12-30 00:10:24.149 INFO: Training rollout: return=0.085 (3.3), episode length=5.0
2022-12-30 00:10:24.152 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-30 00:10:24.154 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-27216_train.pkl
2022-12-30 00:10:27.629 DEBUG: Taking gradient step
2022-12-30 00:10:27.637 DEBUG: Loss 0: {'policy_loss': 0.05938491230057183, 'entropy_loss': -0.024311743676662445, 'vf_loss': 0.013120381604789328, 'total_loss': 0.04819355022869872, 'approx_kl': -5.5801745446615314e-08, 'clip_fraction': 0.0, 'grad_norm': 16.89459991455078}
2022-12-30 00:10:30.915 DEBUG: Taking gradient step
2022-12-30 00:10:30.922 DEBUG: Loss 1: {'policy_loss': 0.010760641608380278, 'entropy_loss': -0.023274746723473072, 'vf_loss': 0.010429737524458506, 'total_loss': -0.002084367590634288, 'approx_kl': 0.0013875273580197245, 'clip_fraction': 0.0078125, 'grad_norm': 8.18160629272461}
2022-12-30 00:10:34.577 DEBUG: Taking gradient step
2022-12-30 00:10:34.587 DEBUG: Loss 2: {'policy_loss': -0.00021172579114780987, 'entropy_loss': -0.024112576618790627, 'vf_loss': 0.010562527861975517, 'total_loss': -0.013761774547962919, 'approx_kl': 0.010247186059132218, 'clip_fraction': 0.12890625, 'grad_norm': 6.180164337158203}
2022-12-30 00:10:38.122 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-30 00:10:38.123 INFO: Optimization: policy loss=-0.000, vf loss=0.011, entropy loss=-0.024, total loss=-0.014, num steps=3
2022-12-30 00:10:38.127 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-30 00:10:39.503 INFO: Evaluation rollout: return=0.784 (0.0), episode length=5.0
2022-12-30 00:10:39.504 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-30 00:10:39.506 INFO: Iteration: 127/137, steps: 27432
2022-12-30 00:11:36.150 INFO: Training rollout: return=0.650 (0.1), episode length=5.0
2022-12-30 00:11:36.153 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-30 00:11:36.155 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-27432_train.pkl
2022-12-30 00:11:39.467 DEBUG: Taking gradient step
2022-12-30 00:11:39.474 DEBUG: Loss 0: {'policy_loss': 0.019616601901896666, 'entropy_loss': -0.02457811450585723, 'vf_loss': 0.00011593463933832015, 'total_loss': -0.0048455779646222365, 'approx_kl': 2.02174632590868e-08, 'clip_fraction': 0.0, 'grad_norm': 24.006546020507812}
2022-12-30 00:11:42.721 DEBUG: Early stopping at step 1 for reaching max KL.
2022-12-30 00:11:42.722 INFO: Optimization: policy loss=0.020, vf loss=0.000, entropy loss=-0.025, total loss=-0.005, num steps=1
2022-12-30 00:11:42.725 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-30 00:11:44.105 INFO: Evaluation rollout: return=0.785 (0.0), episode length=5.0
2022-12-30 00:11:44.107 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-30 00:11:44.109 INFO: Iteration: 128/137, steps: 27648
2022-12-30 00:12:25.479 DEBUG: Atoms are too close
2022-12-30 00:12:26.900 DEBUG: Atoms are too close
2022-12-30 00:12:26.901 DEBUG: Atoms are too close
2022-12-30 00:12:39.547 INFO: Training rollout: return=-1.060 (5.6), episode length=4.9
2022-12-30 00:12:39.548 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-30 00:12:39.551 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-27648_train.pkl
2022-12-30 00:12:42.738 DEBUG: Taking gradient step
2022-12-30 00:12:42.746 DEBUG: Loss 0: {'policy_loss': -0.006405584076398284, 'entropy_loss': -0.024509604554623365, 'vf_loss': 0.021469907214717848, 'total_loss': -0.009445281416303797, 'approx_kl': 4.7885503562383747e-08, 'clip_fraction': 0.0, 'grad_norm': 20.464956283569336}
2022-12-30 00:12:46.243 DEBUG: Taking gradient step
2022-12-30 00:12:46.250 DEBUG: Loss 1: {'policy_loss': -0.010831990874216955, 'entropy_loss': -0.02394837699830532, 'vf_loss': 0.021399247784548082, 'total_loss': -0.013381120087974194, 'approx_kl': 0.023856935556977987, 'clip_fraction': 0.2135416679084301, 'grad_norm': 11.32333755493164}
2022-12-30 00:12:49.825 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-30 00:12:49.825 INFO: Optimization: policy loss=-0.011, vf loss=0.021, entropy loss=-0.024, total loss=-0.013, num steps=2
2022-12-30 00:12:49.831 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-30 00:12:51.252 INFO: Evaluation rollout: return=0.778 (0.0), episode length=5.0
2022-12-30 00:12:51.253 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-30 00:12:51.255 INFO: Iteration: 129/137, steps: 27864
2022-12-30 00:13:00.384 DEBUG: Atoms are too close
2022-12-30 00:13:36.611 DEBUG: Atoms are too close
2022-12-30 00:13:46.720 INFO: Training rollout: return=-0.469 (4.6), episode length=5.0
2022-12-30 00:13:46.722 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-30 00:13:46.725 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-27864_train.pkl
2022-12-30 00:13:49.990 DEBUG: Taking gradient step
2022-12-30 00:13:49.998 DEBUG: Loss 0: {'policy_loss': 0.0663457282777242, 'entropy_loss': -0.0240078317001462, 'vf_loss': 0.021799470176795108, 'total_loss': 0.06413736675437309, 'approx_kl': -4.35005249599385e-08, 'clip_fraction': 0.0, 'grad_norm': 18.479875564575195}
2022-12-30 00:13:53.377 DEBUG: Taking gradient step
2022-12-30 00:13:53.385 DEBUG: Loss 1: {'policy_loss': 0.04990183461777064, 'entropy_loss': -0.024412402883172035, 'vf_loss': 0.021698246973027004, 'total_loss': 0.04718767870762561, 'approx_kl': 0.020249660359695554, 'clip_fraction': 0.2552083358168602, 'grad_norm': 9.204877853393555}
2022-12-30 00:13:56.696 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-30 00:13:56.697 INFO: Optimization: policy loss=0.050, vf loss=0.022, entropy loss=-0.024, total loss=0.047, num steps=2
2022-12-30 00:13:56.700 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-30 00:13:58.122 INFO: Evaluation rollout: return=0.763 (0.0), episode length=5.0
2022-12-30 00:13:58.123 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-30 00:13:58.126 INFO: Iteration: 130/137, steps: 28080
2022-12-30 00:14:54.509 INFO: Training rollout: return=0.654 (0.1), episode length=5.0
2022-12-30 00:14:54.511 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-30 00:14:54.513 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-28080_train.pkl
2022-12-30 00:14:57.974 DEBUG: Taking gradient step
2022-12-30 00:14:57.981 DEBUG: Loss 0: {'policy_loss': -0.0580348997115898, 'entropy_loss': -0.02323077479377389, 'vf_loss': 0.00012991666198985464, 'total_loss': -0.08113575784337385, 'approx_kl': 2.355469952419753e-08, 'clip_fraction': 0.0, 'grad_norm': 13.947704315185547}
2022-12-30 00:15:01.371 DEBUG: Early stopping at step 1 for reaching max KL.
2022-12-30 00:15:01.371 INFO: Optimization: policy loss=-0.058, vf loss=0.000, entropy loss=-0.023, total loss=-0.081, num steps=1
2022-12-30 00:15:01.376 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-30 00:15:02.746 INFO: Evaluation rollout: return=0.751 (0.0), episode length=5.0
2022-12-30 00:15:02.748 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-30 00:15:02.751 DEBUG: Deleting old model: runs/CH4_int/models/CH4_int_run-1_steps-26136.model
2022-12-30 00:15:02.753 DEBUG: Saving model: runs/CH4_int/models/CH4_int_run-1_steps-28296.model
2022-12-30 00:15:02.775 INFO: Iteration: 131/137, steps: 28296
2022-12-30 00:15:58.779 INFO: Training rollout: return=0.635 (0.1), episode length=5.0
2022-12-30 00:15:58.781 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-30 00:15:58.783 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-28296_train.pkl
2022-12-30 00:16:02.191 DEBUG: Taking gradient step
2022-12-30 00:16:02.202 DEBUG: Loss 0: {'policy_loss': 0.01614579882494363, 'entropy_loss': -0.023401521146297455, 'vf_loss': 0.00011912211508145533, 'total_loss': -0.007136600206272367, 'approx_kl': -1.3504177331924438e-08, 'clip_fraction': 0.0, 'grad_norm': 9.512051582336426}
2022-12-30 00:16:05.925 DEBUG: Early stopping at step 1 for reaching max KL.
2022-12-30 00:16:05.925 INFO: Optimization: policy loss=0.016, vf loss=0.000, entropy loss=-0.023, total loss=-0.007, num steps=1
2022-12-30 00:16:05.931 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-30 00:16:07.310 INFO: Evaluation rollout: return=0.734 (0.0), episode length=5.0
2022-12-30 00:16:07.311 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-30 00:16:07.314 INFO: Iteration: 132/137, steps: 28512
2022-12-30 00:16:36.078 DEBUG: Atoms are too close
2022-12-30 00:16:53.302 DEBUG: Atoms are too close
2022-12-30 00:17:02.893 INFO: Training rollout: return=-0.477 (4.6), episode length=5.0
2022-12-30 00:17:02.895 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-30 00:17:02.897 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-28512_train.pkl
2022-12-30 00:17:06.368 DEBUG: Taking gradient step
2022-12-30 00:17:06.376 DEBUG: Loss 0: {'policy_loss': -0.03677867089164199, 'entropy_loss': -0.020867158193141222, 'vf_loss': 0.015486777364150347, 'total_loss': -0.04215905172063286, 'approx_kl': -2.696955014869218e-08, 'clip_fraction': 0.0, 'grad_norm': 12.209836959838867}
2022-12-30 00:17:10.024 DEBUG: Taking gradient step
2022-12-30 00:17:10.031 DEBUG: Loss 1: {'policy_loss': -0.03848296794216403, 'entropy_loss': -0.02135953214019537, 'vf_loss': 0.015458048304759324, 'total_loss': -0.04438445177760007, 'approx_kl': 0.029093607678078115, 'clip_fraction': 0.3385416716337204, 'grad_norm': 7.619070053100586}
2022-12-30 00:17:13.659 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-30 00:17:13.660 INFO: Optimization: policy loss=-0.038, vf loss=0.015, entropy loss=-0.021, total loss=-0.044, num steps=2
2022-12-30 00:17:13.664 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-30 00:17:15.001 INFO: Evaluation rollout: return=0.704 (0.0), episode length=5.0
2022-12-30 00:17:15.002 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-30 00:17:15.005 INFO: Iteration: 133/137, steps: 28728
2022-12-30 00:18:11.473 INFO: Training rollout: return=0.599 (0.1), episode length=5.0
2022-12-30 00:18:11.475 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-30 00:18:11.477 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-28728_train.pkl
2022-12-30 00:18:14.973 DEBUG: Taking gradient step
2022-12-30 00:18:14.983 DEBUG: Loss 0: {'policy_loss': 0.03736596536400713, 'entropy_loss': -0.021646887995302677, 'vf_loss': 0.00012123487570352041, 'total_loss': 0.01584031224440796, 'approx_kl': 8.253846317529678e-08, 'clip_fraction': 0.0, 'grad_norm': 8.485806465148926}
2022-12-30 00:18:18.300 DEBUG: Taking gradient step
2022-12-30 00:18:18.310 DEBUG: Loss 1: {'policy_loss': 0.037047621143467366, 'entropy_loss': -0.01988543663173914, 'vf_loss': 0.00013008532997289398, 'total_loss': 0.017292269841701124, 'approx_kl': 0.01796387298963964, 'clip_fraction': 0.2486979216337204, 'grad_norm': 21.630577087402344}
2022-12-30 00:18:21.969 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-30 00:18:21.970 INFO: Optimization: policy loss=0.037, vf loss=0.000, entropy loss=-0.020, total loss=0.017, num steps=2
2022-12-30 00:18:21.975 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-30 00:18:23.360 INFO: Evaluation rollout: return=0.688 (0.0), episode length=5.0
2022-12-30 00:18:23.361 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-30 00:18:23.364 INFO: Iteration: 134/137, steps: 28944
2022-12-30 00:19:20.297 INFO: Training rollout: return=0.624 (0.0), episode length=5.0
2022-12-30 00:19:20.299 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-30 00:19:20.302 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-28944_train.pkl
2022-12-30 00:19:23.562 DEBUG: Taking gradient step
2022-12-30 00:19:23.571 DEBUG: Loss 0: {'policy_loss': 0.00797486718444057, 'entropy_loss': -0.019886642694473267, 'vf_loss': 0.00015123380434318447, 'total_loss': -0.011760541705689511, 'approx_kl': -5.0640664994716644e-08, 'clip_fraction': 0.0, 'grad_norm': 20.71885871887207}
2022-12-30 00:19:26.934 DEBUG: Taking gradient step
2022-12-30 00:19:26.945 DEBUG: Loss 1: {'policy_loss': -0.0064456216072925525, 'entropy_loss': -0.019411877263337374, 'vf_loss': 0.00015869525220178898, 'total_loss': -0.02569880361842814, 'approx_kl': 0.004029629461001605, 'clip_fraction': 0.0, 'grad_norm': 17.99424934387207}
2022-12-30 00:19:30.733 DEBUG: Taking gradient step
2022-12-30 00:19:30.741 DEBUG: Loss 2: {'policy_loss': -0.009242968821537984, 'entropy_loss': -0.019886841997504234, 'vf_loss': 0.0001620978270552001, 'total_loss': -0.02896771299198702, 'approx_kl': 0.008075459161773324, 'clip_fraction': 0.1276041679084301, 'grad_norm': 11.900907516479492}
2022-12-30 00:19:34.328 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-30 00:19:34.329 INFO: Optimization: policy loss=-0.009, vf loss=0.000, entropy loss=-0.020, total loss=-0.029, num steps=3
2022-12-30 00:19:34.332 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-30 00:19:35.644 INFO: Evaluation rollout: return=0.707 (0.0), episode length=5.0
2022-12-30 00:19:35.645 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-30 00:19:35.647 INFO: Iteration: 135/137, steps: 29160
2022-12-30 00:20:31.839 INFO: Training rollout: return=0.652 (0.1), episode length=5.0
2022-12-30 00:20:31.842 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-30 00:20:31.844 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-29160_train.pkl
2022-12-30 00:20:35.193 DEBUG: Taking gradient step
2022-12-30 00:20:35.201 DEBUG: Loss 0: {'policy_loss': 0.004649948269637452, 'entropy_loss': -0.01808056514710188, 'vf_loss': 0.00017308184687939108, 'total_loss': -0.013257535030585035, 'approx_kl': 5.122274160385132e-08, 'clip_fraction': 0.0, 'grad_norm': 10.970565795898438}
2022-12-30 00:20:38.455 DEBUG: Taking gradient step
2022-12-30 00:20:38.463 DEBUG: Loss 1: {'policy_loss': 0.07286067407053548, 'entropy_loss': -0.018226984422653913, 'vf_loss': 0.0001692140784113199, 'total_loss': 0.05480290372629287, 'approx_kl': 0.018583709723316133, 'clip_fraction': 0.19921875, 'grad_norm': 16.631643295288086}
2022-12-30 00:20:41.698 DEBUG: Taking gradient step
2022-12-30 00:20:41.705 DEBUG: Loss 2: {'policy_loss': 0.00042746196085904843, 'entropy_loss': -0.018405976239591837, 'vf_loss': 0.00017721680403203657, 'total_loss': -0.01780129747470075, 'approx_kl': 0.04051844868808985, 'clip_fraction': 0.3125, 'grad_norm': 13.192892074584961}
2022-12-30 00:20:44.933 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-30 00:20:44.934 INFO: Optimization: policy loss=0.000, vf loss=0.000, entropy loss=-0.018, total loss=-0.018, num steps=3
2022-12-30 00:20:44.937 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-30 00:20:46.226 INFO: Evaluation rollout: return=0.717 (0.0), episode length=5.0
2022-12-30 00:20:46.227 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-30 00:20:46.230 INFO: Iteration: 136/137, steps: 29376
2022-12-30 00:21:30.696 DEBUG: There is a single atom floating around
2022-12-30 00:21:31.257 DEBUG: There is a single atom floating around
2022-12-30 00:21:41.828 INFO: Training rollout: return=-0.472 (4.6), episode length=5.0
2022-12-30 00:21:41.831 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-30 00:21:41.834 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-29376_train.pkl
2022-12-30 00:21:45.126 DEBUG: Taking gradient step
2022-12-30 00:21:45.133 DEBUG: Loss 0: {'policy_loss': -0.03564080085924004, 'entropy_loss': -0.01884070923551917, 'vf_loss': 0.015380345681224353, 'total_loss': -0.03910116441353487, 'approx_kl': 5.021380999892244e-08, 'clip_fraction': 0.0, 'grad_norm': 12.838334083557129}
2022-12-30 00:21:48.363 DEBUG: Taking gradient step
2022-12-30 00:21:48.370 DEBUG: Loss 1: {'policy_loss': -0.014110973820329442, 'entropy_loss': -0.018758935388177633, 'vf_loss': 0.01789161558820232, 'total_loss': -0.014978293620304756, 'approx_kl': -0.011071052518673241, 'clip_fraction': 0.02734375, 'grad_norm': 14.430856704711914}
2022-12-30 00:21:51.850 DEBUG: Taking gradient step
2022-12-30 00:21:51.858 DEBUG: Loss 2: {'policy_loss': 0.07006244685284652, 'entropy_loss': -0.016980225685983896, 'vf_loss': 0.025430015615661147, 'total_loss': 0.07851223678252377, 'approx_kl': -0.013064669445157051, 'clip_fraction': 0.1953125, 'grad_norm': 13.767746925354004}
2022-12-30 00:21:55.280 DEBUG: Taking gradient step
2022-12-30 00:21:55.287 DEBUG: Loss 3: {'policy_loss': -0.021323052057634493, 'entropy_loss': -0.01740608480758965, 'vf_loss': 0.017914069357033033, 'total_loss': -0.020815067508191114, 'approx_kl': -0.005492784781381488, 'clip_fraction': 0.3619791716337204, 'grad_norm': 8.315073013305664}
2022-12-30 00:21:58.551 DEBUG: Taking gradient step
2022-12-30 00:21:58.558 DEBUG: Loss 4: {'policy_loss': 0.028245424001032686, 'entropy_loss': -0.017279725521802902, 'vf_loss': 0.02293665876005023, 'total_loss': 0.033902357239280013, 'approx_kl': 0.009922762401401997, 'clip_fraction': 0.3880208358168602, 'grad_norm': 9.518132209777832}
2022-12-30 00:22:02.247 DEBUG: Taking gradient step
2022-12-30 00:22:02.257 DEBUG: Loss 5: {'policy_loss': -0.03322143845355812, 'entropy_loss': -0.016851014690473676, 'vf_loss': 0.017902757618364334, 'total_loss': -0.03216969552566746, 'approx_kl': 0.0036668297834694386, 'clip_fraction': 0.4348958358168602, 'grad_norm': 4.711128234863281}
2022-12-30 00:22:05.494 DEBUG: Taking gradient step
2022-12-30 00:22:05.501 DEBUG: Loss 6: {'policy_loss': -0.056941480210404835, 'entropy_loss': -0.017267298884689808, 'vf_loss': 0.015323952765475005, 'total_loss': -0.05888482632961964, 'approx_kl': 0.010460877791047096, 'clip_fraction': 0.4322916716337204, 'grad_norm': 4.775726795196533}
2022-12-30 00:22:08.945 DEBUG: Taking gradient step
2022-12-30 00:22:08.952 DEBUG: Loss 7: {'policy_loss': -0.05307776659219793, 'entropy_loss': -0.016863436438143253, 'vf_loss': 0.01530439026775416, 'total_loss': -0.054636812762587014, 'approx_kl': 0.018709387630224228, 'clip_fraction': 0.3880208358168602, 'grad_norm': 5.773702621459961}
2022-12-30 00:22:12.244 DEBUG: Taking gradient step
2022-12-30 00:22:12.251 DEBUG: Loss 8: {'policy_loss': -0.030137675135413947, 'entropy_loss': -0.01648528059013188, 'vf_loss': 0.017787324059661144, 'total_loss': -0.02883563166588468, 'approx_kl': 0.01219762908294797, 'clip_fraction': 0.3736979216337204, 'grad_norm': 4.705536365509033}
2022-12-30 00:22:15.453 DEBUG: Taking gradient step
2022-12-30 00:22:15.461 DEBUG: Loss 9: {'policy_loss': 0.019372341631289633, 'entropy_loss': -0.01661238051019609, 'vf_loss': 0.022669587702504823, 'total_loss': 0.025429548823598366, 'approx_kl': 0.025878601241856813, 'clip_fraction': 0.3984375, 'grad_norm': 6.401921272277832}
2022-12-30 00:22:15.461 INFO: Optimization: policy loss=0.019, vf loss=0.023, entropy loss=-0.017, total loss=0.025, num steps=10
2022-12-30 00:22:15.465 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-30 00:22:16.826 INFO: Evaluation rollout: return=0.697 (0.0), episode length=5.0
2022-12-30 00:22:16.827 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-30 00:22:16.830 INFO: Iteration: 137/137, steps: 29592
2022-12-30 00:23:13.463 INFO: Training rollout: return=0.633 (0.1), episode length=5.0
2022-12-30 00:23:13.465 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-30 00:23:13.468 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-29592_train.pkl
2022-12-30 00:23:16.646 DEBUG: Taking gradient step
2022-12-30 00:23:16.657 DEBUG: Loss 0: {'policy_loss': -0.008910538777376598, 'entropy_loss': -0.017884243745356798, 'vf_loss': 0.00031140215833989313, 'total_loss': -0.026483380364393502, 'approx_kl': 1.8941719304166327e-09, 'clip_fraction': 0.0, 'grad_norm': 5.755257606506348}
2022-12-30 00:23:20.514 DEBUG: Taking gradient step
2022-12-30 00:23:20.521 DEBUG: Loss 1: {'policy_loss': 0.013196751591556992, 'entropy_loss': -0.017063860781490803, 'vf_loss': 0.000334511619441333, 'total_loss': -0.003532597570492481, 'approx_kl': 0.006130402907729149, 'clip_fraction': 0.2291666679084301, 'grad_norm': 19.663333892822266}
2022-12-30 00:23:23.848 DEBUG: Taking gradient step
2022-12-30 00:23:23.856 DEBUG: Loss 2: {'policy_loss': 0.0736725138579426, 'entropy_loss': -0.018116049701347947, 'vf_loss': 0.00034920029585819594, 'total_loss': 0.05590566445245285, 'approx_kl': 0.03956824168562889, 'clip_fraction': 0.3528645858168602, 'grad_norm': 21.077205657958984}
2022-12-30 00:23:27.368 DEBUG: Taking gradient step
2022-12-30 00:23:27.376 DEBUG: Loss 3: {'policy_loss': 0.09061923152886095, 'entropy_loss': -0.01767842937260866, 'vf_loss': 0.00035772383593580127, 'total_loss': 0.07329852599218808, 'approx_kl': 0.037511865608394146, 'clip_fraction': 0.3020833358168602, 'grad_norm': 21.749603271484375}
2022-12-30 00:23:30.603 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-30 00:23:30.604 INFO: Optimization: policy loss=0.091, vf loss=0.000, entropy loss=-0.018, total loss=0.073, num steps=4
2022-12-30 00:23:30.608 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-30 00:23:31.973 INFO: Evaluation rollout: return=0.684 (0.0), episode length=5.0
2022-12-30 00:23:31.974 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-30 00:23:31.976 DEBUG: Deleting old model: runs/CH4_int/models/CH4_int_run-1_steps-28296.model
2022-12-30 00:23:31.981 DEBUG: Saving model: runs/CH4_int/models/CH4_int_run-1_steps-29808.model
2022-12-30 00:23:32.003 INFO: Finished PPO
2022-12-30 12:27:31.316 INFO: {
    "bag_scale": 5,
    "beta": "-10",
    "canvas_size": 5,
    "clip_ratio": 0.2,
    "cutoff": 4.0,
    "data_dir": "runs/CH4_int/data",
    "device": "cuda",
    "discount": 1.0,
    "entropy_coef": 0.06,
    "eval_formulas": "CH4",
    "eval_freq": 1,
    "formulas": "CH4",
    "gradient_clip": 0.5,
    "keep_models": false,
    "lam": 1.0,
    "learning_rate": 0.0005,
    "load_latest": false,
    "load_model": null,
    "log_dir": "runs/CH4_int/logs",
    "log_level": "DEBUG",
    "max_mean_distance": 1.8,
    "max_num_steps": 30000,
    "max_num_train_iters": 10,
    "max_solo_distance": 2.0,
    "maxl": 4,
    "min_atomic_distance": 0.6,
    "min_mean_distance": 0.8,
    "min_reward": -20.0,
    "mini_batch_size": 64,
    "model": "internal",
    "model_dir": "runs/CH4_int/models",
    "name": "CH4_int",
    "network_width": 128,
    "num_cg_levels": 3,
    "num_channels_hidden": 10,
    "num_channels_per_element": 4,
    "num_envs": 12,
    "num_eval_episodes": null,
    "num_gaussians": 3,
    "num_interactions": 3,
    "num_steps_per_iter": 216,
    "optimizer": "adam",
    "results_dir": "runs/CH4_int/results",
    "save_freq": 10,
    "save_rollouts": "train",
    "seed": 1,
    "symbols": "X,H,C",
    "target_kl": 0.03,
    "update_edges": true,
    "vf_coef": 0.001
}
2022-12-30 12:27:31.356 INFO: CUDA Device: 0
2022-12-30 12:27:31.357 INFO: Training bags: ['CH4']
2022-12-30 12:27:31.357 INFO: Evaluation bags: ['CH4']
2022-12-30 12:27:33.498 INFO: Number of parameters: 212524
2022-12-30 12:27:33.509 INFO: Starting PPO
2022-12-30 12:27:33.509 INFO: Iteration: 0/137, steps: 0
2022-12-30 12:28:59.588 INFO: {
    "bag_scale": 5,
    "beta": "-10",
    "canvas_size": 5,
    "clip_ratio": 0.2,
    "cutoff": 4.0,
    "data_dir": "runs/CH4_int/data",
    "device": "cuda",
    "discount": 1.0,
    "entropy_coef": 0.06,
    "eval_formulas": "CH4",
    "eval_freq": 1,
    "formulas": "CH4",
    "gradient_clip": 0.5,
    "keep_models": false,
    "lam": 1.0,
    "learning_rate": 0.0005,
    "load_latest": false,
    "load_model": null,
    "log_dir": "runs/CH4_int/logs",
    "log_level": "DEBUG",
    "max_mean_distance": 1.8,
    "max_num_steps": 30000,
    "max_num_train_iters": 10,
    "max_solo_distance": 2.0,
    "maxl": 4,
    "min_atomic_distance": 0.6,
    "min_mean_distance": 0.8,
    "min_reward": -20.0,
    "mini_batch_size": 64,
    "model": "schnet_edge",
    "model_dir": "runs/CH4_int/models",
    "name": "CH4_int",
    "network_width": 128,
    "num_cg_levels": 3,
    "num_channels_hidden": 10,
    "num_channels_per_element": 4,
    "num_envs": 12,
    "num_eval_episodes": null,
    "num_gaussians": 3,
    "num_interactions": 3,
    "num_steps_per_iter": 216,
    "optimizer": "adam",
    "results_dir": "runs/CH4_int/results",
    "save_freq": 10,
    "save_rollouts": "train",
    "seed": 1,
    "symbols": "X,H,C",
    "target_kl": 0.03,
    "update_edges": true,
    "vf_coef": 0.001
}
2022-12-30 12:28:59.628 INFO: CUDA Device: 0
2022-12-30 12:28:59.629 INFO: Training bags: ['CH4']
2022-12-30 12:28:59.629 INFO: Evaluation bags: ['CH4']
2022-12-30 12:29:01.459 INFO: Number of parameters: 548381
2022-12-30 12:29:01.472 INFO: Starting PPO
2022-12-30 12:29:01.472 INFO: Iteration: 0/137, steps: 0
2022-12-30 12:29:04.060 DEBUG: There is a single atom floating around
2022-12-30 12:29:04.270 DEBUG: There is a single atom floating around
2022-12-30 12:29:04.709 DEBUG: There is a single atom floating around
2022-12-30 12:29:04.710 DEBUG: There is a single atom floating around
2022-12-30 12:29:05.335 DEBUG: There is a single atom floating around
2022-12-30 12:29:09.408 DEBUG: Atoms are too close
2022-12-30 12:29:10.382 DEBUG: Atoms are too close
2022-12-30 12:29:14.577 DEBUG: Atoms are too close
2022-12-30 12:29:14.775 DEBUG: There is a single atom floating around
2022-12-30 12:29:14.776 DEBUG: There is a single atom floating around
2022-12-30 12:29:14.976 DEBUG: Atoms are too close
2022-12-30 12:29:15.185 DEBUG: There is a single atom floating around
2022-12-30 12:29:15.900 DEBUG: Atoms are too close
2022-12-30 12:29:16.906 DEBUG: Atoms are too close
2022-12-30 12:29:18.227 DEBUG: Atoms are too close
2022-12-30 12:29:20.291 DEBUG: Atoms are too close
2022-12-30 12:29:21.371 DEBUG: Atoms are too close
2022-12-30 12:29:21.924 DEBUG: Atoms are too close
2022-12-30 12:29:22.800 DEBUG: Atoms are too close
2022-12-30 12:29:24.055 DEBUG: There is a single atom floating around
2022-12-30 12:29:25.537 DEBUG: There is a single atom floating around
2022-12-30 12:29:25.540 DEBUG: There is a single atom floating around
2022-12-30 12:29:25.841 DEBUG: There is a single atom floating around
2022-12-30 12:29:26.285 DEBUG: Atoms are too close
2022-12-30 12:29:27.546 DEBUG: There is a single atom floating around
2022-12-30 12:29:28.130 DEBUG: There is a single atom floating around
2022-12-30 12:29:29.315 DEBUG: There is a single atom floating around
2022-12-30 12:29:29.660 DEBUG: Atoms are too close
2022-12-30 12:29:30.458 DEBUG: Atoms are too close
2022-12-30 12:29:32.512 DEBUG: Atoms are too close
2022-12-30 12:29:33.665 DEBUG: Atoms are too close
2022-12-30 12:29:33.666 DEBUG: Atoms are too close
2022-12-30 12:29:33.666 DEBUG: There is a single atom floating around
2022-12-30 12:29:33.667 DEBUG: There is a single atom floating around
2022-12-30 12:29:34.679 DEBUG: There is a single atom floating around
2022-12-30 12:29:35.906 DEBUG: Atoms are too close
2022-12-30 12:29:36.351 DEBUG: There is a single atom floating around
2022-12-30 12:29:36.680 INFO: Training rollout: return=-13.743 (9.3), episode length=3.8
2022-12-30 12:29:36.681 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-30 12:29:36.685 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-0_train.pkl
2022-12-30 12:29:37.991 DEBUG: Taking gradient step
2022-12-30 12:29:38.003 DEBUG: Loss 0: {'policy_loss': 0.028799227106426403, 'entropy_loss': -0.04379872418940067, 'vf_loss': 0.22980807641413648, 'total_loss': -0.014999497082974267, 'approx_kl': -4.090058247641082e-08, 'clip_fraction': 0.0, 'grad_norm': 10.241655349731445}
2022-12-30 12:29:39.377 DEBUG: Early stopping at step 1 for reaching max KL.
2022-12-30 12:29:39.377 INFO: Optimization: policy loss=0.029, vf loss=0.230, entropy loss=-0.044, total loss=-0.015, num steps=1
2022-12-30 12:29:39.378 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-30 12:29:40.577 INFO: Evaluation rollout: return=0.475 (0.0), episode length=5.0
2022-12-30 12:29:40.579 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-30 12:29:40.583 DEBUG: Saving model: runs/CH4_int/models/CH4_int_run-1_steps-216.model
2022-12-30 12:29:40.631 INFO: Iteration: 1/137, steps: 216
2022-12-30 12:29:42.804 DEBUG: There is a single atom floating around
2022-12-30 12:29:42.805 DEBUG: There is a single atom floating around
2022-12-30 12:29:43.514 DEBUG: There is a single atom floating around
2022-12-30 12:29:44.314 DEBUG: Atoms are too close
2022-12-30 12:29:45.781 DEBUG: Atoms are too close
2022-12-30 12:29:47.595 DEBUG: Atoms are too close
2022-12-30 12:29:48.963 DEBUG: Atoms are too close
2022-12-30 12:29:50.668 DEBUG: Atoms are too close
2022-12-30 12:29:50.670 DEBUG: Atoms are too close
2022-12-30 12:29:51.437 DEBUG: Atoms are too close
2022-12-30 12:29:51.549 DEBUG: There is a single atom floating around
2022-12-30 12:29:54.359 DEBUG: Atoms are too close
2022-12-30 12:29:55.690 DEBUG: There is a single atom floating around
2022-12-30 12:29:55.925 DEBUG: There is a single atom floating around
2022-12-30 12:29:58.449 DEBUG: There is a single atom floating around
2022-12-30 12:29:59.257 DEBUG: There is a single atom floating around
2022-12-30 12:30:00.154 DEBUG: Atoms are too close
2022-12-30 12:30:00.386 DEBUG: Atoms are too close
2022-12-30 12:30:01.846 DEBUG: Atoms are too close
2022-12-30 12:30:02.320 DEBUG: There is a single atom floating around
2022-12-30 12:30:05.216 DEBUG: There is a single atom floating around
2022-12-30 12:30:08.057 DEBUG: There is a single atom floating around
2022-12-30 12:30:08.058 DEBUG: Atoms are too close
2022-12-30 12:30:08.059 DEBUG: There is a single atom floating around
2022-12-30 12:30:09.317 DEBUG: Atoms are too close
2022-12-30 12:30:10.456 DEBUG: There is a single atom floating around
2022-12-30 12:30:11.142 DEBUG: Atoms are too close
2022-12-30 12:30:11.920 DEBUG: There is a single atom floating around
2022-12-30 12:30:13.431 DEBUG: Atoms are too close
2022-12-30 12:30:14.424 DEBUG: There is a single atom floating around
2022-12-30 12:30:14.426 DEBUG: Atoms are too close
2022-12-30 12:30:14.427 DEBUG: There is a single atom floating around
2022-12-30 12:30:16.122 DEBUG: There is a single atom floating around
2022-12-30 12:30:17.139 DEBUG: There is a single atom floating around
2022-12-30 12:30:17.272 INFO: Training rollout: return=-13.112 (9.5), episode length=3.7
2022-12-30 12:30:17.273 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-30 12:30:17.276 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-216_train.pkl
2022-12-30 12:30:18.566 DEBUG: Taking gradient step
2022-12-30 12:30:18.577 DEBUG: Loss 0: {'policy_loss': 9.476922570232174e-06, 'entropy_loss': -0.04422823805361986, 'vf_loss': 0.1949661603762281, 'total_loss': -0.04421876113104963, 'approx_kl': 2.1498030022826242e-08, 'clip_fraction': 0.0, 'grad_norm': 24.944992065429688}
2022-12-30 12:30:19.799 DEBUG: Early stopping at step 1 for reaching max KL.
2022-12-30 12:30:19.800 INFO: Optimization: policy loss=0.000, vf loss=0.195, entropy loss=-0.044, total loss=-0.044, num steps=1
2022-12-30 12:30:19.800 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-30 12:30:21.014 INFO: Evaluation rollout: return=0.528 (0.0), episode length=5.0
2022-12-30 12:30:21.015 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-30 12:30:21.018 INFO: Iteration: 2/137, steps: 432
2022-12-30 12:30:22.553 DEBUG: There is a single atom floating around
2022-12-30 12:30:22.788 DEBUG: There is a single atom floating around
2022-12-30 12:30:23.024 DEBUG: There is a single atom floating around
2022-12-30 12:30:31.566 DEBUG: There is a single atom floating around
2022-12-30 12:30:31.568 DEBUG: Atoms are too close
2022-12-30 12:30:31.568 DEBUG: There is a single atom floating around
2022-12-30 12:30:31.777 DEBUG: Atoms are too close
2022-12-30 12:30:33.895 DEBUG: Atoms are too close
2022-12-30 12:30:34.113 DEBUG: Atoms are too close
2022-12-30 12:30:34.367 DEBUG: Atoms are too close
2022-12-30 12:30:34.588 DEBUG: There is a single atom floating around
2022-12-30 12:30:35.284 DEBUG: There is a single atom floating around
2022-12-30 12:30:38.349 DEBUG: There is a single atom floating around
2022-12-30 12:30:38.576 DEBUG: There is a single atom floating around
2022-12-30 12:30:38.808 DEBUG: There is a single atom floating around
2022-12-30 12:30:39.519 DEBUG: There is a single atom floating around
2022-12-30 12:30:41.375 DEBUG: Atoms are too close
2022-12-30 12:30:41.377 DEBUG: Atoms are too close
2022-12-30 12:30:43.903 DEBUG: Atoms are too close
2022-12-30 12:30:43.904 DEBUG: There is a single atom floating around
2022-12-30 12:30:48.366 DEBUG: Atoms are too close
2022-12-30 12:30:49.695 DEBUG: Atoms are too close
2022-12-30 12:30:51.533 DEBUG: Atoms are too close
2022-12-30 12:30:52.353 DEBUG: Atoms are too close
2022-12-30 12:30:56.131 DEBUG: There is a single atom floating around
2022-12-30 12:31:00.811 INFO: Training rollout: return=-11.066 (10.0), episode length=4.2
2022-12-30 12:31:00.812 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-30 12:31:00.815 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-432_train.pkl
2022-12-30 12:31:02.111 DEBUG: Taking gradient step
2022-12-30 12:31:02.121 DEBUG: Loss 0: {'policy_loss': 0.06951702199182748, 'entropy_loss': -0.04529158677905798, 'vf_loss': 0.17652091143197188, 'total_loss': 0.0242254352127695, 'approx_kl': -4.536317099734788e-08, 'clip_fraction': 0.0, 'grad_norm': 18.85520362854004}
2022-12-30 12:31:03.399 DEBUG: Early stopping at step 1 for reaching max KL.
2022-12-30 12:31:03.400 INFO: Optimization: policy loss=0.070, vf loss=0.177, entropy loss=-0.045, total loss=0.024, num steps=1
2022-12-30 12:31:03.400 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-30 12:31:04.626 INFO: Evaluation rollout: return=0.559 (0.0), episode length=5.0
2022-12-30 12:31:04.627 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-30 12:31:04.630 INFO: Iteration: 3/137, steps: 648
2022-12-30 12:31:06.599 DEBUG: There is a single atom floating around
2022-12-30 12:31:06.600 DEBUG: There is a single atom floating around
2022-12-30 12:31:07.061 DEBUG: There is a single atom floating around
2022-12-30 12:31:07.272 DEBUG: There is a single atom floating around
2022-12-30 12:31:07.274 DEBUG: There is a single atom floating around
2022-12-30 12:31:07.480 DEBUG: There is a single atom floating around
2022-12-30 12:31:10.368 DEBUG: There is a single atom floating around
2022-12-30 12:31:11.738 DEBUG: There is a single atom floating around
2022-12-30 12:31:13.122 DEBUG: There is a single atom floating around
2022-12-30 12:31:13.362 DEBUG: There is a single atom floating around
2022-12-30 12:31:17.767 DEBUG: Atoms are too close
2022-12-30 12:31:21.729 DEBUG: There is a single atom floating around
2022-12-30 12:31:22.827 DEBUG: There is a single atom floating around
2022-12-30 12:31:24.331 DEBUG: There is a single atom floating around
2022-12-30 12:31:30.295 DEBUG: Atoms are too close
2022-12-30 12:31:31.911 DEBUG: There is a single atom floating around
2022-12-30 12:31:33.764 DEBUG: There is a single atom floating around
2022-12-30 12:31:33.766 DEBUG: Atoms are too close
2022-12-30 12:31:34.411 DEBUG: Atoms are too close
2022-12-30 12:31:34.953 DEBUG: There is a single atom floating around
2022-12-30 12:31:43.387 INFO: Training rollout: return=-8.751 (10.1), episode length=4.3
2022-12-30 12:31:43.389 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-30 12:31:43.392 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-648_train.pkl
2022-12-30 12:31:44.358 DEBUG: Taking gradient step
2022-12-30 12:31:44.366 DEBUG: Loss 0: {'policy_loss': 0.015685095279893556, 'entropy_loss': -0.04345886316150427, 'vf_loss': 0.12997507254172136, 'total_loss': -0.027773767881610716, 'approx_kl': 5.362865884706025e-08, 'clip_fraction': 0.0, 'grad_norm': 17.740007400512695}
2022-12-30 12:31:45.345 DEBUG: Early stopping at step 1 for reaching max KL.
2022-12-30 12:31:45.345 INFO: Optimization: policy loss=0.016, vf loss=0.130, entropy loss=-0.043, total loss=-0.028, num steps=1
2022-12-30 12:31:45.345 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-30 12:31:46.500 INFO: Evaluation rollout: return=0.586 (0.0), episode length=5.0
2022-12-30 12:31:46.501 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-30 12:31:46.504 INFO: Iteration: 4/137, steps: 864
2022-12-30 12:31:49.675 DEBUG: There is a single atom floating around
2022-12-30 12:31:49.676 DEBUG: There is a single atom floating around
2022-12-30 12:31:54.137 DEBUG: There is a single atom floating around
2022-12-30 12:32:09.958 INFO: {
    "bag_scale": 5,
    "beta": "-10",
    "canvas_size": 5,
    "clip_ratio": 0.2,
    "cutoff": 4.0,
    "data_dir": "runs/CH4_int/data",
    "device": "cuda",
    "discount": 1.0,
    "entropy_coef": 0.06,
    "eval_formulas": "CH4",
    "eval_freq": 1,
    "formulas": "CH4",
    "gradient_clip": 0.5,
    "keep_models": false,
    "lam": 1.0,
    "learning_rate": 0.0005,
    "load_latest": false,
    "load_model": null,
    "log_dir": "runs/CH4_int/logs",
    "log_level": "DEBUG",
    "max_mean_distance": 1.8,
    "max_num_steps": 30000,
    "max_num_train_iters": 10,
    "max_solo_distance": 2.0,
    "maxl": 4,
    "min_atomic_distance": 0.6,
    "min_mean_distance": 0.8,
    "min_reward": -20.0,
    "mini_batch_size": 64,
    "model": "schnet_edge",
    "model_dir": "runs/CH4_int/models",
    "name": "CH4_int",
    "network_width": 128,
    "num_cg_levels": 3,
    "num_channels_hidden": 10,
    "num_channels_per_element": 4,
    "num_envs": 12,
    "num_eval_episodes": null,
    "num_gaussians": 3,
    "num_interactions": 3,
    "num_steps_per_iter": 216,
    "optimizer": "adam",
    "results_dir": "runs/CH4_int/results",
    "save_freq": 10,
    "save_rollouts": "train",
    "seed": 1,
    "symbols": "X,H,C",
    "target_kl": 0.03,
    "update_edges": true,
    "vf_coef": 0.001
}
2022-12-30 12:32:09.999 INFO: CUDA Device: 0
2022-12-30 12:32:10.000 INFO: Training bags: ['CH4']
2022-12-30 12:32:10.000 INFO: Evaluation bags: ['CH4']
2022-12-30 12:32:12.170 INFO: Number of parameters: 548381
2022-12-30 12:32:12.182 INFO: Starting PPO
2022-12-30 12:32:12.182 INFO: Iteration: 0/137, steps: 0
2022-12-30 12:32:15.026 DEBUG: There is a single atom floating around
2022-12-30 12:32:15.261 DEBUG: There is a single atom floating around
2022-12-30 12:32:15.726 DEBUG: There is a single atom floating around
2022-12-30 12:32:15.728 DEBUG: There is a single atom floating around
2022-12-30 12:32:16.415 DEBUG: There is a single atom floating around
2022-12-30 12:32:20.839 DEBUG: Atoms are too close
2022-12-30 12:32:21.919 DEBUG: Atoms are too close
2022-12-30 12:32:26.353 DEBUG: Atoms are too close
2022-12-30 12:32:26.581 DEBUG: There is a single atom floating around
2022-12-30 12:32:26.582 DEBUG: There is a single atom floating around
2022-12-30 12:32:26.809 DEBUG: Atoms are too close
2022-12-30 12:32:27.040 DEBUG: There is a single atom floating around
2022-12-30 12:32:27.813 DEBUG: Atoms are too close
2022-12-30 12:32:28.966 DEBUG: Atoms are too close
2022-12-30 12:32:30.441 DEBUG: Atoms are too close
2022-12-30 12:32:32.735 DEBUG: Atoms are too close
2022-12-30 12:32:33.801 DEBUG: Atoms are too close
2022-12-30 12:32:34.367 DEBUG: Atoms are too close
2022-12-30 12:32:35.290 DEBUG: Atoms are too close
2022-12-30 12:32:36.556 DEBUG: There is a single atom floating around
2022-12-30 12:32:38.108 DEBUG: There is a single atom floating around
2022-12-30 12:32:38.109 DEBUG: There is a single atom floating around
2022-12-30 12:32:38.440 DEBUG: There is a single atom floating around
2022-12-30 12:32:38.910 DEBUG: Atoms are too close
2022-12-30 12:32:40.181 DEBUG: There is a single atom floating around
2022-12-30 12:32:40.775 DEBUG: There is a single atom floating around
2022-12-30 12:32:41.946 DEBUG: There is a single atom floating around
2022-12-30 12:32:42.322 DEBUG: Atoms are too close
2022-12-30 12:32:43.137 DEBUG: Atoms are too close
2022-12-30 12:32:45.200 DEBUG: Atoms are too close
2022-12-30 12:32:46.362 DEBUG: Atoms are too close
2022-12-30 12:32:46.363 DEBUG: Atoms are too close
2022-12-30 12:32:46.364 DEBUG: There is a single atom floating around
2022-12-30 12:32:46.365 DEBUG: There is a single atom floating around
2022-12-30 12:32:47.403 DEBUG: There is a single atom floating around
2022-12-30 12:32:48.654 DEBUG: Atoms are too close
2022-12-30 12:32:49.118 DEBUG: There is a single atom floating around
2022-12-30 12:32:49.446 INFO: Training rollout: return=-13.743 (9.3), episode length=3.8
2022-12-30 12:32:49.447 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-30 12:32:49.450 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-0_train.pkl
2022-12-30 12:32:50.706 DEBUG: Taking gradient step
2022-12-30 12:32:50.717 DEBUG: Loss 0: {'policy_loss': 0.02879921809187021, 'entropy_loss': -0.04379872418940067, 'vf_loss': 0.22980807633018385, 'total_loss': -0.014999506097530466, 'approx_kl': -4.6178077361958e-08, 'clip_fraction': 0.0, 'grad_norm': 10.241655349731445}
2022-12-30 12:32:51.996 DEBUG: Early stopping at step 1 for reaching max KL.
2022-12-30 12:32:51.997 INFO: Optimization: policy loss=0.029, vf loss=0.230, entropy loss=-0.044, total loss=-0.015, num steps=1
2022-12-30 12:32:51.997 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-30 12:32:53.260 INFO: Evaluation rollout: return=0.475 (0.0), episode length=5.0
2022-12-30 12:32:53.262 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-30 12:32:53.265 DEBUG: Saving model: runs/CH4_int/models/CH4_int_run-1_steps-216.model
2022-12-30 12:32:53.315 INFO: Iteration: 1/137, steps: 216
2022-12-30 12:32:55.367 DEBUG: There is a single atom floating around
2022-12-30 12:32:55.369 DEBUG: There is a single atom floating around
2022-12-30 12:32:56.144 DEBUG: There is a single atom floating around
2022-12-30 12:33:55.252 INFO: {
    "bag_scale": 5,
    "beta": "-10",
    "canvas_size": 5,
    "clip_ratio": 0.2,
    "cutoff": 4.0,
    "data_dir": "runs/CH4_int/data",
    "device": "cuda",
    "discount": 1.0,
    "entropy_coef": 0.06,
    "eval_formulas": "CH4",
    "eval_freq": 1,
    "formulas": "CH4",
    "gradient_clip": 0.5,
    "keep_models": false,
    "lam": 1.0,
    "learning_rate": 0.0005,
    "load_latest": false,
    "load_model": null,
    "log_dir": "runs/CH4_int/logs",
    "log_level": "DEBUG",
    "max_mean_distance": 1.8,
    "max_num_steps": 30000,
    "max_num_train_iters": 10,
    "max_solo_distance": 2.0,
    "maxl": 4,
    "min_atomic_distance": 0.6,
    "min_mean_distance": 0.8,
    "min_reward": -20.0,
    "mini_batch_size": 64,
    "model": "schnet_edge",
    "model_dir": "runs/CH4_int/models",
    "name": "CH4_int",
    "network_width": 128,
    "num_cg_levels": 3,
    "num_channels_hidden": 10,
    "num_channels_per_element": 4,
    "num_envs": 12,
    "num_eval_episodes": null,
    "num_gaussians": 3,
    "num_interactions": 3,
    "num_steps_per_iter": 216,
    "optimizer": "adam",
    "results_dir": "runs/CH4_int/results",
    "save_freq": 10,
    "save_rollouts": "train",
    "seed": 1,
    "symbols": "X,H,C",
    "target_kl": 0.03,
    "update_edges": true,
    "vf_coef": 0.001
}
2022-12-30 12:33:55.290 INFO: CUDA Device: 0
2022-12-30 12:33:55.291 INFO: Training bags: ['CH4']
2022-12-30 12:33:55.291 INFO: Evaluation bags: ['CH4']
2022-12-30 12:33:57.320 INFO: Number of parameters: 548381
2022-12-30 12:33:57.331 INFO: Starting PPO
2022-12-30 12:33:57.331 INFO: Iteration: 0/137, steps: 0
2022-12-30 12:34:00.235 DEBUG: There is a single atom floating around
2022-12-30 12:34:00.476 DEBUG: There is a single atom floating around
2022-12-30 12:34:00.936 DEBUG: There is a single atom floating around
2022-12-30 12:34:00.937 DEBUG: There is a single atom floating around
2022-12-30 12:34:01.639 DEBUG: There is a single atom floating around
2022-12-30 12:34:06.166 DEBUG: Atoms are too close
2022-12-30 12:34:07.172 DEBUG: Atoms are too close
2022-12-30 12:34:11.438 DEBUG: Atoms are too close
2022-12-30 12:34:11.660 DEBUG: There is a single atom floating around
2022-12-30 12:34:11.662 DEBUG: There is a single atom floating around
2022-12-30 12:34:11.899 DEBUG: Atoms are too close
2022-12-30 12:34:12.121 DEBUG: There is a single atom floating around
2022-12-30 12:34:12.862 DEBUG: Atoms are too close
2022-12-30 12:34:13.987 DEBUG: Atoms are too close
2022-12-30 12:34:15.409 DEBUG: Atoms are too close
2022-12-30 12:34:17.634 DEBUG: Atoms are too close
2022-12-30 12:34:18.647 DEBUG: Atoms are too close
2022-12-30 12:34:19.171 DEBUG: Atoms are too close
2022-12-30 12:34:20.048 DEBUG: Atoms are too close
2022-12-30 12:34:21.246 DEBUG: There is a single atom floating around
2022-12-30 12:34:22.683 DEBUG: There is a single atom floating around
2022-12-30 12:34:22.685 DEBUG: There is a single atom floating around
2022-12-30 12:34:22.978 DEBUG: There is a single atom floating around
2022-12-30 12:34:23.418 DEBUG: Atoms are too close
2022-12-30 12:34:24.628 DEBUG: There is a single atom floating around
2022-12-30 12:34:25.167 DEBUG: There is a single atom floating around
2022-12-30 12:34:26.260 DEBUG: There is a single atom floating around
2022-12-30 12:34:26.581 DEBUG: Atoms are too close
2022-12-30 12:34:27.336 DEBUG: Atoms are too close
2022-12-30 12:34:29.275 DEBUG: Atoms are too close
2022-12-30 12:34:30.341 DEBUG: Atoms are too close
2022-12-30 12:34:30.343 DEBUG: Atoms are too close
2022-12-30 12:34:30.344 DEBUG: There is a single atom floating around
2022-12-30 12:34:30.345 DEBUG: There is a single atom floating around
2022-12-30 12:34:31.318 DEBUG: There is a single atom floating around
2022-12-30 12:34:32.473 DEBUG: Atoms are too close
2022-12-30 12:34:32.929 DEBUG: There is a single atom floating around
2022-12-30 12:34:33.214 INFO: Training rollout: return=-13.743 (9.3), episode length=3.8
2022-12-30 12:34:33.214 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-30 12:34:33.217 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-0_train.pkl
2022-12-30 12:35:05.417 INFO: {
    "bag_scale": 5,
    "beta": "-10",
    "canvas_size": 5,
    "clip_ratio": 0.2,
    "cutoff": 4.0,
    "data_dir": "runs/CH4_int/data",
    "device": "cuda",
    "discount": 1.0,
    "entropy_coef": 0.06,
    "eval_formulas": "CH4",
    "eval_freq": 1,
    "formulas": "CH4",
    "gradient_clip": 0.5,
    "keep_models": false,
    "lam": 1.0,
    "learning_rate": 0.0005,
    "load_latest": false,
    "load_model": null,
    "log_dir": "runs/CH4_int/logs",
    "log_level": "DEBUG",
    "max_mean_distance": 1.8,
    "max_num_steps": 30000,
    "max_num_train_iters": 10,
    "max_solo_distance": 2.0,
    "maxl": 4,
    "min_atomic_distance": 0.6,
    "min_mean_distance": 0.8,
    "min_reward": -20.0,
    "mini_batch_size": 64,
    "model": "schnet_edge",
    "model_dir": "runs/CH4_int/models",
    "name": "CH4_int",
    "network_width": 128,
    "num_cg_levels": 3,
    "num_channels_hidden": 10,
    "num_channels_per_element": 4,
    "num_envs": 12,
    "num_eval_episodes": null,
    "num_gaussians": 3,
    "num_interactions": 3,
    "num_steps_per_iter": 216,
    "optimizer": "adam",
    "results_dir": "runs/CH4_int/results",
    "save_freq": 10,
    "save_rollouts": "train",
    "seed": 1,
    "symbols": "X,H,C",
    "target_kl": 0.03,
    "update_edges": true,
    "vf_coef": 0.001
}
2022-12-30 12:35:05.454 INFO: CUDA Device: 0
2022-12-30 12:35:05.455 INFO: Training bags: ['CH4']
2022-12-30 12:35:05.455 INFO: Evaluation bags: ['CH4']
2022-12-30 12:35:07.626 INFO: Number of parameters: 548381
2022-12-30 12:35:07.638 INFO: Starting PPO
2022-12-30 12:35:07.638 INFO: Iteration: 0/137, steps: 0
2022-12-30 12:35:10.567 DEBUG: There is a single atom floating around
2022-12-30 12:35:10.821 DEBUG: There is a single atom floating around
2022-12-30 12:35:11.283 DEBUG: There is a single atom floating around
2022-12-30 12:35:11.285 DEBUG: There is a single atom floating around
2022-12-30 12:35:11.991 DEBUG: There is a single atom floating around
2022-12-30 12:35:16.588 DEBUG: Atoms are too close
2022-12-30 12:35:17.652 DEBUG: Atoms are too close
2022-12-30 12:35:22.317 DEBUG: Atoms are too close
2022-12-30 12:35:22.539 DEBUG: There is a single atom floating around
2022-12-30 12:35:22.541 DEBUG: There is a single atom floating around
2022-12-30 12:35:22.791 DEBUG: Atoms are too close
2022-12-30 12:35:23.036 DEBUG: There is a single atom floating around
2022-12-30 12:35:23.861 DEBUG: Atoms are too close
2022-12-30 12:35:25.077 DEBUG: Atoms are too close
2022-12-30 12:35:26.649 DEBUG: Atoms are too close
2022-12-30 12:35:29.058 DEBUG: Atoms are too close
2022-12-30 12:35:30.156 DEBUG: Atoms are too close
2022-12-30 12:35:30.740 DEBUG: Atoms are too close
2022-12-30 12:35:31.704 DEBUG: Atoms are too close
2022-12-30 12:35:33.020 DEBUG: There is a single atom floating around
2022-12-30 12:35:34.602 DEBUG: There is a single atom floating around
2022-12-30 12:35:34.603 DEBUG: There is a single atom floating around
2022-12-30 12:35:34.944 DEBUG: There is a single atom floating around
2022-12-30 12:35:35.429 DEBUG: Atoms are too close
2022-12-30 12:35:36.737 DEBUG: There is a single atom floating around
2022-12-30 12:35:37.357 DEBUG: There is a single atom floating around
2022-12-30 12:35:38.612 DEBUG: There is a single atom floating around
2022-12-30 12:35:38.987 DEBUG: Atoms are too close
2022-12-30 12:35:39.866 DEBUG: Atoms are too close
2022-12-30 12:35:42.051 DEBUG: Atoms are too close
2022-12-30 12:35:43.302 DEBUG: Atoms are too close
2022-12-30 12:35:43.304 DEBUG: Atoms are too close
2022-12-30 12:35:43.305 DEBUG: There is a single atom floating around
2022-12-30 12:35:43.305 DEBUG: There is a single atom floating around
2022-12-30 12:35:44.390 DEBUG: There is a single atom floating around
2022-12-30 12:35:45.737 DEBUG: Atoms are too close
2022-12-30 12:35:46.223 DEBUG: There is a single atom floating around
2022-12-30 12:35:46.545 INFO: Training rollout: return=-13.743 (9.3), episode length=3.8
2022-12-30 12:35:46.545 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-30 12:35:46.548 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-0_train.pkl
2022-12-30 12:39:40.824 INFO: {
    "bag_scale": 5,
    "beta": "-10",
    "canvas_size": 5,
    "clip_ratio": 0.2,
    "cutoff": 4.0,
    "data_dir": "runs/CH4_int/data",
    "device": "cuda",
    "discount": 1.0,
    "entropy_coef": 0.06,
    "eval_formulas": "CH4",
    "eval_freq": 1,
    "formulas": "CH4",
    "gradient_clip": 0.5,
    "keep_models": false,
    "lam": 1.0,
    "learning_rate": 0.0005,
    "load_latest": false,
    "load_model": null,
    "log_dir": "runs/CH4_int/logs",
    "log_level": "DEBUG",
    "max_mean_distance": 1.8,
    "max_num_steps": 30000,
    "max_num_train_iters": 10,
    "max_solo_distance": 2.0,
    "maxl": 4,
    "min_atomic_distance": 0.6,
    "min_mean_distance": 0.8,
    "min_reward": -20.0,
    "mini_batch_size": 64,
    "model": "schnet_edge",
    "model_dir": "runs/CH4_int/models",
    "name": "CH4_int",
    "network_width": 128,
    "num_cg_levels": 3,
    "num_channels_hidden": 10,
    "num_channels_per_element": 4,
    "num_envs": 12,
    "num_eval_episodes": null,
    "num_gaussians": 3,
    "num_interactions": 3,
    "num_steps_per_iter": 216,
    "optimizer": "adam",
    "results_dir": "runs/CH4_int/results",
    "save_freq": 10,
    "save_rollouts": "train",
    "seed": 1,
    "symbols": "X,H,C",
    "target_kl": 0.03,
    "update_edges": true,
    "vf_coef": 0.001
}
2022-12-30 12:39:40.870 INFO: CUDA Device: 0
2022-12-30 12:39:40.871 INFO: Training bags: ['CH4']
2022-12-30 12:39:40.872 INFO: Evaluation bags: ['CH4']
2022-12-30 12:39:43.133 INFO: Number of parameters: 548381
2022-12-30 12:39:43.147 INFO: Starting PPO
2022-12-30 12:39:43.148 INFO: Iteration: 0/137, steps: 0
2022-12-30 12:39:46.179 DEBUG: There is a single atom floating around
2022-12-30 12:39:46.450 DEBUG: There is a single atom floating around
2022-12-30 12:39:46.944 DEBUG: There is a single atom floating around
2022-12-30 12:39:46.945 DEBUG: There is a single atom floating around
2022-12-30 12:39:47.691 DEBUG: There is a single atom floating around
2022-12-30 12:39:52.415 DEBUG: Atoms are too close
2022-12-30 12:39:53.503 DEBUG: Atoms are too close
2022-12-30 12:39:58.314 DEBUG: Atoms are too close
2022-12-30 12:39:58.570 DEBUG: There is a single atom floating around
2022-12-30 12:39:58.570 DEBUG: There is a single atom floating around
2022-12-30 12:39:58.825 DEBUG: Atoms are too close
2022-12-30 12:39:59.092 DEBUG: There is a single atom floating around
2022-12-30 12:39:59.937 DEBUG: Atoms are too close
2022-12-30 12:40:01.209 DEBUG: Atoms are too close
2022-12-30 12:40:02.812 DEBUG: Atoms are too close
2022-12-30 12:40:05.270 DEBUG: Atoms are too close
2022-12-30 12:40:06.381 DEBUG: Atoms are too close
2022-12-30 12:40:06.976 DEBUG: Atoms are too close
2022-12-30 12:40:07.956 DEBUG: Atoms are too close
2022-12-30 12:40:09.223 DEBUG: There is a single atom floating around
2022-12-30 12:40:10.874 DEBUG: There is a single atom floating around
2022-12-30 12:40:10.877 DEBUG: There is a single atom floating around
2022-12-30 12:40:11.179 DEBUG: There is a single atom floating around
2022-12-30 12:40:11.703 DEBUG: Atoms are too close
2022-12-30 12:40:13.019 DEBUG: There is a single atom floating around
2022-12-30 12:40:13.639 DEBUG: There is a single atom floating around
2022-12-30 12:40:14.825 DEBUG: There is a single atom floating around
2022-12-30 12:40:15.194 DEBUG: Atoms are too close
2022-12-30 12:40:16.044 DEBUG: Atoms are too close
2022-12-30 12:40:18.182 DEBUG: Atoms are too close
2022-12-30 12:40:19.327 DEBUG: Atoms are too close
2022-12-30 12:40:19.330 DEBUG: Atoms are too close
2022-12-30 12:40:19.331 DEBUG: There is a single atom floating around
2022-12-30 12:40:19.332 DEBUG: There is a single atom floating around
2022-12-30 12:40:20.402 DEBUG: There is a single atom floating around
2022-12-30 12:40:21.677 DEBUG: Atoms are too close
2022-12-30 12:40:22.150 DEBUG: There is a single atom floating around
2022-12-30 12:40:22.463 INFO: Training rollout: return=-13.743 (9.3), episode length=3.8
2022-12-30 12:40:22.463 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-30 12:40:22.467 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-0_train.pkl
2022-12-30 12:50:16.911 INFO: {
    "bag_scale": 5,
    "beta": "-10",
    "canvas_size": 5,
    "clip_ratio": 0.2,
    "cutoff": 4.0,
    "data_dir": "runs/CH4_int/data",
    "device": "cuda",
    "discount": 1.0,
    "entropy_coef": 0.06,
    "eval_formulas": "CH4",
    "eval_freq": 1,
    "formulas": "CH4",
    "gradient_clip": 0.5,
    "keep_models": false,
    "lam": 1.0,
    "learning_rate": 0.0005,
    "load_latest": false,
    "load_model": null,
    "log_dir": "runs/CH4_int/logs",
    "log_level": "DEBUG",
    "max_mean_distance": 1.8,
    "max_num_steps": 30000,
    "max_num_train_iters": 10,
    "max_solo_distance": 2.0,
    "maxl": 4,
    "min_atomic_distance": 0.6,
    "min_mean_distance": 0.8,
    "min_reward": -20.0,
    "mini_batch_size": 64,
    "model": "schnet_edge",
    "model_dir": "runs/CH4_int/models",
    "name": "CH4_int",
    "network_width": 128,
    "num_cg_levels": 3,
    "num_channels_hidden": 10,
    "num_channels_per_element": 4,
    "num_envs": 12,
    "num_eval_episodes": null,
    "num_gaussians": 3,
    "num_interactions": 3,
    "num_steps_per_iter": 216,
    "optimizer": "adam",
    "results_dir": "runs/CH4_int/results",
    "save_freq": 10,
    "save_rollouts": "train",
    "seed": 1,
    "symbols": "X,H,C",
    "target_kl": 0.03,
    "update_edges": true,
    "vf_coef": 0.001
}
2022-12-30 12:50:16.954 INFO: CUDA Device: 0
2022-12-30 12:50:16.955 INFO: Training bags: ['CH4']
2022-12-30 12:50:16.955 INFO: Evaluation bags: ['CH4']
2022-12-30 12:50:19.195 INFO: Number of parameters: 548381
2022-12-30 12:50:19.207 INFO: Starting PPO
2022-12-30 12:50:19.207 INFO: Iteration: 0/137, steps: 0
2022-12-30 12:52:09.195 INFO: {
    "bag_scale": 5,
    "beta": "-10",
    "canvas_size": 5,
    "clip_ratio": 0.2,
    "cutoff": 4.0,
    "data_dir": "runs/CH4_int/data",
    "device": "cuda",
    "discount": 1.0,
    "entropy_coef": 0.06,
    "eval_formulas": "CH4",
    "eval_freq": 1,
    "formulas": "CH4",
    "gradient_clip": 0.5,
    "keep_models": false,
    "lam": 1.0,
    "learning_rate": 0.0005,
    "load_latest": false,
    "load_model": null,
    "log_dir": "runs/CH4_int/logs",
    "log_level": "DEBUG",
    "max_mean_distance": 1.8,
    "max_num_steps": 30000,
    "max_num_train_iters": 10,
    "max_solo_distance": 2.0,
    "maxl": 4,
    "min_atomic_distance": 0.6,
    "min_mean_distance": 0.8,
    "min_reward": -20.0,
    "mini_batch_size": 64,
    "model": "schnet_edge",
    "model_dir": "runs/CH4_int/models",
    "name": "CH4_int",
    "network_width": 128,
    "num_cg_levels": 3,
    "num_channels_hidden": 10,
    "num_channels_per_element": 4,
    "num_envs": 12,
    "num_eval_episodes": null,
    "num_gaussians": 3,
    "num_interactions": 3,
    "num_steps_per_iter": 216,
    "optimizer": "adam",
    "results_dir": "runs/CH4_int/results",
    "save_freq": 10,
    "save_rollouts": "train",
    "seed": 1,
    "symbols": "X,H,C",
    "target_kl": 0.03,
    "update_edges": true,
    "vf_coef": 0.001
}
2022-12-30 12:52:09.231 INFO: CUDA Device: 0
2022-12-30 12:52:09.232 INFO: Training bags: ['CH4']
2022-12-30 12:52:09.232 INFO: Evaluation bags: ['CH4']
2022-12-30 12:52:11.606 INFO: Number of parameters: 548381
2022-12-30 12:52:11.618 INFO: Starting PPO
2022-12-30 12:52:11.618 INFO: Iteration: 0/137, steps: 0
2022-12-30 12:52:14.854 DEBUG: There is a single atom floating around
2022-12-30 12:52:15.105 DEBUG: There is a single atom floating around
2022-12-30 12:52:15.643 DEBUG: There is a single atom floating around
2022-12-30 12:52:15.645 DEBUG: There is a single atom floating around
2022-12-30 12:52:16.430 DEBUG: There is a single atom floating around
2022-12-30 12:52:21.695 DEBUG: Atoms are too close
2022-12-30 12:52:22.920 DEBUG: Atoms are too close
2022-12-30 12:52:28.114 DEBUG: Atoms are too close
2022-12-30 12:52:28.363 DEBUG: There is a single atom floating around
2022-12-30 12:52:28.365 DEBUG: There is a single atom floating around
2022-12-30 12:52:28.642 DEBUG: Atoms are too close
2022-12-30 12:52:28.901 DEBUG: There is a single atom floating around
2022-12-30 12:52:29.830 DEBUG: Atoms are too close
2022-12-30 12:52:31.147 DEBUG: Atoms are too close
2022-12-30 12:52:32.842 DEBUG: Atoms are too close
2022-12-30 12:52:35.520 DEBUG: Atoms are too close
2022-12-30 12:52:36.724 DEBUG: Atoms are too close
2022-12-30 12:52:37.337 DEBUG: Atoms are too close
2022-12-30 12:52:38.428 DEBUG: Atoms are too close
2022-12-30 12:52:39.852 DEBUG: There is a single atom floating around
2022-12-30 12:52:41.572 DEBUG: There is a single atom floating around
2022-12-30 12:52:41.574 DEBUG: There is a single atom floating around
2022-12-30 12:52:41.968 DEBUG: There is a single atom floating around
2022-12-30 12:52:42.504 DEBUG: Atoms are too close
2022-12-30 12:52:43.974 DEBUG: There is a single atom floating around
2022-12-30 12:52:44.633 DEBUG: There is a single atom floating around
2022-12-30 12:52:45.940 DEBUG: There is a single atom floating around
2022-12-30 12:52:46.344 DEBUG: Atoms are too close
2022-12-30 12:52:47.291 DEBUG: Atoms are too close
2022-12-30 12:52:49.711 DEBUG: Atoms are too close
2022-12-30 12:52:51.013 DEBUG: Atoms are too close
2022-12-30 12:52:51.015 DEBUG: Atoms are too close
2022-12-30 12:52:51.015 DEBUG: There is a single atom floating around
2022-12-30 12:52:51.016 DEBUG: There is a single atom floating around
2022-12-30 12:52:52.184 DEBUG: There is a single atom floating around
2022-12-30 12:52:53.625 DEBUG: Atoms are too close
2022-12-30 12:52:54.148 DEBUG: There is a single atom floating around
2022-12-30 12:52:54.526 INFO: Training rollout: return=-13.743 (9.3), episode length=3.8
2022-12-30 12:52:54.527 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-30 12:52:54.530 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-0_train.pkl
2022-12-30 12:53:38.428 INFO: {
    "bag_scale": 5,
    "beta": "-10",
    "canvas_size": 5,
    "clip_ratio": 0.2,
    "cutoff": 4.0,
    "data_dir": "runs/CH4_int/data",
    "device": "cuda",
    "discount": 1.0,
    "entropy_coef": 0.06,
    "eval_formulas": "CH4",
    "eval_freq": 1,
    "formulas": "CH4",
    "gradient_clip": 0.5,
    "keep_models": false,
    "lam": 1.0,
    "learning_rate": 0.0005,
    "load_latest": false,
    "load_model": null,
    "log_dir": "runs/CH4_int/logs",
    "log_level": "DEBUG",
    "max_mean_distance": 1.8,
    "max_num_steps": 30000,
    "max_num_train_iters": 10,
    "max_solo_distance": 2.0,
    "maxl": 4,
    "min_atomic_distance": 0.6,
    "min_mean_distance": 0.8,
    "min_reward": -20.0,
    "mini_batch_size": 64,
    "model": "schnet_edge",
    "model_dir": "runs/CH4_int/models",
    "name": "CH4_int",
    "network_width": 128,
    "num_cg_levels": 3,
    "num_channels_hidden": 10,
    "num_channels_per_element": 4,
    "num_envs": 12,
    "num_eval_episodes": null,
    "num_gaussians": 3,
    "num_interactions": 3,
    "num_steps_per_iter": 216,
    "optimizer": "adam",
    "results_dir": "runs/CH4_int/results",
    "save_freq": 10,
    "save_rollouts": "train",
    "seed": 1,
    "symbols": "X,H,C",
    "target_kl": 0.03,
    "update_edges": true,
    "vf_coef": 0.001
}
2022-12-30 12:53:38.468 INFO: CUDA Device: 0
2022-12-30 12:53:38.469 INFO: Training bags: ['CH4']
2022-12-30 12:53:38.469 INFO: Evaluation bags: ['CH4']
2022-12-30 12:53:40.964 INFO: Number of parameters: 548381
2022-12-30 12:53:40.976 INFO: Starting PPO
2022-12-30 12:53:40.976 INFO: Iteration: 0/137, steps: 0
2022-12-30 12:53:44.028 DEBUG: There is a single atom floating around
2022-12-30 12:53:44.277 DEBUG: There is a single atom floating around
2022-12-30 12:53:44.766 DEBUG: There is a single atom floating around
2022-12-30 12:53:44.767 DEBUG: There is a single atom floating around
2022-12-30 12:53:45.516 DEBUG: There is a single atom floating around
2022-12-30 12:53:50.254 DEBUG: Atoms are too close
2022-12-30 12:53:51.383 DEBUG: Atoms are too close
2022-12-30 12:53:56.241 DEBUG: Atoms are too close
2022-12-30 12:53:56.504 DEBUG: There is a single atom floating around
2022-12-30 12:53:56.505 DEBUG: There is a single atom floating around
2022-12-30 12:53:56.749 DEBUG: Atoms are too close
2022-12-30 12:53:56.997 DEBUG: There is a single atom floating around
2022-12-30 12:53:57.860 DEBUG: Atoms are too close
2022-12-30 12:53:59.123 DEBUG: Atoms are too close
2022-12-30 12:54:00.743 DEBUG: Atoms are too close
2022-12-30 12:54:03.250 DEBUG: Atoms are too close
2022-12-30 12:54:04.418 DEBUG: Atoms are too close
2022-12-30 12:54:05.049 DEBUG: Atoms are too close
2022-12-30 12:54:06.043 DEBUG: Atoms are too close
2022-12-30 12:54:07.407 DEBUG: There is a single atom floating around
2022-12-30 12:54:09.024 DEBUG: There is a single atom floating around
2022-12-30 12:54:09.027 DEBUG: There is a single atom floating around
2022-12-30 12:54:09.393 DEBUG: There is a single atom floating around
2022-12-30 12:54:09.914 DEBUG: Atoms are too close
2022-12-30 12:54:11.255 DEBUG: There is a single atom floating around
2022-12-30 12:54:11.874 DEBUG: There is a single atom floating around
2022-12-30 12:54:13.153 DEBUG: There is a single atom floating around
2022-12-30 12:54:13.523 DEBUG: Atoms are too close
2022-12-30 12:54:14.397 DEBUG: Atoms are too close
2022-12-30 12:54:16.630 DEBUG: Atoms are too close
2022-12-30 12:54:17.865 DEBUG: Atoms are too close
2022-12-30 12:54:17.867 DEBUG: Atoms are too close
2022-12-30 12:54:17.868 DEBUG: There is a single atom floating around
2022-12-30 12:54:17.868 DEBUG: There is a single atom floating around
2022-12-30 12:54:18.989 DEBUG: There is a single atom floating around
2022-12-30 12:54:20.371 DEBUG: Atoms are too close
2022-12-30 12:54:20.869 DEBUG: There is a single atom floating around
2022-12-30 12:54:21.241 INFO: Training rollout: return=-13.743 (9.3), episode length=3.8
2022-12-30 12:54:21.241 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-30 12:54:21.244 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-0_train.pkl
2022-12-30 12:55:42.021 INFO: {
    "bag_scale": 5,
    "beta": "-10",
    "canvas_size": 5,
    "clip_ratio": 0.2,
    "cutoff": 4.0,
    "data_dir": "runs/CH4_int/data",
    "device": "cuda",
    "discount": 1.0,
    "entropy_coef": 0.06,
    "eval_formulas": "CH4",
    "eval_freq": 1,
    "formulas": "CH4",
    "gradient_clip": 0.5,
    "keep_models": false,
    "lam": 1.0,
    "learning_rate": 0.0005,
    "load_latest": false,
    "load_model": null,
    "log_dir": "runs/CH4_int/logs",
    "log_level": "DEBUG",
    "max_mean_distance": 1.8,
    "max_num_steps": 30000,
    "max_num_train_iters": 10,
    "max_solo_distance": 2.0,
    "maxl": 4,
    "min_atomic_distance": 0.6,
    "min_mean_distance": 0.8,
    "min_reward": -20.0,
    "mini_batch_size": 64,
    "model": "schnet_edge",
    "model_dir": "runs/CH4_int/models",
    "name": "CH4_int",
    "network_width": 128,
    "num_cg_levels": 3,
    "num_channels_hidden": 10,
    "num_channels_per_element": 4,
    "num_envs": 12,
    "num_eval_episodes": null,
    "num_gaussians": 3,
    "num_interactions": 3,
    "num_steps_per_iter": 216,
    "optimizer": "adam",
    "results_dir": "runs/CH4_int/results",
    "save_freq": 10,
    "save_rollouts": "train",
    "seed": 1,
    "symbols": "X,H,C",
    "target_kl": 0.03,
    "update_edges": true,
    "vf_coef": 0.001
}
2022-12-30 12:55:42.055 INFO: CUDA Device: 0
2022-12-30 12:55:42.056 INFO: Training bags: ['CH4']
2022-12-30 12:55:42.056 INFO: Evaluation bags: ['CH4']
2022-12-30 12:55:44.094 INFO: Number of parameters: 548381
2022-12-30 12:55:44.105 INFO: Starting PPO
2022-12-30 12:55:44.105 INFO: Iteration: 0/137, steps: 0
2022-12-30 12:55:46.521 DEBUG: There is a single atom floating around
2022-12-30 12:55:46.724 DEBUG: There is a single atom floating around
2022-12-30 12:55:47.151 DEBUG: There is a single atom floating around
2022-12-30 12:55:47.153 DEBUG: There is a single atom floating around
2022-12-30 12:55:47.753 DEBUG: There is a single atom floating around
2022-12-30 12:55:51.677 DEBUG: Atoms are too close
2022-12-30 12:55:52.556 DEBUG: Atoms are too close
2022-12-30 12:55:56.510 DEBUG: Atoms are too close
2022-12-30 12:55:56.732 DEBUG: There is a single atom floating around
2022-12-30 12:55:56.733 DEBUG: There is a single atom floating around
2022-12-30 12:55:56.924 DEBUG: Atoms are too close
2022-12-30 12:55:57.146 DEBUG: There is a single atom floating around
2022-12-30 12:55:57.806 DEBUG: Atoms are too close
2022-12-30 12:55:58.848 DEBUG: Atoms are too close
2022-12-30 12:56:00.104 DEBUG: Atoms are too close
2022-12-30 12:56:02.152 DEBUG: Atoms are too close
2022-12-30 12:56:03.073 DEBUG: Atoms are too close
2022-12-30 12:56:03.550 DEBUG: Atoms are too close
2022-12-30 12:56:04.387 DEBUG: Atoms are too close
2022-12-30 12:56:05.475 DEBUG: There is a single atom floating around
2022-12-30 12:56:06.792 DEBUG: There is a single atom floating around
2022-12-30 12:56:06.795 DEBUG: There is a single atom floating around
2022-12-30 12:56:07.058 DEBUG: There is a single atom floating around
2022-12-30 12:56:07.467 DEBUG: Atoms are too close
2022-12-30 12:56:08.537 DEBUG: There is a single atom floating around
2022-12-30 12:56:09.068 DEBUG: There is a single atom floating around
2022-12-30 12:56:10.051 DEBUG: There is a single atom floating around
2022-12-30 12:56:10.352 DEBUG: Atoms are too close
2022-12-30 12:56:11.067 DEBUG: Atoms are too close
2022-12-30 12:56:12.815 DEBUG: Atoms are too close
2022-12-30 12:56:13.828 DEBUG: Atoms are too close
2022-12-30 12:56:13.830 DEBUG: Atoms are too close
2022-12-30 12:56:13.831 DEBUG: There is a single atom floating around
2022-12-30 12:56:13.833 DEBUG: There is a single atom floating around
2022-12-30 12:56:14.744 DEBUG: There is a single atom floating around
2022-12-30 12:56:15.813 DEBUG: Atoms are too close
2022-12-30 12:56:16.214 DEBUG: There is a single atom floating around
2022-12-30 12:56:16.493 INFO: Training rollout: return=-13.743 (9.3), episode length=3.8
2022-12-30 12:56:16.494 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-30 12:56:16.496 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-0_train.pkl
2022-12-30 12:57:46.470 INFO: {
    "bag_scale": 5,
    "beta": "-10",
    "canvas_size": 5,
    "clip_ratio": 0.2,
    "cutoff": 4.0,
    "data_dir": "runs/CH4_int/data",
    "device": "cuda",
    "discount": 1.0,
    "entropy_coef": 0.06,
    "eval_formulas": "CH4",
    "eval_freq": 1,
    "formulas": "CH4",
    "gradient_clip": 0.5,
    "keep_models": false,
    "lam": 1.0,
    "learning_rate": 0.0005,
    "load_latest": false,
    "load_model": null,
    "log_dir": "runs/CH4_int/logs",
    "log_level": "DEBUG",
    "max_mean_distance": 1.8,
    "max_num_steps": 30000,
    "max_num_train_iters": 10,
    "max_solo_distance": 2.0,
    "maxl": 4,
    "min_atomic_distance": 0.6,
    "min_mean_distance": 0.8,
    "min_reward": -20.0,
    "mini_batch_size": 64,
    "model": "schnet_edge",
    "model_dir": "runs/CH4_int/models",
    "name": "CH4_int",
    "network_width": 128,
    "num_cg_levels": 3,
    "num_channels_hidden": 10,
    "num_channels_per_element": 4,
    "num_envs": 12,
    "num_eval_episodes": null,
    "num_gaussians": 3,
    "num_interactions": 3,
    "num_steps_per_iter": 216,
    "optimizer": "adam",
    "results_dir": "runs/CH4_int/results",
    "save_freq": 10,
    "save_rollouts": "train",
    "seed": 1,
    "symbols": "X,H,C",
    "target_kl": 0.03,
    "update_edges": true,
    "vf_coef": 0.001
}
2022-12-30 12:57:46.506 INFO: CUDA Device: 0
2022-12-30 12:57:46.507 INFO: Training bags: ['CH4']
2022-12-30 12:57:46.507 INFO: Evaluation bags: ['CH4']
2022-12-30 12:57:48.453 INFO: Number of parameters: 548381
2022-12-30 12:57:48.463 INFO: Starting PPO
2022-12-30 12:57:48.463 INFO: Iteration: 0/137, steps: 0
2022-12-30 12:57:50.760 DEBUG: There is a single atom floating around
2022-12-30 12:57:50.947 DEBUG: There is a single atom floating around
2022-12-30 12:57:51.335 DEBUG: There is a single atom floating around
2022-12-30 12:57:51.337 DEBUG: There is a single atom floating around
2022-12-30 12:57:51.914 DEBUG: There is a single atom floating around
2022-12-30 12:57:55.825 DEBUG: Atoms are too close
2022-12-30 12:57:56.708 DEBUG: Atoms are too close
2022-12-30 12:58:02.692 DEBUG: Atoms are too close
2022-12-30 12:58:03.095 DEBUG: There is a single atom floating around
2022-12-30 12:58:03.095 DEBUG: There is a single atom floating around
2022-12-30 12:58:03.552 DEBUG: Atoms are too close
2022-12-30 12:58:03.889 DEBUG: There is a single atom floating around
2022-12-30 12:58:05.020 DEBUG: Atoms are too close
2022-12-30 12:58:06.724 DEBUG: Atoms are too close
2022-12-30 12:58:08.632 DEBUG: Atoms are too close
2022-12-30 12:58:10.999 DEBUG: Atoms are too close
2022-12-30 12:58:11.909 DEBUG: Atoms are too close
2022-12-30 12:58:12.448 DEBUG: Atoms are too close
2022-12-30 12:58:13.215 DEBUG: Atoms are too close
2022-12-30 12:58:14.394 DEBUG: There is a single atom floating around
2022-12-30 12:58:15.714 DEBUG: There is a single atom floating around
2022-12-30 12:58:15.717 DEBUG: There is a single atom floating around
2022-12-30 12:58:16.066 DEBUG: There is a single atom floating around
2022-12-30 12:58:16.480 DEBUG: Atoms are too close
2022-12-30 12:58:17.609 DEBUG: There is a single atom floating around
2022-12-30 12:58:18.196 DEBUG: There is a single atom floating around
2022-12-30 12:58:19.296 DEBUG: There is a single atom floating around
2022-12-30 12:58:19.624 DEBUG: Atoms are too close
2022-12-30 12:58:20.418 DEBUG: Atoms are too close
2022-12-30 12:58:22.390 DEBUG: Atoms are too close
2022-12-30 12:58:23.543 DEBUG: Atoms are too close
2022-12-30 12:58:23.545 DEBUG: Atoms are too close
2022-12-30 12:58:23.547 DEBUG: There is a single atom floating around
2022-12-30 12:58:23.549 DEBUG: There is a single atom floating around
2022-12-30 12:58:24.531 DEBUG: There is a single atom floating around
2022-12-30 12:58:25.786 DEBUG: Atoms are too close
2022-12-30 12:58:26.239 DEBUG: There is a single atom floating around
2022-12-30 12:58:26.539 INFO: Training rollout: return=-13.743 (9.3), episode length=3.8
2022-12-30 12:58:26.540 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-30 12:58:26.543 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-0_train.pkl
2022-12-30 12:59:44.812 INFO: {
    "bag_scale": 5,
    "beta": "-10",
    "canvas_size": 5,
    "clip_ratio": 0.2,
    "cutoff": 4.0,
    "data_dir": "runs/CH4_int/data",
    "device": "cuda",
    "discount": 1.0,
    "entropy_coef": 0.06,
    "eval_formulas": "CH4",
    "eval_freq": 1,
    "formulas": "CH4",
    "gradient_clip": 0.5,
    "keep_models": false,
    "lam": 1.0,
    "learning_rate": 0.0005,
    "load_latest": false,
    "load_model": null,
    "log_dir": "runs/CH4_int/logs",
    "log_level": "DEBUG",
    "max_mean_distance": 1.8,
    "max_num_steps": 30000,
    "max_num_train_iters": 10,
    "max_solo_distance": 2.0,
    "maxl": 4,
    "min_atomic_distance": 0.6,
    "min_mean_distance": 0.8,
    "min_reward": -20.0,
    "mini_batch_size": 64,
    "model": "schnet_edge",
    "model_dir": "runs/CH4_int/models",
    "name": "CH4_int",
    "network_width": 128,
    "num_cg_levels": 3,
    "num_channels_hidden": 10,
    "num_channels_per_element": 4,
    "num_envs": 12,
    "num_eval_episodes": null,
    "num_gaussians": 3,
    "num_interactions": 3,
    "num_steps_per_iter": 216,
    "optimizer": "adam",
    "results_dir": "runs/CH4_int/results",
    "save_freq": 10,
    "save_rollouts": "train",
    "seed": 1,
    "symbols": "X,H,C",
    "target_kl": 0.03,
    "update_edges": true,
    "vf_coef": 0.001
}
2022-12-30 12:59:44.850 INFO: CUDA Device: 0
2022-12-30 12:59:44.851 INFO: Training bags: ['CH4']
2022-12-30 12:59:44.851 INFO: Evaluation bags: ['CH4']
2022-12-30 12:59:46.956 INFO: Number of parameters: 548381
2022-12-30 12:59:46.968 INFO: Starting PPO
2022-12-30 12:59:46.968 INFO: Iteration: 0/137, steps: 0
2022-12-30 12:59:50.000 DEBUG: There is a single atom floating around
2022-12-30 12:59:50.258 DEBUG: There is a single atom floating around
2022-12-30 12:59:50.768 DEBUG: There is a single atom floating around
2022-12-30 12:59:50.770 DEBUG: There is a single atom floating around
2022-12-30 12:59:51.543 DEBUG: There is a single atom floating around
2022-12-30 12:59:56.497 DEBUG: Atoms are too close
2022-12-30 12:59:57.668 DEBUG: Atoms are too close
2022-12-30 13:00:02.740 DEBUG: Atoms are too close
2022-12-30 13:00:02.999 DEBUG: There is a single atom floating around
2022-12-30 13:00:03.000 DEBUG: There is a single atom floating around
2022-12-30 13:00:03.250 DEBUG: Atoms are too close
2022-12-30 13:00:03.516 DEBUG: There is a single atom floating around
2022-12-30 13:00:04.389 DEBUG: Atoms are too close
2022-12-30 13:00:05.713 DEBUG: Atoms are too close
2022-12-30 13:00:07.380 DEBUG: Atoms are too close
2022-12-30 13:00:10.111 DEBUG: Atoms are too close
2022-12-30 13:00:11.273 DEBUG: Atoms are too close
2022-12-30 13:00:11.936 DEBUG: Atoms are too close
2022-12-30 13:00:13.004 DEBUG: Atoms are too close
2022-12-30 13:00:14.370 DEBUG: There is a single atom floating around
2022-12-30 13:00:15.993 DEBUG: There is a single atom floating around
2022-12-30 13:00:15.995 DEBUG: There is a single atom floating around
2022-12-30 13:00:16.319 DEBUG: There is a single atom floating around
2022-12-30 13:00:16.807 DEBUG: Atoms are too close
2022-12-30 13:00:18.129 DEBUG: There is a single atom floating around
2022-12-30 13:00:18.743 DEBUG: There is a single atom floating around
2022-12-30 13:00:19.936 DEBUG: There is a single atom floating around
2022-12-30 13:00:20.284 DEBUG: Atoms are too close
2022-12-30 13:00:21.205 DEBUG: Atoms are too close
2022-12-30 13:00:23.397 DEBUG: Atoms are too close
2022-12-30 13:00:24.601 DEBUG: Atoms are too close
2022-12-30 13:00:24.603 DEBUG: Atoms are too close
2022-12-30 13:00:24.604 DEBUG: There is a single atom floating around
2022-12-30 13:00:24.604 DEBUG: There is a single atom floating around
2022-12-30 13:00:25.723 DEBUG: There is a single atom floating around
2022-12-30 13:00:27.035 DEBUG: Atoms are too close
2022-12-30 13:00:27.539 DEBUG: There is a single atom floating around
2022-12-30 13:00:27.873 INFO: Training rollout: return=-13.743 (9.3), episode length=3.8
2022-12-30 13:00:27.874 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-30 13:00:27.877 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-0_train.pkl
2022-12-30 13:01:17.313 INFO: {
    "bag_scale": 5,
    "beta": "-10",
    "canvas_size": 5,
    "clip_ratio": 0.2,
    "cutoff": 4.0,
    "data_dir": "runs/CH4_int/data",
    "device": "cuda",
    "discount": 1.0,
    "entropy_coef": 0.06,
    "eval_formulas": "CH4",
    "eval_freq": 1,
    "formulas": "CH4",
    "gradient_clip": 0.5,
    "keep_models": false,
    "lam": 1.0,
    "learning_rate": 0.0005,
    "load_latest": false,
    "load_model": null,
    "log_dir": "runs/CH4_int/logs",
    "log_level": "DEBUG",
    "max_mean_distance": 1.8,
    "max_num_steps": 30000,
    "max_num_train_iters": 10,
    "max_solo_distance": 2.0,
    "maxl": 4,
    "min_atomic_distance": 0.6,
    "min_mean_distance": 0.8,
    "min_reward": -20.0,
    "mini_batch_size": 64,
    "model": "schnet_edge",
    "model_dir": "runs/CH4_int/models",
    "name": "CH4_int",
    "network_width": 128,
    "num_cg_levels": 3,
    "num_channels_hidden": 10,
    "num_channels_per_element": 4,
    "num_envs": 12,
    "num_eval_episodes": null,
    "num_gaussians": 3,
    "num_interactions": 3,
    "num_steps_per_iter": 216,
    "optimizer": "adam",
    "results_dir": "runs/CH4_int/results",
    "save_freq": 10,
    "save_rollouts": "train",
    "seed": 1,
    "symbols": "X,H,C",
    "target_kl": 0.03,
    "update_edges": true,
    "vf_coef": 0.001
}
2022-12-30 13:01:17.352 INFO: CUDA Device: 0
2022-12-30 13:01:17.353 INFO: Training bags: ['CH4']
2022-12-30 13:01:17.353 INFO: Evaluation bags: ['CH4']
2022-12-30 13:01:19.455 INFO: Number of parameters: 548381
2022-12-30 13:01:19.467 INFO: Starting PPO
2022-12-30 13:01:19.467 INFO: Iteration: 0/137, steps: 0
2022-12-30 13:01:22.350 DEBUG: There is a single atom floating around
2022-12-30 13:01:22.620 DEBUG: There is a single atom floating around
2022-12-30 13:01:23.115 DEBUG: There is a single atom floating around
2022-12-30 13:01:23.116 DEBUG: There is a single atom floating around
2022-12-30 13:01:23.861 DEBUG: There is a single atom floating around
2022-12-30 13:01:28.691 DEBUG: Atoms are too close
2022-12-30 13:01:29.807 DEBUG: Atoms are too close
2022-12-30 13:01:34.532 DEBUG: Atoms are too close
2022-12-30 13:01:34.771 DEBUG: There is a single atom floating around
2022-12-30 13:01:34.772 DEBUG: There is a single atom floating around
2022-12-30 13:01:35.002 DEBUG: Atoms are too close
2022-12-30 13:01:35.252 DEBUG: There is a single atom floating around
2022-12-30 13:01:36.085 DEBUG: Atoms are too close
2022-12-30 13:01:37.290 DEBUG: Atoms are too close
2022-12-30 13:01:38.892 DEBUG: Atoms are too close
2022-12-30 13:01:41.319 DEBUG: Atoms are too close
2022-12-30 13:01:42.408 DEBUG: Atoms are too close
2022-12-30 13:01:42.971 DEBUG: Atoms are too close
2022-12-30 13:01:43.929 DEBUG: Atoms are too close
2022-12-30 13:01:45.251 DEBUG: There is a single atom floating around
2022-12-30 13:01:46.841 DEBUG: There is a single atom floating around
2022-12-30 13:01:46.842 DEBUG: There is a single atom floating around
2022-12-30 13:01:47.171 DEBUG: There is a single atom floating around
2022-12-30 13:01:47.656 DEBUG: Atoms are too close
2022-12-30 13:01:48.977 DEBUG: There is a single atom floating around
2022-12-30 13:01:49.578 DEBUG: There is a single atom floating around
2022-12-30 13:01:50.757 DEBUG: There is a single atom floating around
2022-12-30 13:01:51.108 DEBUG: Atoms are too close
2022-12-30 13:01:51.940 DEBUG: Atoms are too close
2022-12-30 13:01:54.080 DEBUG: Atoms are too close
2022-12-30 13:01:55.287 DEBUG: Atoms are too close
2022-12-30 13:01:55.289 DEBUG: Atoms are too close
2022-12-30 13:01:55.289 DEBUG: There is a single atom floating around
2022-12-30 13:01:55.290 DEBUG: There is a single atom floating around
2022-12-30 13:01:56.361 DEBUG: There is a single atom floating around
2022-12-30 13:01:57.713 DEBUG: Atoms are too close
2022-12-30 13:01:58.194 DEBUG: There is a single atom floating around
2022-12-30 13:01:58.559 INFO: Training rollout: return=-13.743 (9.3), episode length=3.8
2022-12-30 13:01:58.560 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-30 13:01:58.563 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-0_train.pkl
2022-12-30 13:02:31.995 INFO: {
    "bag_scale": 5,
    "beta": "-10",
    "canvas_size": 5,
    "clip_ratio": 0.2,
    "cutoff": 4.0,
    "data_dir": "runs/CH4_int/data",
    "device": "cuda",
    "discount": 1.0,
    "entropy_coef": 0.06,
    "eval_formulas": "CH4",
    "eval_freq": 1,
    "formulas": "CH4",
    "gradient_clip": 0.5,
    "keep_models": false,
    "lam": 1.0,
    "learning_rate": 0.0005,
    "load_latest": false,
    "load_model": null,
    "log_dir": "runs/CH4_int/logs",
    "log_level": "DEBUG",
    "max_mean_distance": 1.8,
    "max_num_steps": 30000,
    "max_num_train_iters": 10,
    "max_solo_distance": 2.0,
    "maxl": 4,
    "min_atomic_distance": 0.6,
    "min_mean_distance": 0.8,
    "min_reward": -20.0,
    "mini_batch_size": 64,
    "model": "schnet_edge",
    "model_dir": "runs/CH4_int/models",
    "name": "CH4_int",
    "network_width": 128,
    "num_cg_levels": 3,
    "num_channels_hidden": 10,
    "num_channels_per_element": 4,
    "num_envs": 12,
    "num_eval_episodes": null,
    "num_gaussians": 3,
    "num_interactions": 3,
    "num_steps_per_iter": 216,
    "optimizer": "adam",
    "results_dir": "runs/CH4_int/results",
    "save_freq": 10,
    "save_rollouts": "train",
    "seed": 1,
    "symbols": "X,H,C",
    "target_kl": 0.03,
    "update_edges": true,
    "vf_coef": 0.001
}
2022-12-30 13:02:32.032 INFO: CUDA Device: 0
2022-12-30 13:02:32.033 INFO: Training bags: ['CH4']
2022-12-30 13:02:32.033 INFO: Evaluation bags: ['CH4']
2022-12-30 13:02:34.328 INFO: Number of parameters: 548381
2022-12-30 13:02:34.340 INFO: Starting PPO
2022-12-30 13:02:34.340 INFO: Iteration: 0/137, steps: 0
2022-12-30 13:02:37.315 DEBUG: There is a single atom floating around
2022-12-30 13:02:37.555 DEBUG: There is a single atom floating around
2022-12-30 13:02:38.041 DEBUG: There is a single atom floating around
2022-12-30 13:02:38.041 DEBUG: There is a single atom floating around
2022-12-30 13:02:38.765 DEBUG: There is a single atom floating around
2022-12-30 13:02:43.622 DEBUG: Atoms are too close
2022-12-30 13:02:44.766 DEBUG: Atoms are too close
2022-12-30 13:02:49.558 DEBUG: Atoms are too close
2022-12-30 13:02:49.818 DEBUG: There is a single atom floating around
2022-12-30 13:02:49.819 DEBUG: There is a single atom floating around
2022-12-30 13:02:50.069 DEBUG: Atoms are too close
2022-12-30 13:02:50.319 DEBUG: There is a single atom floating around
2022-12-30 13:02:51.143 DEBUG: Atoms are too close
2022-12-30 13:02:52.357 DEBUG: Atoms are too close
2022-12-30 13:02:53.968 DEBUG: Atoms are too close
2022-12-30 13:02:56.417 DEBUG: Atoms are too close
2022-12-30 13:02:57.528 DEBUG: Atoms are too close
2022-12-30 13:02:58.146 DEBUG: Atoms are too close
2022-12-30 13:02:59.147 DEBUG: Atoms are too close
2022-12-30 13:03:00.535 DEBUG: There is a single atom floating around
2022-12-30 13:03:02.115 DEBUG: There is a single atom floating around
2022-12-30 13:03:02.116 DEBUG: There is a single atom floating around
2022-12-30 13:03:02.444 DEBUG: There is a single atom floating around
2022-12-30 13:03:02.943 DEBUG: Atoms are too close
2022-12-30 13:03:04.298 DEBUG: There is a single atom floating around
2022-12-30 13:03:04.882 DEBUG: There is a single atom floating around
2022-12-30 13:03:06.033 DEBUG: There is a single atom floating around
2022-12-30 13:03:06.397 DEBUG: Atoms are too close
2022-12-30 13:03:07.221 DEBUG: Atoms are too close
2022-12-30 13:03:09.352 DEBUG: Atoms are too close
2022-12-30 13:03:10.528 DEBUG: Atoms are too close
2022-12-30 13:03:10.530 DEBUG: Atoms are too close
2022-12-30 13:03:10.530 DEBUG: There is a single atom floating around
2022-12-30 13:03:10.531 DEBUG: There is a single atom floating around
2022-12-30 13:03:11.649 DEBUG: There is a single atom floating around
2022-12-30 13:03:12.932 DEBUG: Atoms are too close
2022-12-30 13:03:13.415 DEBUG: There is a single atom floating around
2022-12-30 13:03:13.757 INFO: Training rollout: return=-13.743 (9.3), episode length=3.8
2022-12-30 13:03:13.758 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-30 13:03:13.761 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-0_train.pkl
2022-12-30 13:03:55.082 INFO: {
    "bag_scale": 5,
    "beta": "-10",
    "canvas_size": 5,
    "clip_ratio": 0.2,
    "cutoff": 4.0,
    "data_dir": "runs/CH4_int/data",
    "device": "cuda",
    "discount": 1.0,
    "entropy_coef": 0.06,
    "eval_formulas": "CH4",
    "eval_freq": 1,
    "formulas": "CH4",
    "gradient_clip": 0.5,
    "keep_models": false,
    "lam": 1.0,
    "learning_rate": 0.0005,
    "load_latest": false,
    "load_model": null,
    "log_dir": "runs/CH4_int/logs",
    "log_level": "DEBUG",
    "max_mean_distance": 1.8,
    "max_num_steps": 30000,
    "max_num_train_iters": 10,
    "max_solo_distance": 2.0,
    "maxl": 4,
    "min_atomic_distance": 0.6,
    "min_mean_distance": 0.8,
    "min_reward": -20.0,
    "mini_batch_size": 64,
    "model": "schnet_edge",
    "model_dir": "runs/CH4_int/models",
    "name": "CH4_int",
    "network_width": 128,
    "num_cg_levels": 3,
    "num_channels_hidden": 10,
    "num_channels_per_element": 4,
    "num_envs": 12,
    "num_eval_episodes": null,
    "num_gaussians": 3,
    "num_interactions": 3,
    "num_steps_per_iter": 216,
    "optimizer": "adam",
    "results_dir": "runs/CH4_int/results",
    "save_freq": 10,
    "save_rollouts": "train",
    "seed": 1,
    "symbols": "X,H,C",
    "target_kl": 0.03,
    "update_edges": true,
    "vf_coef": 0.001
}
2022-12-30 13:03:55.121 INFO: CUDA Device: 0
2022-12-30 13:03:55.122 INFO: Training bags: ['CH4']
2022-12-30 13:03:55.122 INFO: Evaluation bags: ['CH4']
2022-12-30 13:03:57.553 INFO: Number of parameters: 548381
2022-12-30 13:03:57.565 INFO: Starting PPO
2022-12-30 13:03:57.565 INFO: Iteration: 0/137, steps: 0
2022-12-30 13:04:00.287 DEBUG: There is a single atom floating around
2022-12-30 13:04:00.549 DEBUG: There is a single atom floating around
2022-12-30 13:04:01.027 DEBUG: There is a single atom floating around
2022-12-30 13:04:01.029 DEBUG: There is a single atom floating around
2022-12-30 13:04:01.744 DEBUG: There is a single atom floating around
2022-12-30 13:04:06.472 DEBUG: Atoms are too close
2022-12-30 13:04:07.581 DEBUG: Atoms are too close
2022-12-30 13:04:12.288 DEBUG: Atoms are too close
2022-12-30 13:04:12.539 DEBUG: There is a single atom floating around
2022-12-30 13:04:12.540 DEBUG: There is a single atom floating around
2022-12-30 13:04:12.785 DEBUG: Atoms are too close
2022-12-30 13:04:13.025 DEBUG: There is a single atom floating around
2022-12-30 13:04:13.844 DEBUG: Atoms are too close
2022-12-30 13:04:15.053 DEBUG: Atoms are too close
2022-12-30 13:04:16.620 DEBUG: Atoms are too close
2022-12-30 13:04:19.075 DEBUG: Atoms are too close
2022-12-30 13:04:20.210 DEBUG: Atoms are too close
2022-12-30 13:04:20.811 DEBUG: Atoms are too close
2022-12-30 13:04:21.807 DEBUG: Atoms are too close
2022-12-30 13:04:23.160 DEBUG: There is a single atom floating around
2022-12-30 13:04:24.758 DEBUG: There is a single atom floating around
2022-12-30 13:04:24.759 DEBUG: There is a single atom floating around
2022-12-30 13:04:25.088 DEBUG: There is a single atom floating around
2022-12-30 13:04:25.590 DEBUG: Atoms are too close
2022-12-30 13:04:26.928 DEBUG: There is a single atom floating around
2022-12-30 13:04:27.529 DEBUG: There is a single atom floating around
2022-12-30 13:04:28.722 DEBUG: There is a single atom floating around
2022-12-30 13:04:29.086 DEBUG: Atoms are too close
2022-12-30 13:04:29.965 DEBUG: Atoms are too close
2022-12-30 13:04:32.112 DEBUG: Atoms are too close
2022-12-30 13:04:33.306 DEBUG: Atoms are too close
2022-12-30 13:04:33.307 DEBUG: Atoms are too close
2022-12-30 13:04:33.308 DEBUG: There is a single atom floating around
2022-12-30 13:04:33.308 DEBUG: There is a single atom floating around
2022-12-30 13:04:34.423 DEBUG: There is a single atom floating around
2022-12-30 13:04:35.747 DEBUG: Atoms are too close
2022-12-30 13:04:36.245 DEBUG: There is a single atom floating around
2022-12-30 13:04:36.586 INFO: Training rollout: return=-13.743 (9.3), episode length=3.8
2022-12-30 13:04:36.587 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-30 13:04:36.590 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-0_train.pkl
2022-12-30 13:04:41.773 DEBUG: Taking gradient step
2022-12-30 13:04:41.788 DEBUG: Loss 0: {'policy_loss': 0.02879920731198763, 'entropy_loss': -0.04379872418940067, 'vf_loss': 0.229808076386026, 'total_loss': -0.014999516877413042, 'approx_kl': -6.682239472866058e-08, 'clip_fraction': 0.0, 'grad_norm': 205.59144592285156}
2022-12-30 13:04:46.856 DEBUG: Taking gradient step
2022-12-30 13:04:46.867 DEBUG: Loss 1: {'policy_loss': 0.004686787695599277, 'entropy_loss': -0.04328545182943344, 'vf_loss': 0.22241253765228416, 'total_loss': -0.03859866413383416, 'approx_kl': 0.020684977527707815, 'clip_fraction': 0.4674479216337204, 'grad_norm': 51.437095642089844}
2022-12-30 13:04:51.930 DEBUG: Taking gradient step
2022-12-30 13:04:51.941 DEBUG: Loss 2: {'policy_loss': -0.051777119984461176, 'entropy_loss': -0.043276059441268444, 'vf_loss': 0.22449209166391548, 'total_loss': -0.09505317942572962, 'approx_kl': -0.007554530631750822, 'clip_fraction': 0.3203125, 'grad_norm': 124.01334381103516}
2022-12-30 13:04:56.794 DEBUG: Taking gradient step
2022-12-30 13:04:56.806 DEBUG: Loss 3: {'policy_loss': 0.05545932468514212, 'entropy_loss': -0.044064899906516075, 'vf_loss': 0.24265499844372318, 'total_loss': 0.011394424778626046, 'approx_kl': 0.041713922284543514, 'clip_fraction': 0.30078125, 'grad_norm': 145.4694061279297}
2022-12-30 13:05:01.771 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-30 13:05:01.772 INFO: Optimization: policy loss=0.055, vf loss=0.243, entropy loss=-0.044, total loss=0.011, num steps=4
2022-12-30 13:05:01.773 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-30 13:05:24.481 INFO: {
    "bag_scale": 5,
    "beta": "-10",
    "canvas_size": 5,
    "clip_ratio": 0.2,
    "cutoff": 4.0,
    "data_dir": "runs/CH4_int/data",
    "device": "cuda",
    "discount": 1.0,
    "entropy_coef": 0.06,
    "eval_formulas": "CH4",
    "eval_freq": 1,
    "formulas": "CH4",
    "gradient_clip": 0.5,
    "keep_models": false,
    "lam": 1.0,
    "learning_rate": 0.0005,
    "load_latest": false,
    "load_model": null,
    "log_dir": "runs/CH4_int/logs",
    "log_level": "DEBUG",
    "max_mean_distance": 1.8,
    "max_num_steps": 30000,
    "max_num_train_iters": 10,
    "max_solo_distance": 2.0,
    "maxl": 4,
    "min_atomic_distance": 0.6,
    "min_mean_distance": 0.8,
    "min_reward": -20.0,
    "mini_batch_size": 64,
    "model": "schnet_edge",
    "model_dir": "runs/CH4_int/models",
    "name": "CH4_int",
    "network_width": 128,
    "num_cg_levels": 3,
    "num_channels_hidden": 10,
    "num_channels_per_element": 4,
    "num_envs": 12,
    "num_eval_episodes": null,
    "num_gaussians": 3,
    "num_interactions": 3,
    "num_steps_per_iter": 216,
    "optimizer": "adam",
    "results_dir": "runs/CH4_int/results",
    "save_freq": 10,
    "save_rollouts": "train",
    "seed": 1,
    "symbols": "X,H,C",
    "target_kl": 0.03,
    "update_edges": true,
    "vf_coef": 0.001
}
2022-12-30 13:05:24.517 INFO: CUDA Device: 0
2022-12-30 13:05:24.518 INFO: Training bags: ['CH4']
2022-12-30 13:05:24.518 INFO: Evaluation bags: ['CH4']
2022-12-30 13:05:26.574 INFO: Number of parameters: 548381
2022-12-30 13:05:26.590 INFO: Starting PPO
2022-12-30 13:05:26.590 INFO: Iteration: 0/137, steps: 0
2022-12-30 13:05:29.773 DEBUG: There is a single atom floating around
2022-12-30 13:05:30.059 DEBUG: There is a single atom floating around
2022-12-30 13:05:30.594 DEBUG: There is a single atom floating around
2022-12-30 13:05:30.595 DEBUG: There is a single atom floating around
2022-12-30 13:05:31.391 DEBUG: There is a single atom floating around
2022-12-30 13:05:36.450 DEBUG: Atoms are too close
2022-12-30 13:05:37.648 DEBUG: Atoms are too close
2022-12-30 13:05:42.702 DEBUG: Atoms are too close
2022-12-30 13:05:42.956 DEBUG: There is a single atom floating around
2022-12-30 13:05:42.957 DEBUG: There is a single atom floating around
2022-12-30 13:05:43.214 DEBUG: Atoms are too close
2022-12-30 13:05:43.475 DEBUG: There is a single atom floating around
2022-12-30 13:05:44.357 DEBUG: Atoms are too close
2022-12-30 13:05:45.686 DEBUG: Atoms are too close
2022-12-30 13:05:47.363 DEBUG: Atoms are too close
2022-12-30 13:05:49.895 DEBUG: Atoms are too close
2022-12-30 13:05:51.052 DEBUG: Atoms are too close
2022-12-30 13:05:51.672 DEBUG: Atoms are too close
2022-12-30 13:05:52.696 DEBUG: Atoms are too close
2022-12-30 13:05:54.105 DEBUG: There is a single atom floating around
2022-12-30 13:05:55.768 DEBUG: There is a single atom floating around
2022-12-30 13:05:55.771 DEBUG: There is a single atom floating around
2022-12-30 13:05:56.120 DEBUG: There is a single atom floating around
2022-12-30 13:05:56.632 DEBUG: Atoms are too close
2022-12-30 13:05:57.999 DEBUG: There is a single atom floating around
2022-12-30 13:05:58.624 DEBUG: There is a single atom floating around
2022-12-30 13:05:59.908 DEBUG: There is a single atom floating around
2022-12-30 13:06:00.293 DEBUG: Atoms are too close
2022-12-30 13:06:01.201 DEBUG: Atoms are too close
2022-12-30 13:06:03.394 DEBUG: Atoms are too close
2022-12-30 13:06:04.662 DEBUG: Atoms are too close
2022-12-30 13:06:04.662 DEBUG: Atoms are too close
2022-12-30 13:06:04.663 DEBUG: There is a single atom floating around
2022-12-30 13:06:04.664 DEBUG: There is a single atom floating around
2022-12-30 13:06:05.813 DEBUG: There is a single atom floating around
2022-12-30 13:06:07.168 DEBUG: Atoms are too close
2022-12-30 13:06:07.693 DEBUG: There is a single atom floating around
2022-12-30 13:06:08.039 INFO: Training rollout: return=-13.743 (9.3), episode length=3.8
2022-12-30 13:06:08.039 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-30 13:06:08.042 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-0_train.pkl
2022-12-30 13:06:12.782 DEBUG: Taking gradient step
2022-12-30 13:06:12.796 DEBUG: Loss 0: {'policy_loss': 0.028799206404388905, 'entropy_loss': -0.04379872418940067, 'vf_loss': 0.22980807651803387, 'total_loss': -0.014999517785011768, 'approx_kl': -3.670963150126383e-08, 'clip_fraction': 0.0, 'grad_norm': 205.59144592285156}
2022-12-30 13:06:17.325 DEBUG: Taking gradient step
2022-12-30 13:06:17.336 DEBUG: Loss 1: {'policy_loss': 0.004686802165812978, 'entropy_loss': -0.04328545182943344, 'vf_loss': 0.2224125376367165, 'total_loss': -0.03859864966362046, 'approx_kl': 0.020684986375272274, 'clip_fraction': 0.4674479216337204, 'grad_norm': 51.437103271484375}
2022-12-30 13:06:21.015 DEBUG: Taking gradient step
2022-12-30 13:06:21.025 DEBUG: Loss 2: {'policy_loss': -0.05177710919518254, 'entropy_loss': -0.04327606037259102, 'vf_loss': 0.22449209197959927, 'total_loss': -0.09505316956777356, 'approx_kl': -0.007554559735581279, 'clip_fraction': 0.3203125, 'grad_norm': 124.01335144042969}
2022-12-30 13:06:24.969 DEBUG: Taking gradient step
2022-12-30 13:06:24.984 DEBUG: Loss 3: {'policy_loss': 0.055459290544841874, 'entropy_loss': -0.044064899906516075, 'vf_loss': 0.24265499843491964, 'total_loss': 0.0113943906383258, 'approx_kl': 0.04171392438001931, 'clip_fraction': 0.30078125, 'grad_norm': 145.4694061279297}
2022-12-30 13:06:28.785 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-30 13:06:28.786 INFO: Optimization: policy loss=0.055, vf loss=0.243, entropy loss=-0.044, total loss=0.011, num steps=4
2022-12-30 13:06:28.787 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-30 14:39:27.129 INFO: {
    "bag_scale": 5,
    "beta": "-10",
    "canvas_size": 5,
    "clip_ratio": 0.2,
    "cutoff": 4.0,
    "data_dir": "runs/CH4_int/data",
    "device": "cuda",
    "discount": 1.0,
    "entropy_coef": 0.06,
    "eval_formulas": "CH4",
    "eval_freq": 1,
    "formulas": "CH4",
    "gradient_clip": 0.5,
    "keep_models": false,
    "lam": 1.0,
    "learning_rate": 0.0005,
    "load_latest": false,
    "load_model": null,
    "log_dir": "runs/CH4_int/logs",
    "log_level": "DEBUG",
    "max_mean_distance": 1.8,
    "max_num_steps": 30000,
    "max_num_train_iters": 10,
    "max_solo_distance": 2.0,
    "maxl": 4,
    "min_atomic_distance": 0.6,
    "min_mean_distance": 0.8,
    "min_reward": -20.0,
    "mini_batch_size": 64,
    "model": "schnet_edge",
    "model_dir": "runs/CH4_int/models",
    "name": "CH4_int",
    "network_width": 128,
    "num_cg_levels": 3,
    "num_channels_hidden": 10,
    "num_channels_per_element": 4,
    "num_envs": 12,
    "num_eval_episodes": null,
    "num_gaussians": 3,
    "num_interactions": 3,
    "num_steps_per_iter": 216,
    "optimizer": "adam",
    "results_dir": "runs/CH4_int/results",
    "save_freq": 10,
    "save_rollouts": "train",
    "seed": 1,
    "symbols": "X,H,C",
    "target_kl": 0.03,
    "update_edges": true,
    "vf_coef": 0.001
}
2022-12-30 14:39:27.170 INFO: CUDA Device: 0
2022-12-30 14:39:27.171 INFO: Training bags: ['CH4']
2022-12-30 14:39:27.171 INFO: Evaluation bags: ['CH4']
2022-12-30 14:39:29.514 INFO: Number of parameters: 548381
2022-12-30 14:39:29.526 INFO: Starting PPO
2022-12-30 14:39:29.526 INFO: Iteration: 0/137, steps: 0
2022-12-30 14:39:32.858 DEBUG: There is a single atom floating around
2022-12-30 14:39:33.126 DEBUG: There is a single atom floating around
2022-12-30 14:39:33.665 DEBUG: There is a single atom floating around
2022-12-30 14:39:33.667 DEBUG: There is a single atom floating around
2022-12-30 14:39:34.471 DEBUG: There is a single atom floating around
2022-12-30 14:39:39.624 DEBUG: Atoms are too close
2022-12-30 14:39:40.812 DEBUG: Atoms are too close
2022-12-30 14:39:45.960 DEBUG: Atoms are too close
2022-12-30 14:39:46.209 DEBUG: There is a single atom floating around
2022-12-30 14:39:46.210 DEBUG: There is a single atom floating around
2022-12-30 14:39:46.477 DEBUG: Atoms are too close
2022-12-30 14:39:46.754 DEBUG: There is a single atom floating around
2022-12-30 14:39:47.639 DEBUG: Atoms are too close
2022-12-30 14:39:49.003 DEBUG: Atoms are too close
2022-12-30 14:39:50.705 DEBUG: Atoms are too close
2022-12-30 14:39:53.333 DEBUG: Atoms are too close
2022-12-30 14:39:54.522 DEBUG: Atoms are too close
2022-12-30 14:39:55.142 DEBUG: Atoms are too close
2022-12-30 14:39:56.206 DEBUG: Atoms are too close
2022-12-30 14:39:57.654 DEBUG: There is a single atom floating around
2022-12-30 14:39:59.394 DEBUG: There is a single atom floating around
2022-12-30 14:39:59.395 DEBUG: There is a single atom floating around
2022-12-30 14:39:59.752 DEBUG: There is a single atom floating around
2022-12-30 14:40:00.282 DEBUG: Atoms are too close
2022-12-30 14:40:01.687 DEBUG: There is a single atom floating around
2022-12-30 14:40:02.355 DEBUG: There is a single atom floating around
2022-12-30 14:40:03.653 DEBUG: There is a single atom floating around
2022-12-30 14:40:04.051 DEBUG: Atoms are too close
2022-12-30 14:40:04.961 DEBUG: Atoms are too close
2022-12-30 14:40:07.207 DEBUG: Atoms are too close
2022-12-30 14:40:08.479 DEBUG: Atoms are too close
2022-12-30 14:40:08.480 DEBUG: Atoms are too close
2022-12-30 14:40:08.481 DEBUG: There is a single atom floating around
2022-12-30 14:40:08.481 DEBUG: There is a single atom floating around
2022-12-30 14:40:09.613 DEBUG: There is a single atom floating around
2022-12-30 14:40:10.978 DEBUG: Atoms are too close
2022-12-30 14:40:11.499 DEBUG: There is a single atom floating around
2022-12-30 14:40:11.853 INFO: Training rollout: return=-13.743 (9.3), episode length=3.8
2022-12-30 14:40:11.854 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-30 14:40:11.859 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-0_train.pkl
2022-12-30 14:40:16.500 DEBUG: Taking gradient step
2022-12-30 14:40:16.514 DEBUG: Loss 0: {'policy_loss': 0.028799228979886283, 'entropy_loss': -0.04379872418940067, 'vf_loss': 0.22980807634974895, 'total_loss': -0.014999495209514394, 'approx_kl': -3.5157427191734314e-08, 'clip_fraction': 0.0, 'grad_norm': 205.59144592285156}
2022-12-30 14:40:20.782 DEBUG: Taking gradient step
2022-12-30 14:40:20.792 DEBUG: Loss 1: {'policy_loss': 0.004686785588032004, 'entropy_loss': -0.04328545182943344, 'vf_loss': 0.22241253721813084, 'total_loss': -0.03859866624140144, 'approx_kl': 0.02068495098501444, 'clip_fraction': 0.4674479216337204, 'grad_norm': 51.437103271484375}
2022-12-30 14:40:25.057 DEBUG: Taking gradient step
2022-12-30 14:40:25.067 DEBUG: Loss 2: {'policy_loss': -0.05177712733356821, 'entropy_loss': -0.043276059441268444, 'vf_loss': 0.2244920919979725, 'total_loss': -0.09505318677483665, 'approx_kl': -0.007554530864581466, 'clip_fraction': 0.3203125, 'grad_norm': 124.01335906982422}
2022-12-30 14:40:28.660 DEBUG: Taking gradient step
2022-12-30 14:40:28.671 DEBUG: Loss 3: {'policy_loss': 0.05545932331193026, 'entropy_loss': -0.044064899906516075, 'vf_loss': 0.24265499919834688, 'total_loss': 0.011394423405414182, 'approx_kl': 0.041713960585184395, 'clip_fraction': 0.30078125, 'grad_norm': 145.46942138671875}
2022-12-30 14:40:32.084 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-30 14:40:32.085 INFO: Optimization: policy loss=0.055, vf loss=0.243, entropy loss=-0.044, total loss=0.011, num steps=4
2022-12-30 14:40:32.085 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-30 14:41:59.678 INFO: {
    "bag_scale": 5,
    "beta": "-10",
    "canvas_size": 5,
    "clip_ratio": 0.2,
    "cutoff": 4.0,
    "data_dir": "runs/CH4_int/data",
    "device": "cuda",
    "discount": 1.0,
    "entropy_coef": 0.06,
    "eval_formulas": "CH4",
    "eval_freq": 1,
    "formulas": "CH4",
    "gradient_clip": 0.5,
    "keep_models": false,
    "lam": 1.0,
    "learning_rate": 0.0005,
    "load_latest": false,
    "load_model": null,
    "log_dir": "runs/CH4_int/logs",
    "log_level": "DEBUG",
    "max_mean_distance": 1.8,
    "max_num_steps": 30000,
    "max_num_train_iters": 10,
    "max_solo_distance": 2.0,
    "maxl": 4,
    "min_atomic_distance": 0.6,
    "min_mean_distance": 0.8,
    "min_reward": -20.0,
    "mini_batch_size": 64,
    "model": "schnet_edge",
    "model_dir": "runs/CH4_int/models",
    "name": "CH4_int",
    "network_width": 128,
    "num_cg_levels": 3,
    "num_channels_hidden": 10,
    "num_channels_per_element": 4,
    "num_envs": 12,
    "num_eval_episodes": null,
    "num_gaussians": 3,
    "num_interactions": 3,
    "num_steps_per_iter": 216,
    "optimizer": "adam",
    "results_dir": "runs/CH4_int/results",
    "save_freq": 10,
    "save_rollouts": "train",
    "seed": 1,
    "symbols": "X,H,C",
    "target_kl": 0.03,
    "update_edges": true,
    "vf_coef": 0.001
}
2022-12-30 14:41:59.718 INFO: CUDA Device: 0
2022-12-30 14:41:59.719 INFO: Training bags: ['CH4']
2022-12-30 14:41:59.719 INFO: Evaluation bags: ['CH4']
2022-12-30 14:42:01.628 INFO: Number of parameters: 548381
2022-12-30 14:42:01.641 INFO: Starting PPO
2022-12-30 14:42:01.641 INFO: Iteration: 0/137, steps: 0
2022-12-30 14:42:04.422 DEBUG: There is a single atom floating around
2022-12-30 14:42:04.672 DEBUG: There is a single atom floating around
2022-12-30 14:42:05.194 DEBUG: There is a single atom floating around
2022-12-30 14:42:05.195 DEBUG: There is a single atom floating around
2022-12-30 14:42:05.978 DEBUG: There is a single atom floating around
2022-12-30 14:42:10.861 DEBUG: Atoms are too close
2022-12-30 14:42:12.035 DEBUG: Atoms are too close
2022-12-30 14:42:17.008 DEBUG: Atoms are too close
2022-12-30 14:42:17.270 DEBUG: There is a single atom floating around
2022-12-30 14:42:17.270 DEBUG: There is a single atom floating around
2022-12-30 14:42:17.515 DEBUG: Atoms are too close
2022-12-30 14:42:17.751 DEBUG: There is a single atom floating around
2022-12-30 14:42:18.599 DEBUG: Atoms are too close
2022-12-30 14:42:19.866 DEBUG: Atoms are too close
2022-12-30 14:42:21.464 DEBUG: Atoms are too close
2022-12-30 14:42:23.958 DEBUG: Atoms are too close
2022-12-30 14:42:25.159 DEBUG: Atoms are too close
2022-12-30 14:42:25.772 DEBUG: Atoms are too close
2022-12-30 14:42:26.799 DEBUG: Atoms are too close
2022-12-30 14:42:28.180 DEBUG: There is a single atom floating around
2022-12-30 14:42:29.858 DEBUG: There is a single atom floating around
2022-12-30 14:42:29.860 DEBUG: There is a single atom floating around
2022-12-30 14:42:30.217 DEBUG: There is a single atom floating around
2022-12-30 14:42:30.753 DEBUG: Atoms are too close
2022-12-30 14:42:32.129 DEBUG: There is a single atom floating around
2022-12-30 14:42:32.732 DEBUG: There is a single atom floating around
2022-12-30 14:42:33.980 DEBUG: There is a single atom floating around
2022-12-30 14:42:34.353 DEBUG: Atoms are too close
2022-12-30 14:42:35.226 DEBUG: Atoms are too close
2022-12-30 14:42:37.495 DEBUG: Atoms are too close
2022-12-30 14:42:38.749 DEBUG: Atoms are too close
2022-12-30 14:42:38.750 DEBUG: Atoms are too close
2022-12-30 14:42:38.751 DEBUG: There is a single atom floating around
2022-12-30 14:42:38.752 DEBUG: There is a single atom floating around
2022-12-30 14:42:39.900 DEBUG: There is a single atom floating around
2022-12-30 14:42:41.269 DEBUG: Atoms are too close
2022-12-30 14:42:41.782 DEBUG: There is a single atom floating around
2022-12-30 14:42:42.136 INFO: Training rollout: return=-13.743 (9.3), episode length=3.8
2022-12-30 14:42:42.137 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-30 14:42:42.140 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-0_train.pkl
2022-12-30 14:42:47.367 DEBUG: Taking gradient step
2022-12-30 14:42:47.383 DEBUG: Loss 0: {'policy_loss': 0.028799216707386038, 'entropy_loss': -0.04379872418940067, 'vf_loss': 0.22980807646213253, 'total_loss': -0.014999507482014639, 'approx_kl': -4.5091534672803135e-08, 'clip_fraction': 0.0, 'grad_norm': 205.59144592285156}
2022-12-30 14:42:52.706 DEBUG: Taking gradient step
2022-12-30 14:42:52.720 DEBUG: Loss 1: {'policy_loss': 0.00468680940616617, 'entropy_loss': -0.04328545089811087, 'vf_loss': 0.22241253757684043, 'total_loss': -0.038598641491944696, 'approx_kl': 0.020684997085481882, 'clip_fraction': 0.4674479216337204, 'grad_norm': 51.43709945678711}
2022-12-30 14:42:57.868 DEBUG: Taking gradient step
2022-12-30 14:42:57.880 DEBUG: Loss 2: {'policy_loss': -0.05177708496006836, 'entropy_loss': -0.043276059441268444, 'vf_loss': 0.22449209175392254, 'total_loss': -0.0950531444013368, 'approx_kl': -0.007554508047178388, 'clip_fraction': 0.3203125, 'grad_norm': 124.01335144042969}
2022-12-30 14:43:02.925 DEBUG: Taking gradient step
2022-12-30 14:43:02.936 DEBUG: Loss 3: {'policy_loss': 0.05545928542439878, 'entropy_loss': -0.044064899906516075, 'vf_loss': 0.24265499860351994, 'total_loss': 0.011394385517882702, 'approx_kl': 0.04171396268066019, 'clip_fraction': 0.30078125, 'grad_norm': 145.4694061279297}
2022-12-30 14:43:08.111 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-30 14:43:08.111 INFO: Optimization: policy loss=0.055, vf loss=0.243, entropy loss=-0.044, total loss=0.011, num steps=4
2022-12-30 14:43:08.112 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-30 14:43:09.460 INFO: Evaluation rollout: return=0.364 (0.0), episode length=5.0
2022-12-30 14:43:09.461 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-30 14:43:09.465 DEBUG: Saving model: runs/CH4_int/models/CH4_int_run-1_steps-216.model
2022-12-30 14:43:09.516 INFO: Iteration: 1/137, steps: 216
2022-12-30 14:43:12.036 DEBUG: There is a single atom floating around
2022-12-30 14:43:12.037 DEBUG: There is a single atom floating around
2022-12-30 14:43:12.810 DEBUG: There is a single atom floating around
2022-12-30 14:43:13.742 DEBUG: Atoms are too close
2022-12-30 14:43:15.381 DEBUG: Atoms are too close
2022-12-30 14:43:16.425 DEBUG: Atoms are too close
2022-12-30 14:43:17.184 DEBUG: Atoms are too close
2022-12-30 14:43:18.720 DEBUG: There is a single atom floating around
2022-12-30 14:43:20.521 DEBUG: Atoms are too close
2022-12-30 14:43:20.523 DEBUG: Atoms are too close
2022-12-30 14:43:21.511 DEBUG: Atoms are too close
2022-12-30 14:43:21.610 DEBUG: There is a single atom floating around
2022-12-30 14:43:22.816 DEBUG: Atoms are too close
2022-12-30 14:43:23.724 DEBUG: Atoms are too close
2022-12-30 14:43:23.725 DEBUG: Atoms are too close
2022-12-30 14:43:24.436 DEBUG: Atoms are too close
2022-12-30 14:43:24.639 DEBUG: There is a single atom floating around
2022-12-30 14:43:24.640 DEBUG: Atoms are too close
2022-12-30 14:43:24.641 DEBUG: There is a single atom floating around
2022-12-30 14:46:56.659 INFO: {
    "bag_scale": 5,
    "beta": "-10",
    "canvas_size": 5,
    "clip_ratio": 0.2,
    "cutoff": 4.0,
    "data_dir": "runs/CH4_int/data",
    "device": "cuda",
    "discount": 1.0,
    "entropy_coef": 0.06,
    "eval_formulas": "CH4",
    "eval_freq": 1,
    "formulas": "CH4",
    "gradient_clip": 0.5,
    "keep_models": false,
    "lam": 1.0,
    "learning_rate": 0.0005,
    "load_latest": false,
    "load_model": null,
    "log_dir": "runs/CH4_int/logs",
    "log_level": "DEBUG",
    "max_mean_distance": 1.8,
    "max_num_steps": 30000,
    "max_num_train_iters": 10,
    "max_solo_distance": 2.0,
    "maxl": 4,
    "min_atomic_distance": 0.6,
    "min_mean_distance": 0.8,
    "min_reward": -20.0,
    "mini_batch_size": 64,
    "model": "schnet_edge",
    "model_dir": "runs/CH4_int/models",
    "name": "CH4_int",
    "network_width": 128,
    "num_cg_levels": 3,
    "num_channels_hidden": 10,
    "num_channels_per_element": 4,
    "num_envs": 12,
    "num_eval_episodes": null,
    "num_gaussians": 3,
    "num_interactions": 3,
    "num_steps_per_iter": 216,
    "optimizer": "adam",
    "results_dir": "runs/CH4_int/results",
    "save_freq": 10,
    "save_rollouts": "train",
    "seed": 1,
    "symbols": "X,H,C",
    "target_kl": 0.03,
    "update_edges": true,
    "vf_coef": 0.001
}
2022-12-30 14:46:56.700 INFO: CUDA Device: 0
2022-12-30 14:46:56.701 INFO: Training bags: ['CH4']
2022-12-30 14:46:56.701 INFO: Evaluation bags: ['CH4']
2022-12-30 14:46:58.760 INFO: Number of parameters: 548381
2022-12-30 14:46:58.773 INFO: Starting PPO
2022-12-30 14:46:58.773 INFO: Iteration: 0/137, steps: 0
2022-12-30 14:47:01.887 DEBUG: There is a single atom floating around
2022-12-30 14:47:02.140 DEBUG: There is a single atom floating around
2022-12-30 14:47:02.669 DEBUG: There is a single atom floating around
2022-12-30 14:47:02.670 DEBUG: There is a single atom floating around
2022-12-30 14:47:03.480 DEBUG: There is a single atom floating around
2022-12-30 14:47:08.608 DEBUG: Atoms are too close
2022-12-30 14:47:09.782 DEBUG: Atoms are too close
2022-12-30 14:47:14.874 DEBUG: Atoms are too close
2022-12-30 14:47:15.132 DEBUG: There is a single atom floating around
2022-12-30 14:47:15.132 DEBUG: There is a single atom floating around
2022-12-30 14:47:15.410 DEBUG: Atoms are too close
2022-12-30 14:47:15.676 DEBUG: There is a single atom floating around
2022-12-30 14:47:16.544 DEBUG: Atoms are too close
2022-12-30 14:47:17.864 DEBUG: Atoms are too close
2022-12-30 14:47:19.502 DEBUG: Atoms are too close
2022-12-30 14:47:22.001 DEBUG: Atoms are too close
2022-12-30 14:47:23.137 DEBUG: Atoms are too close
2022-12-30 14:47:23.728 DEBUG: Atoms are too close
2022-12-30 14:47:24.747 DEBUG: Atoms are too close
2022-12-30 14:47:26.092 DEBUG: There is a single atom floating around
2022-12-30 14:47:27.813 DEBUG: There is a single atom floating around
2022-12-30 14:47:27.816 DEBUG: There is a single atom floating around
2022-12-30 14:47:28.158 DEBUG: There is a single atom floating around
2022-12-30 14:47:28.683 DEBUG: Atoms are too close
2022-12-30 14:47:30.045 DEBUG: There is a single atom floating around
2022-12-30 14:47:30.699 DEBUG: There is a single atom floating around
2022-12-30 14:47:31.955 DEBUG: There is a single atom floating around
2022-12-30 14:47:32.343 DEBUG: Atoms are too close
2022-12-30 14:47:33.270 DEBUG: Atoms are too close
2022-12-30 14:47:35.543 DEBUG: Atoms are too close
2022-12-30 14:47:36.761 DEBUG: Atoms are too close
2022-12-30 14:47:36.763 DEBUG: Atoms are too close
2022-12-30 14:47:36.763 DEBUG: There is a single atom floating around
2022-12-30 14:47:36.764 DEBUG: There is a single atom floating around
2022-12-30 14:47:37.899 DEBUG: There is a single atom floating around
2022-12-30 14:47:39.281 DEBUG: Atoms are too close
2022-12-30 14:47:39.803 DEBUG: There is a single atom floating around
2022-12-30 14:47:40.152 INFO: Training rollout: return=-13.743 (9.3), episode length=3.8
2022-12-30 14:47:40.153 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_train.txt
2022-12-30 14:47:40.156 DEBUG: Saving rollout: runs/CH4_int/data/CH4_int_run-1_steps-0_train.pkl
2022-12-30 14:47:41.987 DEBUG: Taking gradient step
2022-12-30 14:47:45.896 DEBUG: Loss 0: {'policy_loss': 0.028799190733568895, 'entropy_loss': -0.04379872418940067, 'vf_loss': 0.2298080764804815, 'total_loss': -0.014999533455831777, 'approx_kl': -4.9282486092039335e-08, 'clip_fraction': 0.0, 'grad_norm': 102.22837829589844}
2022-12-30 14:47:49.454 DEBUG: Taking gradient step
2022-12-30 14:47:51.692 DEBUG: Loss 1: {'policy_loss': -0.03724214687874947, 'entropy_loss': -0.043032088316977024, 'vf_loss': 0.22636127070852863, 'total_loss': -0.08027423519572649, 'approx_kl': -0.012912363279610872, 'clip_fraction': 0.3515625, 'grad_norm': 44.52015686035156}
2022-12-30 14:47:54.055 DEBUG: Taking gradient step
2022-12-30 14:47:56.470 DEBUG: Loss 2: {'policy_loss': 0.08703783142284352, 'entropy_loss': -0.04336636886000633, 'vf_loss': 0.22386220094112455, 'total_loss': 0.04367146256283718, 'approx_kl': 0.018601828487589955, 'clip_fraction': 0.47265625, 'grad_norm': 56.10928726196289}
2022-12-30 14:47:58.931 DEBUG: Taking gradient step
2022-12-30 14:48:01.348 DEBUG: Loss 3: {'policy_loss': 0.18306223331733712, 'entropy_loss': -0.04470180906355381, 'vf_loss': 0.23652886869082673, 'total_loss': 0.1383604242537833, 'approx_kl': 0.031283189775422215, 'clip_fraction': 0.52734375, 'grad_norm': 35.29237365722656}
2022-12-30 14:48:03.822 DEBUG: Taking gradient step
2022-12-30 14:48:06.186 DEBUG: Loss 4: {'policy_loss': 0.08396577876886215, 'entropy_loss': -0.04393826238811016, 'vf_loss': 0.2259126136624695, 'total_loss': 0.040027516380751985, 'approx_kl': -0.022809477522969246, 'clip_fraction': 0.4361979216337204, 'grad_norm': 55.92783737182617}
2022-12-30 14:48:08.587 DEBUG: Taking gradient step
2022-12-30 14:48:11.002 DEBUG: Loss 5: {'policy_loss': 0.0558198379475097, 'entropy_loss': -0.04237668402493, 'vf_loss': 0.23173884377047627, 'total_loss': 0.0134431539225797, 'approx_kl': 0.0007788287475705147, 'clip_fraction': 0.26953125, 'grad_norm': 42.306758880615234}
2022-12-30 14:48:13.377 DEBUG: Taking gradient step
2022-12-30 14:48:15.732 DEBUG: Loss 6: {'policy_loss': 0.012407757500492387, 'entropy_loss': -0.04294328950345516, 'vf_loss': 0.2286808630877522, 'total_loss': -0.030535532002962773, 'approx_kl': -0.013328674016520381, 'clip_fraction': 0.2200520858168602, 'grad_norm': 14.585282325744629}
2022-12-30 14:48:18.147 DEBUG: Taking gradient step
2022-12-30 14:48:20.572 DEBUG: Loss 7: {'policy_loss': 0.024210789855835975, 'entropy_loss': -0.04469472635537386, 'vf_loss': 0.23597721088761062, 'total_loss': -0.020483936499537884, 'approx_kl': -0.011478906963020563, 'clip_fraction': 0.3463541716337204, 'grad_norm': 25.521732330322266}
2022-12-30 14:48:23.039 DEBUG: Taking gradient step
2022-12-30 14:48:25.550 DEBUG: Loss 8: {'policy_loss': 0.019106220566060088, 'entropy_loss': -0.04351152200251818, 'vf_loss': 0.23143716151855728, 'total_loss': -0.02440530143645809, 'approx_kl': -0.012117802631109953, 'clip_fraction': 0.375, 'grad_norm': 38.47792434692383}
2022-12-30 14:48:28.047 DEBUG: Taking gradient step
2022-12-30 14:48:30.515 DEBUG: Loss 9: {'policy_loss': 0.04203683614838176, 'entropy_loss': -0.044515362940728664, 'vf_loss': 0.23367704016351162, 'total_loss': -0.0024785267923469086, 'approx_kl': -0.016541787888854742, 'clip_fraction': 0.3411458358168602, 'grad_norm': 28.44597053527832}
2022-12-30 14:48:30.516 INFO: Optimization: policy loss=0.042, vf loss=0.234, entropy loss=-0.045, total loss=-0.002, num steps=10
2022-12-30 14:48:30.517 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_opt.txt
2022-12-30 14:48:31.672 DEBUG: Atoms are too close
2022-12-30 14:48:31.674 INFO: Evaluation rollout: return=-19.688 (0.0), episode length=5.0
2022-12-30 14:48:31.674 DEBUG: Saving info: runs/CH4_int/results/CH4_int_run-1_eval.txt
2022-12-30 14:48:31.677 DEBUG: Saving model: runs/CH4_int/models/CH4_int_run-1_steps-216.model
2022-12-30 14:48:31.727 INFO: Iteration: 1/137, steps: 216
2022-12-30 14:48:34.290 DEBUG: There is a single atom floating around
2022-12-30 14:48:35.344 DEBUG: There is a single atom floating around
2022-12-30 14:48:35.345 DEBUG: There is a single atom floating around
2022-12-30 14:48:35.998 DEBUG: Atoms are too close
2022-12-30 14:48:38.384 DEBUG: Atoms are too close
2022-12-30 14:48:38.988 DEBUG: Atoms are too close
2022-12-30 14:48:41.824 DEBUG: Atoms are too close
2022-12-30 14:48:42.020 DEBUG: Atoms are too close
2022-12-30 14:48:42.021 DEBUG: Atoms are too close
2022-12-30 14:48:42.431 DEBUG: There is a single atom floating around
2022-12-30 14:48:42.886 DEBUG: There is a single atom floating around
2022-12-30 14:48:44.582 DEBUG: There is a single atom floating around
2022-12-30 14:48:45.260 DEBUG: There is a single atom floating around
2022-12-30 14:48:45.261 DEBUG: Atoms are too close
2022-12-30 14:48:47.077 DEBUG: There is a single atom floating around
2022-12-30 14:48:48.747 DEBUG: There is a single atom floating around
2022-12-30 14:48:49.276 DEBUG: There is a single atom floating around
