2022-12-29 11:29:28.508 INFO: {
    "bag_scale": 6,
    "beta": "-10",
    "canvas_size": 6,
    "clip_ratio": 0.2,
    "cutoff": 4.0,
    "data_dir": "runs/H2O/data",
    "device": "cuda",
    "discount": 1.0,
    "entropy_coef": 0.06,
    "eval_formulas": "H2O",
    "eval_freq": 1,
    "formulas": "H2O",
    "gradient_clip": 0.5,
    "keep_models": false,
    "lam": 1.0,
    "learning_rate": 0.0003,
    "load_latest": false,
    "load_model": null,
    "log_dir": "runs/H2O/logs",
    "log_level": "DEBUG",
    "max_mean_distance": 1.8,
    "max_num_steps": 30000,
    "max_num_train_iters": 10,
    "max_solo_distance": 2.0,
    "maxl": 4,
    "min_atomic_distance": 0.6,
    "min_mean_distance": 0.8,
    "min_reward": -20.0,
    "mini_batch_size": 64,
    "model": "schnet_edge",
    "model_dir": "runs/H2O/models",
    "name": "H2O",
    "network_width": 128,
    "num_cg_levels": 3,
    "num_channels_hidden": 10,
    "num_channels_per_element": 4,
    "num_envs": 12,
    "num_eval_episodes": null,
    "num_gaussians": 3,
    "num_interactions": 3,
    "num_steps_per_iter": 216,
    "optimizer": "adam",
    "results_dir": "runs/H2O/results",
    "save_freq": 10,
    "save_rollouts": "train",
    "seed": 1,
    "symbols": "X,H,O",
    "target_kl": 0.03,
    "update_edges": true,
    "vf_coef": 0.001
}
2022-12-29 11:29:28.545 INFO: CUDA Device: 0
2022-12-29 11:29:28.546 INFO: Training bags: ['H2O']
2022-12-29 11:29:28.546 INFO: Evaluation bags: ['H2O']
2022-12-29 11:29:30.272 INFO: Number of parameters: 299732
2022-12-29 11:29:30.284 INFO: Starting PPO
2022-12-29 11:29:30.284 INFO: Iteration: 0/137, steps: 0
2022-12-29 11:29:33.075 DEBUG: There is a single atom floating around
2022-12-29 11:29:33.363 DEBUG: There is a single atom floating around
2022-12-29 11:29:33.911 DEBUG: There is a single atom floating around
2022-12-29 11:29:34.977 DEBUG: There is a single atom floating around
2022-12-29 11:29:40.082 DEBUG: There is a single atom floating around
2022-12-29 11:29:48.097 DEBUG: Atoms are too close
2022-12-29 11:29:48.365 DEBUG: There is a single atom floating around
2022-12-29 11:29:49.381 DEBUG: There is a single atom floating around
2022-12-29 11:29:49.956 DEBUG: There is a single atom floating around
2022-12-29 11:29:51.068 DEBUG: Atoms are too close
2022-12-29 11:29:55.360 DEBUG: Atoms are too close
2022-12-29 11:29:55.948 DEBUG: There is a single atom floating around
2022-12-29 11:29:57.706 DEBUG: Atoms are too close
2022-12-29 11:30:00.203 DEBUG: There is a single atom floating around
2022-12-29 11:30:00.204 DEBUG: There is a single atom floating around
2022-12-29 11:30:00.917 DEBUG: There is a single atom floating around
2022-12-29 11:30:05.609 DEBUG: There is a single atom floating around
2022-12-29 11:30:06.103 DEBUG: There is a single atom floating around
2022-12-29 11:30:06.217 DEBUG: Atoms are too close
2022-12-29 11:30:07.475 DEBUG: There is a single atom floating around
2022-12-29 11:30:07.477 DEBUG: There is a single atom floating around
2022-12-29 11:30:09.224 DEBUG: There is a single atom floating around
2022-12-29 11:30:09.510 DEBUG: There is a single atom floating around
2022-12-29 11:30:10.395 DEBUG: There is a single atom floating around
2022-12-29 11:30:10.657 DEBUG: Atoms are too close
2022-12-29 11:30:10.830 DEBUG: There is a single atom floating around
2022-12-29 11:30:10.944 DEBUG: There is a single atom floating around
2022-12-29 11:30:10.946 DEBUG: There is a single atom floating around
2022-12-29 11:30:12.249 INFO: Training rollout: return=-6.968 (9.8), episode length=2.7
2022-12-29 11:30:12.250 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 11:30:12.253 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-0_train.pkl
2022-12-29 11:30:12.943 DEBUG: Taking gradient step
2022-12-29 11:30:12.955 DEBUG: Loss 0: {'policy_loss': 0.0011064176295018321, 'entropy_loss': -0.03312969580292702, 'vf_loss': 0.11547588542256312, 'total_loss': 0.08345260724913794, 'approx_kl': 2.405919019565772e-09, 'clip_fraction': 0.0, 'grad_norm': 9.306910514831543}
2022-12-29 11:30:13.642 DEBUG: Taking gradient step
2022-12-29 11:30:13.651 DEBUG: Loss 1: {'policy_loss': -0.02995608131351092, 'entropy_loss': -0.0321284644305706, 'vf_loss': 0.11515461814359511, 'total_loss': 0.053070072399513606, 'approx_kl': 0.017147082835435867, 'clip_fraction': 0.13411458395421505, 'grad_norm': 7.904665470123291}
2022-12-29 11:30:14.346 DEBUG: Taking gradient step
2022-12-29 11:30:14.355 DEBUG: Loss 2: {'policy_loss': -0.01276759929767847, 'entropy_loss': -0.032311015762388706, 'vf_loss': 0.1194937595210914, 'total_loss': 0.07441514446102424, 'approx_kl': 0.017684446182101965, 'clip_fraction': 0.09765625, 'grad_norm': 5.353682518005371}
2022-12-29 11:30:15.033 DEBUG: Taking gradient step
2022-12-29 11:30:15.043 DEBUG: Loss 3: {'policy_loss': -0.06996237826233494, 'entropy_loss': -0.03204905055463314, 'vf_loss': 0.11125326832889434, 'total_loss': 0.009241839511926274, 'approx_kl': 0.016425703652203083, 'clip_fraction': 0.25, 'grad_norm': 9.789529800415039}
2022-12-29 11:30:15.733 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-29 11:30:15.733 INFO: Optimization: policy loss=-0.070, vf loss=0.111, entropy loss=-0.032, total loss=0.009, num steps=4
2022-12-29 11:30:15.733 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 11:30:16.475 INFO: Evaluation rollout: return=0.475 (0.0), episode length=3.0
2022-12-29 11:30:16.476 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 11:30:16.478 DEBUG: Saving model: runs/H2O/models/H2O_run-1_steps-216.model
2022-12-29 11:30:16.509 INFO: Iteration: 1/137, steps: 216
2022-12-29 11:30:18.924 DEBUG: There is a single atom floating around
2022-12-29 11:30:20.107 DEBUG: There is a single atom floating around
2022-12-29 11:30:20.943 DEBUG: Atoms are too close
2022-12-29 11:30:26.057 DEBUG: There is a single atom floating around
2022-12-29 11:30:26.867 DEBUG: There is a single atom floating around
2022-12-29 11:30:26.868 DEBUG: There is a single atom floating around
2022-12-29 11:30:28.794 DEBUG: Atoms are too close
2022-12-29 11:30:30.914 DEBUG: There is a single atom floating around
2022-12-29 11:30:31.232 DEBUG: There is a single atom floating around
2022-12-29 11:30:31.546 DEBUG: There is a single atom floating around
2022-12-29 11:30:33.115 DEBUG: There is a single atom floating around
2022-12-29 11:30:36.973 DEBUG: There is a single atom floating around
2022-12-29 11:30:38.203 DEBUG: There is a single atom floating around
2022-12-29 11:30:40.981 DEBUG: Atoms are too close
2022-12-29 11:30:41.427 DEBUG: Atoms are too close
2022-12-29 11:30:41.427 DEBUG: There is a single atom floating around
2022-12-29 11:30:46.807 DEBUG: There is a single atom floating around
2022-12-29 11:30:47.528 DEBUG: There is a single atom floating around
2022-12-29 11:30:47.529 DEBUG: There is a single atom floating around
2022-12-29 11:30:48.064 DEBUG: There is a single atom floating around
2022-12-29 11:30:51.919 DEBUG: There is a single atom floating around
2022-12-29 11:30:53.114 DEBUG: There is a single atom floating around
2022-12-29 11:30:59.556 INFO: Training rollout: return=-5.703 (9.4), episode length=2.8
2022-12-29 11:30:59.558 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 11:30:59.560 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-216_train.pkl
2022-12-29 11:31:00.281 DEBUG: Taking gradient step
2022-12-29 11:31:00.290 DEBUG: Loss 0: {'policy_loss': -0.005703284232247455, 'entropy_loss': -0.03209078963845968, 'vf_loss': 0.08684152785198979, 'total_loss': 0.049047453981282664, 'approx_kl': 4.8855630652155924e-08, 'clip_fraction': 0.0, 'grad_norm': 9.782194137573242}
2022-12-29 11:31:00.968 DEBUG: Taking gradient step
2022-12-29 11:31:00.977 DEBUG: Loss 1: {'policy_loss': -0.03185946214820452, 'entropy_loss': -0.03272768808528781, 'vf_loss': 0.08634757797594529, 'total_loss': 0.021760427742452966, 'approx_kl': 0.0044994542840868235, 'clip_fraction': 0.026041666977107525, 'grad_norm': 6.307703018188477}
2022-12-29 11:31:01.642 DEBUG: Taking gradient step
2022-12-29 11:31:01.651 DEBUG: Loss 2: {'policy_loss': 0.009139998059259774, 'entropy_loss': -0.03262536134570837, 'vf_loss': 0.09630883894751585, 'total_loss': 0.07282347566106726, 'approx_kl': 0.014896789100021124, 'clip_fraction': 0.1341145858168602, 'grad_norm': 4.619225978851318}
2022-12-29 11:31:02.338 DEBUG: Taking gradient step
2022-12-29 11:31:02.347 DEBUG: Loss 3: {'policy_loss': -0.039124670390153556, 'entropy_loss': -0.03094186121597886, 'vf_loss': 0.08856653710784826, 'total_loss': 0.01850000550171585, 'approx_kl': 0.014135218691080809, 'clip_fraction': 0.1783854179084301, 'grad_norm': 5.188128471374512}
2022-12-29 11:31:03.038 DEBUG: Taking gradient step
2022-12-29 11:31:03.047 DEBUG: Loss 4: {'policy_loss': -0.02368984030994869, 'entropy_loss': -0.030318149365484715, 'vf_loss': 0.09045535375465938, 'total_loss': 0.036447364079225976, 'approx_kl': 0.03596178186126053, 'clip_fraction': 0.2395833358168602, 'grad_norm': 3.573984146118164}
2022-12-29 11:31:03.759 DEBUG: Taking gradient step
2022-12-29 11:31:03.769 DEBUG: Loss 5: {'policy_loss': -0.06302384972067937, 'entropy_loss': -0.03066869918256998, 'vf_loss': 0.08510643027269106, 'total_loss': -0.00858611863055828, 'approx_kl': 0.038024787325412035, 'clip_fraction': 0.2747395858168602, 'grad_norm': 7.588587760925293}
2022-12-29 11:31:04.445 DEBUG: Taking gradient step
2022-12-29 11:31:04.454 DEBUG: Loss 6: {'policy_loss': -0.08568342670882567, 'entropy_loss': -0.0282945167273283, 'vf_loss': 0.08218358308870308, 'total_loss': -0.03179436034745092, 'approx_kl': 0.0435295479837805, 'clip_fraction': 0.2161458358168602, 'grad_norm': 5.667273998260498}
2022-12-29 11:31:05.163 DEBUG: Early stopping at step 7 for reaching max KL.
2022-12-29 11:31:05.163 INFO: Optimization: policy loss=-0.086, vf loss=0.082, entropy loss=-0.028, total loss=-0.032, num steps=7
2022-12-29 11:31:05.164 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 11:31:05.842 INFO: Evaluation rollout: return=0.476 (0.0), episode length=3.0
2022-12-29 11:31:05.843 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 11:31:05.845 INFO: Iteration: 2/137, steps: 432
2022-12-29 11:31:07.439 DEBUG: There is a single atom floating around
2022-12-29 11:31:07.715 DEBUG: There is a single atom floating around
2022-12-29 11:31:08.018 DEBUG: There is a single atom floating around
2022-12-29 11:31:26.101 DEBUG: There is a single atom floating around
2022-12-29 11:31:32.875 DEBUG: There is a single atom floating around
2022-12-29 11:31:33.400 DEBUG: There is a single atom floating around
2022-12-29 11:31:38.667 DEBUG: There is a single atom floating around
2022-12-29 11:31:48.146 DEBUG: There is a single atom floating around
2022-12-29 11:31:52.924 INFO: Training rollout: return=-1.824 (6.4), episode length=2.9
2022-12-29 11:31:52.925 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 11:31:52.928 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-432_train.pkl
2022-12-29 11:31:53.651 DEBUG: Taking gradient step
2022-12-29 11:31:53.660 DEBUG: Loss 0: {'policy_loss': 0.055558388428204104, 'entropy_loss': -0.028396154288202524, 'vf_loss': 0.034718593015875536, 'total_loss': 0.06188082715587712, 'approx_kl': -4.190951585769653e-09, 'clip_fraction': 0.0, 'grad_norm': 6.788373947143555}
2022-12-29 11:31:54.397 DEBUG: Taking gradient step
2022-12-29 11:31:54.406 DEBUG: Loss 1: {'policy_loss': -0.006673504950173274, 'entropy_loss': -0.026943274307996035, 'vf_loss': 0.029897652426634936, 'total_loss': -0.0037191268315343706, 'approx_kl': 0.003367546043591574, 'clip_fraction': 0.022135416977107525, 'grad_norm': 5.831541538238525}
2022-12-29 11:31:55.157 DEBUG: Taking gradient step
2022-12-29 11:31:55.166 DEBUG: Loss 2: {'policy_loss': -0.044288813568509014, 'entropy_loss': -0.026351148262619972, 'vf_loss': 0.02733913639779171, 'total_loss': -0.04330082543333727, 'approx_kl': 0.00697636412223801, 'clip_fraction': 0.049479166977107525, 'grad_norm': 7.831761837005615}
2022-12-29 11:31:55.916 DEBUG: Taking gradient step
2022-12-29 11:31:55.925 DEBUG: Loss 3: {'policy_loss': 0.02138690412558246, 'entropy_loss': -0.02664985228329897, 'vf_loss': 0.03475411027053904, 'total_loss': 0.029491162112822517, 'approx_kl': 0.012264435994438827, 'clip_fraction': 0.08203125, 'grad_norm': 5.154264450073242}
2022-12-29 11:31:56.774 DEBUG: Taking gradient step
2022-12-29 11:31:56.784 DEBUG: Loss 4: {'policy_loss': -0.07266226236328749, 'entropy_loss': -0.02582762623205781, 'vf_loss': 0.024879966256901635, 'total_loss': -0.07360992233844366, 'approx_kl': 0.0015462731244042516, 'clip_fraction': 0.03515625, 'grad_norm': 2.193014144897461}
2022-12-29 11:31:57.513 DEBUG: Taking gradient step
2022-12-29 11:31:57.522 DEBUG: Loss 5: {'policy_loss': -0.0028836699699856735, 'entropy_loss': -0.026048345491290092, 'vf_loss': 0.03250255719256671, 'total_loss': 0.003570541731290934, 'approx_kl': -0.0022368452046066523, 'clip_fraction': 0.0625, 'grad_norm': 1.6953881978988647}
2022-12-29 11:31:58.236 DEBUG: Taking gradient step
2022-12-29 11:31:58.245 DEBUG: Loss 6: {'policy_loss': -0.017562707768318433, 'entropy_loss': -0.02517093624919653, 'vf_loss': 0.032009577195465155, 'total_loss': -0.010724066822049808, 'approx_kl': 0.0026870127767324448, 'clip_fraction': 0.16145833395421505, 'grad_norm': 3.6772689819335938}
2022-12-29 11:31:58.980 DEBUG: Taking gradient step
2022-12-29 11:31:58.991 DEBUG: Loss 7: {'policy_loss': -0.011051522049226617, 'entropy_loss': -0.025220916140824556, 'vf_loss': 0.03213618117828322, 'total_loss': -0.004136257011767938, 'approx_kl': 0.007463765796273947, 'clip_fraction': 0.1888020858168602, 'grad_norm': 3.770278215408325}
2022-12-29 11:31:59.761 DEBUG: Taking gradient step
2022-12-29 11:31:59.770 DEBUG: Loss 8: {'policy_loss': -0.0641462941189218, 'entropy_loss': -0.024204114452004433, 'vf_loss': 0.027211828542024703, 'total_loss': -0.06113858002890153, 'approx_kl': -0.007871496956795454, 'clip_fraction': 0.1979166679084301, 'grad_norm': 2.970576524734497}
2022-12-29 11:32:00.540 DEBUG: Taking gradient step
2022-12-29 11:32:00.553 DEBUG: Loss 9: {'policy_loss': -0.06388187600751323, 'entropy_loss': -0.02396623231470585, 'vf_loss': 0.026839283274057317, 'total_loss': -0.06100882504816177, 'approx_kl': 0.0107104986673221, 'clip_fraction': 0.09114583395421505, 'grad_norm': 1.1814160346984863}
2022-12-29 11:32:00.553 INFO: Optimization: policy loss=-0.064, vf loss=0.027, entropy loss=-0.024, total loss=-0.061, num steps=10
2022-12-29 11:32:00.554 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 11:32:01.302 INFO: Evaluation rollout: return=0.475 (0.0), episode length=3.0
2022-12-29 11:32:01.303 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 11:32:01.305 INFO: Iteration: 3/137, steps: 648
2022-12-29 11:32:03.510 DEBUG: There is a single atom floating around
2022-12-29 11:32:05.646 DEBUG: There is a single atom floating around
2022-12-29 11:32:36.527 DEBUG: There is a single atom floating around
2022-12-29 11:32:46.544 DEBUG: There is a single atom floating around
2022-12-29 11:32:49.744 INFO: Training rollout: return=-0.685 (4.7), episode length=2.9
2022-12-29 11:32:49.746 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 11:32:49.748 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-648_train.pkl
2022-12-29 11:32:50.489 DEBUG: Taking gradient step
2022-12-29 11:32:50.499 DEBUG: Loss 0: {'policy_loss': -0.029682227654506795, 'entropy_loss': -0.023292584344744682, 'vf_loss': 0.01287609483257913, 'total_loss': -0.04009871716667235, 'approx_kl': -5.1853324745110285e-08, 'clip_fraction': 0.0, 'grad_norm': 6.928159236907959}
2022-12-29 11:32:51.204 DEBUG: Taking gradient step
2022-12-29 11:32:51.213 DEBUG: Loss 1: {'policy_loss': -0.03560821109412379, 'entropy_loss': -0.023848360404372215, 'vf_loss': 0.012783010821755612, 'total_loss': -0.046673560676740396, 'approx_kl': 0.0004201245028525591, 'clip_fraction': 0.03515625, 'grad_norm': 3.272732734680176}
2022-12-29 11:32:51.913 DEBUG: Taking gradient step
2022-12-29 11:32:51.922 DEBUG: Loss 2: {'policy_loss': -0.006846033741682864, 'entropy_loss': -0.023776891641318798, 'vf_loss': 0.015293194885196593, 'total_loss': -0.015329730497805071, 'approx_kl': -0.0006463376339524984, 'clip_fraction': 0.11979166697710752, 'grad_norm': 4.847349166870117}
2022-12-29 11:32:52.627 DEBUG: Taking gradient step
2022-12-29 11:32:52.644 DEBUG: Loss 3: {'policy_loss': 0.020577728563797477, 'entropy_loss': -0.024179916363209486, 'vf_loss': 0.01749227687313381, 'total_loss': 0.0138900890737218, 'approx_kl': 0.0023238197900354862, 'clip_fraction': 0.14453125, 'grad_norm': 6.171711444854736}
2022-12-29 11:32:53.383 DEBUG: Taking gradient step
2022-12-29 11:32:53.392 DEBUG: Loss 4: {'policy_loss': -0.04621007173776633, 'entropy_loss': -0.02375200856477022, 'vf_loss': 0.012609155465171235, 'total_loss': -0.057352924837365316, 'approx_kl': 0.007407056866213679, 'clip_fraction': 0.15755208395421505, 'grad_norm': 4.283931732177734}
2022-12-29 11:32:54.087 DEBUG: Taking gradient step
2022-12-29 11:32:54.099 DEBUG: Loss 5: {'policy_loss': -0.05521788181508368, 'entropy_loss': -0.02319230232387781, 'vf_loss': 0.012608074968918453, 'total_loss': -0.06580210917004303, 'approx_kl': -0.00012612459249794483, 'clip_fraction': 0.1471354179084301, 'grad_norm': 3.1478023529052734}
2022-12-29 11:32:54.803 DEBUG: Taking gradient step
2022-12-29 11:32:54.816 DEBUG: Loss 6: {'policy_loss': -0.026359235968288874, 'entropy_loss': -0.02346312953159213, 'vf_loss': 0.014746844779764413, 'total_loss': -0.03507552072011659, 'approx_kl': 0.00790656846947968, 'clip_fraction': 0.10416666697710752, 'grad_norm': 2.7573609352111816}
2022-12-29 11:32:55.519 DEBUG: Taking gradient step
2022-12-29 11:32:55.529 DEBUG: Loss 7: {'policy_loss': -0.018749889494080293, 'entropy_loss': -0.024099016562104225, 'vf_loss': 0.014981851407762366, 'total_loss': -0.027867054648422155, 'approx_kl': -0.004532441729679704, 'clip_fraction': 0.061197916977107525, 'grad_norm': 1.7669767141342163}
2022-12-29 11:32:56.284 DEBUG: Taking gradient step
2022-12-29 11:32:56.294 DEBUG: Loss 8: {'policy_loss': -0.022886133813313045, 'entropy_loss': -0.024050516542047262, 'vf_loss': 0.014943091061672041, 'total_loss': -0.031993559293688266, 'approx_kl': -0.0021101085003465414, 'clip_fraction': 0.10546875, 'grad_norm': 1.627208948135376}
2022-12-29 11:32:57.014 DEBUG: Taking gradient step
2022-12-29 11:32:57.023 DEBUG: Loss 9: {'policy_loss': -0.052522262810572276, 'entropy_loss': -0.02345595322549343, 'vf_loss': 0.01232001272773413, 'total_loss': -0.06365820330833158, 'approx_kl': -0.004295566817745566, 'clip_fraction': 0.2135416679084301, 'grad_norm': 2.3824667930603027}
2022-12-29 11:32:57.024 INFO: Optimization: policy loss=-0.053, vf loss=0.012, entropy loss=-0.023, total loss=-0.064, num steps=10
2022-12-29 11:32:57.024 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 11:32:57.754 INFO: Evaluation rollout: return=0.466 (0.0), episode length=3.0
2022-12-29 11:32:57.755 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 11:32:57.757 INFO: Iteration: 4/137, steps: 864
2022-12-29 11:33:18.235 DEBUG: There is a single atom floating around
2022-12-29 11:33:47.334 INFO: Training rollout: return=0.167 (2.4), episode length=3.0
2022-12-29 11:33:47.335 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 11:33:47.338 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-864_train.pkl
2022-12-29 11:33:48.103 DEBUG: Taking gradient step
2022-12-29 11:33:48.117 DEBUG: Loss 0: {'policy_loss': -0.019548746984628183, 'entropy_loss': -0.022783535532653332, 'vf_loss': 0.0037008606452000295, 'total_loss': -0.03863142187208148, 'approx_kl': 3.158735761843445e-08, 'clip_fraction': 0.0, 'grad_norm': 4.466148853302002}
2022-12-29 11:33:48.839 DEBUG: Taking gradient step
2022-12-29 11:33:48.849 DEBUG: Loss 1: {'policy_loss': 0.03963342869127429, 'entropy_loss': -0.022161778062582016, 'vf_loss': 0.005870988231913491, 'total_loss': 0.023342638860605766, 'approx_kl': -0.0026015175972133875, 'clip_fraction': 0.00390625, 'grad_norm': 8.009576797485352}
2022-12-29 11:33:49.555 DEBUG: Taking gradient step
2022-12-29 11:33:49.564 DEBUG: Loss 2: {'policy_loss': 0.08360762756212052, 'entropy_loss': -0.022054576314985752, 'vf_loss': 0.008435319711465848, 'total_loss': 0.06998837095860062, 'approx_kl': -0.0009032455272972584, 'clip_fraction': 0.06510416697710752, 'grad_norm': 2.013571262359619}
2022-12-29 11:33:50.281 DEBUG: Taking gradient step
2022-12-29 11:33:50.290 DEBUG: Loss 3: {'policy_loss': -0.026828430110822036, 'entropy_loss': -0.022649701684713364, 'vf_loss': 0.0035589098519518358, 'total_loss': -0.04591922194358356, 'approx_kl': 0.003117771353572607, 'clip_fraction': 0.10286458395421505, 'grad_norm': 1.9283617734909058}
2022-12-29 11:33:51.031 DEBUG: Taking gradient step
2022-12-29 11:33:51.041 DEBUG: Loss 4: {'policy_loss': -0.024123006570113195, 'entropy_loss': -0.022413253784179688, 'vf_loss': 0.0034994381672711727, 'total_loss': -0.043036822187021706, 'approx_kl': -0.0020724469795823097, 'clip_fraction': 0.17578125, 'grad_norm': 1.932259202003479}
2022-12-29 11:33:51.781 DEBUG: Taking gradient step
2022-12-29 11:33:51.790 DEBUG: Loss 5: {'policy_loss': -0.022518665449082934, 'entropy_loss': -0.022935028187930584, 'vf_loss': 0.003449653049842115, 'total_loss': -0.0420040405871714, 'approx_kl': 0.0038514065090566874, 'clip_fraction': 0.234375, 'grad_norm': 1.798871636390686}
2022-12-29 11:33:52.509 DEBUG: Taking gradient step
2022-12-29 11:33:52.519 DEBUG: Loss 6: {'policy_loss': -0.028600456833553837, 'entropy_loss': -0.02160948608070612, 'vf_loss': 0.003446490652184777, 'total_loss': -0.04676345226207518, 'approx_kl': 0.016533719841390848, 'clip_fraction': 0.2200520858168602, 'grad_norm': 1.6430424451828003}
2022-12-29 11:33:53.247 DEBUG: Taking gradient step
2022-12-29 11:33:53.256 DEBUG: Loss 7: {'policy_loss': 0.018462739849250204, 'entropy_loss': -0.022032789885997772, 'vf_loss': 0.00573229540757989, 'total_loss': 0.0021622453708323233, 'approx_kl': 0.004473672015592456, 'clip_fraction': 0.1731770858168602, 'grad_norm': 1.6211621761322021}
2022-12-29 11:33:53.971 DEBUG: Taking gradient step
2022-12-29 11:33:53.981 DEBUG: Loss 8: {'policy_loss': -0.025938004250819695, 'entropy_loss': -0.021750094834715128, 'vf_loss': 0.00337745261342245, 'total_loss': -0.04431064647211237, 'approx_kl': 0.01747183594852686, 'clip_fraction': 0.1458333358168602, 'grad_norm': 1.9136072397232056}
2022-12-29 11:33:54.742 DEBUG: Taking gradient step
2022-12-29 11:33:54.751 DEBUG: Loss 9: {'policy_loss': -0.033153877923873726, 'entropy_loss': -0.021459282841533422, 'vf_loss': 0.003391836458112241, 'total_loss': -0.05122132430729491, 'approx_kl': 0.012349416414508596, 'clip_fraction': 0.1497395858168602, 'grad_norm': 1.1125909090042114}
2022-12-29 11:33:54.751 INFO: Optimization: policy loss=-0.033, vf loss=0.003, entropy loss=-0.021, total loss=-0.051, num steps=10
2022-12-29 11:33:54.752 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 11:33:55.491 INFO: Evaluation rollout: return=0.474 (0.0), episode length=3.0
2022-12-29 11:33:55.492 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 11:33:55.493 INFO: Iteration: 5/137, steps: 1080
2022-12-29 11:34:39.238 DEBUG: There is a single atom floating around
2022-12-29 11:34:45.504 INFO: Training rollout: return=0.164 (2.4), episode length=3.0
2022-12-29 11:34:45.506 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 11:34:45.509 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-1080_train.pkl
2022-12-29 11:34:46.336 DEBUG: Taking gradient step
2022-12-29 11:34:46.345 DEBUG: Loss 0: {'policy_loss': -0.014735016324292572, 'entropy_loss': -0.02170374058187008, 'vf_loss': 0.0032808787093916067, 'total_loss': -0.033157878196771046, 'approx_kl': -5.34734381218982e-08, 'clip_fraction': 0.0, 'grad_norm': 5.2095627784729}
2022-12-29 11:34:47.185 DEBUG: Taking gradient step
2022-12-29 11:34:47.197 DEBUG: Loss 1: {'policy_loss': 0.04407183414777548, 'entropy_loss': -0.02313758386299014, 'vf_loss': 0.005592607918903158, 'total_loss': 0.02652685820368849, 'approx_kl': 0.002134723647031933, 'clip_fraction': 0.0, 'grad_norm': 14.42873764038086}
2022-12-29 11:34:47.923 DEBUG: Taking gradient step
2022-12-29 11:34:47.932 DEBUG: Loss 2: {'policy_loss': -0.019904330439601374, 'entropy_loss': -0.022975089959800243, 'vf_loss': 0.0032768439455963597, 'total_loss': -0.03960257645380526, 'approx_kl': 0.001876779948361218, 'clip_fraction': 0.0078125, 'grad_norm': 4.882984161376953}
2022-12-29 11:34:48.642 DEBUG: Taking gradient step
2022-12-29 11:34:48.652 DEBUG: Loss 3: {'policy_loss': -0.018581954319735305, 'entropy_loss': -0.021427044412121177, 'vf_loss': 0.0032879743471753826, 'total_loss': -0.0367210243846811, 'approx_kl': 0.009380185802001506, 'clip_fraction': 0.029947916977107525, 'grad_norm': 2.6255457401275635}
2022-12-29 11:34:49.365 DEBUG: Taking gradient step
2022-12-29 11:34:49.375 DEBUG: Loss 4: {'policy_loss': -0.016397044173614463, 'entropy_loss': -0.023500056471675634, 'vf_loss': 0.0032773898491637804, 'total_loss': -0.03661971079612632, 'approx_kl': 0.009787621995201334, 'clip_fraction': 0.037760416977107525, 'grad_norm': 1.633791208267212}
2022-12-29 11:34:50.079 DEBUG: Taking gradient step
2022-12-29 11:34:50.089 DEBUG: Loss 5: {'policy_loss': -0.024249331837061794, 'entropy_loss': -0.024078012444078922, 'vf_loss': 0.0032881433382445763, 'total_loss': -0.04503920094289614, 'approx_kl': 0.018011131323873997, 'clip_fraction': 0.05989583395421505, 'grad_norm': 0.8766017556190491}
2022-12-29 11:34:50.829 DEBUG: Taking gradient step
2022-12-29 11:34:50.838 DEBUG: Loss 6: {'policy_loss': -0.017952576197956923, 'entropy_loss': -0.02374214679002762, 'vf_loss': 0.0032755426038976227, 'total_loss': -0.03841918038408692, 'approx_kl': 0.02485895634163171, 'clip_fraction': 0.11979166697710752, 'grad_norm': 1.1269413232803345}
2022-12-29 11:34:51.556 DEBUG: Taking gradient step
2022-12-29 11:34:51.565 DEBUG: Loss 7: {'policy_loss': -0.031019895283637897, 'entropy_loss': -0.024351974483579397, 'vf_loss': 0.003292362170063094, 'total_loss': -0.0520795075971542, 'approx_kl': 0.043439445085823536, 'clip_fraction': 0.2408854179084301, 'grad_norm': 0.9991201162338257}
2022-12-29 11:34:52.275 DEBUG: Early stopping at step 8 for reaching max KL.
2022-12-29 11:34:52.275 INFO: Optimization: policy loss=-0.031, vf loss=0.003, entropy loss=-0.024, total loss=-0.052, num steps=8
2022-12-29 11:34:52.275 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 11:34:53.043 INFO: Evaluation rollout: return=0.484 (0.0), episode length=3.0
2022-12-29 11:34:53.043 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 11:34:53.045 INFO: Iteration: 6/137, steps: 1296
2022-12-29 11:35:43.032 INFO: Training rollout: return=0.446 (0.1), episode length=3.0
2022-12-29 11:35:43.034 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 11:35:43.036 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-1296_train.pkl
2022-12-29 11:35:43.754 DEBUG: Taking gradient step
2022-12-29 11:35:43.764 DEBUG: Loss 0: {'policy_loss': 0.0003735127011905296, 'entropy_loss': -0.02449370687827468, 'vf_loss': 0.0003492257888721121, 'total_loss': -0.023770968388212035, 'approx_kl': -1.0283354612283802e-08, 'clip_fraction': 0.0, 'grad_norm': 8.696868896484375}
2022-12-29 11:35:44.479 DEBUG: Taking gradient step
2022-12-29 11:35:44.488 DEBUG: Loss 1: {'policy_loss': 0.009846617670029225, 'entropy_loss': -0.02347827237099409, 'vf_loss': 0.0003410917622068603, 'total_loss': -0.013290562938758006, 'approx_kl': 0.0032990480931403, 'clip_fraction': 0.00390625, 'grad_norm': 7.621365070343018}
2022-12-29 11:35:45.210 DEBUG: Taking gradient step
2022-12-29 11:35:45.219 DEBUG: Loss 2: {'policy_loss': 0.009547809729350158, 'entropy_loss': -0.025054410565644503, 'vf_loss': 0.0003400642836263713, 'total_loss': -0.015166536552667972, 'approx_kl': 0.01859008485917002, 'clip_fraction': 0.1015625, 'grad_norm': 7.402724742889404}
2022-12-29 11:35:45.947 DEBUG: Taking gradient step
2022-12-29 11:35:45.957 DEBUG: Loss 3: {'policy_loss': -0.010107216097826853, 'entropy_loss': -0.024832405149936676, 'vf_loss': 0.0003524630125337001, 'total_loss': -0.03458715823522983, 'approx_kl': 0.028643020370509475, 'clip_fraction': 0.1744791716337204, 'grad_norm': 12.92519760131836}
2022-12-29 11:35:46.681 DEBUG: Taking gradient step
2022-12-29 11:35:46.690 DEBUG: Loss 4: {'policy_loss': 0.028677632930492716, 'entropy_loss': -0.024711630307137966, 'vf_loss': 0.000329288978343889, 'total_loss': 0.004295291601698642, 'approx_kl': 0.03573492914438248, 'clip_fraction': 0.1822916716337204, 'grad_norm': 11.277280807495117}
2022-12-29 11:35:47.449 DEBUG: Taking gradient step
2022-12-29 11:35:47.459 DEBUG: Loss 5: {'policy_loss': -0.010574168633726289, 'entropy_loss': -0.023938117548823357, 'vf_loss': 0.0003160499460122439, 'total_loss': -0.034196236236537406, 'approx_kl': 0.044173699629027396, 'clip_fraction': 0.1953125, 'grad_norm': 5.264613628387451}
2022-12-29 11:35:48.176 DEBUG: Early stopping at step 6 for reaching max KL.
2022-12-29 11:35:48.177 INFO: Optimization: policy loss=-0.011, vf loss=0.000, entropy loss=-0.024, total loss=-0.034, num steps=6
2022-12-29 11:35:48.177 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 11:35:48.964 INFO: Evaluation rollout: return=0.476 (0.0), episode length=3.0
2022-12-29 11:35:48.965 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 11:35:48.966 INFO: Iteration: 7/137, steps: 1512
2022-12-29 11:36:03.234 DEBUG: Atoms are too close
2022-12-29 11:36:10.513 DEBUG: Atoms are too close
2022-12-29 11:36:38.846 INFO: Training rollout: return=-0.121 (3.3), episode length=3.0
2022-12-29 11:36:38.848 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 11:36:38.851 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-1512_train.pkl
2022-12-29 11:36:39.580 DEBUG: Taking gradient step
2022-12-29 11:36:39.589 DEBUG: Loss 0: {'policy_loss': -0.025002490009352424, 'entropy_loss': -0.024910600390285254, 'vf_loss': 0.009803465615122629, 'total_loss': -0.04010962478451505, 'approx_kl': -1.1641532182693481e-10, 'clip_fraction': 0.0, 'grad_norm': 12.660956382751465}
2022-12-29 11:36:40.298 DEBUG: Taking gradient step
2022-12-29 11:36:40.312 DEBUG: Loss 1: {'policy_loss': 0.03854818538138848, 'entropy_loss': -0.023960383608937263, 'vf_loss': 0.015230064927812032, 'total_loss': 0.029817866700263262, 'approx_kl': 0.005797375226393342, 'clip_fraction': 0.014322916977107525, 'grad_norm': 12.322843551635742}
2022-12-29 11:36:41.056 DEBUG: Taking gradient step
2022-12-29 11:36:41.066 DEBUG: Loss 2: {'policy_loss': 0.027820402262337715, 'entropy_loss': -0.023411863017827272, 'vf_loss': 0.01498210279461189, 'total_loss': 0.01939064203912233, 'approx_kl': 0.01803708099760115, 'clip_fraction': 0.10286458395421505, 'grad_norm': 10.015055656433105}
2022-12-29 11:36:41.781 DEBUG: Taking gradient step
2022-12-29 11:36:41.791 DEBUG: Loss 3: {'policy_loss': -0.040622824948260486, 'entropy_loss': -0.023374108597636223, 'vf_loss': 0.009781319553551847, 'total_loss': -0.05421561399234487, 'approx_kl': 0.0382617088034749, 'clip_fraction': 0.25390625, 'grad_norm': 1.416680932044983}
2022-12-29 11:36:42.502 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-29 11:36:42.503 INFO: Optimization: policy loss=-0.041, vf loss=0.010, entropy loss=-0.023, total loss=-0.054, num steps=4
2022-12-29 11:36:42.503 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 11:36:43.237 INFO: Evaluation rollout: return=0.460 (0.0), episode length=3.0
2022-12-29 11:36:43.238 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 11:36:43.240 INFO: Iteration: 8/137, steps: 1728
2022-12-29 11:37:34.621 INFO: Training rollout: return=0.440 (0.0), episode length=3.0
2022-12-29 11:37:34.623 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 11:37:34.625 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-1728_train.pkl
2022-12-29 11:37:35.358 DEBUG: Taking gradient step
2022-12-29 11:37:35.367 DEBUG: Loss 0: {'policy_loss': 0.0664877063812023, 'entropy_loss': -0.02433810941874981, 'vf_loss': 0.0002663093857267276, 'total_loss': 0.042415906348179225, 'approx_kl': 4.078416893094072e-08, 'clip_fraction': 0.0, 'grad_norm': 13.865891456604004}
2022-12-29 11:37:36.140 DEBUG: Taking gradient step
2022-12-29 11:37:36.150 DEBUG: Loss 1: {'policy_loss': -0.022572638164569295, 'entropy_loss': -0.02449253434315324, 'vf_loss': 0.00029761633406251886, 'total_loss': -0.04676755617366002, 'approx_kl': 0.0027334495243849233, 'clip_fraction': 0.0, 'grad_norm': 16.770959854125977}
2022-12-29 11:37:36.857 DEBUG: Taking gradient step
2022-12-29 11:37:36.869 DEBUG: Loss 2: {'policy_loss': 0.029847802533463183, 'entropy_loss': -0.023712342604994774, 'vf_loss': 0.00025878452711171064, 'total_loss': 0.006394244455580116, 'approx_kl': 0.014573583845049143, 'clip_fraction': 0.0546875, 'grad_norm': 10.748529434204102}
2022-12-29 11:37:37.586 DEBUG: Taking gradient step
2022-12-29 11:37:37.596 DEBUG: Loss 3: {'policy_loss': -0.005613323435951804, 'entropy_loss': -0.024340736214071512, 'vf_loss': 0.00026046600965229475, 'total_loss': -0.029693593640371017, 'approx_kl': 0.02788498974405229, 'clip_fraction': 0.1341145858168602, 'grad_norm': 7.190924167633057}
2022-12-29 11:37:38.344 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-29 11:37:38.345 INFO: Optimization: policy loss=-0.006, vf loss=0.000, entropy loss=-0.024, total loss=-0.030, num steps=4
2022-12-29 11:37:38.345 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 11:37:39.077 INFO: Evaluation rollout: return=0.451 (0.0), episode length=3.0
2022-12-29 11:37:39.078 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 11:37:39.080 INFO: Iteration: 9/137, steps: 1944
2022-12-29 11:38:10.546 DEBUG: Atoms are too close
2022-12-29 11:38:31.045 INFO: Training rollout: return=0.153 (2.4), episode length=3.0
2022-12-29 11:38:31.047 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 11:38:31.050 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-1944_train.pkl
2022-12-29 11:38:31.811 DEBUG: Taking gradient step
2022-12-29 11:38:31.820 DEBUG: Loss 0: {'policy_loss': -0.018413951416116632, 'entropy_loss': -0.024155263788998127, 'vf_loss': 0.004948209894673859, 'total_loss': -0.0376210053104409, 'approx_kl': 2.029507117917717e-08, 'clip_fraction': 0.0, 'grad_norm': 17.362730026245117}
2022-12-29 11:38:32.628 DEBUG: Taking gradient step
2022-12-29 11:38:32.637 DEBUG: Loss 1: {'policy_loss': -0.011502504637216623, 'entropy_loss': -0.025050603784620762, 'vf_loss': 0.00492397484090082, 'total_loss': -0.03162913358093656, 'approx_kl': 0.001759802151354961, 'clip_fraction': 0.00390625, 'grad_norm': 18.380935668945312}
2022-12-29 11:38:33.413 DEBUG: Taking gradient step
2022-12-29 11:38:33.422 DEBUG: Loss 2: {'policy_loss': -0.02087739492958182, 'entropy_loss': -0.023826882243156433, 'vf_loss': 0.004924047898994905, 'total_loss': -0.03978022927374334, 'approx_kl': 0.00927647715434432, 'clip_fraction': 0.06770833395421505, 'grad_norm': 15.711893081665039}
2022-12-29 11:38:34.228 DEBUG: Taking gradient step
2022-12-29 11:38:34.238 DEBUG: Loss 3: {'policy_loss': 0.030943279095505413, 'entropy_loss': -0.022963937371969223, 'vf_loss': 0.007560504688830787, 'total_loss': 0.015539846412366977, 'approx_kl': 0.0151552758179605, 'clip_fraction': 0.125, 'grad_norm': 12.483541488647461}
2022-12-29 11:38:35.049 DEBUG: Taking gradient step
2022-12-29 11:38:35.058 DEBUG: Loss 4: {'policy_loss': -0.020252816055044538, 'entropy_loss': -0.024487948045134544, 'vf_loss': 0.00490507240129823, 'total_loss': -0.039835691698880855, 'approx_kl': 0.026846104534342885, 'clip_fraction': 0.2174479216337204, 'grad_norm': 4.475002288818359}
2022-12-29 11:38:35.838 DEBUG: Taking gradient step
2022-12-29 11:38:35.847 DEBUG: Loss 5: {'policy_loss': -0.02004718103174708, 'entropy_loss': -0.023888058494776487, 'vf_loss': 0.004891544611438197, 'total_loss': -0.03904369491508537, 'approx_kl': 0.03888589050620794, 'clip_fraction': 0.30078125, 'grad_norm': 1.3831313848495483}
2022-12-29 11:38:36.614 DEBUG: Early stopping at step 6 for reaching max KL.
2022-12-29 11:38:36.614 INFO: Optimization: policy loss=-0.020, vf loss=0.005, entropy loss=-0.024, total loss=-0.039, num steps=6
2022-12-29 11:38:36.615 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 11:38:37.446 INFO: Evaluation rollout: return=0.427 (0.0), episode length=3.0
2022-12-29 11:38:37.446 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 11:38:37.448 INFO: Iteration: 10/137, steps: 2160
2022-12-29 11:38:59.845 DEBUG: Atoms are too close
2022-12-29 11:39:26.970 INFO: Training rollout: return=0.142 (2.4), episode length=3.0
2022-12-29 11:39:26.972 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 11:39:26.975 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-2160_train.pkl
2022-12-29 11:39:27.690 DEBUG: Taking gradient step
2022-12-29 11:39:27.700 DEBUG: Loss 0: {'policy_loss': 0.037110624570235756, 'entropy_loss': -0.023962932638823986, 'vf_loss': 0.007600193400100503, 'total_loss': 0.020747885331512277, 'approx_kl': 1.9615981727838516e-08, 'clip_fraction': 0.0, 'grad_norm': 29.48434066772461}
2022-12-29 11:39:28.420 DEBUG: Taking gradient step
2022-12-29 11:39:28.430 DEBUG: Loss 1: {'policy_loss': 0.019247752276282122, 'entropy_loss': -0.024336018599569798, 'vf_loss': 0.007574290723917999, 'total_loss': 0.002486024400630331, 'approx_kl': 0.01936768740415573, 'clip_fraction': 0.0690104179084301, 'grad_norm': 3.760688304901123}
2022-12-29 11:39:29.126 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-29 11:39:29.127 INFO: Optimization: policy loss=0.019, vf loss=0.008, entropy loss=-0.024, total loss=0.002, num steps=2
2022-12-29 11:39:29.127 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 11:39:29.839 INFO: Evaluation rollout: return=0.413 (0.0), episode length=3.0
2022-12-29 11:39:29.840 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 11:39:29.842 DEBUG: Deleting old model: runs/H2O/models/H2O_run-1_steps-216.model
2022-12-29 11:39:29.844 DEBUG: Saving model: runs/H2O/models/H2O_run-1_steps-2376.model
2022-12-29 11:39:29.873 INFO: Iteration: 11/137, steps: 2376
2022-12-29 11:39:53.744 DEBUG: Atoms are too close
2022-12-29 11:40:19.661 INFO: Training rollout: return=0.116 (2.4), episode length=3.0
2022-12-29 11:40:19.663 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 11:40:19.666 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-2376_train.pkl
2022-12-29 11:40:20.412 DEBUG: Taking gradient step
2022-12-29 11:40:20.422 DEBUG: Loss 0: {'policy_loss': 0.03463988328993634, 'entropy_loss': -0.02464688615873456, 'vf_loss': 0.007546357097302442, 'total_loss': 0.017539354228504223, 'approx_kl': 2.9103830456733704e-09, 'clip_fraction': 0.0, 'grad_norm': 44.59164047241211}
2022-12-29 11:40:21.109 DEBUG: Taking gradient step
2022-12-29 11:40:21.119 DEBUG: Loss 1: {'policy_loss': -0.02567997036123311, 'entropy_loss': -0.023607943207025528, 'vf_loss': 0.004877382096777455, 'total_loss': -0.044410531471481184, 'approx_kl': -0.008220354560762644, 'clip_fraction': 0.12109375, 'grad_norm': 1.4154921770095825}
2022-12-29 11:40:21.824 DEBUG: Taking gradient step
2022-12-29 11:40:21.833 DEBUG: Loss 2: {'policy_loss': -0.017876905108354067, 'entropy_loss': -0.024376026820391417, 'vf_loss': 0.004851111085303375, 'total_loss': -0.03740182084344211, 'approx_kl': -0.002560891523899045, 'clip_fraction': 0.2278645858168602, 'grad_norm': 1.5632216930389404}
2022-12-29 11:40:22.559 DEBUG: Taking gradient step
2022-12-29 11:40:22.573 DEBUG: Loss 3: {'policy_loss': -0.026235360293463322, 'entropy_loss': -0.023620834574103355, 'vf_loss': 0.0048665617953776545, 'total_loss': -0.04498963307218902, 'approx_kl': 0.0034099938347935677, 'clip_fraction': 0.2486979179084301, 'grad_norm': 1.617380142211914}
2022-12-29 11:40:23.326 DEBUG: Taking gradient step
2022-12-29 11:40:23.335 DEBUG: Loss 4: {'policy_loss': -0.023794527877190948, 'entropy_loss': -0.02365834452211857, 'vf_loss': 0.0048514131387371135, 'total_loss': -0.042601459260572405, 'approx_kl': 0.00433772848919034, 'clip_fraction': 0.2395833358168602, 'grad_norm': 1.574995756149292}
2022-12-29 11:40:24.054 DEBUG: Taking gradient step
2022-12-29 11:40:24.063 DEBUG: Loss 5: {'policy_loss': -0.028216537496561146, 'entropy_loss': -0.024265591986477375, 'vf_loss': 0.004855656469089399, 'total_loss': -0.04762647301394912, 'approx_kl': 0.0007315635084523819, 'clip_fraction': 0.1549479179084301, 'grad_norm': 1.5284855365753174}
2022-12-29 11:40:24.773 DEBUG: Taking gradient step
2022-12-29 11:40:24.782 DEBUG: Loss 6: {'policy_loss': 0.07859506763240597, 'entropy_loss': -0.024228171445429325, 'vf_loss': 0.010054035426735853, 'total_loss': 0.06442093161371251, 'approx_kl': 0.008154407143592834, 'clip_fraction': 0.1080729179084301, 'grad_norm': 2.7649056911468506}
2022-12-29 11:40:25.498 DEBUG: Taking gradient step
2022-12-29 11:40:25.508 DEBUG: Loss 7: {'policy_loss': 0.025541804387900335, 'entropy_loss': -0.02433900674805045, 'vf_loss': 0.007434731712245967, 'total_loss': 0.00863752935209585, 'approx_kl': 0.02860272617544979, 'clip_fraction': 0.1236979179084301, 'grad_norm': 1.6930111646652222}
2022-12-29 11:40:26.215 DEBUG: Taking gradient step
2022-12-29 11:40:26.225 DEBUG: Loss 8: {'policy_loss': 0.015548174366532604, 'entropy_loss': -0.023556817322969437, 'vf_loss': 0.007418649597595563, 'total_loss': -0.0005899933588412731, 'approx_kl': 0.03294495400041342, 'clip_fraction': 0.25, 'grad_norm': 4.191258907318115}
2022-12-29 11:40:26.969 DEBUG: Early stopping at step 9 for reaching max KL.
2022-12-29 11:40:26.969 INFO: Optimization: policy loss=0.016, vf loss=0.007, entropy loss=-0.024, total loss=-0.001, num steps=9
2022-12-29 11:40:26.970 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 11:40:27.635 INFO: Evaluation rollout: return=0.442 (0.0), episode length=3.0
2022-12-29 11:40:27.636 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 11:40:27.638 INFO: Iteration: 12/137, steps: 2592
2022-12-29 11:41:17.536 INFO: Training rollout: return=0.419 (0.0), episode length=3.0
2022-12-29 11:41:17.537 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 11:41:17.540 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-2592_train.pkl
2022-12-29 11:41:18.287 DEBUG: Taking gradient step
2022-12-29 11:41:18.297 DEBUG: Loss 0: {'policy_loss': -0.014126760181164863, 'entropy_loss': -0.024909716099500656, 'vf_loss': 0.00023899889418004165, 'total_loss': -0.03879747738648548, 'approx_kl': 3.8494667009558725e-08, 'clip_fraction': 0.0, 'grad_norm': 16.940841674804688}
2022-12-29 11:41:19.039 DEBUG: Taking gradient step
2022-12-29 11:41:19.048 DEBUG: Loss 1: {'policy_loss': -0.0003956764262300107, 'entropy_loss': -0.0243326211348176, 'vf_loss': 0.0002301835515336675, 'total_loss': -0.024498114009513943, 'approx_kl': 0.023540373658761382, 'clip_fraction': 0.16796875, 'grad_norm': 5.807784557342529}
2022-12-29 11:41:19.768 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-29 11:41:19.768 INFO: Optimization: policy loss=-0.000, vf loss=0.000, entropy loss=-0.024, total loss=-0.024, num steps=2
2022-12-29 11:41:19.769 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 11:41:20.522 INFO: Evaluation rollout: return=0.462 (0.0), episode length=3.0
2022-12-29 11:41:20.523 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 11:41:20.525 INFO: Iteration: 13/137, steps: 2808
2022-12-29 11:41:42.761 DEBUG: Atoms are too close
2022-12-29 11:41:50.388 DEBUG: Atoms are too close
2022-12-29 11:42:06.372 DEBUG: Atoms are too close
2022-12-29 11:42:08.663 INFO: Training rollout: return=-0.409 (4.0), episode length=3.0
2022-12-29 11:42:08.664 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 11:42:08.667 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-2808_train.pkl
2022-12-29 11:42:09.411 DEBUG: Taking gradient step
2022-12-29 11:42:09.421 DEBUG: Loss 0: {'policy_loss': -0.0014736661077975931, 'entropy_loss': -0.02421969687566161, 'vf_loss': 0.016586736313023348, 'total_loss': -0.009106626670435856, 'approx_kl': -6.076879799365997e-08, 'clip_fraction': 0.0, 'grad_norm': 26.322521209716797}
2022-12-29 11:42:10.121 DEBUG: Taking gradient step
2022-12-29 11:42:10.131 DEBUG: Loss 1: {'policy_loss': 0.026476861297483948, 'entropy_loss': -0.023856014013290405, 'vf_loss': 0.01659257834457894, 'total_loss': 0.01921342562877248, 'approx_kl': 0.005967269651591778, 'clip_fraction': 0.06901041697710752, 'grad_norm': 44.3988151550293}
2022-12-29 11:42:10.830 DEBUG: Taking gradient step
2022-12-29 11:42:10.839 DEBUG: Loss 2: {'policy_loss': 0.09493283101423242, 'entropy_loss': -0.023740538395941257, 'vf_loss': 0.021635574268316894, 'total_loss': 0.09282786688660806, 'approx_kl': -0.002549032913520932, 'clip_fraction': 0.2447916716337204, 'grad_norm': 44.05073928833008}
2022-12-29 11:42:11.527 DEBUG: Taking gradient step
2022-12-29 11:42:11.536 DEBUG: Loss 3: {'policy_loss': 0.046197617232519556, 'entropy_loss': -0.024064206518232822, 'vf_loss': 0.019011043372546152, 'total_loss': 0.0411444540868329, 'approx_kl': 0.0063286591321229935, 'clip_fraction': 0.2578125, 'grad_norm': 25.49675178527832}
2022-12-29 11:42:12.229 DEBUG: Taking gradient step
2022-12-29 11:42:12.238 DEBUG: Loss 4: {'policy_loss': -0.023188183274171985, 'entropy_loss': -0.02524579269811511, 'vf_loss': 0.01397460819165995, 'total_loss': -0.03445936778062714, 'approx_kl': 0.02312411298044026, 'clip_fraction': 0.3046875, 'grad_norm': 6.654329299926758}
2022-12-29 11:42:12.934 DEBUG: Taking gradient step
2022-12-29 11:42:12.943 DEBUG: Loss 5: {'policy_loss': 0.0023138162333562837, 'entropy_loss': -0.02407208690419793, 'vf_loss': 0.016538854283756108, 'total_loss': -0.0052194163870855435, 'approx_kl': 0.03339207777753472, 'clip_fraction': 0.3763020858168602, 'grad_norm': 6.472980499267578}
2022-12-29 11:42:13.632 DEBUG: Taking gradient step
2022-12-29 11:42:13.641 DEBUG: Loss 6: {'policy_loss': 0.009201769117645132, 'entropy_loss': -0.02529708342626691, 'vf_loss': 0.016475086563208292, 'total_loss': 0.00037977225458651984, 'approx_kl': 0.04251046199351549, 'clip_fraction': 0.39453125, 'grad_norm': 6.874258518218994}
2022-12-29 11:42:14.334 DEBUG: Taking gradient step
2022-12-29 11:42:14.344 DEBUG: Loss 7: {'policy_loss': 0.021427825003223464, 'entropy_loss': -0.023822054732590914, 'vf_loss': 0.01649569360122463, 'total_loss': 0.014101463871857185, 'approx_kl': 0.01581346639432013, 'clip_fraction': 0.3854166716337204, 'grad_norm': 13.314902305603027}
2022-12-29 11:42:15.043 DEBUG: Taking gradient step
2022-12-29 11:42:15.052 DEBUG: Loss 8: {'policy_loss': -0.0010014616909427964, 'entropy_loss': -0.02506677946075797, 'vf_loss': 0.01645934548992252, 'total_loss': -0.009608895661778251, 'approx_kl': 0.02208715188317001, 'clip_fraction': 0.3072916716337204, 'grad_norm': 4.725674629211426}
2022-12-29 11:42:15.754 DEBUG: Taking gradient step
2022-12-29 11:42:15.763 DEBUG: Loss 9: {'policy_loss': -0.009356224337390483, 'entropy_loss': -0.023647458292543888, 'vf_loss': 0.016460597369416415, 'total_loss': -0.016543085260517957, 'approx_kl': 0.005206414498388767, 'clip_fraction': 0.14973958395421505, 'grad_norm': 1.8373945951461792}
2022-12-29 11:42:15.763 INFO: Optimization: policy loss=-0.009, vf loss=0.016, entropy loss=-0.024, total loss=-0.017, num steps=10
2022-12-29 11:42:15.764 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 11:42:16.468 INFO: Evaluation rollout: return=0.458 (0.0), episode length=3.0
2022-12-29 11:42:16.469 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 11:42:16.471 INFO: Iteration: 14/137, steps: 3024
2022-12-29 11:42:50.686 DEBUG: There is a single atom floating around
2022-12-29 11:43:05.246 INFO: Training rollout: return=0.142 (2.4), episode length=3.0
2022-12-29 11:43:05.248 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 11:43:05.251 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-3024_train.pkl
2022-12-29 11:43:06.029 DEBUG: Taking gradient step
2022-12-29 11:43:06.039 DEBUG: Loss 0: {'policy_loss': -0.0092804107863192, 'entropy_loss': -0.024120712652802467, 'vf_loss': 0.0033192221334207503, 'total_loss': -0.030081901305700917, 'approx_kl': 1.3659397612997282e-08, 'clip_fraction': 0.0, 'grad_norm': 5.459130764007568}
2022-12-29 11:43:06.763 DEBUG: Taking gradient step
2022-12-29 11:43:06.773 DEBUG: Loss 1: {'policy_loss': -0.014175869216826634, 'entropy_loss': -0.024752269964665174, 'vf_loss': 0.003335175631341562, 'total_loss': -0.03559296355015024, 'approx_kl': -0.011146324570290744, 'clip_fraction': 0.09895833395421505, 'grad_norm': 5.099992275238037}
2022-12-29 11:43:07.517 DEBUG: Taking gradient step
2022-12-29 11:43:07.531 DEBUG: Loss 2: {'policy_loss': 0.04961233270400081, 'entropy_loss': -0.024468859191983938, 'vf_loss': 0.005919125330691245, 'total_loss': 0.031062598842708122, 'approx_kl': -0.008061215281486511, 'clip_fraction': 0.25, 'grad_norm': 4.367609024047852}
2022-12-29 11:43:08.263 DEBUG: Taking gradient step
2022-12-29 11:43:08.272 DEBUG: Loss 3: {'policy_loss': -0.018425130883431673, 'entropy_loss': -0.02455544425174594, 'vf_loss': 0.003347940341171669, 'total_loss': -0.039632634794005944, 'approx_kl': 0.018477746285498142, 'clip_fraction': 0.34375, 'grad_norm': 1.7066277265548706}
2022-12-29 11:43:09.002 DEBUG: Taking gradient step
2022-12-29 11:43:09.011 DEBUG: Loss 4: {'policy_loss': -0.01732670541720733, 'entropy_loss': -0.024442546535283327, 'vf_loss': 0.0033458347047761127, 'total_loss': -0.038423417247714545, 'approx_kl': 0.016511423280462623, 'clip_fraction': 0.4244791716337204, 'grad_norm': 1.8000844717025757}
2022-12-29 11:43:09.724 DEBUG: Taking gradient step
2022-12-29 11:43:09.734 DEBUG: Loss 5: {'policy_loss': -0.023708731211481565, 'entropy_loss': -0.02386317914351821, 'vf_loss': 0.0033528240500506805, 'total_loss': -0.04421908630494909, 'approx_kl': 0.018858378753066063, 'clip_fraction': 0.4244791716337204, 'grad_norm': 1.7198585271835327}
2022-12-29 11:43:10.471 DEBUG: Taking gradient step
2022-12-29 11:43:10.480 DEBUG: Loss 6: {'policy_loss': -0.020607953998473812, 'entropy_loss': -0.024599757976830006, 'vf_loss': 0.0033288508208456245, 'total_loss': -0.04187886115445819, 'approx_kl': 0.004771117120981216, 'clip_fraction': 0.4361979216337204, 'grad_norm': 1.7120537757873535}
2022-12-29 11:43:11.194 DEBUG: Taking gradient step
2022-12-29 11:43:11.203 DEBUG: Loss 7: {'policy_loss': -0.023960881819590517, 'entropy_loss': -0.024920033756643534, 'vf_loss': 0.0033240827793991133, 'total_loss': -0.04555683279683494, 'approx_kl': 0.021025947527959943, 'clip_fraction': 0.4127604216337204, 'grad_norm': 1.8164490461349487}
2022-12-29 11:43:11.914 DEBUG: Taking gradient step
2022-12-29 11:43:11.923 DEBUG: Loss 8: {'policy_loss': 0.036923436952703594, 'entropy_loss': -0.023788820952177048, 'vf_loss': 0.005699460232614333, 'total_loss': 0.018834076233140873, 'approx_kl': 0.01672933390364051, 'clip_fraction': 0.3802083358168602, 'grad_norm': 1.7756470441818237}
2022-12-29 11:43:12.617 DEBUG: Taking gradient step
2022-12-29 11:43:12.626 DEBUG: Loss 9: {'policy_loss': -0.023678394273519972, 'entropy_loss': -0.02434130245819688, 'vf_loss': 0.0032751512567075983, 'total_loss': -0.04474454547500925, 'approx_kl': -0.01159407151862979, 'clip_fraction': 0.3072916716337204, 'grad_norm': 1.6630120277404785}
2022-12-29 11:43:12.627 INFO: Optimization: policy loss=-0.024, vf loss=0.003, entropy loss=-0.024, total loss=-0.045, num steps=10
2022-12-29 11:43:12.627 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 11:43:13.291 INFO: Evaluation rollout: return=0.446 (0.0), episode length=3.0
2022-12-29 11:43:13.292 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 11:43:13.294 INFO: Iteration: 15/137, steps: 3240
2022-12-29 11:44:03.422 INFO: Training rollout: return=0.427 (0.0), episode length=3.0
2022-12-29 11:44:03.424 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 11:44:03.426 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-3240_train.pkl
2022-12-29 11:44:04.138 DEBUG: Taking gradient step
2022-12-29 11:44:04.148 DEBUG: Loss 0: {'policy_loss': 0.024136544515192683, 'entropy_loss': -0.02418395085260272, 'vf_loss': 0.00023402094872317469, 'total_loss': 0.0001866146113131406, 'approx_kl': 2.6387473539557504e-08, 'clip_fraction': 0.0, 'grad_norm': 14.98816967010498}
2022-12-29 11:44:04.840 DEBUG: Taking gradient step
2022-12-29 11:44:04.849 DEBUG: Loss 1: {'policy_loss': 0.033094342708718326, 'entropy_loss': -0.024949859362095594, 'vf_loss': 0.00020565202699522972, 'total_loss': 0.00835013537361795, 'approx_kl': 0.026333716930821538, 'clip_fraction': 0.1015625, 'grad_norm': 3.975808620452881}
2022-12-29 11:44:05.564 DEBUG: Early stopping at step 2 for reaching max KL.
2022-12-29 11:44:05.564 INFO: Optimization: policy loss=0.033, vf loss=0.000, entropy loss=-0.025, total loss=0.008, num steps=2
2022-12-29 11:44:05.564 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 11:44:06.331 INFO: Evaluation rollout: return=0.460 (0.0), episode length=3.0
2022-12-29 11:44:06.332 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 11:44:06.333 INFO: Iteration: 16/137, steps: 3456
2022-12-29 11:44:50.898 DEBUG: There is a single atom floating around
2022-12-29 11:44:56.406 INFO: Training rollout: return=0.150 (2.4), episode length=3.0
2022-12-29 11:44:56.407 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 11:44:56.410 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-3456_train.pkl
2022-12-29 11:44:57.139 DEBUG: Taking gradient step
2022-12-29 11:44:57.149 DEBUG: Loss 0: {'policy_loss': -0.013587082570168937, 'entropy_loss': -0.02465839171782136, 'vf_loss': 0.003223797546410365, 'total_loss': -0.035021676741579924, 'approx_kl': 8.537126561236619e-10, 'clip_fraction': 0.0, 'grad_norm': 3.9384922981262207}
2022-12-29 11:44:57.830 DEBUG: Taking gradient step
2022-12-29 11:44:57.840 DEBUG: Loss 1: {'policy_loss': -0.018175822789328173, 'entropy_loss': -0.024138289038091898, 'vf_loss': 0.003206360300029392, 'total_loss': -0.03910775152739068, 'approx_kl': 0.008488155668601394, 'clip_fraction': 0.10026041697710752, 'grad_norm': 3.0029618740081787}
2022-12-29 11:44:58.567 DEBUG: Taking gradient step
2022-12-29 11:44:58.584 DEBUG: Loss 2: {'policy_loss': -0.025357804080674215, 'entropy_loss': -0.023627816699445248, 'vf_loss': 0.0032072516786437405, 'total_loss': -0.04577836910147572, 'approx_kl': 0.026003281818702817, 'clip_fraction': 0.30078125, 'grad_norm': 1.3768757581710815}
2022-12-29 11:44:59.284 DEBUG: Taking gradient step
2022-12-29 11:44:59.293 DEBUG: Loss 3: {'policy_loss': -0.017252743225480767, 'entropy_loss': -0.02440473483875394, 'vf_loss': 0.0031888749931744745, 'total_loss': -0.03846860307106023, 'approx_kl': 0.03518289001658559, 'clip_fraction': 0.4361979216337204, 'grad_norm': 1.4748111963272095}
2022-12-29 11:45:00.029 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-29 11:45:00.029 INFO: Optimization: policy loss=-0.017, vf loss=0.003, entropy loss=-0.024, total loss=-0.038, num steps=4
2022-12-29 11:45:00.030 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 11:45:00.728 INFO: Evaluation rollout: return=0.481 (0.0), episode length=3.0
2022-12-29 11:45:00.729 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 11:45:00.730 INFO: Iteration: 17/137, steps: 3672
2022-12-29 11:45:32.567 DEBUG: Atoms are too close
2022-12-29 11:45:48.756 INFO: Training rollout: return=0.167 (2.4), episode length=3.0
2022-12-29 11:45:48.758 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 11:45:48.760 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-3672_train.pkl
2022-12-29 11:45:49.486 DEBUG: Taking gradient step
2022-12-29 11:45:49.496 DEBUG: Loss 0: {'policy_loss': -0.02256811482995841, 'entropy_loss': -0.023003838025033474, 'vf_loss': 0.004825686205621034, 'total_loss': -0.04074626664937085, 'approx_kl': -1.9169722698109126e-08, 'clip_fraction': 0.0, 'grad_norm': 13.503654479980469}
2022-12-29 11:45:50.202 DEBUG: Taking gradient step
2022-12-29 11:45:50.212 DEBUG: Loss 1: {'policy_loss': -0.020314099704967815, 'entropy_loss': -0.023903694469481707, 'vf_loss': 0.004820885139957458, 'total_loss': -0.03939690903449206, 'approx_kl': 0.0033639546018093824, 'clip_fraction': 0.0, 'grad_norm': 13.107605934143066}
2022-12-29 11:45:50.912 DEBUG: Taking gradient step
2022-12-29 11:45:50.921 DEBUG: Loss 2: {'policy_loss': -0.024444385406427738, 'entropy_loss': -0.023607525508850813, 'vf_loss': 0.004828256174449203, 'total_loss': -0.04322365474082935, 'approx_kl': 0.007487709634006023, 'clip_fraction': 0.02734375, 'grad_norm': 0.7958281636238098}
2022-12-29 11:45:51.655 DEBUG: Taking gradient step
2022-12-29 11:45:51.664 DEBUG: Loss 3: {'policy_loss': 0.0359329349234737, 'entropy_loss': -0.022839507088065147, 'vf_loss': 0.007428630696654876, 'total_loss': 0.02052205853206343, 'approx_kl': 0.014585447614081204, 'clip_fraction': 0.140625, 'grad_norm': 0.824225664138794}
2022-12-29 11:45:52.378 DEBUG: Taking gradient step
2022-12-29 11:45:52.387 DEBUG: Loss 4: {'policy_loss': 0.033621427809662194, 'entropy_loss': -0.022882429882884026, 'vf_loss': 0.00735156418800521, 'total_loss': 0.01809056211478339, 'approx_kl': 0.013259432860650122, 'clip_fraction': 0.13802083395421505, 'grad_norm': 0.8853679299354553}
2022-12-29 11:45:53.105 DEBUG: Taking gradient step
2022-12-29 11:45:53.115 DEBUG: Loss 5: {'policy_loss': -0.020504480706281157, 'entropy_loss': -0.023840194568037987, 'vf_loss': 0.004815018769052516, 'total_loss': -0.03952965650526663, 'approx_kl': 0.015197515953332186, 'clip_fraction': 0.13411458395421505, 'grad_norm': 0.4258635342121124}
2022-12-29 11:45:53.829 DEBUG: Taking gradient step
2022-12-29 11:45:53.838 DEBUG: Loss 6: {'policy_loss': 0.02942779008840949, 'entropy_loss': -0.02275939704850316, 'vf_loss': 0.007421040641144996, 'total_loss': 0.014089433681051332, 'approx_kl': 0.01757229317445308, 'clip_fraction': 0.14973958395421505, 'grad_norm': 0.9267891049385071}
2022-12-29 11:45:54.586 DEBUG: Taking gradient step
2022-12-29 11:45:54.595 DEBUG: Loss 7: {'policy_loss': 0.030307325228125213, 'entropy_loss': -0.021921748761087656, 'vf_loss': 0.007406318470779825, 'total_loss': 0.015791894937817387, 'approx_kl': 0.013195700943470001, 'clip_fraction': 0.1588541679084301, 'grad_norm': 0.8217371106147766}
2022-12-29 11:45:55.310 DEBUG: Taking gradient step
2022-12-29 11:45:55.321 DEBUG: Loss 8: {'policy_loss': 0.024445526280336454, 'entropy_loss': -0.023700070567429066, 'vf_loss': 0.007437603116760121, 'total_loss': 0.008183058829667515, 'approx_kl': 0.025605090893805027, 'clip_fraction': 0.1796875, 'grad_norm': 0.600017786026001}
2022-12-29 11:45:56.007 DEBUG: Taking gradient step
2022-12-29 11:45:56.017 DEBUG: Loss 9: {'policy_loss': -0.020127554842741594, 'entropy_loss': -0.02337547577917576, 'vf_loss': 0.0047842843690771965, 'total_loss': -0.03871874625284015, 'approx_kl': 0.008840147871524096, 'clip_fraction': 0.2330729216337204, 'grad_norm': 0.35860082507133484}
2022-12-29 11:45:56.017 INFO: Optimization: policy loss=-0.020, vf loss=0.005, entropy loss=-0.023, total loss=-0.039, num steps=10
2022-12-29 11:45:56.018 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 11:45:56.679 INFO: Evaluation rollout: return=0.478 (0.0), episode length=3.0
2022-12-29 11:45:56.680 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 11:45:56.682 INFO: Iteration: 18/137, steps: 3888
2022-12-29 11:46:45.502 INFO: Training rollout: return=0.438 (0.1), episode length=3.0
2022-12-29 11:46:45.504 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 11:46:45.506 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-3888_train.pkl
2022-12-29 11:46:46.226 DEBUG: Taking gradient step
2022-12-29 11:46:46.235 DEBUG: Loss 0: {'policy_loss': -0.03223182636802411, 'entropy_loss': -0.0236680805683136, 'vf_loss': 0.00016289355446009863, 'total_loss': -0.05573701338187761, 'approx_kl': -3.166496753692627e-08, 'clip_fraction': 0.0, 'grad_norm': 4.716222286224365}
2022-12-29 11:46:46.925 DEBUG: Taking gradient step
2022-12-29 11:46:46.935 DEBUG: Loss 1: {'policy_loss': -0.034736081415406496, 'entropy_loss': -0.023496261332184076, 'vf_loss': 0.00017353337678804138, 'total_loss': -0.05805880937080254, 'approx_kl': 0.0006363564170897007, 'clip_fraction': 0.0, 'grad_norm': 4.98961067199707}
2022-12-29 11:46:47.643 DEBUG: Taking gradient step
2022-12-29 11:46:47.653 DEBUG: Loss 2: {'policy_loss': 0.00460002506471334, 'entropy_loss': -0.022882935125380754, 'vf_loss': 0.00017352701663666753, 'total_loss': -0.018109383044030748, 'approx_kl': 0.0030115186236798763, 'clip_fraction': 0.026041666977107525, 'grad_norm': 5.068737983703613}
2022-12-29 11:46:48.362 DEBUG: Taking gradient step
2022-12-29 11:46:48.371 DEBUG: Loss 3: {'policy_loss': 0.04115131134033789, 'entropy_loss': -0.02349398983642459, 'vf_loss': 0.00017888108805039278, 'total_loss': 0.017836202591963682, 'approx_kl': -0.0018016290850937366, 'clip_fraction': 0.05989583395421505, 'grad_norm': 13.138826370239258}
2022-12-29 11:46:49.065 DEBUG: Taking gradient step
2022-12-29 11:46:49.076 DEBUG: Loss 4: {'policy_loss': -0.03756828467007958, 'entropy_loss': -0.02315394952893257, 'vf_loss': 0.00019537068663188725, 'total_loss': -0.06052686351238026, 'approx_kl': 0.004438521922565997, 'clip_fraction': 0.01953125, 'grad_norm': 5.912851333618164}
2022-12-29 11:46:49.807 DEBUG: Taking gradient step
2022-12-29 11:46:49.816 DEBUG: Loss 5: {'policy_loss': -0.016774074588737864, 'entropy_loss': -0.02398784551769495, 'vf_loss': 0.00019836915584504406, 'total_loss': -0.04056355095058777, 'approx_kl': 0.01347643369808793, 'clip_fraction': 0.1041666679084301, 'grad_norm': 8.135019302368164}
2022-12-29 11:46:50.547 DEBUG: Taking gradient step
2022-12-29 11:46:50.557 DEBUG: Loss 6: {'policy_loss': 0.03038033539953451, 'entropy_loss': -0.0236950539983809, 'vf_loss': 0.00019430761618673186, 'total_loss': 0.006879589017340343, 'approx_kl': 0.027935188729315996, 'clip_fraction': 0.1575520858168602, 'grad_norm': 13.163536071777344}
2022-12-29 11:46:51.256 DEBUG: Taking gradient step
2022-12-29 11:46:51.265 DEBUG: Loss 7: {'policy_loss': 0.019682763989017388, 'entropy_loss': -0.02356820460408926, 'vf_loss': 0.00019964403227929874, 'total_loss': -0.003685796582792576, 'approx_kl': 0.04098300635814667, 'clip_fraction': 0.3125, 'grad_norm': 2.44293475151062}
2022-12-29 11:46:51.973 DEBUG: Taking gradient step
2022-12-29 11:46:51.982 DEBUG: Loss 8: {'policy_loss': -0.03669747651825056, 'entropy_loss': -0.02372382441535592, 'vf_loss': 0.00021027876922171063, 'total_loss': -0.06021102216438477, 'approx_kl': 0.04488494712859392, 'clip_fraction': 0.2994791716337204, 'grad_norm': 11.406152725219727}
2022-12-29 11:46:52.685 DEBUG: Taking gradient step
2022-12-29 11:46:52.700 DEBUG: Loss 9: {'policy_loss': -0.04444680729377233, 'entropy_loss': -0.02399635501205921, 'vf_loss': 0.00020578948265226278, 'total_loss': -0.06823737282317927, 'approx_kl': 0.04386921599507332, 'clip_fraction': 0.2994791679084301, 'grad_norm': 12.665009498596191}
2022-12-29 11:46:52.701 INFO: Optimization: policy loss=-0.044, vf loss=0.000, entropy loss=-0.024, total loss=-0.068, num steps=10
2022-12-29 11:46:52.701 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 11:46:53.417 INFO: Evaluation rollout: return=0.487 (0.0), episode length=3.0
2022-12-29 11:46:53.418 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 11:46:53.419 INFO: Iteration: 19/137, steps: 4104
2022-12-29 11:47:42.289 INFO: Training rollout: return=0.446 (0.1), episode length=3.0
2022-12-29 11:47:42.291 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 11:47:42.293 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-4104_train.pkl
2022-12-29 11:47:43.017 DEBUG: Taking gradient step
2022-12-29 11:47:43.026 DEBUG: Loss 0: {'policy_loss': 0.005249089153188452, 'entropy_loss': -0.023830341175198555, 'vf_loss': 0.00021106190797004942, 'total_loss': -0.018370190114040057, 'approx_kl': -8.381903171539307e-09, 'clip_fraction': 0.0, 'grad_norm': 6.889439105987549}
2022-12-29 11:47:43.717 DEBUG: Taking gradient step
2022-12-29 11:47:43.728 DEBUG: Loss 1: {'policy_loss': 0.056993879838937334, 'entropy_loss': -0.02374758617952466, 'vf_loss': 0.00020291051492349446, 'total_loss': 0.03344920417433617, 'approx_kl': 0.0024675501917954534, 'clip_fraction': 0.04036458395421505, 'grad_norm': 11.162727355957031}
2022-12-29 11:47:44.430 DEBUG: Taking gradient step
2022-12-29 11:47:44.439 DEBUG: Loss 2: {'policy_loss': -0.03382395094405543, 'entropy_loss': -0.02343666460365057, 'vf_loss': 0.0002109863136223048, 'total_loss': -0.057049629234083694, 'approx_kl': 0.00537701859138906, 'clip_fraction': 0.03515625, 'grad_norm': 6.765340328216553}
2022-12-29 11:47:45.140 DEBUG: Taking gradient step
2022-12-29 11:47:45.150 DEBUG: Loss 3: {'policy_loss': -0.011088368838805433, 'entropy_loss': -0.02436720160767436, 'vf_loss': 0.00020535345653374147, 'total_loss': -0.03525021698994606, 'approx_kl': 0.009366742975544184, 'clip_fraction': 0.03515625, 'grad_norm': 7.830733299255371}
2022-12-29 11:47:45.847 DEBUG: Taking gradient step
2022-12-29 11:47:45.857 DEBUG: Loss 4: {'policy_loss': -0.026939983473748586, 'entropy_loss': -0.024151303805410862, 'vf_loss': 0.00020054171792091268, 'total_loss': -0.05089074556123853, 'approx_kl': 0.018181635765358806, 'clip_fraction': 0.08333333395421505, 'grad_norm': 5.357537746429443}
2022-12-29 11:47:46.581 DEBUG: Taking gradient step
2022-12-29 11:47:46.591 DEBUG: Loss 5: {'policy_loss': 0.020330006398094777, 'entropy_loss': -0.024326863698661327, 'vf_loss': 0.00018847998060858811, 'total_loss': -0.003808377319957961, 'approx_kl': 0.019454188994131982, 'clip_fraction': 0.12890625, 'grad_norm': 5.862937927246094}
2022-12-29 11:47:47.302 DEBUG: Taking gradient step
2022-12-29 11:47:47.311 DEBUG: Loss 6: {'policy_loss': -0.029073371016376755, 'entropy_loss': -0.024086597375571728, 'vf_loss': 0.000189629881007245, 'total_loss': -0.05297033851094124, 'approx_kl': 0.028475226368755102, 'clip_fraction': 0.12890625, 'grad_norm': 6.591006755828857}
2022-12-29 11:47:48.010 DEBUG: Taking gradient step
2022-12-29 11:47:48.020 DEBUG: Loss 7: {'policy_loss': -0.014318709304632526, 'entropy_loss': -0.024348368868231773, 'vf_loss': 0.00017954655172300373, 'total_loss': -0.0384875316211413, 'approx_kl': 0.026489694020710886, 'clip_fraction': 0.12239583395421505, 'grad_norm': 7.517306804656982}
2022-12-29 11:47:48.742 DEBUG: Taking gradient step
2022-12-29 11:47:48.751 DEBUG: Loss 8: {'policy_loss': -0.04231669208630153, 'entropy_loss': -0.024394291918724775, 'vf_loss': 0.00017495461773059363, 'total_loss': -0.06653602938729569, 'approx_kl': 0.03726217313669622, 'clip_fraction': 0.109375, 'grad_norm': 9.272130966186523}
2022-12-29 11:47:49.481 DEBUG: Taking gradient step
2022-12-29 11:47:49.491 DEBUG: Loss 9: {'policy_loss': -0.04160188807692906, 'entropy_loss': -0.024143077433109283, 'vf_loss': 0.00016729533864076861, 'total_loss': -0.06557767017139757, 'approx_kl': 0.03852179553359747, 'clip_fraction': 0.10416666697710752, 'grad_norm': 7.869653224945068}
2022-12-29 11:47:49.491 INFO: Optimization: policy loss=-0.042, vf loss=0.000, entropy loss=-0.024, total loss=-0.066, num steps=10
2022-12-29 11:47:49.492 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 11:47:50.263 INFO: Evaluation rollout: return=0.486 (0.0), episode length=3.0
2022-12-29 11:47:50.264 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 11:47:50.265 INFO: Iteration: 20/137, steps: 4320
2022-12-29 11:48:39.447 INFO: Training rollout: return=0.438 (0.1), episode length=3.0
2022-12-29 11:48:39.449 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 11:48:39.451 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-4320_train.pkl
2022-12-29 11:48:40.166 DEBUG: Taking gradient step
2022-12-29 11:48:40.175 DEBUG: Loss 0: {'policy_loss': 0.013175015238438729, 'entropy_loss': -0.02486294973641634, 'vf_loss': 0.00014940412903536576, 'total_loss': -0.011538530368942245, 'approx_kl': 4.811832710061026e-09, 'clip_fraction': 0.0, 'grad_norm': 4.373462200164795}
2022-12-29 11:48:40.908 DEBUG: Taking gradient step
2022-12-29 11:48:40.918 DEBUG: Loss 1: {'policy_loss': -0.0341019144940377, 'entropy_loss': -0.024077609181404114, 'vf_loss': 0.0001478637465779069, 'total_loss': -0.0580316599288639, 'approx_kl': 0.0008060539257712662, 'clip_fraction': 0.010416666977107525, 'grad_norm': 6.195263385772705}
2022-12-29 11:48:41.660 DEBUG: Taking gradient step
2022-12-29 11:48:41.672 DEBUG: Loss 2: {'policy_loss': 0.0146731105067682, 'entropy_loss': -0.024612985085695982, 'vf_loss': 0.0001343266356080527, 'total_loss': -0.00980554794331973, 'approx_kl': 0.0045028734020888805, 'clip_fraction': 0.02734375, 'grad_norm': 5.009040355682373}
2022-12-29 11:48:42.428 DEBUG: Taking gradient step
2022-12-29 11:48:42.442 DEBUG: Loss 3: {'policy_loss': 0.0033275359274662353, 'entropy_loss': -0.02527703158557415, 'vf_loss': 0.00012866251696499282, 'total_loss': -0.02182083314114292, 'approx_kl': 0.011928342748433352, 'clip_fraction': 0.07421875, 'grad_norm': 6.185201644897461}
2022-12-29 11:48:43.161 DEBUG: Taking gradient step
2022-12-29 11:48:43.170 DEBUG: Loss 4: {'policy_loss': -0.007308366299354688, 'entropy_loss': -0.024335226509720087, 'vf_loss': 0.0001217875482466622, 'total_loss': -0.03152180526082811, 'approx_kl': 0.014407624490559101, 'clip_fraction': 0.1171875, 'grad_norm': 6.9899678230285645}
2022-12-29 11:48:43.876 DEBUG: Taking gradient step
2022-12-29 11:48:43.893 DEBUG: Loss 5: {'policy_loss': 0.015391972504140792, 'entropy_loss': -0.023832089267671108, 'vf_loss': 0.0001146870923993933, 'total_loss': -0.00832542967113092, 'approx_kl': 0.02610271912999451, 'clip_fraction': 0.1497395858168602, 'grad_norm': 14.82795238494873}
2022-12-29 11:48:44.585 DEBUG: Taking gradient step
2022-12-29 11:48:44.594 DEBUG: Loss 6: {'policy_loss': -0.008882116600705035, 'entropy_loss': -0.0239080679602921, 'vf_loss': 0.00010916335467985422, 'total_loss': -0.03268102120631728, 'approx_kl': 0.019800689769908786, 'clip_fraction': 0.1588541679084301, 'grad_norm': 7.475534915924072}
2022-12-29 11:48:45.313 DEBUG: Taking gradient step
2022-12-29 11:48:45.324 DEBUG: Loss 7: {'policy_loss': 0.021419881292007607, 'entropy_loss': -0.023771738167852163, 'vf_loss': 0.00010150250028959306, 'total_loss': -0.002250354375554965, 'approx_kl': 0.018696161918342113, 'clip_fraction': 0.16015625, 'grad_norm': 7.4541144371032715}
2022-12-29 11:48:46.066 DEBUG: Taking gradient step
2022-12-29 11:48:46.075 DEBUG: Loss 8: {'policy_loss': 0.0031776623834861763, 'entropy_loss': -0.023925350978970528, 'vf_loss': 9.685838686023913e-05, 'total_loss': -0.020650830208624113, 'approx_kl': 0.005767613649368286, 'clip_fraction': 0.1666666679084301, 'grad_norm': 3.622011423110962}
2022-12-29 11:48:46.794 DEBUG: Taking gradient step
2022-12-29 11:48:46.804 DEBUG: Loss 9: {'policy_loss': -0.0016736555520438321, 'entropy_loss': -0.023726988583803177, 'vf_loss': 9.210924831844992e-05, 'total_loss': -0.025308534887528555, 'approx_kl': 0.004534340696409345, 'clip_fraction': 0.1549479179084301, 'grad_norm': 5.626461982727051}
2022-12-29 11:48:46.804 INFO: Optimization: policy loss=-0.002, vf loss=0.000, entropy loss=-0.024, total loss=-0.025, num steps=10
2022-12-29 11:48:46.804 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 11:48:47.518 INFO: Evaluation rollout: return=0.485 (0.0), episode length=3.0
2022-12-29 11:48:47.519 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 11:48:47.520 DEBUG: Deleting old model: runs/H2O/models/H2O_run-1_steps-2376.model
2022-12-29 11:48:47.525 DEBUG: Saving model: runs/H2O/models/H2O_run-1_steps-4536.model
2022-12-29 11:48:47.554 INFO: Iteration: 21/137, steps: 4536
2022-12-29 11:49:36.355 INFO: Training rollout: return=0.454 (0.0), episode length=3.0
2022-12-29 11:49:36.357 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 11:49:36.359 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-4536_train.pkl
2022-12-29 11:49:37.087 DEBUG: Taking gradient step
2022-12-29 11:49:37.097 DEBUG: Loss 0: {'policy_loss': 0.011895117910638322, 'entropy_loss': -0.024304577615112066, 'vf_loss': 9.29001216495593e-05, 'total_loss': -0.012316559582824184, 'approx_kl': -5.704350769519806e-09, 'clip_fraction': 0.0, 'grad_norm': 7.11700963973999}
2022-12-29 11:49:37.809 DEBUG: Taking gradient step
2022-12-29 11:49:37.820 DEBUG: Loss 1: {'policy_loss': -0.03408502623146474, 'entropy_loss': -0.023320783395320177, 'vf_loss': 9.165168880872992e-05, 'total_loss': -0.05731415793797619, 'approx_kl': 0.0072558874962851405, 'clip_fraction': 0.01171875, 'grad_norm': 6.535422325134277}
2022-12-29 11:49:38.506 DEBUG: Taking gradient step
2022-12-29 11:49:38.515 DEBUG: Loss 2: {'policy_loss': 0.002066195912618333, 'entropy_loss': -0.023482208605855703, 'vf_loss': 8.263786604726857e-05, 'total_loss': -0.021333374827190103, 'approx_kl': 0.020327101461589336, 'clip_fraction': 0.07161458395421505, 'grad_norm': 8.464680671691895}
2022-12-29 11:49:39.237 DEBUG: Taking gradient step
2022-12-29 11:49:39.251 DEBUG: Loss 3: {'policy_loss': -0.011083339232063498, 'entropy_loss': -0.024041044991463423, 'vf_loss': 7.891459797376691e-05, 'total_loss': -0.035045469625553154, 'approx_kl': 0.04425812233239412, 'clip_fraction': 0.1640625, 'grad_norm': 11.05560302734375}
2022-12-29 11:49:39.953 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-29 11:49:39.953 INFO: Optimization: policy loss=-0.011, vf loss=0.000, entropy loss=-0.024, total loss=-0.035, num steps=4
2022-12-29 11:49:39.954 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 11:49:40.723 INFO: Evaluation rollout: return=0.493 (0.0), episode length=3.0
2022-12-29 11:49:40.724 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 11:49:40.726 INFO: Iteration: 22/137, steps: 4752
2022-12-29 11:50:29.426 INFO: Training rollout: return=0.440 (0.1), episode length=3.0
2022-12-29 11:50:29.427 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 11:50:29.430 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-4752_train.pkl
2022-12-29 11:50:30.190 DEBUG: Taking gradient step
2022-12-29 11:50:30.199 DEBUG: Loss 0: {'policy_loss': 0.012871010805752307, 'entropy_loss': -0.02461973764002323, 'vf_loss': 6.896570610135581e-05, 'total_loss': -0.011679761128169566, 'approx_kl': 1.2417636696682166e-08, 'clip_fraction': 0.0, 'grad_norm': 9.97832202911377}
2022-12-29 11:50:30.901 DEBUG: Taking gradient step
2022-12-29 11:50:30.911 DEBUG: Loss 1: {'policy_loss': 0.017040786082041855, 'entropy_loss': -0.024323331657797098, 'vf_loss': 6.668503881050291e-05, 'total_loss': -0.00721586053694474, 'approx_kl': 0.00216274440754205, 'clip_fraction': 0.014322916977107525, 'grad_norm': 7.783938884735107}
2022-12-29 11:50:31.632 DEBUG: Taking gradient step
2022-12-29 11:50:31.645 DEBUG: Loss 2: {'policy_loss': -0.07297387922998498, 'entropy_loss': -0.024133920203894377, 'vf_loss': 6.832800116064026e-05, 'total_loss': -0.09703947143271872, 'approx_kl': 0.010261012590490282, 'clip_fraction': 0.03125, 'grad_norm': 4.808191776275635}
2022-12-29 11:50:32.364 DEBUG: Taking gradient step
2022-12-29 11:50:32.374 DEBUG: Loss 3: {'policy_loss': -0.006589694217144677, 'entropy_loss': -0.024729123804718256, 'vf_loss': 6.118727339667396e-05, 'total_loss': -0.03125763074846626, 'approx_kl': 0.0168344893027097, 'clip_fraction': 0.13671875, 'grad_norm': 3.853189706802368}
2022-12-29 11:50:33.126 DEBUG: Taking gradient step
2022-12-29 11:50:33.138 DEBUG: Loss 4: {'policy_loss': -0.03282315057049305, 'entropy_loss': -0.024260487873107195, 'vf_loss': 6.055451113508722e-05, 'total_loss': -0.057023083932465156, 'approx_kl': 0.014662815723568201, 'clip_fraction': 0.2252604216337204, 'grad_norm': 7.622354030609131}
2022-12-29 11:50:33.847 DEBUG: Taking gradient step
2022-12-29 11:50:33.857 DEBUG: Loss 5: {'policy_loss': -0.017780199897540733, 'entropy_loss': -0.025019948836416006, 'vf_loss': 5.8028057317641655e-05, 'total_loss': -0.0427421206766391, 'approx_kl': 0.02850394370034337, 'clip_fraction': 0.2252604179084301, 'grad_norm': 5.032956600189209}
2022-12-29 11:50:34.571 DEBUG: Taking gradient step
2022-12-29 11:50:34.580 DEBUG: Loss 6: {'policy_loss': -0.039624679453599654, 'entropy_loss': -0.02491073263809085, 'vf_loss': 5.715551964999593e-05, 'total_loss': -0.06447825657204051, 'approx_kl': 0.027103285770863295, 'clip_fraction': 0.21223958395421505, 'grad_norm': 8.22423267364502}
2022-12-29 11:50:35.268 DEBUG: Taking gradient step
2022-12-29 11:50:35.278 DEBUG: Loss 7: {'policy_loss': 0.03839546944472949, 'entropy_loss': -0.02519367542117834, 'vf_loss': 5.0934075552915294e-05, 'total_loss': 0.013252728099104064, 'approx_kl': 0.027194209396839142, 'clip_fraction': 0.19921875, 'grad_norm': 5.59364652633667}
2022-12-29 11:50:35.973 DEBUG: Taking gradient step
2022-12-29 11:50:35.982 DEBUG: Loss 8: {'policy_loss': -0.02457103969433308, 'entropy_loss': -0.024131867103278637, 'vf_loss': 5.203367632361644e-05, 'total_loss': -0.0486508731212881, 'approx_kl': 0.014072188176214695, 'clip_fraction': 0.12630208395421505, 'grad_norm': 6.459493160247803}
2022-12-29 11:50:36.699 DEBUG: Taking gradient step
2022-12-29 11:50:36.709 DEBUG: Loss 9: {'policy_loss': 0.0352110603536405, 'entropy_loss': -0.025699264835566282, 'vf_loss': 4.929322731097997e-05, 'total_loss': 0.0095610887453852, 'approx_kl': 0.02169185457751155, 'clip_fraction': 0.0963541679084301, 'grad_norm': 6.492896556854248}
2022-12-29 11:50:36.709 INFO: Optimization: policy loss=0.035, vf loss=0.000, entropy loss=-0.026, total loss=0.010, num steps=10
2022-12-29 11:50:36.709 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 11:50:37.454 INFO: Evaluation rollout: return=0.494 (0.0), episode length=3.0
2022-12-29 11:50:37.455 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 11:50:37.457 INFO: Iteration: 23/137, steps: 4968
2022-12-29 11:51:26.065 INFO: Training rollout: return=0.440 (0.0), episode length=3.0
2022-12-29 11:51:26.066 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 11:51:26.069 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-4968_train.pkl
2022-12-29 11:51:26.802 DEBUG: Taking gradient step
2022-12-29 11:51:26.812 DEBUG: Loss 0: {'policy_loss': 0.05407766895612504, 'entropy_loss': -0.026426761876791716, 'vf_loss': 4.745299946667333e-05, 'total_loss': 0.027698360078799993, 'approx_kl': 3.4924596548080444e-09, 'clip_fraction': 0.0, 'grad_norm': 12.666152000427246}
2022-12-29 11:51:27.506 DEBUG: Taking gradient step
2022-12-29 11:51:27.515 DEBUG: Loss 1: {'policy_loss': 0.024804121409340858, 'entropy_loss': -0.025005695410072803, 'vf_loss': 4.568313984795602e-05, 'total_loss': -0.00015589086088399484, 'approx_kl': 0.0017260814784094691, 'clip_fraction': 0.0078125, 'grad_norm': 9.993032455444336}
2022-12-29 11:51:28.215 DEBUG: Taking gradient step
2022-12-29 11:51:28.225 DEBUG: Loss 2: {'policy_loss': 0.011844533928218659, 'entropy_loss': -0.026158073917031288, 'vf_loss': 4.6345905734735006e-05, 'total_loss': -0.014267194083077896, 'approx_kl': 0.019285492599010468, 'clip_fraction': 0.07552083395421505, 'grad_norm': 11.87490177154541}
2022-12-29 11:51:28.917 DEBUG: Taking gradient step
2022-12-29 11:51:28.931 DEBUG: Loss 3: {'policy_loss': 0.008534492382812203, 'entropy_loss': -0.024801107123494148, 'vf_loss': 4.4684427786304096e-05, 'total_loss': -0.016221930312895642, 'approx_kl': 0.034506447147578, 'clip_fraction': 0.1927083358168602, 'grad_norm': 5.568680763244629}
2022-12-29 11:51:29.674 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-29 11:51:29.674 INFO: Optimization: policy loss=0.009, vf loss=0.000, entropy loss=-0.025, total loss=-0.016, num steps=4
2022-12-29 11:51:29.674 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 11:51:30.420 INFO: Evaluation rollout: return=0.491 (0.0), episode length=3.0
2022-12-29 11:51:30.420 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 11:51:30.422 INFO: Iteration: 24/137, steps: 5184
2022-12-29 11:52:18.965 INFO: Training rollout: return=0.434 (0.0), episode length=3.0
2022-12-29 11:52:18.967 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 11:52:18.969 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-5184_train.pkl
2022-12-29 11:52:19.685 DEBUG: Taking gradient step
2022-12-29 11:52:19.695 DEBUG: Loss 0: {'policy_loss': -0.02915455424149492, 'entropy_loss': -0.02501887595281005, 'vf_loss': 4.490872780552333e-05, 'total_loss': -0.05412852146649944, 'approx_kl': 1.0710209608078003e-08, 'clip_fraction': 0.0, 'grad_norm': 12.703458786010742}
2022-12-29 11:52:20.384 DEBUG: Taking gradient step
2022-12-29 11:52:20.393 DEBUG: Loss 1: {'policy_loss': 0.0011253067349632437, 'entropy_loss': -0.024520274251699448, 'vf_loss': 4.1800860304212193e-05, 'total_loss': -0.023353166656431994, 'approx_kl': 0.0005083238938823342, 'clip_fraction': 0.0078125, 'grad_norm': 9.06620979309082}
2022-12-29 11:52:21.102 DEBUG: Taking gradient step
2022-12-29 11:52:21.112 DEBUG: Loss 2: {'policy_loss': -0.06131710115377248, 'entropy_loss': -0.024413686711341143, 'vf_loss': 4.453107996026419e-05, 'total_loss': -0.08568625678515336, 'approx_kl': 0.0064345013233833015, 'clip_fraction': 0.061197916977107525, 'grad_norm': 10.597912788391113}
2022-12-29 11:52:21.824 DEBUG: Taking gradient step
2022-12-29 11:52:21.833 DEBUG: Loss 3: {'policy_loss': -0.06430552226032388, 'entropy_loss': -0.02490872796624899, 'vf_loss': 4.363506995545745e-05, 'total_loss': -0.08917061515661741, 'approx_kl': 0.019694262417033315, 'clip_fraction': 0.1419270858168602, 'grad_norm': 10.00747299194336}
2022-12-29 11:52:22.565 DEBUG: Taking gradient step
2022-12-29 11:52:22.574 DEBUG: Loss 4: {'policy_loss': -0.03152414413459105, 'entropy_loss': -0.02345079556107521, 'vf_loss': 4.087787173867935e-05, 'total_loss': -0.054934061823927585, 'approx_kl': 0.025820825016126037, 'clip_fraction': 0.14192708395421505, 'grad_norm': 11.273212432861328}
2022-12-29 11:52:23.331 DEBUG: Early stopping at step 5 for reaching max KL.
2022-12-29 11:52:23.331 INFO: Optimization: policy loss=-0.032, vf loss=0.000, entropy loss=-0.023, total loss=-0.055, num steps=5
2022-12-29 11:52:23.332 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 11:52:23.979 INFO: Evaluation rollout: return=0.497 (0.0), episode length=3.0
2022-12-29 11:52:23.980 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 11:52:23.982 INFO: Iteration: 25/137, steps: 5400
2022-12-29 11:53:12.753 INFO: Training rollout: return=0.448 (0.0), episode length=3.0
2022-12-29 11:53:12.755 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 11:53:12.758 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-5400_train.pkl
2022-12-29 11:53:13.498 DEBUG: Taking gradient step
2022-12-29 11:53:13.507 DEBUG: Loss 0: {'policy_loss': -0.032612538618078446, 'entropy_loss': -0.024086901918053627, 'vf_loss': 4.425862404428316e-05, 'total_loss': -0.05665518191208779, 'approx_kl': -1.5095186878255618e-08, 'clip_fraction': 0.0, 'grad_norm': 7.244290828704834}
2022-12-29 11:53:14.191 DEBUG: Taking gradient step
2022-12-29 11:53:14.200 DEBUG: Loss 1: {'policy_loss': 0.022875883671249594, 'entropy_loss': -0.02510045049712062, 'vf_loss': 4.231808042115804e-05, 'total_loss': -0.0021822487454498662, 'approx_kl': 0.005301085417158902, 'clip_fraction': 0.022135416977107525, 'grad_norm': 4.449506759643555}
2022-12-29 11:53:14.896 DEBUG: Taking gradient step
2022-12-29 11:53:14.905 DEBUG: Loss 2: {'policy_loss': -0.050348816403952654, 'entropy_loss': -0.023622851818799973, 'vf_loss': 4.1334577463698645e-05, 'total_loss': -0.07393033364528892, 'approx_kl': 0.007242650259286165, 'clip_fraction': 0.12760416697710752, 'grad_norm': 13.552079200744629}
2022-12-29 11:53:15.648 DEBUG: Taking gradient step
2022-12-29 11:53:15.657 DEBUG: Loss 3: {'policy_loss': 0.02988514314009295, 'entropy_loss': -0.022467403672635555, 'vf_loss': 3.859745930474269e-05, 'total_loss': 0.007456336926762137, 'approx_kl': 0.0074820751324296, 'clip_fraction': 0.1744791679084301, 'grad_norm': 17.706823348999023}
2022-12-29 11:53:16.382 DEBUG: Taking gradient step
2022-12-29 11:53:16.392 DEBUG: Loss 4: {'policy_loss': 0.011374971329003003, 'entropy_loss': -0.023197513539344072, 'vf_loss': 3.910954818154432e-05, 'total_loss': -0.011783432662159525, 'approx_kl': 0.028056960087269545, 'clip_fraction': 0.2096354179084301, 'grad_norm': 12.746391296386719}
2022-12-29 11:53:17.097 DEBUG: Taking gradient step
2022-12-29 11:53:17.106 DEBUG: Loss 5: {'policy_loss': 0.014010240298884414, 'entropy_loss': -0.02243235521018505, 'vf_loss': 3.821069132079487e-05, 'total_loss': -0.008383904219979841, 'approx_kl': 0.03350655594840646, 'clip_fraction': 0.2356770858168602, 'grad_norm': 8.940839767456055}
2022-12-29 11:53:17.835 DEBUG: Taking gradient step
2022-12-29 11:53:17.845 DEBUG: Loss 6: {'policy_loss': 0.03364857714724928, 'entropy_loss': -0.021297706523910165, 'vf_loss': 3.515548349827405e-05, 'total_loss': 0.01238602610683738, 'approx_kl': 0.024293008958920836, 'clip_fraction': 0.3020833358168602, 'grad_norm': 5.305160999298096}
2022-12-29 11:53:18.569 DEBUG: Taking gradient step
2022-12-29 11:53:18.578 DEBUG: Loss 7: {'policy_loss': -0.03809133141873782, 'entropy_loss': -0.023072019685059786, 'vf_loss': 3.8583415474368464e-05, 'total_loss': -0.06112476768832324, 'approx_kl': 0.016306015953887254, 'clip_fraction': 0.2421875, 'grad_norm': 6.88956356048584}
2022-12-29 11:53:19.312 DEBUG: Taking gradient step
2022-12-29 11:53:19.321 DEBUG: Loss 8: {'policy_loss': 0.04765048330053849, 'entropy_loss': -0.02233865624293685, 'vf_loss': 3.404808276742686e-05, 'total_loss': 0.025345875140369067, 'approx_kl': 0.02921779779717326, 'clip_fraction': 0.2096354216337204, 'grad_norm': 15.399680137634277}
2022-12-29 11:53:20.041 DEBUG: Taking gradient step
2022-12-29 11:53:20.051 DEBUG: Loss 9: {'policy_loss': 0.02188761659641443, 'entropy_loss': -0.022745990194380283, 'vf_loss': 3.4248744680391056e-05, 'total_loss': -0.0008241248532854691, 'approx_kl': 0.018876628135330975, 'clip_fraction': 0.1848958358168602, 'grad_norm': 14.573602676391602}
2022-12-29 11:53:20.051 INFO: Optimization: policy loss=0.022, vf loss=0.000, entropy loss=-0.023, total loss=-0.001, num steps=10
2022-12-29 11:53:20.051 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 11:53:20.691 INFO: Evaluation rollout: return=0.499 (0.0), episode length=3.0
2022-12-29 11:53:20.692 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 11:53:20.694 INFO: Iteration: 26/137, steps: 5616
2022-12-29 11:54:09.776 INFO: Training rollout: return=0.453 (0.0), episode length=3.0
2022-12-29 11:54:09.777 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 11:54:09.780 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-5616_train.pkl
2022-12-29 11:54:10.485 DEBUG: Taking gradient step
2022-12-29 11:54:10.495 DEBUG: Loss 0: {'policy_loss': -0.02128941293228025, 'entropy_loss': -0.022934377659112215, 'vf_loss': 3.7225797133547006e-05, 'total_loss': -0.04418656479425892, 'approx_kl': -5.587935447692871e-09, 'clip_fraction': 0.0, 'grad_norm': 10.333904266357422}
2022-12-29 11:54:11.190 DEBUG: Taking gradient step
2022-12-29 11:54:11.200 DEBUG: Loss 1: {'policy_loss': 0.001740567444945676, 'entropy_loss': -0.022406222764402628, 'vf_loss': 3.504728861155847e-05, 'total_loss': -0.02063060803084539, 'approx_kl': 0.0006025885813869536, 'clip_fraction': 0.0, 'grad_norm': 6.496268272399902}
2022-12-29 11:54:11.897 DEBUG: Taking gradient step
2022-12-29 11:54:11.906 DEBUG: Loss 2: {'policy_loss': 0.052298613535105815, 'entropy_loss': -0.022299189120531082, 'vf_loss': 3.2349862211556104e-05, 'total_loss': 0.030031774276786292, 'approx_kl': 0.005804348562378436, 'clip_fraction': 0.0, 'grad_norm': 8.741069793701172}
2022-12-29 11:54:12.620 DEBUG: Taking gradient step
2022-12-29 11:54:12.631 DEBUG: Loss 3: {'policy_loss': -0.04508221562754984, 'entropy_loss': -0.02278056927025318, 'vf_loss': 3.505790967762758e-05, 'total_loss': -0.06782772698812538, 'approx_kl': 0.005459708045236766, 'clip_fraction': 0.01953125, 'grad_norm': 4.969192981719971}
2022-12-29 11:54:13.328 DEBUG: Taking gradient step
2022-12-29 11:54:13.337 DEBUG: Loss 4: {'policy_loss': -0.045097546908716625, 'entropy_loss': -0.023025894537568092, 'vf_loss': 3.5419805006739675e-05, 'total_loss': -0.06808802164127797, 'approx_kl': 0.011400812887586653, 'clip_fraction': 0.07942708395421505, 'grad_norm': 3.168682336807251}
2022-12-29 11:54:14.026 DEBUG: Taking gradient step
2022-12-29 11:54:14.035 DEBUG: Loss 5: {'policy_loss': -0.01892286187786336, 'entropy_loss': -0.023368760477751493, 'vf_loss': 3.472458583819293e-05, 'total_loss': -0.04225689776977666, 'approx_kl': 0.011503836372867227, 'clip_fraction': 0.07552083395421505, 'grad_norm': 4.976224899291992}
2022-12-29 11:54:14.768 DEBUG: Taking gradient step
2022-12-29 11:54:14.777 DEBUG: Loss 6: {'policy_loss': -0.012289479479173714, 'entropy_loss': -0.023959601297974586, 'vf_loss': 3.280090716505565e-05, 'total_loss': -0.03621627986998324, 'approx_kl': 0.01589296676684171, 'clip_fraction': 0.08072916697710752, 'grad_norm': 2.135709762573242}
2022-12-29 11:54:15.478 DEBUG: Taking gradient step
2022-12-29 11:54:15.488 DEBUG: Loss 7: {'policy_loss': 0.015588621612903898, 'entropy_loss': -0.023535779677331448, 'vf_loss': 3.2047518540914356e-05, 'total_loss': -0.00791511054588663, 'approx_kl': 0.034648733446374536, 'clip_fraction': 0.1002604179084301, 'grad_norm': 5.173840522766113}
2022-12-29 11:54:16.185 DEBUG: Taking gradient step
2022-12-29 11:54:16.194 DEBUG: Loss 8: {'policy_loss': -0.057203118862347746, 'entropy_loss': -0.0242097657173872, 'vf_loss': 3.2757175771609654e-05, 'total_loss': -0.08138012740396333, 'approx_kl': 0.03161444840952754, 'clip_fraction': 0.08463541697710752, 'grad_norm': 5.334026336669922}
2022-12-29 11:54:16.896 DEBUG: Early stopping at step 9 for reaching max KL.
2022-12-29 11:54:16.897 INFO: Optimization: policy loss=-0.057, vf loss=0.000, entropy loss=-0.024, total loss=-0.081, num steps=9
2022-12-29 11:54:16.897 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 11:54:17.588 INFO: Evaluation rollout: return=0.498 (0.0), episode length=3.0
2022-12-29 11:54:17.590 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 11:54:17.592 INFO: Iteration: 27/137, steps: 5832
2022-12-29 11:54:53.690 DEBUG: Atoms are too close
2022-12-29 11:55:06.014 INFO: Training rollout: return=0.166 (2.4), episode length=3.0
2022-12-29 11:55:06.016 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 11:55:06.018 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-5832_train.pkl
2022-12-29 11:55:06.732 DEBUG: Taking gradient step
2022-12-29 11:55:06.741 DEBUG: Loss 0: {'policy_loss': 0.05002063350088677, 'entropy_loss': -0.023750821128487587, 'vf_loss': 0.005916061506449696, 'total_loss': 0.03218587387884887, 'approx_kl': 2.2157717438631153e-08, 'clip_fraction': 0.0, 'grad_norm': 9.851401329040527}
2022-12-29 11:55:07.452 DEBUG: Taking gradient step
2022-12-29 11:55:07.462 DEBUG: Loss 1: {'policy_loss': -0.014662425296328017, 'entropy_loss': -0.025061514228582382, 'vf_loss': 0.0032558293914108326, 'total_loss': -0.036468110133499564, 'approx_kl': -0.00010010099504143, 'clip_fraction': 0.00390625, 'grad_norm': 9.712309837341309}
2022-12-29 11:55:08.148 DEBUG: Taking gradient step
2022-12-29 11:55:08.157 DEBUG: Loss 2: {'policy_loss': -0.019959649224786626, 'entropy_loss': -0.02472945163026452, 'vf_loss': 0.003254737264321733, 'total_loss': -0.04143436359072941, 'approx_kl': 0.0018712026067078114, 'clip_fraction': 0.07552083395421505, 'grad_norm': 8.456193923950195}
2022-12-29 11:55:08.871 DEBUG: Taking gradient step
2022-12-29 11:55:08.881 DEBUG: Loss 3: {'policy_loss': -0.0211265481333982, 'entropy_loss': -0.023454517126083374, 'vf_loss': 0.0032536967185011973, 'total_loss': -0.041327368540980375, 'approx_kl': 0.0070792511105537415, 'clip_fraction': 0.1927083358168602, 'grad_norm': 0.5203959941864014}
2022-12-29 11:55:09.610 DEBUG: Taking gradient step
2022-12-29 11:55:09.623 DEBUG: Loss 4: {'policy_loss': 0.0316268213976947, 'entropy_loss': -0.025544241536408663, 'vf_loss': 0.005962495553661659, 'total_loss': 0.012045075414947704, 'approx_kl': 0.029042808804661036, 'clip_fraction': 0.2473958358168602, 'grad_norm': 0.5217512249946594}
2022-12-29 11:55:10.341 DEBUG: Taking gradient step
2022-12-29 11:55:10.350 DEBUG: Loss 5: {'policy_loss': -0.019330388506420163, 'entropy_loss': -0.025809704791754484, 'vf_loss': 0.003242430104815227, 'total_loss': -0.04189766319335942, 'approx_kl': 0.011180959641933441, 'clip_fraction': 0.2890625, 'grad_norm': 0.48109111189842224}
2022-12-29 11:55:11.065 DEBUG: Taking gradient step
2022-12-29 11:55:11.074 DEBUG: Loss 6: {'policy_loss': -0.025458283068141754, 'entropy_loss': -0.024853413924574852, 'vf_loss': 0.0032390356534859038, 'total_loss': -0.0470726613392307, 'approx_kl': 0.013635905459523201, 'clip_fraction': 0.2669270858168602, 'grad_norm': 0.6310334205627441}
2022-12-29 11:55:11.790 DEBUG: Taking gradient step
2022-12-29 11:55:11.799 DEBUG: Loss 7: {'policy_loss': -0.021826437235799623, 'entropy_loss': -0.025227436795830727, 'vf_loss': 0.003233516389535666, 'total_loss': -0.04382035764209469, 'approx_kl': 0.006721381563693285, 'clip_fraction': 0.3125, 'grad_norm': 0.501895546913147}
2022-12-29 11:55:12.538 DEBUG: Taking gradient step
2022-12-29 11:55:12.548 DEBUG: Loss 8: {'policy_loss': -0.023321453688846187, 'entropy_loss': -0.02628602646291256, 'vf_loss': 0.003231422184520904, 'total_loss': -0.046376057967237844, 'approx_kl': 0.015566424001008272, 'clip_fraction': 0.2760416716337204, 'grad_norm': 0.6685588955879211}
2022-12-29 11:55:13.247 DEBUG: Taking gradient step
2022-12-29 11:55:13.257 DEBUG: Loss 9: {'policy_loss': -0.019444842298147608, 'entropy_loss': -0.025806710124015808, 'vf_loss': 0.003228635523289057, 'total_loss': -0.04202291689887437, 'approx_kl': 0.020245840772986412, 'clip_fraction': 0.2252604216337204, 'grad_norm': 0.6646305918693542}
2022-12-29 11:55:13.257 INFO: Optimization: policy loss=-0.019, vf loss=0.003, entropy loss=-0.026, total loss=-0.042, num steps=10
2022-12-29 11:55:13.258 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 11:55:13.972 INFO: Evaluation rollout: return=0.498 (0.0), episode length=3.0
2022-12-29 11:55:13.973 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 11:55:13.975 INFO: Iteration: 28/137, steps: 6048
2022-12-29 11:55:19.514 DEBUG: Atoms are too close
2022-12-29 11:55:36.371 DEBUG: Atoms are too close
2022-12-29 11:55:52.216 DEBUG: Atoms are too close
2022-12-29 11:56:01.893 INFO: Training rollout: return=-0.393 (4.0), episode length=3.0
2022-12-29 11:56:01.895 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 11:56:01.898 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-6048_train.pkl
2022-12-29 11:56:02.617 DEBUG: Taking gradient step
2022-12-29 11:56:02.627 DEBUG: Loss 0: {'policy_loss': -0.03235504928940447, 'entropy_loss': -0.026401149109005928, 'vf_loss': 0.014131618873059155, 'total_loss': -0.04462457952535123, 'approx_kl': 2.421438694000244e-08, 'clip_fraction': 0.0, 'grad_norm': 14.90025806427002}
2022-12-29 11:56:03.336 DEBUG: Taking gradient step
2022-12-29 11:56:03.345 DEBUG: Loss 1: {'policy_loss': -0.03616887816375561, 'entropy_loss': -0.025482095312327147, 'vf_loss': 0.014128339365948627, 'total_loss': -0.047522634110134125, 'approx_kl': 0.007151025463826954, 'clip_fraction': 0.0, 'grad_norm': 14.217117309570312}
2022-12-29 11:56:04.049 DEBUG: Taking gradient step
2022-12-29 11:56:04.060 DEBUG: Loss 2: {'policy_loss': -0.007606011737449888, 'entropy_loss': -0.025657207239419222, 'vf_loss': 0.016706363705908174, 'total_loss': -0.016556855270960937, 'approx_kl': 0.010707098175771534, 'clip_fraction': 0.06510416697710752, 'grad_norm': 4.911334991455078}
2022-12-29 11:56:04.757 DEBUG: Taking gradient step
2022-12-29 11:56:04.766 DEBUG: Loss 3: {'policy_loss': 0.022806235163799773, 'entropy_loss': -0.026739230379462242, 'vf_loss': 0.019294300453268166, 'total_loss': 0.015361305237605705, 'approx_kl': 0.018756022211164236, 'clip_fraction': 0.1848958358168602, 'grad_norm': 5.285162925720215}
2022-12-29 11:56:05.473 DEBUG: Taking gradient step
2022-12-29 11:56:05.482 DEBUG: Loss 4: {'policy_loss': -0.0413764750027988, 'entropy_loss': -0.025497956667095423, 'vf_loss': 0.014088523731314022, 'total_loss': -0.05278590793858019, 'approx_kl': 0.02127192262560129, 'clip_fraction': 0.2109375, 'grad_norm': 2.204927682876587}
2022-12-29 11:56:06.206 DEBUG: Taking gradient step
2022-12-29 11:56:06.216 DEBUG: Loss 5: {'policy_loss': -0.04049023053922977, 'entropy_loss': -0.02730440627783537, 'vf_loss': 0.014058894793356855, 'total_loss': -0.05373574202370829, 'approx_kl': 0.03168954444117844, 'clip_fraction': 0.18359375, 'grad_norm': 1.9157428741455078}
2022-12-29 11:56:06.919 DEBUG: Taking gradient step
2022-12-29 11:56:06.928 DEBUG: Loss 6: {'policy_loss': -0.016423560745018537, 'entropy_loss': -0.026792440563440323, 'vf_loss': 0.016633634340505826, 'total_loss': -0.026582366967953033, 'approx_kl': 0.025938430335372686, 'clip_fraction': 0.12239583395421505, 'grad_norm': 1.4705393314361572}
2022-12-29 11:56:07.644 DEBUG: Taking gradient step
2022-12-29 11:56:07.654 DEBUG: Loss 7: {'policy_loss': -0.006625356661669487, 'entropy_loss': -0.02710632374510169, 'vf_loss': 0.016510056284855246, 'total_loss': -0.017221624121915934, 'approx_kl': 0.029220367083325982, 'clip_fraction': 0.14453125, 'grad_norm': 3.053860664367676}
2022-12-29 11:56:08.436 DEBUG: Taking gradient step
2022-12-29 11:56:08.449 DEBUG: Loss 8: {'policy_loss': 0.04384624641515868, 'entropy_loss': -0.026483161840587854, 'vf_loss': 0.021605797498259055, 'total_loss': 0.03896888207282988, 'approx_kl': 0.03616583556868136, 'clip_fraction': 0.13020833395421505, 'grad_norm': 2.5467300415039062}
2022-12-29 11:56:09.213 DEBUG: Taking gradient step
2022-12-29 11:56:09.223 DEBUG: Loss 9: {'policy_loss': -0.012968802715783184, 'entropy_loss': -0.026684468612074852, 'vf_loss': 0.016511487655094297, 'total_loss': -0.023141783672763736, 'approx_kl': 0.014392038341611624, 'clip_fraction': 0.2786458358168602, 'grad_norm': 2.0672669410705566}
2022-12-29 11:56:09.223 INFO: Optimization: policy loss=-0.013, vf loss=0.017, entropy loss=-0.027, total loss=-0.023, num steps=10
2022-12-29 11:56:09.223 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 11:56:09.877 INFO: Evaluation rollout: return=0.491 (0.0), episode length=3.0
2022-12-29 11:56:09.878 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 11:56:09.880 INFO: Iteration: 29/137, steps: 6264
2022-12-29 11:56:31.999 DEBUG: Atoms are too close
2022-12-29 11:56:58.974 INFO: Training rollout: return=0.167 (2.4), episode length=3.0
2022-12-29 11:56:58.976 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 11:56:58.978 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-6264_train.pkl
2022-12-29 11:56:59.703 DEBUG: Taking gradient step
2022-12-29 11:56:59.712 DEBUG: Loss 0: {'policy_loss': -0.02114549043228023, 'entropy_loss': -0.0258562876842916, 'vf_loss': 0.0048238034960995015, 'total_loss': -0.04217797462047232, 'approx_kl': 9.778887033462524e-09, 'clip_fraction': 0.0, 'grad_norm': 15.840259552001953}
2022-12-29 11:57:00.443 DEBUG: Taking gradient step
2022-12-29 11:57:00.452 DEBUG: Loss 1: {'policy_loss': -0.02164921493220244, 'entropy_loss': -0.025775541085749865, 'vf_loss': 0.004840843022351314, 'total_loss': -0.04258391299560099, 'approx_kl': 0.006133527960628271, 'clip_fraction': 0.0, 'grad_norm': 13.685574531555176}
2022-12-29 11:57:01.208 DEBUG: Taking gradient step
2022-12-29 11:57:01.222 DEBUG: Loss 2: {'policy_loss': 0.03434047537410877, 'entropy_loss': -0.025449990760535002, 'vf_loss': 0.007378380351587845, 'total_loss': 0.016268864965161618, 'approx_kl': 0.010686623281799257, 'clip_fraction': 0.046875, 'grad_norm': 3.7576065063476562}
2022-12-29 11:57:01.958 DEBUG: Taking gradient step
2022-12-29 11:57:01.967 DEBUG: Loss 3: {'policy_loss': -0.020517479319396247, 'entropy_loss': -0.026089714374393225, 'vf_loss': 0.00488048638642614, 'total_loss': -0.04172670730736333, 'approx_kl': 0.022939380607567728, 'clip_fraction': 0.12890625, 'grad_norm': 1.9605196714401245}
2022-12-29 11:57:02.677 DEBUG: Taking gradient step
2022-12-29 11:57:02.686 DEBUG: Loss 4: {'policy_loss': 0.03757565721591304, 'entropy_loss': -0.026295632123947144, 'vf_loss': 0.007380012496641553, 'total_loss': 0.018660037588607452, 'approx_kl': 0.021785298362374306, 'clip_fraction': 0.1549479179084301, 'grad_norm': 4.255289077758789}
2022-12-29 11:57:03.465 DEBUG: Taking gradient step
2022-12-29 11:57:03.475 DEBUG: Loss 5: {'policy_loss': 0.03134387582715695, 'entropy_loss': -0.026055535301566124, 'vf_loss': 0.007402579522383145, 'total_loss': 0.012690920047973966, 'approx_kl': 0.030829524621367455, 'clip_fraction': 0.1822916679084301, 'grad_norm': 4.551477432250977}
2022-12-29 11:57:04.200 DEBUG: Taking gradient step
2022-12-29 11:57:04.210 DEBUG: Loss 6: {'policy_loss': -0.025565749305986672, 'entropy_loss': -0.024796131532639265, 'vf_loss': 0.0049199528751498875, 'total_loss': -0.04544192796347605, 'approx_kl': 0.03271448379382491, 'clip_fraction': 0.1861979179084301, 'grad_norm': 2.220162868499756}
2022-12-29 11:57:04.938 DEBUG: Taking gradient step
2022-12-29 11:57:04.947 DEBUG: Loss 7: {'policy_loss': -0.0270493688610768, 'entropy_loss': -0.026576565112918615, 'vf_loss': 0.004916789927794627, 'total_loss': -0.04870914404620078, 'approx_kl': 0.034317093435674906, 'clip_fraction': 0.1783854179084301, 'grad_norm': 1.7679001092910767}
2022-12-29 11:57:05.649 DEBUG: Taking gradient step
2022-12-29 11:57:05.659 DEBUG: Loss 8: {'policy_loss': -0.027740952524091797, 'entropy_loss': -0.026369377970695496, 'vf_loss': 0.004902126097893216, 'total_loss': -0.049208204396894065, 'approx_kl': 0.02820682618767023, 'clip_fraction': 0.1861979179084301, 'grad_norm': 1.4496618509292603}
2022-12-29 11:57:06.359 DEBUG: Early stopping at step 9 for reaching max KL.
2022-12-29 11:57:06.360 INFO: Optimization: policy loss=-0.028, vf loss=0.005, entropy loss=-0.026, total loss=-0.049, num steps=9
2022-12-29 11:57:06.360 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 11:57:07.030 INFO: Evaluation rollout: return=0.493 (0.0), episode length=3.0
2022-12-29 11:57:07.031 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 11:57:07.033 INFO: Iteration: 30/137, steps: 6480
2022-12-29 11:57:12.954 DEBUG: Atoms are too close
2022-12-29 11:57:54.905 INFO: Training rollout: return=0.167 (2.4), episode length=3.0
2022-12-29 11:57:54.906 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 11:57:54.909 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-6480_train.pkl
2022-12-29 11:57:55.622 DEBUG: Taking gradient step
2022-12-29 11:57:55.631 DEBUG: Loss 0: {'policy_loss': -0.018783214541579378, 'entropy_loss': -0.026477681938558817, 'vf_loss': 0.0049019375333598045, 'total_loss': -0.040358958946778385, 'approx_kl': -3.725290298461914e-09, 'clip_fraction': 0.0, 'grad_norm': 16.946104049682617}
2022-12-29 11:57:56.335 DEBUG: Taking gradient step
2022-12-29 11:57:56.346 DEBUG: Loss 1: {'policy_loss': 0.03479950408762618, 'entropy_loss': -0.027043091598898172, 'vf_loss': 0.007451823158349236, 'total_loss': 0.01520823564707724, 'approx_kl': 0.007683697389438748, 'clip_fraction': 0.00390625, 'grad_norm': 16.270265579223633}
2022-12-29 11:57:57.076 DEBUG: Taking gradient step
2022-12-29 11:57:57.085 DEBUG: Loss 2: {'policy_loss': -0.024857937906758398, 'entropy_loss': -0.02732600923627615, 'vf_loss': 0.0048829365137193406, 'total_loss': -0.04730101062931521, 'approx_kl': 0.015914297429844737, 'clip_fraction': 0.0625, 'grad_norm': 1.5787783861160278}
2022-12-29 11:57:57.777 DEBUG: Taking gradient step
2022-12-29 11:57:57.787 DEBUG: Loss 3: {'policy_loss': -0.02000642273333601, 'entropy_loss': -0.026513290591537952, 'vf_loss': 0.004856532292079659, 'total_loss': -0.041663181032794296, 'approx_kl': 0.025867604301311076, 'clip_fraction': 0.1302083358168602, 'grad_norm': 1.7982856035232544}
2022-12-29 11:57:58.495 DEBUG: Taking gradient step
2022-12-29 11:57:58.504 DEBUG: Loss 4: {'policy_loss': -0.020815696142535256, 'entropy_loss': -0.02677035192027688, 'vf_loss': 0.004838716380655252, 'total_loss': -0.04274733168215688, 'approx_kl': 0.018371822661720216, 'clip_fraction': 0.10416666697710752, 'grad_norm': 1.5110892057418823}
2022-12-29 11:57:59.212 DEBUG: Taking gradient step
2022-12-29 11:57:59.221 DEBUG: Loss 5: {'policy_loss': 0.03472616724334592, 'entropy_loss': -0.02600926999002695, 'vf_loss': 0.007302308261629003, 'total_loss': 0.016019205514947975, 'approx_kl': 0.010185078717768192, 'clip_fraction': 0.057291666977107525, 'grad_norm': 1.8406034708023071}
2022-12-29 11:57:59.921 DEBUG: Taking gradient step
2022-12-29 11:57:59.930 DEBUG: Loss 6: {'policy_loss': -0.026392849927668292, 'entropy_loss': -0.025457557756453753, 'vf_loss': 0.0048022480557586575, 'total_loss': -0.04704815962836338, 'approx_kl': 0.01105202583130449, 'clip_fraction': 0.022135416977107525, 'grad_norm': 1.3104184865951538}
2022-12-29 11:58:00.645 DEBUG: Taking gradient step
2022-12-29 11:58:00.654 DEBUG: Loss 7: {'policy_loss': -0.028326928327450356, 'entropy_loss': -0.025471821427345276, 'vf_loss': 0.004788841747601145, 'total_loss': -0.049009908007194486, 'approx_kl': 0.00422867143061012, 'clip_fraction': 0.00390625, 'grad_norm': 14.072282791137695}
2022-12-29 11:58:01.356 DEBUG: Taking gradient step
2022-12-29 11:58:01.368 DEBUG: Loss 8: {'policy_loss': -0.02857437766350943, 'entropy_loss': -0.0257015572860837, 'vf_loss': 0.004771724374822711, 'total_loss': -0.04950421057477041, 'approx_kl': 0.0031468624365516007, 'clip_fraction': 0.04427083395421505, 'grad_norm': 0.8935872912406921}
2022-12-29 11:58:02.068 DEBUG: Taking gradient step
2022-12-29 11:58:02.077 DEBUG: Loss 9: {'policy_loss': -0.02241073238939949, 'entropy_loss': -0.02683415962383151, 'vf_loss': 0.004753109516059042, 'total_loss': -0.044491782497171964, 'approx_kl': 0.005972838494926691, 'clip_fraction': 0.0546875, 'grad_norm': 0.7507645487785339}
2022-12-29 11:58:02.077 INFO: Optimization: policy loss=-0.022, vf loss=0.005, entropy loss=-0.027, total loss=-0.044, num steps=10
2022-12-29 11:58:02.078 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 11:58:02.801 INFO: Evaluation rollout: return=0.486 (0.0), episode length=3.0
2022-12-29 11:58:02.804 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 11:58:02.806 DEBUG: Deleting old model: runs/H2O/models/H2O_run-1_steps-4536.model
2022-12-29 11:58:02.808 DEBUG: Saving model: runs/H2O/models/H2O_run-1_steps-6696.model
2022-12-29 11:58:02.837 INFO: Iteration: 31/137, steps: 6696
2022-12-29 11:58:51.238 INFO: Training rollout: return=0.452 (0.0), episode length=3.0
2022-12-29 11:58:51.240 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 11:58:51.242 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-6696_train.pkl
2022-12-29 11:58:51.982 DEBUG: Taking gradient step
2022-12-29 11:58:51.991 DEBUG: Loss 0: {'policy_loss': 0.04193827637310242, 'entropy_loss': -0.026818757876753807, 'vf_loss': 0.0001545633638222154, 'total_loss': 0.015274081860170832, 'approx_kl': -3.7408123709781194e-08, 'clip_fraction': 0.0, 'grad_norm': 12.29453182220459}
2022-12-29 11:58:52.712 DEBUG: Taking gradient step
2022-12-29 11:58:52.722 DEBUG: Loss 1: {'policy_loss': 0.03711548552464076, 'entropy_loss': -0.026190028060227633, 'vf_loss': 0.00013348634597929945, 'total_loss': 0.011058943810392421, 'approx_kl': 0.004229001002386212, 'clip_fraction': 0.022135416977107525, 'grad_norm': 11.377633094787598}
2022-12-29 11:58:53.432 DEBUG: Taking gradient step
2022-12-29 11:58:53.441 DEBUG: Loss 2: {'policy_loss': 0.04139866592771704, 'entropy_loss': -0.02630235254764557, 'vf_loss': 0.00011713738468479529, 'total_loss': 0.015213450764756262, 'approx_kl': 0.015466379350982606, 'clip_fraction': 0.11458333395421505, 'grad_norm': 9.011796951293945}
2022-12-29 11:58:54.153 DEBUG: Taking gradient step
2022-12-29 11:58:54.163 DEBUG: Loss 3: {'policy_loss': 0.047541785365065564, 'entropy_loss': -0.026703379582613707, 'vf_loss': 0.0001023554058913745, 'total_loss': 0.020940761188343225, 'approx_kl': 0.015570302261039615, 'clip_fraction': 0.171875, 'grad_norm': 9.58907413482666}
2022-12-29 11:58:54.875 DEBUG: Taking gradient step
2022-12-29 11:58:54.884 DEBUG: Loss 4: {'policy_loss': 0.0384448078275189, 'entropy_loss': -0.025386566296219826, 'vf_loss': 9.058303841726601e-05, 'total_loss': 0.013148824569716333, 'approx_kl': 0.026103364769369364, 'clip_fraction': 0.2083333358168602, 'grad_norm': 11.880335807800293}
2022-12-29 11:58:55.577 DEBUG: Taking gradient step
2022-12-29 11:58:55.586 DEBUG: Loss 5: {'policy_loss': 0.012422341073485936, 'entropy_loss': -0.02574467333033681, 'vf_loss': 8.362622410640348e-05, 'total_loss': -0.013238706032744471, 'approx_kl': 0.009023199556395411, 'clip_fraction': 0.1705729179084301, 'grad_norm': 9.99749755859375}
2022-12-29 11:58:56.272 DEBUG: Taking gradient step
2022-12-29 11:58:56.281 DEBUG: Loss 6: {'policy_loss': 0.0006646411174862643, 'entropy_loss': -0.025891571771353483, 'vf_loss': 7.775018708114156e-05, 'total_loss': -0.025149180466786086, 'approx_kl': 0.019632167415693402, 'clip_fraction': 0.1536458358168602, 'grad_norm': 10.292638778686523}
2022-12-29 11:58:57.002 DEBUG: Taking gradient step
2022-12-29 11:58:57.012 DEBUG: Loss 7: {'policy_loss': -0.055977940035356284, 'entropy_loss': -0.025557428132742643, 'vf_loss': 7.565584087851099e-05, 'total_loss': -0.08145971232722042, 'approx_kl': 0.014070824487134814, 'clip_fraction': 0.11067708395421505, 'grad_norm': 7.160069465637207}
2022-12-29 11:58:57.730 DEBUG: Taking gradient step
2022-12-29 11:58:57.739 DEBUG: Loss 8: {'policy_loss': -0.025211718993173236, 'entropy_loss': -0.025092239025980234, 'vf_loss': 6.479652981429134e-05, 'total_loss': -0.050239161489339185, 'approx_kl': 0.01431043322372716, 'clip_fraction': 0.1315104179084301, 'grad_norm': 5.559658527374268}
2022-12-29 11:58:58.439 DEBUG: Taking gradient step
2022-12-29 11:58:58.448 DEBUG: Loss 9: {'policy_loss': -0.04293839202892995, 'entropy_loss': -0.025045993737876415, 'vf_loss': 6.629967279765588e-05, 'total_loss': -0.0679180860940087, 'approx_kl': 0.018071638303808868, 'clip_fraction': 0.15234375, 'grad_norm': 8.38999080657959}
2022-12-29 11:58:58.448 INFO: Optimization: policy loss=-0.043, vf loss=0.000, entropy loss=-0.025, total loss=-0.068, num steps=10
2022-12-29 11:58:58.449 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 11:58:59.142 INFO: Evaluation rollout: return=0.490 (0.0), episode length=3.0
2022-12-29 11:58:59.143 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 11:58:59.144 INFO: Iteration: 32/137, steps: 6912
2022-12-29 11:59:47.720 INFO: Training rollout: return=0.452 (0.0), episode length=3.0
2022-12-29 11:59:47.722 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 11:59:47.724 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-6912_train.pkl
2022-12-29 11:59:48.462 DEBUG: Taking gradient step
2022-12-29 11:59:48.475 DEBUG: Loss 0: {'policy_loss': 0.016021665346939717, 'entropy_loss': -0.026056019123643637, 'vf_loss': 5.718702880115228e-05, 'total_loss': -0.009977166747902767, 'approx_kl': -2.0644318254881e-08, 'clip_fraction': 0.0, 'grad_norm': 12.861330032348633}
2022-12-29 11:59:49.178 DEBUG: Taking gradient step
2022-12-29 11:59:49.188 DEBUG: Loss 1: {'policy_loss': -0.02228154865334236, 'entropy_loss': -0.025555070023983717, 'vf_loss': 5.650749811432698e-05, 'total_loss': -0.04778011117921176, 'approx_kl': 0.004447067040018737, 'clip_fraction': 0.010416666977107525, 'grad_norm': 12.357144355773926}
2022-12-29 11:59:49.926 DEBUG: Taking gradient step
2022-12-29 11:59:49.939 DEBUG: Loss 2: {'policy_loss': 0.022862174043821987, 'entropy_loss': -0.025628923904150724, 'vf_loss': 5.367114954881278e-05, 'total_loss': -0.0027130787107799287, 'approx_kl': 0.018112576857674867, 'clip_fraction': 0.06640625, 'grad_norm': 9.327176094055176}
2022-12-29 11:59:50.677 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-29 11:59:50.678 INFO: Optimization: policy loss=0.023, vf loss=0.000, entropy loss=-0.026, total loss=-0.003, num steps=3
2022-12-29 11:59:50.678 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 11:59:51.365 INFO: Evaluation rollout: return=0.500 (0.0), episode length=3.0
2022-12-29 11:59:51.365 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 11:59:51.367 INFO: Iteration: 33/137, steps: 7128
2022-12-29 12:00:40.028 INFO: Training rollout: return=0.444 (0.1), episode length=3.0
2022-12-29 12:00:40.030 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:00:40.033 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-7128_train.pkl
2022-12-29 12:00:40.773 DEBUG: Taking gradient step
2022-12-29 12:00:40.782 DEBUG: Loss 0: {'policy_loss': 0.044910324258080156, 'entropy_loss': -0.02575830090790987, 'vf_loss': 5.20221907680811e-05, 'total_loss': 0.019204045540938366, 'approx_kl': -5.405551561921129e-08, 'clip_fraction': 0.0, 'grad_norm': 21.91569709777832}
2022-12-29 12:00:41.495 DEBUG: Taking gradient step
2022-12-29 12:00:41.505 DEBUG: Loss 1: {'policy_loss': 0.008310402015499221, 'entropy_loss': -0.0247065844014287, 'vf_loss': 5.2206302540921475e-05, 'total_loss': -0.01634397608338856, 'approx_kl': 0.00644942419603467, 'clip_fraction': 0.03125, 'grad_norm': 12.957025527954102}
2022-12-29 12:00:42.260 DEBUG: Taking gradient step
2022-12-29 12:00:42.269 DEBUG: Loss 2: {'policy_loss': 0.012728632230055464, 'entropy_loss': -0.02555956644937396, 'vf_loss': 5.345696985371004e-05, 'total_loss': -0.012777477249464786, 'approx_kl': 0.02837783587165177, 'clip_fraction': 0.1471354179084301, 'grad_norm': 10.424631118774414}
2022-12-29 12:00:43.003 DEBUG: Taking gradient step
2022-12-29 12:00:43.012 DEBUG: Loss 3: {'policy_loss': 0.00017702365405646535, 'entropy_loss': -0.02541396487504244, 'vf_loss': 5.4459169194320306e-05, 'total_loss': -0.025182482051791653, 'approx_kl': 0.04027881193906069, 'clip_fraction': 0.2174479179084301, 'grad_norm': 15.706379890441895}
2022-12-29 12:00:43.720 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-29 12:00:43.721 INFO: Optimization: policy loss=0.000, vf loss=0.000, entropy loss=-0.025, total loss=-0.025, num steps=4
2022-12-29 12:00:43.721 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:00:44.433 INFO: Evaluation rollout: return=0.506 (0.0), episode length=3.0
2022-12-29 12:00:44.434 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:00:44.436 INFO: Iteration: 34/137, steps: 7344
2022-12-29 12:01:19.856 DEBUG: There is a single atom floating around
2022-12-29 12:01:31.936 DEBUG: Atoms are too close
2022-12-29 12:01:32.712 INFO: Training rollout: return=-0.106 (3.3), episode length=3.0
2022-12-29 12:01:32.713 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:01:32.716 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-7344_train.pkl
2022-12-29 12:01:33.451 DEBUG: Taking gradient step
2022-12-29 12:01:33.465 DEBUG: Loss 0: {'policy_loss': 0.022237369078262736, 'entropy_loss': -0.02519921213388443, 'vf_loss': 0.010510365080029917, 'total_loss': 0.007548522024408231, 'approx_kl': -4.353933036327362e-08, 'clip_fraction': 0.0, 'grad_norm': 10.761828422546387}
2022-12-29 12:01:34.195 DEBUG: Taking gradient step
2022-12-29 12:01:34.204 DEBUG: Loss 1: {'policy_loss': 0.10575832047994639, 'entropy_loss': -0.02412850223481655, 'vf_loss': 0.01570265259409426, 'total_loss': 0.0973324708392241, 'approx_kl': -0.0009195810125675052, 'clip_fraction': 0.0, 'grad_norm': 11.835555076599121}
2022-12-29 12:01:34.897 DEBUG: Taking gradient step
2022-12-29 12:01:34.906 DEBUG: Loss 2: {'policy_loss': 0.045709423445083226, 'entropy_loss': -0.02473406493663788, 'vf_loss': 0.013275203290320725, 'total_loss': 0.03425056179876607, 'approx_kl': 0.0007885452941991389, 'clip_fraction': 0.0, 'grad_norm': 24.37001609802246}
2022-12-29 12:01:35.620 DEBUG: Taking gradient step
2022-12-29 12:01:35.629 DEBUG: Loss 3: {'policy_loss': -0.03688329611196894, 'entropy_loss': -0.0252508157864213, 'vf_loss': 0.007941063137790347, 'total_loss': -0.05419304876059989, 'approx_kl': 0.00364902731962502, 'clip_fraction': 0.033854166977107525, 'grad_norm': 2.092582941055298}
2022-12-29 12:01:36.330 DEBUG: Taking gradient step
2022-12-29 12:01:36.340 DEBUG: Loss 4: {'policy_loss': -0.03542441946509467, 'entropy_loss': -0.023934151511639357, 'vf_loss': 0.00793078163320014, 'total_loss': -0.05142778934353388, 'approx_kl': 0.005848443601280451, 'clip_fraction': 0.053385416977107525, 'grad_norm': 0.9448940753936768}
2022-12-29 12:01:37.055 DEBUG: Taking gradient step
2022-12-29 12:01:37.064 DEBUG: Loss 5: {'policy_loss': -0.03595979232386418, 'entropy_loss': -0.02426151419058442, 'vf_loss': 0.007916781504297475, 'total_loss': -0.05230452501015113, 'approx_kl': 0.004575956845656037, 'clip_fraction': 0.06510416697710752, 'grad_norm': 0.7487732172012329}
2022-12-29 12:01:37.800 DEBUG: Taking gradient step
2022-12-29 12:01:37.810 DEBUG: Loss 6: {'policy_loss': 0.0049708398893273595, 'entropy_loss': -0.0236879657022655, 'vf_loss': 0.010539254830048831, 'total_loss': -0.008177870982889305, 'approx_kl': 0.006038461811840534, 'clip_fraction': 0.11588541697710752, 'grad_norm': 0.8678625226020813}
2022-12-29 12:01:38.498 DEBUG: Taking gradient step
2022-12-29 12:01:38.507 DEBUG: Loss 7: {'policy_loss': 0.0005429626176958469, 'entropy_loss': -0.023973860312253237, 'vf_loss': 0.01051769075334268, 'total_loss': -0.012913206941214707, 'approx_kl': 0.01350555825047195, 'clip_fraction': 0.19921875, 'grad_norm': 1.0799338817596436}
2022-12-29 12:01:39.220 DEBUG: Taking gradient step
2022-12-29 12:01:39.235 DEBUG: Loss 8: {'policy_loss': -0.039143636221012384, 'entropy_loss': -0.02317809220403433, 'vf_loss': 0.007846516020589773, 'total_loss': -0.05447521240445694, 'approx_kl': 0.0010866890661418438, 'clip_fraction': 0.2174479216337204, 'grad_norm': 1.008336067199707}
2022-12-29 12:01:39.934 DEBUG: Taking gradient step
2022-12-29 12:01:39.944 DEBUG: Loss 9: {'policy_loss': -0.04249012829856196, 'entropy_loss': -0.023583058267831802, 'vf_loss': 0.007818793791730658, 'total_loss': -0.058254392774663113, 'approx_kl': 0.012217450188472867, 'clip_fraction': 0.1901041679084301, 'grad_norm': 1.0007786750793457}
2022-12-29 12:01:39.944 INFO: Optimization: policy loss=-0.042, vf loss=0.008, entropy loss=-0.024, total loss=-0.058, num steps=10
2022-12-29 12:01:39.944 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:01:40.598 INFO: Evaluation rollout: return=0.510 (0.0), episode length=3.0
2022-12-29 12:01:40.599 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:01:40.601 INFO: Iteration: 35/137, steps: 7560
2022-12-29 12:01:42.371 DEBUG: Atoms are too close
2022-12-29 12:02:28.352 INFO: Training rollout: return=0.173 (2.4), episode length=3.0
2022-12-29 12:02:28.354 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:02:28.357 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-7560_train.pkl
2022-12-29 12:02:29.101 DEBUG: Taking gradient step
2022-12-29 12:02:29.114 DEBUG: Loss 0: {'policy_loss': -0.012989006135945311, 'entropy_loss': -0.023468663915991783, 'vf_loss': 0.003286099473709638, 'total_loss': -0.03317157057822745, 'approx_kl': 4.5673612447671985e-08, 'clip_fraction': 0.0, 'grad_norm': 7.389545440673828}
2022-12-29 12:02:29.866 DEBUG: Taking gradient step
2022-12-29 12:02:29.880 DEBUG: Loss 1: {'policy_loss': -0.01703865309906935, 'entropy_loss': -0.023169926833361387, 'vf_loss': 0.00329807837151393, 'total_loss': -0.03691050156091681, 'approx_kl': 0.0008622551104053855, 'clip_fraction': 0.0, 'grad_norm': 6.6394453048706055}
2022-12-29 12:02:30.586 DEBUG: Taking gradient step
2022-12-29 12:02:30.595 DEBUG: Loss 2: {'policy_loss': -0.018561715901668687, 'entropy_loss': -0.023344764951616526, 'vf_loss': 0.003314690207312982, 'total_loss': -0.038591790645972235, 'approx_kl': 0.009066654878552072, 'clip_fraction': 0.06901041697710752, 'grad_norm': 0.9385892152786255}
2022-12-29 12:02:31.286 DEBUG: Taking gradient step
2022-12-29 12:02:31.296 DEBUG: Loss 3: {'policy_loss': -0.01980979238429075, 'entropy_loss': -0.02367445733398199, 'vf_loss': 0.00332938435341924, 'total_loss': -0.0401548653648535, 'approx_kl': 0.014970589971198933, 'clip_fraction': 0.17578125, 'grad_norm': 0.8740228414535522}
2022-12-29 12:02:31.987 DEBUG: Taking gradient step
2022-12-29 12:02:31.996 DEBUG: Loss 4: {'policy_loss': -0.024704557374559927, 'entropy_loss': -0.022761191707104445, 'vf_loss': 0.0033557313408338584, 'total_loss': -0.04411001774083051, 'approx_kl': 0.024143720511347055, 'clip_fraction': 0.2526041716337204, 'grad_norm': 1.231467604637146}
2022-12-29 12:02:32.712 DEBUG: Taking gradient step
2022-12-29 12:02:32.721 DEBUG: Loss 5: {'policy_loss': -0.02105251615134987, 'entropy_loss': -0.02345396624878049, 'vf_loss': 0.003345093612362299, 'total_loss': -0.04116138878776805, 'approx_kl': 0.024925533216446638, 'clip_fraction': 0.3125, 'grad_norm': 0.7531812191009521}
2022-12-29 12:02:33.389 DEBUG: Taking gradient step
2022-12-29 12:02:33.398 DEBUG: Loss 6: {'policy_loss': 0.028419691666370955, 'entropy_loss': -0.022753614000976086, 'vf_loss': 0.006039360714914337, 'total_loss': 0.0117054383803092, 'approx_kl': 0.02096509002149105, 'clip_fraction': 0.29296875, 'grad_norm': 1.1162739992141724}
2022-12-29 12:02:34.076 DEBUG: Taking gradient step
2022-12-29 12:02:34.086 DEBUG: Loss 7: {'policy_loss': -0.017879168669985936, 'entropy_loss': -0.02357329661026597, 'vf_loss': 0.0033298843333980214, 'total_loss': -0.03812258094685389, 'approx_kl': 0.017283721594139934, 'clip_fraction': 0.3294270858168602, 'grad_norm': 0.6508793830871582}
2022-12-29 12:02:34.781 DEBUG: Taking gradient step
2022-12-29 12:02:34.791 DEBUG: Loss 8: {'policy_loss': -0.015890581401285984, 'entropy_loss': -0.023408059030771255, 'vf_loss': 0.00331635863052039, 'total_loss': -0.035982281801536856, 'approx_kl': 0.008574883337132633, 'clip_fraction': 0.3229166716337204, 'grad_norm': 0.7555612325668335}
2022-12-29 12:02:35.482 DEBUG: Taking gradient step
2022-12-29 12:02:35.492 DEBUG: Loss 9: {'policy_loss': -0.01842810398152437, 'entropy_loss': -0.02409550314769149, 'vf_loss': 0.0033085757048263303, 'total_loss': -0.03921503142438953, 'approx_kl': 0.025884911185130477, 'clip_fraction': 0.2916666716337204, 'grad_norm': 1.114007830619812}
2022-12-29 12:02:35.492 INFO: Optimization: policy loss=-0.018, vf loss=0.003, entropy loss=-0.024, total loss=-0.039, num steps=10
2022-12-29 12:02:35.492 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:02:36.322 INFO: Evaluation rollout: return=0.506 (0.0), episode length=3.0
2022-12-29 12:02:36.323 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:02:36.325 INFO: Iteration: 36/137, steps: 7776
2022-12-29 12:03:24.880 INFO: Training rollout: return=0.466 (0.0), episode length=3.0
2022-12-29 12:03:24.882 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:03:24.885 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-7776_train.pkl
2022-12-29 12:03:25.608 DEBUG: Taking gradient step
2022-12-29 12:03:25.619 DEBUG: Loss 0: {'policy_loss': 0.029977082330187484, 'entropy_loss': -0.02303610136732459, 'vf_loss': 8.583576472475499e-05, 'total_loss': 0.007026816727587648, 'approx_kl': -3.927076974719057e-08, 'clip_fraction': 0.0, 'grad_norm': 9.777826309204102}
2022-12-29 12:03:26.304 DEBUG: Taking gradient step
2022-12-29 12:03:26.313 DEBUG: Loss 1: {'policy_loss': 0.03589362384000362, 'entropy_loss': -0.024285128340125084, 'vf_loss': 7.47501159414033e-05, 'total_loss': 0.011683245615819939, 'approx_kl': 0.0005265490617603064, 'clip_fraction': 0.0, 'grad_norm': 6.951578617095947}
2022-12-29 12:03:27.035 DEBUG: Taking gradient step
2022-12-29 12:03:27.044 DEBUG: Loss 2: {'policy_loss': -0.004627785349636254, 'entropy_loss': -0.023156387731432915, 'vf_loss': 7.3949553851865e-05, 'total_loss': -0.0277102235272173, 'approx_kl': 0.004911773663479835, 'clip_fraction': 0.0078125, 'grad_norm': 3.854485034942627}
2022-12-29 12:03:27.727 DEBUG: Taking gradient step
2022-12-29 12:03:27.737 DEBUG: Loss 3: {'policy_loss': -0.014511448411737949, 'entropy_loss': -0.02260932559147477, 'vf_loss': 7.046566094578643e-05, 'total_loss': -0.037050308342266934, 'approx_kl': 0.012551479434478097, 'clip_fraction': 0.03125, 'grad_norm': 3.210167169570923}
2022-12-29 12:03:28.431 DEBUG: Taking gradient step
2022-12-29 12:03:28.444 DEBUG: Loss 4: {'policy_loss': -0.03954215672230939, 'entropy_loss': -0.024052706081420183, 'vf_loss': 6.736156141745064e-05, 'total_loss': -0.06352750124231211, 'approx_kl': 0.03274153498932719, 'clip_fraction': 0.041666666977107525, 'grad_norm': 3.8991334438323975}
2022-12-29 12:03:29.192 DEBUG: Early stopping at step 5 for reaching max KL.
2022-12-29 12:03:29.193 INFO: Optimization: policy loss=-0.040, vf loss=0.000, entropy loss=-0.024, total loss=-0.064, num steps=5
2022-12-29 12:03:29.193 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:03:29.899 INFO: Evaluation rollout: return=0.503 (0.0), episode length=3.0
2022-12-29 12:03:29.899 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:03:29.901 INFO: Iteration: 37/137, steps: 7992
2022-12-29 12:03:51.634 DEBUG: Atoms are too close
2022-12-29 12:04:01.629 DEBUG: Atoms are too close
2022-12-29 12:04:08.364 DEBUG: Atoms are too close
2022-12-29 12:04:14.798 DEBUG: Atoms are too close
2022-12-29 12:04:17.508 INFO: Training rollout: return=-0.672 (4.6), episode length=3.0
2022-12-29 12:04:17.510 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:04:17.512 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-7992_train.pkl
2022-12-29 12:04:18.243 DEBUG: Taking gradient step
2022-12-29 12:04:18.252 DEBUG: Loss 0: {'policy_loss': -0.011632866511888666, 'entropy_loss': -0.022873738780617714, 'vf_loss': 0.021496548199318316, 'total_loss': -0.013010057093188067, 'approx_kl': 1.1253481257966769e-08, 'clip_fraction': 0.0, 'grad_norm': 24.01609992980957}
2022-12-29 12:04:19.011 DEBUG: Taking gradient step
2022-12-29 12:04:19.020 DEBUG: Loss 1: {'policy_loss': -0.00038797271691528093, 'entropy_loss': -0.02410422684624791, 'vf_loss': 0.021608632220228213, 'total_loss': -0.002883567342934979, 'approx_kl': 0.0020922478870488703, 'clip_fraction': 0.00390625, 'grad_norm': 32.914546966552734}
2022-12-29 12:04:19.788 DEBUG: Taking gradient step
2022-12-29 12:04:19.797 DEBUG: Loss 2: {'policy_loss': -0.003960982375260805, 'entropy_loss': -0.02487487904727459, 'vf_loss': 0.02152877635873752, 'total_loss': -0.007307085063797868, 'approx_kl': 0.007120588212274015, 'clip_fraction': 0.05989583395421505, 'grad_norm': 24.21741485595703}
2022-12-29 12:04:20.488 DEBUG: Taking gradient step
2022-12-29 12:04:20.499 DEBUG: Loss 3: {'policy_loss': 0.010478937449789234, 'entropy_loss': -0.024357651360332966, 'vf_loss': 0.024268262994399672, 'total_loss': 0.010389549083855941, 'approx_kl': 0.02217154367826879, 'clip_fraction': 0.1341145858168602, 'grad_norm': 27.868581771850586}
2022-12-29 12:04:21.231 DEBUG: Taking gradient step
2022-12-29 12:04:21.240 DEBUG: Loss 4: {'policy_loss': -0.04335792749054311, 'entropy_loss': -0.02489380957558751, 'vf_loss': 0.018977818825151666, 'total_loss': -0.04927391824097895, 'approx_kl': 0.031373852281831205, 'clip_fraction': 0.2356770858168602, 'grad_norm': 4.908588886260986}
2022-12-29 12:04:21.927 DEBUG: Taking gradient step
2022-12-29 12:04:21.937 DEBUG: Loss 5: {'policy_loss': 0.005500363613741222, 'entropy_loss': -0.023246765602380037, 'vf_loss': 0.02425111786974527, 'total_loss': 0.006504715881106456, 'approx_kl': 0.023126817541196942, 'clip_fraction': 0.2486979179084301, 'grad_norm': 4.230988025665283}
2022-12-29 12:04:22.636 DEBUG: Taking gradient step
2022-12-29 12:04:22.645 DEBUG: Loss 6: {'policy_loss': 0.0026609318075116253, 'entropy_loss': -0.024203477427363396, 'vf_loss': 0.024341128209838234, 'total_loss': 0.0027985825899864564, 'approx_kl': 0.027183644473552704, 'clip_fraction': 0.3020833432674408, 'grad_norm': 3.5582430362701416}
2022-12-29 12:04:23.341 DEBUG: Taking gradient step
2022-12-29 12:04:23.351 DEBUG: Loss 7: {'policy_loss': 0.0606773260701462, 'entropy_loss': -0.023692058864980936, 'vf_loss': 0.02938118942032018, 'total_loss': 0.06636645662548545, 'approx_kl': 0.013817576924338937, 'clip_fraction': 0.203125, 'grad_norm': 3.220337390899658}
2022-12-29 12:04:24.034 DEBUG: Taking gradient step
2022-12-29 12:04:24.043 DEBUG: Loss 8: {'policy_loss': -0.026817143475877138, 'entropy_loss': -0.023792176507413387, 'vf_loss': 0.021581069077119854, 'total_loss': -0.029028250906170675, 'approx_kl': 0.013534401310607791, 'clip_fraction': 0.1315104179084301, 'grad_norm': 2.1250317096710205}
2022-12-29 12:04:24.745 DEBUG: Taking gradient step
2022-12-29 12:04:24.754 DEBUG: Loss 9: {'policy_loss': -0.05274393790435398, 'entropy_loss': -0.024221367202699184, 'vf_loss': 0.01885735556635659, 'total_loss': -0.05810794954069658, 'approx_kl': -0.001839787932112813, 'clip_fraction': 0.1171875, 'grad_norm': 1.6322956085205078}
2022-12-29 12:04:24.754 INFO: Optimization: policy loss=-0.053, vf loss=0.019, entropy loss=-0.024, total loss=-0.058, num steps=10
2022-12-29 12:04:24.755 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:04:25.403 INFO: Evaluation rollout: return=0.506 (0.0), episode length=3.0
2022-12-29 12:04:25.404 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:04:25.405 INFO: Iteration: 38/137, steps: 8208
2022-12-29 12:04:37.083 DEBUG: Atoms are too close
2022-12-29 12:04:56.221 DEBUG: Atoms are too close
2022-12-29 12:04:56.818 DEBUG: Atoms are too close
2022-12-29 12:04:57.079 DEBUG: Atoms are too close
2022-12-29 12:05:13.700 INFO: Training rollout: return=-0.667 (4.6), episode length=3.0
2022-12-29 12:05:13.701 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:05:13.704 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-8208_train.pkl
2022-12-29 12:05:14.432 DEBUG: Taking gradient step
2022-12-29 12:05:14.443 DEBUG: Loss 0: {'policy_loss': -0.03645424442350854, 'entropy_loss': -0.02420308953151107, 'vf_loss': 0.01728600337142589, 'total_loss': -0.04337133058359371, 'approx_kl': -3.2848523900952387e-08, 'clip_fraction': 0.0, 'grad_norm': 17.132047653198242}
2022-12-29 12:05:15.164 DEBUG: Taking gradient step
2022-12-29 12:05:15.173 DEBUG: Loss 1: {'policy_loss': 0.03185846126925611, 'entropy_loss': -0.023476083297282457, 'vf_loss': 0.022448462633863644, 'total_loss': 0.030830840605837302, 'approx_kl': -0.0021380108664743602, 'clip_fraction': 0.015625, 'grad_norm': 21.764741897583008}
2022-12-29 12:05:15.885 DEBUG: Taking gradient step
2022-12-29 12:05:15.894 DEBUG: Loss 2: {'policy_loss': -0.03045665231950153, 'entropy_loss': -0.023539516609162092, 'vf_loss': 0.01721353490026439, 'total_loss': -0.03678263402839922, 'approx_kl': 0.004389205714687705, 'clip_fraction': 0.057291666977107525, 'grad_norm': 18.737043380737305}
2022-12-29 12:05:16.597 DEBUG: Taking gradient step
2022-12-29 12:05:16.607 DEBUG: Loss 3: {'policy_loss': -0.03726628062136096, 'entropy_loss': -0.024323172867298126, 'vf_loss': 0.01717740810476264, 'total_loss': -0.04441204538389644, 'approx_kl': 0.004385475185699761, 'clip_fraction': 0.07942708395421505, 'grad_norm': 17.1445369720459}
2022-12-29 12:05:17.311 DEBUG: Taking gradient step
2022-12-29 12:05:17.321 DEBUG: Loss 4: {'policy_loss': 0.04131295386799992, 'entropy_loss': -0.02398949535563588, 'vf_loss': 0.024848423557132307, 'total_loss': 0.04217188206949634, 'approx_kl': 0.017161008901894093, 'clip_fraction': 0.15625, 'grad_norm': 3.8788082599639893}
2022-12-29 12:05:18.013 DEBUG: Taking gradient step
2022-12-29 12:05:18.023 DEBUG: Loss 5: {'policy_loss': -0.018602705781395373, 'entropy_loss': -0.02376258885487914, 'vf_loss': 0.01969571478819208, 'total_loss': -0.022669579848082433, 'approx_kl': 0.02395426668226719, 'clip_fraction': 0.1705729179084301, 'grad_norm': 4.250612735748291}
2022-12-29 12:05:18.719 DEBUG: Taking gradient step
2022-12-29 12:05:18.728 DEBUG: Loss 6: {'policy_loss': -0.02130741942262033, 'entropy_loss': -0.024025357328355312, 'vf_loss': 0.01965967636865397, 'total_loss': -0.02567310038232167, 'approx_kl': 0.036836212035268545, 'clip_fraction': 0.19921875, 'grad_norm': 3.8528149127960205}
2022-12-29 12:05:19.432 DEBUG: Taking gradient step
2022-12-29 12:05:19.442 DEBUG: Loss 7: {'policy_loss': -0.00048004495165716865, 'entropy_loss': -0.024207602720707655, 'vf_loss': 0.02217285130337439, 'total_loss': -0.002514796368990435, 'approx_kl': 0.039167491253465414, 'clip_fraction': 0.2330729216337204, 'grad_norm': 3.0227043628692627}
2022-12-29 12:05:20.178 DEBUG: Taking gradient step
2022-12-29 12:05:20.187 DEBUG: Loss 8: {'policy_loss': -0.023511966740700482, 'entropy_loss': -0.024136225692927837, 'vf_loss': 0.019636442868408228, 'total_loss': -0.02801174956522009, 'approx_kl': 0.03669411258306354, 'clip_fraction': 0.265625, 'grad_norm': 3.164659023284912}
2022-12-29 12:05:20.902 DEBUG: Early stopping at step 9 for reaching max KL.
2022-12-29 12:05:20.902 INFO: Optimization: policy loss=-0.024, vf loss=0.020, entropy loss=-0.024, total loss=-0.028, num steps=9
2022-12-29 12:05:20.903 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:05:21.672 INFO: Evaluation rollout: return=0.500 (0.0), episode length=3.0
2022-12-29 12:05:21.673 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:05:21.675 INFO: Iteration: 39/137, steps: 8424
2022-12-29 12:05:51.486 DEBUG: Atoms are too close
2022-12-29 12:06:10.117 INFO: Training rollout: return=0.169 (2.4), episode length=3.0
2022-12-29 12:06:10.119 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:06:10.121 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-8424_train.pkl
2022-12-29 12:06:10.835 DEBUG: Taking gradient step
2022-12-29 12:06:10.844 DEBUG: Loss 0: {'policy_loss': -0.018043127711533342, 'entropy_loss': -0.02426189510151744, 'vf_loss': 0.0047804611860423835, 'total_loss': -0.03752456162700839, 'approx_kl': -3.880511023623967e-09, 'clip_fraction': 0.0, 'grad_norm': 16.295578002929688}
2022-12-29 12:06:11.544 DEBUG: Taking gradient step
2022-12-29 12:06:11.554 DEBUG: Loss 1: {'policy_loss': -0.023452965285179136, 'entropy_loss': -0.024499686434864998, 'vf_loss': 0.004796219110270994, 'total_loss': -0.043156432609773136, 'approx_kl': -0.0012754661729559302, 'clip_fraction': 0.053385416977107525, 'grad_norm': 14.09635066986084}
2022-12-29 12:06:12.251 DEBUG: Taking gradient step
2022-12-29 12:06:12.260 DEBUG: Loss 2: {'policy_loss': 0.022053173842573652, 'entropy_loss': -0.023574303835630417, 'vf_loss': 0.007266945347606365, 'total_loss': 0.005745815354549606, 'approx_kl': 0.003297005081549287, 'clip_fraction': 0.16927083395421505, 'grad_norm': 10.85962963104248}
2022-12-29 12:06:13.004 DEBUG: Taking gradient step
2022-12-29 12:06:13.017 DEBUG: Loss 3: {'policy_loss': -0.02812950951714283, 'entropy_loss': -0.02365971775725484, 'vf_loss': 0.004833778288948554, 'total_loss': -0.046955448985449115, 'approx_kl': 0.010462267557159066, 'clip_fraction': 0.23046875, 'grad_norm': 2.173410654067993}
2022-12-29 12:06:13.770 DEBUG: Taking gradient step
2022-12-29 12:06:13.780 DEBUG: Loss 4: {'policy_loss': -0.0259548724547881, 'entropy_loss': -0.02435458917170763, 'vf_loss': 0.004842762864826225, 'total_loss': -0.0454666987616695, 'approx_kl': 0.022653910098597407, 'clip_fraction': 0.2864583358168602, 'grad_norm': 2.173959732055664}
2022-12-29 12:06:14.466 DEBUG: Taking gradient step
2022-12-29 12:06:14.475 DEBUG: Loss 5: {'policy_loss': 0.01686961969372784, 'entropy_loss': -0.024411289487034082, 'vf_loss': 0.007329070524111372, 'total_loss': -0.00021259926919487554, 'approx_kl': 0.009442872600629926, 'clip_fraction': 0.3020833358168602, 'grad_norm': 1.893950343132019}
2022-12-29 12:06:15.176 DEBUG: Taking gradient step
2022-12-29 12:06:15.186 DEBUG: Loss 6: {'policy_loss': -0.025599793904197886, 'entropy_loss': -0.025034713093191385, 'vf_loss': 0.004852989946275009, 'total_loss': -0.04578151705111426, 'approx_kl': 0.024736535968258977, 'clip_fraction': 0.3059895858168602, 'grad_norm': 2.2337076663970947}
2022-12-29 12:06:15.888 DEBUG: Taking gradient step
2022-12-29 12:06:15.897 DEBUG: Loss 7: {'policy_loss': -0.02901342204897973, 'entropy_loss': -0.024538015481084585, 'vf_loss': 0.00485110574127438, 'total_loss': -0.048700331788789936, 'approx_kl': -0.009556777542456985, 'clip_fraction': 0.2395833358168602, 'grad_norm': 1.2319332361221313}
2022-12-29 12:06:16.589 DEBUG: Taking gradient step
2022-12-29 12:06:16.598 DEBUG: Loss 8: {'policy_loss': -0.028447694727598786, 'entropy_loss': -0.024552051909267902, 'vf_loss': 0.004845904851177447, 'total_loss': -0.04815384178568924, 'approx_kl': 0.003135223698336631, 'clip_fraction': 0.1731770858168602, 'grad_norm': 1.0043500661849976}
2022-12-29 12:06:17.367 DEBUG: Taking gradient step
2022-12-29 12:06:17.377 DEBUG: Loss 9: {'policy_loss': 0.013924518410418502, 'entropy_loss': -0.02397681074216962, 'vf_loss': 0.007277110713855708, 'total_loss': -0.00277518161789541, 'approx_kl': 0.006133172428235412, 'clip_fraction': 0.19140625, 'grad_norm': 1.4531227350234985}
2022-12-29 12:06:17.377 INFO: Optimization: policy loss=0.014, vf loss=0.007, entropy loss=-0.024, total loss=-0.003, num steps=10
2022-12-29 12:06:17.377 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:06:18.121 INFO: Evaluation rollout: return=0.499 (0.0), episode length=3.0
2022-12-29 12:06:18.122 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:06:18.124 INFO: Iteration: 40/137, steps: 8640
2022-12-29 12:07:06.645 INFO: Training rollout: return=0.447 (0.0), episode length=3.0
2022-12-29 12:07:06.646 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:07:06.648 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-8640_train.pkl
2022-12-29 12:07:07.371 DEBUG: Taking gradient step
2022-12-29 12:07:07.381 DEBUG: Loss 0: {'policy_loss': 0.004564286046391489, 'entropy_loss': -0.024138519074767828, 'vf_loss': 0.00033881870013806206, 'total_loss': -0.019235414328238276, 'approx_kl': -4.8157138277105105e-08, 'clip_fraction': 0.0, 'grad_norm': 4.531121730804443}
2022-12-29 12:07:08.067 DEBUG: Taking gradient step
2022-12-29 12:07:08.076 DEBUG: Loss 1: {'policy_loss': 0.021505140919422537, 'entropy_loss': -0.024069274310022593, 'vf_loss': 0.0003144407517869138, 'total_loss': -0.002249692638813146, 'approx_kl': -0.003358916612342, 'clip_fraction': 0.018229166977107525, 'grad_norm': 3.250575065612793}
2022-12-29 12:07:08.775 DEBUG: Taking gradient step
2022-12-29 12:07:08.784 DEBUG: Loss 2: {'policy_loss': -0.006822206633997998, 'entropy_loss': -0.02383220801129937, 'vf_loss': 0.0002983649568061077, 'total_loss': -0.03035604968849126, 'approx_kl': 0.015604403335601091, 'clip_fraction': 0.15234375, 'grad_norm': 8.098240852355957}
2022-12-29 12:07:09.509 DEBUG: Taking gradient step
2022-12-29 12:07:09.518 DEBUG: Loss 3: {'policy_loss': 0.016273845348983264, 'entropy_loss': -0.0236001661978662, 'vf_loss': 0.0002731515239655602, 'total_loss': -0.007053169324917379, 'approx_kl': 0.018812970025464892, 'clip_fraction': 0.22265625, 'grad_norm': 8.699413299560547}
2022-12-29 12:07:10.226 DEBUG: Taking gradient step
2022-12-29 12:07:10.236 DEBUG: Loss 4: {'policy_loss': 0.00713542529444321, 'entropy_loss': -0.022571630775928497, 'vf_loss': 0.0002583443148636731, 'total_loss': -0.015177861166621611, 'approx_kl': 0.019208320882171392, 'clip_fraction': 0.25911458395421505, 'grad_norm': 8.717615127563477}
2022-12-29 12:07:10.943 DEBUG: Taking gradient step
2022-12-29 12:07:10.952 DEBUG: Loss 5: {'policy_loss': -0.0025022426934717904, 'entropy_loss': -0.02260114811360836, 'vf_loss': 0.00023944376895712767, 'total_loss': -0.024863947038123023, 'approx_kl': 0.01853168336674571, 'clip_fraction': 0.29296875, 'grad_norm': 8.222548484802246}
2022-12-29 12:07:11.644 DEBUG: Taking gradient step
2022-12-29 12:07:11.653 DEBUG: Loss 6: {'policy_loss': 0.008897784217901699, 'entropy_loss': -0.023236730135977268, 'vf_loss': 0.0002212710228856725, 'total_loss': -0.014117674895189898, 'approx_kl': 0.028987403959035873, 'clip_fraction': 0.2825520858168602, 'grad_norm': 8.680845260620117}
2022-12-29 12:07:12.386 DEBUG: Taking gradient step
2022-12-29 12:07:12.396 DEBUG: Loss 7: {'policy_loss': 0.015972430021449484, 'entropy_loss': -0.02293440280482173, 'vf_loss': 0.00020730490522254585, 'total_loss': -0.006754667878149677, 'approx_kl': 0.016129648312926292, 'clip_fraction': 0.2877604216337204, 'grad_norm': 10.826639175415039}
2022-12-29 12:07:13.097 DEBUG: Taking gradient step
2022-12-29 12:07:13.106 DEBUG: Loss 8: {'policy_loss': 0.01706335614362824, 'entropy_loss': -0.021620068699121475, 'vf_loss': 0.00019559233262127885, 'total_loss': -0.00436112022287196, 'approx_kl': 0.013533906312659383, 'clip_fraction': 0.2760416716337204, 'grad_norm': 8.575862884521484}
2022-12-29 12:07:13.834 DEBUG: Taking gradient step
2022-12-29 12:07:13.848 DEBUG: Loss 9: {'policy_loss': 0.03236728897379865, 'entropy_loss': -0.02199647668749094, 'vf_loss': 0.00018622973641289507, 'total_loss': 0.010557042022720599, 'approx_kl': 0.0016280009876936674, 'clip_fraction': 0.2135416679084301, 'grad_norm': 3.2667877674102783}
2022-12-29 12:07:13.848 INFO: Optimization: policy loss=0.032, vf loss=0.000, entropy loss=-0.022, total loss=0.011, num steps=10
2022-12-29 12:07:13.849 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:07:14.615 INFO: Evaluation rollout: return=0.500 (0.0), episode length=3.0
2022-12-29 12:07:14.616 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:07:14.619 DEBUG: Deleting old model: runs/H2O/models/H2O_run-1_steps-6696.model
2022-12-29 12:07:14.623 DEBUG: Saving model: runs/H2O/models/H2O_run-1_steps-8856.model
2022-12-29 12:07:14.653 INFO: Iteration: 41/137, steps: 8856
2022-12-29 12:08:02.400 INFO: Training rollout: return=0.465 (0.0), episode length=3.0
2022-12-29 12:08:02.402 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:08:02.404 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-8856_train.pkl
2022-12-29 12:08:03.118 DEBUG: Taking gradient step
2022-12-29 12:08:03.128 DEBUG: Loss 0: {'policy_loss': 0.02537754611694914, 'entropy_loss': -0.02146750409156084, 'vf_loss': 0.00018044081706389503, 'total_loss': 0.004090482842452191, 'approx_kl': -1.435789087622652e-08, 'clip_fraction': 0.0, 'grad_norm': 13.872101783752441}
2022-12-29 12:08:03.822 DEBUG: Taking gradient step
2022-12-29 12:08:03.832 DEBUG: Loss 1: {'policy_loss': 0.031079956477993262, 'entropy_loss': -0.02165301190689206, 'vf_loss': 0.00016894260110412594, 'total_loss': 0.009595887172205324, 'approx_kl': -0.005655599059537053, 'clip_fraction': 0.03125, 'grad_norm': 9.616286277770996}
2022-12-29 12:08:04.532 DEBUG: Taking gradient step
2022-12-29 12:08:04.541 DEBUG: Loss 2: {'policy_loss': 0.003836960232426771, 'entropy_loss': -0.020820654928684235, 'vf_loss': 0.0001603836456203455, 'total_loss': -0.016823311050637113, 'approx_kl': 0.0033265604870393872, 'clip_fraction': 0.13020833395421505, 'grad_norm': 9.42626953125}
2022-12-29 12:08:05.238 DEBUG: Taking gradient step
2022-12-29 12:08:05.247 DEBUG: Loss 3: {'policy_loss': -0.02373334787622879, 'entropy_loss': -0.02044155914336443, 'vf_loss': 0.00015308969928356155, 'total_loss': -0.04402181732030966, 'approx_kl': -0.0047792859841138124, 'clip_fraction': 0.1783854179084301, 'grad_norm': 11.134821891784668}
2022-12-29 12:08:05.940 DEBUG: Taking gradient step
2022-12-29 12:08:05.949 DEBUG: Loss 4: {'policy_loss': 0.04929396197375623, 'entropy_loss': -0.02109050052240491, 'vf_loss': 0.00014053216481410915, 'total_loss': 0.028343993616165436, 'approx_kl': 0.007196267135441303, 'clip_fraction': 0.1940104179084301, 'grad_norm': 9.642721176147461}
2022-12-29 12:08:06.676 DEBUG: Taking gradient step
2022-12-29 12:08:06.686 DEBUG: Loss 5: {'policy_loss': -0.05590532437481238, 'entropy_loss': -0.020982046611607075, 'vf_loss': 0.00014204725251261375, 'total_loss': -0.07674532373390686, 'approx_kl': -0.002434689551591873, 'clip_fraction': 0.1979166679084301, 'grad_norm': 11.305685043334961}
2022-12-29 12:08:07.389 DEBUG: Taking gradient step
2022-12-29 12:08:07.398 DEBUG: Loss 6: {'policy_loss': -0.004957042450055521, 'entropy_loss': -0.02067401632666588, 'vf_loss': 0.00012955057367336714, 'total_loss': -0.025501508203048036, 'approx_kl': 0.011748303310014307, 'clip_fraction': 0.17317708395421505, 'grad_norm': 9.329593658447266}
2022-12-29 12:08:08.088 DEBUG: Taking gradient step
2022-12-29 12:08:08.097 DEBUG: Loss 7: {'policy_loss': -0.03399707418317313, 'entropy_loss': -0.02039755927398801, 'vf_loss': 0.00012586940388127437, 'total_loss': -0.05426876405327987, 'approx_kl': 0.010407174471765757, 'clip_fraction': 0.22265625, 'grad_norm': 4.833805084228516}
2022-12-29 12:08:08.830 DEBUG: Taking gradient step
2022-12-29 12:08:08.839 DEBUG: Loss 8: {'policy_loss': 0.011591413479891101, 'entropy_loss': -0.02116819517686963, 'vf_loss': 0.00011660185682987165, 'total_loss': -0.009460179840148651, 'approx_kl': 0.015401601791381836, 'clip_fraction': 0.2513020858168602, 'grad_norm': 8.372695922851562}
2022-12-29 12:08:09.521 DEBUG: Taking gradient step
2022-12-29 12:08:09.530 DEBUG: Loss 9: {'policy_loss': -0.007592817670637828, 'entropy_loss': -0.020151127595454454, 'vf_loss': 0.00011169769885894456, 'total_loss': -0.02763224756723334, 'approx_kl': 0.030759960412979126, 'clip_fraction': 0.2786458358168602, 'grad_norm': 6.679692268371582}
2022-12-29 12:08:09.530 INFO: Optimization: policy loss=-0.008, vf loss=0.000, entropy loss=-0.020, total loss=-0.028, num steps=10
2022-12-29 12:08:09.531 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:08:10.273 INFO: Evaluation rollout: return=0.506 (0.0), episode length=3.0
2022-12-29 12:08:10.274 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:08:10.275 INFO: Iteration: 42/137, steps: 9072
2022-12-29 12:08:58.440 INFO: Training rollout: return=0.467 (0.0), episode length=3.0
2022-12-29 12:08:58.442 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:08:58.445 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-9072_train.pkl
2022-12-29 12:08:59.172 DEBUG: Taking gradient step
2022-12-29 12:08:59.182 DEBUG: Loss 0: {'policy_loss': 0.007946605294397752, 'entropy_loss': -0.020970559678971767, 'vf_loss': 0.0001133386533865173, 'total_loss': -0.012910615731187507, 'approx_kl': -2.9045622795820236e-08, 'clip_fraction': 0.0, 'grad_norm': 15.41305923461914}
2022-12-29 12:08:59.894 DEBUG: Taking gradient step
2022-12-29 12:08:59.909 DEBUG: Loss 1: {'policy_loss': -0.007493016674421007, 'entropy_loss': -0.020729240495711565, 'vf_loss': 0.00010858274613087957, 'total_loss': -0.028113674424001693, 'approx_kl': 0.0030560572049580514, 'clip_fraction': 0.0, 'grad_norm': 15.635355949401855}
2022-12-29 12:09:00.614 DEBUG: Taking gradient step
2022-12-29 12:09:00.623 DEBUG: Loss 2: {'policy_loss': -0.06255767352152915, 'entropy_loss': -0.02068679826334119, 'vf_loss': 0.00010858043599185123, 'total_loss': -0.0831358913488785, 'approx_kl': 0.005652564577758312, 'clip_fraction': 0.061197916977107525, 'grad_norm': 6.135820388793945}
2022-12-29 12:09:01.357 DEBUG: Taking gradient step
2022-12-29 12:09:01.371 DEBUG: Loss 3: {'policy_loss': 0.011586673348238173, 'entropy_loss': -0.020048320293426514, 'vf_loss': 9.890180951323762e-05, 'total_loss': -0.008362745135675101, 'approx_kl': 0.01639049593359232, 'clip_fraction': 0.203125, 'grad_norm': 7.913151264190674}
2022-12-29 12:09:02.073 DEBUG: Taking gradient step
2022-12-29 12:09:02.083 DEBUG: Loss 4: {'policy_loss': 0.0047096767950532414, 'entropy_loss': -0.020570392720401287, 'vf_loss': 9.650049646517275e-05, 'total_loss': -0.015764215428882872, 'approx_kl': 0.026480513159185648, 'clip_fraction': 0.2825520858168602, 'grad_norm': 13.620558738708496}
2022-12-29 12:09:02.792 DEBUG: Taking gradient step
2022-12-29 12:09:02.802 DEBUG: Loss 5: {'policy_loss': 0.02183340607999394, 'entropy_loss': -0.021293275523930788, 'vf_loss': 9.276469224005565e-05, 'total_loss': 0.0006328952483032058, 'approx_kl': 0.030411530286073685, 'clip_fraction': 0.3203125, 'grad_norm': 8.835813522338867}
2022-12-29 12:09:03.509 DEBUG: Taking gradient step
2022-12-29 12:09:03.518 DEBUG: Loss 6: {'policy_loss': -0.030281262604061544, 'entropy_loss': -0.020267562940716743, 'vf_loss': 9.304583003230427e-05, 'total_loss': -0.05045577971474599, 'approx_kl': 0.0305598103441298, 'clip_fraction': 0.3216145858168602, 'grad_norm': 8.288674354553223}
2022-12-29 12:09:04.208 DEBUG: Taking gradient step
2022-12-29 12:09:04.217 DEBUG: Loss 7: {'policy_loss': -0.023771140952165377, 'entropy_loss': -0.020637068431824446, 'vf_loss': 9.05461647241986e-05, 'total_loss': -0.04431766321926563, 'approx_kl': 0.017448630183935165, 'clip_fraction': 0.2721354179084301, 'grad_norm': 8.279073715209961}
2022-12-29 12:09:04.945 DEBUG: Taking gradient step
2022-12-29 12:09:04.953 DEBUG: Loss 8: {'policy_loss': -0.016712015005013646, 'entropy_loss': -0.019817159045487642, 'vf_loss': 8.713774524649947e-05, 'total_loss': -0.03644203630525479, 'approx_kl': 0.015443269978277385, 'clip_fraction': 0.2799479216337204, 'grad_norm': 7.725502014160156}
2022-12-29 12:09:05.672 DEBUG: Taking gradient step
2022-12-29 12:09:05.681 DEBUG: Loss 9: {'policy_loss': -0.04157844746685698, 'entropy_loss': -0.019603478722274303, 'vf_loss': 8.639295714788441e-05, 'total_loss': -0.0610955332319834, 'approx_kl': 0.014325080206617713, 'clip_fraction': 0.2200520858168602, 'grad_norm': 8.125539779663086}
2022-12-29 12:09:05.681 INFO: Optimization: policy loss=-0.042, vf loss=0.000, entropy loss=-0.020, total loss=-0.061, num steps=10
2022-12-29 12:09:05.682 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:09:06.343 INFO: Evaluation rollout: return=0.503 (0.0), episode length=3.0
2022-12-29 12:09:06.343 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:09:06.345 INFO: Iteration: 43/137, steps: 9288
2022-12-29 12:09:55.141 INFO: Training rollout: return=0.469 (0.0), episode length=3.0
2022-12-29 12:09:55.143 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:09:55.146 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-9288_train.pkl
2022-12-29 12:09:55.896 DEBUG: Taking gradient step
2022-12-29 12:09:55.905 DEBUG: Loss 0: {'policy_loss': -0.022058317550726868, 'entropy_loss': -0.02021648082882166, 'vf_loss': 8.99202213395725e-05, 'total_loss': -0.042184878158208955, 'approx_kl': 1.4435499906539917e-08, 'clip_fraction': 0.0, 'grad_norm': 9.128338813781738}
2022-12-29 12:09:56.608 DEBUG: Taking gradient step
2022-12-29 12:09:56.618 DEBUG: Loss 1: {'policy_loss': 0.0009235530117994734, 'entropy_loss': -0.020694970153272152, 'vf_loss': 8.498769757000693e-05, 'total_loss': -0.01968642944390267, 'approx_kl': 0.008005785231944174, 'clip_fraction': 0.00390625, 'grad_norm': 6.190992832183838}
2022-12-29 12:09:57.354 DEBUG: Taking gradient step
2022-12-29 12:09:57.363 DEBUG: Loss 2: {'policy_loss': -0.022147719904088585, 'entropy_loss': -0.020296429749578238, 'vf_loss': 8.394344299869093e-05, 'total_loss': -0.04236020621066813, 'approx_kl': 0.019831199664622545, 'clip_fraction': 0.0859375, 'grad_norm': 2.5300629138946533}
2022-12-29 12:09:58.092 DEBUG: Taking gradient step
2022-12-29 12:09:58.103 DEBUG: Loss 3: {'policy_loss': -0.033869190222057546, 'entropy_loss': -0.02134416764602065, 'vf_loss': 8.276547067149808e-05, 'total_loss': -0.0551305923974067, 'approx_kl': 0.0356279534753412, 'clip_fraction': 0.2578125, 'grad_norm': 10.378883361816406}
2022-12-29 12:09:58.840 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-29 12:09:58.840 INFO: Optimization: policy loss=-0.034, vf loss=0.000, entropy loss=-0.021, total loss=-0.055, num steps=4
2022-12-29 12:09:58.840 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:09:59.499 INFO: Evaluation rollout: return=0.510 (0.0), episode length=3.0
2022-12-29 12:09:59.500 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:09:59.501 INFO: Iteration: 44/137, steps: 9504
2022-12-29 12:10:37.965 DEBUG: Atoms are too close
2022-12-29 12:10:48.174 INFO: Training rollout: return=0.166 (2.4), episode length=3.0
2022-12-29 12:10:48.176 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:10:48.178 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-9504_train.pkl
2022-12-29 12:10:48.895 DEBUG: Taking gradient step
2022-12-29 12:10:48.904 DEBUG: Loss 0: {'policy_loss': -0.017487628973035782, 'entropy_loss': -0.021813228726387024, 'vf_loss': 0.004774752895519966, 'total_loss': -0.03452610480390284, 'approx_kl': 1.3581786806327045e-09, 'clip_fraction': 0.0, 'grad_norm': 4.731837272644043}
2022-12-29 12:10:49.609 DEBUG: Taking gradient step
2022-12-29 12:10:49.618 DEBUG: Loss 1: {'policy_loss': 0.09497810746294708, 'entropy_loss': -0.02100081881508231, 'vf_loss': 0.010047413433174286, 'total_loss': 0.08402470208103907, 'approx_kl': -0.00271091127069667, 'clip_fraction': 0.010416666977107525, 'grad_norm': 13.020707130432129}
2022-12-29 12:10:50.320 DEBUG: Taking gradient step
2022-12-29 12:10:50.332 DEBUG: Loss 2: {'policy_loss': -0.02038010967581308, 'entropy_loss': -0.02194255543872714, 'vf_loss': 0.004777043501863783, 'total_loss': -0.03754562161267643, 'approx_kl': 0.0003128575626760721, 'clip_fraction': 0.0234375, 'grad_norm': 4.9907660484313965}
2022-12-29 12:10:51.060 DEBUG: Taking gradient step
2022-12-29 12:10:51.069 DEBUG: Loss 3: {'policy_loss': 0.029915554702050862, 'entropy_loss': -0.021677397657185793, 'vf_loss': 0.007376469190500321, 'total_loss': 0.015614626235365386, 'approx_kl': -0.002388611261267215, 'clip_fraction': 0.061197916977107525, 'grad_norm': 1.7286107540130615}
2022-12-29 12:10:51.768 DEBUG: Taking gradient step
2022-12-29 12:10:51.777 DEBUG: Loss 4: {'policy_loss': -0.02300429336944133, 'entropy_loss': -0.023628355469554663, 'vf_loss': 0.004775613721697633, 'total_loss': -0.041857035117298345, 'approx_kl': 0.004455912858247757, 'clip_fraction': 0.0885416679084301, 'grad_norm': 3.773798704147339}
2022-12-29 12:10:52.474 DEBUG: Taking gradient step
2022-12-29 12:10:52.483 DEBUG: Loss 5: {'policy_loss': 0.028876205166236277, 'entropy_loss': -0.0237316838465631, 'vf_loss': 0.007343221251967149, 'total_loss': 0.012487742571640328, 'approx_kl': 0.010515346308238804, 'clip_fraction': 0.109375, 'grad_norm': 2.8488245010375977}
2022-12-29 12:10:53.197 DEBUG: Taking gradient step
2022-12-29 12:10:53.206 DEBUG: Loss 6: {'policy_loss': -0.026614142943678212, 'entropy_loss': -0.02330886758863926, 'vf_loss': 0.004772401511688844, 'total_loss': -0.04515060902062863, 'approx_kl': 0.005433153826743364, 'clip_fraction': 0.1796875, 'grad_norm': 2.809093713760376}
2022-12-29 12:10:53.915 DEBUG: Taking gradient step
2022-12-29 12:10:53.924 DEBUG: Loss 7: {'policy_loss': 0.029848880688278314, 'entropy_loss': -0.023837596643716097, 'vf_loss': 0.0073630711430713956, 'total_loss': 0.0133743551876336, 'approx_kl': 0.02504280861467123, 'clip_fraction': 0.1888020858168602, 'grad_norm': 6.82765531539917}
2022-12-29 12:10:54.613 DEBUG: Taking gradient step
2022-12-29 12:10:54.623 DEBUG: Loss 8: {'policy_loss': -0.02459026611401696, 'entropy_loss': -0.02458884520456195, 'vf_loss': 0.004763930973130154, 'total_loss': -0.04441518034544876, 'approx_kl': 0.028574188239872456, 'clip_fraction': 0.2903645858168602, 'grad_norm': 2.1912906169891357}
2022-12-29 12:10:55.318 DEBUG: Taking gradient step
2022-12-29 12:10:55.328 DEBUG: Loss 9: {'policy_loss': -0.025278809997616773, 'entropy_loss': -0.024251515977084637, 'vf_loss': 0.004762605249240699, 'total_loss': -0.0447677207254607, 'approx_kl': 0.03478925861418247, 'clip_fraction': 0.2877604216337204, 'grad_norm': 4.1586689949035645}
2022-12-29 12:10:55.328 INFO: Optimization: policy loss=-0.025, vf loss=0.005, entropy loss=-0.024, total loss=-0.045, num steps=10
2022-12-29 12:10:55.328 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:10:56.014 INFO: Evaluation rollout: return=0.511 (0.0), episode length=3.0
2022-12-29 12:10:56.015 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:10:56.016 INFO: Iteration: 45/137, steps: 9720
2022-12-29 12:10:58.688 DEBUG: There is a single atom floating around
2022-12-29 12:11:02.771 DEBUG: There is a single atom floating around
2022-12-29 12:11:07.476 DEBUG: Atoms are too close
2022-12-29 12:11:09.366 DEBUG: There is a single atom floating around
2022-12-29 12:11:43.307 INFO: Training rollout: return=-0.681 (4.7), episode length=3.0
2022-12-29 12:11:43.308 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:11:43.311 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-9720_train.pkl
2022-12-29 12:11:44.045 DEBUG: Taking gradient step
2022-12-29 12:11:44.054 DEBUG: Loss 0: {'policy_loss': -0.004062677959138622, 'entropy_loss': -0.024067148566246033, 'vf_loss': 0.018429075985946692, 'total_loss': -0.009700750539437964, 'approx_kl': 1.9635383985416865e-08, 'clip_fraction': 0.0, 'grad_norm': 28.464332580566406}
2022-12-29 12:11:44.741 DEBUG: Taking gradient step
2022-12-29 12:11:44.750 DEBUG: Loss 1: {'policy_loss': 0.058008608979340334, 'entropy_loss': -0.02546686213463545, 'vf_loss': 0.023655161999929043, 'total_loss': 0.056196908844633936, 'approx_kl': 0.004251036967616528, 'clip_fraction': 0.0, 'grad_norm': 14.728099822998047}
2022-12-29 12:11:45.455 DEBUG: Taking gradient step
2022-12-29 12:11:45.471 DEBUG: Loss 2: {'policy_loss': -0.03934411573568147, 'entropy_loss': -0.02473738556727767, 'vf_loss': 0.01575575438819254, 'total_loss': -0.048325746914766605, 'approx_kl': 0.005164052359759808, 'clip_fraction': 0.06510416697710752, 'grad_norm': 2.597853899002075}
2022-12-29 12:11:46.189 DEBUG: Taking gradient step
2022-12-29 12:11:46.201 DEBUG: Loss 3: {'policy_loss': -0.03945197587215088, 'entropy_loss': -0.024225808680057526, 'vf_loss': 0.015745538611871848, 'total_loss': -0.04793224594033656, 'approx_kl': 0.011142725590616465, 'clip_fraction': 0.11067708395421505, 'grad_norm': 3.277150869369507}
2022-12-29 12:11:46.916 DEBUG: Taking gradient step
2022-12-29 12:11:46.925 DEBUG: Loss 4: {'policy_loss': -0.012190450062608106, 'entropy_loss': -0.024829173926264048, 'vf_loss': 0.018288695438298204, 'total_loss': -0.01873092855057395, 'approx_kl': 0.011136241490021348, 'clip_fraction': 0.1484375, 'grad_norm': 2.8188467025756836}
2022-12-29 12:11:47.647 DEBUG: Taking gradient step
2022-12-29 12:11:47.657 DEBUG: Loss 5: {'policy_loss': -0.041099720336426865, 'entropy_loss': -0.025054677855223417, 'vf_loss': 0.015712457198904704, 'total_loss': -0.05044194099274557, 'approx_kl': 0.023492602864280343, 'clip_fraction': 0.1875, 'grad_norm': 3.4206888675689697}
2022-12-29 12:11:48.388 DEBUG: Taking gradient step
2022-12-29 12:11:48.397 DEBUG: Loss 6: {'policy_loss': -0.04182884589312281, 'entropy_loss': -0.02595289284363389, 'vf_loss': 0.01568848056737619, 'total_loss': -0.052093258169380506, 'approx_kl': 0.005177641287446022, 'clip_fraction': 0.1979166716337204, 'grad_norm': 2.487295150756836}
2022-12-29 12:11:49.081 DEBUG: Taking gradient step
2022-12-29 12:11:49.090 DEBUG: Loss 7: {'policy_loss': 0.015209653318737935, 'entropy_loss': -0.0243107657879591, 'vf_loss': 0.020832359520314522, 'total_loss': 0.011731247051093359, 'approx_kl': -0.006029062904417515, 'clip_fraction': 0.1927083358168602, 'grad_norm': 2.581317663192749}
2022-12-29 12:11:49.790 DEBUG: Taking gradient step
2022-12-29 12:11:49.800 DEBUG: Loss 8: {'policy_loss': -0.013009593955506847, 'entropy_loss': -0.025027848314493895, 'vf_loss': 0.018164252755579063, 'total_loss': -0.01987318951442168, 'approx_kl': -0.0012224618840264156, 'clip_fraction': 0.1744791679084301, 'grad_norm': 2.977595806121826}
2022-12-29 12:11:50.560 DEBUG: Taking gradient step
2022-12-29 12:11:50.571 DEBUG: Loss 9: {'policy_loss': -0.04568957499779721, 'entropy_loss': -0.02487014140933752, 'vf_loss': 0.015622380330021059, 'total_loss': -0.05493733607711367, 'approx_kl': -0.006499099661596119, 'clip_fraction': 0.1549479179084301, 'grad_norm': 2.787257671356201}
2022-12-29 12:11:50.571 INFO: Optimization: policy loss=-0.046, vf loss=0.016, entropy loss=-0.025, total loss=-0.055, num steps=10
2022-12-29 12:11:50.572 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:11:51.304 INFO: Evaluation rollout: return=0.510 (0.0), episode length=3.0
2022-12-29 12:11:51.305 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:11:51.307 INFO: Iteration: 46/137, steps: 9936
2022-12-29 12:12:40.555 INFO: Training rollout: return=0.446 (0.1), episode length=3.0
2022-12-29 12:12:40.556 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:12:40.559 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-9936_train.pkl
2022-12-29 12:12:41.264 DEBUG: Taking gradient step
2022-12-29 12:12:41.274 DEBUG: Loss 0: {'policy_loss': 0.018927420869966332, 'entropy_loss': -0.02462966600432992, 'vf_loss': 0.00014221106085415223, 'total_loss': -0.005560034073509433, 'approx_kl': -1.552204320631745e-08, 'clip_fraction': 0.0, 'grad_norm': 12.414385795593262}
2022-12-29 12:12:41.969 DEBUG: Taking gradient step
2022-12-29 12:12:41.979 DEBUG: Loss 1: {'policy_loss': -0.04014339966660396, 'entropy_loss': -0.02404134627431631, 'vf_loss': 0.00016663309975980286, 'total_loss': -0.06401811284116046, 'approx_kl': -0.0029111781041137874, 'clip_fraction': 0.0, 'grad_norm': 14.72727108001709}
2022-12-29 12:12:42.732 DEBUG: Taking gradient step
2022-12-29 12:12:42.746 DEBUG: Loss 2: {'policy_loss': -0.05935718145927678, 'entropy_loss': -0.024284951388835907, 'vf_loss': 0.00018914139824839784, 'total_loss': -0.08345299144986429, 'approx_kl': -0.002617126563563943, 'clip_fraction': 0.0234375, 'grad_norm': 11.655632019042969}
2022-12-29 12:12:43.445 DEBUG: Taking gradient step
2022-12-29 12:12:43.454 DEBUG: Loss 3: {'policy_loss': -0.013352533154686416, 'entropy_loss': -0.02471811044961214, 'vf_loss': 0.00019498614380143633, 'total_loss': -0.03787565746049712, 'approx_kl': 0.003191877156496048, 'clip_fraction': 0.06380208395421505, 'grad_norm': 9.305436134338379}
2022-12-29 12:12:44.145 DEBUG: Taking gradient step
2022-12-29 12:12:44.155 DEBUG: Loss 4: {'policy_loss': -0.02014562878311721, 'entropy_loss': -0.02415561582893133, 'vf_loss': 0.0002078831083837299, 'total_loss': -0.0440933615036648, 'approx_kl': 0.009599609766155481, 'clip_fraction': 0.08333333395421505, 'grad_norm': 8.127747535705566}
2022-12-29 12:12:44.860 DEBUG: Taking gradient step
2022-12-29 12:12:44.869 DEBUG: Loss 5: {'policy_loss': 0.009580885416672381, 'entropy_loss': -0.025056288577616215, 'vf_loss': 0.00021949067647796062, 'total_loss': -0.015255912484465874, 'approx_kl': 0.015324002597481012, 'clip_fraction': 0.11848958395421505, 'grad_norm': 7.6885528564453125}
2022-12-29 12:12:45.572 DEBUG: Taking gradient step
2022-12-29 12:12:45.581 DEBUG: Loss 6: {'policy_loss': 0.042093848112790454, 'entropy_loss': -0.02441199030727148, 'vf_loss': 0.00022075353225207522, 'total_loss': 0.017902611337771046, 'approx_kl': 0.03008499019779265, 'clip_fraction': 0.1861979179084301, 'grad_norm': 7.311145782470703}
2022-12-29 12:12:46.317 DEBUG: Early stopping at step 7 for reaching max KL.
2022-12-29 12:12:46.317 INFO: Optimization: policy loss=0.042, vf loss=0.000, entropy loss=-0.024, total loss=0.018, num steps=7
2022-12-29 12:12:46.318 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:12:47.007 INFO: Evaluation rollout: return=0.510 (0.0), episode length=3.0
2022-12-29 12:12:47.008 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:12:47.011 INFO: Iteration: 47/137, steps: 10152
2022-12-29 12:13:36.374 INFO: Training rollout: return=0.455 (0.0), episode length=3.0
2022-12-29 12:13:36.376 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:13:36.378 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-10152_train.pkl
2022-12-29 12:13:37.097 DEBUG: Taking gradient step
2022-12-29 12:13:37.106 DEBUG: Loss 0: {'policy_loss': -0.0241357683174555, 'entropy_loss': -0.024314922280609608, 'vf_loss': 0.00024801536064810944, 'total_loss': -0.048202675237416996, 'approx_kl': -1.6220534249100638e-08, 'clip_fraction': 0.0, 'grad_norm': 6.46183967590332}
2022-12-29 12:13:37.803 DEBUG: Taking gradient step
2022-12-29 12:13:37.812 DEBUG: Loss 1: {'policy_loss': -0.027800481848867, 'entropy_loss': -0.023637878708541393, 'vf_loss': 0.00025384871829406885, 'total_loss': -0.05118451183911432, 'approx_kl': 0.007847882574424148, 'clip_fraction': 0.03125, 'grad_norm': 5.429346084594727}
2022-12-29 12:13:38.552 DEBUG: Taking gradient step
2022-12-29 12:13:38.566 DEBUG: Loss 2: {'policy_loss': 0.026146498296813026, 'entropy_loss': -0.024463971611112356, 'vf_loss': 0.0002464148884967246, 'total_loss': 0.0019289415741973945, 'approx_kl': 0.015073941089212894, 'clip_fraction': 0.12109375, 'grad_norm': 2.4060773849487305}
2022-12-29 12:13:39.344 DEBUG: Taking gradient step
2022-12-29 12:13:39.355 DEBUG: Loss 3: {'policy_loss': -0.00309109726160516, 'entropy_loss': -0.024653525091707706, 'vf_loss': 0.00024889724942407925, 'total_loss': -0.02749572510388879, 'approx_kl': 0.015091764042153955, 'clip_fraction': 0.1705729216337204, 'grad_norm': 2.542539596557617}
2022-12-29 12:13:40.037 DEBUG: Taking gradient step
2022-12-29 12:13:40.046 DEBUG: Loss 4: {'policy_loss': 0.011996978839713915, 'entropy_loss': -0.02404048666357994, 'vf_loss': 0.0002404095143614783, 'total_loss': -0.011803098309504552, 'approx_kl': 0.032640944176819175, 'clip_fraction': 0.1809895858168602, 'grad_norm': 4.293323040008545}
2022-12-29 12:13:40.755 DEBUG: Taking gradient step
2022-12-29 12:13:40.767 DEBUG: Loss 5: {'policy_loss': -0.004254514974333988, 'entropy_loss': -0.022746273316442966, 'vf_loss': 0.0002337055234596654, 'total_loss': -0.026767082767317287, 'approx_kl': 0.007945038145408034, 'clip_fraction': 0.14192708395421505, 'grad_norm': 2.504426956176758}
2022-12-29 12:13:41.447 DEBUG: Taking gradient step
2022-12-29 12:13:41.456 DEBUG: Loss 6: {'policy_loss': 0.025452443839798906, 'entropy_loss': -0.022682684008032084, 'vf_loss': 0.00021725003947937582, 'total_loss': 0.002987009871246199, 'approx_kl': 0.012072340585291386, 'clip_fraction': 0.15755208395421505, 'grad_norm': 3.2131001949310303}
2022-12-29 12:13:42.196 DEBUG: Taking gradient step
2022-12-29 12:13:42.205 DEBUG: Loss 7: {'policy_loss': -0.01282545715292829, 'entropy_loss': -0.02324040373787284, 'vf_loss': 0.00021051180808814417, 'total_loss': -0.035855349082712984, 'approx_kl': 0.0208389675244689, 'clip_fraction': 0.20703125, 'grad_norm': 4.2334723472595215}
2022-12-29 12:13:42.904 DEBUG: Taking gradient step
2022-12-29 12:13:42.913 DEBUG: Loss 8: {'policy_loss': 0.018999886691177654, 'entropy_loss': -0.022377552930265665, 'vf_loss': 0.00019247438193519494, 'total_loss': -0.003185191857152818, 'approx_kl': 0.013441126327961683, 'clip_fraction': 0.2369791679084301, 'grad_norm': 3.4056243896484375}
2022-12-29 12:13:43.617 DEBUG: Taking gradient step
2022-12-29 12:13:43.626 DEBUG: Loss 9: {'policy_loss': 0.051629663783841845, 'entropy_loss': -0.022438644897192717, 'vf_loss': 0.00017654553081827162, 'total_loss': 0.029367564417467393, 'approx_kl': 0.03893857775256038, 'clip_fraction': 0.21484375, 'grad_norm': 3.1375627517700195}
2022-12-29 12:13:43.627 INFO: Optimization: policy loss=0.052, vf loss=0.000, entropy loss=-0.022, total loss=0.029, num steps=10
2022-12-29 12:13:43.627 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:13:44.379 INFO: Evaluation rollout: return=0.512 (0.0), episode length=3.0
2022-12-29 12:13:44.379 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:13:44.381 INFO: Iteration: 48/137, steps: 10368
2022-12-29 12:13:57.674 DEBUG: Atoms are too close
2022-12-29 12:14:22.479 DEBUG: Atoms are too close
2022-12-29 12:14:30.106 DEBUG: Atoms are too close
2022-12-29 12:14:32.218 INFO: Training rollout: return=-0.376 (4.0), episode length=3.0
2022-12-29 12:14:32.219 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:14:32.222 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-10368_train.pkl
2022-12-29 12:14:32.947 DEBUG: Taking gradient step
2022-12-29 12:14:32.958 DEBUG: Loss 0: {'policy_loss': -0.03303074775918274, 'entropy_loss': -0.021202655974775553, 'vf_loss': 0.01394887933445052, 'total_loss': -0.04028452439950777, 'approx_kl': 1.5366822481155396e-08, 'clip_fraction': 0.0, 'grad_norm': 16.071155548095703}
2022-12-29 12:14:33.663 DEBUG: Taking gradient step
2022-12-29 12:14:33.672 DEBUG: Loss 1: {'policy_loss': -0.0038909839887236253, 'entropy_loss': -0.022165018133819103, 'vf_loss': 0.01654007281875249, 'total_loss': -0.009515929303790237, 'approx_kl': 0.0008003318580449559, 'clip_fraction': 0.0, 'grad_norm': 27.493377685546875}
2022-12-29 12:14:34.395 DEBUG: Taking gradient step
2022-12-29 12:14:34.404 DEBUG: Loss 2: {'policy_loss': -0.004205043233601371, 'entropy_loss': -0.021276038140058517, 'vf_loss': 0.01652170812188255, 'total_loss': -0.00895937325177734, 'approx_kl': 0.0006616768660023808, 'clip_fraction': 0.01953125, 'grad_norm': 6.757186412811279}
2022-12-29 12:14:35.097 DEBUG: Taking gradient step
2022-12-29 12:14:35.110 DEBUG: Loss 3: {'policy_loss': 0.0486707623977279, 'entropy_loss': -0.020287525141611695, 'vf_loss': 0.021695220674662744, 'total_loss': 0.05007845793077896, 'approx_kl': 0.006015529623255134, 'clip_fraction': 0.0963541679084301, 'grad_norm': 6.298614025115967}
2022-12-29 12:14:35.821 DEBUG: Taking gradient step
2022-12-29 12:14:35.830 DEBUG: Loss 4: {'policy_loss': -0.038189519757696806, 'entropy_loss': -0.021819626446813345, 'vf_loss': 0.013974721758078398, 'total_loss': -0.04603442444643175, 'approx_kl': 0.03090215043630451, 'clip_fraction': 0.1966145858168602, 'grad_norm': 3.309316396713257}
2022-12-29 12:14:36.544 DEBUG: Taking gradient step
2022-12-29 12:14:36.553 DEBUG: Loss 5: {'policy_loss': -0.012234771519959808, 'entropy_loss': -0.02152202045544982, 'vf_loss': 0.016552806860346953, 'total_loss': -0.017203985115062676, 'approx_kl': 0.02392372814938426, 'clip_fraction': 0.25, 'grad_norm': 4.183419227600098}
2022-12-29 12:14:37.288 DEBUG: Early stopping at step 6 for reaching max KL.
2022-12-29 12:14:37.288 INFO: Optimization: policy loss=-0.012, vf loss=0.017, entropy loss=-0.022, total loss=-0.017, num steps=6
2022-12-29 12:14:37.288 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:14:38.026 INFO: Evaluation rollout: return=0.510 (0.0), episode length=3.0
2022-12-29 12:14:38.027 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:14:38.029 INFO: Iteration: 49/137, steps: 10584
2022-12-29 12:15:15.352 DEBUG: Atoms are too close
2022-12-29 12:15:26.989 INFO: Training rollout: return=0.176 (2.4), episode length=3.0
2022-12-29 12:15:26.991 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:15:26.993 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-10584_train.pkl
2022-12-29 12:15:27.764 DEBUG: Taking gradient step
2022-12-29 12:15:27.778 DEBUG: Loss 0: {'policy_loss': -0.013381498458261532, 'entropy_loss': -0.021009621676057577, 'vf_loss': 0.0032847131732903346, 'total_loss': -0.031106406961028774, 'approx_kl': 7.799826562404633e-09, 'clip_fraction': 0.0, 'grad_norm': 7.0169172286987305}
2022-12-29 12:15:28.491 DEBUG: Taking gradient step
2022-12-29 12:15:28.501 DEBUG: Loss 1: {'policy_loss': -0.019701370663489447, 'entropy_loss': -0.02093983767554164, 'vf_loss': 0.003288285781856123, 'total_loss': -0.03735292255717496, 'approx_kl': -0.001897117297630757, 'clip_fraction': 0.0, 'grad_norm': 6.9030961990356445}
2022-12-29 12:15:29.198 DEBUG: Taking gradient step
2022-12-29 12:15:29.207 DEBUG: Loss 2: {'policy_loss': 0.031060390642226376, 'entropy_loss': -0.020888292230665684, 'vf_loss': 0.0059239097462053985, 'total_loss': 0.0160960081577661, 'approx_kl': -0.001440292107872665, 'clip_fraction': 0.03515625, 'grad_norm': 16.114927291870117}
2022-12-29 12:15:29.880 DEBUG: Taking gradient step
2022-12-29 12:15:29.889 DEBUG: Loss 3: {'policy_loss': -0.021507924552126308, 'entropy_loss': -0.0215801065787673, 'vf_loss': 0.0032825907605041524, 'total_loss': -0.03980544037038945, 'approx_kl': 0.00858990487176925, 'clip_fraction': 0.12890625, 'grad_norm': 0.8051950335502625}
2022-12-29 12:15:30.589 DEBUG: Taking gradient step
2022-12-29 12:15:30.598 DEBUG: Loss 4: {'policy_loss': -0.022016706192467424, 'entropy_loss': -0.02189828222617507, 'vf_loss': 0.0032790599342164654, 'total_loss': -0.04063592848442603, 'approx_kl': 0.004062677500769496, 'clip_fraction': 0.2252604216337204, 'grad_norm': 0.823330819606781}
2022-12-29 12:15:31.297 DEBUG: Taking gradient step
2022-12-29 12:15:31.306 DEBUG: Loss 5: {'policy_loss': -0.02686505289688089, 'entropy_loss': -0.020669732242822647, 'vf_loss': 0.003281281901530025, 'total_loss': -0.044253503238173515, 'approx_kl': 0.013490518787875772, 'clip_fraction': 0.2239583358168602, 'grad_norm': 0.8189758658409119}
2022-12-29 12:15:32.015 DEBUG: Taking gradient step
2022-12-29 12:15:32.024 DEBUG: Loss 6: {'policy_loss': 0.03308307568151814, 'entropy_loss': -0.021229621954262257, 'vf_loss': 0.005908133908667578, 'total_loss': 0.01776158763592344, 'approx_kl': 0.026683253701776266, 'clip_fraction': 0.23828125, 'grad_norm': 0.8244206309318542}
2022-12-29 12:15:32.735 DEBUG: Taking gradient step
2022-12-29 12:15:32.745 DEBUG: Loss 7: {'policy_loss': -0.02609221237560732, 'entropy_loss': -0.021591330878436565, 'vf_loss': 0.00326743373338206, 'total_loss': -0.04441610952066182, 'approx_kl': 0.019432542845606804, 'clip_fraction': 0.2057291679084301, 'grad_norm': 0.8521119356155396}
2022-12-29 12:15:33.582 DEBUG: Taking gradient step
2022-12-29 12:15:33.593 DEBUG: Loss 8: {'policy_loss': 0.03840146561333081, 'entropy_loss': -0.021766590885818005, 'vf_loss': 0.005890735219893215, 'total_loss': 0.02252560994740603, 'approx_kl': 0.012181894853711128, 'clip_fraction': 0.16536458395421505, 'grad_norm': 0.6327021718025208}
2022-12-29 12:15:34.287 DEBUG: Taking gradient step
2022-12-29 12:15:34.296 DEBUG: Loss 9: {'policy_loss': -0.02583469971188175, 'entropy_loss': -0.02270511817187071, 'vf_loss': 0.0032554671903366034, 'total_loss': -0.045284350693415854, 'approx_kl': 0.014927781419828534, 'clip_fraction': 0.1653645858168602, 'grad_norm': 0.300041526556015}
2022-12-29 12:15:34.296 INFO: Optimization: policy loss=-0.026, vf loss=0.003, entropy loss=-0.023, total loss=-0.045, num steps=10
2022-12-29 12:15:34.296 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:15:35.024 INFO: Evaluation rollout: return=0.509 (0.0), episode length=3.0
2022-12-29 12:15:35.024 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:15:35.026 INFO: Iteration: 50/137, steps: 10800
2022-12-29 12:15:54.318 DEBUG: Atoms are too close
2022-12-29 12:16:23.372 INFO: Training rollout: return=0.178 (2.4), episode length=3.0
2022-12-29 12:16:23.374 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:16:23.376 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-10800_train.pkl
2022-12-29 12:16:24.079 DEBUG: Taking gradient step
2022-12-29 12:16:24.088 DEBUG: Loss 0: {'policy_loss': -0.011230497043876596, 'entropy_loss': -0.024111770559102297, 'vf_loss': 0.003247628739436905, 'total_loss': -0.032094638863542, 'approx_kl': 4.035731193674508e-09, 'clip_fraction': 0.0, 'grad_norm': 7.568488597869873}
2022-12-29 12:16:24.810 DEBUG: Taking gradient step
2022-12-29 12:16:24.820 DEBUG: Loss 1: {'policy_loss': -0.013862222038410761, 'entropy_loss': -0.023954530712217093, 'vf_loss': 0.0032489104534819406, 'total_loss': -0.03456784229714591, 'approx_kl': -0.0009176584426313639, 'clip_fraction': 0.0, 'grad_norm': 7.75313138961792}
2022-12-29 12:16:25.513 DEBUG: Taking gradient step
2022-12-29 12:16:25.522 DEBUG: Loss 2: {'policy_loss': -0.015365893031342916, 'entropy_loss': -0.024512406904250383, 'vf_loss': 0.003247230785162606, 'total_loss': -0.03663106915043069, 'approx_kl': 0.0012288782163523138, 'clip_fraction': 0.0, 'grad_norm': 7.656985759735107}
2022-12-29 12:16:26.198 DEBUG: Taking gradient step
2022-12-29 12:16:26.209 DEBUG: Loss 3: {'policy_loss': -0.020756914313759704, 'entropy_loss': -0.023952621035277843, 'vf_loss': 0.0032459712407563483, 'total_loss': -0.0414635641082812, 'approx_kl': 0.0038038728525862098, 'clip_fraction': 0.015625, 'grad_norm': 7.5395588874816895}
2022-12-29 12:16:26.889 DEBUG: Taking gradient step
2022-12-29 12:16:26.898 DEBUG: Loss 4: {'policy_loss': -0.01996612282581302, 'entropy_loss': -0.02468518167734146, 'vf_loss': 0.0032448627887684176, 'total_loss': -0.041406441714386066, 'approx_kl': 0.014289261191152036, 'clip_fraction': 0.07421875, 'grad_norm': 0.6488677263259888}
2022-12-29 12:16:27.619 DEBUG: Taking gradient step
2022-12-29 12:16:27.629 DEBUG: Loss 5: {'policy_loss': -0.020439699375975822, 'entropy_loss': -0.025212443433701992, 'vf_loss': 0.0032447365583484003, 'total_loss': -0.04240740625132942, 'approx_kl': 0.017474981024861336, 'clip_fraction': 0.09244791697710752, 'grad_norm': 0.682745635509491}
2022-12-29 12:16:28.360 DEBUG: Taking gradient step
2022-12-29 12:16:28.369 DEBUG: Loss 6: {'policy_loss': -0.025669052276098628, 'entropy_loss': -0.024840937927365303, 'vf_loss': 0.0032473728735264913, 'total_loss': -0.04726261732993744, 'approx_kl': 0.016916677821427584, 'clip_fraction': 0.13671875, 'grad_norm': 0.7203467488288879}
2022-12-29 12:16:29.071 DEBUG: Taking gradient step
2022-12-29 12:16:29.083 DEBUG: Loss 7: {'policy_loss': -0.026622314646694376, 'entropy_loss': -0.025069929659366608, 'vf_loss': 0.003247978651992687, 'total_loss': -0.04844426565406829, 'approx_kl': 0.013778240536339581, 'clip_fraction': 0.2317708358168602, 'grad_norm': 0.6937287449836731}
2022-12-29 12:16:29.800 DEBUG: Taking gradient step
2022-12-29 12:16:29.810 DEBUG: Loss 8: {'policy_loss': 0.032008024781384786, 'entropy_loss': -0.025348727125674486, 'vf_loss': 0.005891075924342543, 'total_loss': 0.012550373580052843, 'approx_kl': 0.015913621988147497, 'clip_fraction': 0.1979166716337204, 'grad_norm': 0.14614762365818024}
2022-12-29 12:16:30.505 DEBUG: Taking gradient step
2022-12-29 12:16:30.515 DEBUG: Loss 9: {'policy_loss': -0.025088962675776285, 'entropy_loss': -0.025422717444598675, 'vf_loss': 0.0032442887456770727, 'total_loss': -0.04726739137469788, 'approx_kl': 0.010681454092264175, 'clip_fraction': 0.1966145858168602, 'grad_norm': 7.36184024810791}
2022-12-29 12:16:30.516 INFO: Optimization: policy loss=-0.025, vf loss=0.003, entropy loss=-0.025, total loss=-0.047, num steps=10
2022-12-29 12:16:30.516 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:16:31.218 INFO: Evaluation rollout: return=0.510 (0.0), episode length=3.0
2022-12-29 12:16:31.219 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:16:31.221 DEBUG: Deleting old model: runs/H2O/models/H2O_run-1_steps-8856.model
2022-12-29 12:16:31.223 DEBUG: Saving model: runs/H2O/models/H2O_run-1_steps-11016.model
2022-12-29 12:16:31.253 INFO: Iteration: 51/137, steps: 11016
2022-12-29 12:16:44.752 DEBUG: Atoms are too close
2022-12-29 12:17:19.824 INFO: Training rollout: return=0.171 (2.4), episode length=3.0
2022-12-29 12:17:19.826 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:17:19.829 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-11016_train.pkl
2022-12-29 12:17:20.543 DEBUG: Taking gradient step
2022-12-29 12:17:20.554 DEBUG: Loss 0: {'policy_loss': -0.019053072630651008, 'entropy_loss': -0.0266076042316854, 'vf_loss': 0.004781709519552342, 'total_loss': -0.04087896734278407, 'approx_kl': 1.8005570368018198e-08, 'clip_fraction': 0.0, 'grad_norm': 11.480879783630371}
2022-12-29 12:17:21.277 DEBUG: Taking gradient step
2022-12-29 12:17:21.288 DEBUG: Loss 1: {'policy_loss': -0.014889261053843385, 'entropy_loss': -0.026375644374638796, 'vf_loss': 0.004775824809753013, 'total_loss': -0.03648908061872916, 'approx_kl': 0.0008263902273029089, 'clip_fraction': 0.0, 'grad_norm': 11.195486068725586}
2022-12-29 12:17:21.994 DEBUG: Taking gradient step
2022-12-29 12:17:22.003 DEBUG: Loss 2: {'policy_loss': -0.02713169244013574, 'entropy_loss': -0.025866919197142124, 'vf_loss': 0.004776727761877515, 'total_loss': -0.04822188387540034, 'approx_kl': 0.005551801761612296, 'clip_fraction': 0.0078125, 'grad_norm': 10.033079147338867}
2022-12-29 12:17:22.731 DEBUG: Taking gradient step
2022-12-29 12:17:22.740 DEBUG: Loss 3: {'policy_loss': 0.07119518743682486, 'entropy_loss': -0.0262092393822968, 'vf_loss': 0.010029012425080332, 'total_loss': 0.05501496047960838, 'approx_kl': 0.016796865733340383, 'clip_fraction': 0.0989583358168602, 'grad_norm': 2.7153995037078857}
2022-12-29 12:17:23.418 DEBUG: Taking gradient step
2022-12-29 12:17:23.427 DEBUG: Loss 4: {'policy_loss': -0.030849943772450466, 'entropy_loss': -0.025505943689495325, 'vf_loss': 0.004770406681649018, 'total_loss': -0.051585480780296775, 'approx_kl': 0.02980960998684168, 'clip_fraction': 0.1536458358168602, 'grad_norm': 1.1305828094482422}
2022-12-29 12:17:24.129 DEBUG: Taking gradient step
2022-12-29 12:17:24.139 DEBUG: Loss 5: {'policy_loss': -0.032646792595492934, 'entropy_loss': -0.024808887392282486, 'vf_loss': 0.004766838159786848, 'total_loss': -0.052688841827988574, 'approx_kl': 0.019129274412989616, 'clip_fraction': 0.1888020858168602, 'grad_norm': 1.184436559677124}
2022-12-29 12:17:24.841 DEBUG: Taking gradient step
2022-12-29 12:17:24.850 DEBUG: Loss 6: {'policy_loss': -0.03331412985191634, 'entropy_loss': -0.026413429528474808, 'vf_loss': 0.004760861944986474, 'total_loss': -0.05496669743540467, 'approx_kl': 0.03915790840983391, 'clip_fraction': 0.171875, 'grad_norm': 1.152732014656067}
2022-12-29 12:17:25.550 DEBUG: Early stopping at step 7 for reaching max KL.
2022-12-29 12:17:25.550 INFO: Optimization: policy loss=-0.033, vf loss=0.005, entropy loss=-0.026, total loss=-0.055, num steps=7
2022-12-29 12:17:25.551 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:17:26.218 INFO: Evaluation rollout: return=0.511 (0.0), episode length=3.0
2022-12-29 12:17:26.218 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:17:26.220 INFO: Iteration: 52/137, steps: 11232
2022-12-29 12:18:14.915 INFO: Training rollout: return=0.448 (0.1), episode length=3.0
2022-12-29 12:18:14.916 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:18:14.919 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-11232_train.pkl
2022-12-29 12:18:15.673 DEBUG: Taking gradient step
2022-12-29 12:18:15.683 DEBUG: Loss 0: {'policy_loss': 0.023510171423901535, 'entropy_loss': -0.027320505119860172, 'vf_loss': 7.925471418300631e-05, 'total_loss': -0.003731078981775632, 'approx_kl': -2.832772827421337e-08, 'clip_fraction': 0.0, 'grad_norm': 5.231992244720459}
2022-12-29 12:18:16.380 DEBUG: Taking gradient step
2022-12-29 12:18:16.389 DEBUG: Loss 1: {'policy_loss': 0.05406204276457206, 'entropy_loss': -0.027123331557959318, 'vf_loss': 8.051660307660245e-05, 'total_loss': 0.027019227809689357, 'approx_kl': 0.004872377146966755, 'clip_fraction': 0.0, 'grad_norm': 15.297618865966797}
2022-12-29 12:18:17.091 DEBUG: Taking gradient step
2022-12-29 12:18:17.100 DEBUG: Loss 2: {'policy_loss': -0.04510364664148709, 'entropy_loss': -0.02573493029922247, 'vf_loss': 8.825455728273164e-05, 'total_loss': -0.07075032238342682, 'approx_kl': 0.012264601304195821, 'clip_fraction': 0.06770833395421505, 'grad_norm': 12.641021728515625}
2022-12-29 12:18:17.807 DEBUG: Taking gradient step
2022-12-29 12:18:17.816 DEBUG: Loss 3: {'policy_loss': -0.011615186539006728, 'entropy_loss': -0.025259985588490963, 'vf_loss': 8.923751431504426e-05, 'total_loss': -0.03678593461318265, 'approx_kl': 0.018048692028969526, 'clip_fraction': 0.1015625, 'grad_norm': 11.946961402893066}
2022-12-29 12:18:18.527 DEBUG: Taking gradient step
2022-12-29 12:18:18.536 DEBUG: Loss 4: {'policy_loss': -0.011768593269089895, 'entropy_loss': -0.025762055534869432, 'vf_loss': 9.096471042009605e-05, 'total_loss': -0.037439684093539226, 'approx_kl': 0.024975863518193364, 'clip_fraction': 0.1432291679084301, 'grad_norm': 12.071006774902344}
2022-12-29 12:18:19.241 DEBUG: Taking gradient step
2022-12-29 12:18:19.251 DEBUG: Loss 5: {'policy_loss': -0.0015758235127425295, 'entropy_loss': -0.02497114473953843, 'vf_loss': 9.180132007171059e-05, 'total_loss': -0.02645516693220925, 'approx_kl': 0.020788429770618677, 'clip_fraction': 0.1666666679084301, 'grad_norm': 8.723714828491211}
2022-12-29 12:18:19.984 DEBUG: Taking gradient step
2022-12-29 12:18:19.995 DEBUG: Loss 6: {'policy_loss': -0.02980354065116396, 'entropy_loss': -0.025976169388741255, 'vf_loss': 9.486296170222742e-05, 'total_loss': -0.05568484707820299, 'approx_kl': 0.037019789684563875, 'clip_fraction': 0.1705729179084301, 'grad_norm': 7.545536994934082}
2022-12-29 12:18:20.704 DEBUG: Taking gradient step
2022-12-29 12:18:20.713 DEBUG: Loss 7: {'policy_loss': -0.013400229235614684, 'entropy_loss': -0.0269509912468493, 'vf_loss': 9.495367352891561e-05, 'total_loss': -0.04025626680893507, 'approx_kl': 0.041954052867367864, 'clip_fraction': 0.1666666679084301, 'grad_norm': 15.569608688354492}
2022-12-29 12:18:21.418 DEBUG: Early stopping at step 8 for reaching max KL.
2022-12-29 12:18:21.418 INFO: Optimization: policy loss=-0.013, vf loss=0.000, entropy loss=-0.027, total loss=-0.040, num steps=8
2022-12-29 12:18:21.418 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:18:22.122 INFO: Evaluation rollout: return=0.513 (0.0), episode length=3.0
2022-12-29 12:18:22.122 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:18:22.124 INFO: Iteration: 53/137, steps: 11448
2022-12-29 12:19:10.989 INFO: Training rollout: return=0.455 (0.1), episode length=3.0
2022-12-29 12:19:10.991 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:19:10.994 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-11448_train.pkl
2022-12-29 12:19:11.713 DEBUG: Taking gradient step
2022-12-29 12:19:11.722 DEBUG: Loss 0: {'policy_loss': 0.05583720499103029, 'entropy_loss': -0.026621204800903797, 'vf_loss': 9.667524417033732e-05, 'total_loss': 0.029312675434296817, 'approx_kl': -2.6775524020195007e-08, 'clip_fraction': 0.0, 'grad_norm': 14.724637031555176}
2022-12-29 12:19:12.417 DEBUG: Taking gradient step
2022-12-29 12:19:12.427 DEBUG: Loss 1: {'policy_loss': -0.007854155081376935, 'entropy_loss': -0.0254920138977468, 'vf_loss': 0.00010240647258435527, 'total_loss': -0.03324376250653938, 'approx_kl': 0.00010507344268262386, 'clip_fraction': 0.0, 'grad_norm': 18.243820190429688}
2022-12-29 12:19:13.147 DEBUG: Taking gradient step
2022-12-29 12:19:13.163 DEBUG: Loss 2: {'policy_loss': -0.0352584143102801, 'entropy_loss': -0.0261493269354105, 'vf_loss': 0.00010349827183186354, 'total_loss': -0.06130424297385874, 'approx_kl': 0.005329000181518495, 'clip_fraction': 0.0, 'grad_norm': 10.93015193939209}
2022-12-29 12:19:13.845 DEBUG: Taking gradient step
2022-12-29 12:19:13.856 DEBUG: Loss 3: {'policy_loss': 0.03769455943480981, 'entropy_loss': -0.02576308185234666, 'vf_loss': 9.876316366938976e-05, 'total_loss': 0.012030240746132542, 'approx_kl': 0.017664954997599125, 'clip_fraction': 0.1041666679084301, 'grad_norm': 5.294554233551025}
2022-12-29 12:19:14.662 DEBUG: Taking gradient step
2022-12-29 12:19:14.676 DEBUG: Loss 4: {'policy_loss': -0.03086178958408485, 'entropy_loss': -0.025590594857931137, 'vf_loss': 0.00010335282005210627, 'total_loss': -0.05634903162196388, 'approx_kl': 0.03227789606899023, 'clip_fraction': 0.1692708358168602, 'grad_norm': 7.921896934509277}
2022-12-29 12:19:15.419 DEBUG: Taking gradient step
2022-12-29 12:19:15.428 DEBUG: Loss 5: {'policy_loss': -0.02361305283887742, 'entropy_loss': -0.024685080628842115, 'vf_loss': 0.00010194117129488643, 'total_loss': -0.04819619229642465, 'approx_kl': 0.035322251031175256, 'clip_fraction': 0.1953125, 'grad_norm': 9.312979698181152}
2022-12-29 12:19:16.122 DEBUG: Early stopping at step 6 for reaching max KL.
2022-12-29 12:19:16.122 INFO: Optimization: policy loss=-0.024, vf loss=0.000, entropy loss=-0.025, total loss=-0.048, num steps=6
2022-12-29 12:19:16.122 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:19:16.769 INFO: Evaluation rollout: return=0.512 (0.0), episode length=3.0
2022-12-29 12:19:16.770 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:19:16.771 INFO: Iteration: 54/137, steps: 11664
2022-12-29 12:20:05.210 INFO: Training rollout: return=0.465 (0.0), episode length=3.0
2022-12-29 12:20:05.212 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:20:05.214 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-11664_train.pkl
2022-12-29 12:20:05.995 DEBUG: Taking gradient step
2022-12-29 12:20:06.006 DEBUG: Loss 0: {'policy_loss': 0.03915321901130534, 'entropy_loss': -0.026226189453154802, 'vf_loss': 9.691718488298579e-05, 'total_loss': 0.013023946743033532, 'approx_kl': -6.674478569834719e-08, 'clip_fraction': 0.0, 'grad_norm': 8.832347869873047}
2022-12-29 12:20:06.734 DEBUG: Taking gradient step
2022-12-29 12:20:06.743 DEBUG: Loss 1: {'policy_loss': -0.0356674518471667, 'entropy_loss': -0.025650315452367067, 'vf_loss': 9.974259983117366e-05, 'total_loss': -0.0612180246997026, 'approx_kl': -0.00032622471917420626, 'clip_fraction': 0.0078125, 'grad_norm': 7.0476393699646}
2022-12-29 12:20:07.473 DEBUG: Taking gradient step
2022-12-29 12:20:07.482 DEBUG: Loss 2: {'policy_loss': -0.03020188949146519, 'entropy_loss': -0.024793922435492277, 'vf_loss': 9.849728625869634e-05, 'total_loss': -0.05489731464069877, 'approx_kl': 0.004374573240056634, 'clip_fraction': 0.022135416977107525, 'grad_norm': 5.555189609527588}
2022-12-29 12:20:08.240 DEBUG: Taking gradient step
2022-12-29 12:20:08.249 DEBUG: Loss 3: {'policy_loss': 0.022388424696279014, 'entropy_loss': -0.024386243894696236, 'vf_loss': 9.220914678193572e-05, 'total_loss': -0.0019056100516352883, 'approx_kl': 0.004342722822912037, 'clip_fraction': 0.029947916977107525, 'grad_norm': 4.227944374084473}
2022-12-29 12:20:08.991 DEBUG: Taking gradient step
2022-12-29 12:20:09.002 DEBUG: Loss 4: {'policy_loss': 0.02588891492734091, 'entropy_loss': -0.025600935332477093, 'vf_loss': 8.902632560812008e-05, 'total_loss': 0.00037700592047194836, 'approx_kl': 0.012971872929483652, 'clip_fraction': 0.11588541697710752, 'grad_norm': 7.75678014755249}
2022-12-29 12:20:09.705 DEBUG: Taking gradient step
2022-12-29 12:20:09.714 DEBUG: Loss 5: {'policy_loss': 0.023639313044399174, 'entropy_loss': -0.02564367139711976, 'vf_loss': 8.624259026071618e-05, 'total_loss': -0.001918115762459871, 'approx_kl': 0.01954566885251552, 'clip_fraction': 0.16536458395421505, 'grad_norm': 6.459376811981201}
2022-12-29 12:20:10.432 DEBUG: Taking gradient step
2022-12-29 12:20:10.446 DEBUG: Loss 6: {'policy_loss': -0.019565615811119114, 'entropy_loss': -0.024409848265349865, 'vf_loss': 8.733785367091667e-05, 'total_loss': -0.043888126222798064, 'approx_kl': 0.028667149366810918, 'clip_fraction': 0.2122395858168602, 'grad_norm': 8.946757316589355}
2022-12-29 12:20:11.174 DEBUG: Taking gradient step
2022-12-29 12:20:11.184 DEBUG: Loss 7: {'policy_loss': -0.07377555221847687, 'entropy_loss': -0.024844328872859478, 'vf_loss': 8.804012690557104e-05, 'total_loss': -0.09853184096443077, 'approx_kl': 0.025728499051183462, 'clip_fraction': 0.19140625, 'grad_norm': 8.193268775939941}
2022-12-29 12:20:11.894 DEBUG: Taking gradient step
2022-12-29 12:20:11.903 DEBUG: Loss 8: {'policy_loss': 0.04778840368552772, 'entropy_loss': -0.025790277868509293, 'vf_loss': 7.656039718336862e-05, 'total_loss': 0.02207468621420179, 'approx_kl': 0.02274444792419672, 'clip_fraction': 0.16015625, 'grad_norm': 8.094758987426758}
2022-12-29 12:20:12.584 DEBUG: Taking gradient step
2022-12-29 12:20:12.593 DEBUG: Loss 9: {'policy_loss': -0.04690722793348044, 'entropy_loss': -0.026482125744223595, 'vf_loss': 7.995293104894658e-05, 'total_loss': -0.0733094007466551, 'approx_kl': 0.024259373545646667, 'clip_fraction': 0.13802083395421505, 'grad_norm': 4.31673526763916}
2022-12-29 12:20:12.593 INFO: Optimization: policy loss=-0.047, vf loss=0.000, entropy loss=-0.026, total loss=-0.073, num steps=10
2022-12-29 12:20:12.594 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:20:13.335 INFO: Evaluation rollout: return=0.511 (0.0), episode length=3.0
2022-12-29 12:20:13.335 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:20:13.338 INFO: Iteration: 55/137, steps: 11880
2022-12-29 12:21:02.292 INFO: Training rollout: return=0.447 (0.1), episode length=3.0
2022-12-29 12:21:02.294 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:21:02.297 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-11880_train.pkl
2022-12-29 12:21:03.033 DEBUG: Taking gradient step
2022-12-29 12:21:03.042 DEBUG: Loss 0: {'policy_loss': -0.002643237408429291, 'entropy_loss': -0.025912095326930285, 'vf_loss': 7.369851874606765e-05, 'total_loss': -0.02848163421661351, 'approx_kl': 5.568533012478838e-08, 'clip_fraction': 0.0, 'grad_norm': 11.895940780639648}
2022-12-29 12:21:03.741 DEBUG: Taking gradient step
2022-12-29 12:21:03.751 DEBUG: Loss 1: {'policy_loss': 0.004465399015380331, 'entropy_loss': -0.02601097570732236, 'vf_loss': 7.063100655696577e-05, 'total_loss': -0.02147494568538506, 'approx_kl': 0.004374916316010058, 'clip_fraction': 0.03645833395421505, 'grad_norm': 9.691869735717773}
2022-12-29 12:21:04.495 DEBUG: Taking gradient step
2022-12-29 12:21:04.505 DEBUG: Loss 2: {'policy_loss': 0.006147673946283129, 'entropy_loss': -0.025656538549810648, 'vf_loss': 6.846875644551077e-05, 'total_loss': -0.019440395847082008, 'approx_kl': 0.005401366273872554, 'clip_fraction': 0.0885416679084301, 'grad_norm': 11.561455726623535}
2022-12-29 12:21:05.273 DEBUG: Taking gradient step
2022-12-29 12:21:05.282 DEBUG: Loss 3: {'policy_loss': -0.01223320789126357, 'entropy_loss': -0.026937275659292936, 'vf_loss': 6.799946432183353e-05, 'total_loss': -0.03910248408623468, 'approx_kl': 0.018036046531051397, 'clip_fraction': 0.08723958395421505, 'grad_norm': 10.796140670776367}
2022-12-29 12:21:06.026 DEBUG: Taking gradient step
2022-12-29 12:21:06.037 DEBUG: Loss 4: {'policy_loss': 0.027690733512585386, 'entropy_loss': -0.026412903796881437, 'vf_loss': 6.418274104458124e-05, 'total_loss': 0.0013420124567485384, 'approx_kl': 0.029660971369594336, 'clip_fraction': 0.1276041679084301, 'grad_norm': 9.771857261657715}
2022-12-29 12:21:06.752 DEBUG: Taking gradient step
2022-12-29 12:21:06.762 DEBUG: Loss 5: {'policy_loss': -0.0389652643490299, 'entropy_loss': -0.025279284454882145, 'vf_loss': 6.70614116663441e-05, 'total_loss': -0.06417748739224571, 'approx_kl': 0.03940919600427151, 'clip_fraction': 0.1979166679084301, 'grad_norm': 7.332461833953857}
2022-12-29 12:21:07.461 DEBUG: Taking gradient step
2022-12-29 12:21:07.471 DEBUG: Loss 6: {'policy_loss': -0.005203274520975333, 'entropy_loss': -0.025725787971168756, 'vf_loss': 6.235337972317779e-05, 'total_loss': -0.030866709112420905, 'approx_kl': 0.04250012361444533, 'clip_fraction': 0.2291666679084301, 'grad_norm': 5.329239845275879}
2022-12-29 12:21:08.210 DEBUG: Early stopping at step 7 for reaching max KL.
2022-12-29 12:21:08.211 INFO: Optimization: policy loss=-0.005, vf loss=0.000, entropy loss=-0.026, total loss=-0.031, num steps=7
2022-12-29 12:21:08.211 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:21:08.993 INFO: Evaluation rollout: return=0.509 (0.0), episode length=3.0
2022-12-29 12:21:08.993 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:21:08.995 INFO: Iteration: 56/137, steps: 12096
2022-12-29 12:21:58.116 INFO: Training rollout: return=0.457 (0.1), episode length=3.0
2022-12-29 12:21:58.118 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:21:58.121 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-12096_train.pkl
2022-12-29 12:21:58.839 DEBUG: Taking gradient step
2022-12-29 12:21:58.848 DEBUG: Loss 0: {'policy_loss': 0.06459740507039244, 'entropy_loss': -0.026097283698618412, 'vf_loss': 5.828315916996037e-05, 'total_loss': 0.03855840453094399, 'approx_kl': 3.822303096256974e-08, 'clip_fraction': 0.0, 'grad_norm': 17.727840423583984}
2022-12-29 12:21:59.575 DEBUG: Taking gradient step
2022-12-29 12:21:59.589 DEBUG: Loss 1: {'policy_loss': -0.004059412460409725, 'entropy_loss': -0.02553814696148038, 'vf_loss': 5.9032959209471915e-05, 'total_loss': -0.029538526462680632, 'approx_kl': 0.011400653864257038, 'clip_fraction': 0.026041666977107525, 'grad_norm': 7.363266468048096}
2022-12-29 12:22:00.293 DEBUG: Taking gradient step
2022-12-29 12:22:00.302 DEBUG: Loss 2: {'policy_loss': 0.01733604841258478, 'entropy_loss': -0.026431254111230373, 'vf_loss': 5.73888609383421e-05, 'total_loss': -0.009037816837707255, 'approx_kl': 0.03138428134843707, 'clip_fraction': 0.11067708395421505, 'grad_norm': 12.334280967712402}
2022-12-29 12:22:01.008 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-29 12:22:01.008 INFO: Optimization: policy loss=0.017, vf loss=0.000, entropy loss=-0.026, total loss=-0.009, num steps=3
2022-12-29 12:22:01.008 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:22:01.685 INFO: Evaluation rollout: return=0.510 (0.0), episode length=3.0
2022-12-29 12:22:01.686 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:22:01.688 INFO: Iteration: 57/137, steps: 12312
2022-12-29 12:22:17.210 DEBUG: Atoms are too close
2022-12-29 12:22:25.227 DEBUG: Atoms are too close
2022-12-29 12:22:50.422 INFO: Training rollout: return=-0.096 (3.3), episode length=3.0
2022-12-29 12:22:50.424 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:22:50.426 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-12312_train.pkl
2022-12-29 12:22:51.143 DEBUG: Taking gradient step
2022-12-29 12:22:51.154 DEBUG: Loss 0: {'policy_loss': 0.010393945550423486, 'entropy_loss': -0.024576461408287287, 'vf_loss': 0.01199992550280594, 'total_loss': -0.0021825903550578545, 'approx_kl': 4.734223013613814e-09, 'clip_fraction': 0.0, 'grad_norm': 16.375986099243164}
2022-12-29 12:22:51.845 DEBUG: Taking gradient step
2022-12-29 12:22:51.855 DEBUG: Loss 1: {'policy_loss': -0.03343679873942043, 'entropy_loss': -0.024717804975807667, 'vf_loss': 0.009434662553452832, 'total_loss': -0.04871994116177526, 'approx_kl': 0.007304989034309983, 'clip_fraction': 0.07161458395421505, 'grad_norm': 3.495497226715088}
2022-12-29 12:22:52.574 DEBUG: Taking gradient step
2022-12-29 12:22:52.585 DEBUG: Loss 2: {'policy_loss': -0.03218725595535789, 'entropy_loss': -0.025268740486353636, 'vf_loss': 0.009433061256073723, 'total_loss': -0.048022935185637806, 'approx_kl': 0.019269769720267504, 'clip_fraction': 0.1302083358168602, 'grad_norm': 3.6061391830444336}
2022-12-29 12:22:53.265 DEBUG: Taking gradient step
2022-12-29 12:22:53.274 DEBUG: Loss 3: {'policy_loss': -0.031327645229742254, 'entropy_loss': -0.024557470344007015, 'vf_loss': 0.009427653808270839, 'total_loss': -0.046457461765478436, 'approx_kl': 0.029613279504701495, 'clip_fraction': 0.171875, 'grad_norm': 3.2863173484802246}
2022-12-29 12:22:53.977 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-29 12:22:53.977 INFO: Optimization: policy loss=-0.031, vf loss=0.009, entropy loss=-0.025, total loss=-0.046, num steps=4
2022-12-29 12:22:53.977 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:22:54.743 INFO: Evaluation rollout: return=0.511 (0.0), episode length=3.0
2022-12-29 12:22:54.744 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:22:54.746 INFO: Iteration: 58/137, steps: 12528
2022-12-29 12:23:43.580 INFO: Training rollout: return=0.460 (0.0), episode length=3.0
2022-12-29 12:23:43.582 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:23:43.585 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-12528_train.pkl
2022-12-29 12:23:44.320 DEBUG: Taking gradient step
2022-12-29 12:23:44.334 DEBUG: Loss 0: {'policy_loss': -0.0397545364211899, 'entropy_loss': -0.02537312125787139, 'vf_loss': 6.321481230014966e-05, 'total_loss': -0.06506444286676115, 'approx_kl': -7.295360315850985e-09, 'clip_fraction': 0.0, 'grad_norm': 3.110252618789673}
2022-12-29 12:23:45.040 DEBUG: Taking gradient step
2022-12-29 12:23:45.050 DEBUG: Loss 1: {'policy_loss': -0.011905468035071122, 'entropy_loss': -0.025268301833420992, 'vf_loss': 6.15547574585249e-05, 'total_loss': -0.03711221511103359, 'approx_kl': 0.0060540550912264735, 'clip_fraction': 0.02734375, 'grad_norm': 9.643135070800781}
2022-12-29 12:23:45.737 DEBUG: Taking gradient step
2022-12-29 12:23:45.746 DEBUG: Loss 2: {'policy_loss': -0.009840248913198003, 'entropy_loss': -0.024207791779190302, 'vf_loss': 6.182230874200197e-05, 'total_loss': -0.0339862183836463, 'approx_kl': 0.012621403089724481, 'clip_fraction': 0.0625, 'grad_norm': 7.595848560333252}
2022-12-29 12:23:46.446 DEBUG: Taking gradient step
2022-12-29 12:23:46.456 DEBUG: Loss 3: {'policy_loss': -0.015626227971171275, 'entropy_loss': -0.023633334320038557, 'vf_loss': 6.215967857461445e-05, 'total_loss': -0.03919740261263521, 'approx_kl': 0.01845712843351066, 'clip_fraction': 0.14583333395421505, 'grad_norm': 11.260697364807129}
2022-12-29 12:23:47.152 DEBUG: Taking gradient step
2022-12-29 12:23:47.162 DEBUG: Loss 4: {'policy_loss': 0.00031486746690367884, 'entropy_loss': -0.02317891363054514, 'vf_loss': 6.207967853758196e-05, 'total_loss': -0.02280196648510388, 'approx_kl': 0.024257174693048, 'clip_fraction': 0.22265625, 'grad_norm': 9.315119743347168}
2022-12-29 12:23:47.901 DEBUG: Taking gradient step
2022-12-29 12:23:47.911 DEBUG: Loss 5: {'policy_loss': -0.08038315901865711, 'entropy_loss': -0.02386370487511158, 'vf_loss': 6.668814533646531e-05, 'total_loss': -0.10418017574843222, 'approx_kl': 0.03040715167298913, 'clip_fraction': 0.23307291697710752, 'grad_norm': 5.117260456085205}
2022-12-29 12:23:48.622 DEBUG: Taking gradient step
2022-12-29 12:23:48.631 DEBUG: Loss 6: {'policy_loss': 0.041373140978584154, 'entropy_loss': -0.022718286141753197, 'vf_loss': 5.977147315696052e-05, 'total_loss': 0.018714626309987922, 'approx_kl': 0.03151402808725834, 'clip_fraction': 0.3125, 'grad_norm': 5.911110877990723}
2022-12-29 12:23:49.339 DEBUG: Taking gradient step
2022-12-29 12:23:49.354 DEBUG: Loss 7: {'policy_loss': 0.009779072891892483, 'entropy_loss': -0.021684983745217323, 'vf_loss': 6.310850949945582e-05, 'total_loss': -0.011842802343825384, 'approx_kl': 0.03309617470949888, 'clip_fraction': 0.2799479216337204, 'grad_norm': 10.819451332092285}
2022-12-29 12:23:50.072 DEBUG: Taking gradient step
2022-12-29 12:23:50.081 DEBUG: Loss 8: {'policy_loss': -0.031972128945398755, 'entropy_loss': -0.0231319279409945, 'vf_loss': 6.419534498040526e-05, 'total_loss': -0.055039861541412854, 'approx_kl': 0.027939741034060717, 'clip_fraction': 0.2799479216337204, 'grad_norm': 10.377041816711426}
2022-12-29 12:23:50.845 DEBUG: Taking gradient step
2022-12-29 12:23:50.854 DEBUG: Loss 9: {'policy_loss': 0.023226825041448518, 'entropy_loss': -0.022539162542670965, 'vf_loss': 5.9882227673659236e-05, 'total_loss': 0.0007475447264512144, 'approx_kl': 0.027659383602440357, 'clip_fraction': 0.2526041716337204, 'grad_norm': 6.815212249755859}
2022-12-29 12:23:50.855 INFO: Optimization: policy loss=0.023, vf loss=0.000, entropy loss=-0.023, total loss=0.001, num steps=10
2022-12-29 12:23:50.855 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:23:51.581 INFO: Evaluation rollout: return=0.512 (0.0), episode length=3.0
2022-12-29 12:23:51.582 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:23:51.584 INFO: Iteration: 59/137, steps: 12744
2022-12-29 12:24:40.880 INFO: Training rollout: return=0.475 (0.0), episode length=3.0
2022-12-29 12:24:40.882 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:24:40.885 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-12744_train.pkl
2022-12-29 12:24:41.615 DEBUG: Taking gradient step
2022-12-29 12:24:41.624 DEBUG: Loss 0: {'policy_loss': 0.0019637827316569935, 'entropy_loss': -0.0215380503796041, 'vf_loss': 6.761850668577118e-05, 'total_loss': -0.019506649141261333, 'approx_kl': 1.0632599689586186e-08, 'clip_fraction': 0.0, 'grad_norm': 6.754582405090332}
2022-12-29 12:24:42.324 DEBUG: Taking gradient step
2022-12-29 12:24:42.333 DEBUG: Loss 1: {'policy_loss': -0.01650055020545884, 'entropy_loss': -0.02291121380403638, 'vf_loss': 6.723480180116755e-05, 'total_loss': -0.039344529207694046, 'approx_kl': 0.0036972740199416876, 'clip_fraction': 0.00390625, 'grad_norm': 6.870409965515137}
2022-12-29 12:24:43.054 DEBUG: Taking gradient step
2022-12-29 12:24:43.064 DEBUG: Loss 2: {'policy_loss': -0.005648231898086882, 'entropy_loss': -0.02275633765384555, 'vf_loss': 6.559084577944686e-05, 'total_loss': -0.028338978706152984, 'approx_kl': 0.013316093944013119, 'clip_fraction': 0.10807291697710752, 'grad_norm': 7.342041015625}
2022-12-29 12:24:43.793 DEBUG: Taking gradient step
2022-12-29 12:24:43.804 DEBUG: Loss 3: {'policy_loss': -0.042155527568210574, 'entropy_loss': -0.022194767836481333, 'vf_loss': 6.736813130451972e-05, 'total_loss': -0.06428292727338739, 'approx_kl': 0.016818939126096666, 'clip_fraction': 0.1640625, 'grad_norm': 9.198965072631836}
2022-12-29 12:24:44.533 DEBUG: Taking gradient step
2022-12-29 12:24:44.542 DEBUG: Loss 4: {'policy_loss': 0.027335600530649082, 'entropy_loss': -0.022577430121600628, 'vf_loss': 6.270112727926484e-05, 'total_loss': 0.004820871536327723, 'approx_kl': 0.02439277246594429, 'clip_fraction': 0.2161458358168602, 'grad_norm': 12.453550338745117}
2022-12-29 12:24:45.248 DEBUG: Taking gradient step
2022-12-29 12:24:45.259 DEBUG: Loss 5: {'policy_loss': -0.0067723964439012335, 'entropy_loss': -0.023047891445457935, 'vf_loss': 6.271648532851564e-05, 'total_loss': -0.02975757140403065, 'approx_kl': 0.028637218638323247, 'clip_fraction': 0.1875, 'grad_norm': 7.178534984588623}
2022-12-29 12:24:45.973 DEBUG: Taking gradient step
2022-12-29 12:24:45.982 DEBUG: Loss 6: {'policy_loss': -0.007371850382213656, 'entropy_loss': -0.022928162943571806, 'vf_loss': 6.236454532246979e-05, 'total_loss': -0.030237648780463, 'approx_kl': 0.019741435768082738, 'clip_fraction': 0.1666666679084301, 'grad_norm': 6.529304504394531}
2022-12-29 12:24:46.686 DEBUG: Taking gradient step
2022-12-29 12:24:46.696 DEBUG: Loss 7: {'policy_loss': 0.017175922537303264, 'entropy_loss': -0.022183622233569622, 'vf_loss': 6.02249461318309e-05, 'total_loss': -0.004947474750134524, 'approx_kl': 0.0110418985132128, 'clip_fraction': 0.1731770858168602, 'grad_norm': 10.031392097473145}
2022-12-29 12:24:47.431 DEBUG: Taking gradient step
2022-12-29 12:24:47.444 DEBUG: Loss 8: {'policy_loss': 0.0016232048838228479, 'entropy_loss': -0.023651503026485443, 'vf_loss': 5.918248164897915e-05, 'total_loss': -0.021969115661013616, 'approx_kl': 0.01165673229843378, 'clip_fraction': 0.07161458395421505, 'grad_norm': 9.567015647888184}
2022-12-29 12:24:48.171 DEBUG: Taking gradient step
2022-12-29 12:24:48.180 DEBUG: Loss 9: {'policy_loss': -0.013264915741267265, 'entropy_loss': -0.023134716786444187, 'vf_loss': 5.8854302414827497e-05, 'total_loss': -0.036340778225296626, 'approx_kl': 0.01674336742144078, 'clip_fraction': 0.041666666977107525, 'grad_norm': 5.471283912658691}
2022-12-29 12:24:48.180 INFO: Optimization: policy loss=-0.013, vf loss=0.000, entropy loss=-0.023, total loss=-0.036, num steps=10
2022-12-29 12:24:48.181 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:24:48.894 INFO: Evaluation rollout: return=0.512 (0.0), episode length=3.0
2022-12-29 12:24:48.895 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:24:48.897 INFO: Iteration: 60/137, steps: 12960
2022-12-29 12:25:37.981 INFO: Training rollout: return=0.470 (0.1), episode length=3.0
2022-12-29 12:25:37.983 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:25:37.986 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-12960_train.pkl
2022-12-29 12:25:38.718 DEBUG: Taking gradient step
2022-12-29 12:25:38.727 DEBUG: Loss 0: {'policy_loss': -0.06108424340886499, 'entropy_loss': -0.024036739487200975, 'vf_loss': 5.6370182116282386e-05, 'total_loss': -0.08506461271394969, 'approx_kl': -5.360925570130348e-08, 'clip_fraction': 0.0, 'grad_norm': 7.283652305603027}
2022-12-29 12:25:39.428 DEBUG: Taking gradient step
2022-12-29 12:25:39.438 DEBUG: Loss 1: {'policy_loss': 0.07498134523444025, 'entropy_loss': -0.02335953852161765, 'vf_loss': 4.8283784042430086e-05, 'total_loss': 0.05167009049686502, 'approx_kl': 0.00421184697188437, 'clip_fraction': 0.0078125, 'grad_norm': 8.144269943237305}
2022-12-29 12:25:40.126 DEBUG: Taking gradient step
2022-12-29 12:25:40.135 DEBUG: Loss 2: {'policy_loss': -0.005075133893827145, 'entropy_loss': -0.023941564839333296, 'vf_loss': 5.169132120029978e-05, 'total_loss': -0.02896500741196014, 'approx_kl': 0.001930012833327055, 'clip_fraction': 0.1236979179084301, 'grad_norm': 12.972309112548828}
2022-12-29 12:25:40.845 DEBUG: Taking gradient step
2022-12-29 12:25:40.856 DEBUG: Loss 3: {'policy_loss': 0.011931371804667003, 'entropy_loss': -0.023353364784270525, 'vf_loss': 4.947494453955114e-05, 'total_loss': -0.011372518035063988, 'approx_kl': 0.022833886847365648, 'clip_fraction': 0.125, 'grad_norm': 10.524981498718262}
2022-12-29 12:25:41.557 DEBUG: Taking gradient step
2022-12-29 12:25:41.567 DEBUG: Loss 4: {'policy_loss': -0.025672641955195932, 'entropy_loss': -0.02329137222841382, 'vf_loss': 5.046942920732128e-05, 'total_loss': -0.04891354475440243, 'approx_kl': 0.021358191675972193, 'clip_fraction': 0.08333333395421505, 'grad_norm': 7.593018531799316}
2022-12-29 12:25:42.308 DEBUG: Taking gradient step
2022-12-29 12:25:42.317 DEBUG: Loss 5: {'policy_loss': -0.012507556129008404, 'entropy_loss': -0.022986537776887417, 'vf_loss': 4.8664020894485395e-05, 'total_loss': -0.03544542988500134, 'approx_kl': 0.03393387608230114, 'clip_fraction': 0.1432291679084301, 'grad_norm': 6.368802547454834}
2022-12-29 12:25:43.055 DEBUG: Early stopping at step 6 for reaching max KL.
2022-12-29 12:25:43.055 INFO: Optimization: policy loss=-0.013, vf loss=0.000, entropy loss=-0.023, total loss=-0.035, num steps=6
2022-12-29 12:25:43.055 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:25:43.725 INFO: Evaluation rollout: return=0.508 (0.0), episode length=3.0
2022-12-29 12:25:43.726 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:25:43.728 DEBUG: Deleting old model: runs/H2O/models/H2O_run-1_steps-11016.model
2022-12-29 12:25:43.733 DEBUG: Saving model: runs/H2O/models/H2O_run-1_steps-13176.model
2022-12-29 12:25:43.762 INFO: Iteration: 61/137, steps: 13176
2022-12-29 12:26:32.920 INFO: Training rollout: return=0.461 (0.1), episode length=3.0
2022-12-29 12:26:32.922 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:26:32.925 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-13176_train.pkl
2022-12-29 12:26:33.666 DEBUG: Taking gradient step
2022-12-29 12:26:33.676 DEBUG: Loss 0: {'policy_loss': -0.03137991960438836, 'entropy_loss': -0.0243960521183908, 'vf_loss': 5.0587119163496625e-05, 'total_loss': -0.05572538460361566, 'approx_kl': -1.0205742029256726e-08, 'clip_fraction': 0.0, 'grad_norm': 9.534622192382812}
2022-12-29 12:26:34.413 DEBUG: Taking gradient step
2022-12-29 12:26:34.422 DEBUG: Loss 1: {'policy_loss': -0.022327868149843354, 'entropy_loss': -0.02401072857901454, 'vf_loss': 5.023412031779053e-05, 'total_loss': -0.0462883626085401, 'approx_kl': 0.004208377249597106, 'clip_fraction': 0.049479166977107525, 'grad_norm': 8.740230560302734}
2022-12-29 12:26:35.181 DEBUG: Taking gradient step
2022-12-29 12:26:35.190 DEBUG: Loss 2: {'policy_loss': 0.02360671919000349, 'entropy_loss': -0.02395541686564684, 'vf_loss': 4.680836517456206e-05, 'total_loss': -0.0003018893104687857, 'approx_kl': 0.015188310295343399, 'clip_fraction': 0.1315104179084301, 'grad_norm': 10.482671737670898}
2022-12-29 12:26:35.912 DEBUG: Taking gradient step
2022-12-29 12:26:35.922 DEBUG: Loss 3: {'policy_loss': -0.036883827512926806, 'entropy_loss': -0.02427548449486494, 'vf_loss': 4.859163926694905e-05, 'total_loss': -0.06111072036852481, 'approx_kl': 0.017872838769108057, 'clip_fraction': 0.14322916697710752, 'grad_norm': 9.545185089111328}
2022-12-29 12:26:36.643 DEBUG: Taking gradient step
2022-12-29 12:26:36.653 DEBUG: Loss 4: {'policy_loss': -0.1023573608344938, 'entropy_loss': -0.02483881078660488, 'vf_loss': 5.035875213670606e-05, 'total_loss': -0.12714581286896195, 'approx_kl': 0.01930234022438526, 'clip_fraction': 0.13411458395421505, 'grad_norm': 8.248396873474121}
2022-12-29 12:26:37.395 DEBUG: Taking gradient step
2022-12-29 12:26:37.404 DEBUG: Loss 5: {'policy_loss': 0.017753697222361958, 'entropy_loss': -0.024620302952826023, 'vf_loss': 4.406626373002974e-05, 'total_loss': -0.006822539466734032, 'approx_kl': 0.012206417071865872, 'clip_fraction': 0.07552083395421505, 'grad_norm': 9.32369613647461}
2022-12-29 12:26:38.110 DEBUG: Taking gradient step
2022-12-29 12:26:38.120 DEBUG: Loss 6: {'policy_loss': -0.0005693095887942968, 'entropy_loss': -0.024387676268815994, 'vf_loss': 4.461287546444146e-05, 'total_loss': -0.02491237298214585, 'approx_kl': 0.012390698248054832, 'clip_fraction': 0.049479166977107525, 'grad_norm': 4.289475917816162}
2022-12-29 12:26:38.825 DEBUG: Taking gradient step
2022-12-29 12:26:38.835 DEBUG: Loss 7: {'policy_loss': 0.020454024130513507, 'entropy_loss': -0.023254919331520796, 'vf_loss': 4.248942892786306e-05, 'total_loss': -0.0027584057720794267, 'approx_kl': 0.011457372223958373, 'clip_fraction': 0.0950520858168602, 'grad_norm': 7.226931571960449}
2022-12-29 12:26:39.534 DEBUG: Taking gradient step
2022-12-29 12:26:39.543 DEBUG: Loss 8: {'policy_loss': 0.025936277024573767, 'entropy_loss': -0.02366494946181774, 'vf_loss': 4.1264230384353965e-05, 'total_loss': 0.0023125917931403825, 'approx_kl': 0.015465583885088563, 'clip_fraction': 0.1575520858168602, 'grad_norm': 9.747817993164062}
2022-12-29 12:26:40.262 DEBUG: Taking gradient step
2022-12-29 12:26:40.272 DEBUG: Loss 9: {'policy_loss': 0.013169911006182113, 'entropy_loss': -0.02327420935034752, 'vf_loss': 4.129309391347826e-05, 'total_loss': -0.010063005250251927, 'approx_kl': 0.01340328250080347, 'clip_fraction': 0.1627604179084301, 'grad_norm': 8.691762924194336}
2022-12-29 12:26:40.272 INFO: Optimization: policy loss=0.013, vf loss=0.000, entropy loss=-0.023, total loss=-0.010, num steps=10
2022-12-29 12:26:40.272 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:26:40.981 INFO: Evaluation rollout: return=0.509 (0.0), episode length=3.0
2022-12-29 12:26:40.982 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:26:40.984 INFO: Iteration: 62/137, steps: 13392
2022-12-29 12:27:30.972 INFO: Training rollout: return=0.466 (0.0), episode length=3.0
2022-12-29 12:27:30.974 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:27:30.977 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-13392_train.pkl
2022-12-29 12:27:31.694 DEBUG: Taking gradient step
2022-12-29 12:27:31.707 DEBUG: Loss 0: {'policy_loss': 0.03882092963358465, 'entropy_loss': -0.024268309120088816, 'vf_loss': 3.9514245704127334e-05, 'total_loss': 0.014592134759199953, 'approx_kl': -4.181250368162637e-08, 'clip_fraction': 0.0, 'grad_norm': 4.496578216552734}
2022-12-29 12:27:32.436 DEBUG: Taking gradient step
2022-12-29 12:27:32.446 DEBUG: Loss 1: {'policy_loss': 0.029598396913586424, 'entropy_loss': -0.02295622369274497, 'vf_loss': 3.9706832667816576e-05, 'total_loss': 0.006681880053509268, 'approx_kl': 0.0019413711852394044, 'clip_fraction': 0.00390625, 'grad_norm': 4.0745954513549805}
2022-12-29 12:27:33.146 DEBUG: Taking gradient step
2022-12-29 12:27:33.156 DEBUG: Loss 2: {'policy_loss': -0.003056686702112309, 'entropy_loss': -0.023672285955399275, 'vf_loss': 4.008149343187719e-05, 'total_loss': -0.026688891164079707, 'approx_kl': 0.0032872699666768312, 'clip_fraction': 0.07421875, 'grad_norm': 10.724967956542969}
2022-12-29 12:27:33.854 DEBUG: Taking gradient step
2022-12-29 12:27:33.863 DEBUG: Loss 3: {'policy_loss': 0.019950765701181265, 'entropy_loss': -0.022786072455346584, 'vf_loss': 3.805953038502414e-05, 'total_loss': -0.0027972472237802956, 'approx_kl': 0.015023485058918595, 'clip_fraction': 0.06770833395421505, 'grad_norm': 2.5998027324676514}
2022-12-29 12:27:34.599 DEBUG: Taking gradient step
2022-12-29 12:27:34.608 DEBUG: Loss 4: {'policy_loss': -0.002407370251243767, 'entropy_loss': -0.021892314311116934, 'vf_loss': 3.882901025130304e-05, 'total_loss': -0.02426085555210939, 'approx_kl': 0.011992959538474679, 'clip_fraction': 0.1328125, 'grad_norm': 12.426705360412598}
2022-12-29 12:27:35.329 DEBUG: Taking gradient step
2022-12-29 12:27:35.339 DEBUG: Loss 5: {'policy_loss': 0.0017128841302205544, 'entropy_loss': -0.0229685646481812, 'vf_loss': 3.723861171623748e-05, 'total_loss': -0.021218441906244407, 'approx_kl': 0.013634213712066412, 'clip_fraction': 0.11328125, 'grad_norm': 4.664065361022949}
2022-12-29 12:27:36.050 DEBUG: Taking gradient step
2022-12-29 12:27:36.059 DEBUG: Loss 6: {'policy_loss': -0.05246675678532195, 'entropy_loss': -0.02274996880441904, 'vf_loss': 3.8255105224669885e-05, 'total_loss': -0.07517847048451631, 'approx_kl': 0.00602240115404129, 'clip_fraction': 0.09895833395421505, 'grad_norm': 1.8785974979400635}
2022-12-29 12:27:36.767 DEBUG: Taking gradient step
2022-12-29 12:27:36.778 DEBUG: Loss 7: {'policy_loss': -0.010694103081119143, 'entropy_loss': -0.022790368646383286, 'vf_loss': 3.6315876293397214e-05, 'total_loss': -0.033448155851209034, 'approx_kl': 0.0061833091313019395, 'clip_fraction': 0.12630208395421505, 'grad_norm': 4.2931904792785645}
2022-12-29 12:27:37.499 DEBUG: Taking gradient step
2022-12-29 12:27:37.508 DEBUG: Loss 8: {'policy_loss': -0.0006035649875224692, 'entropy_loss': -0.022312377579510212, 'vf_loss': 3.485626186619536e-05, 'total_loss': -0.022881086305166484, 'approx_kl': 0.005640515126287937, 'clip_fraction': 0.1627604179084301, 'grad_norm': 4.7269158363342285}
2022-12-29 12:27:38.201 DEBUG: Taking gradient step
2022-12-29 12:27:38.210 DEBUG: Loss 9: {'policy_loss': -0.0259543270234462, 'entropy_loss': -0.0222382303327322, 'vf_loss': 3.506374990436189e-05, 'total_loss': -0.048157493606274034, 'approx_kl': 0.004662653780542314, 'clip_fraction': 0.1471354179084301, 'grad_norm': 4.668651580810547}
2022-12-29 12:27:38.210 INFO: Optimization: policy loss=-0.026, vf loss=0.000, entropy loss=-0.022, total loss=-0.048, num steps=10
2022-12-29 12:27:38.211 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:27:38.898 INFO: Evaluation rollout: return=0.506 (0.0), episode length=3.0
2022-12-29 12:27:38.899 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:27:38.900 INFO: Iteration: 63/137, steps: 13608
2022-12-29 12:28:02.964 DEBUG: Atoms are too close
2022-12-29 12:28:27.536 INFO: Training rollout: return=0.188 (2.4), episode length=3.0
2022-12-29 12:28:27.538 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:28:27.541 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-13608_train.pkl
2022-12-29 12:28:28.376 DEBUG: Taking gradient step
2022-12-29 12:28:28.387 DEBUG: Loss 0: {'policy_loss': -0.019015827326637175, 'entropy_loss': -0.022455852944403887, 'vf_loss': 0.004748326829855768, 'total_loss': -0.03672335344118529, 'approx_kl': -2.8133703366961527e-08, 'clip_fraction': 0.0, 'grad_norm': 13.076288223266602}
2022-12-29 12:28:29.105 DEBUG: Taking gradient step
2022-12-29 12:28:29.119 DEBUG: Loss 1: {'policy_loss': 0.029033110869395973, 'entropy_loss': -0.022614893037825823, 'vf_loss': 0.007346246322527951, 'total_loss': 0.0137644641540981, 'approx_kl': 0.005541189864743501, 'clip_fraction': 0.015625, 'grad_norm': 2.7523045539855957}
2022-12-29 12:28:29.876 DEBUG: Taking gradient step
2022-12-29 12:28:29.885 DEBUG: Loss 2: {'policy_loss': 0.029561735647055148, 'entropy_loss': -0.02226567128673196, 'vf_loss': 0.007340293718857318, 'total_loss': 0.014636358079180505, 'approx_kl': 0.012347521260380745, 'clip_fraction': 0.07421875, 'grad_norm': 1.2808955907821655}
2022-12-29 12:28:30.573 DEBUG: Taking gradient step
2022-12-29 12:28:30.583 DEBUG: Loss 3: {'policy_loss': 0.02843816252070969, 'entropy_loss': -0.022056044079363346, 'vf_loss': 0.007343662638762011, 'total_loss': 0.01372578108010835, 'approx_kl': 0.023973919451236725, 'clip_fraction': 0.12890625, 'grad_norm': 3.1340010166168213}
2022-12-29 12:28:31.272 DEBUG: Taking gradient step
2022-12-29 12:28:31.283 DEBUG: Loss 4: {'policy_loss': -0.027136793075894262, 'entropy_loss': -0.022993050049990416, 'vf_loss': 0.004743674541218933, 'total_loss': -0.04538616858466574, 'approx_kl': 0.02309208200313151, 'clip_fraction': 0.1666666679084301, 'grad_norm': 0.9669926762580872}
2022-12-29 12:28:31.975 DEBUG: Early stopping at step 5 for reaching max KL.
2022-12-29 12:28:31.975 INFO: Optimization: policy loss=-0.027, vf loss=0.005, entropy loss=-0.023, total loss=-0.045, num steps=5
2022-12-29 12:28:31.975 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:28:32.709 INFO: Evaluation rollout: return=0.500 (0.0), episode length=3.0
2022-12-29 12:28:32.710 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:28:32.712 INFO: Iteration: 64/137, steps: 13824
2022-12-29 12:29:22.110 INFO: Training rollout: return=0.459 (0.1), episode length=3.0
2022-12-29 12:29:22.112 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:29:22.115 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-13824_train.pkl
2022-12-29 12:29:22.809 DEBUG: Taking gradient step
2022-12-29 12:29:22.818 DEBUG: Loss 0: {'policy_loss': 0.03029085635898191, 'entropy_loss': -0.02232964662835002, 'vf_loss': 3.189573759599269e-05, 'total_loss': 0.007993105468227887, 'approx_kl': -3.090826794505119e-08, 'clip_fraction': 0.0, 'grad_norm': 8.434326171875}
2022-12-29 12:29:23.526 DEBUG: Taking gradient step
2022-12-29 12:29:23.536 DEBUG: Loss 1: {'policy_loss': 0.0030279518326399657, 'entropy_loss': -0.0226206099614501, 'vf_loss': 3.494767387166824e-05, 'total_loss': -0.019557710454938464, 'approx_kl': 0.0030665493104606867, 'clip_fraction': 0.01953125, 'grad_norm': 13.454156875610352}
2022-12-29 12:29:24.238 DEBUG: Taking gradient step
2022-12-29 12:29:24.247 DEBUG: Loss 2: {'policy_loss': -0.03636739869754815, 'entropy_loss': -0.02335109654814005, 'vf_loss': 3.710065887236855e-05, 'total_loss': -0.05968139458681583, 'approx_kl': 0.01267457811627537, 'clip_fraction': 0.1614583358168602, 'grad_norm': 12.155529022216797}
2022-12-29 12:29:24.983 DEBUG: Taking gradient step
2022-12-29 12:29:24.996 DEBUG: Loss 3: {'policy_loss': -0.02283076472321802, 'entropy_loss': -0.022263411432504654, 'vf_loss': 3.833294849913198e-05, 'total_loss': -0.04505584320722354, 'approx_kl': 0.016940058558247983, 'clip_fraction': 0.2213541679084301, 'grad_norm': 14.780656814575195}
2022-12-29 12:29:25.707 DEBUG: Taking gradient step
2022-12-29 12:29:25.716 DEBUG: Loss 4: {'policy_loss': 0.014782075557964366, 'entropy_loss': -0.021527606062591076, 'vf_loss': 3.768770769476092e-05, 'total_loss': -0.006707842796931944, 'approx_kl': 0.0408866535872221, 'clip_fraction': 0.2630208358168602, 'grad_norm': 11.87275218963623}
2022-12-29 12:29:26.479 DEBUG: Early stopping at step 5 for reaching max KL.
2022-12-29 12:29:26.479 INFO: Optimization: policy loss=0.015, vf loss=0.000, entropy loss=-0.022, total loss=-0.007, num steps=5
2022-12-29 12:29:26.479 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:29:27.308 INFO: Evaluation rollout: return=0.497 (0.0), episode length=3.0
2022-12-29 12:29:27.308 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:29:27.310 INFO: Iteration: 65/137, steps: 14040
2022-12-29 12:30:16.442 INFO: Training rollout: return=0.466 (0.0), episode length=3.0
2022-12-29 12:30:16.444 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:30:16.447 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-14040_train.pkl
2022-12-29 12:30:17.189 DEBUG: Taking gradient step
2022-12-29 12:30:17.198 DEBUG: Loss 0: {'policy_loss': -0.03938716861222939, 'entropy_loss': -0.022615822032094002, 'vf_loss': 3.946338420102652e-05, 'total_loss': -0.061963527260122366, 'approx_kl': 2.7978482364243717e-08, 'clip_fraction': 0.0, 'grad_norm': 6.8730950355529785}
2022-12-29 12:30:17.904 DEBUG: Taking gradient step
2022-12-29 12:30:17.914 DEBUG: Loss 1: {'policy_loss': -0.03775859454009776, 'entropy_loss': -0.022184827830642462, 'vf_loss': 3.9967457501221164e-05, 'total_loss': -0.05990345491323899, 'approx_kl': 0.004719052463769913, 'clip_fraction': 0.014322916977107525, 'grad_norm': 7.722714424133301}
2022-12-29 12:30:18.618 DEBUG: Taking gradient step
2022-12-29 12:30:18.627 DEBUG: Loss 2: {'policy_loss': 0.021560475579594375, 'entropy_loss': -0.021928617730736732, 'vf_loss': 3.874002767950542e-05, 'total_loss': -0.00032940212346285747, 'approx_kl': 0.018006020691245794, 'clip_fraction': 0.07291666697710752, 'grad_norm': 3.3121705055236816}
2022-12-29 12:30:19.318 DEBUG: Taking gradient step
2022-12-29 12:30:19.328 DEBUG: Loss 3: {'policy_loss': -0.024726050679350978, 'entropy_loss': -0.021386966109275818, 'vf_loss': 4.075521392291313e-05, 'total_loss': -0.046072261574703885, 'approx_kl': 0.025466205552220345, 'clip_fraction': 0.1653645858168602, 'grad_norm': 7.733469486236572}
2022-12-29 12:30:20.024 DEBUG: Taking gradient step
2022-12-29 12:30:20.033 DEBUG: Loss 4: {'policy_loss': -0.005335791618147399, 'entropy_loss': -0.022173830308020115, 'vf_loss': 4.017695755966962e-05, 'total_loss': -0.027469444968607846, 'approx_kl': 0.04180343495681882, 'clip_fraction': 0.2369791716337204, 'grad_norm': 6.505187511444092}
2022-12-29 12:30:20.743 DEBUG: Taking gradient step
2022-12-29 12:30:20.752 DEBUG: Loss 5: {'policy_loss': -0.026431403033626656, 'entropy_loss': -0.02090776851400733, 'vf_loss': 4.105963398953196e-05, 'total_loss': -0.04729811191364445, 'approx_kl': 0.03386007959488779, 'clip_fraction': 0.2486979216337204, 'grad_norm': 11.223496437072754}
2022-12-29 12:30:21.457 DEBUG: Taking gradient step
2022-12-29 12:30:21.466 DEBUG: Loss 6: {'policy_loss': 0.029519358498441967, 'entropy_loss': -0.01892016944475472, 'vf_loss': 3.9689259509588154e-05, 'total_loss': 0.010638878313196841, 'approx_kl': 0.04423374682664871, 'clip_fraction': 0.2109375, 'grad_norm': 6.561595916748047}
2022-12-29 12:30:22.154 DEBUG: Taking gradient step
2022-12-29 12:30:22.163 DEBUG: Loss 7: {'policy_loss': -0.07175875170806446, 'entropy_loss': -0.020944117568433285, 'vf_loss': 4.199429829661838e-05, 'total_loss': -0.09266087497820114, 'approx_kl': 0.04228953132405877, 'clip_fraction': 0.11979166697710752, 'grad_norm': 5.488365650177002}
2022-12-29 12:30:22.844 DEBUG: Taking gradient step
2022-12-29 12:30:22.853 DEBUG: Loss 8: {'policy_loss': -0.05752594556651708, 'entropy_loss': -0.02116244798526168, 'vf_loss': 4.120379233638882e-05, 'total_loss': -0.07864718975944238, 'approx_kl': 0.03640214912593365, 'clip_fraction': 0.1015625, 'grad_norm': 1.880908727645874}
2022-12-29 12:30:23.537 DEBUG: Early stopping at step 9 for reaching max KL.
2022-12-29 12:30:23.537 INFO: Optimization: policy loss=-0.058, vf loss=0.000, entropy loss=-0.021, total loss=-0.079, num steps=9
2022-12-29 12:30:23.538 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:30:24.268 INFO: Evaluation rollout: return=0.497 (0.0), episode length=3.0
2022-12-29 12:30:24.268 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:30:24.270 INFO: Iteration: 66/137, steps: 14256
2022-12-29 12:31:13.499 INFO: Training rollout: return=0.471 (0.0), episode length=3.0
2022-12-29 12:31:13.500 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:31:13.503 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-14256_train.pkl
2022-12-29 12:31:14.248 DEBUG: Taking gradient step
2022-12-29 12:31:14.258 DEBUG: Loss 0: {'policy_loss': 0.015292908910457828, 'entropy_loss': -0.02016699966043234, 'vf_loss': 3.7192355801853365e-05, 'total_loss': -0.0048368983941726625, 'approx_kl': 3.26641993453336e-08, 'clip_fraction': 0.0, 'grad_norm': 4.583917140960693}
2022-12-29 12:31:14.970 DEBUG: Taking gradient step
2022-12-29 12:31:14.979 DEBUG: Loss 1: {'policy_loss': 0.04514264413537974, 'entropy_loss': -0.020877433940768242, 'vf_loss': 3.541671333454161e-05, 'total_loss': 0.024300626907946044, 'approx_kl': 0.009763057343661785, 'clip_fraction': 0.00390625, 'grad_norm': 4.968636989593506}
2022-12-29 12:31:15.671 DEBUG: Taking gradient step
2022-12-29 12:31:15.680 DEBUG: Loss 2: {'policy_loss': 0.0020777850063610323, 'entropy_loss': -0.019684510305523872, 'vf_loss': 3.543019178459544e-05, 'total_loss': -0.017571295107378246, 'approx_kl': 0.016944478586083278, 'clip_fraction': 0.1197916679084301, 'grad_norm': 11.690024375915527}
2022-12-29 12:31:16.417 DEBUG: Taking gradient step
2022-12-29 12:31:16.426 DEBUG: Loss 3: {'policy_loss': 0.014686086088721996, 'entropy_loss': -0.02133169397711754, 'vf_loss': 3.369713187135852e-05, 'total_loss': -0.006611910756524186, 'approx_kl': 0.041128074983134866, 'clip_fraction': 0.1614583358168602, 'grad_norm': 6.496244430541992}
2022-12-29 12:31:17.155 DEBUG: Taking gradient step
2022-12-29 12:31:17.164 DEBUG: Loss 4: {'policy_loss': -0.04377857468188012, 'entropy_loss': -0.020770946517586708, 'vf_loss': 3.4808712497305854e-05, 'total_loss': -0.06451471248696954, 'approx_kl': 0.023547119460999966, 'clip_fraction': 0.1783854179084301, 'grad_norm': 9.55473518371582}
2022-12-29 12:31:17.858 DEBUG: Taking gradient step
2022-12-29 12:31:17.868 DEBUG: Loss 5: {'policy_loss': -0.004872898637565428, 'entropy_loss': -0.020375674590468407, 'vf_loss': 3.261346597788434e-05, 'total_loss': -0.025215959762055946, 'approx_kl': 0.03577005956321955, 'clip_fraction': 0.1731770858168602, 'grad_norm': 7.181197166442871}
2022-12-29 12:31:18.558 DEBUG: Taking gradient step
2022-12-29 12:31:18.569 DEBUG: Loss 6: {'policy_loss': -0.032110567335382714, 'entropy_loss': -0.020921017043292522, 'vf_loss': 3.222135520349612e-05, 'total_loss': -0.05299936302347174, 'approx_kl': 0.03080062149092555, 'clip_fraction': 0.1497395858168602, 'grad_norm': 5.205795764923096}
2022-12-29 12:31:19.262 DEBUG: Taking gradient step
2022-12-29 12:31:19.271 DEBUG: Loss 7: {'policy_loss': -0.01605255351386859, 'entropy_loss': -0.02121672546491027, 'vf_loss': 3.069930123950549e-05, 'total_loss': -0.03723857967753935, 'approx_kl': 0.013729515485465527, 'clip_fraction': 0.1328125, 'grad_norm': 7.08432149887085}
2022-12-29 12:31:19.997 DEBUG: Taking gradient step
2022-12-29 12:31:20.011 DEBUG: Loss 8: {'policy_loss': -0.02207851530453069, 'entropy_loss': -0.02138004871085286, 'vf_loss': 3.0134424945074056e-05, 'total_loss': -0.04342842959043848, 'approx_kl': 0.011048021726310253, 'clip_fraction': 0.125, 'grad_norm': 7.989808082580566}
2022-12-29 12:31:20.791 DEBUG: Taking gradient step
2022-12-29 12:31:20.800 DEBUG: Loss 9: {'policy_loss': -0.018080451125288784, 'entropy_loss': -0.02127480087801814, 'vf_loss': 2.838171455578782e-05, 'total_loss': -0.039326870288751134, 'approx_kl': 0.009867227345239371, 'clip_fraction': 0.09505208395421505, 'grad_norm': 5.401713848114014}
2022-12-29 12:31:20.801 INFO: Optimization: policy loss=-0.018, vf loss=0.000, entropy loss=-0.021, total loss=-0.039, num steps=10
2022-12-29 12:31:20.801 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:31:21.507 INFO: Evaluation rollout: return=0.500 (0.0), episode length=3.0
2022-12-29 12:31:21.508 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:31:21.510 INFO: Iteration: 67/137, steps: 14472
2022-12-29 12:31:40.597 DEBUG: There is a single atom floating around
2022-12-29 12:32:10.354 INFO: Training rollout: return=0.187 (2.4), episode length=3.0
2022-12-29 12:32:10.356 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:32:10.358 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-14472_train.pkl
2022-12-29 12:32:11.108 DEBUG: Taking gradient step
2022-12-29 12:32:11.118 DEBUG: Loss 0: {'policy_loss': -0.015783862142929567, 'entropy_loss': -0.021361746825277805, 'vf_loss': 0.003265869293657518, 'total_loss': -0.03387973967454985, 'approx_kl': 1.7578713595867157e-08, 'clip_fraction': 0.0, 'grad_norm': 6.402438640594482}
2022-12-29 12:32:11.838 DEBUG: Taking gradient step
2022-12-29 12:32:11.848 DEBUG: Loss 1: {'policy_loss': 0.03552209117436689, 'entropy_loss': -0.020446349401026964, 'vf_loss': 0.005992316169496844, 'total_loss': 0.021068057942836775, 'approx_kl': 0.0029171081259846687, 'clip_fraction': 0.0, 'grad_norm': 15.171640396118164}
2022-12-29 12:32:12.544 DEBUG: Taking gradient step
2022-12-29 12:32:12.559 DEBUG: Loss 2: {'policy_loss': -0.02545583354121757, 'entropy_loss': -0.020997490268200636, 'vf_loss': 0.003265431226332118, 'total_loss': -0.043187892583086085, 'approx_kl': 0.009075898211449385, 'clip_fraction': 0.057291666977107525, 'grad_norm': 0.4079463481903076}
2022-12-29 12:32:13.328 DEBUG: Taking gradient step
2022-12-29 12:32:13.338 DEBUG: Loss 3: {'policy_loss': -0.021483003420014433, 'entropy_loss': -0.02097325073555112, 'vf_loss': 0.003259272737244758, 'total_loss': -0.03919698141832079, 'approx_kl': 0.01918464689515531, 'clip_fraction': 0.11328125, 'grad_norm': 0.5626360177993774}
2022-12-29 12:32:14.065 DEBUG: Taking gradient step
2022-12-29 12:32:14.079 DEBUG: Loss 4: {'policy_loss': -0.023716699415977843, 'entropy_loss': -0.021249018143862486, 'vf_loss': 0.0032542832778608213, 'total_loss': -0.04171143428197951, 'approx_kl': 0.029473673552274704, 'clip_fraction': 0.1432291679084301, 'grad_norm': 0.7976454496383667}
2022-12-29 12:32:14.807 DEBUG: Taking gradient step
2022-12-29 12:32:14.817 DEBUG: Loss 5: {'policy_loss': -0.02164608259784163, 'entropy_loss': -0.020758213009685278, 'vf_loss': 0.0032465340591333585, 'total_loss': -0.03915776154839355, 'approx_kl': 0.015607699286192656, 'clip_fraction': 0.1705729216337204, 'grad_norm': 0.492066890001297}
2022-12-29 12:32:15.556 DEBUG: Taking gradient step
2022-12-29 12:32:15.565 DEBUG: Loss 6: {'policy_loss': 0.04329640452760926, 'entropy_loss': -0.022260283585637808, 'vf_loss': 0.005906197744576257, 'total_loss': 0.0269423186865477, 'approx_kl': 0.022785433568060398, 'clip_fraction': 0.21484375, 'grad_norm': 0.9654278755187988}
2022-12-29 12:32:16.274 DEBUG: Taking gradient step
2022-12-29 12:32:16.283 DEBUG: Loss 7: {'policy_loss': 0.09754662524612612, 'entropy_loss': -0.022159602027386427, 'vf_loss': 0.008576683134270006, 'total_loss': 0.0839637063530097, 'approx_kl': 0.039079644018784165, 'clip_fraction': 0.2421875, 'grad_norm': 0.9848398566246033}
2022-12-29 12:32:17.012 DEBUG: Taking gradient step
2022-12-29 12:32:17.023 DEBUG: Loss 8: {'policy_loss': -0.02571123856471149, 'entropy_loss': -0.022116214968264103, 'vf_loss': 0.0032266376039902724, 'total_loss': -0.04460081592898532, 'approx_kl': 0.030274931341409683, 'clip_fraction': 0.18098958395421505, 'grad_norm': 0.4301592707633972}
2022-12-29 12:32:17.700 DEBUG: Taking gradient step
2022-12-29 12:32:17.709 DEBUG: Loss 9: {'policy_loss': -0.024328286127709306, 'entropy_loss': -0.022604795638471842, 'vf_loss': 0.003221738420821515, 'total_loss': -0.043711343345359636, 'approx_kl': 0.02861931110965088, 'clip_fraction': 0.1731770858168602, 'grad_norm': 0.4702252447605133}
2022-12-29 12:32:17.710 INFO: Optimization: policy loss=-0.024, vf loss=0.003, entropy loss=-0.023, total loss=-0.044, num steps=10
2022-12-29 12:32:17.710 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:32:18.412 INFO: Evaluation rollout: return=0.500 (0.0), episode length=3.0
2022-12-29 12:32:18.412 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:32:18.414 INFO: Iteration: 68/137, steps: 14688
2022-12-29 12:33:07.172 INFO: Training rollout: return=0.457 (0.0), episode length=3.0
2022-12-29 12:33:07.174 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:33:07.176 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-14688_train.pkl
2022-12-29 12:33:07.924 DEBUG: Taking gradient step
2022-12-29 12:33:07.934 DEBUG: Loss 0: {'policy_loss': -0.004002541150406819, 'entropy_loss': -0.023513709660619497, 'vf_loss': 3.493112162789574e-05, 'total_loss': -0.02748131968939842, 'approx_kl': 4.0745362639427185e-10, 'clip_fraction': 0.0, 'grad_norm': 9.575300216674805}
2022-12-29 12:33:08.659 DEBUG: Taking gradient step
2022-12-29 12:33:08.669 DEBUG: Loss 1: {'policy_loss': -0.029985041850160484, 'entropy_loss': -0.023545638658106327, 'vf_loss': 3.9361017058834723e-05, 'total_loss': -0.05349131949120797, 'approx_kl': 0.0027154333074577153, 'clip_fraction': 0.00390625, 'grad_norm': 8.684843063354492}
2022-12-29 12:33:09.368 DEBUG: Taking gradient step
2022-12-29 12:33:09.377 DEBUG: Loss 2: {'policy_loss': -0.04365075870338689, 'entropy_loss': -0.023643622640520334, 'vf_loss': 4.435870834273253e-05, 'total_loss': -0.06725002263556448, 'approx_kl': 0.01170189119875431, 'clip_fraction': 0.06770833395421505, 'grad_norm': 7.611988544464111}
2022-12-29 12:33:10.103 DEBUG: Taking gradient step
2022-12-29 12:33:10.113 DEBUG: Loss 3: {'policy_loss': 0.029736327447654184, 'entropy_loss': -0.02345459396019578, 'vf_loss': 4.160033731914815e-05, 'total_loss': 0.006323333824777545, 'approx_kl': 0.01759537571342662, 'clip_fraction': 0.1236979179084301, 'grad_norm': 7.130340576171875}
2022-12-29 12:33:10.836 DEBUG: Taking gradient step
2022-12-29 12:33:10.845 DEBUG: Loss 4: {'policy_loss': -0.014212663068175129, 'entropy_loss': -0.02391963731497526, 'vf_loss': 4.6338643726916406e-05, 'total_loss': -0.03808596173942347, 'approx_kl': 0.04232905968092382, 'clip_fraction': 0.1888020858168602, 'grad_norm': 4.56011962890625}
2022-12-29 12:33:11.546 DEBUG: Taking gradient step
2022-12-29 12:33:11.560 DEBUG: Loss 5: {'policy_loss': -0.03797030337328939, 'entropy_loss': -0.024146450217813253, 'vf_loss': 4.916208408258089e-05, 'total_loss': -0.06206759150702006, 'approx_kl': 0.043638926930725574, 'clip_fraction': 0.2395833358168602, 'grad_norm': 4.421372890472412}
2022-12-29 12:33:12.286 DEBUG: Early stopping at step 6 for reaching max KL.
2022-12-29 12:33:12.286 INFO: Optimization: policy loss=-0.038, vf loss=0.000, entropy loss=-0.024, total loss=-0.062, num steps=6
2022-12-29 12:33:12.287 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:33:13.051 INFO: Evaluation rollout: return=0.505 (0.0), episode length=3.0
2022-12-29 12:33:13.052 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:33:13.054 INFO: Iteration: 69/137, steps: 14904
2022-12-29 12:34:02.166 INFO: Training rollout: return=0.474 (0.0), episode length=3.0
2022-12-29 12:34:02.168 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:34:02.170 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-14904_train.pkl
2022-12-29 12:34:02.908 DEBUG: Taking gradient step
2022-12-29 12:34:02.922 DEBUG: Loss 0: {'policy_loss': -0.01951852449445127, 'entropy_loss': -0.023562938440591097, 'vf_loss': 5.493573883604931e-05, 'total_loss': -0.04302652719620632, 'approx_kl': 4.5479586319174814e-08, 'clip_fraction': 0.0, 'grad_norm': 4.4526214599609375}
2022-12-29 12:34:03.711 DEBUG: Taking gradient step
2022-12-29 12:34:03.722 DEBUG: Loss 1: {'policy_loss': 0.00046193087324862374, 'entropy_loss': -0.022970974445343018, 'vf_loss': 5.5401432130536304e-05, 'total_loss': -0.022453642139963852, 'approx_kl': 0.008899937150999904, 'clip_fraction': 0.026041666977107525, 'grad_norm': 3.4219653606414795}
2022-12-29 12:34:04.415 DEBUG: Taking gradient step
2022-12-29 12:34:04.424 DEBUG: Loss 2: {'policy_loss': -0.011134679468946966, 'entropy_loss': -0.020930326310917735, 'vf_loss': 6.379819422703764e-05, 'total_loss': -0.03200120758563767, 'approx_kl': 0.016901808470720425, 'clip_fraction': 0.10677083395421505, 'grad_norm': 2.0845563411712646}
2022-12-29 12:34:05.127 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-29 12:34:05.128 INFO: Optimization: policy loss=-0.011, vf loss=0.000, entropy loss=-0.021, total loss=-0.032, num steps=3
2022-12-29 12:34:05.128 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:34:05.822 INFO: Evaluation rollout: return=0.508 (0.0), episode length=3.0
2022-12-29 12:34:05.823 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:34:05.825 INFO: Iteration: 70/137, steps: 15120
2022-12-29 12:34:54.359 INFO: Training rollout: return=0.482 (0.0), episode length=3.0
2022-12-29 12:34:54.361 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:34:54.363 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-15120_train.pkl
2022-12-29 12:34:55.095 DEBUG: Taking gradient step
2022-12-29 12:34:55.106 DEBUG: Loss 0: {'policy_loss': -0.02609438929099946, 'entropy_loss': -0.021737294271588326, 'vf_loss': 6.3049277520372e-05, 'total_loss': -0.04776863428506741, 'approx_kl': -1.56772639314795e-08, 'clip_fraction': 0.0, 'grad_norm': 3.171412944793701}
2022-12-29 12:34:55.807 DEBUG: Taking gradient step
2022-12-29 12:34:55.816 DEBUG: Loss 1: {'policy_loss': -0.008182554013500423, 'entropy_loss': -0.021130077075213194, 'vf_loss': 6.236598296734428e-05, 'total_loss': -0.02925026510574627, 'approx_kl': 0.007899657008238137, 'clip_fraction': 0.01171875, 'grad_norm': 4.725128650665283}
2022-12-29 12:34:56.563 DEBUG: Taking gradient step
2022-12-29 12:34:56.577 DEBUG: Loss 2: {'policy_loss': -0.007594893787877602, 'entropy_loss': -0.022436966188251972, 'vf_loss': 5.726501993416286e-05, 'total_loss': -0.029974594956195408, 'approx_kl': 0.027755726594477892, 'clip_fraction': 0.11848958395421505, 'grad_norm': 4.474094867706299}
2022-12-29 12:34:57.288 DEBUG: Taking gradient step
2022-12-29 12:34:57.298 DEBUG: Loss 3: {'policy_loss': 0.013547276565832957, 'entropy_loss': -0.022210235707461834, 'vf_loss': 5.638348996404671e-05, 'total_loss': -0.008606575651664831, 'approx_kl': 0.04436325654387474, 'clip_fraction': 0.2526041716337204, 'grad_norm': 7.0710906982421875}
2022-12-29 12:34:57.988 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-29 12:34:57.989 INFO: Optimization: policy loss=0.014, vf loss=0.000, entropy loss=-0.022, total loss=-0.009, num steps=4
2022-12-29 12:34:57.989 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:34:58.716 INFO: Evaluation rollout: return=0.511 (0.0), episode length=3.0
2022-12-29 12:34:58.717 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:34:58.718 DEBUG: Deleting old model: runs/H2O/models/H2O_run-1_steps-13176.model
2022-12-29 12:34:58.721 DEBUG: Saving model: runs/H2O/models/H2O_run-1_steps-15336.model
2022-12-29 12:34:58.750 INFO: Iteration: 71/137, steps: 15336
2022-12-29 12:35:46.796 INFO: Training rollout: return=0.469 (0.0), episode length=3.0
2022-12-29 12:35:46.797 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:35:46.800 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-15336_train.pkl
2022-12-29 12:35:47.564 DEBUG: Taking gradient step
2022-12-29 12:35:47.574 DEBUG: Loss 0: {'policy_loss': -0.019777816824616164, 'entropy_loss': -0.021247926633805037, 'vf_loss': 7.646729224947165e-05, 'total_loss': -0.04094927616617172, 'approx_kl': -2.0081643015146255e-08, 'clip_fraction': 0.0, 'grad_norm': 7.201051235198975}
2022-12-29 12:35:48.279 DEBUG: Taking gradient step
2022-12-29 12:35:48.289 DEBUG: Loss 1: {'policy_loss': 0.04507139645764485, 'entropy_loss': -0.02228476293385029, 'vf_loss': 6.67924387096639e-05, 'total_loss': 0.02285342596250424, 'approx_kl': -0.0017129192128777504, 'clip_fraction': 0.0, 'grad_norm': 7.482187271118164}
2022-12-29 12:35:48.990 DEBUG: Taking gradient step
2022-12-29 12:35:49.000 DEBUG: Loss 2: {'policy_loss': -0.06473538429738696, 'entropy_loss': -0.021479915361851454, 'vf_loss': 7.761669983329607e-05, 'total_loss': -0.0861376829594051, 'approx_kl': 0.0006052180542610586, 'clip_fraction': 0.0078125, 'grad_norm': 7.577760696411133}
2022-12-29 12:35:49.708 DEBUG: Taking gradient step
2022-12-29 12:35:49.717 DEBUG: Loss 3: {'policy_loss': -0.0046016239397026594, 'entropy_loss': -0.021507357247173786, 'vf_loss': 7.023383200265605e-05, 'total_loss': -0.026038747354873795, 'approx_kl': 0.007176958257332444, 'clip_fraction': 0.09635416697710752, 'grad_norm': 9.253003120422363}
2022-12-29 12:35:50.452 DEBUG: Taking gradient step
2022-12-29 12:35:50.462 DEBUG: Loss 4: {'policy_loss': -0.026500449897118045, 'entropy_loss': -0.021551480516791344, 'vf_loss': 7.088582070554015e-05, 'total_loss': -0.04798104459320385, 'approx_kl': 0.006936246063560247, 'clip_fraction': 0.1666666679084301, 'grad_norm': 6.359511375427246}
2022-12-29 12:35:51.174 DEBUG: Taking gradient step
2022-12-29 12:35:51.184 DEBUG: Loss 5: {'policy_loss': 0.02322613344152096, 'entropy_loss': -0.021754207089543343, 'vf_loss': 6.36997409881844e-05, 'total_loss': 0.0015356260929658, 'approx_kl': 0.015137598034925759, 'clip_fraction': 0.1796875, 'grad_norm': 5.827615737915039}
2022-12-29 12:35:51.895 DEBUG: Taking gradient step
2022-12-29 12:35:51.904 DEBUG: Loss 6: {'policy_loss': 0.008388280059212204, 'entropy_loss': -0.020917543675750494, 'vf_loss': 6.724541222774814e-05, 'total_loss': -0.012462018204310542, 'approx_kl': 0.026697802124544978, 'clip_fraction': 0.1640625, 'grad_norm': 3.7702078819274902}
2022-12-29 12:35:52.602 DEBUG: Taking gradient step
2022-12-29 12:35:52.611 DEBUG: Loss 7: {'policy_loss': -0.021543159121941203, 'entropy_loss': -0.022335323505103588, 'vf_loss': 6.497375890679795e-05, 'total_loss': -0.04381350886813799, 'approx_kl': 0.021536598447710276, 'clip_fraction': 0.10416666697710752, 'grad_norm': 5.844771862030029}
2022-12-29 12:35:53.328 DEBUG: Taking gradient step
2022-12-29 12:35:53.342 DEBUG: Loss 8: {'policy_loss': 0.06645731959292589, 'entropy_loss': -0.02241628710180521, 'vf_loss': 5.7398979495101e-05, 'total_loss': 0.044098431470615776, 'approx_kl': 0.03399486094713211, 'clip_fraction': 0.05208333395421505, 'grad_norm': 3.5785200595855713}
2022-12-29 12:35:54.107 DEBUG: Taking gradient step
2022-12-29 12:35:54.121 DEBUG: Loss 9: {'policy_loss': 0.025011706870946747, 'entropy_loss': -0.02179150888696313, 'vf_loss': 6.0512026889265465e-05, 'total_loss': 0.003280710010872885, 'approx_kl': 0.029072934295982122, 'clip_fraction': 0.05598958395421505, 'grad_norm': 3.6580874919891357}
2022-12-29 12:35:54.121 INFO: Optimization: policy loss=0.025, vf loss=0.000, entropy loss=-0.022, total loss=0.003, num steps=10
2022-12-29 12:35:54.122 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:35:54.829 INFO: Evaluation rollout: return=0.512 (0.0), episode length=3.0
2022-12-29 12:35:54.830 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:35:54.832 INFO: Iteration: 72/137, steps: 15552
2022-12-29 12:36:00.725 DEBUG: Atoms are too close
2022-12-29 12:36:01.848 DEBUG: Atoms are too close
2022-12-29 12:36:43.747 INFO: Training rollout: return=-0.099 (3.3), episode length=3.0
2022-12-29 12:36:43.749 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:36:43.751 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-15552_train.pkl
2022-12-29 12:36:44.503 DEBUG: Taking gradient step
2022-12-29 12:36:44.516 DEBUG: Loss 0: {'policy_loss': -0.0268382676712755, 'entropy_loss': -0.022309116553515196, 'vf_loss': 0.009453898694446412, 'total_loss': -0.03969348553034429, 'approx_kl': 3.321717212401154e-08, 'clip_fraction': 0.0, 'grad_norm': 8.551140785217285}
2022-12-29 12:36:45.284 DEBUG: Taking gradient step
2022-12-29 12:36:45.294 DEBUG: Loss 1: {'policy_loss': 0.1298576348901791, 'entropy_loss': -0.022828012704849243, 'vf_loss': 0.01998966890500316, 'total_loss': 0.12701929109033305, 'approx_kl': 0.005297007097397, 'clip_fraction': 0.0, 'grad_norm': 22.403024673461914}
2022-12-29 12:36:45.992 DEBUG: Taking gradient step
2022-12-29 12:36:46.001 DEBUG: Loss 2: {'policy_loss': 0.0039146130352956145, 'entropy_loss': -0.02374723134562373, 'vf_loss': 0.011992933512797213, 'total_loss': -0.007839684797530904, 'approx_kl': 0.00949464167933911, 'clip_fraction': 0.00390625, 'grad_norm': 8.76418685913086}
2022-12-29 12:36:46.733 DEBUG: Taking gradient step
2022-12-29 12:36:46.743 DEBUG: Loss 3: {'policy_loss': -0.03783829235233667, 'entropy_loss': -0.02407567761838436, 'vf_loss': 0.009450833896179603, 'total_loss': -0.05246313607454143, 'approx_kl': 0.020667268661782146, 'clip_fraction': 0.045572916977107525, 'grad_norm': 7.09788703918457}
2022-12-29 12:36:47.457 DEBUG: Taking gradient step
2022-12-29 12:36:47.467 DEBUG: Loss 4: {'policy_loss': -0.04142218539020589, 'entropy_loss': -0.023689041379839182, 'vf_loss': 0.009447211512071967, 'total_loss': -0.055664015257973105, 'approx_kl': 0.03236888814717531, 'clip_fraction': 0.11848958395421505, 'grad_norm': 1.6613013744354248}
2022-12-29 12:36:48.193 DEBUG: Taking gradient step
2022-12-29 12:36:48.202 DEBUG: Loss 5: {'policy_loss': -0.0014833632795214907, 'entropy_loss': -0.02483079582452774, 'vf_loss': 0.01203414755299223, 'total_loss': -0.014280011551056994, 'approx_kl': 0.039170592557638884, 'clip_fraction': 0.15755208395421505, 'grad_norm': 1.3322575092315674}
2022-12-29 12:36:48.911 DEBUG: Taking gradient step
2022-12-29 12:36:48.920 DEBUG: Loss 6: {'policy_loss': -0.007259072643166281, 'entropy_loss': -0.023660029750317335, 'vf_loss': 0.01192027547081656, 'total_loss': -0.01899882692266705, 'approx_kl': 0.04082876583561301, 'clip_fraction': 0.16145833395421505, 'grad_norm': 2.1978647708892822}
2022-12-29 12:36:49.637 DEBUG: Early stopping at step 7 for reaching max KL.
2022-12-29 12:36:49.638 INFO: Optimization: policy loss=-0.007, vf loss=0.012, entropy loss=-0.024, total loss=-0.019, num steps=7
2022-12-29 12:36:49.638 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:36:50.322 INFO: Evaluation rollout: return=0.510 (0.0), episode length=3.0
2022-12-29 12:36:50.323 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:36:50.325 INFO: Iteration: 73/137, steps: 15768
2022-12-29 12:37:40.030 INFO: Training rollout: return=0.466 (0.0), episode length=3.0
2022-12-29 12:37:40.031 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:37:40.034 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-15768_train.pkl
2022-12-29 12:37:40.756 DEBUG: Taking gradient step
2022-12-29 12:37:40.766 DEBUG: Loss 0: {'policy_loss': -0.009206383998822568, 'entropy_loss': -0.02441384829580784, 'vf_loss': 6.0030401417938155e-05, 'total_loss': -0.03356020189321247, 'approx_kl': 5.545249948113451e-08, 'clip_fraction': 0.0, 'grad_norm': 4.934612274169922}
2022-12-29 12:37:41.462 DEBUG: Taking gradient step
2022-12-29 12:37:41.471 DEBUG: Loss 1: {'policy_loss': 0.00518207969232376, 'entropy_loss': -0.023313671350479126, 'vf_loss': 7.132634392892347e-05, 'total_loss': -0.018060265314226442, 'approx_kl': 0.005594959016889334, 'clip_fraction': 0.0234375, 'grad_norm': 4.64084529876709}
2022-12-29 12:37:42.170 DEBUG: Taking gradient step
2022-12-29 12:37:42.179 DEBUG: Loss 2: {'policy_loss': -0.028247851998398608, 'entropy_loss': -0.024130692705512047, 'vf_loss': 8.56049200689746e-05, 'total_loss': -0.05229293978384168, 'approx_kl': 0.022041309857741, 'clip_fraction': 0.1002604179084301, 'grad_norm': 6.944105625152588}
2022-12-29 12:37:42.893 DEBUG: Taking gradient step
2022-12-29 12:37:42.902 DEBUG: Loss 3: {'policy_loss': 0.009759102064506416, 'entropy_loss': -0.024218506179749966, 'vf_loss': 8.664992624314925e-05, 'total_loss': -0.0143727541890004, 'approx_kl': 0.020178226986899972, 'clip_fraction': 0.08854166697710752, 'grad_norm': 2.5880963802337646}
2022-12-29 12:37:43.626 DEBUG: Taking gradient step
2022-12-29 12:37:43.640 DEBUG: Loss 4: {'policy_loss': -0.00406948903622583, 'entropy_loss': -0.02363334270194173, 'vf_loss': 9.818800883248646e-05, 'total_loss': -0.027604643729335073, 'approx_kl': 0.014453434385359287, 'clip_fraction': 0.049479166977107525, 'grad_norm': 5.241678237915039}
2022-12-29 12:37:44.374 DEBUG: Taking gradient step
2022-12-29 12:37:44.383 DEBUG: Loss 5: {'policy_loss': 0.0161221638809711, 'entropy_loss': -0.024126271717250347, 'vf_loss': 0.00010141115544780001, 'total_loss': -0.007902696680831447, 'approx_kl': 0.015283859334886074, 'clip_fraction': 0.045572916977107525, 'grad_norm': 5.401111602783203}
2022-12-29 12:37:45.095 DEBUG: Taking gradient step
2022-12-29 12:37:45.104 DEBUG: Loss 6: {'policy_loss': 0.002042956292648326, 'entropy_loss': -0.02570453379303217, 'vf_loss': 9.96043780655302e-05, 'total_loss': -0.02356197312231831, 'approx_kl': 0.019626117311418056, 'clip_fraction': 0.05078125, 'grad_norm': 3.5298683643341064}
2022-12-29 12:37:45.843 DEBUG: Taking gradient step
2022-12-29 12:37:45.857 DEBUG: Loss 7: {'policy_loss': 0.034497874364716324, 'entropy_loss': -0.024849878158420324, 'vf_loss': 0.00010171153504592193, 'total_loss': 0.009749707741341915, 'approx_kl': 0.027542116586118937, 'clip_fraction': 0.06510416697710752, 'grad_norm': 4.364693641662598}
2022-12-29 12:37:46.626 DEBUG: Taking gradient step
2022-12-29 12:37:46.638 DEBUG: Loss 8: {'policy_loss': 0.02201422231703615, 'entropy_loss': -0.024542219005525112, 'vf_loss': 0.00010562469095795345, 'total_loss': -0.0024223719975310053, 'approx_kl': 0.031202674377709627, 'clip_fraction': 0.09114583395421505, 'grad_norm': 2.346151351928711}
2022-12-29 12:37:47.340 DEBUG: Taking gradient step
2022-12-29 12:37:47.349 DEBUG: Loss 9: {'policy_loss': -0.008392874759977114, 'entropy_loss': -0.024462564382702112, 'vf_loss': 0.00011176349855728455, 'total_loss': -0.03274367564412194, 'approx_kl': 0.03176884324057028, 'clip_fraction': 0.13802083395421505, 'grad_norm': 4.18943977355957}
2022-12-29 12:37:47.350 INFO: Optimization: policy loss=-0.008, vf loss=0.000, entropy loss=-0.024, total loss=-0.033, num steps=10
2022-12-29 12:37:47.350 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:37:48.094 INFO: Evaluation rollout: return=0.507 (0.0), episode length=3.0
2022-12-29 12:37:48.094 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:37:48.096 INFO: Iteration: 74/137, steps: 15984
2022-12-29 12:38:36.412 INFO: Training rollout: return=0.468 (0.0), episode length=3.0
2022-12-29 12:38:36.414 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:38:36.416 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-15984_train.pkl
2022-12-29 12:38:37.132 DEBUG: Taking gradient step
2022-12-29 12:38:37.141 DEBUG: Loss 0: {'policy_loss': -0.03281324060718459, 'entropy_loss': -0.025081207044422626, 'vf_loss': 0.00011970208571052848, 'total_loss': -0.05777474556589668, 'approx_kl': -4.0357308606076e-09, 'clip_fraction': 0.0, 'grad_norm': 5.293612003326416}
2022-12-29 12:38:37.832 DEBUG: Taking gradient step
2022-12-29 12:38:37.841 DEBUG: Loss 1: {'policy_loss': 0.038673760361876024, 'entropy_loss': -0.02444169344380498, 'vf_loss': 0.00010806299438743155, 'total_loss': 0.014340129912458477, 'approx_kl': 0.0010795935886562802, 'clip_fraction': 0.0, 'grad_norm': 6.661841869354248}
2022-12-29 12:38:38.567 DEBUG: Taking gradient step
2022-12-29 12:38:38.576 DEBUG: Loss 2: {'policy_loss': -0.005847256868881471, 'entropy_loss': -0.025728484615683556, 'vf_loss': 0.00011054457331440183, 'total_loss': -0.031465196911250624, 'approx_kl': 0.007088272366672754, 'clip_fraction': 0.022135416977107525, 'grad_norm': 3.5439090728759766}
2022-12-29 12:38:39.322 DEBUG: Taking gradient step
2022-12-29 12:38:39.331 DEBUG: Loss 3: {'policy_loss': 0.028457049525848332, 'entropy_loss': -0.025045023299753666, 'vf_loss': 0.00010236041120900453, 'total_loss': 0.0035143866373036625, 'approx_kl': 0.014288821024820209, 'clip_fraction': 0.08333333395421505, 'grad_norm': 1.69188392162323}
2022-12-29 12:38:40.056 DEBUG: Taking gradient step
2022-12-29 12:38:40.066 DEBUG: Loss 4: {'policy_loss': -0.014071022729746625, 'entropy_loss': -0.025054037105292082, 'vf_loss': 0.00010346542082215059, 'total_loss': -0.03902159441421656, 'approx_kl': 0.03275177744217217, 'clip_fraction': 0.1875, 'grad_norm': 4.104743003845215}
2022-12-29 12:38:40.766 DEBUG: Taking gradient step
2022-12-29 12:38:40.776 DEBUG: Loss 5: {'policy_loss': -0.08436983929529665, 'entropy_loss': -0.02530883625149727, 'vf_loss': 0.00010405899966407905, 'total_loss': -0.10957461654712983, 'approx_kl': 0.040149965323507786, 'clip_fraction': 0.2408854216337204, 'grad_norm': 2.235267400741577}
2022-12-29 12:38:41.470 DEBUG: Early stopping at step 6 for reaching max KL.
2022-12-29 12:38:41.470 INFO: Optimization: policy loss=-0.084, vf loss=0.000, entropy loss=-0.025, total loss=-0.110, num steps=6
2022-12-29 12:38:41.471 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:38:42.198 INFO: Evaluation rollout: return=0.502 (0.0), episode length=3.0
2022-12-29 12:38:42.199 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:38:42.200 INFO: Iteration: 75/137, steps: 16200
2022-12-29 12:39:31.514 INFO: Training rollout: return=0.461 (0.1), episode length=3.0
2022-12-29 12:39:31.515 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:39:31.518 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-16200_train.pkl
2022-12-29 12:39:32.220 DEBUG: Taking gradient step
2022-12-29 12:39:32.229 DEBUG: Loss 0: {'policy_loss': 0.03261266617947864, 'entropy_loss': -0.02477603778243065, 'vf_loss': 7.288240727259238e-05, 'total_loss': 0.007909510804320584, 'approx_kl': 4.9748148711614704e-08, 'clip_fraction': 0.0, 'grad_norm': 10.652914047241211}
2022-12-29 12:39:32.932 DEBUG: Taking gradient step
2022-12-29 12:39:32.941 DEBUG: Loss 1: {'policy_loss': -0.0392529083314396, 'entropy_loss': -0.02573111606761813, 'vf_loss': 7.295981413116882e-05, 'total_loss': -0.06491106458492657, 'approx_kl': 0.002330634742975235, 'clip_fraction': 0.00390625, 'grad_norm': 12.534727096557617}
2022-12-29 12:39:33.673 DEBUG: Taking gradient step
2022-12-29 12:39:33.682 DEBUG: Loss 2: {'policy_loss': -0.06279061533143085, 'entropy_loss': -0.024969579186290503, 'vf_loss': 6.923127150154054e-05, 'total_loss': -0.0876909632462198, 'approx_kl': 0.0069209919311106205, 'clip_fraction': 0.05989583395421505, 'grad_norm': 3.38976788520813}
2022-12-29 12:39:34.385 DEBUG: Taking gradient step
2022-12-29 12:39:34.395 DEBUG: Loss 3: {'policy_loss': -0.05542881977161601, 'entropy_loss': -0.0247092810459435, 'vf_loss': 6.428973364457053e-05, 'total_loss': -0.08007381108391495, 'approx_kl': 0.019132052548229694, 'clip_fraction': 0.1458333358168602, 'grad_norm': 6.8014235496521}
2022-12-29 12:39:35.171 DEBUG: Taking gradient step
2022-12-29 12:39:35.182 DEBUG: Loss 4: {'policy_loss': -0.026797118359351297, 'entropy_loss': -0.025205241981893778, 'vf_loss': 5.6007695557354634e-05, 'total_loss': -0.05194635264568772, 'approx_kl': 0.034715906251221895, 'clip_fraction': 0.1822916679084301, 'grad_norm': 8.886550903320312}
2022-12-29 12:39:35.891 DEBUG: Early stopping at step 5 for reaching max KL.
2022-12-29 12:39:35.891 INFO: Optimization: policy loss=-0.027, vf loss=0.000, entropy loss=-0.025, total loss=-0.052, num steps=5
2022-12-29 12:39:35.892 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:39:36.576 INFO: Evaluation rollout: return=0.497 (0.0), episode length=3.0
2022-12-29 12:39:36.577 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:39:36.579 INFO: Iteration: 76/137, steps: 16416
2022-12-29 12:40:00.509 DEBUG: Atoms are too close
2022-12-29 12:40:23.407 DEBUG: Atoms are too close
2022-12-29 12:40:25.890 INFO: Training rollout: return=-0.091 (3.3), episode length=3.0
2022-12-29 12:40:25.891 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:40:25.895 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-16416_train.pkl
2022-12-29 12:40:26.661 DEBUG: Taking gradient step
2022-12-29 12:40:26.671 DEBUG: Loss 0: {'policy_loss': -0.02667301998173551, 'entropy_loss': -0.02470399858430028, 'vf_loss': 0.009553537548230531, 'total_loss': -0.04182348101780525, 'approx_kl': -7.101334631443024e-09, 'clip_fraction': 0.0, 'grad_norm': 16.20058250427246}
2022-12-29 12:40:27.434 DEBUG: Taking gradient step
2022-12-29 12:40:27.444 DEBUG: Loss 1: {'policy_loss': 0.014147167044084745, 'entropy_loss': -0.025393254589289427, 'vf_loss': 0.012172874418486742, 'total_loss': 0.0009267868732820601, 'approx_kl': 0.002401038756943308, 'clip_fraction': 0.0, 'grad_norm': 15.349523544311523}
2022-12-29 12:40:28.175 DEBUG: Taking gradient step
2022-12-29 12:40:28.184 DEBUG: Loss 2: {'policy_loss': 0.04501145494475653, 'entropy_loss': -0.02488286094740033, 'vf_loss': 0.01483970270049148, 'total_loss': 0.03496829669784768, 'approx_kl': 0.002392269263509661, 'clip_fraction': 0.01171875, 'grad_norm': 10.653474807739258}
2022-12-29 12:40:28.878 DEBUG: Taking gradient step
2022-12-29 12:40:28.887 DEBUG: Loss 3: {'policy_loss': -0.040163752408839626, 'entropy_loss': -0.02481669094413519, 'vf_loss': 0.009556814603705489, 'total_loss': -0.05542362874926933, 'approx_kl': 0.002605473855510354, 'clip_fraction': 0.05989583395421505, 'grad_norm': 5.352544784545898}
2022-12-29 12:40:29.658 DEBUG: Taking gradient step
2022-12-29 12:40:29.671 DEBUG: Loss 4: {'policy_loss': -0.00810794680187783, 'entropy_loss': -0.025263695046305656, 'vf_loss': 0.012213407738033623, 'total_loss': -0.02115823411014986, 'approx_kl': 0.008764593512751162, 'clip_fraction': 0.13151041697710752, 'grad_norm': 5.028358459472656}
2022-12-29 12:40:30.376 DEBUG: Taking gradient step
2022-12-29 12:40:30.387 DEBUG: Loss 5: {'policy_loss': -0.041133623856380884, 'entropy_loss': -0.024497860576957464, 'vf_loss': 0.009549513817156482, 'total_loss': -0.056081970616181864, 'approx_kl': 0.020643343217670918, 'clip_fraction': 0.2838541716337204, 'grad_norm': 2.4027011394500732}
2022-12-29 12:40:31.093 DEBUG: Taking gradient step
2022-12-29 12:40:31.102 DEBUG: Loss 6: {'policy_loss': -0.04486202021181815, 'entropy_loss': -0.024485298432409763, 'vf_loss': 0.009546670441690906, 'total_loss': -0.05980064820253701, 'approx_kl': 0.012024643365293741, 'clip_fraction': 0.2903645858168602, 'grad_norm': 1.919731855392456}
2022-12-29 12:40:31.805 DEBUG: Taking gradient step
2022-12-29 12:40:31.817 DEBUG: Loss 7: {'policy_loss': -0.012212137442861013, 'entropy_loss': -0.024737315718084574, 'vf_loss': 0.012175490068164402, 'total_loss': -0.024773963092781185, 'approx_kl': 0.028265831992030144, 'clip_fraction': 0.2994791716337204, 'grad_norm': 1.7267582416534424}
2022-12-29 12:40:32.562 DEBUG: Taking gradient step
2022-12-29 12:40:32.571 DEBUG: Loss 8: {'policy_loss': -0.04397563350270543, 'entropy_loss': -0.024523409083485603, 'vf_loss': 0.009520447976642572, 'total_loss': -0.05897859460954846, 'approx_kl': 0.008593437494710088, 'clip_fraction': 0.3111979216337204, 'grad_norm': 1.712172269821167}
2022-12-29 12:40:33.317 DEBUG: Taking gradient step
2022-12-29 12:40:33.327 DEBUG: Loss 9: {'policy_loss': -0.04486007915923692, 'entropy_loss': -0.025053974241018295, 'vf_loss': 0.009504124724479986, 'total_loss': -0.060409928675775236, 'approx_kl': 0.013052179012447596, 'clip_fraction': 0.2669270858168602, 'grad_norm': 1.6335036754608154}
2022-12-29 12:40:33.327 INFO: Optimization: policy loss=-0.045, vf loss=0.010, entropy loss=-0.025, total loss=-0.060, num steps=10
2022-12-29 12:40:33.327 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:40:34.176 INFO: Evaluation rollout: return=0.504 (0.0), episode length=3.0
2022-12-29 12:40:34.177 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:40:34.179 INFO: Iteration: 77/137, steps: 16632
2022-12-29 12:41:23.555 INFO: Training rollout: return=0.464 (0.0), episode length=3.0
2022-12-29 12:41:23.557 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:41:23.559 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-16632_train.pkl
2022-12-29 12:41:24.304 DEBUG: Taking gradient step
2022-12-29 12:41:24.318 DEBUG: Loss 0: {'policy_loss': 0.033350900824140994, 'entropy_loss': -0.02485964447259903, 'vf_loss': 5.304424326458289e-05, 'total_loss': 0.008544300594806549, 'approx_kl': -1.2184802500314618e-08, 'clip_fraction': 0.0, 'grad_norm': 6.461952209472656}
2022-12-29 12:41:25.172 DEBUG: Taking gradient step
2022-12-29 12:41:25.183 DEBUG: Loss 1: {'policy_loss': 0.010256084334061603, 'entropy_loss': -0.02486257255077362, 'vf_loss': 6.210737625250004e-05, 'total_loss': -0.014544380840459519, 'approx_kl': 0.003983199712820351, 'clip_fraction': 0.0078125, 'grad_norm': 11.10878849029541}
2022-12-29 12:41:25.884 DEBUG: Taking gradient step
2022-12-29 12:41:25.893 DEBUG: Loss 2: {'policy_loss': 0.02558341476852328, 'entropy_loss': -0.02457925444468856, 'vf_loss': 6.725764339268625e-05, 'total_loss': 0.0010714179672274074, 'approx_kl': 0.007032949826680124, 'clip_fraction': 0.05598958395421505, 'grad_norm': 2.7827229499816895}
2022-12-29 12:41:26.585 DEBUG: Taking gradient step
2022-12-29 12:41:26.595 DEBUG: Loss 3: {'policy_loss': -0.034407552811690334, 'entropy_loss': -0.024143618065863848, 'vf_loss': 7.615527641240347e-05, 'total_loss': -0.05847501560114177, 'approx_kl': 0.010087523492984474, 'clip_fraction': 0.1901041716337204, 'grad_norm': 5.7722954750061035}
2022-12-29 12:41:27.291 DEBUG: Taking gradient step
2022-12-29 12:41:27.301 DEBUG: Loss 4: {'policy_loss': 0.012493077884213964, 'entropy_loss': -0.02449540514498949, 'vf_loss': 7.655105728250344e-05, 'total_loss': -0.011925776203493024, 'approx_kl': 0.027986832428723574, 'clip_fraction': 0.1979166679084301, 'grad_norm': 7.505780220031738}
2022-12-29 12:41:28.024 DEBUG: Taking gradient step
2022-12-29 12:41:28.034 DEBUG: Loss 5: {'policy_loss': 0.024461011765848722, 'entropy_loss': -0.02477460214868188, 'vf_loss': 7.931425032588678e-05, 'total_loss': -0.0002342761325072676, 'approx_kl': 0.028351155808195472, 'clip_fraction': 0.2018229179084301, 'grad_norm': 3.8742945194244385}
2022-12-29 12:41:28.725 DEBUG: Taking gradient step
2022-12-29 12:41:28.734 DEBUG: Loss 6: {'policy_loss': -0.015542245752044066, 'entropy_loss': -0.023980378173291683, 'vf_loss': 8.386850963149394e-05, 'total_loss': -0.039438755415704255, 'approx_kl': 0.02666272595524788, 'clip_fraction': 0.1979166679084301, 'grad_norm': 5.472054958343506}
2022-12-29 12:41:29.435 DEBUG: Taking gradient step
2022-12-29 12:41:29.444 DEBUG: Loss 7: {'policy_loss': -0.009958439006937707, 'entropy_loss': -0.02471004379913211, 'vf_loss': 8.473705989053968e-05, 'total_loss': -0.03458374574617928, 'approx_kl': 0.03244344890117645, 'clip_fraction': 0.2200520858168602, 'grad_norm': 11.758455276489258}
2022-12-29 12:41:30.163 DEBUG: Taking gradient step
2022-12-29 12:41:30.172 DEBUG: Loss 8: {'policy_loss': -0.015133805861880843, 'entropy_loss': -0.0248373756185174, 'vf_loss': 8.490571133711785e-05, 'total_loss': -0.03988627576906112, 'approx_kl': 0.01909088809043169, 'clip_fraction': 0.1927083358168602, 'grad_norm': 2.6976685523986816}
2022-12-29 12:41:30.892 DEBUG: Taking gradient step
2022-12-29 12:41:30.901 DEBUG: Loss 9: {'policy_loss': -0.011632550573313881, 'entropy_loss': -0.023005728609859943, 'vf_loss': 8.67431114495936e-05, 'total_loss': -0.03455153607172423, 'approx_kl': 0.023260445799678564, 'clip_fraction': 0.15625, 'grad_norm': 6.103706359863281}
2022-12-29 12:41:30.901 INFO: Optimization: policy loss=-0.012, vf loss=0.000, entropy loss=-0.023, total loss=-0.035, num steps=10
2022-12-29 12:41:30.902 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:41:31.596 INFO: Evaluation rollout: return=0.504 (0.0), episode length=3.0
2022-12-29 12:41:31.597 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:41:31.599 INFO: Iteration: 78/137, steps: 16848
2022-12-29 12:42:10.131 DEBUG: Atoms are too close
2022-12-29 12:42:20.373 INFO: Training rollout: return=0.186 (2.4), episode length=3.0
2022-12-29 12:42:20.375 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:42:20.378 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-16848_train.pkl
2022-12-29 12:42:21.084 DEBUG: Taking gradient step
2022-12-29 12:42:21.093 DEBUG: Loss 0: {'policy_loss': -0.015694356425753488, 'entropy_loss': -0.024544151034206152, 'vf_loss': 0.004742629031737397, 'total_loss': -0.03549587842822224, 'approx_kl': -1.3581788138594675e-08, 'clip_fraction': 0.0, 'grad_norm': 11.252772331237793}
2022-12-29 12:42:21.820 DEBUG: Taking gradient step
2022-12-29 12:42:21.829 DEBUG: Loss 1: {'policy_loss': -0.02734604560327878, 'entropy_loss': -0.02329691546037793, 'vf_loss': 0.0047480566666110065, 'total_loss': -0.04589490439704571, 'approx_kl': -0.0032153839711099863, 'clip_fraction': 0.0234375, 'grad_norm': 0.48490169644355774}
2022-12-29 12:42:22.525 DEBUG: Taking gradient step
2022-12-29 12:42:22.534 DEBUG: Loss 2: {'policy_loss': -0.026626538006401614, 'entropy_loss': -0.023775425739586353, 'vf_loss': 0.004744458313993728, 'total_loss': -0.04565750543199425, 'approx_kl': -0.003122470690868795, 'clip_fraction': 0.041666666977107525, 'grad_norm': 0.5990750193595886}
2022-12-29 12:42:23.274 DEBUG: Taking gradient step
2022-12-29 12:42:23.283 DEBUG: Loss 3: {'policy_loss': -0.02496148731895706, 'entropy_loss': -0.0242190258577466, 'vf_loss': 0.0047394291637914915, 'total_loss': -0.04444108401291216, 'approx_kl': 0.0025842459872365, 'clip_fraction': 0.09765625, 'grad_norm': 0.8128156661987305}
2022-12-29 12:42:24.020 DEBUG: Taking gradient step
2022-12-29 12:42:24.029 DEBUG: Loss 4: {'policy_loss': 0.028076627894487338, 'entropy_loss': -0.023810639511793852, 'vf_loss': 0.007306404065765603, 'total_loss': 0.01157239244845909, 'approx_kl': 0.0061040971195325255, 'clip_fraction': 0.12630208395421505, 'grad_norm': 1.6399677991867065}
2022-12-29 12:42:24.744 DEBUG: Taking gradient step
2022-12-29 12:42:24.754 DEBUG: Loss 5: {'policy_loss': -0.026383656458634455, 'entropy_loss': -0.02386270510032773, 'vf_loss': 0.00473687246631703, 'total_loss': -0.045509489092645156, 'approx_kl': 0.008709155721589923, 'clip_fraction': 0.1875, 'grad_norm': 0.6814954280853271}
2022-12-29 12:42:25.440 DEBUG: Taking gradient step
2022-12-29 12:42:25.452 DEBUG: Loss 6: {'policy_loss': -0.027039478629438084, 'entropy_loss': -0.023601389955729246, 'vf_loss': 0.004733870183399077, 'total_loss': -0.045906998401768255, 'approx_kl': 0.004630995914340019, 'clip_fraction': 0.234375, 'grad_norm': 0.5669674277305603}
2022-12-29 12:42:26.167 DEBUG: Taking gradient step
2022-12-29 12:42:26.176 DEBUG: Loss 7: {'policy_loss': -0.02604696416401262, 'entropy_loss': -0.024146100506186485, 'vf_loss': 0.0047312557048685856, 'total_loss': -0.045461808965330516, 'approx_kl': 0.010181964607909322, 'clip_fraction': 0.2265625, 'grad_norm': 0.6316370964050293}
2022-12-29 12:42:26.861 DEBUG: Taking gradient step
2022-12-29 12:42:26.870 DEBUG: Loss 8: {'policy_loss': -0.027443521394318285, 'entropy_loss': -0.02510540932416916, 'vf_loss': 0.004728243210835908, 'total_loss': -0.04782068750765153, 'approx_kl': 0.012549507431685925, 'clip_fraction': 0.2109375, 'grad_norm': 0.6252352595329285}
2022-12-29 12:42:27.577 DEBUG: Taking gradient step
2022-12-29 12:42:27.586 DEBUG: Loss 9: {'policy_loss': -0.02962385487433093, 'entropy_loss': -0.024515978526324034, 'vf_loss': 0.004727996540708506, 'total_loss': -0.04941183685994646, 'approx_kl': 0.001261156052350998, 'clip_fraction': 0.1953125, 'grad_norm': 0.9010951519012451}
2022-12-29 12:42:27.586 INFO: Optimization: policy loss=-0.030, vf loss=0.005, entropy loss=-0.025, total loss=-0.049, num steps=10
2022-12-29 12:42:27.587 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:42:28.285 INFO: Evaluation rollout: return=0.508 (0.0), episode length=3.0
2022-12-29 12:42:28.285 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:42:28.287 INFO: Iteration: 79/137, steps: 17064
2022-12-29 12:43:17.440 INFO: Training rollout: return=0.458 (0.0), episode length=3.0
2022-12-29 12:43:17.441 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:43:17.445 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-17064_train.pkl
2022-12-29 12:43:18.172 DEBUG: Taking gradient step
2022-12-29 12:43:18.186 DEBUG: Loss 0: {'policy_loss': -0.02854518224748261, 'entropy_loss': -0.024967587552964687, 'vf_loss': 6.0265617476946324e-05, 'total_loss': -0.05345250418297035, 'approx_kl': 1.703544150188918e-08, 'clip_fraction': 0.0, 'grad_norm': 9.542469024658203}
2022-12-29 12:43:18.926 DEBUG: Taking gradient step
2022-12-29 12:43:18.936 DEBUG: Loss 1: {'policy_loss': -0.034739462099557285, 'entropy_loss': -0.024441357236355543, 'vf_loss': 6.05815128352549e-05, 'total_loss': -0.05912023782307758, 'approx_kl': 0.0036922754952684045, 'clip_fraction': 0.02734375, 'grad_norm': 5.847529888153076}
2022-12-29 12:43:19.646 DEBUG: Taking gradient step
2022-12-29 12:43:19.655 DEBUG: Loss 2: {'policy_loss': 0.014303132858685345, 'entropy_loss': -0.0248782429844141, 'vf_loss': 5.754466711416199e-05, 'total_loss': -0.010517565458614594, 'approx_kl': 0.008240734925493598, 'clip_fraction': 0.049479166977107525, 'grad_norm': 7.597659111022949}
2022-12-29 12:43:20.360 DEBUG: Taking gradient step
2022-12-29 12:43:20.370 DEBUG: Loss 3: {'policy_loss': -0.03832096964105191, 'entropy_loss': -0.02442014403641224, 'vf_loss': 5.928340764166327e-05, 'total_loss': -0.06268183026982249, 'approx_kl': 0.005488899070769548, 'clip_fraction': 0.053385416977107525, 'grad_norm': 7.415445804595947}
2022-12-29 12:43:21.052 DEBUG: Taking gradient step
2022-12-29 12:43:21.061 DEBUG: Loss 4: {'policy_loss': -0.022459595323636845, 'entropy_loss': -0.024526267312467098, 'vf_loss': 5.708487404737522e-05, 'total_loss': -0.04692877776205656, 'approx_kl': 0.005512239724339452, 'clip_fraction': 0.046875, 'grad_norm': 6.312162399291992}
2022-12-29 12:43:21.747 DEBUG: Taking gradient step
2022-12-29 12:43:21.757 DEBUG: Loss 5: {'policy_loss': -0.05211685915490641, 'entropy_loss': -0.024303986690938473, 'vf_loss': 5.937332845741127e-05, 'total_loss': -0.07636147251738748, 'approx_kl': 0.00658553175162524, 'clip_fraction': 0.09375, 'grad_norm': 5.831136703491211}
2022-12-29 12:43:22.455 DEBUG: Taking gradient step
2022-12-29 12:43:22.465 DEBUG: Loss 6: {'policy_loss': -0.02159677081916824, 'entropy_loss': -0.02435105526819825, 'vf_loss': 5.48082793940612e-05, 'total_loss': -0.04589301780797243, 'approx_kl': 0.01133407384622842, 'clip_fraction': 0.06510416697710752, 'grad_norm': 13.426839828491211}
2022-12-29 12:43:23.185 DEBUG: Taking gradient step
2022-12-29 12:43:23.194 DEBUG: Loss 7: {'policy_loss': -0.02605528480195015, 'entropy_loss': -0.025045187212526798, 'vf_loss': 5.4730451771612774e-05, 'total_loss': -0.05104574156270533, 'approx_kl': 0.002202590461820364, 'clip_fraction': 0.07682291697710752, 'grad_norm': 12.80898666381836}
2022-12-29 12:43:23.889 DEBUG: Taking gradient step
2022-12-29 12:43:23.903 DEBUG: Loss 8: {'policy_loss': -0.03965405010899261, 'entropy_loss': -0.025510299019515514, 'vf_loss': 5.601545730570154e-05, 'total_loss': -0.06510833367120242, 'approx_kl': 0.0011470331810414791, 'clip_fraction': 0.11067708395421505, 'grad_norm': 4.52681303024292}
2022-12-29 12:43:24.604 DEBUG: Taking gradient step
2022-12-29 12:43:24.613 DEBUG: Loss 9: {'policy_loss': 0.0251393156918412, 'entropy_loss': -0.023704370018094778, 'vf_loss': 5.087748657450639e-05, 'total_loss': 0.0014858231603209274, 'approx_kl': 0.013642845675349236, 'clip_fraction': 0.1015625, 'grad_norm': 5.995176315307617}
2022-12-29 12:43:24.614 INFO: Optimization: policy loss=0.025, vf loss=0.000, entropy loss=-0.024, total loss=0.001, num steps=10
2022-12-29 12:43:24.614 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:43:25.333 INFO: Evaluation rollout: return=0.509 (0.0), episode length=3.0
2022-12-29 12:43:25.334 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:43:25.336 INFO: Iteration: 80/137, steps: 17280
2022-12-29 12:43:46.685 DEBUG: Atoms are too close
2022-12-29 12:43:55.353 DEBUG: Atoms are too close
2022-12-29 12:44:13.532 INFO: Training rollout: return=-0.090 (3.3), episode length=3.0
2022-12-29 12:44:13.534 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:44:13.536 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-17280_train.pkl
2022-12-29 12:44:14.271 DEBUG: Taking gradient step
2022-12-29 12:44:14.281 DEBUG: Loss 0: {'policy_loss': -0.027551000180675765, 'entropy_loss': -0.024644088931381702, 'vf_loss': 0.009408846022714365, 'total_loss': -0.042786243089343104, 'approx_kl': -3.930957426234727e-08, 'clip_fraction': 0.0, 'grad_norm': 9.994732856750488}
2022-12-29 12:44:14.994 DEBUG: Taking gradient step
2022-12-29 12:44:15.004 DEBUG: Loss 1: {'policy_loss': -0.0340762394197691, 'entropy_loss': -0.024659904185682535, 'vf_loss': 0.00940886848071154, 'total_loss': -0.0493272751247401, 'approx_kl': 0.0017707033548504114, 'clip_fraction': 0.015625, 'grad_norm': 4.595855236053467}
2022-12-29 12:44:15.686 DEBUG: Taking gradient step
2022-12-29 12:44:15.695 DEBUG: Loss 2: {'policy_loss': -0.0024162652873174414, 'entropy_loss': -0.024690257851034403, 'vf_loss': 0.012053331567572184, 'total_loss': -0.015053191570779667, 'approx_kl': 0.009242792963050306, 'clip_fraction': 0.041666666977107525, 'grad_norm': 0.7939644455909729}
2022-12-29 12:44:16.371 DEBUG: Taking gradient step
2022-12-29 12:44:16.380 DEBUG: Loss 3: {'policy_loss': -0.004255446884930866, 'entropy_loss': -0.024991654325276613, 'vf_loss': 0.012029837578047074, 'total_loss': -0.017217263632160407, 'approx_kl': 0.013596102595329285, 'clip_fraction': 0.1119791679084301, 'grad_norm': 1.32608163356781}
2022-12-29 12:44:17.082 DEBUG: Taking gradient step
2022-12-29 12:44:17.093 DEBUG: Loss 4: {'policy_loss': -0.03459111677670295, 'entropy_loss': -0.02446939144283533, 'vf_loss': 0.009377332483672375, 'total_loss': -0.049683175735865906, 'approx_kl': 0.01291028899140656, 'clip_fraction': 0.1666666716337204, 'grad_norm': 1.5530145168304443}
2022-12-29 12:44:17.788 DEBUG: Taking gradient step
2022-12-29 12:44:17.797 DEBUG: Loss 5: {'policy_loss': 0.004743238473527603, 'entropy_loss': -0.024967185221612453, 'vf_loss': 0.011903520316121146, 'total_loss': -0.008320426431963703, 'approx_kl': 0.013420735951513052, 'clip_fraction': 0.18359375, 'grad_norm': 1.499888300895691}
2022-12-29 12:44:18.487 DEBUG: Taking gradient step
2022-12-29 12:44:18.496 DEBUG: Loss 6: {'policy_loss': 0.0020977732485752826, 'entropy_loss': -0.0237103383988142, 'vf_loss': 0.011943262552430944, 'total_loss': -0.009669302597807974, 'approx_kl': 0.005050517385825515, 'clip_fraction': 0.09375, 'grad_norm': 1.116228461265564}
2022-12-29 12:44:19.214 DEBUG: Taking gradient step
2022-12-29 12:44:19.224 DEBUG: Loss 7: {'policy_loss': -0.005864269193849097, 'entropy_loss': -0.025096815079450607, 'vf_loss': 0.011921468544181323, 'total_loss': -0.019039615729118383, 'approx_kl': 0.0031213207985274494, 'clip_fraction': 0.0625, 'grad_norm': 1.087131381034851}
2022-12-29 12:44:19.918 DEBUG: Taking gradient step
2022-12-29 12:44:19.927 DEBUG: Loss 8: {'policy_loss': 0.0035190226495871203, 'entropy_loss': -0.023288677912205458, 'vf_loss': 0.011867445699275152, 'total_loss': -0.007902209563343192, 'approx_kl': -0.003664709161967039, 'clip_fraction': 0.041666666977107525, 'grad_norm': 5.8352556228637695}
2022-12-29 12:44:20.649 DEBUG: Taking gradient step
2022-12-29 12:44:20.658 DEBUG: Loss 9: {'policy_loss': 0.04819774388166077, 'entropy_loss': -0.02424045605584979, 'vf_loss': 0.014395446691929832, 'total_loss': 0.03835273451774082, 'approx_kl': 0.0003171286080032587, 'clip_fraction': 0.05208333395421505, 'grad_norm': 13.065037727355957}
2022-12-29 12:44:20.658 INFO: Optimization: policy loss=0.048, vf loss=0.014, entropy loss=-0.024, total loss=0.038, num steps=10
2022-12-29 12:44:20.659 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:44:21.336 INFO: Evaluation rollout: return=0.507 (0.0), episode length=3.0
2022-12-29 12:44:21.337 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:44:21.339 DEBUG: Deleting old model: runs/H2O/models/H2O_run-1_steps-15336.model
2022-12-29 12:44:21.344 DEBUG: Saving model: runs/H2O/models/H2O_run-1_steps-17496.model
2022-12-29 12:44:21.374 INFO: Iteration: 81/137, steps: 17496
2022-12-29 12:45:09.498 INFO: Training rollout: return=0.461 (0.0), episode length=3.0
2022-12-29 12:45:09.499 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:45:09.502 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-17496_train.pkl
2022-12-29 12:45:10.258 DEBUG: Taking gradient step
2022-12-29 12:45:10.267 DEBUG: Loss 0: {'policy_loss': -0.03948129712519963, 'entropy_loss': -0.023725171573460102, 'vf_loss': 0.00017068327042450005, 'total_loss': -0.06303578542823522, 'approx_kl': 8.343097990248793e-09, 'clip_fraction': 0.0, 'grad_norm': 5.4507341384887695}
2022-12-29 12:45:11.054 DEBUG: Taking gradient step
2022-12-29 12:45:11.069 DEBUG: Loss 1: {'policy_loss': 0.0005546790335680968, 'entropy_loss': -0.0234964769333601, 'vf_loss': 0.00018402307676689973, 'total_loss': -0.0227577748230251, 'approx_kl': -0.0018656461834325455, 'clip_fraction': 0.0078125, 'grad_norm': 6.541454315185547}
2022-12-29 12:45:11.794 DEBUG: Taking gradient step
2022-12-29 12:45:11.803 DEBUG: Loss 2: {'policy_loss': 0.02172188143385339, 'entropy_loss': -0.023892346303910017, 'vf_loss': 0.00019678071889291384, 'total_loss': -0.001973684151163717, 'approx_kl': -0.002118320553563535, 'clip_fraction': 0.078125, 'grad_norm': 6.358492374420166}
2022-12-29 12:45:12.501 DEBUG: Taking gradient step
2022-12-29 12:45:12.510 DEBUG: Loss 3: {'policy_loss': -0.03800076241194404, 'entropy_loss': -0.024908061139285564, 'vf_loss': 0.00021845947832802124, 'total_loss': -0.06269036407290159, 'approx_kl': -0.0036523668095469475, 'clip_fraction': 0.12890625, 'grad_norm': 8.156744956970215}
2022-12-29 12:45:13.245 DEBUG: Taking gradient step
2022-12-29 12:45:13.255 DEBUG: Loss 4: {'policy_loss': -0.055318895493847206, 'entropy_loss': -0.02412970457226038, 'vf_loss': 0.0002332803642112858, 'total_loss': -0.0792153197018963, 'approx_kl': 0.003304186277091503, 'clip_fraction': 0.1432291679084301, 'grad_norm': 9.201715469360352}
2022-12-29 12:45:13.962 DEBUG: Taking gradient step
2022-12-29 12:45:13.971 DEBUG: Loss 5: {'policy_loss': -0.06992533548215937, 'entropy_loss': -0.025064693298190832, 'vf_loss': 0.00024723253771874074, 'total_loss': -0.09474279624263146, 'approx_kl': 0.006825610180385411, 'clip_fraction': 0.1536458358168602, 'grad_norm': 10.496869087219238}
2022-12-29 12:45:14.706 DEBUG: Taking gradient step
2022-12-29 12:45:14.715 DEBUG: Loss 6: {'policy_loss': -0.03813762779250134, 'entropy_loss': -0.024186724331229925, 'vf_loss': 0.00024898566623511044, 'total_loss': -0.06207536645749616, 'approx_kl': 0.0014590315986424685, 'clip_fraction': 0.14192708395421505, 'grad_norm': 8.326294898986816}
2022-12-29 12:45:15.442 DEBUG: Taking gradient step
2022-12-29 12:45:15.453 DEBUG: Loss 7: {'policy_loss': -0.0020459328920317127, 'entropy_loss': -0.024665909819304943, 'vf_loss': 0.0002462465426123034, 'total_loss': -0.026465596168724355, 'approx_kl': -0.0033126655034720898, 'clip_fraction': 0.1432291679084301, 'grad_norm': 5.906723976135254}
2022-12-29 12:45:16.139 DEBUG: Taking gradient step
2022-12-29 12:45:16.149 DEBUG: Loss 8: {'policy_loss': -0.02807813666911139, 'entropy_loss': -0.02359485486522317, 'vf_loss': 0.000251978349892262, 'total_loss': -0.0514210131844423, 'approx_kl': 0.002592495293356478, 'clip_fraction': 0.08203125, 'grad_norm': 9.569826126098633}
2022-12-29 12:45:16.833 DEBUG: Taking gradient step
2022-12-29 12:45:16.842 DEBUG: Loss 9: {'policy_loss': 0.0036066863615947468, 'entropy_loss': -0.02452440233901143, 'vf_loss': 0.00024931639577414574, 'total_loss': -0.02066839958164254, 'approx_kl': -0.0016542369266971946, 'clip_fraction': 0.109375, 'grad_norm': 6.196199417114258}
2022-12-29 12:45:16.842 INFO: Optimization: policy loss=0.004, vf loss=0.000, entropy loss=-0.025, total loss=-0.021, num steps=10
2022-12-29 12:45:16.843 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:45:17.617 INFO: Evaluation rollout: return=0.505 (0.0), episode length=3.0
2022-12-29 12:45:17.618 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:45:17.620 INFO: Iteration: 82/137, steps: 17712
2022-12-29 12:45:39.723 DEBUG: Atoms are too close
2022-12-29 12:46:04.274 DEBUG: Atoms are too close
2022-12-29 12:46:06.411 INFO: Training rollout: return=-0.089 (3.3), episode length=3.0
2022-12-29 12:46:06.413 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:46:06.415 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-17712_train.pkl
2022-12-29 12:46:07.146 DEBUG: Taking gradient step
2022-12-29 12:46:07.156 DEBUG: Loss 0: {'policy_loss': 0.013827696607455725, 'entropy_loss': -0.024272897746413946, 'vf_loss': 0.011880171740769937, 'total_loss': 0.0014349706018117088, 'approx_kl': -3.570070106206913e-08, 'clip_fraction': 0.0, 'grad_norm': 19.397809982299805}
2022-12-29 12:46:07.843 DEBUG: Taking gradient step
2022-12-29 12:46:07.852 DEBUG: Loss 1: {'policy_loss': -0.02641384856604107, 'entropy_loss': -0.023815836291760206, 'vf_loss': 0.009387474170370447, 'total_loss': -0.040842210687430824, 'approx_kl': 7.828784873709083e-05, 'clip_fraction': 0.0, 'grad_norm': 8.597394943237305}
2022-12-29 12:46:08.609 DEBUG: Taking gradient step
2022-12-29 12:46:08.619 DEBUG: Loss 2: {'policy_loss': 0.00020003442695282203, 'entropy_loss': -0.02276836382225156, 'vf_loss': 0.011891929891695935, 'total_loss': -0.010676399503602798, 'approx_kl': 0.007515765610150993, 'clip_fraction': 0.033854166977107525, 'grad_norm': 7.592468738555908}
2022-12-29 12:46:09.357 DEBUG: Taking gradient step
2022-12-29 12:46:09.367 DEBUG: Loss 3: {'policy_loss': 0.03947577920099071, 'entropy_loss': -0.02291408646851778, 'vf_loss': 0.01436930894801491, 'total_loss': 0.03093100168048786, 'approx_kl': 0.01270940521499142, 'clip_fraction': 0.05598958395421505, 'grad_norm': 18.143901824951172}
2022-12-29 12:46:10.106 DEBUG: Taking gradient step
2022-12-29 12:46:10.115 DEBUG: Loss 4: {'policy_loss': -0.03326521247128471, 'entropy_loss': -0.023399989120662212, 'vf_loss': 0.009393465161300341, 'total_loss': -0.047271736430646576, 'approx_kl': 0.018796175136230886, 'clip_fraction': 0.11458333395421505, 'grad_norm': 3.5117945671081543}
2022-12-29 12:46:10.818 DEBUG: Taking gradient step
2022-12-29 12:46:10.828 DEBUG: Loss 5: {'policy_loss': 0.004374119420844532, 'entropy_loss': -0.023083676118403673, 'vf_loss': 0.011896202372796972, 'total_loss': -0.006813354324762169, 'approx_kl': 0.02367409085854888, 'clip_fraction': 0.1653645858168602, 'grad_norm': 4.802591323852539}
2022-12-29 12:46:11.530 DEBUG: Taking gradient step
2022-12-29 12:46:11.543 DEBUG: Loss 6: {'policy_loss': 0.04765105340674941, 'entropy_loss': -0.023677806369960308, 'vf_loss': 0.014453911701352651, 'total_loss': 0.03842715873814176, 'approx_kl': 0.018988037016242743, 'clip_fraction': 0.12630208395421505, 'grad_norm': 3.5709760189056396}
2022-12-29 12:46:12.254 DEBUG: Taking gradient step
2022-12-29 12:46:12.263 DEBUG: Loss 7: {'policy_loss': 0.04790369955399924, 'entropy_loss': -0.02286207303404808, 'vf_loss': 0.01446151880546901, 'total_loss': 0.03950314532542017, 'approx_kl': 0.022769292118027806, 'clip_fraction': 0.09505208395421505, 'grad_norm': 2.3232946395874023}
2022-12-29 12:46:12.972 DEBUG: Taking gradient step
2022-12-29 12:46:12.981 DEBUG: Loss 8: {'policy_loss': 0.03906010602521992, 'entropy_loss': -0.02309634443372488, 'vf_loss': 0.01445622550833784, 'total_loss': 0.03041998709983288, 'approx_kl': 0.02384146547410637, 'clip_fraction': 0.1158854179084301, 'grad_norm': 7.405314922332764}
2022-12-29 12:46:13.687 DEBUG: Taking gradient step
2022-12-29 12:46:13.696 DEBUG: Loss 9: {'policy_loss': -0.028903109278828255, 'entropy_loss': -0.02265916531905532, 'vf_loss': 0.009388899381962686, 'total_loss': -0.042173375215920884, 'approx_kl': 0.022360256407409906, 'clip_fraction': 0.13671875, 'grad_norm': 10.089828491210938}
2022-12-29 12:46:13.697 INFO: Optimization: policy loss=-0.029, vf loss=0.009, entropy loss=-0.023, total loss=-0.042, num steps=10
2022-12-29 12:46:13.697 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:46:14.342 INFO: Evaluation rollout: return=0.503 (0.0), episode length=3.0
2022-12-29 12:46:14.343 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:46:14.345 INFO: Iteration: 83/137, steps: 17928
2022-12-29 12:47:03.306 INFO: Training rollout: return=0.467 (0.0), episode length=3.0
2022-12-29 12:47:03.308 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:47:03.311 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-17928_train.pkl
2022-12-29 12:47:04.059 DEBUG: Taking gradient step
2022-12-29 12:47:04.069 DEBUG: Loss 0: {'policy_loss': -0.018467016558193643, 'entropy_loss': -0.02177751250565052, 'vf_loss': 0.00027482568623990174, 'total_loss': -0.03996970337760426, 'approx_kl': -2.9336661100387573e-08, 'clip_fraction': 0.0, 'grad_norm': 12.673138618469238}
2022-12-29 12:47:04.751 DEBUG: Taking gradient step
2022-12-29 12:47:04.760 DEBUG: Loss 1: {'policy_loss': 0.02651085861913339, 'entropy_loss': -0.02217459725216031, 'vf_loss': 0.00026715993551743185, 'total_loss': 0.004603421302490508, 'approx_kl': -0.00041747017530724406, 'clip_fraction': 0.00390625, 'grad_norm': 5.7218122482299805}
2022-12-29 12:47:05.461 DEBUG: Taking gradient step
2022-12-29 12:47:05.470 DEBUG: Loss 2: {'policy_loss': 0.0024972574949340097, 'entropy_loss': -0.023478709626942873, 'vf_loss': 0.00026873219065825485, 'total_loss': -0.020712719941350606, 'approx_kl': -0.0018587762024253607, 'clip_fraction': 0.1432291679084301, 'grad_norm': 10.69986343383789}
2022-12-29 12:47:06.154 DEBUG: Taking gradient step
2022-12-29 12:47:06.164 DEBUG: Loss 3: {'policy_loss': -0.005541085718348778, 'entropy_loss': -0.022649625781923532, 'vf_loss': 0.00026807291935308786, 'total_loss': -0.027922638580919222, 'approx_kl': 0.009613269590772688, 'clip_fraction': 0.171875, 'grad_norm': 14.86865234375}
2022-12-29 12:47:06.911 DEBUG: Taking gradient step
2022-12-29 12:47:06.923 DEBUG: Loss 4: {'policy_loss': -0.002211832723117039, 'entropy_loss': -0.022176981437951326, 'vf_loss': 0.00026291637395705155, 'total_loss': -0.024125897787111314, 'approx_kl': 0.006506584584712982, 'clip_fraction': 0.140625, 'grad_norm': 11.23038101196289}
2022-12-29 12:47:07.625 DEBUG: Taking gradient step
2022-12-29 12:47:07.639 DEBUG: Loss 5: {'policy_loss': -0.06341385046365125, 'entropy_loss': -0.02288376586511731, 'vf_loss': 0.00026606912852162896, 'total_loss': -0.08603154720024693, 'approx_kl': -0.0026949169114232063, 'clip_fraction': 0.17578125, 'grad_norm': 6.090701103210449}
2022-12-29 12:47:08.367 DEBUG: Taking gradient step
2022-12-29 12:47:08.376 DEBUG: Loss 6: {'policy_loss': 0.022080776313711, 'entropy_loss': -0.02256088564172387, 'vf_loss': 0.0002495367993940474, 'total_loss': -0.00023057252861882066, 'approx_kl': 0.0025795423425734043, 'clip_fraction': 0.08723958395421505, 'grad_norm': 3.7133820056915283}
2022-12-29 12:47:09.105 DEBUG: Taking gradient step
2022-12-29 12:47:09.114 DEBUG: Loss 7: {'policy_loss': -0.025124559069698224, 'entropy_loss': -0.021821036003530025, 'vf_loss': 0.00024759578256147567, 'total_loss': -0.04669799929066677, 'approx_kl': 0.0018085172632709146, 'clip_fraction': 0.1197916679084301, 'grad_norm': 14.271358489990234}
2022-12-29 12:47:09.812 DEBUG: Taking gradient step
2022-12-29 12:47:09.821 DEBUG: Loss 8: {'policy_loss': 0.03583586726306974, 'entropy_loss': -0.02278898749500513, 'vf_loss': 0.0002306311746183168, 'total_loss': 0.013277510942682924, 'approx_kl': 0.015137838548980653, 'clip_fraction': 0.109375, 'grad_norm': 9.129319190979004}
2022-12-29 12:47:10.516 DEBUG: Taking gradient step
2022-12-29 12:47:10.525 DEBUG: Loss 9: {'policy_loss': -0.042154012279734435, 'entropy_loss': -0.022819713223725557, 'vf_loss': 0.0002309033279433287, 'total_loss': -0.06474282217551666, 'approx_kl': 0.011210822500288486, 'clip_fraction': 0.08854166697710752, 'grad_norm': 8.338759422302246}
2022-12-29 12:47:10.525 INFO: Optimization: policy loss=-0.042, vf loss=0.000, entropy loss=-0.023, total loss=-0.065, num steps=10
2022-12-29 12:47:10.526 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:47:11.189 INFO: Evaluation rollout: return=0.503 (0.0), episode length=3.0
2022-12-29 12:47:11.190 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:47:11.191 INFO: Iteration: 84/137, steps: 18144
2022-12-29 12:47:59.043 INFO: Training rollout: return=0.467 (0.0), episode length=3.0
2022-12-29 12:47:59.045 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:47:59.047 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-18144_train.pkl
2022-12-29 12:47:59.763 DEBUG: Taking gradient step
2022-12-29 12:47:59.772 DEBUG: Loss 0: {'policy_loss': 0.025976344927946766, 'entropy_loss': -0.02245279075577855, 'vf_loss': 0.00020860341663933617, 'total_loss': 0.003732157588807551, 'approx_kl': 4.798251573845391e-08, 'clip_fraction': 0.0, 'grad_norm': 8.744950294494629}
2022-12-29 12:48:00.464 DEBUG: Taking gradient step
2022-12-29 12:48:00.474 DEBUG: Loss 1: {'policy_loss': -0.022318952831380932, 'entropy_loss': -0.022213781252503395, 'vf_loss': 0.0002046204660810637, 'total_loss': -0.04432811361780327, 'approx_kl': 0.003990312048699707, 'clip_fraction': 0.018229166977107525, 'grad_norm': 8.015233993530273}
2022-12-29 12:48:01.195 DEBUG: Taking gradient step
2022-12-29 12:48:01.204 DEBUG: Loss 2: {'policy_loss': -0.02386974121207703, 'entropy_loss': -0.02139465371146798, 'vf_loss': 0.00019565868918140468, 'total_loss': -0.04506873623436361, 'approx_kl': 0.003876677481457591, 'clip_fraction': 0.015625, 'grad_norm': 7.925320148468018}
2022-12-29 12:48:01.909 DEBUG: Taking gradient step
2022-12-29 12:48:01.920 DEBUG: Loss 3: {'policy_loss': 0.007517691923604849, 'entropy_loss': -0.02189132245257497, 'vf_loss': 0.0001845367802120224, 'total_loss': -0.014189093748758097, 'approx_kl': 0.0021099342266097665, 'clip_fraction': 0.0546875, 'grad_norm': 10.990703582763672}
2022-12-29 12:48:02.611 DEBUG: Taking gradient step
2022-12-29 12:48:02.622 DEBUG: Loss 4: {'policy_loss': -0.010538498226151114, 'entropy_loss': -0.022082533221691847, 'vf_loss': 0.00017654168494203956, 'total_loss': -0.032444489762900916, 'approx_kl': -0.005353469401597977, 'clip_fraction': 0.1822916679084301, 'grad_norm': 8.208999633789062}
2022-12-29 12:48:03.323 DEBUG: Taking gradient step
2022-12-29 12:48:03.332 DEBUG: Loss 5: {'policy_loss': 0.00267316749421068, 'entropy_loss': -0.02220782358199358, 'vf_loss': 0.00016871734965120448, 'total_loss': -0.019365938738131694, 'approx_kl': -0.011568353045731783, 'clip_fraction': 0.2057291679084301, 'grad_norm': 8.36054515838623}
2022-12-29 12:48:04.032 DEBUG: Taking gradient step
2022-12-29 12:48:04.043 DEBUG: Loss 6: {'policy_loss': -0.006502367907161927, 'entropy_loss': -0.02101179165765643, 'vf_loss': 0.00016213579684804904, 'total_loss': -0.02735202376797031, 'approx_kl': -0.0071487053064629436, 'clip_fraction': 0.2213541679084301, 'grad_norm': 9.713309288024902}
2022-12-29 12:48:04.760 DEBUG: Taking gradient step
2022-12-29 12:48:04.771 DEBUG: Loss 7: {'policy_loss': -0.059112278148329055, 'entropy_loss': -0.0209162007085979, 'vf_loss': 0.000160528032066474, 'total_loss': -0.07986795082486048, 'approx_kl': -0.0053802733309566975, 'clip_fraction': 0.16927083395421505, 'grad_norm': 10.043741226196289}
2022-12-29 12:48:05.471 DEBUG: Taking gradient step
2022-12-29 12:48:05.480 DEBUG: Loss 8: {'policy_loss': 0.037407310889186335, 'entropy_loss': -0.0213616662658751, 'vf_loss': 0.00014643192825707552, 'total_loss': 0.016192076551568305, 'approx_kl': -0.005392876919358969, 'clip_fraction': 0.07552083395421505, 'grad_norm': 4.904493808746338}
2022-12-29 12:48:06.223 DEBUG: Taking gradient step
2022-12-29 12:48:06.232 DEBUG: Loss 9: {'policy_loss': 0.007281163833686908, 'entropy_loss': -0.021278266794979572, 'vf_loss': 0.00013856136307922244, 'total_loss': -0.013858541598213437, 'approx_kl': 0.008934424782637507, 'clip_fraction': 0.0533854179084301, 'grad_norm': 9.056467056274414}
2022-12-29 12:48:06.232 INFO: Optimization: policy loss=0.007, vf loss=0.000, entropy loss=-0.021, total loss=-0.014, num steps=10
2022-12-29 12:48:06.233 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:48:06.969 INFO: Evaluation rollout: return=0.503 (0.0), episode length=3.0
2022-12-29 12:48:06.970 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:48:06.972 INFO: Iteration: 85/137, steps: 18360
2022-12-29 12:48:54.412 INFO: Training rollout: return=0.467 (0.0), episode length=3.0
2022-12-29 12:48:54.413 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:48:54.416 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-18360_train.pkl
2022-12-29 12:48:55.142 DEBUG: Taking gradient step
2022-12-29 12:48:55.151 DEBUG: Loss 0: {'policy_loss': -0.04397601297331932, 'entropy_loss': -0.02035662718117237, 'vf_loss': 0.0001460300490737165, 'total_loss': -0.06418661010541798, 'approx_kl': 3.018067218363285e-08, 'clip_fraction': 0.0, 'grad_norm': 9.428979873657227}
2022-12-29 12:48:55.846 DEBUG: Taking gradient step
2022-12-29 12:48:55.855 DEBUG: Loss 1: {'policy_loss': -0.004266445605727391, 'entropy_loss': -0.02133587095886469, 'vf_loss': 0.0001363053224038636, 'total_loss': -0.025466011242188218, 'approx_kl': -0.0014973986544646323, 'clip_fraction': 0.0, 'grad_norm': 8.337587356567383}
2022-12-29 12:48:56.583 DEBUG: Taking gradient step
2022-12-29 12:48:56.592 DEBUG: Loss 2: {'policy_loss': 0.04969714652129331, 'entropy_loss': -0.021387471817433834, 'vf_loss': 0.00012677063689462098, 'total_loss': 0.028436445340754096, 'approx_kl': 0.0010045686503872275, 'clip_fraction': 0.109375, 'grad_norm': 5.063841819763184}
2022-12-29 12:48:57.282 DEBUG: Taking gradient step
2022-12-29 12:48:57.293 DEBUG: Loss 3: {'policy_loss': 0.021871941434315482, 'entropy_loss': -0.020597172435373068, 'vf_loss': 0.00012255613950251456, 'total_loss': 0.001397325138444927, 'approx_kl': 0.0018032747320830822, 'clip_fraction': 0.13151041697710752, 'grad_norm': 5.3669538497924805}
2022-12-29 12:48:57.991 DEBUG: Taking gradient step
2022-12-29 12:48:58.004 DEBUG: Loss 4: {'policy_loss': 0.032357722240165976, 'entropy_loss': -0.021108774468302727, 'vf_loss': 0.00011446902822332185, 'total_loss': 0.011363416800086568, 'approx_kl': -0.00720149336848408, 'clip_fraction': 0.1901041716337204, 'grad_norm': 10.308588027954102}
2022-12-29 12:48:58.743 DEBUG: Taking gradient step
2022-12-29 12:48:58.754 DEBUG: Loss 5: {'policy_loss': -0.03727512526457579, 'entropy_loss': -0.019960453268140554, 'vf_loss': 0.0001132350538416963, 'total_loss': -0.05712234347887465, 'approx_kl': 0.0038290023803710938, 'clip_fraction': 0.2083333358168602, 'grad_norm': 5.454355716705322}
2022-12-29 12:48:59.467 DEBUG: Taking gradient step
2022-12-29 12:48:59.480 DEBUG: Loss 6: {'policy_loss': 0.018906799687758876, 'entropy_loss': -0.021148189902305603, 'vf_loss': 0.00010641064413154252, 'total_loss': -0.0021349795704151825, 'approx_kl': 0.005203200620599091, 'clip_fraction': 0.18359375, 'grad_norm': 5.426214694976807}
2022-12-29 12:49:00.176 DEBUG: Taking gradient step
2022-12-29 12:49:00.186 DEBUG: Loss 7: {'policy_loss': -0.05660286965510596, 'entropy_loss': -0.01913539762608707, 'vf_loss': 0.0001033692517079398, 'total_loss': -0.07563489802948509, 'approx_kl': 0.0075988342287018895, 'clip_fraction': 0.1783854179084301, 'grad_norm': 4.413180828094482}
2022-12-29 12:49:00.890 DEBUG: Taking gradient step
2022-12-29 12:49:00.900 DEBUG: Loss 8: {'policy_loss': -0.004043295629156831, 'entropy_loss': -0.019528918899595737, 'vf_loss': 9.680310019464922e-05, 'total_loss': -0.02347541142855792, 'approx_kl': -0.001183855114504695, 'clip_fraction': 0.1705729179084301, 'grad_norm': 1.5204137563705444}
2022-12-29 12:49:01.586 DEBUG: Taking gradient step
2022-12-29 12:49:01.596 DEBUG: Loss 9: {'policy_loss': 0.00985315014795823, 'entropy_loss': -0.019896285142749548, 'vf_loss': 8.954250967347777e-05, 'total_loss': -0.009953592485117842, 'approx_kl': -0.001846859697252512, 'clip_fraction': 0.15364583395421505, 'grad_norm': 4.00351095199585}
2022-12-29 12:49:01.596 INFO: Optimization: policy loss=0.010, vf loss=0.000, entropy loss=-0.020, total loss=-0.010, num steps=10
2022-12-29 12:49:01.597 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:49:02.283 INFO: Evaluation rollout: return=0.503 (0.0), episode length=3.0
2022-12-29 12:49:02.284 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:49:02.285 INFO: Iteration: 86/137, steps: 18576
2022-12-29 12:49:50.705 INFO: Training rollout: return=0.470 (0.0), episode length=3.0
2022-12-29 12:49:50.707 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:49:50.710 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-18576_train.pkl
2022-12-29 12:49:51.455 DEBUG: Taking gradient step
2022-12-29 12:49:51.464 DEBUG: Loss 0: {'policy_loss': -0.008599593500431223, 'entropy_loss': -0.021123331040143967, 'vf_loss': 7.716428607603207e-05, 'total_loss': -0.029645760254499155, 'approx_kl': -2.9026220538241887e-08, 'clip_fraction': 0.0, 'grad_norm': 5.446321964263916}
2022-12-29 12:49:52.197 DEBUG: Taking gradient step
2022-12-29 12:49:52.208 DEBUG: Loss 1: {'policy_loss': 0.05290095435939257, 'entropy_loss': -0.019933111499994993, 'vf_loss': 6.913303565896113e-05, 'total_loss': 0.03303697589505654, 'approx_kl': 0.00023418628552462906, 'clip_fraction': 0.0, 'grad_norm': 9.02600383758545}
2022-12-29 12:49:52.977 DEBUG: Taking gradient step
2022-12-29 12:49:52.991 DEBUG: Loss 2: {'policy_loss': -0.06812989053087218, 'entropy_loss': -0.019859277177602053, 'vf_loss': 7.104526957854377e-05, 'total_loss': -0.08791812243889569, 'approx_kl': 0.0006903248722665012, 'clip_fraction': 0.0, 'grad_norm': 4.798583507537842}
2022-12-29 12:49:53.763 DEBUG: Taking gradient step
2022-12-29 12:49:53.773 DEBUG: Loss 3: {'policy_loss': 0.024168944640630588, 'entropy_loss': -0.020753686781972647, 'vf_loss': 6.234726087009381e-05, 'total_loss': 0.003477605119528035, 'approx_kl': 0.0017551161581650376, 'clip_fraction': 0.0859375, 'grad_norm': 11.489679336547852}
2022-12-29 12:49:54.463 DEBUG: Taking gradient step
2022-12-29 12:49:54.472 DEBUG: Loss 4: {'policy_loss': 0.04754114953328844, 'entropy_loss': -0.01967876823619008, 'vf_loss': 5.792756853457762e-05, 'total_loss': 0.027920308865632938, 'approx_kl': 0.002531045349314809, 'clip_fraction': 0.12239583395421505, 'grad_norm': 13.830961227416992}
2022-12-29 12:49:55.164 DEBUG: Taking gradient step
2022-12-29 12:49:55.173 DEBUG: Loss 5: {'policy_loss': -0.012239733375846135, 'entropy_loss': -0.020137526094913483, 'vf_loss': 5.810314060202339e-05, 'total_loss': -0.0323191563301576, 'approx_kl': 0.000502169132232666, 'clip_fraction': 0.09114583395421505, 'grad_norm': 11.198565483093262}
2022-12-29 12:49:55.888 DEBUG: Taking gradient step
2022-12-29 12:49:55.897 DEBUG: Loss 6: {'policy_loss': -0.004146847279636632, 'entropy_loss': -0.019916517194360495, 'vf_loss': 5.4796975709195414e-05, 'total_loss': -0.024008567498287937, 'approx_kl': 0.00577900221105665, 'clip_fraction': 0.05859375, 'grad_norm': 5.420821189880371}
2022-12-29 12:49:56.639 DEBUG: Taking gradient step
2022-12-29 12:49:56.649 DEBUG: Loss 7: {'policy_loss': -0.017970890748946464, 'entropy_loss': -0.020581779535859823, 'vf_loss': 5.29422502129849e-05, 'total_loss': -0.0384997280345933, 'approx_kl': 0.008014707826077938, 'clip_fraction': 0.11197916697710752, 'grad_norm': 9.657176971435547}
2022-12-29 12:49:57.369 DEBUG: Taking gradient step
2022-12-29 12:49:57.378 DEBUG: Loss 8: {'policy_loss': -0.01956736030671284, 'entropy_loss': -0.020511936862021685, 'vf_loss': 5.079278285954199e-05, 'total_loss': -0.04002850438587499, 'approx_kl': 0.018563530407845974, 'clip_fraction': 0.1484375, 'grad_norm': 8.3539457321167}
2022-12-29 12:49:58.103 DEBUG: Taking gradient step
2022-12-29 12:49:58.112 DEBUG: Loss 9: {'policy_loss': 0.018173642839646988, 'entropy_loss': -0.020036266651004553, 'vf_loss': 4.775356699378697e-05, 'total_loss': -0.0018148702443637789, 'approx_kl': 0.012630340177565813, 'clip_fraction': 0.14453125, 'grad_norm': 10.531420707702637}
2022-12-29 12:49:58.113 INFO: Optimization: policy loss=0.018, vf loss=0.000, entropy loss=-0.020, total loss=-0.002, num steps=10
2022-12-29 12:49:58.113 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:49:58.756 INFO: Evaluation rollout: return=0.501 (0.0), episode length=3.0
2022-12-29 12:49:58.756 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:49:58.758 INFO: Iteration: 87/137, steps: 18792
2022-12-29 12:50:46.531 INFO: Training rollout: return=0.472 (0.0), episode length=3.0
2022-12-29 12:50:46.533 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:50:46.535 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-18792_train.pkl
2022-12-29 12:50:47.286 DEBUG: Taking gradient step
2022-12-29 12:50:47.295 DEBUG: Loss 0: {'policy_loss': -0.0017641681466051954, 'entropy_loss': -0.020759231876581907, 'vf_loss': 4.734011871383625e-05, 'total_loss': -0.022476059904473267, 'approx_kl': -2.8240418004088497e-08, 'clip_fraction': 0.0, 'grad_norm': 3.9794883728027344}
2022-12-29 12:50:47.987 DEBUG: Taking gradient step
2022-12-29 12:50:47.997 DEBUG: Loss 1: {'policy_loss': 0.00433063433776909, 'entropy_loss': -0.02041214844211936, 'vf_loss': 4.5394384565395566e-05, 'total_loss': -0.016036119719784876, 'approx_kl': 0.0022856635332573205, 'clip_fraction': 0.0, 'grad_norm': 4.784761905670166}
2022-12-29 12:50:48.713 DEBUG: Taking gradient step
2022-12-29 12:50:48.722 DEBUG: Loss 2: {'policy_loss': 0.011194561179155887, 'entropy_loss': -0.02063460648059845, 'vf_loss': 4.3975719202555595e-05, 'total_loss': -0.00939606958224001, 'approx_kl': 0.007075434958096594, 'clip_fraction': 0.01171875, 'grad_norm': 4.5622735023498535}
2022-12-29 12:50:49.445 DEBUG: Taking gradient step
2022-12-29 12:50:49.456 DEBUG: Loss 3: {'policy_loss': 0.020185141930659477, 'entropy_loss': -0.02078772382810712, 'vf_loss': 4.1807934853933125e-05, 'total_loss': -0.0005607739625937067, 'approx_kl': 0.018357527209445834, 'clip_fraction': 0.1158854179084301, 'grad_norm': 11.382296562194824}
2022-12-29 12:50:50.250 DEBUG: Taking gradient step
2022-12-29 12:50:50.260 DEBUG: Loss 4: {'policy_loss': -0.03431329926043594, 'entropy_loss': -0.02003206731751561, 'vf_loss': 4.3010739982050905e-05, 'total_loss': -0.05430235583796951, 'approx_kl': 0.024270132067613304, 'clip_fraction': 0.13411458395421505, 'grad_norm': 10.182938575744629}
2022-12-29 12:50:50.946 DEBUG: Taking gradient step
2022-12-29 12:50:50.956 DEBUG: Loss 5: {'policy_loss': -0.027794991267425954, 'entropy_loss': -0.02085711434483528, 'vf_loss': 4.151090326537283e-05, 'total_loss': -0.048610594708995855, 'approx_kl': 0.02609918569214642, 'clip_fraction': 0.13802083395421505, 'grad_norm': 9.244256019592285}
2022-12-29 12:50:51.678 DEBUG: Taking gradient step
2022-12-29 12:50:51.687 DEBUG: Loss 6: {'policy_loss': 0.027713874060558384, 'entropy_loss': -0.021165975369513035, 'vf_loss': 3.866284318940143e-05, 'total_loss': 0.006586561534234758, 'approx_kl': 0.02277324185706675, 'clip_fraction': 0.09114583395421505, 'grad_norm': 10.53388500213623}
2022-12-29 12:50:52.429 DEBUG: Taking gradient step
2022-12-29 12:50:52.438 DEBUG: Loss 7: {'policy_loss': 0.01830877817095161, 'entropy_loss': -0.0212277309037745, 'vf_loss': 3.761374962933321e-05, 'total_loss': -0.0028813389831935585, 'approx_kl': 0.022861809164169244, 'clip_fraction': 0.09375, 'grad_norm': 6.343778133392334}
2022-12-29 12:50:53.162 DEBUG: Taking gradient step
2022-12-29 12:50:53.176 DEBUG: Loss 8: {'policy_loss': 0.010836683890078178, 'entropy_loss': -0.02074373560026288, 'vf_loss': 3.702083402418067e-05, 'total_loss': -0.009870030876160521, 'approx_kl': 0.030699813971295953, 'clip_fraction': 0.1341145858168602, 'grad_norm': 10.627909660339355}
2022-12-29 12:50:53.873 DEBUG: Taking gradient step
2022-12-29 12:50:53.882 DEBUG: Loss 9: {'policy_loss': -0.004678567665762521, 'entropy_loss': -0.02195714833214879, 'vf_loss': 3.7049252466059686e-05, 'total_loss': -0.026598666745445254, 'approx_kl': 0.0343641797080636, 'clip_fraction': 0.11067708395421505, 'grad_norm': 11.83938217163086}
2022-12-29 12:50:53.882 INFO: Optimization: policy loss=-0.005, vf loss=0.000, entropy loss=-0.022, total loss=-0.027, num steps=10
2022-12-29 12:50:53.883 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:50:54.625 INFO: Evaluation rollout: return=0.504 (0.0), episode length=3.0
2022-12-29 12:50:54.626 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:50:54.628 INFO: Iteration: 88/137, steps: 19008
2022-12-29 12:51:00.187 DEBUG: Atoms are too close
2022-12-29 12:51:00.994 DEBUG: Atoms are too close
2022-12-29 12:51:09.047 DEBUG: Atoms are too close
2022-12-29 12:51:16.415 DEBUG: Atoms are too close
2022-12-29 12:51:39.506 DEBUG: Atoms are too close
2022-12-29 12:51:40.333 INFO: Training rollout: return=-0.934 (5.1), episode length=3.0
2022-12-29 12:51:40.334 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:51:40.337 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-19008_train.pkl
2022-12-29 12:51:41.065 DEBUG: Taking gradient step
2022-12-29 12:51:41.075 DEBUG: Loss 0: {'policy_loss': 0.008151970386589647, 'entropy_loss': -0.02135790977627039, 'vf_loss': 0.029092087477695896, 'total_loss': 0.015886148088015153, 'approx_kl': 2.5941214509828114e-08, 'clip_fraction': 0.0, 'grad_norm': 16.24016761779785}
2022-12-29 12:51:41.816 DEBUG: Taking gradient step
2022-12-29 12:51:41.829 DEBUG: Loss 1: {'policy_loss': 0.012422763252952431, 'entropy_loss': -0.021732536610215902, 'vf_loss': 0.02909312136560943, 'total_loss': 0.01978334800834596, 'approx_kl': 0.003374636173248291, 'clip_fraction': 0.0, 'grad_norm': 13.28018856048584}
2022-12-29 12:51:42.527 DEBUG: Taking gradient step
2022-12-29 12:51:42.536 DEBUG: Loss 2: {'policy_loss': -0.015900421023044956, 'entropy_loss': -0.022236397489905357, 'vf_loss': 0.02634613769109019, 'total_loss': -0.011790680821860126, 'approx_kl': 0.008745623985305429, 'clip_fraction': 0.01953125, 'grad_norm': 9.992505073547363}
2022-12-29 12:51:43.232 DEBUG: Taking gradient step
2022-12-29 12:51:43.242 DEBUG: Loss 3: {'policy_loss': -0.023331334712762455, 'entropy_loss': -0.022826784756034613, 'vf_loss': 0.02633313182276059, 'total_loss': -0.019824987646036477, 'approx_kl': 0.01397974241990596, 'clip_fraction': 0.07942708395421505, 'grad_norm': 6.810053825378418}
2022-12-29 12:51:43.970 DEBUG: Taking gradient step
2022-12-29 12:51:43.980 DEBUG: Loss 4: {'policy_loss': 0.020211279706810872, 'entropy_loss': -0.021135409362614155, 'vf_loss': 0.03156964533080685, 'total_loss': 0.030645515675003565, 'approx_kl': 0.017250923672690988, 'clip_fraction': 0.10026041697710752, 'grad_norm': 4.355777263641357}
2022-12-29 12:51:44.678 DEBUG: Taking gradient step
2022-12-29 12:51:44.687 DEBUG: Loss 5: {'policy_loss': -0.0012651117800110447, 'entropy_loss': -0.022217020858079195, 'vf_loss': 0.02892893384076673, 'total_loss': 0.005446801202676491, 'approx_kl': 0.01683139195665717, 'clip_fraction': 0.10546875, 'grad_norm': 5.42664098739624}
2022-12-29 12:51:45.374 DEBUG: Taking gradient step
2022-12-29 12:51:45.383 DEBUG: Loss 6: {'policy_loss': 0.023189089813102227, 'entropy_loss': -0.021030467469245195, 'vf_loss': 0.03145993071867653, 'total_loss': 0.03361855306253356, 'approx_kl': 0.019177335081622005, 'clip_fraction': 0.04296875, 'grad_norm': 4.7686333656311035}
2022-12-29 12:51:46.074 DEBUG: Taking gradient step
2022-12-29 12:51:46.083 DEBUG: Loss 7: {'policy_loss': -0.005733116335096395, 'entropy_loss': -0.020891592372208834, 'vf_loss': 0.0288159785052366, 'total_loss': 0.0021912697979313764, 'approx_kl': 0.015318484220188111, 'clip_fraction': 0.04296875, 'grad_norm': 2.32660174369812}
2022-12-29 12:51:46.799 DEBUG: Taking gradient step
2022-12-29 12:51:46.808 DEBUG: Loss 8: {'policy_loss': 0.016506564758865805, 'entropy_loss': -0.019691707100719213, 'vf_loss': 0.03137031185659206, 'total_loss': 0.028185169514738664, 'approx_kl': 0.0197947402484715, 'clip_fraction': 0.10286458395421505, 'grad_norm': 5.281301498413086}
2022-12-29 12:51:47.556 DEBUG: Taking gradient step
2022-12-29 12:51:47.566 DEBUG: Loss 9: {'policy_loss': -0.05903353224778861, 'entropy_loss': -0.02154893521219492, 'vf_loss': 0.02345851564930359, 'total_loss': -0.05712395181067993, 'approx_kl': 0.006314946687780321, 'clip_fraction': 0.17578125, 'grad_norm': 4.04185152053833}
2022-12-29 12:51:47.567 INFO: Optimization: policy loss=-0.059, vf loss=0.023, entropy loss=-0.022, total loss=-0.057, num steps=10
2022-12-29 12:51:47.567 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:51:48.358 INFO: Evaluation rollout: return=0.506 (0.0), episode length=3.0
2022-12-29 12:51:48.360 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:51:48.362 INFO: Iteration: 89/137, steps: 19224
2022-12-29 12:52:01.917 DEBUG: Atoms are too close
2022-12-29 12:52:19.209 DEBUG: Atoms are too close
2022-12-29 12:52:35.681 INFO: Training rollout: return=-0.095 (3.3), episode length=3.0
2022-12-29 12:52:35.683 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:52:35.686 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-19224_train.pkl
2022-12-29 12:52:36.459 DEBUG: Taking gradient step
2022-12-29 12:52:36.468 DEBUG: Loss 0: {'policy_loss': -0.02576216853137811, 'entropy_loss': -0.021477191243320704, 'vf_loss': 0.009410926857074469, 'total_loss': -0.03782843291762435, 'approx_kl': -9.992314531359625e-09, 'clip_fraction': 0.0, 'grad_norm': 12.779623031616211}
2022-12-29 12:52:37.155 DEBUG: Taking gradient step
2022-12-29 12:52:37.165 DEBUG: Loss 1: {'policy_loss': 0.003248843756913297, 'entropy_loss': -0.02147656213492155, 'vf_loss': 0.012001405439690895, 'total_loss': -0.006226312938317359, 'approx_kl': -0.0033104854519478977, 'clip_fraction': 0.022135416977107525, 'grad_norm': 2.3295412063598633}
2022-12-29 12:52:37.864 DEBUG: Taking gradient step
2022-12-29 12:52:37.877 DEBUG: Loss 2: {'policy_loss': -0.03432276774444194, 'entropy_loss': -0.020744186360388994, 'vf_loss': 0.009400259910316738, 'total_loss': -0.045666694194514204, 'approx_kl': 0.0004738509887829423, 'clip_fraction': 0.08463541697710752, 'grad_norm': 2.020761013031006}
2022-12-29 12:52:38.567 DEBUG: Taking gradient step
2022-12-29 12:52:38.581 DEBUG: Loss 3: {'policy_loss': -0.03547282769920472, 'entropy_loss': -0.02027453063055873, 'vf_loss': 0.009397461391668756, 'total_loss': -0.046349896938094694, 'approx_kl': 0.005882617086172104, 'clip_fraction': 0.13411458395421505, 'grad_norm': 2.480451822280884}
2022-12-29 12:52:39.336 DEBUG: Taking gradient step
2022-12-29 12:52:39.345 DEBUG: Loss 4: {'policy_loss': -0.03574389602941215, 'entropy_loss': -0.0212098378688097, 'vf_loss': 0.009394867659820083, 'total_loss': -0.04755886623840176, 'approx_kl': 0.012636821949854493, 'clip_fraction': 0.1770833358168602, 'grad_norm': 2.393690347671509}
2022-12-29 12:52:40.009 DEBUG: Taking gradient step
2022-12-29 12:52:40.019 DEBUG: Loss 5: {'policy_loss': 0.0048521055229942996, 'entropy_loss': -0.02067450527101755, 'vf_loss': 0.011947490051978076, 'total_loss': -0.003874909696045179, 'approx_kl': 0.025567506439983845, 'clip_fraction': 0.15234375, 'grad_norm': 1.7780336141586304}
2022-12-29 12:52:40.676 DEBUG: Early stopping at step 6 for reaching max KL.
2022-12-29 12:52:40.676 INFO: Optimization: policy loss=0.005, vf loss=0.012, entropy loss=-0.021, total loss=-0.004, num steps=6
2022-12-29 12:52:40.676 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:52:41.452 INFO: Evaluation rollout: return=0.504 (0.0), episode length=3.0
2022-12-29 12:52:41.453 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:52:41.454 INFO: Iteration: 90/137, steps: 19440
2022-12-29 12:52:49.174 DEBUG: Atoms are too close
2022-12-29 12:53:04.520 DEBUG: Atoms are too close
2022-12-29 12:53:19.554 DEBUG: Atoms are too close
2022-12-29 12:53:28.391 INFO: Training rollout: return=-0.369 (4.0), episode length=3.0
2022-12-29 12:53:28.393 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:53:28.395 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-19440_train.pkl
2022-12-29 12:53:29.167 DEBUG: Taking gradient step
2022-12-29 12:53:29.178 DEBUG: Loss 0: {'policy_loss': -0.032757762589288635, 'entropy_loss': -0.020834953524172306, 'vf_loss': 0.013951519410562446, 'total_loss': -0.03964119670289849, 'approx_kl': -4.307366907596588e-08, 'clip_fraction': 0.0, 'grad_norm': 21.6842041015625}
2022-12-29 12:53:29.893 DEBUG: Taking gradient step
2022-12-29 12:53:29.904 DEBUG: Loss 1: {'policy_loss': -0.011415747710167304, 'entropy_loss': -0.020286313723772764, 'vf_loss': 0.016464571979294726, 'total_loss': -0.015237489454645342, 'approx_kl': 0.0023843490052968264, 'clip_fraction': 0.01171875, 'grad_norm': 13.774888038635254}
2022-12-29 12:53:30.612 DEBUG: Taking gradient step
2022-12-29 12:53:30.621 DEBUG: Loss 2: {'policy_loss': 0.015131189350388825, 'entropy_loss': -0.02120632817968726, 'vf_loss': 0.019009680989154343, 'total_loss': 0.012934542159855907, 'approx_kl': 0.007054881425574422, 'clip_fraction': 0.12239583395421505, 'grad_norm': 5.47509765625}
2022-12-29 12:53:31.325 DEBUG: Taking gradient step
2022-12-29 12:53:31.335 DEBUG: Loss 3: {'policy_loss': -0.014683865858531061, 'entropy_loss': -0.021596535574644804, 'vf_loss': 0.016490670779620624, 'total_loss': -0.019789730653555243, 'approx_kl': 0.01605446799658239, 'clip_fraction': 0.2057291679084301, 'grad_norm': 3.128068208694458}
2022-12-29 12:53:32.011 DEBUG: Taking gradient step
2022-12-29 12:53:32.020 DEBUG: Loss 4: {'policy_loss': -0.04924924916279774, 'entropy_loss': -0.020378703717142344, 'vf_loss': 0.013926990660040129, 'total_loss': -0.05570096221989995, 'approx_kl': 0.02166891493834555, 'clip_fraction': 0.328125, 'grad_norm': 1.3183587789535522}
2022-12-29 12:53:32.717 DEBUG: Early stopping at step 5 for reaching max KL.
2022-12-29 12:53:32.717 INFO: Optimization: policy loss=-0.049, vf loss=0.014, entropy loss=-0.020, total loss=-0.056, num steps=5
2022-12-29 12:53:32.718 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:53:33.427 INFO: Evaluation rollout: return=0.496 (0.0), episode length=3.0
2022-12-29 12:53:33.427 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:53:33.429 DEBUG: Deleting old model: runs/H2O/models/H2O_run-1_steps-17496.model
2022-12-29 12:53:33.432 DEBUG: Saving model: runs/H2O/models/H2O_run-1_steps-19656.model
2022-12-29 12:53:33.464 INFO: Iteration: 91/137, steps: 19656
2022-12-29 12:54:21.247 INFO: Training rollout: return=0.464 (0.0), episode length=3.0
2022-12-29 12:54:21.249 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:54:21.251 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-19656_train.pkl
2022-12-29 12:54:21.980 DEBUG: Taking gradient step
2022-12-29 12:54:21.989 DEBUG: Loss 0: {'policy_loss': 0.04185691113053576, 'entropy_loss': -0.021605638787150383, 'vf_loss': 0.0002525871652237471, 'total_loss': 0.02050385950860912, 'approx_kl': -1.2863893061876297e-08, 'clip_fraction': 0.0, 'grad_norm': 10.86412525177002}
2022-12-29 12:54:22.706 DEBUG: Taking gradient step
2022-12-29 12:54:22.716 DEBUG: Loss 1: {'policy_loss': 0.013858052215879695, 'entropy_loss': -0.021645142696797848, 'vf_loss': 0.0002705305708132201, 'total_loss': -0.007516559910104928, 'approx_kl': 0.0044652887590928, 'clip_fraction': 0.00390625, 'grad_norm': 12.304574966430664}
2022-12-29 12:54:23.419 DEBUG: Taking gradient step
2022-12-29 12:54:23.428 DEBUG: Loss 2: {'policy_loss': 0.027816733542864028, 'entropy_loss': -0.021147973835468292, 'vf_loss': 0.0002811708861028308, 'total_loss': 0.006949930593498559, 'approx_kl': 0.005672149010933936, 'clip_fraction': 0.01953125, 'grad_norm': 13.797102928161621}
2022-12-29 12:54:24.138 DEBUG: Taking gradient step
2022-12-29 12:54:24.147 DEBUG: Loss 3: {'policy_loss': 0.02143304875032713, 'entropy_loss': -0.021630194503813982, 'vf_loss': 0.00029226628974242424, 'total_loss': 9.512053625557182e-05, 'approx_kl': 0.00392779108369723, 'clip_fraction': 0.045572916977107525, 'grad_norm': 15.531017303466797}
2022-12-29 12:54:24.845 DEBUG: Taking gradient step
2022-12-29 12:54:24.855 DEBUG: Loss 4: {'policy_loss': 0.04171877061614716, 'entropy_loss': -0.0215703290887177, 'vf_loss': 0.00029804278370026364, 'total_loss': 0.020446484311129734, 'approx_kl': -0.0006116090808063745, 'clip_fraction': 0.04427083395421505, 'grad_norm': 11.67168140411377}
2022-12-29 12:54:25.551 DEBUG: Taking gradient step
2022-12-29 12:54:25.561 DEBUG: Loss 5: {'policy_loss': -0.018645313944948262, 'entropy_loss': -0.020734422374516726, 'vf_loss': 0.0003117803432684305, 'total_loss': -0.039067955976196556, 'approx_kl': -0.006414271367248148, 'clip_fraction': 0.1015625, 'grad_norm': 3.762974500656128}
2022-12-29 12:54:26.276 DEBUG: Taking gradient step
2022-12-29 12:54:26.285 DEBUG: Loss 6: {'policy_loss': 0.002587429090551256, 'entropy_loss': -0.021211799699813128, 'vf_loss': 0.00031158941949631087, 'total_loss': -0.018312781189765558, 'approx_kl': -0.013520609587430954, 'clip_fraction': 0.16145833395421505, 'grad_norm': 6.464130878448486}
2022-12-29 12:54:27.008 DEBUG: Taking gradient step
2022-12-29 12:54:27.017 DEBUG: Loss 7: {'policy_loss': -0.03093445405477474, 'entropy_loss': -0.02156216325238347, 'vf_loss': 0.00031524393957102476, 'total_loss': -0.052181373367587186, 'approx_kl': -0.01728252647444606, 'clip_fraction': 0.2174479216337204, 'grad_norm': 9.3102388381958}
2022-12-29 12:54:27.751 DEBUG: Taking gradient step
2022-12-29 12:54:27.761 DEBUG: Loss 8: {'policy_loss': 0.029017708600687447, 'entropy_loss': -0.021406144835054874, 'vf_loss': 0.00030773246290110966, 'total_loss': 0.007919296228533684, 'approx_kl': -0.006139154429547489, 'clip_fraction': 0.1861979179084301, 'grad_norm': 9.658622741699219}
2022-12-29 12:54:28.475 DEBUG: Taking gradient step
2022-12-29 12:54:28.485 DEBUG: Loss 9: {'policy_loss': 0.003957974884195966, 'entropy_loss': -0.02155841188505292, 'vf_loss': 0.00030638454273785, 'total_loss': -0.0172940524581191, 'approx_kl': -0.006946950918063521, 'clip_fraction': 0.140625, 'grad_norm': 4.340301513671875}
2022-12-29 12:54:28.485 INFO: Optimization: policy loss=0.004, vf loss=0.000, entropy loss=-0.022, total loss=-0.017, num steps=10
2022-12-29 12:54:28.485 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:54:29.200 INFO: Evaluation rollout: return=0.498 (0.0), episode length=3.0
2022-12-29 12:54:29.201 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:54:29.203 INFO: Iteration: 92/137, steps: 19872
2022-12-29 12:55:16.737 INFO: Training rollout: return=0.472 (0.0), episode length=3.0
2022-12-29 12:55:16.739 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:55:16.741 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-19872_train.pkl
2022-12-29 12:55:17.469 DEBUG: Taking gradient step
2022-12-29 12:55:17.479 DEBUG: Loss 0: {'policy_loss': -0.019720021542616706, 'entropy_loss': -0.020267854677513242, 'vf_loss': 0.0003107027788212278, 'total_loss': -0.039677173441308715, 'approx_kl': 4.3675148830857324e-08, 'clip_fraction': 0.0, 'grad_norm': 6.291001796722412}
2022-12-29 12:55:18.204 DEBUG: Taking gradient step
2022-12-29 12:55:18.213 DEBUG: Loss 1: {'policy_loss': 0.008285035550669582, 'entropy_loss': -0.02157739643007517, 'vf_loss': 0.00030039140842051, 'total_loss': -0.012991969470985076, 'approx_kl': 0.005195785954128951, 'clip_fraction': 0.014322916977107525, 'grad_norm': 10.993616104125977}
2022-12-29 12:55:18.908 DEBUG: Taking gradient step
2022-12-29 12:55:18.919 DEBUG: Loss 2: {'policy_loss': 0.028471097494362104, 'entropy_loss': -0.02193679939955473, 'vf_loss': 0.0002909814695402285, 'total_loss': 0.006825279564347607, 'approx_kl': 0.008501843665726483, 'clip_fraction': 0.05598958395421505, 'grad_norm': 9.432069778442383}
2022-12-29 12:55:19.628 DEBUG: Taking gradient step
2022-12-29 12:55:19.638 DEBUG: Loss 3: {'policy_loss': 0.02430224606641642, 'entropy_loss': -0.021196997724473476, 'vf_loss': 0.0002829647252345894, 'total_loss': 0.0033882130671775354, 'approx_kl': 0.0010355000849813223, 'clip_fraction': 0.07942708395421505, 'grad_norm': 6.415026664733887}
2022-12-29 12:55:20.344 DEBUG: Taking gradient step
2022-12-29 12:55:20.353 DEBUG: Loss 4: {'policy_loss': -0.027174848743873607, 'entropy_loss': -0.02122090756893158, 'vf_loss': 0.0002803123048792322, 'total_loss': -0.04811544400792595, 'approx_kl': 0.00772236823104322, 'clip_fraction': 0.1484375, 'grad_norm': 7.640218257904053}
2022-12-29 12:55:21.046 DEBUG: Taking gradient step
2022-12-29 12:55:21.055 DEBUG: Loss 5: {'policy_loss': -0.011416111749944724, 'entropy_loss': -0.020645491313189268, 'vf_loss': 0.00026932342366230177, 'total_loss': -0.03179227963947169, 'approx_kl': 0.0034362411097390577, 'clip_fraction': 0.1979166716337204, 'grad_norm': 8.045915603637695}
2022-12-29 12:55:21.778 DEBUG: Taking gradient step
2022-12-29 12:55:21.787 DEBUG: Loss 6: {'policy_loss': 0.015930649123920726, 'entropy_loss': -0.021190569270402193, 'vf_loss': 0.0002572355024290576, 'total_loss': -0.005002684644052412, 'approx_kl': 0.0023048106813803315, 'clip_fraction': 0.1822916679084301, 'grad_norm': 10.45598316192627}
2022-12-29 12:55:22.480 DEBUG: Taking gradient step
2022-12-29 12:55:22.489 DEBUG: Loss 7: {'policy_loss': 0.009993098792946187, 'entropy_loss': -0.021906625013798475, 'vf_loss': 0.0002480421744724201, 'total_loss': -0.011665484046379862, 'approx_kl': 0.000628153036814183, 'clip_fraction': 0.11067708395421505, 'grad_norm': 3.299760580062866}
2022-12-29 12:55:23.186 DEBUG: Taking gradient step
2022-12-29 12:55:23.195 DEBUG: Loss 8: {'policy_loss': 0.013433132809066436, 'entropy_loss': -0.021938801277428865, 'vf_loss': 0.00023706070740590372, 'total_loss': -0.008268607760956528, 'approx_kl': -0.001464107888750732, 'clip_fraction': 0.08203125, 'grad_norm': 9.689602851867676}
2022-12-29 12:55:23.880 DEBUG: Taking gradient step
2022-12-29 12:55:23.890 DEBUG: Loss 9: {'policy_loss': 0.012762831489562889, 'entropy_loss': -0.021539393346756697, 'vf_loss': 0.0002259960689024382, 'total_loss': -0.008550565788291366, 'approx_kl': 0.0015102894976735115, 'clip_fraction': 0.109375, 'grad_norm': 5.392125606536865}
2022-12-29 12:55:23.890 INFO: Optimization: policy loss=0.013, vf loss=0.000, entropy loss=-0.022, total loss=-0.009, num steps=10
2022-12-29 12:55:23.890 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:55:24.578 INFO: Evaluation rollout: return=0.494 (0.0), episode length=3.0
2022-12-29 12:55:24.579 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:55:24.581 INFO: Iteration: 93/137, steps: 20088
2022-12-29 12:56:00.552 DEBUG: Atoms are too close
2022-12-29 12:56:11.736 INFO: Training rollout: return=0.192 (2.4), episode length=3.0
2022-12-29 12:56:11.738 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:56:11.741 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-20088_train.pkl
2022-12-29 12:56:12.543 DEBUG: Taking gradient step
2022-12-29 12:56:12.552 DEBUG: Loss 0: {'policy_loss': -0.018479897342927556, 'entropy_loss': -0.021353026386350393, 'vf_loss': 0.004803266913041897, 'total_loss': -0.03502965681623606, 'approx_kl': -3.121870895128609e-08, 'clip_fraction': 0.0, 'grad_norm': 6.9500861167907715}
2022-12-29 12:56:13.311 DEBUG: Taking gradient step
2022-12-29 12:56:13.320 DEBUG: Loss 1: {'policy_loss': -0.01947165727167677, 'entropy_loss': -0.021523879375308752, 'vf_loss': 0.004795443579525697, 'total_loss': -0.036200093067459825, 'approx_kl': 0.0026133017090614885, 'clip_fraction': 0.010416666977107525, 'grad_norm': 6.480295181274414}
2022-12-29 12:56:14.027 DEBUG: Taking gradient step
2022-12-29 12:56:14.036 DEBUG: Loss 2: {'policy_loss': 0.03156225906882504, 'entropy_loss': -0.021261022426187992, 'vf_loss': 0.007361531265033189, 'total_loss': 0.017662767907670233, 'approx_kl': 0.005905729602091014, 'clip_fraction': 0.01953125, 'grad_norm': 4.87542724609375}
2022-12-29 12:56:14.720 DEBUG: Taking gradient step
2022-12-29 12:56:14.729 DEBUG: Loss 3: {'policy_loss': -0.02710643172158634, 'entropy_loss': -0.020890217274427414, 'vf_loss': 0.004790218694751801, 'total_loss': -0.04320643030126196, 'approx_kl': 0.006554909748956561, 'clip_fraction': 0.07552083395421505, 'grad_norm': 4.981696605682373}
2022-12-29 12:56:15.456 DEBUG: Taking gradient step
2022-12-29 12:56:15.465 DEBUG: Loss 4: {'policy_loss': -0.028555709140370145, 'entropy_loss': -0.020528406836092472, 'vf_loss': 0.004784557080704637, 'total_loss': -0.04429955889575798, 'approx_kl': 0.006943031490663998, 'clip_fraction': 0.08723958395421505, 'grad_norm': 4.519797325134277}
2022-12-29 12:56:16.149 DEBUG: Taking gradient step
2022-12-29 12:56:16.158 DEBUG: Loss 5: {'policy_loss': 0.05601793974025723, 'entropy_loss': -0.01924234046600759, 'vf_loss': 0.009891385041166456, 'total_loss': 0.04666698431541612, 'approx_kl': 0.010336679173633456, 'clip_fraction': 0.1197916679084301, 'grad_norm': 1.5543606281280518}
2022-12-29 12:56:16.843 DEBUG: Taking gradient step
2022-12-29 12:56:16.853 DEBUG: Loss 6: {'policy_loss': -0.03171165246208835, 'entropy_loss': -0.02055908739566803, 'vf_loss': 0.004780201815765715, 'total_loss': -0.04749053804199066, 'approx_kl': 0.0006390749476850033, 'clip_fraction': 0.08072916697710752, 'grad_norm': 0.5524966716766357}
2022-12-29 12:56:17.546 DEBUG: Taking gradient step
2022-12-29 12:56:17.555 DEBUG: Loss 7: {'policy_loss': 0.01155607101874771, 'entropy_loss': -0.02056586742401123, 'vf_loss': 0.007330815551171127, 'total_loss': -0.0016789808540923976, 'approx_kl': 0.0035129854222759604, 'clip_fraction': 0.07682291697710752, 'grad_norm': 0.8917902112007141}
2022-12-29 12:56:18.271 DEBUG: Taking gradient step
2022-12-29 12:56:18.281 DEBUG: Loss 8: {'policy_loss': -0.03368384498138227, 'entropy_loss': -0.020319207571446896, 'vf_loss': 0.00476882319271947, 'total_loss': -0.049234229360109696, 'approx_kl': 0.0011262476909905672, 'clip_fraction': 0.11328125, 'grad_norm': 0.6398284435272217}
2022-12-29 12:56:18.972 DEBUG: Taking gradient step
2022-12-29 12:56:18.982 DEBUG: Loss 9: {'policy_loss': -0.03226514267128035, 'entropy_loss': -0.01988139864988625, 'vf_loss': 0.004764494814152741, 'total_loss': -0.04738204650701386, 'approx_kl': 0.01591401977930218, 'clip_fraction': 0.2330729216337204, 'grad_norm': 1.7784571647644043}
2022-12-29 12:56:18.982 INFO: Optimization: policy loss=-0.032, vf loss=0.005, entropy loss=-0.020, total loss=-0.047, num steps=10
2022-12-29 12:56:18.982 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:56:19.736 INFO: Evaluation rollout: return=0.501 (0.0), episode length=3.0
2022-12-29 12:56:19.737 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:56:19.739 INFO: Iteration: 94/137, steps: 20304
2022-12-29 12:57:07.182 INFO: Training rollout: return=0.480 (0.0), episode length=3.0
2022-12-29 12:57:07.184 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:57:07.187 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-20304_train.pkl
2022-12-29 12:57:07.928 DEBUG: Taking gradient step
2022-12-29 12:57:07.940 DEBUG: Loss 0: {'policy_loss': -0.004404056145393982, 'entropy_loss': -0.022017945535480976, 'vf_loss': 0.00014308102592182887, 'total_loss': -0.02627892065495313, 'approx_kl': 1.9121216610074043e-08, 'clip_fraction': 0.0, 'grad_norm': 15.289239883422852}
2022-12-29 12:57:08.661 DEBUG: Taking gradient step
2022-12-29 12:57:08.677 DEBUG: Loss 1: {'policy_loss': -0.027703562701300668, 'entropy_loss': -0.02130290912464261, 'vf_loss': 0.00013724455075240447, 'total_loss': -0.04886922727519087, 'approx_kl': -0.001004788908176124, 'clip_fraction': 0.0, 'grad_norm': 13.28792953491211}
2022-12-29 12:57:09.359 DEBUG: Taking gradient step
2022-12-29 12:57:09.370 DEBUG: Loss 2: {'policy_loss': -0.02860950063173267, 'entropy_loss': -0.02089555747807026, 'vf_loss': 0.0001306873968464747, 'total_loss': -0.04937437071295645, 'approx_kl': 0.0006640005158260465, 'clip_fraction': 0.07942708395421505, 'grad_norm': 7.483601093292236}
2022-12-29 12:57:10.102 DEBUG: Taking gradient step
2022-12-29 12:57:10.111 DEBUG: Loss 3: {'policy_loss': -0.06990967183194821, 'entropy_loss': -0.02122834324836731, 'vf_loss': 0.00012719657800341406, 'total_loss': -0.0910108185023121, 'approx_kl': 0.007670040271477774, 'clip_fraction': 0.15364583395421505, 'grad_norm': 8.751638412475586}
2022-12-29 12:57:10.795 DEBUG: Taking gradient step
2022-12-29 12:57:10.804 DEBUG: Loss 4: {'policy_loss': 0.002626745607064624, 'entropy_loss': -0.020805119536817074, 'vf_loss': 0.00011857431991130557, 'total_loss': -0.018059799609841148, 'approx_kl': 0.015076008858159184, 'clip_fraction': 0.2552083358168602, 'grad_norm': 13.112787246704102}
2022-12-29 12:57:11.513 DEBUG: Taking gradient step
2022-12-29 12:57:11.523 DEBUG: Loss 5: {'policy_loss': -0.019350596959252106, 'entropy_loss': -0.02110166661441326, 'vf_loss': 0.00011514639961538273, 'total_loss': -0.040337117174049975, 'approx_kl': 0.025726799154654145, 'clip_fraction': 0.265625, 'grad_norm': 5.8155646324157715}
2022-12-29 12:57:12.219 DEBUG: Taking gradient step
2022-12-29 12:57:12.228 DEBUG: Loss 6: {'policy_loss': -0.05436140968974351, 'entropy_loss': -0.02087967237457633, 'vf_loss': 0.00011240311718132564, 'total_loss': -0.07512867894713851, 'approx_kl': 0.01740856491960585, 'clip_fraction': 0.3046875, 'grad_norm': 6.705230236053467}
2022-12-29 12:57:12.929 DEBUG: Taking gradient step
2022-12-29 12:57:12.940 DEBUG: Loss 7: {'policy_loss': 0.04671975915308971, 'entropy_loss': -0.02262437716126442, 'vf_loss': 0.00010540000160367614, 'total_loss': 0.02420078199342897, 'approx_kl': 0.026792178628966212, 'clip_fraction': 0.2669270858168602, 'grad_norm': 9.383581161499023}
2022-12-29 12:57:13.631 DEBUG: Taking gradient step
2022-12-29 12:57:13.640 DEBUG: Loss 8: {'policy_loss': -0.02622900760417081, 'entropy_loss': -0.021932501811534166, 'vf_loss': 0.00010264536883158873, 'total_loss': -0.04805886404687339, 'approx_kl': 0.021223580464720726, 'clip_fraction': 0.25, 'grad_norm': 5.948152542114258}
2022-12-29 12:57:14.342 DEBUG: Taking gradient step
2022-12-29 12:57:14.351 DEBUG: Loss 9: {'policy_loss': -0.03384305344822332, 'entropy_loss': -0.02193626295775175, 'vf_loss': 9.981084590381938e-05, 'total_loss': -0.055679505560071244, 'approx_kl': 0.03631867887452245, 'clip_fraction': 0.1940104216337204, 'grad_norm': 3.8166184425354004}
2022-12-29 12:57:14.351 INFO: Optimization: policy loss=-0.034, vf loss=0.000, entropy loss=-0.022, total loss=-0.056, num steps=10
2022-12-29 12:57:14.352 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:57:15.049 INFO: Evaluation rollout: return=0.502 (0.0), episode length=3.0
2022-12-29 12:57:15.050 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:57:15.052 INFO: Iteration: 95/137, steps: 20520
2022-12-29 12:58:03.245 INFO: Training rollout: return=0.475 (0.0), episode length=3.0
2022-12-29 12:58:03.247 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:58:03.252 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-20520_train.pkl
2022-12-29 12:58:04.042 DEBUG: Taking gradient step
2022-12-29 12:58:04.052 DEBUG: Loss 0: {'policy_loss': -0.014189210206496522, 'entropy_loss': -0.020974098471924663, 'vf_loss': 9.095315370316758e-05, 'total_loss': -0.03507235552471802, 'approx_kl': -2.0566707448210764e-08, 'clip_fraction': 0.0, 'grad_norm': 4.204982280731201}
2022-12-29 12:58:04.757 DEBUG: Taking gradient step
2022-12-29 12:58:04.767 DEBUG: Loss 1: {'policy_loss': 0.010092720506763504, 'entropy_loss': -0.022088013123720884, 'vf_loss': 8.5875476532535e-05, 'total_loss': -0.011909417140424847, 'approx_kl': 6.38207420706749e-05, 'clip_fraction': 0.0, 'grad_norm': 7.291218280792236}
2022-12-29 12:58:05.490 DEBUG: Taking gradient step
2022-12-29 12:58:05.500 DEBUG: Loss 2: {'policy_loss': 0.06091770008640691, 'entropy_loss': -0.022233090363442898, 'vf_loss': 7.925147760342575e-05, 'total_loss': 0.038763861200567434, 'approx_kl': -0.006703240796923637, 'clip_fraction': 0.018229166977107525, 'grad_norm': 10.892414093017578}
2022-12-29 12:58:06.223 DEBUG: Taking gradient step
2022-12-29 12:58:06.232 DEBUG: Loss 3: {'policy_loss': -0.02436301923892532, 'entropy_loss': -0.021961379796266556, 'vf_loss': 8.039293171223422e-05, 'total_loss': -0.04624400610347964, 'approx_kl': 0.010163022670894861, 'clip_fraction': 0.06770833395421505, 'grad_norm': 8.1126127243042}
2022-12-29 12:58:06.933 DEBUG: Taking gradient step
2022-12-29 12:58:06.942 DEBUG: Loss 4: {'policy_loss': -0.014272397745542752, 'entropy_loss': -0.02298810938373208, 'vf_loss': 7.792689370525355e-05, 'total_loss': -0.03718258023556958, 'approx_kl': 0.01241260819369927, 'clip_fraction': 0.08984375, 'grad_norm': 9.134723663330078}
2022-12-29 12:58:07.638 DEBUG: Taking gradient step
2022-12-29 12:58:07.647 DEBUG: Loss 5: {'policy_loss': 0.0016725859360435056, 'entropy_loss': -0.023037286940962076, 'vf_loss': 7.402402708131376e-05, 'total_loss': -0.021290676977837257, 'approx_kl': 0.025726328371092677, 'clip_fraction': 0.1145833358168602, 'grad_norm': 9.64645767211914}
2022-12-29 12:58:08.407 DEBUG: Taking gradient step
2022-12-29 12:58:08.416 DEBUG: Loss 6: {'policy_loss': -0.09039746859053513, 'entropy_loss': -0.023317786864936352, 'vf_loss': 7.510217961099941e-05, 'total_loss': -0.11364015327586048, 'approx_kl': 0.024254167452454567, 'clip_fraction': 0.11067708395421505, 'grad_norm': 10.71962833404541}
2022-12-29 12:58:09.104 DEBUG: Taking gradient step
2022-12-29 12:58:09.113 DEBUG: Loss 7: {'policy_loss': -0.02749510978768284, 'entropy_loss': -0.023309828713536263, 'vf_loss': 6.960892506384709e-05, 'total_loss': -0.05073532957615526, 'approx_kl': 0.03562106587924063, 'clip_fraction': 0.1875, 'grad_norm': 4.920176029205322}
2022-12-29 12:58:09.798 DEBUG: Early stopping at step 8 for reaching max KL.
2022-12-29 12:58:09.798 INFO: Optimization: policy loss=-0.027, vf loss=0.000, entropy loss=-0.023, total loss=-0.051, num steps=8
2022-12-29 12:58:09.798 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:58:10.496 INFO: Evaluation rollout: return=0.506 (0.0), episode length=3.0
2022-12-29 12:58:10.496 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:58:10.498 INFO: Iteration: 96/137, steps: 20736
2022-12-29 12:58:58.644 INFO: Training rollout: return=0.459 (0.1), episode length=3.0
2022-12-29 12:58:58.646 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:58:58.649 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-20736_train.pkl
2022-12-29 12:58:59.382 DEBUG: Taking gradient step
2022-12-29 12:58:59.397 DEBUG: Loss 0: {'policy_loss': 0.018017848536390865, 'entropy_loss': -0.022896986920386553, 'vf_loss': 5.944446165377601e-05, 'total_loss': -0.004819693922341911, 'approx_kl': -8.032657206058502e-09, 'clip_fraction': 0.0, 'grad_norm': 12.704758644104004}
2022-12-29 12:59:00.198 DEBUG: Taking gradient step
2022-12-29 12:59:00.207 DEBUG: Loss 1: {'policy_loss': 0.019937471854083875, 'entropy_loss': -0.02440859144553542, 'vf_loss': 5.786811880500914e-05, 'total_loss': -0.00441325147264654, 'approx_kl': 0.003308233805000782, 'clip_fraction': 0.033854166977107525, 'grad_norm': 14.61605453491211}
2022-12-29 12:59:00.903 DEBUG: Taking gradient step
2022-12-29 12:59:00.914 DEBUG: Loss 2: {'policy_loss': -0.031855431888241185, 'entropy_loss': -0.02390498947352171, 'vf_loss': 5.820272745441681e-05, 'total_loss': -0.05570221863430847, 'approx_kl': 0.01950706820935011, 'clip_fraction': 0.13020833395421505, 'grad_norm': 13.444548606872559}
2022-12-29 12:59:01.609 DEBUG: Taking gradient step
2022-12-29 12:59:01.619 DEBUG: Loss 3: {'policy_loss': -0.052348975271514914, 'entropy_loss': -0.024337605107575655, 'vf_loss': 5.7992630450137215e-05, 'total_loss': -0.07662858774864044, 'approx_kl': 0.026123170042410493, 'clip_fraction': 0.11979166697710752, 'grad_norm': 8.073453903198242}
2022-12-29 12:59:02.318 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-29 12:59:02.318 INFO: Optimization: policy loss=-0.052, vf loss=0.000, entropy loss=-0.024, total loss=-0.077, num steps=4
2022-12-29 12:59:02.318 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:59:03.019 INFO: Evaluation rollout: return=0.508 (0.0), episode length=3.0
2022-12-29 12:59:03.020 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:59:03.022 INFO: Iteration: 97/137, steps: 20952
2022-12-29 12:59:50.060 INFO: Training rollout: return=0.464 (0.1), episode length=3.0
2022-12-29 12:59:50.062 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 12:59:50.064 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-20952_train.pkl
2022-12-29 12:59:50.785 DEBUG: Taking gradient step
2022-12-29 12:59:50.794 DEBUG: Loss 0: {'policy_loss': -0.01034275800062871, 'entropy_loss': -0.024368795566260815, 'vf_loss': 5.570721391773571e-05, 'total_loss': -0.034655846352971795, 'approx_kl': -9.837094694375992e-09, 'clip_fraction': 0.0, 'grad_norm': 15.51174259185791}
2022-12-29 12:59:51.488 DEBUG: Taking gradient step
2022-12-29 12:59:51.498 DEBUG: Loss 1: {'policy_loss': -0.00682737459016167, 'entropy_loss': -0.024329839274287224, 'vf_loss': 5.403699294666921e-05, 'total_loss': -0.03110317687150222, 'approx_kl': 0.005367780104279518, 'clip_fraction': 0.00390625, 'grad_norm': 11.261273384094238}
2022-12-29 12:59:52.198 DEBUG: Taking gradient step
2022-12-29 12:59:52.207 DEBUG: Loss 2: {'policy_loss': -0.014212722689078349, 'entropy_loss': -0.024111938197165728, 'vf_loss': 5.253729852489407e-05, 'total_loss': -0.03827212358771919, 'approx_kl': 0.010731079848483205, 'clip_fraction': 0.04296875, 'grad_norm': 9.642546653747559}
2022-12-29 12:59:52.933 DEBUG: Taking gradient step
2022-12-29 12:59:52.942 DEBUG: Loss 3: {'policy_loss': -0.006511932474949987, 'entropy_loss': -0.024386909790337086, 'vf_loss': 5.0785410588252954e-05, 'total_loss': -0.030848056854698817, 'approx_kl': 0.025852048420347273, 'clip_fraction': 0.049479166977107525, 'grad_norm': 9.61656665802002}
2022-12-29 12:59:53.643 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-29 12:59:53.643 INFO: Optimization: policy loss=-0.007, vf loss=0.000, entropy loss=-0.024, total loss=-0.031, num steps=4
2022-12-29 12:59:53.644 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 12:59:54.402 INFO: Evaluation rollout: return=0.508 (0.0), episode length=3.0
2022-12-29 12:59:54.403 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 12:59:54.405 INFO: Iteration: 98/137, steps: 21168
2022-12-29 13:00:20.901 DEBUG: Atoms are too close
2022-12-29 13:00:41.978 INFO: Training rollout: return=0.175 (2.4), episode length=3.0
2022-12-29 13:00:41.980 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 13:00:41.983 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-21168_train.pkl
2022-12-29 13:00:42.707 DEBUG: Taking gradient step
2022-12-29 13:00:42.716 DEBUG: Loss 0: {'policy_loss': -0.01674599586960177, 'entropy_loss': -0.024440126959234476, 'vf_loss': 0.00325638972192879, 'total_loss': -0.03792973310690745, 'approx_kl': 2.0877147788311845e-08, 'clip_fraction': 0.0, 'grad_norm': 8.36839485168457}
2022-12-29 13:00:43.424 DEBUG: Taking gradient step
2022-12-29 13:00:43.435 DEBUG: Loss 1: {'policy_loss': -0.023671899829697217, 'entropy_loss': -0.025103984866291285, 'vf_loss': 0.003255937460043278, 'total_loss': -0.04551994723594522, 'approx_kl': 0.00651590945199132, 'clip_fraction': 0.015625, 'grad_norm': 7.1354475021362305}
2022-12-29 13:00:44.121 DEBUG: Taking gradient step
2022-12-29 13:00:44.130 DEBUG: Loss 2: {'policy_loss': -0.02133195190081233, 'entropy_loss': -0.025599859189242125, 'vf_loss': 0.003253388314848706, 'total_loss': -0.043678422775205755, 'approx_kl': 0.008429032983258367, 'clip_fraction': 0.11197916697710752, 'grad_norm': 0.4914652407169342}
2022-12-29 13:00:44.833 DEBUG: Taking gradient step
2022-12-29 13:00:44.842 DEBUG: Loss 3: {'policy_loss': -0.02425712592214556, 'entropy_loss': -0.025984271429479122, 'vf_loss': 0.0032544603997488796, 'total_loss': -0.04698693695187581, 'approx_kl': 0.023843910777941346, 'clip_fraction': 0.2122395858168602, 'grad_norm': 0.5325384736061096}
2022-12-29 13:00:45.576 DEBUG: Taking gradient step
2022-12-29 13:00:45.585 DEBUG: Loss 4: {'policy_loss': -0.021653226052976024, 'entropy_loss': -0.026277694385498762, 'vf_loss': 0.003251158242094779, 'total_loss': -0.04467976219638001, 'approx_kl': 0.040798710426315665, 'clip_fraction': 0.2473958358168602, 'grad_norm': 0.580175518989563}
2022-12-29 13:00:46.297 DEBUG: Early stopping at step 5 for reaching max KL.
2022-12-29 13:00:46.297 INFO: Optimization: policy loss=-0.022, vf loss=0.003, entropy loss=-0.026, total loss=-0.045, num steps=5
2022-12-29 13:00:46.298 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 13:00:46.977 INFO: Evaluation rollout: return=0.502 (0.0), episode length=3.0
2022-12-29 13:00:46.979 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 13:00:46.982 INFO: Iteration: 99/137, steps: 21384
2022-12-29 13:00:56.857 DEBUG: There is a single atom floating around
2022-12-29 13:01:34.325 INFO: Training rollout: return=0.182 (2.4), episode length=3.0
2022-12-29 13:01:34.327 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 13:01:34.330 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-21384_train.pkl
2022-12-29 13:01:35.047 DEBUG: Taking gradient step
2022-12-29 13:01:35.057 DEBUG: Loss 0: {'policy_loss': -0.018291298197969773, 'entropy_loss': -0.02627803711220622, 'vf_loss': 0.00322690367208228, 'total_loss': -0.04134243163809371, 'approx_kl': -1.5677262155122662e-08, 'clip_fraction': 0.0, 'grad_norm': 3.23309588432312}
2022-12-29 13:01:35.748 DEBUG: Taking gradient step
2022-12-29 13:01:35.758 DEBUG: Loss 1: {'policy_loss': -0.017370458919807454, 'entropy_loss': -0.026726040989160538, 'vf_loss': 0.003226250458082675, 'total_loss': -0.04087024945088531, 'approx_kl': 0.005390727717895061, 'clip_fraction': 0.0, 'grad_norm': 2.904723882675171}
2022-12-29 13:01:36.474 DEBUG: Taking gradient step
2022-12-29 13:01:36.484 DEBUG: Loss 2: {'policy_loss': -0.01772002794565052, 'entropy_loss': -0.026907185558229685, 'vf_loss': 0.0032264850481268496, 'total_loss': -0.041400728455753356, 'approx_kl': 0.012095347512513399, 'clip_fraction': 0.022135416977107525, 'grad_norm': 0.39978519082069397}
2022-12-29 13:01:37.183 DEBUG: Taking gradient step
2022-12-29 13:01:37.192 DEBUG: Loss 3: {'policy_loss': -0.025285703722250388, 'entropy_loss': -0.026000944897532463, 'vf_loss': 0.0032308617086502485, 'total_loss': -0.04805578691113261, 'approx_kl': 0.022435482125729322, 'clip_fraction': 0.049479166977107525, 'grad_norm': 0.35383331775665283}
2022-12-29 13:01:37.909 DEBUG: Taking gradient step
2022-12-29 13:01:37.919 DEBUG: Loss 4: {'policy_loss': -0.02124413145116083, 'entropy_loss': -0.027782524470239878, 'vf_loss': 0.003228941090083333, 'total_loss': -0.04579771483131738, 'approx_kl': 0.03189763519912958, 'clip_fraction': 0.09895833395421505, 'grad_norm': 0.31585386395454407}
2022-12-29 13:01:38.619 DEBUG: Early stopping at step 5 for reaching max KL.
2022-12-29 13:01:38.619 INFO: Optimization: policy loss=-0.021, vf loss=0.003, entropy loss=-0.028, total loss=-0.046, num steps=5
2022-12-29 13:01:38.620 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 13:01:39.411 INFO: Evaluation rollout: return=0.502 (0.0), episode length=3.0
2022-12-29 13:01:39.412 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 13:01:39.414 INFO: Iteration: 100/137, steps: 21600
2022-12-29 13:01:46.347 DEBUG: Atoms are too close
2022-12-29 13:01:52.262 DEBUG: Atoms are too close
2022-12-29 13:02:07.710 DEBUG: Atoms are too close
2022-12-29 13:02:08.643 DEBUG: Atoms are too close
2022-12-29 13:02:09.914 DEBUG: Atoms are too close
2022-12-29 13:02:25.988 INFO: Training rollout: return=-0.937 (5.1), episode length=3.0
2022-12-29 13:02:25.990 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 13:02:25.992 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-21600_train.pkl
2022-12-29 13:02:26.805 DEBUG: Taking gradient step
2022-12-29 13:02:26.817 DEBUG: Loss 0: {'policy_loss': 0.008724703631913442, 'entropy_loss': -0.027741233818233013, 'vf_loss': 0.028815495033319805, 'total_loss': 0.009798964847000245, 'approx_kl': 1.6065314412117004e-08, 'clip_fraction': 0.0, 'grad_norm': 13.980277061462402}
2022-12-29 13:02:27.516 DEBUG: Taking gradient step
2022-12-29 13:02:27.525 DEBUG: Loss 1: {'policy_loss': 0.003256739987541342, 'entropy_loss': -0.027070324402302504, 'vf_loss': 0.028814016292383095, 'total_loss': 0.00500043187762193, 'approx_kl': 0.008344721398316324, 'clip_fraction': 0.00390625, 'grad_norm': 12.955504417419434}
2022-12-29 13:02:28.226 DEBUG: Taking gradient step
2022-12-29 13:02:28.235 DEBUG: Loss 2: {'policy_loss': -0.054702512108910833, 'entropy_loss': -0.027155110612511635, 'vf_loss': 0.023610323542114325, 'total_loss': -0.05824729917930814, 'approx_kl': 0.02161817834712565, 'clip_fraction': 0.0703125, 'grad_norm': 4.338885307312012}
2022-12-29 13:02:28.954 DEBUG: Taking gradient step
2022-12-29 13:02:28.963 DEBUG: Loss 3: {'policy_loss': -0.05018637396047132, 'entropy_loss': -0.02850964618846774, 'vf_loss': 0.023594811314086365, 'total_loss': -0.0551012088348527, 'approx_kl': 0.04499452514573932, 'clip_fraction': 0.1575520858168602, 'grad_norm': 4.329164028167725}
2022-12-29 13:02:29.657 DEBUG: Taking gradient step
2022-12-29 13:02:29.666 DEBUG: Loss 4: {'policy_loss': -0.05102775340482858, 'entropy_loss': -0.027439740486443043, 'vf_loss': 0.02357349230548013, 'total_loss': -0.0548940015857915, 'approx_kl': 0.04105304938275367, 'clip_fraction': 0.1783854216337204, 'grad_norm': 3.7214860916137695}
2022-12-29 13:02:30.380 DEBUG: Early stopping at step 5 for reaching max KL.
2022-12-29 13:02:30.380 INFO: Optimization: policy loss=-0.051, vf loss=0.024, entropy loss=-0.027, total loss=-0.055, num steps=5
2022-12-29 13:02:30.381 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 13:02:31.145 INFO: Evaluation rollout: return=0.505 (0.0), episode length=3.0
2022-12-29 13:02:31.146 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 13:02:31.148 DEBUG: Deleting old model: runs/H2O/models/H2O_run-1_steps-19656.model
2022-12-29 13:02:31.153 DEBUG: Saving model: runs/H2O/models/H2O_run-1_steps-21816.model
2022-12-29 13:02:31.183 INFO: Iteration: 101/137, steps: 21816
2022-12-29 13:03:18.603 INFO: Training rollout: return=0.467 (0.0), episode length=3.0
2022-12-29 13:03:18.605 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 13:03:18.608 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-21816_train.pkl
2022-12-29 13:03:19.314 DEBUG: Taking gradient step
2022-12-29 13:03:19.324 DEBUG: Loss 0: {'policy_loss': -0.0030454879969678775, 'entropy_loss': -0.027972852811217308, 'vf_loss': 4.804850219565027e-05, 'total_loss': -0.030970292305989536, 'approx_kl': -3.989165087148194e-08, 'clip_fraction': 0.0, 'grad_norm': 6.516493320465088}
2022-12-29 13:03:20.022 DEBUG: Taking gradient step
2022-12-29 13:03:20.033 DEBUG: Loss 1: {'policy_loss': 0.006535949911854702, 'entropy_loss': -0.027704248670488596, 'vf_loss': 5.0821127325307084e-05, 'total_loss': -0.02111747763130859, 'approx_kl': 0.010625289753079414, 'clip_fraction': 0.049479166977107525, 'grad_norm': 6.055311679840088}
2022-12-29 13:03:20.721 DEBUG: Taking gradient step
2022-12-29 13:03:20.730 DEBUG: Loss 2: {'policy_loss': -0.008646747187294829, 'entropy_loss': -0.027470944449305534, 'vf_loss': 5.466641662015731e-05, 'total_loss': -0.0360630252199802, 'approx_kl': 0.019283915404230356, 'clip_fraction': 0.109375, 'grad_norm': 9.179109573364258}
2022-12-29 13:03:21.440 DEBUG: Taking gradient step
2022-12-29 13:03:21.449 DEBUG: Loss 3: {'policy_loss': -0.021034448439143545, 'entropy_loss': -0.0275178337469697, 'vf_loss': 5.782000523582718e-05, 'total_loss': -0.04849446218087742, 'approx_kl': 0.030578750651329756, 'clip_fraction': 0.1510416679084301, 'grad_norm': 14.488277435302734}
2022-12-29 13:03:22.149 DEBUG: Taking gradient step
2022-12-29 13:03:22.162 DEBUG: Loss 4: {'policy_loss': -0.02504097848022132, 'entropy_loss': -0.027027472387999296, 'vf_loss': 6.153032423247462e-05, 'total_loss': -0.052006920543988144, 'approx_kl': 0.020729200914502144, 'clip_fraction': 0.10807291697710752, 'grad_norm': 11.886122703552246}
2022-12-29 13:03:22.925 DEBUG: Early stopping at step 5 for reaching max KL.
2022-12-29 13:03:22.925 INFO: Optimization: policy loss=-0.025, vf loss=0.000, entropy loss=-0.027, total loss=-0.052, num steps=5
2022-12-29 13:03:22.926 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 13:03:23.609 INFO: Evaluation rollout: return=0.505 (0.0), episode length=3.0
2022-12-29 13:03:23.610 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 13:03:23.611 INFO: Iteration: 102/137, steps: 22032
2022-12-29 13:04:11.015 INFO: Training rollout: return=0.457 (0.1), episode length=3.0
2022-12-29 13:04:11.017 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 13:04:11.019 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-22032_train.pkl
2022-12-29 13:04:11.727 DEBUG: Taking gradient step
2022-12-29 13:04:11.736 DEBUG: Loss 0: {'policy_loss': 0.03944072101089437, 'entropy_loss': -0.0284208869561553, 'vf_loss': 5.904715811284719e-05, 'total_loss': 0.011078881212851915, 'approx_kl': 4.873921710668583e-08, 'clip_fraction': 0.0, 'grad_norm': 19.03287124633789}
2022-12-29 13:04:12.425 DEBUG: Taking gradient step
2022-12-29 13:04:12.436 DEBUG: Loss 1: {'policy_loss': -0.029978257082373387, 'entropy_loss': -0.028434331063181162, 'vf_loss': 6.370365312774039e-05, 'total_loss': -0.05834888449242681, 'approx_kl': 0.0026064779376611114, 'clip_fraction': 0.01171875, 'grad_norm': 5.908157825469971}
2022-12-29 13:04:13.125 DEBUG: Taking gradient step
2022-12-29 13:04:13.134 DEBUG: Loss 2: {'policy_loss': -0.04075618719889374, 'entropy_loss': -0.027634058613330126, 'vf_loss': 6.643775113265274e-05, 'total_loss': -0.06832380806109123, 'approx_kl': 0.026378589449450374, 'clip_fraction': 0.11848958395421505, 'grad_norm': 8.3284273147583}
2022-12-29 13:04:13.884 DEBUG: Taking gradient step
2022-12-29 13:04:13.893 DEBUG: Loss 3: {'policy_loss': -0.026350735398894636, 'entropy_loss': -0.027636695187538862, 'vf_loss': 6.733513852693078e-05, 'total_loss': -0.05392009544790656, 'approx_kl': 0.03770494554191828, 'clip_fraction': 0.15364583395421505, 'grad_norm': 9.005111694335938}
2022-12-29 13:04:14.633 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-29 13:04:14.633 INFO: Optimization: policy loss=-0.026, vf loss=0.000, entropy loss=-0.028, total loss=-0.054, num steps=4
2022-12-29 13:04:14.633 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 13:04:15.311 INFO: Evaluation rollout: return=0.506 (0.0), episode length=3.0
2022-12-29 13:04:15.313 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 13:04:15.315 INFO: Iteration: 103/137, steps: 22248
2022-12-29 13:04:29.616 DEBUG: Atoms are too close
2022-12-29 13:05:02.692 INFO: Training rollout: return=0.181 (2.4), episode length=3.0
2022-12-29 13:05:02.694 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 13:05:02.696 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-22248_train.pkl
2022-12-29 13:05:03.416 DEBUG: Taking gradient step
2022-12-29 13:05:03.427 DEBUG: Loss 0: {'policy_loss': 0.036298835119263045, 'entropy_loss': -0.0276333917863667, 'vf_loss': 0.007333186802982327, 'total_loss': 0.015998630135878676, 'approx_kl': 1.8471230767147517e-08, 'clip_fraction': 0.0, 'grad_norm': 13.523055076599121}
2022-12-29 13:05:04.119 DEBUG: Taking gradient step
2022-12-29 13:05:04.129 DEBUG: Loss 1: {'policy_loss': 0.030762144668416373, 'entropy_loss': -0.028175681363791227, 'vf_loss': 0.007332195184541824, 'total_loss': 0.009918658489166975, 'approx_kl': 0.013763768132776022, 'clip_fraction': 0.041666666977107525, 'grad_norm': 2.05452299118042}
2022-12-29 13:05:04.813 DEBUG: Taking gradient step
2022-12-29 13:05:04.822 DEBUG: Loss 2: {'policy_loss': 0.027917123222304992, 'entropy_loss': -0.027637514285743237, 'vf_loss': 0.007335533529353207, 'total_loss': 0.007615142465914958, 'approx_kl': 0.030058293603360653, 'clip_fraction': 0.0859375, 'grad_norm': 4.591961860656738}
2022-12-29 13:05:05.542 DEBUG: Taking gradient step
2022-12-29 13:05:05.552 DEBUG: Loss 3: {'policy_loss': 0.018382235739886156, 'entropy_loss': -0.028450467623770237, 'vf_loss': 0.007350640358099454, 'total_loss': -0.0027175915257846156, 'approx_kl': 0.03117968048900366, 'clip_fraction': 0.1536458358168602, 'grad_norm': 1.9342172145843506}
2022-12-29 13:05:06.242 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-29 13:05:06.242 INFO: Optimization: policy loss=0.018, vf loss=0.007, entropy loss=-0.028, total loss=-0.003, num steps=4
2022-12-29 13:05:06.243 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 13:05:06.915 INFO: Evaluation rollout: return=0.511 (0.0), episode length=3.0
2022-12-29 13:05:06.916 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 13:05:06.918 INFO: Iteration: 104/137, steps: 22464
2022-12-29 13:05:54.162 INFO: Training rollout: return=0.456 (0.0), episode length=3.0
2022-12-29 13:05:54.163 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 13:05:54.166 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-22464_train.pkl
2022-12-29 13:05:54.877 DEBUG: Taking gradient step
2022-12-29 13:05:54.886 DEBUG: Loss 0: {'policy_loss': 0.0011828361423316992, 'entropy_loss': -0.027634961996227503, 'vf_loss': 6.844094100130848e-05, 'total_loss': -0.026383684912894497, 'approx_kl': 8.381903171539307e-09, 'clip_fraction': 0.0, 'grad_norm': 4.706882953643799}
2022-12-29 13:05:55.612 DEBUG: Taking gradient step
2022-12-29 13:05:55.628 DEBUG: Loss 1: {'policy_loss': -0.002761198440409005, 'entropy_loss': -0.028165414463728666, 'vf_loss': 7.00817334410831e-05, 'total_loss': -0.03085653117069659, 'approx_kl': 0.0007413991261273623, 'clip_fraction': 0.0078125, 'grad_norm': 7.215110778808594}
2022-12-29 13:05:56.323 DEBUG: Taking gradient step
2022-12-29 13:05:56.332 DEBUG: Loss 2: {'policy_loss': -0.04446201260369524, 'entropy_loss': -0.026777678169310093, 'vf_loss': 7.255367921469799e-05, 'total_loss': -0.07116713709379063, 'approx_kl': 0.006644698325544596, 'clip_fraction': 0.08072916697710752, 'grad_norm': 6.600033760070801}
2022-12-29 13:05:57.032 DEBUG: Taking gradient step
2022-12-29 13:05:57.043 DEBUG: Loss 3: {'policy_loss': -0.0626808071500981, 'entropy_loss': -0.027233717497438192, 'vf_loss': 7.4366759417866e-05, 'total_loss': -0.08984015788811844, 'approx_kl': 0.014556809095665812, 'clip_fraction': 0.1953125, 'grad_norm': 15.385208129882812}
2022-12-29 13:05:57.770 DEBUG: Taking gradient step
2022-12-29 13:05:57.781 DEBUG: Loss 4: {'policy_loss': -0.04496334243302601, 'entropy_loss': -0.027666506357491016, 'vf_loss': 7.34846389111169e-05, 'total_loss': -0.0725563641516059, 'approx_kl': 0.010937649523839355, 'clip_fraction': 0.24609375, 'grad_norm': 9.34383487701416}
2022-12-29 13:05:58.488 DEBUG: Taking gradient step
2022-12-29 13:05:58.498 DEBUG: Loss 5: {'policy_loss': 0.03178588660278644, 'entropy_loss': -0.02722332999110222, 'vf_loss': 7.258920335748347e-05, 'total_loss': 0.004635145815041701, 'approx_kl': 0.010536253452301025, 'clip_fraction': 0.2799479216337204, 'grad_norm': 16.674163818359375}
2022-12-29 13:05:59.283 DEBUG: Taking gradient step
2022-12-29 13:05:59.297 DEBUG: Loss 6: {'policy_loss': -0.07396841992888646, 'entropy_loss': -0.02573941508308053, 'vf_loss': 7.59569219365869e-05, 'total_loss': -0.0996318780900304, 'approx_kl': 0.010798105970025063, 'clip_fraction': 0.328125, 'grad_norm': 11.794902801513672}
2022-12-29 13:06:00.053 DEBUG: Taking gradient step
2022-12-29 13:06:00.067 DEBUG: Loss 7: {'policy_loss': 0.003446789554487434, 'entropy_loss': -0.0274017546325922, 'vf_loss': 7.310815691771936e-05, 'total_loss': -0.023881856921187047, 'approx_kl': 0.04463222809135914, 'clip_fraction': 0.4010416716337204, 'grad_norm': 10.401023864746094}
2022-12-29 13:06:00.816 DEBUG: Taking gradient step
2022-12-29 13:06:00.829 DEBUG: Loss 8: {'policy_loss': -0.04000510673266111, 'entropy_loss': -0.026677534449845552, 'vf_loss': 7.419957202529242e-05, 'total_loss': -0.06660844161048138, 'approx_kl': 0.04241496417671442, 'clip_fraction': 0.4127604216337204, 'grad_norm': 6.184337139129639}
2022-12-29 13:06:01.536 DEBUG: Early stopping at step 9 for reaching max KL.
2022-12-29 13:06:01.536 INFO: Optimization: policy loss=-0.040, vf loss=0.000, entropy loss=-0.027, total loss=-0.067, num steps=9
2022-12-29 13:06:01.537 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 13:06:02.168 INFO: Evaluation rollout: return=0.509 (0.0), episode length=3.0
2022-12-29 13:06:02.169 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 13:06:02.171 INFO: Iteration: 105/137, steps: 22680
2022-12-29 13:06:15.674 DEBUG: Atoms are too close
2022-12-29 13:06:49.941 INFO: Training rollout: return=0.180 (2.4), episode length=3.0
2022-12-29 13:06:49.943 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 13:06:49.946 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-22680_train.pkl
2022-12-29 13:06:50.675 DEBUG: Taking gradient step
2022-12-29 13:06:50.684 DEBUG: Loss 0: {'policy_loss': -0.018282980842544493, 'entropy_loss': -0.02714553428813815, 'vf_loss': 0.004745771531138098, 'total_loss': -0.040682743599544546, 'approx_kl': 9.158005326304064e-09, 'clip_fraction': 0.0, 'grad_norm': 13.894939422607422}
2022-12-29 13:06:51.401 DEBUG: Taking gradient step
2022-12-29 13:06:51.410 DEBUG: Loss 1: {'policy_loss': -0.024442185844577177, 'entropy_loss': -0.02679245127364993, 'vf_loss': 0.00474612587694029, 'total_loss': -0.04648851124128681, 'approx_kl': -0.00358909135684371, 'clip_fraction': 0.022135416977107525, 'grad_norm': 12.737831115722656}
2022-12-29 13:06:52.136 DEBUG: Taking gradient step
2022-12-29 13:06:52.145 DEBUG: Loss 2: {'policy_loss': -0.028450912542941235, 'entropy_loss': -0.026592922396957874, 'vf_loss': 0.004744186296065643, 'total_loss': -0.05029964864383346, 'approx_kl': -0.011060298420488834, 'clip_fraction': 0.1276041679084301, 'grad_norm': 2.827265501022339}
2022-12-29 13:06:52.854 DEBUG: Taking gradient step
2022-12-29 13:06:52.864 DEBUG: Loss 3: {'policy_loss': -0.03157839846370764, 'entropy_loss': -0.025700779631733894, 'vf_loss': 0.004745078304456682, 'total_loss': -0.05253409979098485, 'approx_kl': -0.010707359877415001, 'clip_fraction': 0.2018229179084301, 'grad_norm': 1.4525431394577026}
2022-12-29 13:06:53.554 DEBUG: Taking gradient step
2022-12-29 13:06:53.563 DEBUG: Loss 4: {'policy_loss': 0.016192511508106314, 'entropy_loss': -0.026166897267103195, 'vf_loss': 0.007335670066050331, 'total_loss': -0.0026387156929465402, 'approx_kl': 0.0004249592311680317, 'clip_fraction': 0.27734375, 'grad_norm': 2.0434703826904297}
2022-12-29 13:06:54.246 DEBUG: Taking gradient step
2022-12-29 13:06:54.258 DEBUG: Loss 5: {'policy_loss': -0.02981592643031339, 'entropy_loss': -0.02689661318436265, 'vf_loss': 0.0047433346560763305, 'total_loss': -0.051969204958599705, 'approx_kl': -0.013547840528190136, 'clip_fraction': 0.3059895858168602, 'grad_norm': 1.3367780447006226}
2022-12-29 13:06:54.954 DEBUG: Taking gradient step
2022-12-29 13:06:54.963 DEBUG: Loss 6: {'policy_loss': -0.030288097484216268, 'entropy_loss': -0.02634091954678297, 'vf_loss': 0.0047445676350148045, 'total_loss': -0.05188444939598444, 'approx_kl': 0.00929801119491458, 'clip_fraction': 0.28515625, 'grad_norm': 1.3067117929458618}
2022-12-29 13:06:55.676 DEBUG: Taking gradient step
2022-12-29 13:06:55.687 DEBUG: Loss 7: {'policy_loss': -0.029672289085181425, 'entropy_loss': -0.02621609764173627, 'vf_loss': 0.00474311969972155, 'total_loss': -0.05114526702719614, 'approx_kl': 0.009977075387723744, 'clip_fraction': 0.2916666716337204, 'grad_norm': 1.61565363407135}
2022-12-29 13:06:56.393 DEBUG: Taking gradient step
2022-12-29 13:06:56.402 DEBUG: Loss 8: {'policy_loss': 0.02380109543600297, 'entropy_loss': -0.026230433024466038, 'vf_loss': 0.007337537419663903, 'total_loss': 0.004908199831200839, 'approx_kl': -0.00044548558071255684, 'clip_fraction': 0.24609375, 'grad_norm': 1.5720367431640625}
2022-12-29 13:06:57.164 DEBUG: Taking gradient step
2022-12-29 13:06:57.173 DEBUG: Loss 9: {'policy_loss': -0.031570844109821916, 'entropy_loss': -0.025658209808170795, 'vf_loss': 0.00474205903763105, 'total_loss': -0.052486994880361654, 'approx_kl': 0.0003553119022399187, 'clip_fraction': 0.2356770858168602, 'grad_norm': 1.7442620992660522}
2022-12-29 13:06:57.173 INFO: Optimization: policy loss=-0.032, vf loss=0.005, entropy loss=-0.026, total loss=-0.052, num steps=10
2022-12-29 13:06:57.174 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 13:06:57.858 INFO: Evaluation rollout: return=0.509 (0.0), episode length=3.0
2022-12-29 13:06:57.859 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 13:06:57.861 INFO: Iteration: 106/137, steps: 22896
2022-12-29 13:07:17.250 DEBUG: Atoms are too close
2022-12-29 13:07:46.028 INFO: Training rollout: return=0.176 (2.4), episode length=3.0
2022-12-29 13:07:46.029 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 13:07:46.032 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-22896_train.pkl
2022-12-29 13:07:46.790 DEBUG: Taking gradient step
2022-12-29 13:07:46.799 DEBUG: Loss 0: {'policy_loss': -0.01452451068859852, 'entropy_loss': -0.026405606418848038, 'vf_loss': 0.0032513607256072926, 'total_loss': -0.03767875638183926, 'approx_kl': 1.098184654324541e-08, 'clip_fraction': 0.0, 'grad_norm': 8.95661449432373}
2022-12-29 13:07:47.504 DEBUG: Taking gradient step
2022-12-29 13:07:47.515 DEBUG: Loss 1: {'policy_loss': -0.013786424338203575, 'entropy_loss': -0.025927087757736444, 'vf_loss': 0.0032512660520159125, 'total_loss': -0.036462246043924104, 'approx_kl': -0.006038960185833275, 'clip_fraction': 0.0, 'grad_norm': 9.237775802612305}
2022-12-29 13:07:48.260 DEBUG: Taking gradient step
2022-12-29 13:07:48.270 DEBUG: Loss 2: {'policy_loss': -0.015258515636235401, 'entropy_loss': -0.026552455499768257, 'vf_loss': 0.0032501154534468123, 'total_loss': -0.03856085568255684, 'approx_kl': -0.003483517561107874, 'clip_fraction': 0.026041666977107525, 'grad_norm': 8.993098258972168}
2022-12-29 13:07:48.946 DEBUG: Taking gradient step
2022-12-29 13:07:48.957 DEBUG: Loss 3: {'policy_loss': 0.04335029517951426, 'entropy_loss': -0.026823711581528187, 'vf_loss': 0.005893270977906604, 'total_loss': 0.02241985457589267, 'approx_kl': -0.008484763326123357, 'clip_fraction': 0.08984375, 'grad_norm': 21.993818283081055}
2022-12-29 13:07:49.632 DEBUG: Taking gradient step
2022-12-29 13:07:49.641 DEBUG: Loss 4: {'policy_loss': -0.023426799475610882, 'entropy_loss': -0.02712032711133361, 'vf_loss': 0.0032465300604667727, 'total_loss': -0.04730059652647771, 'approx_kl': 0.00024001847486943007, 'clip_fraction': 0.1328125, 'grad_norm': 0.8967084288597107}
2022-12-29 13:07:50.368 DEBUG: Taking gradient step
2022-12-29 13:07:50.378 DEBUG: Loss 5: {'policy_loss': -0.020421086864094343, 'entropy_loss': -0.02682304149493575, 'vf_loss': 0.003242372845531906, 'total_loss': -0.04400175551349819, 'approx_kl': 0.009577383985742927, 'clip_fraction': 0.18359375, 'grad_norm': 1.108898401260376}
2022-12-29 13:07:51.075 DEBUG: Taking gradient step
2022-12-29 13:07:51.084 DEBUG: Loss 6: {'policy_loss': -0.023847904329303653, 'entropy_loss': -0.026154456194490194, 'vf_loss': 0.003241507122012752, 'total_loss': -0.04676085340178109, 'approx_kl': 0.009064565878361464, 'clip_fraction': 0.1822916679084301, 'grad_norm': 1.0773818492889404}
2022-12-29 13:07:51.786 DEBUG: Taking gradient step
2022-12-29 13:07:51.795 DEBUG: Loss 7: {'policy_loss': -0.024278169005571695, 'entropy_loss': -0.02676316211000085, 'vf_loss': 0.003238471014321439, 'total_loss': -0.0478028601012511, 'approx_kl': 0.0009437091648578644, 'clip_fraction': 0.1510416679084301, 'grad_norm': 0.8842535614967346}
2022-12-29 13:07:52.507 DEBUG: Taking gradient step
2022-12-29 13:07:52.520 DEBUG: Loss 8: {'policy_loss': -0.023568240180736617, 'entropy_loss': -0.02701784996315837, 'vf_loss': 0.003231754300152071, 'total_loss': -0.04735433584374291, 'approx_kl': 0.0039808861911296844, 'clip_fraction': 0.07161458395421505, 'grad_norm': 0.8621576428413391}
2022-12-29 13:07:53.278 DEBUG: Taking gradient step
2022-12-29 13:07:53.292 DEBUG: Loss 9: {'policy_loss': -0.023003864944689142, 'entropy_loss': -0.026949793566018343, 'vf_loss': 0.003230029644227152, 'total_loss': -0.046723628866480335, 'approx_kl': -0.002496955683454871, 'clip_fraction': 0.0390625, 'grad_norm': 7.611640930175781}
2022-12-29 13:07:53.292 INFO: Optimization: policy loss=-0.023, vf loss=0.003, entropy loss=-0.027, total loss=-0.047, num steps=10
2022-12-29 13:07:53.293 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 13:07:53.986 INFO: Evaluation rollout: return=0.508 (0.0), episode length=3.0
2022-12-29 13:07:53.987 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 13:07:53.989 INFO: Iteration: 107/137, steps: 23112
2022-12-29 13:08:42.819 INFO: Training rollout: return=0.471 (0.0), episode length=3.0
2022-12-29 13:08:42.820 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 13:08:42.823 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-23112_train.pkl
2022-12-29 13:08:43.515 DEBUG: Taking gradient step
2022-12-29 13:08:43.524 DEBUG: Loss 0: {'policy_loss': 0.004863501441594186, 'entropy_loss': -0.026934136170893908, 'vf_loss': 5.941312551288418e-05, 'total_loss': -0.022011221603786837, 'approx_kl': -2.0372681319713593e-08, 'clip_fraction': 0.0, 'grad_norm': 8.396525382995605}
2022-12-29 13:08:44.247 DEBUG: Taking gradient step
2022-12-29 13:08:44.256 DEBUG: Loss 1: {'policy_loss': 0.005631978250940025, 'entropy_loss': -0.027149740140885115, 'vf_loss': 5.736196243887615e-05, 'total_loss': -0.021460399927506216, 'approx_kl': 0.0042570753721520305, 'clip_fraction': 0.0, 'grad_norm': 7.505400657653809}
2022-12-29 13:08:44.948 DEBUG: Taking gradient step
2022-12-29 13:08:44.958 DEBUG: Loss 2: {'policy_loss': 0.00042612087307535105, 'entropy_loss': -0.027487631421536207, 'vf_loss': 5.505537636473007e-05, 'total_loss': -0.02700645517209612, 'approx_kl': 0.010289395664585754, 'clip_fraction': 0.07552083395421505, 'grad_norm': 6.653335094451904}
2022-12-29 13:08:45.618 DEBUG: Taking gradient step
2022-12-29 13:08:45.628 DEBUG: Loss 3: {'policy_loss': 0.02663864801752829, 'entropy_loss': -0.026922327931970358, 'vf_loss': 5.296368103885604e-05, 'total_loss': -0.0002307162334032123, 'approx_kl': 0.018559008836746216, 'clip_fraction': 0.09244791697710752, 'grad_norm': 7.177402019500732}
2022-12-29 13:08:46.318 DEBUG: Taking gradient step
2022-12-29 13:08:46.327 DEBUG: Loss 4: {'policy_loss': 0.009901610768267705, 'entropy_loss': -0.02719109458848834, 'vf_loss': 5.194248860653239e-05, 'total_loss': -0.0172375413316141, 'approx_kl': 0.021592285367660224, 'clip_fraction': 0.10026041697710752, 'grad_norm': 5.233780860900879}
2022-12-29 13:08:47.019 DEBUG: Taking gradient step
2022-12-29 13:08:47.028 DEBUG: Loss 5: {'policy_loss': -0.02089237070399183, 'entropy_loss': -0.02670454839244485, 'vf_loss': 5.35907365627974e-05, 'total_loss': -0.047543328359873877, 'approx_kl': 0.023185694124549627, 'clip_fraction': 0.1015625, 'grad_norm': 6.07546329498291}
2022-12-29 13:08:47.753 DEBUG: Taking gradient step
2022-12-29 13:08:47.763 DEBUG: Loss 6: {'policy_loss': 0.024217029890092237, 'entropy_loss': -0.02744552306830883, 'vf_loss': 4.941615113333619e-05, 'total_loss': -0.0031790770270832616, 'approx_kl': 0.02456469787284732, 'clip_fraction': 0.10546875, 'grad_norm': 8.725196838378906}
2022-12-29 13:08:48.464 DEBUG: Taking gradient step
2022-12-29 13:08:48.473 DEBUG: Loss 7: {'policy_loss': 0.0361174974958712, 'entropy_loss': -0.026683567091822624, 'vf_loss': 4.944079899746967e-05, 'total_loss': 0.009483371203046043, 'approx_kl': 0.022562364698387682, 'clip_fraction': 0.1315104179084301, 'grad_norm': 8.419371604919434}
2022-12-29 13:08:49.161 DEBUG: Taking gradient step
2022-12-29 13:08:49.170 DEBUG: Loss 8: {'policy_loss': -0.005519167855209969, 'entropy_loss': -0.027386087458580732, 'vf_loss': 5.032106815083183e-05, 'total_loss': -0.03285493424563987, 'approx_kl': 0.028567684581503272, 'clip_fraction': 0.1432291679084301, 'grad_norm': 7.262542724609375}
2022-12-29 13:08:49.897 DEBUG: Taking gradient step
2022-12-29 13:08:49.910 DEBUG: Loss 9: {'policy_loss': 0.04424872509911111, 'entropy_loss': -0.026378349401056767, 'vf_loss': 4.7607314331656874e-05, 'total_loss': 0.017917983012386007, 'approx_kl': 0.04228193452581763, 'clip_fraction': 0.1692708358168602, 'grad_norm': 4.54170036315918}
2022-12-29 13:08:49.911 INFO: Optimization: policy loss=0.044, vf loss=0.000, entropy loss=-0.026, total loss=0.018, num steps=10
2022-12-29 13:08:49.911 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 13:08:50.581 INFO: Evaluation rollout: return=0.509 (0.0), episode length=3.0
2022-12-29 13:08:50.582 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 13:08:50.584 INFO: Iteration: 108/137, steps: 23328
2022-12-29 13:09:37.626 INFO: Training rollout: return=0.465 (0.0), episode length=3.0
2022-12-29 13:09:37.628 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 13:09:37.631 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-23328_train.pkl
2022-12-29 13:09:38.348 DEBUG: Taking gradient step
2022-12-29 13:09:38.357 DEBUG: Loss 0: {'policy_loss': -0.008860977267840225, 'entropy_loss': -0.027304209303110838, 'vf_loss': 4.222557677769175e-05, 'total_loss': -0.03612296099417337, 'approx_kl': -1.6725000051565075e-08, 'clip_fraction': 0.0, 'grad_norm': 14.750127792358398}
2022-12-29 13:09:39.052 DEBUG: Taking gradient step
2022-12-29 13:09:39.061 DEBUG: Loss 1: {'policy_loss': 0.0628334934070589, 'entropy_loss': -0.02655999269336462, 'vf_loss': 3.843247323354484e-05, 'total_loss': 0.03631193318692781, 'approx_kl': 0.002636287361383438, 'clip_fraction': 0.0, 'grad_norm': 10.96664047241211}
2022-12-29 13:09:39.760 DEBUG: Taking gradient step
2022-12-29 13:09:39.770 DEBUG: Loss 2: {'policy_loss': -0.0013711408784756393, 'entropy_loss': -0.026655422989279032, 'vf_loss': 4.1869472593812e-05, 'total_loss': -0.02798469439516086, 'approx_kl': 0.010020171757787466, 'clip_fraction': 0.01171875, 'grad_norm': 12.695201873779297}
2022-12-29 13:09:40.459 DEBUG: Taking gradient step
2022-12-29 13:09:40.468 DEBUG: Loss 3: {'policy_loss': -0.009178467386575358, 'entropy_loss': -0.02725470205768943, 'vf_loss': 4.0852530563537414e-05, 'total_loss': -0.036392316913701254, 'approx_kl': 0.023175315582193434, 'clip_fraction': 0.07161458395421505, 'grad_norm': 5.199162483215332}
2022-12-29 13:09:41.173 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-29 13:09:41.173 INFO: Optimization: policy loss=-0.009, vf loss=0.000, entropy loss=-0.027, total loss=-0.036, num steps=4
2022-12-29 13:09:41.174 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 13:09:41.839 INFO: Evaluation rollout: return=0.508 (0.0), episode length=3.0
2022-12-29 13:09:41.840 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 13:09:41.841 INFO: Iteration: 109/137, steps: 23544
2022-12-29 13:10:29.653 INFO: Training rollout: return=0.458 (0.0), episode length=3.0
2022-12-29 13:10:29.655 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 13:10:29.658 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-23544_train.pkl
2022-12-29 13:10:30.381 DEBUG: Taking gradient step
2022-12-29 13:10:30.395 DEBUG: Loss 0: {'policy_loss': -0.06298825746819313, 'entropy_loss': -0.02655253279954195, 'vf_loss': 4.220992292478193e-05, 'total_loss': -0.0894985803448103, 'approx_kl': -5.820766091346741e-09, 'clip_fraction': 0.0, 'grad_norm': 16.28006362915039}
2022-12-29 13:10:31.126 DEBUG: Taking gradient step
2022-12-29 13:10:31.135 DEBUG: Loss 1: {'policy_loss': 0.021907555229390793, 'entropy_loss': -0.02737741731107235, 'vf_loss': 3.827695804786658e-05, 'total_loss': -0.005431585123633689, 'approx_kl': 0.0058283028192818165, 'clip_fraction': 0.029947916977107525, 'grad_norm': 12.340010643005371}
2022-12-29 13:10:31.867 DEBUG: Taking gradient step
2022-12-29 13:10:31.876 DEBUG: Loss 2: {'policy_loss': -0.024627610052752442, 'entropy_loss': -0.02716585388407111, 'vf_loss': 3.8792978973816445e-05, 'total_loss': -0.05175467095784973, 'approx_kl': 0.027845474192872643, 'clip_fraction': 0.09895833395421505, 'grad_norm': 8.871062278747559}
2022-12-29 13:10:32.611 DEBUG: Early stopping at step 3 for reaching max KL.
2022-12-29 13:10:32.612 INFO: Optimization: policy loss=-0.025, vf loss=0.000, entropy loss=-0.027, total loss=-0.052, num steps=3
2022-12-29 13:10:32.612 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 13:10:33.337 INFO: Evaluation rollout: return=0.509 (0.0), episode length=3.0
2022-12-29 13:10:33.337 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 13:10:33.339 INFO: Iteration: 110/137, steps: 23760
2022-12-29 13:10:39.987 DEBUG: Atoms are too close
2022-12-29 13:11:21.076 INFO: Training rollout: return=0.177 (2.4), episode length=3.0
2022-12-29 13:11:21.078 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 13:11:21.080 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-23760_train.pkl
2022-12-29 13:11:21.813 DEBUG: Taking gradient step
2022-12-29 13:11:21.822 DEBUG: Loss 0: {'policy_loss': -0.017069850619685342, 'entropy_loss': -0.027470901608467102, 'vf_loss': 0.004750672477500407, 'total_loss': -0.03979007975065203, 'approx_kl': -2.0178667625714297e-09, 'clip_fraction': 0.0, 'grad_norm': 13.184587478637695}
2022-12-29 13:11:22.513 DEBUG: Taking gradient step
2022-12-29 13:11:22.523 DEBUG: Loss 1: {'policy_loss': 0.0388259514234163, 'entropy_loss': -0.026711398735642433, 'vf_loss': 0.007333255461495474, 'total_loss': 0.01944780814926933, 'approx_kl': 0.0020608799532055855, 'clip_fraction': 0.01171875, 'grad_norm': 17.559343338012695}
2022-12-29 13:11:23.226 DEBUG: Taking gradient step
2022-12-29 13:11:23.235 DEBUG: Loss 2: {'policy_loss': -0.02194782258549953, 'entropy_loss': -0.0272908010520041, 'vf_loss': 0.0047512079997482125, 'total_loss': -0.044487415637755406, 'approx_kl': -0.004617283120751381, 'clip_fraction': 0.06770833395421505, 'grad_norm': 12.278157234191895}
2022-12-29 13:11:23.917 DEBUG: Taking gradient step
2022-12-29 13:11:23.926 DEBUG: Loss 3: {'policy_loss': -0.029416103133382172, 'entropy_loss': -0.028134526684880257, 'vf_loss': 0.004751977845021862, 'total_loss': -0.052798651973240567, 'approx_kl': -0.0010337282437831163, 'clip_fraction': 0.1510416679084301, 'grad_norm': 3.248882293701172}
2022-12-29 13:11:24.612 DEBUG: Taking gradient step
2022-12-29 13:11:24.621 DEBUG: Loss 4: {'policy_loss': 0.02537493963591942, 'entropy_loss': -0.027626415248960257, 'vf_loss': 0.007342785804704479, 'total_loss': 0.005091310191663645, 'approx_kl': 0.016395250102505088, 'clip_fraction': 0.2604166716337204, 'grad_norm': 1.171294927597046}
2022-12-29 13:11:25.311 DEBUG: Taking gradient step
2022-12-29 13:11:25.321 DEBUG: Loss 5: {'policy_loss': -0.027152682990051816, 'entropy_loss': -0.027902163099497557, 'vf_loss': 0.004748828499121752, 'total_loss': -0.05030601759042762, 'approx_kl': 0.00997266685590148, 'clip_fraction': 0.3229166716337204, 'grad_norm': 1.1915372610092163}
2022-12-29 13:11:26.018 DEBUG: Taking gradient step
2022-12-29 13:11:26.027 DEBUG: Loss 6: {'policy_loss': -0.029100117934936942, 'entropy_loss': -0.02710638800635934, 'vf_loss': 0.004748168565760026, 'total_loss': -0.051458337375536255, 'approx_kl': 0.0006046525668352842, 'clip_fraction': 0.3424479216337204, 'grad_norm': 1.2863438129425049}
2022-12-29 13:11:26.726 DEBUG: Taking gradient step
2022-12-29 13:11:26.737 DEBUG: Loss 7: {'policy_loss': 0.01163544908230445, 'entropy_loss': -0.028462416026741266, 'vf_loss': 0.007412544981470629, 'total_loss': -0.009414421962966185, 'approx_kl': 0.013481430010870099, 'clip_fraction': 0.28515625, 'grad_norm': 1.1446774005889893}
2022-12-29 13:11:27.460 DEBUG: Taking gradient step
2022-12-29 13:11:27.469 DEBUG: Loss 8: {'policy_loss': -0.030434199887829205, 'entropy_loss': -0.02765356982126832, 'vf_loss': 0.004738458973071433, 'total_loss': -0.05334931073602609, 'approx_kl': 0.016991490963846445, 'clip_fraction': 0.2330729179084301, 'grad_norm': 0.9143626689910889}
2022-12-29 13:11:28.226 DEBUG: Taking gradient step
2022-12-29 13:11:28.235 DEBUG: Loss 9: {'policy_loss': -0.02965750781086155, 'entropy_loss': -0.027642647735774517, 'vf_loss': 0.0047340026000349915, 'total_loss': -0.05256615294660108, 'approx_kl': 0.014843637123703957, 'clip_fraction': 0.23046875, 'grad_norm': 0.84300297498703}
2022-12-29 13:11:28.235 INFO: Optimization: policy loss=-0.030, vf loss=0.005, entropy loss=-0.028, total loss=-0.053, num steps=10
2022-12-29 13:11:28.235 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 13:11:28.958 INFO: Evaluation rollout: return=0.505 (0.0), episode length=3.0
2022-12-29 13:11:28.959 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 13:11:28.960 DEBUG: Deleting old model: runs/H2O/models/H2O_run-1_steps-21816.model
2022-12-29 13:11:28.963 DEBUG: Saving model: runs/H2O/models/H2O_run-1_steps-23976.model
2022-12-29 13:11:28.993 INFO: Iteration: 111/137, steps: 23976
2022-12-29 13:12:04.714 DEBUG: Atoms are too close
2022-12-29 13:12:16.281 INFO: Training rollout: return=0.165 (2.4), episode length=3.0
2022-12-29 13:12:16.283 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 13:12:16.285 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-23976_train.pkl
2022-12-29 13:12:17.007 DEBUG: Taking gradient step
2022-12-29 13:12:17.017 DEBUG: Loss 0: {'policy_loss': 0.05146675951818728, 'entropy_loss': -0.027101595420390368, 'vf_loss': 0.005850099254650689, 'total_loss': 0.030215263352447598, 'approx_kl': 3.1354526641713676e-08, 'clip_fraction': 0.0, 'grad_norm': 25.61469841003418}
2022-12-29 13:12:17.734 DEBUG: Taking gradient step
2022-12-29 13:12:17.744 DEBUG: Loss 1: {'policy_loss': -0.01292531415582521, 'entropy_loss': -0.027621016837656498, 'vf_loss': 0.0032158014497939043, 'total_loss': -0.037330529543687804, 'approx_kl': -0.0014146602861728752, 'clip_fraction': 0.00390625, 'grad_norm': 10.177645683288574}
2022-12-29 13:12:18.448 DEBUG: Taking gradient step
2022-12-29 13:12:18.457 DEBUG: Loss 2: {'policy_loss': -0.013361575139599766, 'entropy_loss': -0.027612861711531878, 'vf_loss': 0.0032176622288489594, 'total_loss': -0.03775677462228269, 'approx_kl': 0.0005478854873217642, 'clip_fraction': 0.046875, 'grad_norm': 10.606496810913086}
2022-12-29 13:12:19.144 DEBUG: Taking gradient step
2022-12-29 13:12:19.154 DEBUG: Loss 3: {'policy_loss': 0.12058053451162096, 'entropy_loss': -0.028137984219938517, 'vf_loss': 0.008498132684602405, 'total_loss': 0.10094068297628485, 'approx_kl': 0.00495540292467922, 'clip_fraction': 0.10677083395421505, 'grad_norm': 26.038772583007812}
2022-12-29 13:12:19.834 DEBUG: Taking gradient step
2022-12-29 13:12:19.843 DEBUG: Loss 4: {'policy_loss': -0.021406519461222448, 'entropy_loss': -0.027052657213062048, 'vf_loss': 0.0032188687017836483, 'total_loss': -0.04524030797250085, 'approx_kl': 0.016272653825581074, 'clip_fraction': 0.1484375, 'grad_norm': 8.599939346313477}
2022-12-29 13:12:20.555 DEBUG: Taking gradient step
2022-12-29 13:12:20.565 DEBUG: Loss 5: {'policy_loss': -0.022015382450848702, 'entropy_loss': -0.027042687870562077, 'vf_loss': 0.0032189958094267176, 'total_loss': -0.04583907451198406, 'approx_kl': 0.022261738893575966, 'clip_fraction': 0.2330729216337204, 'grad_norm': 0.5852354764938354}
2022-12-29 13:12:21.310 DEBUG: Taking gradient step
2022-12-29 13:12:21.319 DEBUG: Loss 6: {'policy_loss': 0.02811194520156906, 'entropy_loss': -0.027304078917950392, 'vf_loss': 0.005846623760839627, 'total_loss': 0.006654490044458297, 'approx_kl': 0.040809675585478544, 'clip_fraction': 0.296875, 'grad_norm': 1.023558497428894}
2022-12-29 13:12:22.020 DEBUG: Taking gradient step
2022-12-29 13:12:22.029 DEBUG: Loss 7: {'policy_loss': 0.032337554767146885, 'entropy_loss': -0.028099152725189924, 'vf_loss': 0.005841591820723223, 'total_loss': 0.010079993862680187, 'approx_kl': 0.043577657314017415, 'clip_fraction': 0.2747395858168602, 'grad_norm': 0.9773046374320984}
2022-12-29 13:12:22.736 DEBUG: Taking gradient step
2022-12-29 13:12:22.745 DEBUG: Loss 8: {'policy_loss': -0.023694744994775783, 'entropy_loss': -0.027570278849452734, 'vf_loss': 0.0032230243570119635, 'total_loss': -0.04804199948721656, 'approx_kl': 0.025204265606589615, 'clip_fraction': 0.2734375, 'grad_norm': 0.9169261455535889}
2022-12-29 13:12:23.429 DEBUG: Taking gradient step
2022-12-29 13:12:23.438 DEBUG: Loss 9: {'policy_loss': -0.024231713936499456, 'entropy_loss': -0.02784530445933342, 'vf_loss': 0.003223151607630674, 'total_loss': -0.04885386678820221, 'approx_kl': 0.022295775823295116, 'clip_fraction': 0.13671875, 'grad_norm': 0.8900899887084961}
2022-12-29 13:12:23.438 INFO: Optimization: policy loss=-0.024, vf loss=0.003, entropy loss=-0.028, total loss=-0.049, num steps=10
2022-12-29 13:12:23.439 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 13:12:24.170 INFO: Evaluation rollout: return=0.504 (0.0), episode length=3.0
2022-12-29 13:12:24.171 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 13:12:24.173 INFO: Iteration: 112/137, steps: 24192
2022-12-29 13:13:02.988 DEBUG: Atoms are too close
2022-12-29 13:13:11.773 INFO: Training rollout: return=0.187 (2.4), episode length=3.0
2022-12-29 13:13:11.775 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 13:13:11.777 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-24192_train.pkl
2022-12-29 13:13:12.528 DEBUG: Taking gradient step
2022-12-29 13:13:12.541 DEBUG: Loss 0: {'policy_loss': 0.0363721731832607, 'entropy_loss': -0.027591015677899122, 'vf_loss': 0.007352088647813127, 'total_loss': 0.016133246153174706, 'approx_kl': -3.0190373756511235e-08, 'clip_fraction': 0.0, 'grad_norm': 12.657373428344727}
2022-12-29 13:13:13.346 DEBUG: Taking gradient step
2022-12-29 13:13:13.355 DEBUG: Loss 1: {'policy_loss': -0.022863115761154268, 'entropy_loss': -0.02732470352202654, 'vf_loss': 0.0047673260052572665, 'total_loss': -0.04542049327792354, 'approx_kl': -0.003088586265221238, 'clip_fraction': 0.029947916977107525, 'grad_norm': 1.464429497718811}
2022-12-29 13:13:14.051 DEBUG: Taking gradient step
2022-12-29 13:13:14.060 DEBUG: Loss 2: {'policy_loss': 0.07417122527095021, 'entropy_loss': -0.02731866529211402, 'vf_loss': 0.009966848194576904, 'total_loss': 0.05681940817341309, 'approx_kl': 0.0021872955840080976, 'clip_fraction': 0.07682291697710752, 'grad_norm': 1.5865195989608765}
2022-12-29 13:13:14.768 DEBUG: Taking gradient step
2022-12-29 13:13:14.778 DEBUG: Loss 3: {'policy_loss': 0.07658166609571015, 'entropy_loss': -0.028384432662278414, 'vf_loss': 0.010021546185692712, 'total_loss': 0.05821877961912446, 'approx_kl': 0.0039913703221827745, 'clip_fraction': 0.17578125, 'grad_norm': 1.9580246210098267}
2022-12-29 13:13:15.513 DEBUG: Taking gradient step
2022-12-29 13:13:15.523 DEBUG: Loss 4: {'policy_loss': -0.022335858310783645, 'entropy_loss': -0.027562640141695738, 'vf_loss': 0.00476835656573876, 'total_loss': -0.045130141886740624, 'approx_kl': -0.01300279563292861, 'clip_fraction': 0.171875, 'grad_norm': 1.344571590423584}
2022-12-29 13:13:16.256 DEBUG: Taking gradient step
2022-12-29 13:13:16.265 DEBUG: Loss 5: {'policy_loss': -0.026153960142336098, 'entropy_loss': -0.027273433282971382, 'vf_loss': 0.004771450835880758, 'total_loss': -0.04865594258942672, 'approx_kl': -0.010376857040682808, 'clip_fraction': 0.13020833395421505, 'grad_norm': 1.2333582639694214}
2022-12-29 13:13:16.964 DEBUG: Taking gradient step
2022-12-29 13:13:16.973 DEBUG: Loss 6: {'policy_loss': -0.024494154867071027, 'entropy_loss': -0.027511706575751305, 'vf_loss': 0.0047664274144291734, 'total_loss': -0.04723943402839315, 'approx_kl': -0.014177074423059821, 'clip_fraction': 0.11328125, 'grad_norm': 1.346174716949463}
2022-12-29 13:13:17.674 DEBUG: Taking gradient step
2022-12-29 13:13:17.686 DEBUG: Loss 7: {'policy_loss': -0.028091465201318007, 'entropy_loss': -0.028806181624531746, 'vf_loss': 0.004765917733006352, 'total_loss': -0.0521317290928434, 'approx_kl': -0.016926394775509834, 'clip_fraction': 0.1041666679084301, 'grad_norm': 1.1271973848342896}
2022-12-29 13:13:18.387 DEBUG: Taking gradient step
2022-12-29 13:13:18.396 DEBUG: Loss 8: {'policy_loss': -0.030461108632561566, 'entropy_loss': -0.028217251412570477, 'vf_loss': 0.004764987348052912, 'total_loss': -0.05391337269707913, 'approx_kl': -0.010511284228414297, 'clip_fraction': 0.08723958395421505, 'grad_norm': 1.1528658866882324}
2022-12-29 13:13:19.171 DEBUG: Taking gradient step
2022-12-29 13:13:19.181 DEBUG: Loss 9: {'policy_loss': -0.024943520070046035, 'entropy_loss': -0.02760067768394947, 'vf_loss': 0.004760784512745143, 'total_loss': -0.047783413241250364, 'approx_kl': -0.008170107379555702, 'clip_fraction': 0.1640625, 'grad_norm': 11.45041561126709}
2022-12-29 13:13:19.181 INFO: Optimization: policy loss=-0.025, vf loss=0.005, entropy loss=-0.028, total loss=-0.048, num steps=10
2022-12-29 13:13:19.181 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 13:13:19.946 INFO: Evaluation rollout: return=0.506 (0.0), episode length=3.0
2022-12-29 13:13:19.946 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 13:13:19.948 INFO: Iteration: 113/137, steps: 24408
2022-12-29 13:14:08.020 INFO: Training rollout: return=0.468 (0.0), episode length=3.0
2022-12-29 13:14:08.022 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 13:14:08.025 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-24408_train.pkl
2022-12-29 13:14:08.722 DEBUG: Taking gradient step
2022-12-29 13:14:08.732 DEBUG: Loss 0: {'policy_loss': 0.017523256475077964, 'entropy_loss': -0.027795518282800913, 'vf_loss': 8.67923169984223e-05, 'total_loss': -0.01018546949072453, 'approx_kl': 3.5778309204204106e-08, 'clip_fraction': 0.0, 'grad_norm': 5.151041030883789}
2022-12-29 13:14:09.418 DEBUG: Taking gradient step
2022-12-29 13:14:09.427 DEBUG: Loss 1: {'policy_loss': -0.014428372353234157, 'entropy_loss': -0.027406055480241776, 'vf_loss': 8.948098614173223e-05, 'total_loss': -0.041744946847334194, 'approx_kl': 0.007102830219082534, 'clip_fraction': 0.015625, 'grad_norm': 9.476388931274414}
2022-12-29 13:14:10.206 DEBUG: Taking gradient step
2022-12-29 13:14:10.215 DEBUG: Loss 2: {'policy_loss': 0.02007005167370838, 'entropy_loss': -0.027776608243584633, 'vf_loss': 8.7089158480823e-05, 'total_loss': -0.0076194674113954294, 'approx_kl': 0.022459233878180385, 'clip_fraction': 0.07552083395421505, 'grad_norm': 1.5737066268920898}
2022-12-29 13:14:10.938 DEBUG: Taking gradient step
2022-12-29 13:14:10.948 DEBUG: Loss 3: {'policy_loss': -0.057811337639208205, 'entropy_loss': -0.027151819318532944, 'vf_loss': 9.028471861639704e-05, 'total_loss': -0.08487287223912476, 'approx_kl': 0.028275862568989396, 'clip_fraction': 0.16927083395421505, 'grad_norm': 3.853121280670166}
2022-12-29 13:14:11.677 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-29 13:14:11.677 INFO: Optimization: policy loss=-0.058, vf loss=0.000, entropy loss=-0.027, total loss=-0.085, num steps=4
2022-12-29 13:14:11.678 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 13:14:12.424 INFO: Evaluation rollout: return=0.505 (0.0), episode length=3.0
2022-12-29 13:14:12.425 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 13:14:12.427 INFO: Iteration: 114/137, steps: 24624
2022-12-29 13:14:23.989 DEBUG: Atoms are too close
2022-12-29 13:14:43.929 DEBUG: Atoms are too close
2022-12-29 13:15:00.630 INFO: Training rollout: return=-0.097 (3.3), episode length=3.0
2022-12-29 13:15:00.631 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 13:15:00.634 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-24624_train.pkl
2022-12-29 13:15:01.370 DEBUG: Taking gradient step
2022-12-29 13:15:01.384 DEBUG: Loss 0: {'policy_loss': 0.019572846441605743, 'entropy_loss': -0.027012680657207966, 'vf_loss': 0.01054884168628073, 'total_loss': 0.0031090074706785105, 'approx_kl': -2.2118911147117615e-08, 'clip_fraction': 0.0, 'grad_norm': 26.25674819946289}
2022-12-29 13:15:02.100 DEBUG: Taking gradient step
2022-12-29 13:15:02.110 DEBUG: Loss 1: {'policy_loss': 0.013488163424807163, 'entropy_loss': -0.024788400623947382, 'vf_loss': 0.010563324359273776, 'total_loss': -0.000736912839866443, 'approx_kl': 0.006554854917339981, 'clip_fraction': 0.022135416977107525, 'grad_norm': 1.8287993669509888}
2022-12-29 13:15:02.854 DEBUG: Taking gradient step
2022-12-29 13:15:02.864 DEBUG: Loss 2: {'policy_loss': -0.025859014625445598, 'entropy_loss': -0.024912373162806034, 'vf_loss': 0.007954424296777113, 'total_loss': -0.04281696349147452, 'approx_kl': 0.004021252854727209, 'clip_fraction': 0.03515625, 'grad_norm': 4.148447036743164}
2022-12-29 13:15:03.626 DEBUG: Taking gradient step
2022-12-29 13:15:03.636 DEBUG: Loss 3: {'policy_loss': -0.02589003352527184, 'entropy_loss': -0.02568447543308139, 'vf_loss': 0.007950150554556874, 'total_loss': -0.04362435840379635, 'approx_kl': 0.008755510207265615, 'clip_fraction': 0.061197916977107525, 'grad_norm': 4.919219017028809}
2022-12-29 13:15:04.338 DEBUG: Taking gradient step
2022-12-29 13:15:04.349 DEBUG: Loss 4: {'policy_loss': 0.04842440401022406, 'entropy_loss': -0.024202467873692513, 'vf_loss': 0.013129274258375264, 'total_loss': 0.03735121039490682, 'approx_kl': 0.005401260335929692, 'clip_fraction': 0.045572916977107525, 'grad_norm': 3.7924644947052}
2022-12-29 13:15:05.066 DEBUG: Taking gradient step
2022-12-29 13:15:05.075 DEBUG: Loss 5: {'policy_loss': -0.02873626234033585, 'entropy_loss': -0.02605753904208541, 'vf_loss': 0.007937497409259328, 'total_loss': -0.04685630397316193, 'approx_kl': 0.0033260741038247943, 'clip_fraction': 0.04817708395421505, 'grad_norm': 3.560364246368408}
2022-12-29 13:15:05.778 DEBUG: Taking gradient step
2022-12-29 13:15:05.797 DEBUG: Loss 6: {'policy_loss': -0.03476697474758783, 'entropy_loss': -0.024542982690036297, 'vf_loss': 0.007937226932616798, 'total_loss': -0.05137273050500733, 'approx_kl': -0.005788162467069924, 'clip_fraction': 0.13020833395421505, 'grad_norm': 3.0318892002105713}
2022-12-29 13:15:06.494 DEBUG: Taking gradient step
2022-12-29 13:15:06.504 DEBUG: Loss 7: {'policy_loss': -0.032218717367280755, 'entropy_loss': -0.02456221543252468, 'vf_loss': 0.007931638866258004, 'total_loss': -0.04884929393354743, 'approx_kl': -0.008066000998951495, 'clip_fraction': 0.19140625, 'grad_norm': 3.470362663269043}
2022-12-29 13:15:07.180 DEBUG: Taking gradient step
2022-12-29 13:15:07.189 DEBUG: Loss 8: {'policy_loss': -0.03078152144153693, 'entropy_loss': -0.02501590456813574, 'vf_loss': 0.007927007897815298, 'total_loss': -0.047870418111857375, 'approx_kl': -0.005720415152609348, 'clip_fraction': 0.2200520858168602, 'grad_norm': 4.102006912231445}
2022-12-29 13:15:07.862 DEBUG: Taking gradient step
2022-12-29 13:15:07.871 DEBUG: Loss 9: {'policy_loss': 0.0972342679892775, 'entropy_loss': -0.023598208092153072, 'vf_loss': 0.015731501082534134, 'total_loss': 0.08936756097965859, 'approx_kl': 0.015503276139497757, 'clip_fraction': 0.16796875, 'grad_norm': 7.9872517585754395}
2022-12-29 13:15:07.872 INFO: Optimization: policy loss=0.097, vf loss=0.016, entropy loss=-0.024, total loss=0.089, num steps=10
2022-12-29 13:15:07.872 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 13:15:08.648 INFO: Evaluation rollout: return=0.506 (0.0), episode length=3.0
2022-12-29 13:15:08.649 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 13:15:08.650 INFO: Iteration: 115/137, steps: 24840
2022-12-29 13:15:56.163 INFO: Training rollout: return=0.472 (0.0), episode length=3.0
2022-12-29 13:15:56.165 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 13:15:56.168 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-24840_train.pkl
2022-12-29 13:15:56.896 DEBUG: Taking gradient step
2022-12-29 13:15:56.906 DEBUG: Loss 0: {'policy_loss': 0.009766651121674907, 'entropy_loss': -0.024313862901180983, 'vf_loss': 0.00010317981542145828, 'total_loss': -0.014444031964084617, 'approx_kl': 7.163422921507845e-08, 'clip_fraction': 0.0, 'grad_norm': 6.133990287780762}
2022-12-29 13:15:57.632 DEBUG: Taking gradient step
2022-12-29 13:15:57.641 DEBUG: Loss 1: {'policy_loss': 0.015651206056376345, 'entropy_loss': -0.024302846752107143, 'vf_loss': 0.00010458105026478018, 'total_loss': -0.008547059645466017, 'approx_kl': 0.0016405549831688404, 'clip_fraction': 0.00390625, 'grad_norm': 7.503367900848389}
2022-12-29 13:15:58.411 DEBUG: Taking gradient step
2022-12-29 13:15:58.420 DEBUG: Loss 2: {'policy_loss': 0.06560169098552562, 'entropy_loss': -0.024181974586099386, 'vf_loss': 0.00010352949166937597, 'total_loss': 0.04152324589109563, 'approx_kl': 0.014287731843069196, 'clip_fraction': 0.045572916977107525, 'grad_norm': 6.0715227127075195}
2022-12-29 13:15:59.136 DEBUG: Taking gradient step
2022-12-29 13:15:59.146 DEBUG: Loss 3: {'policy_loss': 0.037322332214608095, 'entropy_loss': -0.024003255646675825, 'vf_loss': 0.00010475435934629749, 'total_loss': 0.013423830927278564, 'approx_kl': 0.02628634951543063, 'clip_fraction': 0.16015625, 'grad_norm': 3.621675491333008}
2022-12-29 13:15:59.895 DEBUG: Taking gradient step
2022-12-29 13:15:59.904 DEBUG: Loss 4: {'policy_loss': 0.003692961850415061, 'entropy_loss': -0.023415545001626015, 'vf_loss': 0.00010507868114862256, 'total_loss': -0.01961750447006233, 'approx_kl': 0.021055835764855146, 'clip_fraction': 0.1822916679084301, 'grad_norm': 9.226884841918945}
2022-12-29 13:16:00.608 DEBUG: Taking gradient step
2022-12-29 13:16:00.619 DEBUG: Loss 5: {'policy_loss': -0.014454874020923325, 'entropy_loss': -0.023147443775087595, 'vf_loss': 0.00010476712603970386, 'total_loss': -0.037497550669971215, 'approx_kl': 0.0265609510242939, 'clip_fraction': 0.19270833395421505, 'grad_norm': 4.014657020568848}
2022-12-29 13:16:01.330 DEBUG: Taking gradient step
2022-12-29 13:16:01.339 DEBUG: Loss 6: {'policy_loss': 0.011301786124507902, 'entropy_loss': -0.023384294006973505, 'vf_loss': 0.00010141270141344552, 'total_loss': -0.011981095181052157, 'approx_kl': 0.020808255183510482, 'clip_fraction': 0.1861979179084301, 'grad_norm': 6.446732997894287}
2022-12-29 13:16:02.062 DEBUG: Taking gradient step
2022-12-29 13:16:02.071 DEBUG: Loss 7: {'policy_loss': -0.01922295183840007, 'entropy_loss': -0.023195759393274784, 'vf_loss': 9.998643570421355e-05, 'total_loss': -0.04231872479597064, 'approx_kl': 0.014157462865114212, 'clip_fraction': 0.11458333395421505, 'grad_norm': 6.085086345672607}
2022-12-29 13:16:02.766 DEBUG: Taking gradient step
2022-12-29 13:16:02.775 DEBUG: Loss 8: {'policy_loss': -0.06014750831529415, 'entropy_loss': -0.02237906912341714, 'vf_loss': 0.00010109781627916092, 'total_loss': -0.08242547962243212, 'approx_kl': 0.00934530165977776, 'clip_fraction': 0.08854166697710752, 'grad_norm': 3.9068589210510254}
2022-12-29 13:16:03.485 DEBUG: Taking gradient step
2022-12-29 13:16:03.495 DEBUG: Loss 9: {'policy_loss': -0.021460090269671515, 'entropy_loss': -0.023277997504919767, 'vf_loss': 9.537320673226904e-05, 'total_loss': -0.044642714567859024, 'approx_kl': 0.017314875032752752, 'clip_fraction': 0.09505208395421505, 'grad_norm': 2.1130483150482178}
2022-12-29 13:16:03.495 INFO: Optimization: policy loss=-0.021, vf loss=0.000, entropy loss=-0.023, total loss=-0.045, num steps=10
2022-12-29 13:16:03.495 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 13:16:04.133 INFO: Evaluation rollout: return=0.506 (0.0), episode length=3.0
2022-12-29 13:16:04.134 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 13:16:04.135 INFO: Iteration: 116/137, steps: 25056
2022-12-29 13:16:51.728 INFO: Training rollout: return=0.460 (0.1), episode length=3.0
2022-12-29 13:16:51.730 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 13:16:51.732 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-25056_train.pkl
2022-12-29 13:16:52.441 DEBUG: Taking gradient step
2022-12-29 13:16:52.452 DEBUG: Loss 0: {'policy_loss': 0.0657457290175019, 'entropy_loss': -0.02343838009983301, 'vf_loss': 8.475314345804191e-05, 'total_loss': 0.04239210206112694, 'approx_kl': 1.7384687911459196e-08, 'clip_fraction': 0.0, 'grad_norm': 20.171466827392578}
2022-12-29 13:16:53.150 DEBUG: Taking gradient step
2022-12-29 13:16:53.160 DEBUG: Loss 1: {'policy_loss': -0.03143488716957407, 'entropy_loss': -0.023581570480018854, 'vf_loss': 8.387150482422066e-05, 'total_loss': -0.0549325861447687, 'approx_kl': 0.004343646403867751, 'clip_fraction': 0.0, 'grad_norm': 9.425599098205566}
2022-12-29 13:16:53.848 DEBUG: Taking gradient step
2022-12-29 13:16:53.857 DEBUG: Loss 2: {'policy_loss': -0.033629173705517434, 'entropy_loss': -0.023342175874859095, 'vf_loss': 8.063734017009171e-05, 'total_loss': -0.05689071224020644, 'approx_kl': 0.015243672067299485, 'clip_fraction': 0.02473958395421505, 'grad_norm': 7.602693557739258}
2022-12-29 13:16:54.551 DEBUG: Taking gradient step
2022-12-29 13:16:54.560 DEBUG: Loss 3: {'policy_loss': -0.03990129974051839, 'entropy_loss': -0.024587933905422688, 'vf_loss': 7.776498171932711e-05, 'total_loss': -0.06441146866422176, 'approx_kl': 0.03627421986311674, 'clip_fraction': 0.1484375, 'grad_norm': 5.898075103759766}
2022-12-29 13:16:55.271 DEBUG: Taking gradient step
2022-12-29 13:16:55.280 DEBUG: Loss 4: {'policy_loss': -0.0464935652536481, 'entropy_loss': -0.02391514042392373, 'vf_loss': 7.435294875056837e-05, 'total_loss': -0.07033435272882127, 'approx_kl': 0.03755636664573103, 'clip_fraction': 0.2395833358168602, 'grad_norm': 7.643534183502197}
2022-12-29 13:16:56.003 DEBUG: Taking gradient step
2022-12-29 13:16:56.012 DEBUG: Loss 5: {'policy_loss': -0.0009627828351361275, 'entropy_loss': -0.02448727237060666, 'vf_loss': 6.933297101810865e-05, 'total_loss': -0.02538072223472468, 'approx_kl': 0.04294569022022188, 'clip_fraction': 0.27734375, 'grad_norm': 6.826584339141846}
2022-12-29 13:16:56.811 DEBUG: Early stopping at step 6 for reaching max KL.
2022-12-29 13:16:56.811 INFO: Optimization: policy loss=-0.001, vf loss=0.000, entropy loss=-0.024, total loss=-0.025, num steps=6
2022-12-29 13:16:56.812 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 13:16:57.492 INFO: Evaluation rollout: return=0.507 (0.0), episode length=3.0
2022-12-29 13:16:57.492 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 13:16:57.494 INFO: Iteration: 117/137, steps: 25272
2022-12-29 13:17:44.195 DEBUG: Atoms are too close
2022-12-29 13:17:45.864 INFO: Training rollout: return=0.199 (2.4), episode length=3.0
2022-12-29 13:17:45.866 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 13:17:45.868 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-25272_train.pkl
2022-12-29 13:17:46.604 DEBUG: Taking gradient step
2022-12-29 13:17:46.613 DEBUG: Loss 0: {'policy_loss': -0.019412016073940042, 'entropy_loss': -0.023072239477187395, 'vf_loss': 0.004748400645877445, 'total_loss': -0.03773585490525, 'approx_kl': 2.4020361366616783e-08, 'clip_fraction': 0.0, 'grad_norm': 8.209794044494629}
2022-12-29 13:17:47.306 DEBUG: Taking gradient step
2022-12-29 13:17:47.315 DEBUG: Loss 1: {'policy_loss': -0.021898047211046642, 'entropy_loss': -0.02396062295883894, 'vf_loss': 0.004747175566786054, 'total_loss': -0.04111149460309953, 'approx_kl': 0.0014238181174732745, 'clip_fraction': 0.0, 'grad_norm': 7.712337493896484}
2022-12-29 13:17:48.033 DEBUG: Taking gradient step
2022-12-29 13:17:48.042 DEBUG: Loss 2: {'policy_loss': -0.02463237921646043, 'entropy_loss': -0.024001275654882193, 'vf_loss': 0.004747502642752235, 'total_loss': -0.04388615222859039, 'approx_kl': 0.008645568450447172, 'clip_fraction': 0.0807291679084301, 'grad_norm': 1.2180070877075195}
2022-12-29 13:17:48.747 DEBUG: Taking gradient step
2022-12-29 13:17:48.758 DEBUG: Loss 3: {'policy_loss': -0.02485646782040086, 'entropy_loss': -0.024592582136392593, 'vf_loss': 0.004747172064718918, 'total_loss': -0.044701877892074526, 'approx_kl': 0.005346957535948604, 'clip_fraction': 0.0859375, 'grad_norm': 1.0079231262207031}
2022-12-29 13:17:49.496 DEBUG: Taking gradient step
2022-12-29 13:17:49.509 DEBUG: Loss 4: {'policy_loss': -0.025794135866667737, 'entropy_loss': -0.02388439793139696, 'vf_loss': 0.0047474566601354235, 'total_loss': -0.04493107713792928, 'approx_kl': 0.009118919027969241, 'clip_fraction': 0.045572916977107525, 'grad_norm': 0.9235550165176392}
2022-12-29 13:17:50.220 DEBUG: Taking gradient step
2022-12-29 13:17:50.232 DEBUG: Loss 5: {'policy_loss': -0.025209455910533255, 'entropy_loss': -0.0244242986664176, 'vf_loss': 0.004744842601520612, 'total_loss': -0.04488891197543024, 'approx_kl': 0.0076789651066064835, 'clip_fraction': 0.0234375, 'grad_norm': 0.9459483623504639}
2022-12-29 13:17:50.985 DEBUG: Taking gradient step
2022-12-29 13:17:51.000 DEBUG: Loss 6: {'policy_loss': -0.02478413883501033, 'entropy_loss': -0.02411989774554968, 'vf_loss': 0.004742271115259531, 'total_loss': -0.04416176546530048, 'approx_kl': 0.006516997003927827, 'clip_fraction': 0.05078125, 'grad_norm': 0.8373506665229797}
2022-12-29 13:17:51.720 DEBUG: Taking gradient step
2022-12-29 13:17:51.729 DEBUG: Loss 7: {'policy_loss': -0.02659996945653725, 'entropy_loss': -0.02372298203408718, 'vf_loss': 0.004742868566648637, 'total_loss': -0.04558008292397579, 'approx_kl': 0.02180395310278982, 'clip_fraction': 0.1471354179084301, 'grad_norm': 0.44187331199645996}
2022-12-29 13:17:52.420 DEBUG: Taking gradient step
2022-12-29 13:17:52.430 DEBUG: Loss 8: {'policy_loss': -0.02817542761762837, 'entropy_loss': -0.024232509545981884, 'vf_loss': 0.0047401079071458805, 'total_loss': -0.04766782925646437, 'approx_kl': 0.024043724057264626, 'clip_fraction': 0.19661458395421505, 'grad_norm': 0.4839816987514496}
2022-12-29 13:17:53.175 DEBUG: Early stopping at step 9 for reaching max KL.
2022-12-29 13:17:53.175 INFO: Optimization: policy loss=-0.028, vf loss=0.005, entropy loss=-0.024, total loss=-0.048, num steps=9
2022-12-29 13:17:53.176 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 13:17:53.837 INFO: Evaluation rollout: return=0.503 (0.0), episode length=3.0
2022-12-29 13:17:53.838 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 13:17:53.840 INFO: Iteration: 118/137, steps: 25488
2022-12-29 13:18:42.016 INFO: Training rollout: return=0.471 (0.0), episode length=3.0
2022-12-29 13:18:42.018 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 13:18:42.021 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-25488_train.pkl
2022-12-29 13:18:42.736 DEBUG: Taking gradient step
2022-12-29 13:18:42.745 DEBUG: Loss 0: {'policy_loss': 0.004187305965800829, 'entropy_loss': -0.02453851653262973, 'vf_loss': 5.324733142678216e-05, 'total_loss': -0.020297963235402113, 'approx_kl': 1.3116126240664272e-08, 'clip_fraction': 0.0, 'grad_norm': 6.566829204559326}
2022-12-29 13:18:43.464 DEBUG: Taking gradient step
2022-12-29 13:18:43.478 DEBUG: Loss 1: {'policy_loss': 0.020327288813574908, 'entropy_loss': -0.025398404337465763, 'vf_loss': 5.261908411507212e-05, 'total_loss': -0.005018496439775786, 'approx_kl': 0.006294317194260657, 'clip_fraction': 0.0078125, 'grad_norm': 8.049407005310059}
2022-12-29 13:18:44.241 DEBUG: Taking gradient step
2022-12-29 13:18:44.250 DEBUG: Loss 2: {'policy_loss': -0.04275414804759352, 'entropy_loss': -0.02466719690710306, 'vf_loss': 5.347792172465568e-05, 'total_loss': -0.06736786703297193, 'approx_kl': 0.01571384014096111, 'clip_fraction': 0.06510416697710752, 'grad_norm': 10.958158493041992}
2022-12-29 13:18:44.940 DEBUG: Taking gradient step
2022-12-29 13:18:44.949 DEBUG: Loss 3: {'policy_loss': -0.0026022603955023864, 'entropy_loss': -0.02435540221631527, 'vf_loss': 5.1182474602492925e-05, 'total_loss': -0.026906480137215163, 'approx_kl': 0.025972423376515508, 'clip_fraction': 0.11848958395421505, 'grad_norm': 13.294148445129395}
2022-12-29 13:18:45.652 DEBUG: Taking gradient step
2022-12-29 13:18:45.661 DEBUG: Loss 4: {'policy_loss': 0.03959390616287988, 'entropy_loss': -0.02483812114223838, 'vf_loss': 4.999759338703264e-05, 'total_loss': 0.014805782614028536, 'approx_kl': 0.024120057001709938, 'clip_fraction': 0.1197916679084301, 'grad_norm': 15.389655113220215}
2022-12-29 13:18:46.367 DEBUG: Taking gradient step
2022-12-29 13:18:46.377 DEBUG: Loss 5: {'policy_loss': 0.00837057385295058, 'entropy_loss': -0.02437426894903183, 'vf_loss': 4.98912262130468e-05, 'total_loss': -0.015953803869868204, 'approx_kl': 0.017963718390092254, 'clip_fraction': 0.06770833395421505, 'grad_norm': 8.211701393127441}
2022-12-29 13:18:47.178 DEBUG: Taking gradient step
2022-12-29 13:18:47.193 DEBUG: Loss 6: {'policy_loss': -0.0630067738931073, 'entropy_loss': -0.02317393757402897, 'vf_loss': 5.0642158593166344e-05, 'total_loss': -0.08613006930854311, 'approx_kl': 0.010167163796722889, 'clip_fraction': 0.01953125, 'grad_norm': 4.082503795623779}
2022-12-29 13:18:47.940 DEBUG: Taking gradient step
2022-12-29 13:18:47.949 DEBUG: Loss 7: {'policy_loss': -0.034777277719081116, 'entropy_loss': -0.023844474460929632, 'vf_loss': 4.755804658570556e-05, 'total_loss': -0.058574194133425045, 'approx_kl': 4.128552973270416e-05, 'clip_fraction': 0.037760416977107525, 'grad_norm': 7.291989326477051}
2022-12-29 13:18:48.638 DEBUG: Taking gradient step
2022-12-29 13:18:48.648 DEBUG: Loss 8: {'policy_loss': -0.014534400877138141, 'entropy_loss': -0.02370391320437193, 'vf_loss': 4.5587816903746656e-05, 'total_loss': -0.038192726264606326, 'approx_kl': 0.010015255655162036, 'clip_fraction': 0.09895833395421505, 'grad_norm': 5.2784905433654785}
2022-12-29 13:18:49.377 DEBUG: Taking gradient step
2022-12-29 13:18:49.386 DEBUG: Loss 9: {'policy_loss': -0.019694465348604293, 'entropy_loss': -0.023040685337036848, 'vf_loss': 4.641242250178628e-05, 'total_loss': -0.042688738263139354, 'approx_kl': 0.03971106419339776, 'clip_fraction': 0.2252604216337204, 'grad_norm': 7.396624565124512}
2022-12-29 13:18:49.386 INFO: Optimization: policy loss=-0.020, vf loss=0.000, entropy loss=-0.023, total loss=-0.043, num steps=10
2022-12-29 13:18:49.387 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 13:18:50.056 INFO: Evaluation rollout: return=0.505 (0.0), episode length=3.0
2022-12-29 13:18:50.057 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 13:18:50.058 INFO: Iteration: 119/137, steps: 25704
2022-12-29 13:19:37.039 INFO: Training rollout: return=0.473 (0.0), episode length=3.0
2022-12-29 13:19:37.041 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 13:19:37.043 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-25704_train.pkl
2022-12-29 13:19:37.773 DEBUG: Taking gradient step
2022-12-29 13:19:37.782 DEBUG: Loss 0: {'policy_loss': 0.020125039518390953, 'entropy_loss': -0.02385875955224037, 'vf_loss': 4.2468822474364515e-05, 'total_loss': -0.0036912512113750524, 'approx_kl': -2.5863602814979458e-08, 'clip_fraction': 0.0, 'grad_norm': 11.359466552734375}
2022-12-29 13:19:38.491 DEBUG: Taking gradient step
2022-12-29 13:19:38.500 DEBUG: Loss 1: {'policy_loss': 0.016798373465681325, 'entropy_loss': -0.023403095081448555, 'vf_loss': 4.122352020917217e-05, 'total_loss': -0.006563498095558059, 'approx_kl': 0.00826096988748759, 'clip_fraction': 0.015625, 'grad_norm': 7.220974445343018}
2022-12-29 13:19:39.207 DEBUG: Taking gradient step
2022-12-29 13:19:39.216 DEBUG: Loss 2: {'policy_loss': 0.006842678614788404, 'entropy_loss': -0.023164767771959305, 'vf_loss': 4.035776833776976e-05, 'total_loss': -0.016281731388833133, 'approx_kl': 0.022051642183214426, 'clip_fraction': 0.125, 'grad_norm': 14.83680248260498}
2022-12-29 13:19:39.949 DEBUG: Taking gradient step
2022-12-29 13:19:39.963 DEBUG: Loss 3: {'policy_loss': -0.009087969084324417, 'entropy_loss': -0.02292624581605196, 'vf_loss': 3.962247010029026e-05, 'total_loss': -0.03197459243027609, 'approx_kl': 0.036419628420844674, 'clip_fraction': 0.1653645858168602, 'grad_norm': 11.260390281677246}
2022-12-29 13:19:40.682 DEBUG: Taking gradient step
2022-12-29 13:19:40.691 DEBUG: Loss 4: {'policy_loss': 0.022846358383284235, 'entropy_loss': -0.023320738226175308, 'vf_loss': 3.703821607862424e-05, 'total_loss': -0.0004373416268124465, 'approx_kl': 0.03209215053357184, 'clip_fraction': 0.14583333395421505, 'grad_norm': 13.443244934082031}
2022-12-29 13:19:41.400 DEBUG: Taking gradient step
2022-12-29 13:19:41.409 DEBUG: Loss 5: {'policy_loss': 0.013068915176266942, 'entropy_loss': -0.023182774428278208, 'vf_loss': 3.532347684759713e-05, 'total_loss': -0.010078535775163667, 'approx_kl': 0.03708703210577369, 'clip_fraction': 0.13932291697710752, 'grad_norm': 7.4025068283081055}
2022-12-29 13:19:42.121 DEBUG: Taking gradient step
2022-12-29 13:19:42.130 DEBUG: Loss 6: {'policy_loss': -0.0295308363602538, 'entropy_loss': -0.022089588455855846, 'vf_loss': 3.5505458159053285e-05, 'total_loss': -0.05158491935795059, 'approx_kl': 0.039068355690687895, 'clip_fraction': 0.1888020858168602, 'grad_norm': 9.0680570602417}
2022-12-29 13:19:42.837 DEBUG: Taking gradient step
2022-12-29 13:19:42.849 DEBUG: Loss 7: {'policy_loss': -0.0029499723625416576, 'entropy_loss': -0.02342395531013608, 'vf_loss': 3.260586247880947e-05, 'total_loss': -0.026341321810198926, 'approx_kl': 0.031815326772630215, 'clip_fraction': 0.14583333395421505, 'grad_norm': 8.03176212310791}
2022-12-29 13:19:43.536 DEBUG: Taking gradient step
2022-12-29 13:19:43.545 DEBUG: Loss 8: {'policy_loss': -0.04087459144521341, 'entropy_loss': -0.022571814246475697, 'vf_loss': 3.2221730827883605e-05, 'total_loss': -0.06341418396086122, 'approx_kl': 0.026860441081225872, 'clip_fraction': 0.12630208395421505, 'grad_norm': 8.255501747131348}
2022-12-29 13:19:44.247 DEBUG: Taking gradient step
2022-12-29 13:19:44.261 DEBUG: Loss 9: {'policy_loss': -0.009965022165812227, 'entropy_loss': -0.023057347163558006, 'vf_loss': 2.8582888058791782e-05, 'total_loss': -0.032993786441311436, 'approx_kl': 0.02121201594127342, 'clip_fraction': 0.09114583395421505, 'grad_norm': 2.4146041870117188}
2022-12-29 13:19:44.261 INFO: Optimization: policy loss=-0.010, vf loss=0.000, entropy loss=-0.023, total loss=-0.033, num steps=10
2022-12-29 13:19:44.261 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 13:19:44.970 INFO: Evaluation rollout: return=0.505 (0.0), episode length=3.0
2022-12-29 13:19:44.971 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 13:19:44.973 INFO: Iteration: 120/137, steps: 25920
2022-12-29 13:20:33.590 INFO: Training rollout: return=0.470 (0.0), episode length=3.0
2022-12-29 13:20:33.592 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 13:20:33.595 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-25920_train.pkl
2022-12-29 13:20:34.322 DEBUG: Taking gradient step
2022-12-29 13:20:34.336 DEBUG: Loss 0: {'policy_loss': -0.018941529344190827, 'entropy_loss': -0.022970690857619047, 'vf_loss': 2.6462478543200514e-05, 'total_loss': -0.04188575772326668, 'approx_kl': -1.6220536025457477e-08, 'clip_fraction': 0.0, 'grad_norm': 7.427340507507324}
2022-12-29 13:20:35.063 DEBUG: Taking gradient step
2022-12-29 13:20:35.072 DEBUG: Loss 1: {'policy_loss': -0.0474603475991611, 'entropy_loss': -0.02311519905924797, 'vf_loss': 2.5149401560687953e-05, 'total_loss': -0.07055039725684839, 'approx_kl': 0.0004484266974031925, 'clip_fraction': 0.0, 'grad_norm': 4.669256687164307}
2022-12-29 13:20:35.789 DEBUG: Taking gradient step
2022-12-29 13:20:35.798 DEBUG: Loss 2: {'policy_loss': -0.02158892813625723, 'entropy_loss': -0.023221969604492188, 'vf_loss': 2.2329394853349123e-05, 'total_loss': -0.04478856834589607, 'approx_kl': 0.006517229019664228, 'clip_fraction': 0.0, 'grad_norm': 7.229326248168945}
2022-12-29 13:20:36.492 DEBUG: Taking gradient step
2022-12-29 13:20:36.502 DEBUG: Loss 3: {'policy_loss': 0.018557635028950782, 'entropy_loss': -0.02177013037726283, 'vf_loss': 2.0743403418496425e-05, 'total_loss': -0.003191751944893545, 'approx_kl': 0.010349840973503888, 'clip_fraction': 0.0234375, 'grad_norm': 13.070701599121094}
2022-12-29 13:20:37.287 DEBUG: Taking gradient step
2022-12-29 13:20:37.300 DEBUG: Loss 4: {'policy_loss': -0.02590520220607403, 'entropy_loss': -0.022817416582256556, 'vf_loss': 1.9179250629628796e-05, 'total_loss': -0.048703439537700954, 'approx_kl': 0.010560607770457864, 'clip_fraction': 0.03125, 'grad_norm': 4.90285587310791}
2022-12-29 13:20:38.007 DEBUG: Taking gradient step
2022-12-29 13:20:38.016 DEBUG: Loss 5: {'policy_loss': 0.015579035040402152, 'entropy_loss': -0.022324439138174057, 'vf_loss': 1.691365937177551e-05, 'total_loss': -0.006728490438400139, 'approx_kl': 0.02469604043290019, 'clip_fraction': 0.109375, 'grad_norm': 5.212908744812012}
2022-12-29 13:20:38.754 DEBUG: Taking gradient step
2022-12-29 13:20:38.763 DEBUG: Loss 6: {'policy_loss': 0.05843115928243058, 'entropy_loss': -0.022827576845884323, 'vf_loss': 1.538503704339408e-05, 'total_loss': 0.035618967473589655, 'approx_kl': 0.040160516276955605, 'clip_fraction': 0.26953125, 'grad_norm': 7.7528605461120605}
2022-12-29 13:20:39.450 DEBUG: Early stopping at step 7 for reaching max KL.
2022-12-29 13:20:39.451 INFO: Optimization: policy loss=0.058, vf loss=0.000, entropy loss=-0.023, total loss=0.036, num steps=7
2022-12-29 13:20:39.451 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 13:20:40.113 INFO: Evaluation rollout: return=0.506 (0.0), episode length=3.0
2022-12-29 13:20:40.114 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 13:20:40.117 DEBUG: Deleting old model: runs/H2O/models/H2O_run-1_steps-23976.model
2022-12-29 13:20:40.121 DEBUG: Saving model: runs/H2O/models/H2O_run-1_steps-26136.model
2022-12-29 13:20:40.153 INFO: Iteration: 121/137, steps: 26136
2022-12-29 13:21:25.643 DEBUG: Atoms are too close
2022-12-29 13:21:27.879 INFO: Training rollout: return=0.197 (2.4), episode length=3.0
2022-12-29 13:21:27.881 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 13:21:27.884 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-26136_train.pkl
2022-12-29 13:21:28.599 DEBUG: Taking gradient step
2022-12-29 13:21:28.609 DEBUG: Loss 0: {'policy_loss': -0.019547180450867264, 'entropy_loss': -0.022158445790410042, 'vf_loss': 0.004800739577029269, 'total_loss': -0.036904886664248036, 'approx_kl': 1.2631062418222427e-08, 'clip_fraction': 0.0, 'grad_norm': 11.749354362487793}
2022-12-29 13:21:29.331 DEBUG: Taking gradient step
2022-12-29 13:21:29.340 DEBUG: Loss 1: {'policy_loss': -0.02567560455858446, 'entropy_loss': -0.023074768017977476, 'vf_loss': 0.004800971549121917, 'total_loss': -0.04394940102744002, 'approx_kl': 0.007294729119166732, 'clip_fraction': 0.00390625, 'grad_norm': 1.9217748641967773}
2022-12-29 13:21:30.053 DEBUG: Taking gradient step
2022-12-29 13:21:30.063 DEBUG: Loss 2: {'policy_loss': -0.025071760560276546, 'entropy_loss': -0.021623837295919657, 'vf_loss': 0.004798723425441135, 'total_loss': -0.04189687443075507, 'approx_kl': 0.011052539804950356, 'clip_fraction': 0.037760416977107525, 'grad_norm': 1.986759901046753}
2022-12-29 13:21:30.774 DEBUG: Taking gradient step
2022-12-29 13:21:30.783 DEBUG: Loss 3: {'policy_loss': 0.029602496256675884, 'entropy_loss': -0.02159539796411991, 'vf_loss': 0.007421244879797595, 'total_loss': 0.015428343172353573, 'approx_kl': 0.00866167969070375, 'clip_fraction': 0.053385416977107525, 'grad_norm': 1.8326351642608643}
2022-12-29 13:21:31.473 DEBUG: Taking gradient step
2022-12-29 13:21:31.482 DEBUG: Loss 4: {'policy_loss': 0.02655167637558797, 'entropy_loss': -0.022352155297994614, 'vf_loss': 0.007413873353981401, 'total_loss': 0.011613394431574754, 'approx_kl': 0.009092242922633886, 'clip_fraction': 0.07942708395421505, 'grad_norm': 2.024048089981079}
2022-12-29 13:21:32.193 DEBUG: Taking gradient step
2022-12-29 13:21:32.207 DEBUG: Loss 5: {'policy_loss': -0.02811574524891155, 'entropy_loss': -0.02136428328230977, 'vf_loss': 0.004780095669933099, 'total_loss': -0.04469993286128822, 'approx_kl': 0.02243776572868228, 'clip_fraction': 0.11458333395421505, 'grad_norm': 1.9232438802719116}
2022-12-29 13:21:32.928 DEBUG: Taking gradient step
2022-12-29 13:21:32.937 DEBUG: Loss 6: {'policy_loss': -0.030971826687789725, 'entropy_loss': -0.02198229730129242, 'vf_loss': 0.004772293650891791, 'total_loss': -0.04818183033819036, 'approx_kl': 0.01574059424456209, 'clip_fraction': 0.12109375, 'grad_norm': 0.7024456262588501}
2022-12-29 13:21:33.633 DEBUG: Taking gradient step
2022-12-29 13:21:33.642 DEBUG: Loss 7: {'policy_loss': -0.03180658176094211, 'entropy_loss': -0.022701443172991276, 'vf_loss': 0.004763465539217845, 'total_loss': -0.04974455939471553, 'approx_kl': 0.015808163967449218, 'clip_fraction': 0.140625, 'grad_norm': 0.8962417840957642}
2022-12-29 13:21:34.354 DEBUG: Taking gradient step
2022-12-29 13:21:34.363 DEBUG: Loss 8: {'policy_loss': -0.029896019152454635, 'entropy_loss': -0.02186866942793131, 'vf_loss': 0.004755290021751641, 'total_loss': -0.047009398558634306, 'approx_kl': 0.03005311358720064, 'clip_fraction': 0.2213541679084301, 'grad_norm': 1.4103893041610718}
2022-12-29 13:21:35.075 DEBUG: Taking gradient step
2022-12-29 13:21:35.085 DEBUG: Loss 9: {'policy_loss': 0.01347726973656329, 'entropy_loss': -0.022292233537882566, 'vf_loss': 0.0073619934588702324, 'total_loss': -0.0014529703424490392, 'approx_kl': 0.0265230571385473, 'clip_fraction': 0.2630208358168602, 'grad_norm': 1.3435382843017578}
2022-12-29 13:21:35.085 INFO: Optimization: policy loss=0.013, vf loss=0.007, entropy loss=-0.022, total loss=-0.001, num steps=10
2022-12-29 13:21:35.085 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 13:21:35.764 INFO: Evaluation rollout: return=0.508 (0.0), episode length=3.0
2022-12-29 13:21:35.765 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 13:21:35.767 INFO: Iteration: 122/137, steps: 26352
2022-12-29 13:22:04.891 DEBUG: Atoms are too close
2022-12-29 13:22:23.203 INFO: Training rollout: return=0.192 (2.4), episode length=3.0
2022-12-29 13:22:23.204 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 13:22:23.207 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-26352_train.pkl
2022-12-29 13:22:23.958 DEBUG: Taking gradient step
2022-12-29 13:22:23.975 DEBUG: Loss 0: {'policy_loss': 0.037426350922189815, 'entropy_loss': -0.023159400559961796, 'vf_loss': 0.007353890505587203, 'total_loss': 0.02162084086781523, 'approx_kl': 2.535913878887186e-08, 'clip_fraction': 0.0, 'grad_norm': 10.694426536560059}
2022-12-29 13:22:24.675 DEBUG: Taking gradient step
2022-12-29 13:22:24.684 DEBUG: Loss 1: {'policy_loss': 0.02661057524779132, 'entropy_loss': -0.02232759166508913, 'vf_loss': 0.007335025354667322, 'total_loss': 0.011618008937369514, 'approx_kl': -0.0007163526024669409, 'clip_fraction': 0.0, 'grad_norm': 23.082834243774414}
2022-12-29 13:22:25.394 DEBUG: Taking gradient step
2022-12-29 13:22:25.408 DEBUG: Loss 2: {'policy_loss': -0.027138152304841533, 'entropy_loss': -0.023377915378659964, 'vf_loss': 0.004735494832475397, 'total_loss': -0.045780572851026095, 'approx_kl': -0.0002556209219619632, 'clip_fraction': 0.03125, 'grad_norm': 2.080435037612915}
2022-12-29 13:22:26.163 DEBUG: Taking gradient step
2022-12-29 13:22:26.173 DEBUG: Loss 3: {'policy_loss': 0.02570186331848391, 'entropy_loss': -0.0227706884033978, 'vf_loss': 0.007339821393255614, 'total_loss': 0.010270996308341718, 'approx_kl': 0.001101367932278663, 'clip_fraction': 0.15234375, 'grad_norm': 1.7201716899871826}
2022-12-29 13:22:26.902 DEBUG: Taking gradient step
2022-12-29 13:22:26.917 DEBUG: Loss 4: {'policy_loss': -0.028934207869486705, 'entropy_loss': -0.022871700581163168, 'vf_loss': 0.004734476319752289, 'total_loss': -0.04707143213089758, 'approx_kl': 0.007648412371054292, 'clip_fraction': 0.18489583395421505, 'grad_norm': 1.8594614267349243}
2022-12-29 13:22:27.628 DEBUG: Taking gradient step
2022-12-29 13:22:27.637 DEBUG: Loss 5: {'policy_loss': -0.03169374152998625, 'entropy_loss': -0.023341542575508356, 'vf_loss': 0.00473540452690301, 'total_loss': -0.0502998795785916, 'approx_kl': 0.012298442190513015, 'clip_fraction': 0.26953125, 'grad_norm': 1.2093223333358765}
2022-12-29 13:22:28.371 DEBUG: Taking gradient step
2022-12-29 13:22:28.382 DEBUG: Loss 6: {'policy_loss': -0.029672614272088574, 'entropy_loss': -0.023417055141180754, 'vf_loss': 0.004734798368002696, 'total_loss': -0.04835487104526663, 'approx_kl': 0.018311007181182504, 'clip_fraction': 0.3098958358168602, 'grad_norm': 1.7243338823318481}
2022-12-29 13:22:29.077 DEBUG: Taking gradient step
2022-12-29 13:22:29.086 DEBUG: Loss 7: {'policy_loss': -0.0326261752067833, 'entropy_loss': -0.023139490745961666, 'vf_loss': 0.00473364626638575, 'total_loss': -0.05103201968635921, 'approx_kl': -0.004452693974599242, 'clip_fraction': 0.2838541716337204, 'grad_norm': 0.8873250484466553}
2022-12-29 13:22:29.788 DEBUG: Taking gradient step
2022-12-29 13:22:29.797 DEBUG: Loss 8: {'policy_loss': 0.013340893376922753, 'entropy_loss': -0.023576438892632723, 'vf_loss': 0.007302480717385021, 'total_loss': -0.00293306479832494, 'approx_kl': 0.013780996203422546, 'clip_fraction': 0.19921875, 'grad_norm': 0.6419898867607117}
2022-12-29 13:22:30.512 DEBUG: Taking gradient step
2022-12-29 13:22:30.521 DEBUG: Loss 9: {'policy_loss': 0.012539036483070653, 'entropy_loss': -0.024995632003992796, 'vf_loss': 0.007300757978784276, 'total_loss': -0.005155837542137866, 'approx_kl': 0.016252961941063404, 'clip_fraction': 0.140625, 'grad_norm': 2.05842661857605}
2022-12-29 13:22:30.521 INFO: Optimization: policy loss=0.013, vf loss=0.007, entropy loss=-0.025, total loss=-0.005, num steps=10
2022-12-29 13:22:30.521 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 13:22:31.242 INFO: Evaluation rollout: return=0.507 (0.0), episode length=3.0
2022-12-29 13:22:31.244 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 13:22:31.245 INFO: Iteration: 123/137, steps: 26568
2022-12-29 13:22:50.979 DEBUG: Atoms are too close
2022-12-29 13:23:17.992 INFO: Training rollout: return=0.181 (2.4), episode length=3.0
2022-12-29 13:23:17.994 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 13:23:17.996 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-26568_train.pkl
2022-12-29 13:23:18.724 DEBUG: Taking gradient step
2022-12-29 13:23:18.734 DEBUG: Loss 0: {'policy_loss': -0.01423798871707288, 'entropy_loss': -0.023585776798427105, 'vf_loss': 0.0032682403276550957, 'total_loss': -0.03455552518784489, 'approx_kl': 9.235615827662969e-09, 'clip_fraction': 0.0, 'grad_norm': 5.633516788482666}
2022-12-29 13:23:19.444 DEBUG: Taking gradient step
2022-12-29 13:23:19.453 DEBUG: Loss 1: {'policy_loss': -0.016066517473283658, 'entropy_loss': -0.023732506670057774, 'vf_loss': 0.003267094748521283, 'total_loss': -0.03653192939482015, 'approx_kl': 0.0004827666562050581, 'clip_fraction': 0.00390625, 'grad_norm': 5.176257610321045}
2022-12-29 13:23:20.136 DEBUG: Taking gradient step
2022-12-29 13:23:20.145 DEBUG: Loss 2: {'policy_loss': -0.022161375260162885, 'entropy_loss': -0.024273706134408712, 'vf_loss': 0.0032682840166337636, 'total_loss': -0.043166797377937834, 'approx_kl': 0.0050840581534430385, 'clip_fraction': 0.037760416977107525, 'grad_norm': 4.588685035705566}
2022-12-29 13:23:20.836 DEBUG: Taking gradient step
2022-12-29 13:23:20.845 DEBUG: Loss 3: {'policy_loss': -0.02613718258860968, 'entropy_loss': -0.0240013818256557, 'vf_loss': 0.003272924242210883, 'total_loss': -0.046865640172054496, 'approx_kl': -0.0019986280240118504, 'clip_fraction': 0.07161458395421505, 'grad_norm': 0.9135006666183472}
2022-12-29 13:23:21.552 DEBUG: Taking gradient step
2022-12-29 13:23:21.561 DEBUG: Loss 4: {'policy_loss': -0.024082787092658715, 'entropy_loss': -0.024808050598949194, 'vf_loss': 0.0032683687489961336, 'total_loss': -0.04562246894261178, 'approx_kl': 0.015711948974058032, 'clip_fraction': 0.1861979179084301, 'grad_norm': 1.20880925655365}
2022-12-29 13:23:22.260 DEBUG: Taking gradient step
2022-12-29 13:23:22.269 DEBUG: Loss 5: {'policy_loss': -0.023765546196881815, 'entropy_loss': -0.025424850173294544, 'vf_loss': 0.0032636568051922837, 'total_loss': -0.045926739564984075, 'approx_kl': 0.022650702856481075, 'clip_fraction': 0.26171875, 'grad_norm': 1.216797113418579}
2022-12-29 13:23:22.965 DEBUG: Taking gradient step
2022-12-29 13:23:22.975 DEBUG: Loss 6: {'policy_loss': -0.023676861894556082, 'entropy_loss': -0.02505626669153571, 'vf_loss': 0.0032593129133262418, 'total_loss': -0.04547381567276555, 'approx_kl': 0.005202450789511204, 'clip_fraction': 0.2408854216337204, 'grad_norm': 1.0391353368759155}
2022-12-29 13:23:23.661 DEBUG: Taking gradient step
2022-12-29 13:23:23.671 DEBUG: Loss 7: {'policy_loss': 0.0301914500399986, 'entropy_loss': -0.024329376872628927, 'vf_loss': 0.005851605025602349, 'total_loss': 0.011713678192972025, 'approx_kl': 0.020351163344457746, 'clip_fraction': 0.2005208358168602, 'grad_norm': 0.9172780513763428}
2022-12-29 13:23:24.395 DEBUG: Taking gradient step
2022-12-29 13:23:24.406 DEBUG: Loss 8: {'policy_loss': 0.04258799713527377, 'entropy_loss': -0.02510716486722231, 'vf_loss': 0.005902641564513006, 'total_loss': 0.023383473832564464, 'approx_kl': 0.021776849403977394, 'clip_fraction': 0.1901041679084301, 'grad_norm': 1.0288336277008057}
2022-12-29 13:23:25.116 DEBUG: Taking gradient step
2022-12-29 13:23:25.125 DEBUG: Loss 9: {'policy_loss': 0.04350730127587188, 'entropy_loss': -0.025626755319535732, 'vf_loss': 0.005893045325121259, 'total_loss': 0.02377359128145741, 'approx_kl': 0.0160211524926126, 'clip_fraction': 0.2005208358168602, 'grad_norm': 0.8646218180656433}
2022-12-29 13:23:25.125 INFO: Optimization: policy loss=0.044, vf loss=0.006, entropy loss=-0.026, total loss=0.024, num steps=10
2022-12-29 13:23:25.126 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 13:23:25.878 INFO: Evaluation rollout: return=0.506 (0.0), episode length=3.0
2022-12-29 13:23:25.879 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 13:23:25.881 INFO: Iteration: 124/137, steps: 26784
2022-12-29 13:24:10.733 DEBUG: Atoms are too close
2022-12-29 13:24:12.239 DEBUG: Atoms are too close
2022-12-29 13:24:13.321 INFO: Training rollout: return=-0.087 (3.3), episode length=3.0
2022-12-29 13:24:13.323 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 13:24:13.325 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-26784_train.pkl
2022-12-29 13:24:14.055 DEBUG: Taking gradient step
2022-12-29 13:24:14.064 DEBUG: Loss 0: {'policy_loss': 0.010997439091086726, 'entropy_loss': -0.024719530250877142, 'vf_loss': 0.012007457595563379, 'total_loss': -0.0017146335642270367, 'approx_kl': -1.70354423900676e-08, 'clip_fraction': 0.0, 'grad_norm': 16.225614547729492}
2022-12-29 13:24:14.772 DEBUG: Taking gradient step
2022-12-29 13:24:14.781 DEBUG: Loss 1: {'policy_loss': 0.011039888110006793, 'entropy_loss': -0.023656796663999557, 'vf_loss': 0.012042291229814591, 'total_loss': -0.0005746173241781768, 'approx_kl': 0.0017258905863855034, 'clip_fraction': 0.00390625, 'grad_norm': 24.872098922729492}
2022-12-29 13:24:15.486 DEBUG: Taking gradient step
2022-12-29 13:24:15.496 DEBUG: Loss 2: {'policy_loss': -0.03904553830624401, 'entropy_loss': -0.02386643225327134, 'vf_loss': 0.009441076106984931, 'total_loss': -0.053470894452530414, 'approx_kl': 0.002723029814660549, 'clip_fraction': 0.05208333395421505, 'grad_norm': 5.140438556671143}
2022-12-29 13:24:16.209 DEBUG: Taking gradient step
2022-12-29 13:24:16.218 DEBUG: Loss 3: {'policy_loss': -0.03592328420172171, 'entropy_loss': -0.025012696161866188, 'vf_loss': 0.009441089404330515, 'total_loss': -0.051494890959257376, 'approx_kl': 0.008183738216757774, 'clip_fraction': 0.0859375, 'grad_norm': 0.9981443881988525}
2022-12-29 13:24:16.914 DEBUG: Taking gradient step
2022-12-29 13:24:16.928 DEBUG: Loss 4: {'policy_loss': 0.003655344260678931, 'entropy_loss': -0.02569432696327567, 'vf_loss': 0.012016740653304893, 'total_loss': -0.010022242049291849, 'approx_kl': 0.014826020109467208, 'clip_fraction': 0.08723958395421505, 'grad_norm': 1.5741219520568848}
2022-12-29 13:24:17.667 DEBUG: Taking gradient step
2022-12-29 13:24:17.677 DEBUG: Loss 5: {'policy_loss': -0.0020079847579767794, 'entropy_loss': -0.024569786619395018, 'vf_loss': 0.012065731780298971, 'total_loss': -0.01451203959707282, 'approx_kl': 0.01953635411337018, 'clip_fraction': 0.08984375, 'grad_norm': 0.8589362502098083}
2022-12-29 13:24:18.392 DEBUG: Taking gradient step
2022-12-29 13:24:18.401 DEBUG: Loss 6: {'policy_loss': 0.0012569890915624243, 'entropy_loss': -0.025999885983765125, 'vf_loss': 0.012003512932615425, 'total_loss': -0.012739383959587272, 'approx_kl': 0.026934541296213865, 'clip_fraction': 0.11328125, 'grad_norm': 1.1918411254882812}
2022-12-29 13:24:19.117 DEBUG: Taking gradient step
2022-12-29 13:24:19.127 DEBUG: Loss 7: {'policy_loss': 0.039044168639049026, 'entropy_loss': -0.024738244246691465, 'vf_loss': 0.014638686078763624, 'total_loss': 0.02894461047112118, 'approx_kl': 0.026533365715295076, 'clip_fraction': 0.1809895858168602, 'grad_norm': 1.646435022354126}
2022-12-29 13:24:19.841 DEBUG: Taking gradient step
2022-12-29 13:24:19.851 DEBUG: Loss 8: {'policy_loss': -0.03709599538470357, 'entropy_loss': -0.02469605254009366, 'vf_loss': 0.009409549248603693, 'total_loss': -0.05238249867619354, 'approx_kl': 0.04225308075547218, 'clip_fraction': 0.2643229216337204, 'grad_norm': 1.1220170259475708}
2022-12-29 13:24:20.560 DEBUG: Taking gradient step
2022-12-29 13:24:20.569 DEBUG: Loss 9: {'policy_loss': 0.002253894989966407, 'entropy_loss': -0.023931582923978567, 'vf_loss': 0.01190633305599597, 'total_loss': -0.00977135487801619, 'approx_kl': 0.039721773471683264, 'clip_fraction': 0.27734375, 'grad_norm': 1.244942307472229}
2022-12-29 13:24:20.569 INFO: Optimization: policy loss=0.002, vf loss=0.012, entropy loss=-0.024, total loss=-0.010, num steps=10
2022-12-29 13:24:20.570 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 13:24:21.343 INFO: Evaluation rollout: return=0.496 (0.0), episode length=3.0
2022-12-29 13:24:21.344 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 13:24:21.346 INFO: Iteration: 125/137, steps: 27000
2022-12-29 13:25:08.951 INFO: Training rollout: return=0.466 (0.0), episode length=3.0
2022-12-29 13:25:08.953 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 13:25:08.956 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-27000_train.pkl
2022-12-29 13:25:09.668 DEBUG: Taking gradient step
2022-12-29 13:25:09.677 DEBUG: Loss 0: {'policy_loss': -0.004043022286249344, 'entropy_loss': -0.024041988421231508, 'vf_loss': 0.00013472000024346411, 'total_loss': -0.027950290707237386, 'approx_kl': -1.461012288928032e-08, 'clip_fraction': 0.0, 'grad_norm': 7.3625664710998535}
2022-12-29 13:25:10.364 DEBUG: Taking gradient step
2022-12-29 13:25:10.373 DEBUG: Loss 1: {'policy_loss': 0.009071048802315067, 'entropy_loss': -0.023477311246097088, 'vf_loss': 0.00014845315724755644, 'total_loss': -0.014257809286534464, 'approx_kl': 0.002568822994362563, 'clip_fraction': 0.0, 'grad_norm': 7.698017597198486}
2022-12-29 13:25:11.061 DEBUG: Taking gradient step
2022-12-29 13:25:11.072 DEBUG: Loss 2: {'policy_loss': 0.009376615581647756, 'entropy_loss': -0.02413551276549697, 'vf_loss': 0.0001602111628645332, 'total_loss': -0.014598686020984679, 'approx_kl': 0.006009796110447496, 'clip_fraction': 0.041666666977107525, 'grad_norm': 2.134721040725708}
2022-12-29 13:25:11.755 DEBUG: Taking gradient step
2022-12-29 13:25:11.764 DEBUG: Loss 3: {'policy_loss': 0.031691216917902935, 'entropy_loss': -0.024086596444249153, 'vf_loss': 0.00016769023625955032, 'total_loss': 0.007772310709913334, 'approx_kl': 0.018142787739634514, 'clip_fraction': 0.1393229179084301, 'grad_norm': 4.808792591094971}
2022-12-29 13:25:12.508 DEBUG: Taking gradient step
2022-12-29 13:25:12.517 DEBUG: Loss 4: {'policy_loss': -0.022538005890671366, 'entropy_loss': -0.023809079080820084, 'vf_loss': 0.0001812882460427415, 'total_loss': -0.04616579672544871, 'approx_kl': 0.02075529843568802, 'clip_fraction': 0.1614583358168602, 'grad_norm': 3.8427445888519287}
2022-12-29 13:25:13.205 DEBUG: Taking gradient step
2022-12-29 13:25:13.214 DEBUG: Loss 5: {'policy_loss': 0.0016716028517329857, 'entropy_loss': -0.02483010571449995, 'vf_loss': 0.00018124066988455483, 'total_loss': -0.02297726219288241, 'approx_kl': 0.019965860759839416, 'clip_fraction': 0.21484375, 'grad_norm': 3.942723035812378}
2022-12-29 13:25:13.918 DEBUG: Taking gradient step
2022-12-29 13:25:13.927 DEBUG: Loss 6: {'policy_loss': -0.005435317122830403, 'entropy_loss': -0.02322119101881981, 'vf_loss': 0.00018655247508694595, 'total_loss': -0.028469955666563268, 'approx_kl': 0.022788549307733774, 'clip_fraction': 0.2486979216337204, 'grad_norm': 4.23154878616333}
2022-12-29 13:25:14.669 DEBUG: Taking gradient step
2022-12-29 13:25:14.678 DEBUG: Loss 7: {'policy_loss': -0.019823179379556556, 'entropy_loss': -0.023053481243550777, 'vf_loss': 0.0001894915610732098, 'total_loss': -0.042687169062034125, 'approx_kl': 0.033011144027113914, 'clip_fraction': 0.2721354216337204, 'grad_norm': 5.469755172729492}
2022-12-29 13:25:15.372 DEBUG: Taking gradient step
2022-12-29 13:25:15.386 DEBUG: Loss 8: {'policy_loss': -0.06274193883955473, 'entropy_loss': -0.02365843951702118, 'vf_loss': 0.00019256621300952535, 'total_loss': -0.08620781214356638, 'approx_kl': 0.03657710272818804, 'clip_fraction': 0.2356770858168602, 'grad_norm': 3.8399007320404053}
2022-12-29 13:25:16.135 DEBUG: Early stopping at step 9 for reaching max KL.
2022-12-29 13:25:16.135 INFO: Optimization: policy loss=-0.063, vf loss=0.000, entropy loss=-0.024, total loss=-0.086, num steps=9
2022-12-29 13:25:16.136 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 13:25:16.853 INFO: Evaluation rollout: return=0.502 (0.0), episode length=3.0
2022-12-29 13:25:16.854 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 13:25:16.856 INFO: Iteration: 126/137, steps: 27216
2022-12-29 13:25:29.433 DEBUG: Atoms are too close
2022-12-29 13:26:03.730 INFO: Training rollout: return=0.189 (2.4), episode length=3.0
2022-12-29 13:26:03.732 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 13:26:03.734 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-27216_train.pkl
2022-12-29 13:26:04.435 DEBUG: Taking gradient step
2022-12-29 13:26:04.445 DEBUG: Loss 0: {'policy_loss': -0.015336519016325626, 'entropy_loss': -0.02497365279123187, 'vf_loss': 0.004789694924728273, 'total_loss': -0.03552047688282922, 'approx_kl': -3.663202186032777e-08, 'clip_fraction': 0.0, 'grad_norm': 9.450636863708496}
2022-12-29 13:26:05.200 DEBUG: Taking gradient step
2022-12-29 13:26:05.209 DEBUG: Loss 1: {'policy_loss': 0.08719130521412517, 'entropy_loss': -0.02431465219706297, 'vf_loss': 0.00991156469072257, 'total_loss': 0.07278821770778476, 'approx_kl': -0.005210098577663302, 'clip_fraction': 0.0, 'grad_norm': 23.09592628479004}
2022-12-29 13:26:05.895 DEBUG: Taking gradient step
2022-12-29 13:26:05.904 DEBUG: Loss 2: {'policy_loss': 0.0279424135377427, 'entropy_loss': -0.024126614909619093, 'vf_loss': 0.007347064794976336, 'total_loss': 0.011162863423099946, 'approx_kl': -0.010523284901864827, 'clip_fraction': 0.05989583395421505, 'grad_norm': 8.177336692810059}
2022-12-29 13:26:06.592 DEBUG: Taking gradient step
2022-12-29 13:26:06.601 DEBUG: Loss 3: {'policy_loss': 0.014655242050684199, 'entropy_loss': -0.023997450713068247, 'vf_loss': 0.007357410589875268, 'total_loss': -0.0019847980725087727, 'approx_kl': -0.006061567226424813, 'clip_fraction': 0.1549479179084301, 'grad_norm': 1.4551504850387573}
2022-12-29 13:26:07.290 DEBUG: Taking gradient step
2022-12-29 13:26:07.309 DEBUG: Loss 4: {'policy_loss': -0.029768707302108698, 'entropy_loss': -0.024022351019084454, 'vf_loss': 0.004787725023582465, 'total_loss': -0.04900333329761068, 'approx_kl': -0.013655840884894133, 'clip_fraction': 0.2421875, 'grad_norm': 0.9304232001304626}
2022-12-29 13:26:08.005 DEBUG: Taking gradient step
2022-12-29 13:26:08.014 DEBUG: Loss 5: {'policy_loss': -0.03123587397015515, 'entropy_loss': -0.02361492346972227, 'vf_loss': 0.00478723970333767, 'total_loss': -0.05006355773653975, 'approx_kl': -0.004222282441332936, 'clip_fraction': 0.3359375, 'grad_norm': 1.4671533107757568}
2022-12-29 13:26:08.701 DEBUG: Taking gradient step
2022-12-29 13:26:08.710 DEBUG: Loss 6: {'policy_loss': -0.028537639559543134, 'entropy_loss': -0.02451307186856866, 'vf_loss': 0.004779624039651225, 'total_loss': -0.048271087388460567, 'approx_kl': 0.009093280415982008, 'clip_fraction': 0.3958333358168602, 'grad_norm': 1.5414890050888062}
2022-12-29 13:26:09.431 DEBUG: Taking gradient step
2022-12-29 13:26:09.441 DEBUG: Loss 7: {'policy_loss': -0.02979078358592822, 'entropy_loss': -0.024781886022537947, 'vf_loss': 0.004775959664870188, 'total_loss': -0.049796709943595974, 'approx_kl': -0.013750817626714706, 'clip_fraction': 0.4270833358168602, 'grad_norm': 1.5316429138183594}
2022-12-29 13:26:10.148 DEBUG: Taking gradient step
2022-12-29 13:26:10.157 DEBUG: Loss 8: {'policy_loss': -0.028239977522639344, 'entropy_loss': -0.025137191638350487, 'vf_loss': 0.0047697800104443, 'total_loss': -0.04860738915054552, 'approx_kl': 0.004828216042369604, 'clip_fraction': 0.4205729216337204, 'grad_norm': 1.6942987442016602}
2022-12-29 13:26:10.890 DEBUG: Taking gradient step
2022-12-29 13:26:10.899 DEBUG: Loss 9: {'policy_loss': -0.02888949909332597, 'entropy_loss': -0.02433455688878894, 'vf_loss': 0.004767014049360361, 'total_loss': -0.04845704193275453, 'approx_kl': 0.011913469526916742, 'clip_fraction': 0.4127604216337204, 'grad_norm': 1.704394817352295}
2022-12-29 13:26:10.899 INFO: Optimization: policy loss=-0.029, vf loss=0.005, entropy loss=-0.024, total loss=-0.048, num steps=10
2022-12-29 13:26:10.900 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 13:26:11.594 INFO: Evaluation rollout: return=0.490 (0.0), episode length=3.0
2022-12-29 13:26:11.595 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 13:26:11.597 INFO: Iteration: 127/137, steps: 27432
2022-12-29 13:27:00.158 INFO: Training rollout: return=0.464 (0.0), episode length=3.0
2022-12-29 13:27:00.160 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 13:27:00.162 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-27432_train.pkl
2022-12-29 13:27:00.909 DEBUG: Taking gradient step
2022-12-29 13:27:00.918 DEBUG: Loss 0: {'policy_loss': -0.04009122094258942, 'entropy_loss': -0.024869479704648256, 'vf_loss': 0.00012813422134202562, 'total_loss': -0.06483256642589566, 'approx_kl': -8.991143474190721e-08, 'clip_fraction': 0.0, 'grad_norm': 9.532310485839844}
2022-12-29 13:27:01.636 DEBUG: Taking gradient step
2022-12-29 13:27:01.646 DEBUG: Loss 1: {'policy_loss': -0.06134092749218168, 'entropy_loss': -0.025026035029441118, 'vf_loss': 0.00012326087433254295, 'total_loss': -0.08624370164729026, 'approx_kl': 0.003383226110599935, 'clip_fraction': 0.01171875, 'grad_norm': 10.101984977722168}
2022-12-29 13:27:02.343 DEBUG: Taking gradient step
2022-12-29 13:27:02.357 DEBUG: Loss 2: {'policy_loss': 0.008783877971134987, 'entropy_loss': -0.025164189282804728, 'vf_loss': 0.00011476084880401781, 'total_loss': -0.01626555046286572, 'approx_kl': 0.014124966925010085, 'clip_fraction': 0.109375, 'grad_norm': 12.03135871887207}
2022-12-29 13:27:03.043 DEBUG: Taking gradient step
2022-12-29 13:27:03.052 DEBUG: Loss 3: {'policy_loss': 0.0368829534998982, 'entropy_loss': -0.0254138121381402, 'vf_loss': 0.00010947363613811378, 'total_loss': 0.011578614997896114, 'approx_kl': 0.012547150021418929, 'clip_fraction': 0.1783854179084301, 'grad_norm': 21.49393653869629}
2022-12-29 13:27:03.746 DEBUG: Taking gradient step
2022-12-29 13:27:03.755 DEBUG: Loss 4: {'policy_loss': -0.01353871771168132, 'entropy_loss': -0.02514998661354184, 'vf_loss': 0.00010634194598808869, 'total_loss': -0.03858236237923507, 'approx_kl': 0.024675377644598484, 'clip_fraction': 0.2434895858168602, 'grad_norm': 11.142230033874512}
2022-12-29 13:27:04.440 DEBUG: Taking gradient step
2022-12-29 13:27:04.449 DEBUG: Loss 5: {'policy_loss': 0.015949886568122976, 'entropy_loss': -0.02536323433741927, 'vf_loss': 0.00010170347067631788, 'total_loss': -0.009311644298619977, 'approx_kl': 0.035754787968471646, 'clip_fraction': 0.2643229216337204, 'grad_norm': 9.156949043273926}
2022-12-29 13:27:05.168 DEBUG: Taking gradient step
2022-12-29 13:27:05.178 DEBUG: Loss 6: {'policy_loss': -0.09750410923271068, 'entropy_loss': -0.024142546579241753, 'vf_loss': 9.966248226050037e-05, 'total_loss': -0.12154699332969192, 'approx_kl': 0.030680212657898664, 'clip_fraction': 0.25390625, 'grad_norm': 5.420801639556885}
2022-12-29 13:27:05.899 DEBUG: Taking gradient step
2022-12-29 13:27:05.908 DEBUG: Loss 7: {'policy_loss': 0.0045921573763575765, 'entropy_loss': -0.025438770651817322, 'vf_loss': 9.513858619491861e-05, 'total_loss': -0.02075147468926483, 'approx_kl': 0.025718812947161496, 'clip_fraction': 0.1627604179084301, 'grad_norm': 6.349245548248291}
2022-12-29 13:27:06.631 DEBUG: Taking gradient step
2022-12-29 13:27:06.640 DEBUG: Loss 8: {'policy_loss': 0.017228276267179654, 'entropy_loss': -0.025098068173974752, 'vf_loss': 9.103932187311922e-05, 'total_loss': -0.007778752584921986, 'approx_kl': 0.028789271600544453, 'clip_fraction': 0.11848958395421505, 'grad_norm': 7.263004779815674}
2022-12-29 13:27:07.365 DEBUG: Taking gradient step
2022-12-29 13:27:07.379 DEBUG: Loss 9: {'policy_loss': -0.03524601348985028, 'entropy_loss': -0.025780394673347473, 'vf_loss': 8.93844652419584e-05, 'total_loss': -0.06093702369795578, 'approx_kl': 0.03317077690735459, 'clip_fraction': 0.11848958395421505, 'grad_norm': 6.498846530914307}
2022-12-29 13:27:07.379 INFO: Optimization: policy loss=-0.035, vf loss=0.000, entropy loss=-0.026, total loss=-0.061, num steps=10
2022-12-29 13:27:07.380 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 13:27:08.061 INFO: Evaluation rollout: return=0.491 (0.0), episode length=3.0
2022-12-29 13:27:08.062 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 13:27:08.064 INFO: Iteration: 128/137, steps: 27648
2022-12-29 13:27:56.626 INFO: Training rollout: return=0.471 (0.0), episode length=3.0
2022-12-29 13:27:56.627 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 13:27:56.630 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-27648_train.pkl
2022-12-29 13:27:57.393 DEBUG: Taking gradient step
2022-12-29 13:27:57.404 DEBUG: Loss 0: {'policy_loss': 0.011631330462265674, 'entropy_loss': -0.026570582296699286, 'vf_loss': 8.819973073486517e-05, 'total_loss': -0.014851052103698744, 'approx_kl': 3.8067810237407684e-08, 'clip_fraction': 0.0, 'grad_norm': 15.352483749389648}
2022-12-29 13:27:58.102 DEBUG: Taking gradient step
2022-12-29 13:27:58.111 DEBUG: Loss 1: {'policy_loss': -0.004244378770962084, 'entropy_loss': -0.026107797864824533, 'vf_loss': 8.509535448778225e-05, 'total_loss': -0.030267081281298833, 'approx_kl': 0.0013668157334905118, 'clip_fraction': 0.0, 'grad_norm': 17.670137405395508}
2022-12-29 13:27:58.790 DEBUG: Taking gradient step
2022-12-29 13:27:58.799 DEBUG: Loss 2: {'policy_loss': 0.006741720165280008, 'entropy_loss': -0.02657359279692173, 'vf_loss': 8.124252112651823e-05, 'total_loss': -0.019750630110515203, 'approx_kl': 0.00817034486681223, 'clip_fraction': 0.01171875, 'grad_norm': 10.637343406677246}
2022-12-29 13:27:59.513 DEBUG: Taking gradient step
2022-12-29 13:27:59.530 DEBUG: Loss 3: {'policy_loss': 0.03544594586898803, 'entropy_loss': -0.0257244436070323, 'vf_loss': 7.68394101818149e-05, 'total_loss': 0.009798341672137542, 'approx_kl': 0.026737671112641692, 'clip_fraction': 0.1119791679084301, 'grad_norm': 6.837813377380371}
2022-12-29 13:28:00.227 DEBUG: Taking gradient step
2022-12-29 13:28:00.236 DEBUG: Loss 4: {'policy_loss': -0.02393242621033302, 'entropy_loss': -0.024559963028877974, 'vf_loss': 7.707342492480477e-05, 'total_loss': -0.048415315814286194, 'approx_kl': 0.04375397600233555, 'clip_fraction': 0.23046875, 'grad_norm': 16.474824905395508}
2022-12-29 13:28:00.978 DEBUG: Early stopping at step 5 for reaching max KL.
2022-12-29 13:28:00.978 INFO: Optimization: policy loss=-0.024, vf loss=0.000, entropy loss=-0.025, total loss=-0.048, num steps=5
2022-12-29 13:28:00.979 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 13:28:01.723 INFO: Evaluation rollout: return=0.497 (0.0), episode length=3.0
2022-12-29 13:28:01.724 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 13:28:01.727 INFO: Iteration: 129/137, steps: 27864
2022-12-29 13:28:14.853 DEBUG: Atoms are too close
2022-12-29 13:28:49.506 INFO: Training rollout: return=0.185 (2.4), episode length=3.0
2022-12-29 13:28:49.507 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 13:28:49.510 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-27864_train.pkl
2022-12-29 13:28:50.231 DEBUG: Taking gradient step
2022-12-29 13:28:50.240 DEBUG: Loss 0: {'policy_loss': -0.019250504618462366, 'entropy_loss': -0.025607403367757797, 'vf_loss': 0.004744820219084229, 'total_loss': -0.04011308776713594, 'approx_kl': 1.8975697457790375e-08, 'clip_fraction': 0.0, 'grad_norm': 12.535911560058594}
2022-12-29 13:28:50.949 DEBUG: Taking gradient step
2022-12-29 13:28:50.958 DEBUG: Loss 1: {'policy_loss': 0.03722099404735796, 'entropy_loss': -0.025467222556471825, 'vf_loss': 0.007331295876135326, 'total_loss': 0.01908506736702146, 'approx_kl': 0.007617168826982379, 'clip_fraction': 0.018229166977107525, 'grad_norm': 14.743520736694336}
2022-12-29 13:28:51.680 DEBUG: Taking gradient step
2022-12-29 13:28:51.689 DEBUG: Loss 2: {'policy_loss': -0.023606324960150537, 'entropy_loss': -0.024516891222447157, 'vf_loss': 0.004745110047036799, 'total_loss': -0.04337810613556089, 'approx_kl': 0.012926380266435444, 'clip_fraction': 0.05598958395421505, 'grad_norm': 11.914443969726562}
2022-12-29 13:28:52.385 DEBUG: Taking gradient step
2022-12-29 13:28:52.394 DEBUG: Loss 3: {'policy_loss': 0.01816992567866637, 'entropy_loss': -0.02510544378310442, 'vf_loss': 0.007333805076295037, 'total_loss': 0.0003982869718569884, 'approx_kl': 0.02789877459872514, 'clip_fraction': 0.14453125, 'grad_norm': 6.092560291290283}
2022-12-29 13:28:53.111 DEBUG: Taking gradient step
2022-12-29 13:28:53.120 DEBUG: Loss 4: {'policy_loss': 0.015654086797650416, 'entropy_loss': -0.02483872463926673, 'vf_loss': 0.00737225288173011, 'total_loss': -0.0018123849598862055, 'approx_kl': 0.023143621277995408, 'clip_fraction': 0.2578125, 'grad_norm': 1.502842903137207}
2022-12-29 13:28:53.811 DEBUG: Early stopping at step 5 for reaching max KL.
2022-12-29 13:28:53.812 INFO: Optimization: policy loss=0.016, vf loss=0.007, entropy loss=-0.025, total loss=-0.002, num steps=5
2022-12-29 13:28:53.812 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 13:28:54.528 INFO: Evaluation rollout: return=0.505 (0.0), episode length=3.0
2022-12-29 13:28:54.528 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 13:28:54.530 INFO: Iteration: 130/137, steps: 28080
2022-12-29 13:29:45.143 INFO: Training rollout: return=0.473 (0.0), episode length=3.0
2022-12-29 13:29:45.144 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 13:29:45.147 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-28080_train.pkl
2022-12-29 13:29:45.885 DEBUG: Taking gradient step
2022-12-29 13:29:45.894 DEBUG: Loss 0: {'policy_loss': -0.0049103124798111596, 'entropy_loss': -0.02550265332683921, 'vf_loss': 6.809847499058854e-05, 'total_loss': -0.03034486733165978, 'approx_kl': -5.560771931811814e-08, 'clip_fraction': 0.0, 'grad_norm': 20.422073364257812}
2022-12-29 13:29:46.603 DEBUG: Taking gradient step
2022-12-29 13:29:46.612 DEBUG: Loss 1: {'policy_loss': -0.036319687206752674, 'entropy_loss': -0.02480476861819625, 'vf_loss': 6.903555514469956e-05, 'total_loss': -0.06105542026980422, 'approx_kl': 0.0027028177864849567, 'clip_fraction': 0.014322916977107525, 'grad_norm': 16.24748420715332}
2022-12-29 13:29:47.322 DEBUG: Taking gradient step
2022-12-29 13:29:47.331 DEBUG: Loss 2: {'policy_loss': 0.004733684659098618, 'entropy_loss': -0.02478806907311082, 'vf_loss': 6.647984340437971e-05, 'total_loss': -0.019987904570607822, 'approx_kl': 0.021554287523031235, 'clip_fraction': 0.09375, 'grad_norm': 12.225652694702148}
2022-12-29 13:29:48.038 DEBUG: Taking gradient step
2022-12-29 13:29:48.047 DEBUG: Loss 3: {'policy_loss': 0.004215300014472165, 'entropy_loss': -0.025125025771558285, 'vf_loss': 6.601844167999401e-05, 'total_loss': -0.020843707315406128, 'approx_kl': 0.04215711331926286, 'clip_fraction': 0.1953125, 'grad_norm': 12.449508666992188}
2022-12-29 13:29:48.745 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-29 13:29:48.745 INFO: Optimization: policy loss=0.004, vf loss=0.000, entropy loss=-0.025, total loss=-0.021, num steps=4
2022-12-29 13:29:48.746 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 13:29:49.387 INFO: Evaluation rollout: return=0.508 (0.0), episode length=3.0
2022-12-29 13:29:49.387 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 13:29:49.389 DEBUG: Deleting old model: runs/H2O/models/H2O_run-1_steps-26136.model
2022-12-29 13:29:49.392 DEBUG: Saving model: runs/H2O/models/H2O_run-1_steps-28296.model
2022-12-29 13:29:49.421 INFO: Iteration: 131/137, steps: 28296
2022-12-29 13:29:51.359 DEBUG: Atoms are too close
2022-12-29 13:30:38.645 INFO: Training rollout: return=0.185 (2.4), episode length=3.0
2022-12-29 13:30:38.647 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 13:30:38.649 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-28296_train.pkl
2022-12-29 13:30:39.377 DEBUG: Taking gradient step
2022-12-29 13:30:39.387 DEBUG: Loss 0: {'policy_loss': 0.053105512262316655, 'entropy_loss': -0.024579154793173075, 'vf_loss': 0.005918546100231383, 'total_loss': 0.03444490356937497, 'approx_kl': -9.561578373507018e-08, 'clip_fraction': 0.0, 'grad_norm': 28.69626235961914}
2022-12-29 13:30:40.105 DEBUG: Taking gradient step
2022-12-29 13:30:40.114 DEBUG: Loss 1: {'policy_loss': 0.03861787038807995, 'entropy_loss': -0.024658730253577232, 'vf_loss': 0.005919486214861412, 'total_loss': 0.01987862634936413, 'approx_kl': 0.0053172820480540395, 'clip_fraction': 0.0, 'grad_norm': 25.59937286376953}
2022-12-29 13:30:40.857 DEBUG: Taking gradient step
2022-12-29 13:30:40.868 DEBUG: Loss 2: {'policy_loss': -0.0221850681945783, 'entropy_loss': -0.024622521363198757, 'vf_loss': 0.0032505355460268072, 'total_loss': -0.04355705401175025, 'approx_kl': 0.015931474277749658, 'clip_fraction': 0.057291666977107525, 'grad_norm': 1.0090166330337524}
2022-12-29 13:30:41.580 DEBUG: Taking gradient step
2022-12-29 13:30:41.590 DEBUG: Loss 3: {'policy_loss': -0.02443082986540078, 'entropy_loss': -0.02344434754922986, 'vf_loss': 0.0032522127086912285, 'total_loss': -0.044622964705939405, 'approx_kl': 0.01951496588299051, 'clip_fraction': 0.11979166697710752, 'grad_norm': 1.140108346939087}
2022-12-29 13:30:42.397 DEBUG: Taking gradient step
2022-12-29 13:30:42.407 DEBUG: Loss 4: {'policy_loss': -0.018679083693006887, 'entropy_loss': -0.024920093826949596, 'vf_loss': 0.003246962728289092, 'total_loss': -0.040352214791667396, 'approx_kl': 0.022383898496627808, 'clip_fraction': 0.1614583358168602, 'grad_norm': 1.162673830986023}
2022-12-29 13:30:43.156 DEBUG: Taking gradient step
2022-12-29 13:30:43.166 DEBUG: Loss 5: {'policy_loss': -0.023216826151932615, 'entropy_loss': -0.024008362088352442, 'vf_loss': 0.003248617027424528, 'total_loss': -0.04397657121286053, 'approx_kl': 0.019895532517693937, 'clip_fraction': 0.1966145858168602, 'grad_norm': 0.7946464419364929}
2022-12-29 13:30:43.889 DEBUG: Taking gradient step
2022-12-29 13:30:43.899 DEBUG: Loss 6: {'policy_loss': -0.023824648725025793, 'entropy_loss': -0.025308408308774233, 'vf_loss': 0.00324744283587064, 'total_loss': -0.04588561419792937, 'approx_kl': 0.013537992490455508, 'clip_fraction': 0.1979166679084301, 'grad_norm': 0.6187508702278137}
2022-12-29 13:30:44.631 DEBUG: Taking gradient step
2022-12-29 13:30:44.641 DEBUG: Loss 7: {'policy_loss': -0.02548246171974302, 'entropy_loss': -0.024249104782938957, 'vf_loss': 0.003246144815004277, 'total_loss': -0.046485421687677705, 'approx_kl': 0.007684730691835284, 'clip_fraction': 0.2161458358168602, 'grad_norm': 9.120229721069336}
2022-12-29 13:30:45.337 DEBUG: Taking gradient step
2022-12-29 13:30:45.348 DEBUG: Loss 8: {'policy_loss': -0.01726189831473395, 'entropy_loss': -0.024140629917383194, 'vf_loss': 0.0032395166773102587, 'total_loss': -0.03816301155480688, 'approx_kl': 0.009040090721100569, 'clip_fraction': 0.2682291716337204, 'grad_norm': 9.706531524658203}
2022-12-29 13:30:46.046 DEBUG: Taking gradient step
2022-12-29 13:30:46.056 DEBUG: Loss 9: {'policy_loss': -0.020728377072318706, 'entropy_loss': -0.023742528166621923, 'vf_loss': 0.0032382890833188133, 'total_loss': -0.04123261615562182, 'approx_kl': 0.01142906816676259, 'clip_fraction': 0.2890625, 'grad_norm': 9.493050575256348}
2022-12-29 13:30:46.056 INFO: Optimization: policy loss=-0.021, vf loss=0.003, entropy loss=-0.024, total loss=-0.041, num steps=10
2022-12-29 13:30:46.056 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 13:30:46.778 INFO: Evaluation rollout: return=0.511 (0.0), episode length=3.0
2022-12-29 13:30:46.778 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 13:30:46.780 INFO: Iteration: 132/137, steps: 28512
2022-12-29 13:31:26.098 DEBUG: Atoms are too close
2022-12-29 13:31:35.016 INFO: Training rollout: return=0.197 (2.4), episode length=3.0
2022-12-29 13:31:35.018 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 13:31:35.020 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-28512_train.pkl
2022-12-29 13:31:35.755 DEBUG: Taking gradient step
2022-12-29 13:31:35.764 DEBUG: Loss 0: {'policy_loss': 0.14925496351319706, 'entropy_loss': -0.024052259977906942, 'vf_loss': 0.012574125175605222, 'total_loss': 0.13777682871089533, 'approx_kl': 1.979060471057892e-08, 'clip_fraction': 0.0, 'grad_norm': 20.96534538269043}
2022-12-29 13:31:36.480 DEBUG: Taking gradient step
2022-12-29 13:31:36.494 DEBUG: Loss 1: {'policy_loss': -0.024353623285405905, 'entropy_loss': -0.0247865691781044, 'vf_loss': 0.004755035909161976, 'total_loss': -0.044385156554348326, 'approx_kl': -0.00012193084694445133, 'clip_fraction': 0.0, 'grad_norm': 7.496884346008301}
2022-12-29 13:31:37.232 DEBUG: Taking gradient step
2022-12-29 13:31:37.243 DEBUG: Loss 2: {'policy_loss': -0.024431384926467507, 'entropy_loss': -0.02438043523579836, 'vf_loss': 0.00475221694868406, 'total_loss': -0.04405960321358181, 'approx_kl': 0.0008996137185022235, 'clip_fraction': 0.022135416977107525, 'grad_norm': 2.111196279525757}
2022-12-29 13:31:37.953 DEBUG: Taking gradient step
2022-12-29 13:31:37.963 DEBUG: Loss 3: {'policy_loss': -0.027389636047071297, 'entropy_loss': -0.024374140426516533, 'vf_loss': 0.004754004073010081, 'total_loss': -0.04700977240057775, 'approx_kl': 0.00820841221138835, 'clip_fraction': 0.06770833395421505, 'grad_norm': 1.81500244140625}
2022-12-29 13:31:38.656 DEBUG: Taking gradient step
2022-12-29 13:31:38.665 DEBUG: Loss 4: {'policy_loss': -0.028430862315960564, 'entropy_loss': -0.02541123004630208, 'vf_loss': 0.004755366522691628, 'total_loss': -0.04908672583957102, 'approx_kl': 0.0259796209866181, 'clip_fraction': 0.12890625, 'grad_norm': 1.6919888257980347}
2022-12-29 13:31:39.363 DEBUG: Taking gradient step
2022-12-29 13:31:39.372 DEBUG: Loss 5: {'policy_loss': -0.028241230493796822, 'entropy_loss': -0.02495980029925704, 'vf_loss': 0.0047547147138636645, 'total_loss': -0.04844631607919019, 'approx_kl': 0.04013825999572873, 'clip_fraction': 0.2395833358168602, 'grad_norm': 1.0408378839492798}
2022-12-29 13:31:40.049 DEBUG: Taking gradient step
2022-12-29 13:31:40.058 DEBUG: Loss 6: {'policy_loss': 0.016211939709897996, 'entropy_loss': -0.02539427252486348, 'vf_loss': 0.007364909596083272, 'total_loss': -0.0018174232188822165, 'approx_kl': 0.041876533068716526, 'clip_fraction': 0.3151041716337204, 'grad_norm': 1.0274919271469116}
2022-12-29 13:31:40.743 DEBUG: Early stopping at step 7 for reaching max KL.
2022-12-29 13:31:40.744 INFO: Optimization: policy loss=0.016, vf loss=0.007, entropy loss=-0.025, total loss=-0.002, num steps=7
2022-12-29 13:31:40.744 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 13:31:41.502 INFO: Evaluation rollout: return=0.511 (0.0), episode length=3.0
2022-12-29 13:31:41.503 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 13:31:41.505 INFO: Iteration: 133/137, steps: 28728
2022-12-29 13:31:55.520 DEBUG: Atoms are too close
2022-12-29 13:32:30.286 INFO: Training rollout: return=0.192 (2.4), episode length=3.0
2022-12-29 13:32:30.288 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 13:32:30.291 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-28728_train.pkl
2022-12-29 13:32:31.016 DEBUG: Taking gradient step
2022-12-29 13:32:31.027 DEBUG: Loss 0: {'policy_loss': -0.017096233926328745, 'entropy_loss': -0.024912186432629824, 'vf_loss': 0.004745525217514828, 'total_loss': -0.037262895141443736, 'approx_kl': 3.104408285992122e-09, 'clip_fraction': 0.0, 'grad_norm': 10.580798149108887}
2022-12-29 13:32:31.728 DEBUG: Taking gradient step
2022-12-29 13:32:31.738 DEBUG: Loss 1: {'policy_loss': 0.0298931688565292, 'entropy_loss': -0.02469813171774149, 'vf_loss': 0.00734702808997889, 'total_loss': 0.012542065228766594, 'approx_kl': 0.0023837560293031856, 'clip_fraction': 0.00390625, 'grad_norm': 9.073287963867188}
2022-12-29 13:32:32.450 DEBUG: Taking gradient step
2022-12-29 13:32:32.459 DEBUG: Loss 2: {'policy_loss': -0.027104058506483574, 'entropy_loss': -0.026070112362504005, 'vf_loss': 0.00474632442590484, 'total_loss': -0.04842784644308274, 'approx_kl': 0.00816017878241837, 'clip_fraction': 0.0234375, 'grad_norm': 0.4565233588218689}
2022-12-29 13:32:33.166 DEBUG: Taking gradient step
2022-12-29 13:32:33.176 DEBUG: Loss 3: {'policy_loss': 0.0298202376329758, 'entropy_loss': -0.025921436492353678, 'vf_loss': 0.007324473053649031, 'total_loss': 0.01122327419427116, 'approx_kl': 0.017713894601911306, 'clip_fraction': 0.037760416977107525, 'grad_norm': 0.6216755509376526}
2022-12-29 13:32:33.894 DEBUG: Taking gradient step
2022-12-29 13:32:33.903 DEBUG: Loss 4: {'policy_loss': -0.024545991733570367, 'entropy_loss': -0.0246716495603323, 'vf_loss': 0.004737510586753597, 'total_loss': -0.044480130707149075, 'approx_kl': 0.015881715109571815, 'clip_fraction': 0.02734375, 'grad_norm': 0.46893519163131714}
2022-12-29 13:32:34.641 DEBUG: Taking gradient step
2022-12-29 13:32:34.650 DEBUG: Loss 5: {'policy_loss': -0.025685003187390153, 'entropy_loss': -0.02592081017792225, 'vf_loss': 0.0047341935096837815, 'total_loss': -0.0468716198556286, 'approx_kl': 0.011795319616794586, 'clip_fraction': 0.049479166977107525, 'grad_norm': 0.5632128119468689}
2022-12-29 13:32:35.363 DEBUG: Taking gradient step
2022-12-29 13:32:35.372 DEBUG: Loss 6: {'policy_loss': -0.024436068236450205, 'entropy_loss': -0.026298686396330595, 'vf_loss': 0.004729391821252689, 'total_loss': -0.04600536281152811, 'approx_kl': 0.009565886575728655, 'clip_fraction': 0.08072916697710752, 'grad_norm': 0.6018651127815247}
2022-12-29 13:32:36.072 DEBUG: Taking gradient step
2022-12-29 13:32:36.082 DEBUG: Loss 7: {'policy_loss': -0.02757192602233356, 'entropy_loss': -0.025774673093110323, 'vf_loss': 0.004727075423526792, 'total_loss': -0.0486195236919171, 'approx_kl': 0.02047330350615084, 'clip_fraction': 0.13020833395421505, 'grad_norm': 0.7230648398399353}
2022-12-29 13:32:36.773 DEBUG: Taking gradient step
2022-12-29 13:32:36.782 DEBUG: Loss 8: {'policy_loss': -0.023236800874799773, 'entropy_loss': -0.02636901242658496, 'vf_loss': 0.00472242609731699, 'total_loss': -0.044883387204067746, 'approx_kl': 0.008555817417800426, 'clip_fraction': 0.1328125, 'grad_norm': 9.319125175476074}
2022-12-29 13:32:37.506 DEBUG: Taking gradient step
2022-12-29 13:32:37.516 DEBUG: Loss 9: {'policy_loss': -0.02109821268728025, 'entropy_loss': -0.026812830939888954, 'vf_loss': 0.0047191168024908, 'total_loss': -0.04319192682467841, 'approx_kl': 0.023170150816440582, 'clip_fraction': 0.1783854179084301, 'grad_norm': 10.477992057800293}
2022-12-29 13:32:37.516 INFO: Optimization: policy loss=-0.021, vf loss=0.005, entropy loss=-0.027, total loss=-0.043, num steps=10
2022-12-29 13:32:37.517 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 13:32:38.254 INFO: Evaluation rollout: return=0.513 (0.0), episode length=3.0
2022-12-29 13:32:38.254 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 13:32:38.256 INFO: Iteration: 134/137, steps: 28944
2022-12-29 13:33:25.860 DEBUG: Atoms are too close
2022-12-29 13:33:27.468 INFO: Training rollout: return=0.195 (2.4), episode length=3.0
2022-12-29 13:33:27.469 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 13:33:27.472 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-28944_train.pkl
2022-12-29 13:33:28.194 DEBUG: Taking gradient step
2022-12-29 13:33:28.204 DEBUG: Loss 0: {'policy_loss': 0.03777721972949488, 'entropy_loss': -0.026111526880413294, 'vf_loss': 0.0073731671315366305, 'total_loss': 0.019038859980618217, 'approx_kl': -3.298434192444688e-09, 'clip_fraction': 0.0, 'grad_norm': 8.959431648254395}
2022-12-29 13:33:28.923 DEBUG: Taking gradient step
2022-12-29 13:33:28.933 DEBUG: Loss 1: {'policy_loss': -0.025674809590864826, 'entropy_loss': -0.026691400445997715, 'vf_loss': 0.004761738452520622, 'total_loss': -0.04760447158434192, 'approx_kl': -0.0023387580877169967, 'clip_fraction': 0.0078125, 'grad_norm': 2.2951300144195557}
2022-12-29 13:33:29.623 DEBUG: Taking gradient step
2022-12-29 13:33:29.632 DEBUG: Loss 2: {'policy_loss': -0.02837317534767998, 'entropy_loss': -0.026226960588246584, 'vf_loss': 0.004765496437495078, 'total_loss': -0.04983463949843149, 'approx_kl': -0.005252490402199328, 'clip_fraction': 0.03515625, 'grad_norm': 2.2208306789398193}
2022-12-29 13:33:30.347 DEBUG: Taking gradient step
2022-12-29 13:33:30.357 DEBUG: Loss 3: {'policy_loss': -0.029580380739795624, 'entropy_loss': -0.025982344523072243, 'vf_loss': 0.004765968781239639, 'total_loss': -0.05079675648162823, 'approx_kl': -0.0060867127031087875, 'clip_fraction': 0.07552083395421505, 'grad_norm': 2.1121342182159424}
2022-12-29 13:33:31.097 DEBUG: Taking gradient step
2022-12-29 13:33:31.106 DEBUG: Loss 4: {'policy_loss': -0.03207082424967683, 'entropy_loss': -0.027149359695613384, 'vf_loss': 0.004766711723474815, 'total_loss': -0.0544534722218154, 'approx_kl': 0.00012414006050676107, 'clip_fraction': 0.15755208395421505, 'grad_norm': 1.6850792169570923}
2022-12-29 13:33:31.804 DEBUG: Taking gradient step
2022-12-29 13:33:31.815 DEBUG: Loss 5: {'policy_loss': 0.01358384516574191, 'entropy_loss': -0.026606798637658358, 'vf_loss': 0.007388991632018102, 'total_loss': -0.005633961839898338, 'approx_kl': 0.003753871191293001, 'clip_fraction': 0.2265625, 'grad_norm': 0.9300241470336914}
2022-12-29 13:33:32.513 DEBUG: Taking gradient step
2022-12-29 13:33:32.526 DEBUG: Loss 6: {'policy_loss': 0.016192872505268893, 'entropy_loss': -0.026049474254250526, 'vf_loss': 0.007382885162307977, 'total_loss': -0.002473716586673655, 'approx_kl': 0.013918466866016388, 'clip_fraction': 0.3229166716337204, 'grad_norm': 0.927338182926178}
2022-12-29 13:33:33.251 DEBUG: Taking gradient step
2022-12-29 13:33:33.261 DEBUG: Loss 7: {'policy_loss': -0.02986967313804904, 'entropy_loss': -0.027118948753923178, 'vf_loss': 0.004762948936712085, 'total_loss': -0.05222567295526012, 'approx_kl': 0.0030461070127785206, 'clip_fraction': 0.2825520858168602, 'grad_norm': 0.894719123840332}
2022-12-29 13:33:33.949 DEBUG: Taking gradient step
2022-12-29 13:33:33.958 DEBUG: Loss 8: {'policy_loss': 0.014592169599057975, 'entropy_loss': -0.02632133150473237, 'vf_loss': 0.007365849140964695, 'total_loss': -0.0043633127647096925, 'approx_kl': -0.001340228132903576, 'clip_fraction': 0.32421875, 'grad_norm': 0.48237890005111694}
2022-12-29 13:33:34.664 DEBUG: Taking gradient step
2022-12-29 13:33:34.674 DEBUG: Loss 9: {'policy_loss': -0.029736333214030727, 'entropy_loss': -0.026543006766587496, 'vf_loss': 0.00475784145268219, 'total_loss': -0.051521498527936034, 'approx_kl': 0.007804563676472753, 'clip_fraction': 0.23828125, 'grad_norm': 0.6189879775047302}
2022-12-29 13:33:34.674 INFO: Optimization: policy loss=-0.030, vf loss=0.005, entropy loss=-0.027, total loss=-0.052, num steps=10
2022-12-29 13:33:34.675 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 13:33:35.357 INFO: Evaluation rollout: return=0.512 (0.0), episode length=3.0
2022-12-29 13:33:35.358 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 13:33:35.359 INFO: Iteration: 135/137, steps: 29160
2022-12-29 13:34:25.279 INFO: Training rollout: return=0.473 (0.0), episode length=3.0
2022-12-29 13:34:25.281 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 13:34:25.284 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-29160_train.pkl
2022-12-29 13:34:25.997 DEBUG: Taking gradient step
2022-12-29 13:34:26.007 DEBUG: Loss 0: {'policy_loss': -0.04962577011260137, 'entropy_loss': -0.026516965124756098, 'vf_loss': 0.00010330431556872973, 'total_loss': -0.07603943092178873, 'approx_kl': 2.087714801035645e-08, 'clip_fraction': 0.0, 'grad_norm': 9.142395973205566}
2022-12-29 13:34:26.719 DEBUG: Taking gradient step
2022-12-29 13:34:26.728 DEBUG: Loss 1: {'policy_loss': -0.03862616819897896, 'entropy_loss': -0.026522407308220863, 'vf_loss': 0.00010649078850584343, 'total_loss': -0.06504208471869398, 'approx_kl': 0.004347241600044072, 'clip_fraction': 0.0078125, 'grad_norm': 6.023612022399902}
2022-12-29 13:34:27.495 DEBUG: Taking gradient step
2022-12-29 13:34:27.504 DEBUG: Loss 2: {'policy_loss': -0.0315814305692204, 'entropy_loss': -0.026102714240550995, 'vf_loss': 0.00011018368796805684, 'total_loss': -0.05757396112180334, 'approx_kl': 0.012007827521301806, 'clip_fraction': 0.09895833395421505, 'grad_norm': 3.589311361312866}
2022-12-29 13:34:28.193 DEBUG: Taking gradient step
2022-12-29 13:34:28.202 DEBUG: Loss 3: {'policy_loss': -0.011367365859813303, 'entropy_loss': -0.026622815988957882, 'vf_loss': 0.00011078652664452776, 'total_loss': -0.03787939532212666, 'approx_kl': 0.028841378167271614, 'clip_fraction': 0.1393229179084301, 'grad_norm': 8.777750015258789}
2022-12-29 13:34:28.898 DEBUG: Early stopping at step 4 for reaching max KL.
2022-12-29 13:34:28.898 INFO: Optimization: policy loss=-0.011, vf loss=0.000, entropy loss=-0.027, total loss=-0.038, num steps=4
2022-12-29 13:34:28.898 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 13:34:29.632 INFO: Evaluation rollout: return=0.513 (0.0), episode length=3.0
2022-12-29 13:34:29.633 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 13:34:29.634 INFO: Iteration: 136/137, steps: 29376
2022-12-29 13:34:35.987 DEBUG: Atoms are too close
2022-12-29 13:34:45.249 DEBUG: Atoms are too close
2022-12-29 13:35:18.958 INFO: Training rollout: return=-0.088 (3.3), episode length=3.0
2022-12-29 13:35:18.960 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 13:35:18.962 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-29376_train.pkl
2022-12-29 13:35:19.687 DEBUG: Taking gradient step
2022-12-29 13:35:19.696 DEBUG: Loss 0: {'policy_loss': -0.026432355378038737, 'entropy_loss': -0.026580745354294777, 'vf_loss': 0.009390840086589502, 'total_loss': -0.043622260645744024, 'approx_kl': 3.659321734517107e-08, 'clip_fraction': 0.0, 'grad_norm': 12.112945556640625}
2022-12-29 13:35:20.420 DEBUG: Taking gradient step
2022-12-29 13:35:20.429 DEBUG: Loss 1: {'policy_loss': 0.018002418990879423, 'entropy_loss': -0.025949285365641117, 'vf_loss': 0.011974598032008565, 'total_loss': 0.004027731657246875, 'approx_kl': -0.0017685561906546354, 'clip_fraction': 0.01171875, 'grad_norm': 24.722930908203125}
2022-12-29 13:35:21.158 DEBUG: Taking gradient step
2022-12-29 13:35:21.170 DEBUG: Loss 2: {'policy_loss': 0.04185241026720082, 'entropy_loss': -0.02585681900382042, 'vf_loss': 0.014567748170963998, 'total_loss': 0.03056333943434439, 'approx_kl': 0.002457882510498166, 'clip_fraction': 0.04296875, 'grad_norm': 17.41786003112793}
2022-12-29 13:35:21.864 DEBUG: Taking gradient step
2022-12-29 13:35:21.874 DEBUG: Loss 3: {'policy_loss': -0.0339334145219332, 'entropy_loss': -0.02622024016454816, 'vf_loss': 0.009393641006816555, 'total_loss': -0.0507600136796648, 'approx_kl': 0.019991596578620374, 'clip_fraction': 0.09765625, 'grad_norm': 4.8466339111328125}
2022-12-29 13:35:22.564 DEBUG: Taking gradient step
2022-12-29 13:35:22.574 DEBUG: Loss 4: {'policy_loss': 0.006024367355299071, 'entropy_loss': -0.026680845767259598, 'vf_loss': 0.011977244634896772, 'total_loss': -0.008679233777063755, 'approx_kl': 0.034884842578321695, 'clip_fraction': 0.1380208358168602, 'grad_norm': 4.5684027671813965}
2022-12-29 13:35:23.301 DEBUG: Taking gradient step
2022-12-29 13:35:23.311 DEBUG: Loss 5: {'policy_loss': 0.032225337551421984, 'entropy_loss': -0.026623050682246685, 'vf_loss': 0.01450819521377698, 'total_loss': 0.020110482082952276, 'approx_kl': 0.039476143661886454, 'clip_fraction': 0.14192708395421505, 'grad_norm': 6.565959930419922}
2022-12-29 13:35:24.022 DEBUG: Taking gradient step
2022-12-29 13:35:24.031 DEBUG: Loss 6: {'policy_loss': -0.04174423631753735, 'entropy_loss': -0.025018831249326468, 'vf_loss': 0.009398064655537379, 'total_loss': -0.057365002911326436, 'approx_kl': 0.034671392291784286, 'clip_fraction': 0.17447916697710752, 'grad_norm': 2.5649399757385254}
2022-12-29 13:35:24.730 DEBUG: Taking gradient step
2022-12-29 13:35:24.739 DEBUG: Loss 7: {'policy_loss': -0.008734589223957551, 'entropy_loss': -0.02636193484067917, 'vf_loss': 0.011965652318881274, 'total_loss': -0.023130871745755448, 'approx_kl': 0.039474843768402934, 'clip_fraction': 0.2630208358168602, 'grad_norm': 1.4902154207229614}
2022-12-29 13:35:25.428 DEBUG: Taking gradient step
2022-12-29 13:35:25.437 DEBUG: Loss 8: {'policy_loss': -0.04151769818080209, 'entropy_loss': -0.026090888306498528, 'vf_loss': 0.009389687693127037, 'total_loss': -0.05821889879417358, 'approx_kl': 0.03250113711692393, 'clip_fraction': 0.2578125, 'grad_norm': 1.3447628021240234}
2022-12-29 13:35:26.144 DEBUG: Taking gradient step
2022-12-29 13:35:26.153 DEBUG: Loss 9: {'policy_loss': -0.04226701964326306, 'entropy_loss': -0.025703422259539366, 'vf_loss': 0.00938665130271713, 'total_loss': -0.05858379060008529, 'approx_kl': 0.021803927142173052, 'clip_fraction': 0.25390625, 'grad_norm': 1.3182929754257202}
2022-12-29 13:35:26.153 INFO: Optimization: policy loss=-0.042, vf loss=0.009, entropy loss=-0.026, total loss=-0.059, num steps=10
2022-12-29 13:35:26.154 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 13:35:26.909 INFO: Evaluation rollout: return=0.513 (0.0), episode length=3.0
2022-12-29 13:35:26.911 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 13:35:26.913 INFO: Iteration: 137/137, steps: 29592
2022-12-29 13:35:49.034 DEBUG: Atoms are too close
2022-12-29 13:36:04.574 DEBUG: Atoms are too close
2022-12-29 13:36:16.401 INFO: Training rollout: return=-0.095 (3.3), episode length=3.0
2022-12-29 13:36:16.403 DEBUG: Saving info: runs/H2O/results/H2O_run-1_train.txt
2022-12-29 13:36:16.405 DEBUG: Saving rollout: runs/H2O/data/H2O_run-1_steps-29592_train.pkl
2022-12-29 13:36:17.127 DEBUG: Taking gradient step
2022-12-29 13:36:17.137 DEBUG: Loss 0: {'policy_loss': 0.019536668965060677, 'entropy_loss': -0.02636750042438507, 'vf_loss': 0.010503220646413663, 'total_loss': 0.0036723891870892728, 'approx_kl': 1.3232541618002358e-08, 'clip_fraction': 0.0, 'grad_norm': 7.915643692016602}
2022-12-29 13:36:17.828 DEBUG: Taking gradient step
2022-12-29 13:36:17.838 DEBUG: Loss 1: {'policy_loss': 0.019051865992494865, 'entropy_loss': -0.026451905257999897, 'vf_loss': 0.010565023367117883, 'total_loss': 0.0031649841016128458, 'approx_kl': 0.0017581625143066049, 'clip_fraction': 0.026041666977107525, 'grad_norm': 7.493860244750977}
2022-12-29 13:36:18.530 DEBUG: Taking gradient step
2022-12-29 13:36:18.540 DEBUG: Loss 2: {'policy_loss': 0.053009848227513645, 'entropy_loss': -0.02552490448579192, 'vf_loss': 0.013136439459792797, 'total_loss': 0.04062138320151451, 'approx_kl': 0.007835006806999445, 'clip_fraction': 0.057291666977107525, 'grad_norm': 7.204895496368408}
2022-12-29 13:36:19.239 DEBUG: Taking gradient step
2022-12-29 13:36:19.249 DEBUG: Loss 3: {'policy_loss': 0.004586179752128525, 'entropy_loss': -0.02594728861004114, 'vf_loss': 0.01047652317716349, 'total_loss': -0.010884585680749126, 'approx_kl': 0.02983078104443848, 'clip_fraction': 0.1315104179084301, 'grad_norm': 5.0848069190979}
2022-12-29 13:36:19.973 DEBUG: Taking gradient step
2022-12-29 13:36:19.982 DEBUG: Loss 4: {'policy_loss': -0.036409467050977605, 'entropy_loss': -0.025259990710765123, 'vf_loss': 0.007924555974843948, 'total_loss': -0.05374490178689877, 'approx_kl': 0.023736247094348073, 'clip_fraction': 0.2135416716337204, 'grad_norm': 4.581297397613525}
2022-12-29 13:36:20.687 DEBUG: Taking gradient step
2022-12-29 13:36:20.697 DEBUG: Loss 5: {'policy_loss': -0.037958243667618144, 'entropy_loss': -0.026237376034259796, 'vf_loss': 0.007920598328861429, 'total_loss': -0.056275021373016515, 'approx_kl': 0.022599388379603624, 'clip_fraction': 0.2669270858168602, 'grad_norm': 1.850856900215149}
2022-12-29 13:36:21.428 DEBUG: Taking gradient step
2022-12-29 13:36:21.437 DEBUG: Loss 6: {'policy_loss': 0.00810979837155338, 'entropy_loss': -0.026870621368288994, 'vf_loss': 0.010563125209554235, 'total_loss': -0.008197697787181386, 'approx_kl': 0.02308381616603583, 'clip_fraction': 0.3424479216337204, 'grad_norm': 1.9120879173278809}
2022-12-29 13:36:22.139 DEBUG: Taking gradient step
2022-12-29 13:36:22.149 DEBUG: Loss 7: {'policy_loss': -0.03527772580514213, 'entropy_loss': -0.026883736718446016, 'vf_loss': 0.007916160677884747, 'total_loss': -0.05424530184570339, 'approx_kl': 0.0273507758975029, 'clip_fraction': 0.41015625, 'grad_norm': 2.122951030731201}
2022-12-29 13:36:22.897 DEBUG: Taking gradient step
2022-12-29 13:36:22.910 DEBUG: Loss 8: {'policy_loss': -0.0024845341527937014, 'entropy_loss': -0.026275387965142727, 'vf_loss': 0.010471713268681637, 'total_loss': -0.01828820884925479, 'approx_kl': 0.020694734528660774, 'clip_fraction': 0.40234375, 'grad_norm': 2.019763469696045}
2022-12-29 13:36:23.653 DEBUG: Taking gradient step
2022-12-29 13:36:23.662 DEBUG: Loss 9: {'policy_loss': 0.006479797086009438, 'entropy_loss': -0.027425622567534447, 'vf_loss': 0.010497645225840688, 'total_loss': -0.010448180255684319, 'approx_kl': 0.005956718465313315, 'clip_fraction': 0.3736979216337204, 'grad_norm': 1.9999144077301025}
2022-12-29 13:36:23.662 INFO: Optimization: policy loss=0.006, vf loss=0.010, entropy loss=-0.027, total loss=-0.010, num steps=10
2022-12-29 13:36:23.663 DEBUG: Saving info: runs/H2O/results/H2O_run-1_opt.txt
2022-12-29 13:36:24.363 INFO: Evaluation rollout: return=0.510 (0.0), episode length=3.0
2022-12-29 13:36:24.364 DEBUG: Saving info: runs/H2O/results/H2O_run-1_eval.txt
2022-12-29 13:36:24.365 DEBUG: Deleting old model: runs/H2O/models/H2O_run-1_steps-28296.model
2022-12-29 13:36:24.367 DEBUG: Saving model: runs/H2O/models/H2O_run-1_steps-29808.model
2022-12-29 13:36:24.397 INFO: Finished PPO
