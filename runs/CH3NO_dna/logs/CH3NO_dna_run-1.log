2023-01-03 11:40:39.046 INFO: {
    "bag_scale": 6,
    "beta": "-10",
    "canvas_size": 6,
    "clip_ratio": 0.2,
    "cutoff": 4.0,
    "data_dir": "runs/CH3NO_dna/data",
    "device": "cuda",
    "discount": 1.0,
    "entropy_coef": 0.06,
    "eval_formulas": "CH3NO",
    "eval_freq": 1,
    "formulas": "CH3NO",
    "gradient_clip": 0.5,
    "keep_models": false,
    "lam": 0.95,
    "learning_rate": 0.001,
    "load_latest": false,
    "load_model": null,
    "log_dir": "runs/CH3NO_dna/logs",
    "log_level": "DEBUG",
    "max_mean_distance": 1.8,
    "max_num_steps": 30000,
    "max_num_train_iters": 15,
    "max_solo_distance": 2.0,
    "maxl": 4,
    "min_atomic_distance": 0.6,
    "min_mean_distance": 0.8,
    "min_reward": -30.0,
    "mini_batch_size": 64,
    "model": "schnet_edge",
    "model_dir": "runs/CH3NO_dna/models",
    "name": "CH3NO_dna",
    "network_width": 128,
    "num_cg_levels": 3,
    "num_channels_hidden": 10,
    "num_channels_per_element": 4,
    "num_envs": 12,
    "num_eval_episodes": null,
    "num_gaussians": 3,
    "num_interactions": 3,
    "num_steps_per_iter": 216,
    "optimizer": "adam",
    "results_dir": "runs/CH3NO_dna/results",
    "save_freq": 10,
    "save_rollouts": "train",
    "seed": 1,
    "symbols": "X,H,C,N,O",
    "target_kl": 0.03,
    "update_edges": true,
    "vf_coef": 0.001
}
2023-01-03 11:40:39.090 INFO: CUDA Device: 0
2023-01-03 11:40:39.091 INFO: Training bags: ['CH3NO']
2023-01-03 11:40:39.092 INFO: Evaluation bags: ['CH3NO']
2023-01-03 11:40:41.031 INFO: Number of parameters: 549407
2023-01-03 11:40:41.046 INFO: Starting PPO
2023-01-03 11:40:41.046 INFO: Iteration: 0/137, steps: 0
2023-01-03 11:40:45.914 DEBUG: There is a single atom floating around
2023-01-03 11:40:47.113 DEBUG: There is a single atom floating around
2023-01-03 11:40:48.253 DEBUG: There is a single atom floating around
2023-01-03 11:40:50.949 DEBUG: Atoms are too close
2023-01-03 11:40:52.733 DEBUG: Atoms are too close
2023-01-03 11:40:53.324 DEBUG: Atoms are too close
2023-01-03 11:40:53.324 DEBUG: Atoms are too close
2023-01-03 11:40:56.003 DEBUG: Atoms are too close
2023-01-03 11:40:56.662 DEBUG: Atoms are too close
2023-01-03 11:40:57.082 DEBUG: There is a single atom floating around
2023-01-03 11:41:01.164 DEBUG: Atoms are too close
2023-01-03 11:41:04.791 DEBUG: There is a single atom floating around
2023-01-03 11:41:07.059 DEBUG: Atoms are too close
2023-01-03 11:41:07.383 DEBUG: Atoms are too close
2023-01-03 11:41:08.152 DEBUG: Atoms are too close
2023-01-03 11:41:08.905 DEBUG: Atoms are too close
2023-01-03 11:41:09.214 DEBUG: Atoms are too close
2023-01-03 11:41:09.365 DEBUG: Atoms are too close
2023-01-03 11:41:10.741 DEBUG: Atoms are too close
2023-01-03 11:41:14.255 DEBUG: Atoms are too close
2023-01-03 11:41:14.573 DEBUG: There is a single atom floating around
2023-01-03 11:41:18.497 DEBUG: Atoms are too close
2023-01-03 11:41:18.805 DEBUG: Atoms are too close
2023-01-03 11:41:18.806 DEBUG: Atoms are too close
2023-01-03 11:41:18.807 DEBUG: Atoms are too close
2023-01-03 11:41:20.165 DEBUG: There is a single atom floating around
2023-01-03 11:41:22.717 DEBUG: Atoms are too close
2023-01-03 11:41:22.855 DEBUG: Atoms are too close
2023-01-03 11:41:25.075 DEBUG: Atoms are too close
2023-01-03 11:41:25.160 DEBUG: Atoms are too close
2023-01-03 11:41:26.096 DEBUG: There is a single atom floating around
2023-01-03 11:41:26.417 DEBUG: There is a single atom floating around
2023-01-03 11:41:29.563 DEBUG: Atoms are too close
2023-01-03 11:41:33.618 DEBUG: Atoms are too close
2023-01-03 11:41:33.711 INFO: Training rollout: return=-23.373 (12.3), episode length=4.3
2023-01-03 11:41:33.712 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 11:41:33.716 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-0_train.pkl
2023-01-03 11:41:35.809 DEBUG: Taking gradient step
2023-01-03 11:41:37.971 DEBUG: Loss 0: {'policy_loss': 0.03087944045625201, 'entropy_loss': -0.08380598947405815, 'vf_loss': 0.5700520262705544, 'total_loss': -0.052926549017806135, 'approx_kl': -7.062530116286325e-09, 'clip_fraction': 0.0, 'grad_norm': 14.560548782348633}
2023-01-03 11:41:40.035 DEBUG: Early stopping at step 1 for reaching max KL.
2023-01-03 11:41:40.035 INFO: Optimization: policy loss=0.031, vf loss=0.570, entropy loss=-0.084, total loss=-0.053, num steps=1
2023-01-03 11:41:40.036 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 11:41:40.925 DEBUG: Atoms are too close
2023-01-03 11:41:40.927 INFO: Evaluation rollout: return=-29.619 (0.0), episode length=4.0
2023-01-03 11:41:40.927 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 11:41:40.931 DEBUG: Saving model: runs/CH3NO_dna/models/CH3NO_dna_run-1_steps-216.model
2023-01-03 11:41:40.984 INFO: Iteration: 1/137, steps: 216
2023-01-03 11:41:44.042 DEBUG: There is a single atom floating around
2023-01-03 11:41:45.287 DEBUG: There is a single atom floating around
2023-01-03 11:41:51.005 DEBUG: Atoms are too close
2023-01-03 11:41:52.847 DEBUG: Atoms are too close
2023-01-03 11:41:55.930 DEBUG: Atoms are too close
2023-01-03 11:41:59.483 DEBUG: There is a single atom floating around
2023-01-03 11:42:09.951 DEBUG: Atoms are too close
2023-01-03 11:42:13.276 DEBUG: Atoms are too close
2023-01-03 11:42:14.599 DEBUG: Atoms are too close
2023-01-03 11:42:21.416 DEBUG: There is a single atom floating around
2023-01-03 11:42:22.852 DEBUG: There is a single atom floating around
2023-01-03 11:42:23.205 DEBUG: Atoms are too close
2023-01-03 11:42:24.462 DEBUG: Atoms are too close
2023-01-03 11:42:26.695 DEBUG: Atoms are too close
2023-01-03 11:42:29.477 DEBUG: Atoms are too close
2023-01-03 11:42:31.841 DEBUG: Atoms are too close
2023-01-03 11:42:33.953 DEBUG: Atoms are too close
2023-01-03 11:42:35.116 DEBUG: Atoms are too close
2023-01-03 11:42:35.736 DEBUG: Atoms are too close
2023-01-03 11:42:38.030 INFO: Training rollout: return=-14.358 (15.0), episode length=5.1
2023-01-03 11:42:38.031 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 11:42:38.034 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-216_train.pkl
2023-01-03 11:42:40.270 DEBUG: Taking gradient step
2023-01-03 11:42:42.586 DEBUG: Loss 0: {'policy_loss': -0.04118736817092032, 'entropy_loss': -0.08660359494388103, 'vf_loss': 0.31634519877683115, 'total_loss': -0.12779096311480137, 'approx_kl': -1.9363748826606297e-08, 'clip_fraction': 0.0, 'grad_norm': 13.235513687133789}
2023-01-03 11:42:44.859 DEBUG: Early stopping at step 1 for reaching max KL.
2023-01-03 11:42:44.860 INFO: Optimization: policy loss=-0.041, vf loss=0.316, entropy loss=-0.087, total loss=-0.128, num steps=1
2023-01-03 11:42:44.861 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 11:42:45.742 DEBUG: Atoms are too close
2023-01-03 11:42:45.744 INFO: Evaluation rollout: return=-29.646 (0.0), episode length=4.0
2023-01-03 11:42:45.745 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 11:42:45.747 INFO: Iteration: 2/137, steps: 432
2023-01-03 11:42:48.883 DEBUG: There is a single atom floating around
2023-01-03 11:42:59.365 DEBUG: Atoms are too close
2023-01-03 11:42:59.367 DEBUG: Atoms are too close
2023-01-03 11:42:59.702 DEBUG: Atoms are too close
2023-01-03 11:43:00.066 DEBUG: Atoms are too close
2023-01-03 11:43:01.741 DEBUG: Atoms are too close
2023-01-03 11:43:03.434 DEBUG: Atoms are too close
2023-01-03 11:43:11.005 DEBUG: There is a single atom floating around
2023-01-03 11:43:12.116 DEBUG: Atoms are too close
2023-01-03 11:43:18.843 DEBUG: Atoms are too close
2023-01-03 11:43:19.154 DEBUG: Atoms are too close
2023-01-03 11:43:19.450 DEBUG: Atoms are too close
2023-01-03 11:43:20.064 DEBUG: Atoms are too close
2023-01-03 11:43:23.706 DEBUG: Atoms are too close
2023-01-03 11:43:26.418 DEBUG: Atoms are too close
2023-01-03 11:43:26.979 DEBUG: There is a single atom floating around
2023-01-03 11:43:26.980 DEBUG: Atoms are too close
2023-01-03 11:43:30.382 DEBUG: Atoms are too close
2023-01-03 11:43:30.543 DEBUG: Atoms are too close
2023-01-03 11:43:34.729 DEBUG: Atoms are too close
2023-01-03 11:43:38.907 DEBUG: Atoms are too close
2023-01-03 11:43:39.314 DEBUG: Atoms are too close
2023-01-03 11:43:40.797 DEBUG: Atoms are too close
2023-01-03 11:43:41.257 DEBUG: Atoms are too close
2023-01-03 11:43:41.421 DEBUG: Atoms are too close
2023-01-03 11:43:41.501 INFO: Training rollout: return=-19.919 (13.9), episode length=5.2
2023-01-03 11:43:41.502 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 11:43:41.505 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-432_train.pkl
2023-01-03 11:43:43.765 DEBUG: Taking gradient step
2023-01-03 11:43:46.044 DEBUG: Loss 0: {'policy_loss': 0.005388065786295786, 'entropy_loss': -0.08444749377667904, 'vf_loss': 0.48869335613131537, 'total_loss': -0.07905942799038326, 'approx_kl': 5.277494707911501e-08, 'clip_fraction': 0.0, 'grad_norm': 14.245491027832031}
2023-01-03 11:43:48.294 DEBUG: Taking gradient step
2023-01-03 11:43:50.569 DEBUG: Loss 1: {'policy_loss': -0.011832351069483271, 'entropy_loss': -0.08434303663671017, 'vf_loss': 0.4563695169054575, 'total_loss': -0.09617538770619344, 'approx_kl': -0.004137469572015107, 'clip_fraction': 0.1861979179084301, 'grad_norm': 15.4155855178833}
2023-01-03 11:43:52.839 DEBUG: Taking gradient step
2023-01-03 11:43:55.094 DEBUG: Loss 2: {'policy_loss': 0.020420767266730096, 'entropy_loss': -0.08456657640635967, 'vf_loss': 0.4344614311946505, 'total_loss': -0.06414580913962958, 'approx_kl': -0.02352067641913891, 'clip_fraction': 0.4479166716337204, 'grad_norm': 14.67185115814209}
2023-01-03 11:43:57.407 DEBUG: Taking gradient step
2023-01-03 11:43:59.667 DEBUG: Loss 3: {'policy_loss': 0.08804620393779469, 'entropy_loss': -0.08301345817744732, 'vf_loss': 0.4192979227167484, 'total_loss': 0.0050327457603473735, 'approx_kl': -0.06614008452743292, 'clip_fraction': 0.4791666716337204, 'grad_norm': 21.129140853881836}
2023-01-03 11:44:01.876 DEBUG: Taking gradient step
2023-01-03 11:44:04.212 DEBUG: Loss 4: {'policy_loss': 0.12787876384044325, 'entropy_loss': -0.08101209253072739, 'vf_loss': 0.40616506435315036, 'total_loss': 0.04686667130971586, 'approx_kl': -0.054081620648503304, 'clip_fraction': 0.5052083358168602, 'grad_norm': 17.161762237548828}
2023-01-03 11:44:06.442 DEBUG: Taking gradient step
2023-01-03 11:44:08.728 DEBUG: Loss 5: {'policy_loss': 0.036529854603422666, 'entropy_loss': -0.08211450651288033, 'vf_loss': 0.362573847373258, 'total_loss': -0.045584651909457645, 'approx_kl': -0.057233902625739574, 'clip_fraction': 0.5104166716337204, 'grad_norm': 13.510445594787598}
2023-01-03 11:44:10.983 DEBUG: Taking gradient step
2023-01-03 11:44:13.326 DEBUG: Loss 6: {'policy_loss': 0.06267160628335454, 'entropy_loss': -0.08248535171151161, 'vf_loss': 0.33724623507501494, 'total_loss': -0.01981374542815707, 'approx_kl': -0.044643537141382694, 'clip_fraction': 0.5104166716337204, 'grad_norm': 14.274759292602539}
2023-01-03 11:44:15.570 DEBUG: Taking gradient step
2023-01-03 11:44:17.986 DEBUG: Loss 7: {'policy_loss': 0.04979710788379774, 'entropy_loss': -0.08268853649497032, 'vf_loss': 0.32956433181360006, 'total_loss': -0.03289142861117259, 'approx_kl': -0.05616768077015877, 'clip_fraction': 0.515625, 'grad_norm': 20.19478416442871}
2023-01-03 11:44:20.295 DEBUG: Taking gradient step
2023-01-03 11:44:22.551 DEBUG: Loss 8: {'policy_loss': 0.08164798988294686, 'entropy_loss': -0.08303188718855381, 'vf_loss': 0.323563240825394, 'total_loss': -0.001383897305606948, 'approx_kl': -0.050996156176552176, 'clip_fraction': 0.4908854216337204, 'grad_norm': 21.64784049987793}
2023-01-03 11:44:24.926 DEBUG: Taking gradient step
2023-01-03 11:44:27.207 DEBUG: Loss 9: {'policy_loss': 0.06402664258186935, 'entropy_loss': -0.08260061219334602, 'vf_loss': 0.3301389357767862, 'total_loss': -0.018573969611476674, 'approx_kl': -0.06148040061816573, 'clip_fraction': 0.515625, 'grad_norm': 17.51594352722168}
2023-01-03 11:44:29.370 DEBUG: Taking gradient step
2023-01-03 11:44:31.615 DEBUG: Loss 10: {'policy_loss': 0.04879113729954204, 'entropy_loss': -0.0822877436876297, 'vf_loss': 0.31080830641807083, 'total_loss': -0.033496606388087664, 'approx_kl': -0.07295239064842463, 'clip_fraction': 0.4674479216337204, 'grad_norm': 12.005223274230957}
2023-01-03 11:44:33.821 DEBUG: Taking gradient step
2023-01-03 11:44:36.068 DEBUG: Loss 11: {'policy_loss': 0.019040670003984038, 'entropy_loss': -0.08370777033269405, 'vf_loss': 0.3099762357250546, 'total_loss': -0.06466710032871002, 'approx_kl': -0.08792422339320183, 'clip_fraction': 0.5260416716337204, 'grad_norm': 15.268108367919922}
2023-01-03 11:44:38.386 DEBUG: Taking gradient step
2023-01-03 11:44:40.641 DEBUG: Loss 12: {'policy_loss': 0.12770034251388906, 'entropy_loss': -0.08337359130382538, 'vf_loss': 0.3023499296892888, 'total_loss': 0.044326751210063686, 'approx_kl': -0.08147341758012772, 'clip_fraction': 0.578125, 'grad_norm': 20.911441802978516}
2023-01-03 11:44:42.949 DEBUG: Taking gradient step
2023-01-03 11:44:45.238 DEBUG: Loss 13: {'policy_loss': 0.10529902888096854, 'entropy_loss': -0.08542625419795513, 'vf_loss': 0.2872483298147147, 'total_loss': 0.019872774683013412, 'approx_kl': -0.11061838641762733, 'clip_fraction': 0.5859375, 'grad_norm': 27.511756896972656}
2023-01-03 11:44:47.483 DEBUG: Taking gradient step
2023-01-03 11:44:49.787 DEBUG: Loss 14: {'policy_loss': 0.07185106293700386, 'entropy_loss': -0.08338348940014839, 'vf_loss': 0.2903003107273675, 'total_loss': -0.011532426463144542, 'approx_kl': -0.11088120937347412, 'clip_fraction': 0.6106770932674408, 'grad_norm': 12.87420654296875}
2023-01-03 11:44:49.788 INFO: Optimization: policy loss=0.072, vf loss=0.290, entropy loss=-0.083, total loss=-0.012, num steps=15
2023-01-03 11:44:49.790 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 11:44:50.967 DEBUG: Atoms are too close
2023-01-03 11:44:50.969 INFO: Evaluation rollout: return=-29.835 (0.0), episode length=5.0
2023-01-03 11:44:50.970 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 11:44:50.976 INFO: Iteration: 3/137, steps: 648
2023-01-03 11:44:53.591 DEBUG: There is a single atom floating around
2023-01-03 11:44:54.578 DEBUG: There is a single atom floating around
2023-01-03 11:44:55.202 DEBUG: There is a single atom floating around
2023-01-03 11:44:58.618 DEBUG: There is a single atom floating around
2023-01-03 11:45:00.627 DEBUG: Atoms are too close
2023-01-03 11:45:00.933 DEBUG: Atoms are too close
2023-01-03 11:45:00.934 DEBUG: Atoms are too close
2023-01-03 11:45:02.154 DEBUG: Atoms are too close
2023-01-03 11:45:02.865 DEBUG: Atoms are too close
2023-01-03 11:45:06.927 DEBUG: There is a single atom floating around
2023-01-03 11:45:08.431 DEBUG: Atoms are too close
2023-01-03 11:45:10.381 DEBUG: Atoms are too close
2023-01-03 11:45:12.670 DEBUG: Atoms are too close
2023-01-03 11:45:12.962 DEBUG: Atoms are too close
2023-01-03 11:45:13.483 DEBUG: Atoms are too close
2023-01-03 11:45:16.722 DEBUG: Atoms are too close
2023-01-03 11:45:18.638 DEBUG: Atoms are too close
2023-01-03 11:45:18.955 DEBUG: Atoms are too close
2023-01-03 11:45:20.459 DEBUG: Atoms are too close
2023-01-03 11:45:22.924 DEBUG: Atoms are too close
2023-01-03 11:45:22.925 DEBUG: Atoms are too close
2023-01-03 11:45:23.725 DEBUG: Atoms are too close
2023-01-03 11:45:24.669 DEBUG: Atoms are too close
2023-01-03 11:45:27.523 DEBUG: There is a single atom floating around
2023-01-03 11:45:28.730 DEBUG: There is a single atom floating around
2023-01-03 11:45:30.385 DEBUG: Atoms are too close
2023-01-03 11:45:31.284 DEBUG: Atoms are too close
2023-01-03 11:45:35.437 DEBUG: Atoms are too close
2023-01-03 11:45:39.612 DEBUG: Atoms are too close
2023-01-03 11:45:44.452 INFO: Training rollout: return=-21.616 (13.2), episode length=4.7
2023-01-03 11:45:44.454 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 11:45:44.457 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-648_train.pkl
2023-01-03 11:45:46.717 DEBUG: Taking gradient step
2023-01-03 11:45:48.923 DEBUG: Loss 0: {'policy_loss': -0.05341512219835424, 'entropy_loss': -0.08140767179429531, 'vf_loss': 0.2916866994118576, 'total_loss': -0.13482279399264954, 'approx_kl': 2.04114862789595e-08, 'clip_fraction': 0.0, 'grad_norm': 11.161677360534668}
2023-01-03 11:45:51.056 DEBUG: Taking gradient step
2023-01-03 11:45:53.273 DEBUG: Loss 1: {'policy_loss': -0.023233546679538634, 'entropy_loss': -0.08005603030323982, 'vf_loss': 0.2770804532305401, 'total_loss': -0.10328957698277846, 'approx_kl': -0.027960325591266155, 'clip_fraction': 0.33984375, 'grad_norm': 23.5410099029541}
2023-01-03 11:45:55.509 DEBUG: Taking gradient step
2023-01-03 11:45:57.808 DEBUG: Loss 2: {'policy_loss': 0.021303035492987198, 'entropy_loss': -0.07892956584692001, 'vf_loss': 0.2600001611306251, 'total_loss': -0.057626530353932816, 'approx_kl': -0.0599697632715106, 'clip_fraction': 0.4049479216337204, 'grad_norm': 19.92413330078125}
2023-01-03 11:45:59.940 DEBUG: Taking gradient step
2023-01-03 11:46:02.090 DEBUG: Loss 3: {'policy_loss': 0.05544848639864252, 'entropy_loss': -0.0771673396229744, 'vf_loss': 0.22617340255197496, 'total_loss': -0.02171885322433188, 'approx_kl': -0.06487608980387449, 'clip_fraction': 0.4973958358168602, 'grad_norm': 11.542815208435059}
2023-01-03 11:46:04.233 DEBUG: Taking gradient step
2023-01-03 11:46:06.406 DEBUG: Loss 4: {'policy_loss': 0.035005796406914994, 'entropy_loss': -0.07558967545628548, 'vf_loss': 0.2339882249736696, 'total_loss': -0.04058387904937048, 'approx_kl': -0.0633251890540123, 'clip_fraction': 0.5299479216337204, 'grad_norm': 17.361949920654297}
2023-01-03 11:46:08.596 DEBUG: Taking gradient step
2023-01-03 11:46:10.825 DEBUG: Loss 5: {'policy_loss': -0.03880658653205864, 'entropy_loss': -0.07854919321835041, 'vf_loss': 0.22317670448223909, 'total_loss': -0.11735577975040905, 'approx_kl': -0.09089184366166592, 'clip_fraction': 0.52734375, 'grad_norm': 12.743143081665039}
2023-01-03 11:46:12.963 DEBUG: Taking gradient step
2023-01-03 11:46:15.330 DEBUG: Loss 6: {'policy_loss': 0.03305237067047999, 'entropy_loss': -0.07971377298235893, 'vf_loss': 0.21216359969813114, 'total_loss': -0.046661402311878944, 'approx_kl': -0.10327031649649143, 'clip_fraction': 0.5755208432674408, 'grad_norm': 17.622222900390625}
2023-01-03 11:46:17.493 DEBUG: Taking gradient step
2023-01-03 11:46:19.666 DEBUG: Loss 7: {'policy_loss': 0.052415994623592144, 'entropy_loss': -0.0805902574211359, 'vf_loss': 0.1926199447606915, 'total_loss': -0.028174262797543755, 'approx_kl': -0.09973738715052605, 'clip_fraction': 0.6315104216337204, 'grad_norm': 16.916751861572266}
2023-01-03 11:46:21.838 DEBUG: Taking gradient step
2023-01-03 11:46:24.039 DEBUG: Loss 8: {'policy_loss': 0.14331093413444093, 'entropy_loss': -0.08093578927218914, 'vf_loss': 0.17730694155961868, 'total_loss': 0.06237514486225179, 'approx_kl': -0.0901382090523839, 'clip_fraction': 0.5260416716337204, 'grad_norm': 13.448212623596191}
2023-01-03 11:46:26.266 DEBUG: Taking gradient step
2023-01-03 11:46:28.473 DEBUG: Loss 9: {'policy_loss': 0.09961281080176201, 'entropy_loss': -0.08009641245007515, 'vf_loss': 0.1867074580295933, 'total_loss': 0.019516398351686864, 'approx_kl': -0.024098461493849754, 'clip_fraction': 0.5364583432674408, 'grad_norm': 13.894579887390137}
2023-01-03 11:46:30.633 DEBUG: Taking gradient step
2023-01-03 11:46:32.822 DEBUG: Loss 10: {'policy_loss': 0.14299956562651475, 'entropy_loss': -0.07903031446039677, 'vf_loss': 0.1874843567740035, 'total_loss': 0.06396925116611799, 'approx_kl': -0.0707677099853754, 'clip_fraction': 0.5416666716337204, 'grad_norm': 15.607889175415039}
2023-01-03 11:46:34.913 DEBUG: Taking gradient step
2023-01-03 11:46:37.213 DEBUG: Loss 11: {'policy_loss': 0.10991022003089337, 'entropy_loss': -0.07899950630962849, 'vf_loss': 0.193435324628359, 'total_loss': 0.030910713721264894, 'approx_kl': -0.03868538746610284, 'clip_fraction': 0.5677083432674408, 'grad_norm': 16.320594787597656}
2023-01-03 11:46:39.388 DEBUG: Taking gradient step
2023-01-03 11:46:41.644 DEBUG: Loss 12: {'policy_loss': 0.1660239276083701, 'entropy_loss': -0.07832332514226437, 'vf_loss': 0.18772691434189628, 'total_loss': 0.08770060246610573, 'approx_kl': -0.04660568293184042, 'clip_fraction': 0.5598958432674408, 'grad_norm': 18.111251831054688}
2023-01-03 11:46:43.900 DEBUG: Taking gradient step
2023-01-03 11:46:46.065 DEBUG: Loss 13: {'policy_loss': 0.14596305207043364, 'entropy_loss': -0.07821810990571976, 'vf_loss': 0.1807378564708429, 'total_loss': 0.06774494216471388, 'approx_kl': -0.1235396871343255, 'clip_fraction': 0.5703125, 'grad_norm': 16.44112777709961}
2023-01-03 11:46:48.252 DEBUG: Taking gradient step
2023-01-03 11:46:50.426 DEBUG: Loss 14: {'policy_loss': 0.0726956381593617, 'entropy_loss': -0.07725614681839943, 'vf_loss': 0.17819142306802738, 'total_loss': -0.004560508659037732, 'approx_kl': -0.12088429182767868, 'clip_fraction': 0.5846354216337204, 'grad_norm': 16.831880569458008}
2023-01-03 11:46:50.427 INFO: Optimization: policy loss=0.073, vf loss=0.178, entropy loss=-0.077, total loss=-0.005, num steps=15
2023-01-03 11:46:50.429 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 11:46:51.357 DEBUG: Atoms are too close
2023-01-03 11:46:51.359 INFO: Evaluation rollout: return=-29.632 (0.0), episode length=4.0
2023-01-03 11:46:51.360 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 11:46:51.362 INFO: Iteration: 4/137, steps: 864
2023-01-03 11:47:02.464 DEBUG: Atoms are too close
2023-01-03 11:47:05.208 DEBUG: Atoms are too close
2023-01-03 11:47:05.312 DEBUG: Atoms are too close
2023-01-03 11:47:05.313 DEBUG: Atoms are too close
2023-01-03 11:47:06.965 DEBUG: Atoms are too close
2023-01-03 11:47:08.835 DEBUG: Atoms are too close
2023-01-03 11:47:08.836 DEBUG: Atoms are too close
2023-01-03 11:47:09.158 DEBUG: Atoms are too close
2023-01-03 11:47:09.943 DEBUG: Atoms are too close
2023-01-03 11:47:17.135 DEBUG: Atoms are too close
2023-01-03 11:47:19.886 DEBUG: Atoms are too close
2023-01-03 11:47:20.442 DEBUG: Atoms are too close
2023-01-03 11:47:21.083 DEBUG: There is a single atom floating around
2023-01-03 11:47:23.592 DEBUG: Atoms are too close
2023-01-03 11:47:23.593 DEBUG: Atoms are too close
2023-01-03 11:47:24.036 DEBUG: Atoms are too close
2023-01-03 11:47:26.742 DEBUG: Atoms are too close
2023-01-03 11:47:37.483 DEBUG: Atoms are too close
2023-01-03 11:47:38.844 DEBUG: Atoms are too close
2023-01-03 11:47:39.018 DEBUG: Atoms are too close
2023-01-03 11:47:39.019 DEBUG: Atoms are too close
2023-01-03 11:47:39.019 DEBUG: Atoms are too close
2023-01-03 11:47:40.410 DEBUG: Atoms are too close
2023-01-03 11:47:42.629 DEBUG: Atoms are too close
2023-01-03 11:47:46.763 INFO: Training rollout: return=-19.867 (14.1), episode length=5.4
2023-01-03 11:47:46.765 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 11:47:46.767 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-864_train.pkl
2023-01-03 11:47:49.215 DEBUG: Taking gradient step
2023-01-03 11:47:51.475 DEBUG: Loss 0: {'policy_loss': -0.05466443842264298, 'entropy_loss': -0.07897413149476051, 'vf_loss': 0.18786447547667465, 'total_loss': -0.1336385699174035, 'approx_kl': -2.308904001324663e-08, 'clip_fraction': 0.0, 'grad_norm': 17.572132110595703}
2023-01-03 11:47:53.672 DEBUG: Taking gradient step
2023-01-03 11:47:55.873 DEBUG: Loss 1: {'policy_loss': 0.039221867641362256, 'entropy_loss': -0.07931746169924736, 'vf_loss': 0.1875756252527527, 'total_loss': -0.040095594057885105, 'approx_kl': -0.008458478143438697, 'clip_fraction': 0.3177083358168602, 'grad_norm': 42.93340301513672}
2023-01-03 11:47:58.047 DEBUG: Taking gradient step
2023-01-03 11:48:00.313 DEBUG: Loss 2: {'policy_loss': 0.04435945808981287, 'entropy_loss': -0.07867039926350117, 'vf_loss': 0.19336383443637342, 'total_loss': -0.0343109411736883, 'approx_kl': -0.020553540671244264, 'clip_fraction': 0.37109375, 'grad_norm': 36.578189849853516}
2023-01-03 11:48:02.478 DEBUG: Taking gradient step
2023-01-03 11:48:04.707 DEBUG: Loss 3: {'policy_loss': 0.0417430441208462, 'entropy_loss': -0.0784117579460144, 'vf_loss': 0.1895761042761393, 'total_loss': -0.0366687138251682, 'approx_kl': -0.0053972352761775255, 'clip_fraction': 0.50390625, 'grad_norm': 16.370826721191406}
2023-01-03 11:48:06.906 DEBUG: Taking gradient step
2023-01-03 11:48:09.155 DEBUG: Loss 4: {'policy_loss': 0.053406407732879954, 'entropy_loss': -0.07881910353899002, 'vf_loss': 0.19059762387760004, 'total_loss': -0.025412695806110063, 'approx_kl': -0.027171052992343903, 'clip_fraction': 0.5104166716337204, 'grad_norm': 24.870994567871094}
2023-01-03 11:48:11.327 DEBUG: Taking gradient step
2023-01-03 11:48:13.540 DEBUG: Loss 5: {'policy_loss': 0.06485548077876674, 'entropy_loss': -0.07826686836779118, 'vf_loss': 0.19247091357378115, 'total_loss': -0.013411387589024444, 'approx_kl': -0.024540092796087265, 'clip_fraction': 0.48046875, 'grad_norm': 27.699586868286133}
2023-01-03 11:48:15.709 DEBUG: Taking gradient step
2023-01-03 11:48:17.931 DEBUG: Loss 6: {'policy_loss': 0.018638851688699637, 'entropy_loss': -0.07611110620200634, 'vf_loss': 0.1872762238416954, 'total_loss': -0.0574722545133067, 'approx_kl': -0.07133116014301777, 'clip_fraction': 0.4622395858168602, 'grad_norm': 32.08088302612305}
2023-01-03 11:48:20.107 DEBUG: Taking gradient step
2023-01-03 11:48:22.400 DEBUG: Loss 7: {'policy_loss': 0.08922447205871203, 'entropy_loss': -0.07456842996180058, 'vf_loss': 0.18384398198413798, 'total_loss': 0.014656042096911459, 'approx_kl': -0.07391735911369324, 'clip_fraction': 0.4830729216337204, 'grad_norm': 17.268526077270508}
2023-01-03 11:48:24.915 DEBUG: Taking gradient step
2023-01-03 11:48:27.225 DEBUG: Loss 8: {'policy_loss': 0.12546526631039764, 'entropy_loss': -0.0738569125533104, 'vf_loss': 0.17763899794626736, 'total_loss': 0.05160835375708725, 'approx_kl': -0.06834264192730188, 'clip_fraction': 0.484375, 'grad_norm': 36.72846984863281}
2023-01-03 11:48:29.385 DEBUG: Taking gradient step
2023-01-03 11:48:31.615 DEBUG: Loss 9: {'policy_loss': 0.06898372659695542, 'entropy_loss': -0.07468742318451405, 'vf_loss': 0.17525073583592232, 'total_loss': -0.005703696587558614, 'approx_kl': -0.08850092394277453, 'clip_fraction': 0.5182291716337204, 'grad_norm': 31.864614486694336}
2023-01-03 11:48:33.840 DEBUG: Taking gradient step
2023-01-03 11:48:36.058 DEBUG: Loss 10: {'policy_loss': 0.10031519096597905, 'entropy_loss': -0.07570643164217472, 'vf_loss': 0.17484143692227222, 'total_loss': 0.024608759323804325, 'approx_kl': -0.07392516266554594, 'clip_fraction': 0.5065104216337204, 'grad_norm': 21.624601364135742}
2023-01-03 11:48:38.409 DEBUG: Taking gradient step
2023-01-03 11:48:40.625 DEBUG: Loss 11: {'policy_loss': 0.021469318764059803, 'entropy_loss': -0.07579289563000202, 'vf_loss': 0.1729132231304107, 'total_loss': -0.05432357686594222, 'approx_kl': -0.09387083910405636, 'clip_fraction': 0.5013020932674408, 'grad_norm': 25.305315017700195}
2023-01-03 11:48:42.804 DEBUG: Taking gradient step
2023-01-03 11:48:45.050 DEBUG: Loss 12: {'policy_loss': 0.07169012413075355, 'entropy_loss': -0.07750258594751358, 'vf_loss': 0.16385765187000198, 'total_loss': -0.005812461816760022, 'approx_kl': -0.08887207042425871, 'clip_fraction': 0.4908854216337204, 'grad_norm': 29.249732971191406}
2023-01-03 11:48:47.197 DEBUG: Taking gradient step
2023-01-03 11:48:49.418 DEBUG: Loss 13: {'policy_loss': 0.1208864591164568, 'entropy_loss': -0.07906926237046719, 'vf_loss': 0.17888743573991672, 'total_loss': 0.04181719674598962, 'approx_kl': -0.09852410666644573, 'clip_fraction': 0.41796875, 'grad_norm': 29.00108528137207}
2023-01-03 11:48:51.603 DEBUG: Taking gradient step
2023-01-03 11:48:53.833 DEBUG: Loss 14: {'policy_loss': 0.10055919154131769, 'entropy_loss': -0.07867461442947388, 'vf_loss': 0.17392516504310196, 'total_loss': 0.02188457711184382, 'approx_kl': -0.1169804697856307, 'clip_fraction': 0.4674479216337204, 'grad_norm': 25.74769401550293}
2023-01-03 11:48:53.834 INFO: Optimization: policy loss=0.101, vf loss=0.174, entropy loss=-0.079, total loss=0.022, num steps=15
2023-01-03 11:48:53.836 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 11:48:54.688 DEBUG: Atoms are too close
2023-01-03 11:48:54.690 INFO: Evaluation rollout: return=-29.634 (0.0), episode length=4.0
2023-01-03 11:48:54.691 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 11:48:54.692 INFO: Iteration: 5/137, steps: 1080
2023-01-03 11:48:57.612 DEBUG: There is a single atom floating around
2023-01-03 11:49:04.539 DEBUG: Atoms are too close
2023-01-03 11:49:05.825 DEBUG: Atoms are too close
2023-01-03 11:49:09.047 DEBUG: Atoms are too close
2023-01-03 11:49:10.147 DEBUG: Atoms are too close
2023-01-03 11:49:19.552 DEBUG: Atoms are too close
2023-01-03 11:49:26.163 DEBUG: Atoms are too close
2023-01-03 11:49:26.462 DEBUG: Atoms are too close
2023-01-03 11:49:28.478 DEBUG: Atoms are too close
2023-01-03 11:49:29.079 DEBUG: Atoms are too close
2023-01-03 11:49:29.889 DEBUG: Atoms are too close
2023-01-03 11:49:32.563 DEBUG: Atoms are too close
2023-01-03 11:49:32.564 DEBUG: Atoms are too close
2023-01-03 11:49:41.703 DEBUG: Atoms are too close
2023-01-03 11:49:44.418 DEBUG: Atoms are too close
2023-01-03 11:49:47.157 DEBUG: Atoms are too close
2023-01-03 11:49:50.427 DEBUG: Atoms are too close
2023-01-03 11:49:51.006 DEBUG: Atoms are too close
2023-01-03 11:49:51.784 DEBUG: Atoms are too close
2023-01-03 11:49:52.255 DEBUG: Atoms are too close
2023-01-03 11:49:52.641 INFO: Training rollout: return=-15.624 (15.0), episode length=5.3
2023-01-03 11:49:52.642 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 11:49:52.645 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-1080_train.pkl
2023-01-03 11:49:54.850 DEBUG: Taking gradient step
2023-01-03 11:49:57.128 DEBUG: Loss 0: {'policy_loss': -0.0341609213019221, 'entropy_loss': -0.07470283284783363, 'vf_loss': 0.2287424282145079, 'total_loss': -0.10886375414975574, 'approx_kl': -3.927076974719057e-08, 'clip_fraction': 0.0, 'grad_norm': 23.767887115478516}
2023-01-03 11:49:59.434 DEBUG: Taking gradient step
2023-01-03 11:50:01.673 DEBUG: Loss 1: {'policy_loss': 0.016405000019729145, 'entropy_loss': -0.07553649507462978, 'vf_loss': 0.21598508291016785, 'total_loss': -0.059131495054900646, 'approx_kl': -0.03606442338787019, 'clip_fraction': 0.1940104216337204, 'grad_norm': 14.138187408447266}
2023-01-03 11:50:03.847 DEBUG: Taking gradient step
2023-01-03 11:50:06.091 DEBUG: Loss 2: {'policy_loss': 0.05969729619953979, 'entropy_loss': -0.07500185072422028, 'vf_loss': 0.21115094702619142, 'total_loss': -0.015304554524680491, 'approx_kl': -0.061676363460719585, 'clip_fraction': 0.4739583358168602, 'grad_norm': 29.40149688720703}
2023-01-03 11:50:08.265 DEBUG: Taking gradient step
2023-01-03 11:50:10.530 DEBUG: Loss 3: {'policy_loss': 0.09530460890077419, 'entropy_loss': -0.07484913431107998, 'vf_loss': 0.20231159592738496, 'total_loss': 0.020455474589694222, 'approx_kl': -0.09841272700577974, 'clip_fraction': 0.5546875, 'grad_norm': 23.63135528564453}
2023-01-03 11:50:12.728 DEBUG: Taking gradient step
2023-01-03 11:50:14.985 DEBUG: Loss 4: {'policy_loss': 0.0515117231935218, 'entropy_loss': -0.07431880757212639, 'vf_loss': 0.20055948501956247, 'total_loss': -0.02280708437860459, 'approx_kl': -0.08971205353736877, 'clip_fraction': 0.5559895858168602, 'grad_norm': 17.28642463684082}
2023-01-03 11:50:17.191 DEBUG: Taking gradient step
2023-01-03 11:50:19.436 DEBUG: Loss 5: {'policy_loss': 0.11883500500678719, 'entropy_loss': -0.07372904382646084, 'vf_loss': 0.21497432677463874, 'total_loss': 0.04510596118032635, 'approx_kl': -0.06044426187872887, 'clip_fraction': 0.6341145932674408, 'grad_norm': 13.518118858337402}
2023-01-03 11:50:21.746 DEBUG: Taking gradient step
2023-01-03 11:50:24.132 DEBUG: Loss 6: {'policy_loss': 0.058103454182994604, 'entropy_loss': -0.07243845239281654, 'vf_loss': 0.22511345743478078, 'total_loss': -0.014334998209821936, 'approx_kl': -0.1077956547960639, 'clip_fraction': 0.6432291716337204, 'grad_norm': 21.234275817871094}
2023-01-03 11:50:26.353 DEBUG: Taking gradient step
2023-01-03 11:50:28.733 DEBUG: Loss 7: {'policy_loss': 0.12088143383756644, 'entropy_loss': -0.07272014208137989, 'vf_loss': 0.22914761807852557, 'total_loss': 0.04816129175618656, 'approx_kl': -0.10392875410616398, 'clip_fraction': 0.64453125, 'grad_norm': 24.908832550048828}
2023-01-03 11:50:31.035 DEBUG: Taking gradient step
2023-01-03 11:50:33.260 DEBUG: Loss 8: {'policy_loss': 0.09399436844018214, 'entropy_loss': -0.07148615829646587, 'vf_loss': 0.21592274388702867, 'total_loss': 0.022508210143716262, 'approx_kl': -0.07592709735035896, 'clip_fraction': 0.546875, 'grad_norm': 18.452402114868164}
2023-01-03 11:50:35.656 DEBUG: Taking gradient step
2023-01-03 11:50:38.211 DEBUG: Loss 9: {'policy_loss': 0.08562956079791027, 'entropy_loss': -0.07149450667202473, 'vf_loss': 0.2034470383031919, 'total_loss': 0.014135054125885546, 'approx_kl': -0.11358826793730259, 'clip_fraction': 0.59765625, 'grad_norm': 19.107284545898438}
2023-01-03 11:50:40.493 DEBUG: Taking gradient step
2023-01-03 11:50:42.790 DEBUG: Loss 10: {'policy_loss': 0.09993195967553682, 'entropy_loss': -0.07099249958992004, 'vf_loss': 0.19654316944316852, 'total_loss': 0.028939460085616778, 'approx_kl': -0.1230501551181078, 'clip_fraction': 0.5950520932674408, 'grad_norm': 14.127490997314453}
2023-01-03 11:50:45.303 DEBUG: Taking gradient step
2023-01-03 11:50:47.589 DEBUG: Loss 11: {'policy_loss': 0.11026007080661229, 'entropy_loss': -0.0709540918469429, 'vf_loss': 0.21043057887454764, 'total_loss': 0.03930597895966938, 'approx_kl': -0.09380008280277252, 'clip_fraction': 0.65234375, 'grad_norm': 22.37877082824707}
2023-01-03 11:50:49.853 DEBUG: Taking gradient step
2023-01-03 11:50:52.113 DEBUG: Loss 12: {'policy_loss': 0.08768391777441258, 'entropy_loss': -0.07322586141526699, 'vf_loss': 0.2203556182204675, 'total_loss': 0.014458056359145585, 'approx_kl': -0.09632832743227482, 'clip_fraction': 0.66796875, 'grad_norm': 18.177165985107422}
2023-01-03 11:50:54.342 DEBUG: Taking gradient step
2023-01-03 11:50:56.575 DEBUG: Loss 13: {'policy_loss': 0.05839967026894022, 'entropy_loss': -0.07300896383821964, 'vf_loss': 0.212581529024972, 'total_loss': -0.014609293569279432, 'approx_kl': -0.09313295083120465, 'clip_fraction': 0.6028645932674408, 'grad_norm': 19.521894454956055}
2023-01-03 11:50:58.743 DEBUG: Taking gradient step
2023-01-03 11:51:00.973 DEBUG: Loss 14: {'policy_loss': 0.023862818721731262, 'entropy_loss': -0.07388200424611568, 'vf_loss': 0.20021368568143497, 'total_loss': -0.05001918552438442, 'approx_kl': -0.11455296352505684, 'clip_fraction': 0.5494791716337204, 'grad_norm': 14.850738525390625}
2023-01-03 11:51:00.973 INFO: Optimization: policy loss=0.024, vf loss=0.200, entropy loss=-0.074, total loss=-0.050, num steps=15
2023-01-03 11:51:00.975 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 11:51:02.573 DEBUG: Atoms are too close
2023-01-03 11:51:02.576 INFO: Evaluation rollout: return=-30.103 (0.0), episode length=6.0
2023-01-03 11:51:02.576 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 11:51:02.579 INFO: Iteration: 6/137, steps: 1296
2023-01-03 11:51:14.877 DEBUG: Atoms are too close
2023-01-03 11:51:17.136 DEBUG: Atoms are too close
2023-01-03 11:51:18.248 DEBUG: Atoms are too close
2023-01-03 11:51:20.406 DEBUG: There is a single atom floating around
2023-01-03 11:51:25.614 DEBUG: There is a single atom floating around
2023-01-03 11:51:31.191 DEBUG: Atoms are too close
2023-01-03 11:51:34.203 DEBUG: Atoms are too close
2023-01-03 11:51:34.657 DEBUG: Atoms are too close
2023-01-03 11:51:34.657 DEBUG: Atoms are too close
2023-01-03 11:51:38.488 DEBUG: Atoms are too close
2023-01-03 11:51:38.966 DEBUG: Atoms are too close
2023-01-03 11:51:51.082 DEBUG: Atoms are too close
2023-01-03 11:51:52.098 DEBUG: Atoms are too close
2023-01-03 11:51:54.685 DEBUG: Atoms are too close
2023-01-03 11:51:55.502 DEBUG: There is a single atom floating around
2023-01-03 11:51:55.956 DEBUG: Atoms are too close
2023-01-03 11:52:00.228 INFO: Training rollout: return=-13.394 (15.0), episode length=5.5
2023-01-03 11:52:00.230 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 11:52:00.234 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-1296_train.pkl
2023-01-03 11:52:02.573 DEBUG: Taking gradient step
2023-01-03 11:52:04.983 DEBUG: Loss 0: {'policy_loss': 0.035163030940299066, 'entropy_loss': -0.07520513609051704, 'vf_loss': 0.18038251777018954, 'total_loss': -0.040042105150217985, 'approx_kl': -4.07841680427623e-08, 'clip_fraction': 0.0, 'grad_norm': 12.992981910705566}
2023-01-03 11:52:07.273 DEBUG: Taking gradient step
2023-01-03 11:52:09.569 DEBUG: Loss 1: {'policy_loss': 0.01716859970102468, 'entropy_loss': -0.07603847235441208, 'vf_loss': 0.1827296885475873, 'total_loss': -0.0588698726533874, 'approx_kl': 0.0029072517063468695, 'clip_fraction': 0.1458333358168602, 'grad_norm': 17.669313430786133}
2023-01-03 11:52:11.798 DEBUG: Taking gradient step
2023-01-03 11:52:14.073 DEBUG: Loss 2: {'policy_loss': 0.0038429975785507983, 'entropy_loss': -0.07780045084655285, 'vf_loss': 0.18693786877512258, 'total_loss': -0.07395745326800204, 'approx_kl': -0.03323139064013958, 'clip_fraction': 0.3020833358168602, 'grad_norm': 23.212688446044922}
2023-01-03 11:52:16.321 DEBUG: Taking gradient step
2023-01-03 11:52:18.687 DEBUG: Loss 3: {'policy_loss': 0.07032306507439882, 'entropy_loss': -0.07814465835690498, 'vf_loss': 0.1914822233880482, 'total_loss': -0.007821593282506159, 'approx_kl': -0.021843623369932175, 'clip_fraction': 0.4114583432674408, 'grad_norm': 27.946521759033203}
2023-01-03 11:52:20.960 DEBUG: Taking gradient step
2023-01-03 11:52:23.255 DEBUG: Loss 4: {'policy_loss': 0.030466442829573177, 'entropy_loss': -0.07659782469272614, 'vf_loss': 0.18078994690355993, 'total_loss': -0.04613138186315295, 'approx_kl': -0.04437761474400759, 'clip_fraction': 0.5130208432674408, 'grad_norm': 25.88055419921875}
2023-01-03 11:52:25.545 DEBUG: Taking gradient step
2023-01-03 11:52:27.867 DEBUG: Loss 5: {'policy_loss': 0.028039892234714127, 'entropy_loss': -0.0764132458716631, 'vf_loss': 0.18611226835192154, 'total_loss': -0.04837335363694897, 'approx_kl': -0.08313201274722815, 'clip_fraction': 0.64453125, 'grad_norm': 25.076801300048828}
2023-01-03 11:52:30.174 DEBUG: Taking gradient step
2023-01-03 11:52:32.523 DEBUG: Loss 6: {'policy_loss': 0.005879855043597105, 'entropy_loss': -0.07516475953161716, 'vf_loss': 0.18599153739165253, 'total_loss': -0.06928490448802006, 'approx_kl': -0.07964139711111784, 'clip_fraction': 0.5950520932674408, 'grad_norm': 23.449554443359375}
2023-01-03 11:52:34.906 DEBUG: Taking gradient step
2023-01-03 11:52:37.715 DEBUG: Loss 7: {'policy_loss': 0.04917595421474231, 'entropy_loss': -0.07519524544477463, 'vf_loss': 0.18664839704594777, 'total_loss': -0.02601929123003232, 'approx_kl': -0.0776549382135272, 'clip_fraction': 0.6015625, 'grad_norm': 21.670503616333008}
2023-01-03 11:52:39.966 DEBUG: Taking gradient step
2023-01-03 11:52:42.415 DEBUG: Loss 8: {'policy_loss': 0.06517141654658605, 'entropy_loss': -0.07518414407968521, 'vf_loss': 0.18445864260669403, 'total_loss': -0.010012727533099161, 'approx_kl': -0.09450233541429043, 'clip_fraction': 0.6458333432674408, 'grad_norm': 35.91358947753906}
2023-01-03 11:52:44.697 DEBUG: Taking gradient step
2023-01-03 11:52:47.091 DEBUG: Loss 9: {'policy_loss': 0.0825799843757967, 'entropy_loss': -0.07305692881345749, 'vf_loss': 0.17763576269789794, 'total_loss': 0.009523055562339209, 'approx_kl': -0.06344558298587799, 'clip_fraction': 0.6705729216337204, 'grad_norm': 24.60553550720215}
2023-01-03 11:52:49.325 DEBUG: Taking gradient step
2023-01-03 11:52:51.604 DEBUG: Loss 10: {'policy_loss': 0.04410962685587902, 'entropy_loss': -0.07443749159574509, 'vf_loss': 0.17650752320543767, 'total_loss': -0.03032786473986606, 'approx_kl': -0.10011119209229946, 'clip_fraction': 0.5794270932674408, 'grad_norm': 23.400314331054688}
2023-01-03 11:52:53.843 DEBUG: Taking gradient step
2023-01-03 11:52:56.123 DEBUG: Loss 11: {'policy_loss': 0.03996525381749816, 'entropy_loss': -0.07570323906838894, 'vf_loss': 0.17519753478530678, 'total_loss': -0.03573798525089078, 'approx_kl': -0.10117201320827007, 'clip_fraction': 0.5651041716337204, 'grad_norm': 23.161767959594727}
2023-01-03 11:52:58.539 DEBUG: Taking gradient step
2023-01-03 11:53:00.945 DEBUG: Loss 12: {'policy_loss': 0.08581605257707507, 'entropy_loss': -0.0752546451985836, 'vf_loss': 0.18213595236090646, 'total_loss': 0.010561407378491473, 'approx_kl': -0.12184299062937498, 'clip_fraction': 0.63671875, 'grad_norm': 21.592365264892578}
2023-01-03 11:53:03.245 DEBUG: Taking gradient step
2023-01-03 11:53:05.520 DEBUG: Loss 13: {'policy_loss': 0.08308694426297014, 'entropy_loss': -0.07636261731386185, 'vf_loss': 0.17877091572559267, 'total_loss': 0.006724326949108295, 'approx_kl': -0.1034852541051805, 'clip_fraction': 0.6614583432674408, 'grad_norm': 23.665569305419922}
2023-01-03 11:53:07.772 DEBUG: Taking gradient step
2023-01-03 11:53:10.043 DEBUG: Loss 14: {'policy_loss': 0.056492723173476075, 'entropy_loss': -0.07700624130666256, 'vf_loss': 0.17503982508610821, 'total_loss': -0.02051351813318649, 'approx_kl': -0.11227555945515633, 'clip_fraction': 0.6796875, 'grad_norm': 26.3275089263916}
2023-01-03 11:53:10.044 INFO: Optimization: policy loss=0.056, vf loss=0.175, entropy loss=-0.077, total loss=-0.021, num steps=15
2023-01-03 11:53:10.046 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 11:53:11.243 DEBUG: Atoms are too close
2023-01-03 11:53:11.245 INFO: Evaluation rollout: return=-29.965 (0.0), episode length=5.0
2023-01-03 11:53:11.245 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 11:53:11.248 INFO: Iteration: 7/137, steps: 1512
2023-01-03 11:53:16.657 DEBUG: There is a single atom floating around
2023-01-03 11:53:20.421 DEBUG: Atoms are too close
2023-01-03 11:53:20.422 DEBUG: Atoms are too close
2023-01-03 11:53:21.404 DEBUG: There is a single atom floating around
2023-01-03 11:53:23.783 DEBUG: Atoms are too close
2023-01-03 11:53:25.240 DEBUG: Atoms are too close
2023-01-03 11:53:27.997 DEBUG: Atoms are too close
2023-01-03 11:53:28.470 DEBUG: Atoms are too close
2023-01-03 11:53:28.770 DEBUG: Atoms are too close
2023-01-03 11:53:41.337 DEBUG: Atoms are too close
2023-01-03 11:53:41.338 DEBUG: Atoms are too close
2023-01-03 11:53:43.883 DEBUG: Atoms are too close
2023-01-03 11:53:44.547 DEBUG: Atoms are too close
2023-01-03 11:53:45.775 DEBUG: Atoms are too close
2023-01-03 11:53:45.776 DEBUG: Atoms are too close
2023-01-03 11:53:47.357 DEBUG: Atoms are too close
2023-01-03 11:53:52.769 DEBUG: Atoms are too close
2023-01-03 11:53:57.078 DEBUG: Atoms are too close
2023-01-03 11:53:57.080 DEBUG: Atoms are too close
2023-01-03 11:53:58.308 DEBUG: Atoms are too close
2023-01-03 11:53:58.310 DEBUG: Atoms are too close
2023-01-03 11:54:01.909 DEBUG: Atoms are too close
2023-01-03 11:54:06.057 DEBUG: Atoms are too close
2023-01-03 11:54:07.926 INFO: Training rollout: return=-18.312 (14.6), episode length=5.4
2023-01-03 11:54:07.928 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 11:54:07.931 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-1512_train.pkl
2023-01-03 11:54:10.186 DEBUG: Taking gradient step
2023-01-03 11:54:12.582 DEBUG: Loss 0: {'policy_loss': -0.09324152061142159, 'entropy_loss': -0.07682311348617077, 'vf_loss': 0.22140642875270697, 'total_loss': -0.17006463409759237, 'approx_kl': -8.56719779562809e-08, 'clip_fraction': 0.0, 'grad_norm': 30.298742294311523}
2023-01-03 11:54:14.817 DEBUG: Taking gradient step
2023-01-03 11:54:17.116 DEBUG: Loss 1: {'policy_loss': -0.03066815449219628, 'entropy_loss': -0.07714086771011353, 'vf_loss': 0.22328435904700458, 'total_loss': -0.10780902220230981, 'approx_kl': -0.004523622919805348, 'clip_fraction': 0.08854166697710752, 'grad_norm': 25.661075592041016}
2023-01-03 11:54:19.382 DEBUG: Taking gradient step
2023-01-03 11:54:21.635 DEBUG: Loss 2: {'policy_loss': -0.026968396981815385, 'entropy_loss': -0.07589802704751492, 'vf_loss': 0.2216803279064944, 'total_loss': -0.1028664240293303, 'approx_kl': -0.00962166371755302, 'clip_fraction': 0.25390625, 'grad_norm': 17.597583770751953}
2023-01-03 11:54:23.923 DEBUG: Taking gradient step
2023-01-03 11:54:26.195 DEBUG: Loss 3: {'policy_loss': -0.016934526358283932, 'entropy_loss': -0.07615167275071144, 'vf_loss': 0.22354429800091902, 'total_loss': -0.09308619910899538, 'approx_kl': -0.019933525938540697, 'clip_fraction': 0.32421875, 'grad_norm': 14.652947425842285}
2023-01-03 11:54:28.550 DEBUG: Taking gradient step
2023-01-03 11:54:31.053 DEBUG: Loss 4: {'policy_loss': -0.05849768998584153, 'entropy_loss': -0.07450179010629654, 'vf_loss': 0.21775440730408624, 'total_loss': -0.13299948009213808, 'approx_kl': -0.025712665636092424, 'clip_fraction': 0.3776041716337204, 'grad_norm': 22.29590606689453}
2023-01-03 11:54:33.403 DEBUG: Taking gradient step
2023-01-03 11:54:35.654 DEBUG: Loss 5: {'policy_loss': 0.015871584810662663, 'entropy_loss': -0.07541751302778721, 'vf_loss': 0.21237067963957484, 'total_loss': -0.059545928217124545, 'approx_kl': -0.02835682686418295, 'clip_fraction': 0.3463541716337204, 'grad_norm': 19.498775482177734}
2023-01-03 11:54:37.879 DEBUG: Taking gradient step
2023-01-03 11:54:40.129 DEBUG: Loss 6: {'policy_loss': 0.005314944726244587, 'entropy_loss': -0.07578495889902115, 'vf_loss': 0.21579435271507613, 'total_loss': -0.07047001417277657, 'approx_kl': -0.0349196782335639, 'clip_fraction': 0.4661458432674408, 'grad_norm': 17.288009643554688}
2023-01-03 11:54:42.350 DEBUG: Taking gradient step
2023-01-03 11:54:44.617 DEBUG: Loss 7: {'policy_loss': 0.012690885908388235, 'entropy_loss': -0.07650090008974075, 'vf_loss': 0.22146460881573438, 'total_loss': -0.06381001418135251, 'approx_kl': -0.03966472623869777, 'clip_fraction': 0.4309895858168602, 'grad_norm': 31.456356048583984}
2023-01-03 11:54:46.858 DEBUG: Taking gradient step
2023-01-03 11:54:49.143 DEBUG: Loss 8: {'policy_loss': 0.04496302419631027, 'entropy_loss': -0.07532265968620777, 'vf_loss': 0.20849566578294854, 'total_loss': -0.030359635489897504, 'approx_kl': -0.03683670179452747, 'clip_fraction': 0.41015625, 'grad_norm': 24.54839324951172}
2023-01-03 11:54:51.393 DEBUG: Taking gradient step
2023-01-03 11:54:53.655 DEBUG: Loss 9: {'policy_loss': 0.012859221564167918, 'entropy_loss': -0.07672581635415554, 'vf_loss': 0.20823511251323562, 'total_loss': -0.06386659478998762, 'approx_kl': -0.058673820458352566, 'clip_fraction': 0.4505208358168602, 'grad_norm': 25.737342834472656}
2023-01-03 11:54:55.848 DEBUG: Taking gradient step
2023-01-03 11:54:58.128 DEBUG: Loss 10: {'policy_loss': 0.06386055723990833, 'entropy_loss': -0.07559027522802353, 'vf_loss': 0.20575840239308368, 'total_loss': -0.011729717988115201, 'approx_kl': -0.07372159510850906, 'clip_fraction': 0.40625, 'grad_norm': 27.870576858520508}
2023-01-03 11:55:00.465 DEBUG: Taking gradient step
2023-01-03 11:55:02.751 DEBUG: Loss 11: {'policy_loss': -0.01465557201454118, 'entropy_loss': -0.07627766951918602, 'vf_loss': 0.2130250122969799, 'total_loss': -0.0909332415337272, 'approx_kl': -0.05151250120252371, 'clip_fraction': 0.34765625, 'grad_norm': 33.83958435058594}
2023-01-03 11:55:05.007 DEBUG: Taking gradient step
2023-01-03 11:55:07.315 DEBUG: Loss 12: {'policy_loss': 0.04439560897308985, 'entropy_loss': -0.07479488477110863, 'vf_loss': 0.2073749622637059, 'total_loss': -0.03039927579801878, 'approx_kl': -0.04976120532955974, 'clip_fraction': 0.4036458358168602, 'grad_norm': 14.827886581420898}
2023-01-03 11:55:09.741 DEBUG: Taking gradient step
2023-01-03 11:55:12.199 DEBUG: Loss 13: {'policy_loss': 0.046181155769694976, 'entropy_loss': -0.07461688667535782, 'vf_loss': 0.20546896844755402, 'total_loss': -0.028435730905662843, 'approx_kl': -0.04771791025996208, 'clip_fraction': 0.4205729216337204, 'grad_norm': 19.945545196533203}
2023-01-03 11:55:14.548 DEBUG: Taking gradient step
2023-01-03 11:55:16.809 DEBUG: Loss 14: {'policy_loss': -0.01439188579574887, 'entropy_loss': -0.07542135939002037, 'vf_loss': 0.2048756898219115, 'total_loss': -0.08981324518576923, 'approx_kl': -0.07679405622184277, 'clip_fraction': 0.5078125, 'grad_norm': 32.32655715942383}
2023-01-03 11:55:16.810 INFO: Optimization: policy loss=-0.014, vf loss=0.205, entropy loss=-0.075, total loss=-0.090, num steps=15
2023-01-03 11:55:16.812 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 11:55:18.055 DEBUG: Atoms are too close
2023-01-03 11:55:18.057 INFO: Evaluation rollout: return=-29.796 (0.0), episode length=5.0
2023-01-03 11:55:18.058 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 11:55:18.060 INFO: Iteration: 8/137, steps: 1728
2023-01-03 11:55:28.275 DEBUG: Atoms are too close
2023-01-03 11:55:28.949 DEBUG: Atoms are too close
2023-01-03 11:55:31.817 DEBUG: Atoms are too close
2023-01-03 11:55:34.274 DEBUG: Atoms are too close
2023-01-03 11:55:37.042 DEBUG: Atoms are too close
2023-01-03 11:55:37.043 DEBUG: Atoms are too close
2023-01-03 11:55:49.212 DEBUG: Atoms are too close
2023-01-03 11:55:51.176 DEBUG: Atoms are too close
2023-01-03 11:55:53.565 DEBUG: Atoms are too close
2023-01-03 11:55:55.470 DEBUG: Atoms are too close
2023-01-03 11:56:00.940 DEBUG: There is a single atom floating around
2023-01-03 11:56:07.614 DEBUG: Atoms are too close
2023-01-03 11:56:08.572 DEBUG: Atoms are too close
2023-01-03 11:56:11.097 DEBUG: Atoms are too close
2023-01-03 11:56:12.000 DEBUG: Atoms are too close
2023-01-03 11:56:15.671 DEBUG: Atoms are too close
2023-01-03 11:56:16.072 INFO: Training rollout: return=-13.321 (14.9), episode length=5.6
2023-01-03 11:56:16.073 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 11:56:16.075 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-1728_train.pkl
2023-01-03 11:56:18.496 DEBUG: Taking gradient step
2023-01-03 11:56:21.062 DEBUG: Loss 0: {'policy_loss': -0.010214005675979217, 'entropy_loss': -0.07748393528163433, 'vf_loss': 0.2213669205613612, 'total_loss': -0.08769794095761355, 'approx_kl': -4.311247536747942e-08, 'clip_fraction': 0.0, 'grad_norm': 22.72153091430664}
2023-01-03 11:56:23.321 DEBUG: Taking gradient step
2023-01-03 11:56:25.646 DEBUG: Loss 1: {'policy_loss': 0.05042998011692448, 'entropy_loss': -0.076839629560709, 'vf_loss': 0.21174039182571788, 'total_loss': -0.026409649443784516, 'approx_kl': -0.011793979676440358, 'clip_fraction': 0.3190104216337204, 'grad_norm': 22.83106231689453}
2023-01-03 11:56:27.922 DEBUG: Taking gradient step
2023-01-03 11:56:30.246 DEBUG: Loss 2: {'policy_loss': 0.0529995118549738, 'entropy_loss': -0.07699932344257832, 'vf_loss': 0.22113156343561072, 'total_loss': -0.023999811587604516, 'approx_kl': -0.03689233306795359, 'clip_fraction': 0.4192708432674408, 'grad_norm': 14.426982879638672}
2023-01-03 11:56:32.528 DEBUG: Taking gradient step
2023-01-03 11:56:34.866 DEBUG: Loss 3: {'policy_loss': 0.042744777207396084, 'entropy_loss': -0.0783255510032177, 'vf_loss': 0.2058672348229031, 'total_loss': -0.03558077379582161, 'approx_kl': -0.021882355213165283, 'clip_fraction': 0.44921875, 'grad_norm': 18.603788375854492}
2023-01-03 11:56:37.123 DEBUG: Taking gradient step
2023-01-03 11:56:39.819 DEBUG: Loss 4: {'policy_loss': 0.052143726508616456, 'entropy_loss': -0.07936729304492474, 'vf_loss': 0.20173856197665094, 'total_loss': -0.027223566536308277, 'approx_kl': -0.04474451672285795, 'clip_fraction': 0.4505208358168602, 'grad_norm': 24.69141960144043}
2023-01-03 11:56:42.102 DEBUG: Taking gradient step
2023-01-03 11:56:44.405 DEBUG: Loss 5: {'policy_loss': 0.06016070781067038, 'entropy_loss': -0.07967387326061726, 'vf_loss': 0.19720228470749923, 'total_loss': -0.019513165449946877, 'approx_kl': -0.058050984516739845, 'clip_fraction': 0.4700520858168602, 'grad_norm': 22.745908737182617}
2023-01-03 11:56:46.662 DEBUG: Taking gradient step
2023-01-03 11:56:48.990 DEBUG: Loss 6: {'policy_loss': 0.10170834732296927, 'entropy_loss': -0.07961982674896717, 'vf_loss': 0.21350074824498627, 'total_loss': 0.022088520574002096, 'approx_kl': -0.04450962785631418, 'clip_fraction': 0.6341145932674408, 'grad_norm': 20.379453659057617}
2023-01-03 11:56:51.265 DEBUG: Taking gradient step
2023-01-03 11:56:53.572 DEBUG: Loss 7: {'policy_loss': -0.00601363085152537, 'entropy_loss': -0.08033430762588978, 'vf_loss': 0.20292288881895432, 'total_loss': -0.08634793847741515, 'approx_kl': -0.07419196236878633, 'clip_fraction': 0.59375, 'grad_norm': 14.301340103149414}
2023-01-03 11:56:55.840 DEBUG: Taking gradient step
2023-01-03 11:56:58.107 DEBUG: Loss 8: {'policy_loss': 0.07828548858699548, 'entropy_loss': -0.07951765693724155, 'vf_loss': 0.21591766526166514, 'total_loss': -0.001232168350246074, 'approx_kl': -0.09660270996391773, 'clip_fraction': 0.5403645858168602, 'grad_norm': 22.269323348999023}
2023-01-03 11:57:00.341 DEBUG: Taking gradient step
2023-01-03 11:57:02.639 DEBUG: Loss 9: {'policy_loss': 0.084051470934169, 'entropy_loss': -0.07862520031630993, 'vf_loss': 0.21670070808651973, 'total_loss': 0.005426270617859073, 'approx_kl': -0.0951409786939621, 'clip_fraction': 0.65234375, 'grad_norm': 27.03432273864746}
2023-01-03 11:57:05.006 DEBUG: Taking gradient step
2023-01-03 11:57:07.284 DEBUG: Loss 10: {'policy_loss': 0.02767948146092816, 'entropy_loss': -0.07855704426765442, 'vf_loss': 0.2110739053811496, 'total_loss': -0.050877562806726256, 'approx_kl': -0.09000277647282928, 'clip_fraction': 0.5494791716337204, 'grad_norm': 19.35943031311035}
2023-01-03 11:57:09.629 DEBUG: Taking gradient step
2023-01-03 11:57:11.918 DEBUG: Loss 11: {'policy_loss': 0.05995027555990515, 'entropy_loss': -0.07745186425745487, 'vf_loss': 0.20802210333378185, 'total_loss': -0.017501588697549725, 'approx_kl': -0.09750333987176418, 'clip_fraction': 0.5677083358168602, 'grad_norm': 11.577977180480957}
2023-01-03 11:57:14.196 DEBUG: Taking gradient step
2023-01-03 11:57:16.521 DEBUG: Loss 12: {'policy_loss': 0.10247200524688052, 'entropy_loss': -0.07729641906917095, 'vf_loss': 0.2064583786814405, 'total_loss': 0.025175586177709576, 'approx_kl': -0.10361776873469353, 'clip_fraction': 0.5481770932674408, 'grad_norm': 18.221071243286133}
2023-01-03 11:57:18.875 DEBUG: Taking gradient step
2023-01-03 11:57:21.256 DEBUG: Loss 13: {'policy_loss': 0.1187160872008981, 'entropy_loss': -0.07816574908792973, 'vf_loss': 0.20155064116492438, 'total_loss': 0.04055033811296837, 'approx_kl': -0.0891811577603221, 'clip_fraction': 0.6419270932674408, 'grad_norm': 27.234094619750977}
2023-01-03 11:57:23.532 DEBUG: Taking gradient step
2023-01-03 11:57:25.866 DEBUG: Loss 14: {'policy_loss': 0.11932813992668707, 'entropy_loss': -0.07773790508508682, 'vf_loss': 0.19826596661296003, 'total_loss': 0.04159023484160025, 'approx_kl': -0.12755454890429974, 'clip_fraction': 0.5703125, 'grad_norm': 25.23230743408203}
2023-01-03 11:57:25.867 INFO: Optimization: policy loss=0.119, vf loss=0.198, entropy loss=-0.078, total loss=0.042, num steps=15
2023-01-03 11:57:25.869 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 11:57:27.791 INFO: Evaluation rollout: return=0.348 (0.0), episode length=6.0
2023-01-03 11:57:27.792 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 11:57:27.795 INFO: Iteration: 9/137, steps: 1944
2023-01-03 11:57:39.088 DEBUG: Atoms are too close
2023-01-03 11:57:39.089 DEBUG: Atoms are too close
2023-01-03 11:57:39.090 DEBUG: Atoms are too close
2023-01-03 11:57:40.075 DEBUG: Atoms are too close
2023-01-03 11:57:44.391 DEBUG: Atoms are too close
2023-01-03 11:57:46.024 DEBUG: Atoms are too close
2023-01-03 11:57:46.024 DEBUG: Atoms are too close
2023-01-03 11:57:52.255 DEBUG: There is a single atom floating around
2023-01-03 11:57:59.769 DEBUG: There is a single atom floating around
2023-01-03 11:58:00.798 DEBUG: Atoms are too close
2023-01-03 11:58:03.922 DEBUG: Atoms are too close
2023-01-03 11:58:03.923 DEBUG: Atoms are too close
2023-01-03 11:58:05.155 DEBUG: Atoms are too close
2023-01-03 11:58:10.638 DEBUG: Atoms are too close
2023-01-03 11:58:10.966 DEBUG: Atoms are too close
2023-01-03 11:58:15.963 DEBUG: Atoms are too close
2023-01-03 11:58:20.117 DEBUG: Atoms are too close
2023-01-03 11:58:23.622 DEBUG: Atoms are too close
2023-01-03 11:58:23.623 DEBUG: Atoms are too close
2023-01-03 11:58:24.245 DEBUG: Atoms are too close
2023-01-03 11:58:25.274 INFO: Training rollout: return=-15.511 (15.0), episode length=5.3
2023-01-03 11:58:25.276 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 11:58:25.279 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-1944_train.pkl
2023-01-03 11:58:27.746 DEBUG: Taking gradient step
2023-01-03 11:58:30.053 DEBUG: Loss 0: {'policy_loss': -0.012905123514167734, 'entropy_loss': -0.07571451738476753, 'vf_loss': 0.21226745348262122, 'total_loss': -0.08861964089893526, 'approx_kl': 3.876630216836929e-08, 'clip_fraction': 0.0, 'grad_norm': 23.350318908691406}
2023-01-03 11:58:32.311 DEBUG: Taking gradient step
2023-01-03 11:58:34.662 DEBUG: Loss 1: {'policy_loss': 0.07443960446481826, 'entropy_loss': -0.07715835608541965, 'vf_loss': 0.21350441405020437, 'total_loss': -0.002718751620601395, 'approx_kl': -0.021650899667292833, 'clip_fraction': 0.2760416716337204, 'grad_norm': 33.1998291015625}
2023-01-03 11:58:36.944 DEBUG: Taking gradient step
2023-01-03 11:58:39.310 DEBUG: Loss 2: {'policy_loss': 0.0869874669896299, 'entropy_loss': -0.0757472850382328, 'vf_loss': 0.21221534604752948, 'total_loss': 0.011240181951397098, 'approx_kl': -0.02955111232586205, 'clip_fraction': 0.4635416716337204, 'grad_norm': 39.6691780090332}
2023-01-03 11:58:41.570 DEBUG: Taking gradient step
2023-01-03 11:58:44.011 DEBUG: Loss 3: {'policy_loss': 0.1049632918814359, 'entropy_loss': -0.07665996439754963, 'vf_loss': 0.2109727410838847, 'total_loss': 0.028303327483886268, 'approx_kl': -0.05571546358987689, 'clip_fraction': 0.45703125, 'grad_norm': 35.449825286865234}
2023-01-03 11:58:46.285 DEBUG: Taking gradient step
2023-01-03 11:58:48.622 DEBUG: Loss 4: {'policy_loss': 0.06346884383205023, 'entropy_loss': -0.0769942756742239, 'vf_loss': 0.21268003987503448, 'total_loss': -0.013525431842173672, 'approx_kl': -0.0554997231811285, 'clip_fraction': 0.45703125, 'grad_norm': 27.42250633239746}
2023-01-03 11:58:50.895 DEBUG: Taking gradient step
2023-01-03 11:58:53.190 DEBUG: Loss 5: {'policy_loss': 0.05466797051347791, 'entropy_loss': -0.07666431181132793, 'vf_loss': 0.21262177203351468, 'total_loss': -0.02199634129785002, 'approx_kl': -0.04174274718388915, 'clip_fraction': 0.5494791716337204, 'grad_norm': 31.605308532714844}
2023-01-03 11:58:55.453 DEBUG: Taking gradient step
2023-01-03 11:58:57.748 DEBUG: Loss 6: {'policy_loss': 0.016253794983768305, 'entropy_loss': -0.07509717345237732, 'vf_loss': 0.21182212600251427, 'total_loss': -0.058843378468609014, 'approx_kl': -0.06489597260951996, 'clip_fraction': 0.5638020932674408, 'grad_norm': 16.92119598388672}
2023-01-03 11:59:00.052 DEBUG: Taking gradient step
2023-01-03 11:59:02.384 DEBUG: Loss 7: {'policy_loss': 0.08993422619632808, 'entropy_loss': -0.07528938353061676, 'vf_loss': 0.22101323581493734, 'total_loss': 0.014644842665711325, 'approx_kl': -0.07467599539086223, 'clip_fraction': 0.6171875, 'grad_norm': 18.329275131225586}
2023-01-03 11:59:04.595 DEBUG: Taking gradient step
2023-01-03 11:59:07.108 DEBUG: Loss 8: {'policy_loss': 0.02799000578729141, 'entropy_loss': -0.07514198310673237, 'vf_loss': 0.2139894492374905, 'total_loss': -0.047151977319440964, 'approx_kl': -0.07811967795714736, 'clip_fraction': 0.58203125, 'grad_norm': 28.448354721069336}
2023-01-03 11:59:09.533 DEBUG: Taking gradient step
2023-01-03 11:59:11.928 DEBUG: Loss 9: {'policy_loss': 0.06878211854587585, 'entropy_loss': -0.07537541165947914, 'vf_loss': 0.22092159377448775, 'total_loss': -0.006593293113603297, 'approx_kl': -0.09871791978366673, 'clip_fraction': 0.4765625, 'grad_norm': 28.468046188354492}
2023-01-03 11:59:14.159 DEBUG: Taking gradient step
2023-01-03 11:59:16.440 DEBUG: Loss 10: {'policy_loss': 0.026366864906242286, 'entropy_loss': -0.07448674738407135, 'vf_loss': 0.21315305918248675, 'total_loss': -0.048119882477829064, 'approx_kl': -0.10102761257439852, 'clip_fraction': 0.3580729216337204, 'grad_norm': 18.131288528442383}
2023-01-03 11:59:18.621 DEBUG: Taking gradient step
2023-01-03 11:59:20.877 DEBUG: Loss 11: {'policy_loss': 0.1150965465305201, 'entropy_loss': -0.07543412037193775, 'vf_loss': 0.22078854215261162, 'total_loss': 0.039662426158582356, 'approx_kl': -0.1073019988834858, 'clip_fraction': 0.39453125, 'grad_norm': 18.026193618774414}
2023-01-03 11:59:23.122 DEBUG: Taking gradient step
2023-01-03 11:59:25.382 DEBUG: Loss 12: {'policy_loss': 0.06860585611953315, 'entropy_loss': -0.07588096149265766, 'vf_loss': 0.21212181001156472, 'total_loss': -0.007275105373124504, 'approx_kl': -0.12059124745428562, 'clip_fraction': 0.5221354216337204, 'grad_norm': 34.80335998535156}
2023-01-03 11:59:27.618 DEBUG: Taking gradient step
2023-01-03 11:59:29.905 DEBUG: Loss 13: {'policy_loss': 0.14875053920452322, 'entropy_loss': -0.07548203133046627, 'vf_loss': 0.20599170320405796, 'total_loss': 0.07326850787405695, 'approx_kl': -0.12086940463632345, 'clip_fraction': 0.4856770858168602, 'grad_norm': 28.146207809448242}
2023-01-03 11:59:32.150 DEBUG: Taking gradient step
2023-01-03 11:59:34.458 DEBUG: Loss 14: {'policy_loss': -0.00025890793715749316, 'entropy_loss': -0.07548877596855164, 'vf_loss': 0.21323736246874278, 'total_loss': -0.07574768390570913, 'approx_kl': -0.09915763745084405, 'clip_fraction': 0.453125, 'grad_norm': 19.473308563232422}
2023-01-03 11:59:34.458 INFO: Optimization: policy loss=-0.000, vf loss=0.213, entropy loss=-0.075, total loss=-0.076, num steps=15
2023-01-03 11:59:34.460 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 11:59:35.691 DEBUG: Atoms are too close
2023-01-03 11:59:35.693 INFO: Evaluation rollout: return=-29.798 (0.0), episode length=5.0
2023-01-03 11:59:35.694 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 11:59:35.696 INFO: Iteration: 10/137, steps: 2160
2023-01-03 11:59:44.499 DEBUG: There is a single atom floating around
2023-01-03 11:59:45.549 DEBUG: Atoms are too close
2023-01-03 11:59:46.504 DEBUG: Atoms are too close
2023-01-03 11:59:46.823 DEBUG: Atoms are too close
2023-01-03 11:59:47.287 DEBUG: Atoms are too close
2023-01-03 11:59:50.568 DEBUG: Atoms are too close
2023-01-03 11:59:51.607 DEBUG: Atoms are too close
2023-01-03 11:59:51.608 DEBUG: Atoms are too close
2023-01-03 11:59:52.575 DEBUG: Atoms are too close
2023-01-03 11:59:59.203 DEBUG: Atoms are too close
2023-01-03 12:00:02.108 DEBUG: Atoms are too close
2023-01-03 12:00:02.934 DEBUG: Atoms are too close
2023-01-03 12:00:03.703 DEBUG: Atoms are too close
2023-01-03 12:00:06.281 DEBUG: Atoms are too close
2023-01-03 12:00:10.106 DEBUG: Atoms are too close
2023-01-03 12:00:11.664 DEBUG: Atoms are too close
2023-01-03 12:00:17.136 DEBUG: Atoms are too close
2023-01-03 12:00:17.472 DEBUG: Atoms are too close
2023-01-03 12:00:21.647 DEBUG: Atoms are too close
2023-01-03 12:00:21.648 DEBUG: Atoms are too close
2023-01-03 12:00:22.063 DEBUG: Atoms are too close
2023-01-03 12:00:24.919 DEBUG: Atoms are too close
2023-01-03 12:00:25.526 DEBUG: Atoms are too close
2023-01-03 12:00:26.468 DEBUG: Atoms are too close
2023-01-03 12:00:28.306 DEBUG: Atoms are too close
2023-01-03 12:00:28.758 DEBUG: Atoms are too close
2023-01-03 12:00:29.889 DEBUG: There is a single atom floating around
2023-01-03 12:00:29.970 INFO: Training rollout: return=-21.034 (13.6), episode length=5.2
2023-01-03 12:00:29.971 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 12:00:29.976 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-2160_train.pkl
2023-01-03 12:00:32.352 DEBUG: Taking gradient step
2023-01-03 12:00:34.599 DEBUG: Loss 0: {'policy_loss': -0.04183146295251181, 'entropy_loss': -0.07775482907891273, 'vf_loss': 0.21548208728600782, 'total_loss': -0.11958629203142454, 'approx_kl': -1.1253482590234398e-09, 'clip_fraction': 0.0, 'grad_norm': 18.58461570739746}
2023-01-03 12:00:36.819 DEBUG: Taking gradient step
2023-01-03 12:00:39.104 DEBUG: Loss 1: {'policy_loss': 0.075287588950664, 'entropy_loss': -0.07694714516401291, 'vf_loss': 0.21381125245546284, 'total_loss': -0.0016595562133489145, 'approx_kl': -0.012785190716385841, 'clip_fraction': 0.2434895858168602, 'grad_norm': 30.260730743408203}
2023-01-03 12:00:41.316 DEBUG: Taking gradient step
2023-01-03 12:00:43.610 DEBUG: Loss 2: {'policy_loss': 0.07278352525306192, 'entropy_loss': -0.07556633464992046, 'vf_loss': 0.21349840170939577, 'total_loss': -0.00278280939685855, 'approx_kl': -0.019921429455280304, 'clip_fraction': 0.3893229216337204, 'grad_norm': 25.421829223632812}
2023-01-03 12:00:45.877 DEBUG: Taking gradient step
2023-01-03 12:00:48.184 DEBUG: Loss 3: {'policy_loss': 0.02537115891819243, 'entropy_loss': -0.07411199621856213, 'vf_loss': 0.19988529278447148, 'total_loss': -0.048740837300369697, 'approx_kl': -0.03263365803286433, 'clip_fraction': 0.2825520858168602, 'grad_norm': 13.563549041748047}
2023-01-03 12:00:50.530 DEBUG: Taking gradient step
2023-01-03 12:00:52.891 DEBUG: Loss 4: {'policy_loss': 0.08450796246464379, 'entropy_loss': -0.07427793182432652, 'vf_loss': 0.19423954218526507, 'total_loss': 0.010230030640317272, 'approx_kl': -0.03619067510589957, 'clip_fraction': 0.3138020858168602, 'grad_norm': 16.31591033935547}
2023-01-03 12:00:55.263 DEBUG: Taking gradient step
2023-01-03 12:00:57.748 DEBUG: Loss 5: {'policy_loss': 0.09226900580972933, 'entropy_loss': -0.07408480532467365, 'vf_loss': 0.18392097485708703, 'total_loss': 0.018184200485055674, 'approx_kl': -0.04057733155786991, 'clip_fraction': 0.3932291716337204, 'grad_norm': 24.456256866455078}
2023-01-03 12:00:59.924 DEBUG: Taking gradient step
2023-01-03 12:01:02.158 DEBUG: Loss 6: {'policy_loss': 0.13014351514949946, 'entropy_loss': -0.07402532547712326, 'vf_loss': 0.18713155712854604, 'total_loss': 0.056118189672376195, 'approx_kl': -0.06389273377135396, 'clip_fraction': 0.4140625, 'grad_norm': 28.52008056640625}
2023-01-03 12:01:04.328 DEBUG: Taking gradient step
2023-01-03 12:01:06.544 DEBUG: Loss 7: {'policy_loss': 0.07628710172190162, 'entropy_loss': -0.07479255087673664, 'vf_loss': 0.20914398927345362, 'total_loss': 0.001494550845164977, 'approx_kl': -0.048732451163232327, 'clip_fraction': 0.5, 'grad_norm': 23.837352752685547}
2023-01-03 12:01:08.797 DEBUG: Taking gradient step
2023-01-03 12:01:11.077 DEBUG: Loss 8: {'policy_loss': 0.02292025823946147, 'entropy_loss': -0.07677622698247433, 'vf_loss': 0.2047460722927406, 'total_loss': -0.05385596874301285, 'approx_kl': -0.05130202416330576, 'clip_fraction': 0.5677083432674408, 'grad_norm': 14.586706161499023}
2023-01-03 12:01:13.232 DEBUG: Taking gradient step
2023-01-03 12:01:15.454 DEBUG: Loss 9: {'policy_loss': 0.09029471903290177, 'entropy_loss': -0.0761164054274559, 'vf_loss': 0.18647186317886882, 'total_loss': 0.014178313605445868, 'approx_kl': -0.06684126541949809, 'clip_fraction': 0.5455729216337204, 'grad_norm': 21.587661743164062}
2023-01-03 12:01:17.648 DEBUG: Taking gradient step
2023-01-03 12:01:19.857 DEBUG: Loss 10: {'policy_loss': 0.14156832622292126, 'entropy_loss': -0.07599883526563644, 'vf_loss': 0.17870346608042442, 'total_loss': 0.06556949095728482, 'approx_kl': -0.06551355961710215, 'clip_fraction': 0.6197916716337204, 'grad_norm': 48.936397552490234}
2023-01-03 12:01:22.082 DEBUG: Taking gradient step
2023-01-03 12:01:24.663 DEBUG: Loss 11: {'policy_loss': 0.13119435935170756, 'entropy_loss': -0.07610855624079704, 'vf_loss': 0.1799961261015845, 'total_loss': 0.05508580311091051, 'approx_kl': -0.08718560822308064, 'clip_fraction': 0.46875, 'grad_norm': 28.598134994506836}
2023-01-03 12:01:26.838 DEBUG: Taking gradient step
2023-01-03 12:01:29.212 DEBUG: Loss 12: {'policy_loss': 0.035428400547629246, 'entropy_loss': -0.0737252663820982, 'vf_loss': 0.19056336080025507, 'total_loss': -0.03829686583446895, 'approx_kl': -0.08458797819912434, 'clip_fraction': 0.4309895858168602, 'grad_norm': 11.449006080627441}
2023-01-03 12:01:31.466 DEBUG: Taking gradient step
2023-01-03 12:01:33.728 DEBUG: Loss 13: {'policy_loss': 0.10942597282292596, 'entropy_loss': -0.07291320525109768, 'vf_loss': 0.19073296059863445, 'total_loss': 0.03651276757182828, 'approx_kl': -0.08246920770034194, 'clip_fraction': 0.4361979216337204, 'grad_norm': 29.479524612426758}
2023-01-03 12:01:35.897 DEBUG: Taking gradient step
2023-01-03 12:01:38.135 DEBUG: Loss 14: {'policy_loss': 0.12579756420779029, 'entropy_loss': -0.0707946065813303, 'vf_loss': 0.18808524973655824, 'total_loss': 0.05500295762645999, 'approx_kl': -0.04750821087509394, 'clip_fraction': 0.5390625, 'grad_norm': 30.85091781616211}
2023-01-03 12:01:38.136 INFO: Optimization: policy loss=0.126, vf loss=0.188, entropy loss=-0.071, total loss=0.055, num steps=15
2023-01-03 12:01:38.137 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 12:01:39.404 DEBUG: Atoms are too close
2023-01-03 12:01:39.407 INFO: Evaluation rollout: return=-29.754 (0.0), episode length=5.0
2023-01-03 12:01:39.407 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 12:01:39.411 DEBUG: Deleting old model: runs/CH3NO_dna/models/CH3NO_dna_run-1_steps-216.model
2023-01-03 12:01:39.416 DEBUG: Saving model: runs/CH3NO_dna/models/CH3NO_dna_run-1_steps-2376.model
2023-01-03 12:01:39.467 INFO: Iteration: 11/137, steps: 2376
2023-01-03 12:01:46.581 DEBUG: There is a single atom floating around
2023-01-03 12:01:48.935 DEBUG: Atoms are too close
2023-01-03 12:01:50.658 DEBUG: Atoms are too close
2023-01-03 12:01:53.422 DEBUG: Atoms are too close
2023-01-03 12:01:54.856 DEBUG: Atoms are too close
2023-01-03 12:01:55.291 DEBUG: Atoms are too close
2023-01-03 12:01:55.292 DEBUG: Atoms are too close
2023-01-03 12:01:56.716 DEBUG: Atoms are too close
2023-01-03 12:01:59.156 DEBUG: There is a single atom floating around
2023-01-03 12:02:01.580 DEBUG: There is a single atom floating around
2023-01-03 12:02:03.321 DEBUG: Atoms are too close
2023-01-03 12:02:03.641 DEBUG: There is a single atom floating around
2023-01-03 12:02:10.093 DEBUG: Atoms are too close
2023-01-03 12:02:11.412 DEBUG: Atoms are too close
2023-01-03 12:02:12.673 DEBUG: Atoms are too close
2023-01-03 12:02:14.603 DEBUG: Atoms are too close
2023-01-03 12:02:14.604 DEBUG: Atoms are too close
2023-01-03 12:02:14.604 DEBUG: Atoms are too close
2023-01-03 12:02:17.768 DEBUG: There is a single atom floating around
2023-01-03 12:02:18.509 DEBUG: Atoms are too close
2023-01-03 12:02:25.027 DEBUG: There is a single atom floating around
2023-01-03 12:02:29.855 DEBUG: Atoms are too close
2023-01-03 12:02:30.473 DEBUG: Atoms are too close
2023-01-03 12:02:30.473 DEBUG: Atoms are too close
2023-01-03 12:02:34.263 INFO: Training rollout: return=-19.229 (14.2), episode length=5.2
2023-01-03 12:02:34.264 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 12:02:34.267 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-2376_train.pkl
2023-01-03 12:02:36.495 DEBUG: Taking gradient step
2023-01-03 12:02:39.020 DEBUG: Loss 0: {'policy_loss': 0.015307683849911411, 'entropy_loss': -0.06967142038047314, 'vf_loss': 0.1926130318907631, 'total_loss': -0.05436373653056172, 'approx_kl': 3.319776897825477e-08, 'clip_fraction': 0.0, 'grad_norm': 18.42865562438965}
2023-01-03 12:02:41.201 DEBUG: Taking gradient step
2023-01-03 12:02:43.439 DEBUG: Loss 1: {'policy_loss': 0.022863570621983652, 'entropy_loss': -0.069968331605196, 'vf_loss': 0.19428160530112948, 'total_loss': -0.04710476098321235, 'approx_kl': -0.009771727956831455, 'clip_fraction': 0.4049479216337204, 'grad_norm': 35.201866149902344}
2023-01-03 12:02:45.595 DEBUG: Taking gradient step
2023-01-03 12:02:47.955 DEBUG: Loss 2: {'policy_loss': 0.104401330530738, 'entropy_loss': -0.06903517805039883, 'vf_loss': 0.1865481219698809, 'total_loss': 0.03536615248033917, 'approx_kl': -0.03181646205484867, 'clip_fraction': 0.4505208432674408, 'grad_norm': 35.07493591308594}
2023-01-03 12:02:50.119 DEBUG: Taking gradient step
2023-01-03 12:02:52.361 DEBUG: Loss 3: {'policy_loss': 0.08656761652826839, 'entropy_loss': -0.0699697807431221, 'vf_loss': 0.19332407221104797, 'total_loss': 0.016597835785146283, 'approx_kl': -0.046413733158260584, 'clip_fraction': 0.3658854216337204, 'grad_norm': 27.226398468017578}
2023-01-03 12:02:54.551 DEBUG: Taking gradient step
2023-01-03 12:02:56.777 DEBUG: Loss 4: {'policy_loss': 0.13793226536800945, 'entropy_loss': -0.0706427600234747, 'vf_loss': 0.1977171222177331, 'total_loss': 0.06728950534453475, 'approx_kl': -0.04443952161818743, 'clip_fraction': 0.5390625, 'grad_norm': 42.78122329711914}
2023-01-03 12:02:58.969 DEBUG: Taking gradient step
2023-01-03 12:03:01.376 DEBUG: Loss 5: {'policy_loss': 0.0959189985799276, 'entropy_loss': -0.0704079270362854, 'vf_loss': 0.1891231858194817, 'total_loss': 0.0255110715436422, 'approx_kl': -0.038356858771294355, 'clip_fraction': 0.66796875, 'grad_norm': 24.52192497253418}
2023-01-03 12:03:03.575 DEBUG: Taking gradient step
2023-01-03 12:03:05.840 DEBUG: Loss 6: {'policy_loss': 0.06478819461358835, 'entropy_loss': -0.0689197275787592, 'vf_loss': 0.18913254416457564, 'total_loss': -0.0041315329651708255, 'approx_kl': -0.0625548455864191, 'clip_fraction': 0.6861979216337204, 'grad_norm': 25.61875343322754}
2023-01-03 12:03:08.034 DEBUG: Taking gradient step
2023-01-03 12:03:10.300 DEBUG: Loss 7: {'policy_loss': 0.1343879489020367, 'entropy_loss': -0.06868469715118408, 'vf_loss': 0.1933389564180489, 'total_loss': 0.06570325175085262, 'approx_kl': -0.06517998548224568, 'clip_fraction': 0.5143229216337204, 'grad_norm': 35.502803802490234}
2023-01-03 12:03:12.605 DEBUG: Taking gradient step
2023-01-03 12:03:15.074 DEBUG: Loss 8: {'policy_loss': 0.13939854875918206, 'entropy_loss': -0.06756236031651497, 'vf_loss': 0.1891729571908254, 'total_loss': 0.07183618844266708, 'approx_kl': -0.07797428499907255, 'clip_fraction': 0.5416666716337204, 'grad_norm': 34.98794937133789}
2023-01-03 12:03:17.278 DEBUG: Taking gradient step
2023-01-03 12:03:19.501 DEBUG: Loss 9: {'policy_loss': 0.056240908917823386, 'entropy_loss': -0.0672568641602993, 'vf_loss': 0.1895213083379223, 'total_loss': -0.011015955242475915, 'approx_kl': -0.06739816698245704, 'clip_fraction': 0.5065104216337204, 'grad_norm': 20.570587158203125}
2023-01-03 12:03:21.683 DEBUG: Taking gradient step
2023-01-03 12:03:23.905 DEBUG: Loss 10: {'policy_loss': 0.08156292429184907, 'entropy_loss': -0.06784014031291008, 'vf_loss': 0.1889702270248523, 'total_loss': 0.013722783978938988, 'approx_kl': -0.10158370062708855, 'clip_fraction': 0.5208333358168602, 'grad_norm': 33.19493865966797}
2023-01-03 12:03:26.291 DEBUG: Taking gradient step
2023-01-03 12:03:28.528 DEBUG: Loss 11: {'policy_loss': 0.022582223787827177, 'entropy_loss': -0.06794185936450958, 'vf_loss': 0.19001498958931534, 'total_loss': -0.04535963557668241, 'approx_kl': -0.09513743687421083, 'clip_fraction': 0.67578125, 'grad_norm': 26.985885620117188}
2023-01-03 12:03:30.677 DEBUG: Taking gradient step
2023-01-03 12:03:32.899 DEBUG: Loss 12: {'policy_loss': 0.10001699946723272, 'entropy_loss': -0.06927730701863766, 'vf_loss': 0.18228718246241482, 'total_loss': 0.030739692448595063, 'approx_kl': -0.11252040229737759, 'clip_fraction': 0.6848958432674408, 'grad_norm': 39.4183349609375}
2023-01-03 12:03:35.248 DEBUG: Taking gradient step
2023-01-03 12:03:37.493 DEBUG: Loss 13: {'policy_loss': 0.16535289421333074, 'entropy_loss': -0.07126163318753242, 'vf_loss': 0.1859024684708607, 'total_loss': 0.09409126102579835, 'approx_kl': -0.1259081270545721, 'clip_fraction': 0.6940104216337204, 'grad_norm': 31.576704025268555}
2023-01-03 12:03:39.818 DEBUG: Taking gradient step
2023-01-03 12:03:42.047 DEBUG: Loss 14: {'policy_loss': 0.1148886921384779, 'entropy_loss': -0.07158930972218513, 'vf_loss': 0.1854460167299775, 'total_loss': 0.04329938241629276, 'approx_kl': -0.1331650372594595, 'clip_fraction': 0.5572916716337204, 'grad_norm': 40.433746337890625}
2023-01-03 12:03:42.048 INFO: Optimization: policy loss=0.115, vf loss=0.185, entropy loss=-0.072, total loss=0.043, num steps=15
2023-01-03 12:03:42.049 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 12:03:43.988 INFO: Evaluation rollout: return=0.448 (0.0), episode length=6.0
2023-01-03 12:03:43.989 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 12:03:43.991 INFO: Iteration: 12/137, steps: 2592
2023-01-03 12:03:55.558 DEBUG: Atoms are too close
2023-01-03 12:03:58.231 DEBUG: Atoms are too close
2023-01-03 12:04:03.695 DEBUG: Atoms are too close
2023-01-03 12:04:15.453 DEBUG: Atoms are too close
2023-01-03 12:04:15.455 DEBUG: Atoms are too close
2023-01-03 12:04:17.101 DEBUG: Atoms are too close
2023-01-03 12:04:17.102 DEBUG: Atoms are too close
2023-01-03 12:04:17.501 DEBUG: Atoms are too close
2023-01-03 12:04:18.321 DEBUG: Atoms are too close
2023-01-03 12:04:22.073 DEBUG: Atoms are too close
2023-01-03 12:04:22.074 DEBUG: Atoms are too close
2023-01-03 12:04:23.974 DEBUG: There is a single atom floating around
2023-01-03 12:04:25.455 DEBUG: Atoms are too close
2023-01-03 12:04:30.073 DEBUG: There is a single atom floating around
2023-01-03 12:04:31.078 DEBUG: Atoms are too close
2023-01-03 12:04:33.669 DEBUG: There is a single atom floating around
2023-01-03 12:04:35.735 DEBUG: Atoms are too close
2023-01-03 12:04:35.736 DEBUG: There is a single atom floating around
2023-01-03 12:04:42.755 INFO: Training rollout: return=-14.350 (15.0), episode length=5.3
2023-01-03 12:04:42.757 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 12:04:42.760 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-2592_train.pkl
2023-01-03 12:04:44.968 DEBUG: Taking gradient step
2023-01-03 12:04:47.241 DEBUG: Loss 0: {'policy_loss': 0.003727275076214502, 'entropy_loss': -0.07236011140048504, 'vf_loss': 0.21399884156869928, 'total_loss': -0.06863283632427053, 'approx_kl': -4.384975937909985e-09, 'clip_fraction': 0.0, 'grad_norm': 14.201435089111328}
2023-01-03 12:04:49.488 DEBUG: Taking gradient step
2023-01-03 12:04:51.720 DEBUG: Loss 1: {'policy_loss': -0.08459539073958686, 'entropy_loss': -0.07319294847548008, 'vf_loss': 0.221037613536644, 'total_loss': -0.15778833921506694, 'approx_kl': -0.00278612005058676, 'clip_fraction': 0.078125, 'grad_norm': 21.124588012695312}
2023-01-03 12:04:54.073 DEBUG: Taking gradient step
2023-01-03 12:04:56.316 DEBUG: Loss 2: {'policy_loss': 0.047570477481217656, 'entropy_loss': -0.07207130081951618, 'vf_loss': 0.21001643158132902, 'total_loss': -0.024500823338298533, 'approx_kl': -0.027458704309538007, 'clip_fraction': 0.2291666679084301, 'grad_norm': 23.635746002197266}
2023-01-03 12:04:58.516 DEBUG: Taking gradient step
2023-01-03 12:05:00.761 DEBUG: Loss 3: {'policy_loss': 0.004199592117660779, 'entropy_loss': -0.07182618230581284, 'vf_loss': 0.2014146915475199, 'total_loss': -0.06762659018815206, 'approx_kl': -0.02490620268508792, 'clip_fraction': 0.3502604216337204, 'grad_norm': 24.5369930267334}
2023-01-03 12:05:03.019 DEBUG: Taking gradient step
2023-01-03 12:05:05.264 DEBUG: Loss 4: {'policy_loss': 0.06167002598226506, 'entropy_loss': -0.06993403285741806, 'vf_loss': 0.19118943494171695, 'total_loss': -0.008264006875153003, 'approx_kl': -0.03484202083200216, 'clip_fraction': 0.3515625, 'grad_norm': 20.830501556396484}
2023-01-03 12:05:07.480 DEBUG: Taking gradient step
2023-01-03 12:05:09.706 DEBUG: Loss 5: {'policy_loss': 0.024213281446168758, 'entropy_loss': -0.07058941759169102, 'vf_loss': 0.19605325796542045, 'total_loss': -0.04637613614552226, 'approx_kl': -0.031324819079600275, 'clip_fraction': 0.3893229216337204, 'grad_norm': 21.822721481323242}
2023-01-03 12:05:11.883 DEBUG: Taking gradient step
2023-01-03 12:05:14.430 DEBUG: Loss 6: {'policy_loss': 0.009084983272255102, 'entropy_loss': -0.07090914808213711, 'vf_loss': 0.19605590974277096, 'total_loss': -0.06182416480988201, 'approx_kl': -0.03406815277412534, 'clip_fraction': 0.32421875, 'grad_norm': 18.745861053466797}
2023-01-03 12:05:16.694 DEBUG: Taking gradient step
2023-01-03 12:05:18.929 DEBUG: Loss 7: {'policy_loss': 0.055439020154714566, 'entropy_loss': -0.07089637964963913, 'vf_loss': 0.21468691834137205, 'total_loss': -0.015457359494924557, 'approx_kl': -0.049874487332999706, 'clip_fraction': 0.3697916716337204, 'grad_norm': 24.26719093322754}
2023-01-03 12:05:21.134 DEBUG: Taking gradient step
2023-01-03 12:05:23.348 DEBUG: Loss 8: {'policy_loss': 0.10026128957422739, 'entropy_loss': -0.06929111108183861, 'vf_loss': 0.2278545524586807, 'total_loss': 0.030970178492388784, 'approx_kl': -0.04439889267086983, 'clip_fraction': 0.3971354216337204, 'grad_norm': 18.92790412902832}
2023-01-03 12:05:25.561 DEBUG: Taking gradient step
2023-01-03 12:05:27.791 DEBUG: Loss 9: {'policy_loss': -0.009488301442126944, 'entropy_loss': -0.07020891644060612, 'vf_loss': 0.20759916362816894, 'total_loss': -0.07969721788273307, 'approx_kl': -0.01406205352395773, 'clip_fraction': 0.4869791716337204, 'grad_norm': 16.635879516601562}
2023-01-03 12:05:29.990 DEBUG: Taking gradient step
2023-01-03 12:05:32.249 DEBUG: Loss 10: {'policy_loss': 0.003539751089458018, 'entropy_loss': -0.06892803497612476, 'vf_loss': 0.20913422735439643, 'total_loss': -0.06538828388666675, 'approx_kl': -0.06052183639258146, 'clip_fraction': 0.4739583358168602, 'grad_norm': 21.220550537109375}
2023-01-03 12:05:34.442 DEBUG: Taking gradient step
2023-01-03 12:05:36.824 DEBUG: Loss 11: {'policy_loss': 0.01633701692755405, 'entropy_loss': -0.06947082281112671, 'vf_loss': 0.19976952789505575, 'total_loss': -0.053133805883572666, 'approx_kl': -0.07864425517618656, 'clip_fraction': 0.4869791716337204, 'grad_norm': 21.696931838989258}
2023-01-03 12:05:39.067 DEBUG: Taking gradient step
2023-01-03 12:05:41.326 DEBUG: Loss 12: {'policy_loss': 0.040647847772414133, 'entropy_loss': -0.0677895788103342, 'vf_loss': 0.19862636256160443, 'total_loss': -0.027141731037920072, 'approx_kl': -0.06971586775034666, 'clip_fraction': 0.38671875, 'grad_norm': 21.312244415283203}
2023-01-03 12:05:43.638 DEBUG: Taking gradient step
2023-01-03 12:05:45.912 DEBUG: Loss 13: {'policy_loss': 0.09697122786399653, 'entropy_loss': -0.06742934696376324, 'vf_loss': 0.19444916166476822, 'total_loss': 0.029541880900233283, 'approx_kl': -0.07006764132529497, 'clip_fraction': 0.5481770858168602, 'grad_norm': 23.34420394897461}
2023-01-03 12:05:48.160 DEBUG: Taking gradient step
2023-01-03 12:05:50.424 DEBUG: Loss 14: {'policy_loss': 0.14733196999196194, 'entropy_loss': -0.067587960511446, 'vf_loss': 0.19323887401909098, 'total_loss': 0.07974400948051594, 'approx_kl': -0.0793891791254282, 'clip_fraction': 0.6276041716337204, 'grad_norm': 25.543922424316406}
2023-01-03 12:05:50.425 INFO: Optimization: policy loss=0.147, vf loss=0.193, entropy loss=-0.068, total loss=0.080, num steps=15
2023-01-03 12:05:50.426 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 12:05:51.663 DEBUG: Atoms are too close
2023-01-03 12:05:51.666 INFO: Evaluation rollout: return=-29.864 (0.0), episode length=5.0
2023-01-03 12:05:51.667 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 12:05:51.670 INFO: Iteration: 13/137, steps: 2808
2023-01-03 12:06:01.383 DEBUG: There is a single atom floating around
2023-01-03 12:06:01.718 DEBUG: Atoms are too close
2023-01-03 12:06:02.349 DEBUG: Atoms are too close
2023-01-03 12:06:03.618 DEBUG: Atoms are too close
2023-01-03 12:06:05.479 DEBUG: Atoms are too close
2023-01-03 12:06:05.777 DEBUG: Atoms are too close
2023-01-03 12:06:06.251 DEBUG: Atoms are too close
2023-01-03 12:06:12.797 DEBUG: Atoms are too close
2023-01-03 12:06:17.788 DEBUG: Atoms are too close
2023-01-03 12:06:20.035 DEBUG: Atoms are too close
2023-01-03 12:06:23.672 DEBUG: Atoms are too close
2023-01-03 12:06:24.918 DEBUG: Atoms are too close
2023-01-03 12:06:34.017 DEBUG: Atoms are too close
2023-01-03 12:06:36.122 DEBUG: Atoms are too close
2023-01-03 12:06:36.773 DEBUG: There is a single atom floating around
2023-01-03 12:06:37.906 DEBUG: There is a single atom floating around
2023-01-03 12:06:40.873 DEBUG: Atoms are too close
2023-01-03 12:06:43.779 DEBUG: Atoms are too close
2023-01-03 12:06:48.025 INFO: Training rollout: return=-14.770 (14.8), episode length=5.2
2023-01-03 12:06:48.027 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 12:06:48.030 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-2808_train.pkl
2023-01-03 12:06:50.272 DEBUG: Taking gradient step
2023-01-03 12:06:52.531 DEBUG: Loss 0: {'policy_loss': 0.004034680818157244, 'entropy_loss': -0.06669483985751867, 'vf_loss': 0.18540557771632443, 'total_loss': -0.06266015903936142, 'approx_kl': 1.5910092798776532e-08, 'clip_fraction': 0.0, 'grad_norm': 12.668581008911133}
2023-01-03 12:06:54.755 DEBUG: Taking gradient step
2023-01-03 12:06:57.019 DEBUG: Loss 1: {'policy_loss': -0.04633592338770973, 'entropy_loss': -0.06943554058670998, 'vf_loss': 0.18765636807830471, 'total_loss': -0.1157714639744197, 'approx_kl': -0.01466963381972164, 'clip_fraction': 0.2434895858168602, 'grad_norm': 19.03530502319336}
2023-01-03 12:06:59.351 DEBUG: Taking gradient step
2023-01-03 12:07:01.560 DEBUG: Loss 2: {'policy_loss': -0.012754755939878718, 'entropy_loss': -0.07061446458101273, 'vf_loss': 0.18763615064988437, 'total_loss': -0.08336922052089143, 'approx_kl': -0.028715050779283047, 'clip_fraction': 0.3151041679084301, 'grad_norm': 12.536036491394043}
2023-01-03 12:07:03.721 DEBUG: Taking gradient step
2023-01-03 12:07:05.908 DEBUG: Loss 3: {'policy_loss': 0.015286135109981693, 'entropy_loss': -0.07097029685974121, 'vf_loss': 0.1886488287677039, 'total_loss': -0.05568416174975952, 'approx_kl': -0.013923543505370617, 'clip_fraction': 0.390625, 'grad_norm': 19.458242416381836}
2023-01-03 12:07:08.218 DEBUG: Taking gradient step
2023-01-03 12:07:10.656 DEBUG: Loss 4: {'policy_loss': -0.021918217582753544, 'entropy_loss': -0.0697586964815855, 'vf_loss': 0.18354617044144522, 'total_loss': -0.09167691406433905, 'approx_kl': -0.03473340661730617, 'clip_fraction': 0.4778645858168602, 'grad_norm': 20.216638565063477}
2023-01-03 12:07:12.803 DEBUG: Taking gradient step
2023-01-03 12:07:15.013 DEBUG: Loss 5: {'policy_loss': -0.0010348141484003148, 'entropy_loss': -0.06828788854181767, 'vf_loss': 0.1843504240195208, 'total_loss': -0.06932270269021798, 'approx_kl': -0.047871265560388565, 'clip_fraction': 0.4817708358168602, 'grad_norm': 22.883129119873047}
2023-01-03 12:07:17.157 DEBUG: Taking gradient step
2023-01-03 12:07:19.376 DEBUG: Loss 6: {'policy_loss': 0.0644032293288728, 'entropy_loss': -0.06647615041583776, 'vf_loss': 0.18201230662403867, 'total_loss': -0.0020729210869649545, 'approx_kl': -0.05740470811724663, 'clip_fraction': 0.3984375, 'grad_norm': 11.900944709777832}
2023-01-03 12:07:21.610 DEBUG: Taking gradient step
2023-01-03 12:07:23.824 DEBUG: Loss 7: {'policy_loss': 0.006468362722760045, 'entropy_loss': -0.06434584595263004, 'vf_loss': 0.18448894910606095, 'total_loss': -0.05787748322986999, 'approx_kl': -0.05462153581902385, 'clip_fraction': 0.4283854216337204, 'grad_norm': 12.233257293701172}
2023-01-03 12:07:25.962 DEBUG: Taking gradient step
2023-01-03 12:07:28.260 DEBUG: Loss 8: {'policy_loss': 0.0858510431151999, 'entropy_loss': -0.06375381257385015, 'vf_loss': 0.1894440155856341, 'total_loss': 0.022097230541349745, 'approx_kl': -0.060113714542239904, 'clip_fraction': 0.4205729216337204, 'grad_norm': 26.361488342285156}
2023-01-03 12:07:30.415 DEBUG: Taking gradient step
2023-01-03 12:07:32.865 DEBUG: Loss 9: {'policy_loss': 0.058797650792660264, 'entropy_loss': -0.06548595987260342, 'vf_loss': 0.18446563388442064, 'total_loss': -0.006688309079943153, 'approx_kl': -0.056531707756221294, 'clip_fraction': 0.453125, 'grad_norm': 22.62427520751953}
2023-01-03 12:07:35.211 DEBUG: Taking gradient step
2023-01-03 12:07:37.741 DEBUG: Loss 10: {'policy_loss': 0.04340225318270963, 'entropy_loss': -0.06543587893247604, 'vf_loss': 0.18606745441974148, 'total_loss': -0.022033625749766417, 'approx_kl': -0.08414294477552176, 'clip_fraction': 0.4166666716337204, 'grad_norm': 12.070035934448242}
2023-01-03 12:07:39.924 DEBUG: Taking gradient step
2023-01-03 12:07:42.182 DEBUG: Loss 11: {'policy_loss': 0.04390658179535217, 'entropy_loss': -0.067037558183074, 'vf_loss': 0.187087812114213, 'total_loss': -0.02313097638772182, 'approx_kl': -0.07493614475242794, 'clip_fraction': 0.4427083432674408, 'grad_norm': 20.977527618408203}
2023-01-03 12:07:44.686 DEBUG: Taking gradient step
2023-01-03 12:07:46.893 DEBUG: Loss 12: {'policy_loss': 0.08786352717399044, 'entropy_loss': -0.06730581168085337, 'vf_loss': 0.18543621494660173, 'total_loss': 0.020557715493137077, 'approx_kl': -0.07775261346250772, 'clip_fraction': 0.3932291716337204, 'grad_norm': 15.07243537902832}
2023-01-03 12:07:49.054 DEBUG: Taking gradient step
2023-01-03 12:07:51.369 DEBUG: Loss 13: {'policy_loss': 0.025544059683093066, 'entropy_loss': -0.06781905516982079, 'vf_loss': 0.18062734871027208, 'total_loss': -0.04227499548672772, 'approx_kl': -0.1250992463901639, 'clip_fraction': 0.4140625, 'grad_norm': 12.880366325378418}
2023-01-03 12:07:53.567 DEBUG: Taking gradient step
2023-01-03 12:07:55.773 DEBUG: Loss 14: {'policy_loss': 0.035581225109225144, 'entropy_loss': -0.06692659109830856, 'vf_loss': 0.18212932518441266, 'total_loss': -0.03134536598908342, 'approx_kl': -0.08536266162991524, 'clip_fraction': 0.4036458358168602, 'grad_norm': 17.627635955810547}
2023-01-03 12:07:55.777 INFO: Optimization: policy loss=0.036, vf loss=0.182, entropy loss=-0.067, total loss=-0.031, num steps=15
2023-01-03 12:07:55.779 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 12:07:57.649 INFO: Evaluation rollout: return=0.388 (0.0), episode length=6.0
2023-01-03 12:07:57.650 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 12:07:57.653 INFO: Iteration: 14/137, steps: 3024
2023-01-03 12:08:06.790 DEBUG: There is a single atom floating around
2023-01-03 12:08:11.469 DEBUG: There is a single atom floating around
2023-01-03 12:08:11.768 DEBUG: Atoms are too close
2023-01-03 12:08:15.422 DEBUG: Atoms are too close
2023-01-03 12:08:32.692 DEBUG: Atoms are too close
2023-01-03 12:08:38.285 DEBUG: Atoms are too close
2023-01-03 12:08:41.424 DEBUG: There is a single atom floating around
2023-01-03 12:08:45.746 DEBUG: There is a single atom floating around
2023-01-03 12:08:58.862 DEBUG: Atoms are too close
2023-01-03 12:08:58.931 INFO: Training rollout: return=-7.041 (13.1), episode length=5.7
2023-01-03 12:08:58.932 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 12:08:58.935 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-3024_train.pkl
2023-01-03 12:09:01.240 DEBUG: Taking gradient step
2023-01-03 12:09:03.605 DEBUG: Loss 0: {'policy_loss': 0.01980301705948937, 'entropy_loss': -0.06951410416513681, 'vf_loss': 0.1963926239876026, 'total_loss': -0.04971108710564745, 'approx_kl': -1.4920564339604425e-08, 'clip_fraction': 0.0, 'grad_norm': 23.490861892700195}
2023-01-03 12:09:05.893 DEBUG: Taking gradient step
2023-01-03 12:09:08.286 DEBUG: Loss 1: {'policy_loss': 0.02048879828513482, 'entropy_loss': -0.07144088670611382, 'vf_loss': 0.18913768316119106, 'total_loss': -0.05095208842097901, 'approx_kl': -0.04312009271234274, 'clip_fraction': 0.2747395858168602, 'grad_norm': 32.38271713256836}
2023-01-03 12:09:10.704 DEBUG: Taking gradient step
2023-01-03 12:09:13.039 DEBUG: Loss 2: {'policy_loss': 0.16309319385409138, 'entropy_loss': -0.0715626459568739, 'vf_loss': 0.1930157135263374, 'total_loss': 0.09153054789721748, 'approx_kl': -0.031157515943050385, 'clip_fraction': 0.4609375, 'grad_norm': 51.950218200683594}
2023-01-03 12:09:15.303 DEBUG: Taking gradient step
2023-01-03 12:09:17.659 DEBUG: Loss 3: {'policy_loss': 0.08633042459530935, 'entropy_loss': -0.07219696044921875, 'vf_loss': 0.17297041411827244, 'total_loss': 0.014133464146090596, 'approx_kl': -0.07756706653162837, 'clip_fraction': 0.5559895932674408, 'grad_norm': 40.909332275390625}
2023-01-03 12:09:20.125 DEBUG: Taking gradient step
2023-01-03 12:09:22.445 DEBUG: Loss 4: {'policy_loss': 0.06870796917663781, 'entropy_loss': -0.07194493524730206, 'vf_loss': 0.1648908690725554, 'total_loss': -0.003236966070664246, 'approx_kl': -0.03315991489216685, 'clip_fraction': 0.5299479216337204, 'grad_norm': 22.135459899902344}
2023-01-03 12:09:24.715 DEBUG: Taking gradient step
2023-01-03 12:09:27.136 DEBUG: Loss 5: {'policy_loss': 0.050379877129176846, 'entropy_loss': -0.07418998144567013, 'vf_loss': 0.15335539198647702, 'total_loss': -0.023810104316493278, 'approx_kl': -0.05871906690299511, 'clip_fraction': 0.5807291716337204, 'grad_norm': 15.312145233154297}
2023-01-03 12:09:29.420 DEBUG: Taking gradient step
2023-01-03 12:09:31.984 DEBUG: Loss 6: {'policy_loss': 0.09943936036270667, 'entropy_loss': -0.07302610203623772, 'vf_loss': 0.14838272389482846, 'total_loss': 0.026413258326468965, 'approx_kl': -0.021798054687678814, 'clip_fraction': 0.515625, 'grad_norm': 22.21975326538086}
2023-01-03 12:09:34.273 DEBUG: Taking gradient step
2023-01-03 12:09:36.629 DEBUG: Loss 7: {'policy_loss': 0.18669090729810148, 'entropy_loss': -0.07263001799583435, 'vf_loss': 0.15545491194086197, 'total_loss': 0.11406088930226713, 'approx_kl': -0.027153898030519485, 'clip_fraction': 0.5078125, 'grad_norm': 44.546630859375}
2023-01-03 12:09:38.909 DEBUG: Taking gradient step
2023-01-03 12:09:41.204 DEBUG: Loss 8: {'policy_loss': 0.10282029922225117, 'entropy_loss': -0.07236169837415218, 'vf_loss': 0.1457052379350854, 'total_loss': 0.03045860084809898, 'approx_kl': -0.011595487594604492, 'clip_fraction': 0.5455729216337204, 'grad_norm': 15.427511215209961}
2023-01-03 12:09:43.462 DEBUG: Taking gradient step
2023-01-03 12:09:45.861 DEBUG: Loss 9: {'policy_loss': 0.08759911545487803, 'entropy_loss': -0.07164343073964119, 'vf_loss': 0.140821050983224, 'total_loss': 0.01595568471523684, 'approx_kl': 0.00910540483891964, 'clip_fraction': 0.5390625, 'grad_norm': 12.274955749511719}
2023-01-03 12:09:48.123 DEBUG: Taking gradient step
2023-01-03 12:09:50.426 DEBUG: Loss 10: {'policy_loss': 0.09453805617741856, 'entropy_loss': -0.07190298661589622, 'vf_loss': 0.1360737489947657, 'total_loss': 0.022635069561522336, 'approx_kl': -0.050573064014315605, 'clip_fraction': 0.5546875, 'grad_norm': 16.557716369628906}
2023-01-03 12:09:52.701 DEBUG: Taking gradient step
2023-01-03 12:09:55.025 DEBUG: Loss 11: {'policy_loss': 0.21292982268762412, 'entropy_loss': -0.07034510001540184, 'vf_loss': 0.1518591860873217, 'total_loss': 0.14258472267222227, 'approx_kl': -0.009225770831108093, 'clip_fraction': 0.5442708432674408, 'grad_norm': 31.107608795166016}
2023-01-03 12:09:57.377 DEBUG: Taking gradient step
2023-01-03 12:09:59.803 DEBUG: Loss 12: {'policy_loss': 0.2449869406962893, 'entropy_loss': -0.07131500542163849, 'vf_loss': 0.1438885298396192, 'total_loss': 0.1736719352746508, 'approx_kl': -0.06676484039053321, 'clip_fraction': 0.62109375, 'grad_norm': 44.94913101196289}
2023-01-03 12:10:02.065 DEBUG: Taking gradient step
2023-01-03 12:10:04.631 DEBUG: Loss 13: {'policy_loss': 0.20502880933132106, 'entropy_loss': -0.07293490320444107, 'vf_loss': 0.12851038080134064, 'total_loss': 0.13209390612688, 'approx_kl': -0.09629029408097267, 'clip_fraction': 0.6341145932674408, 'grad_norm': 49.35587692260742}
2023-01-03 12:10:06.930 DEBUG: Taking gradient step
2023-01-03 12:10:09.326 DEBUG: Loss 14: {'policy_loss': 0.20287011989484646, 'entropy_loss': -0.07244164869189262, 'vf_loss': 0.15123202185806814, 'total_loss': 0.1304284712029538, 'approx_kl': -0.09747802466154099, 'clip_fraction': 0.5833333358168602, 'grad_norm': 42.69935989379883}
2023-01-03 12:10:09.326 INFO: Optimization: policy loss=0.203, vf loss=0.151, entropy loss=-0.072, total loss=0.130, num steps=15
2023-01-03 12:10:09.328 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 12:10:10.200 DEBUG: Atoms are too close
2023-01-03 12:10:10.202 INFO: Evaluation rollout: return=-29.413 (0.0), episode length=4.0
2023-01-03 12:10:10.203 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 12:10:10.205 INFO: Iteration: 15/137, steps: 3240
2023-01-03 12:10:17.439 DEBUG: There is a single atom floating around
2023-01-03 12:10:21.503 DEBUG: There is a single atom floating around
2023-01-03 12:10:22.185 DEBUG: Atoms are too close
2023-01-03 12:10:28.257 DEBUG: Atoms are too close
2023-01-03 12:10:29.509 DEBUG: Atoms are too close
2023-01-03 12:10:29.510 DEBUG: Atoms are too close
2023-01-03 12:10:30.233 DEBUG: Atoms are too close
2023-01-03 12:10:37.982 DEBUG: There is a single atom floating around
2023-01-03 12:10:39.724 DEBUG: There is a single atom floating around
2023-01-03 12:10:41.027 DEBUG: Atoms are too close
2023-01-03 12:10:43.363 DEBUG: Atoms are too close
2023-01-03 12:10:48.271 DEBUG: Atoms are too close
2023-01-03 12:10:49.001 DEBUG: There is a single atom floating around
2023-01-03 12:10:53.084 DEBUG: Atoms are too close
2023-01-03 12:10:53.412 DEBUG: Atoms are too close
2023-01-03 12:10:53.413 DEBUG: Atoms are too close
2023-01-03 12:10:54.435 DEBUG: There is a single atom floating around
2023-01-03 12:11:00.394 DEBUG: There is a single atom floating around
2023-01-03 12:11:01.427 DEBUG: There is a single atom floating around
2023-01-03 12:11:05.758 DEBUG: Atoms are too close
2023-01-03 12:11:07.490 INFO: Training rollout: return=-15.004 (15.1), episode length=5.1
2023-01-03 12:11:07.491 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 12:11:07.494 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-3240_train.pkl
2023-01-03 12:11:09.707 DEBUG: Taking gradient step
2023-01-03 12:11:11.909 DEBUG: Loss 0: {'policy_loss': 0.013801247537355968, 'entropy_loss': -0.06684578023850918, 'vf_loss': 0.25747332495758246, 'total_loss': -0.05304453270115321, 'approx_kl': 1.1461088433861732e-07, 'clip_fraction': 0.0, 'grad_norm': 19.55759048461914}
2023-01-03 12:11:14.082 DEBUG: Taking gradient step
2023-01-03 12:11:16.353 DEBUG: Loss 1: {'policy_loss': 0.022085130281479536, 'entropy_loss': -0.06793488003313541, 'vf_loss': 0.2515649355278105, 'total_loss': -0.04584974975165588, 'approx_kl': -0.011945474660024047, 'clip_fraction': 0.2643229216337204, 'grad_norm': 19.238656997680664}
2023-01-03 12:11:18.501 DEBUG: Taking gradient step
2023-01-03 12:11:20.706 DEBUG: Loss 2: {'policy_loss': 0.10235107483913083, 'entropy_loss': -0.06567336153239012, 'vf_loss': 0.2500810462501811, 'total_loss': 0.03667771330674073, 'approx_kl': -0.020186485024169087, 'clip_fraction': 0.41015625, 'grad_norm': 32.175052642822266}
2023-01-03 12:11:22.968 DEBUG: Taking gradient step
2023-01-03 12:11:25.182 DEBUG: Loss 3: {'policy_loss': 0.11025074508562602, 'entropy_loss': -0.0661045927554369, 'vf_loss': 0.2407188501046695, 'total_loss': 0.0441461523301891, 'approx_kl': -0.004946891218423843, 'clip_fraction': 0.5182291716337204, 'grad_norm': 35.2076416015625}
2023-01-03 12:11:27.354 DEBUG: Taking gradient step
2023-01-03 12:11:29.588 DEBUG: Loss 4: {'policy_loss': 0.13792965053098644, 'entropy_loss': -0.06631614454090595, 'vf_loss': 0.24283735241557564, 'total_loss': 0.07161350599008046, 'approx_kl': -0.011464998126029968, 'clip_fraction': 0.54296875, 'grad_norm': 29.6302547454834}
2023-01-03 12:11:31.844 DEBUG: Taking gradient step
2023-01-03 12:11:34.051 DEBUG: Loss 5: {'policy_loss': 0.17882390181036398, 'entropy_loss': -0.06452762242406607, 'vf_loss': 0.24611641502329357, 'total_loss': 0.11429627938629791, 'approx_kl': -0.033045356161892414, 'clip_fraction': 0.5651041716337204, 'grad_norm': 26.277790069580078}
2023-01-03 12:11:36.257 DEBUG: Taking gradient step
2023-01-03 12:11:38.467 DEBUG: Loss 6: {'policy_loss': 0.07890090497622153, 'entropy_loss': -0.06387671362608671, 'vf_loss': 0.23334322865954593, 'total_loss': 0.01502419135013481, 'approx_kl': -0.024561598198488355, 'clip_fraction': 0.4908854216337204, 'grad_norm': 29.68207359313965}
2023-01-03 12:11:40.694 DEBUG: Taking gradient step
2023-01-03 12:11:43.201 DEBUG: Loss 7: {'policy_loss': 0.08159431096669628, 'entropy_loss': -0.06406865548342466, 'vf_loss': 0.22186313756450574, 'total_loss': 0.017525655483271608, 'approx_kl': -0.03652210044674575, 'clip_fraction': 0.4661458432674408, 'grad_norm': 22.792510986328125}
2023-01-03 12:11:45.377 DEBUG: Taking gradient step
2023-01-03 12:11:47.576 DEBUG: Loss 8: {'policy_loss': 0.1214965778078928, 'entropy_loss': -0.0653885267674923, 'vf_loss': 0.21562445748262413, 'total_loss': 0.056108051040400515, 'approx_kl': -0.04773073364049196, 'clip_fraction': 0.4739583358168602, 'grad_norm': 34.46242141723633}
2023-01-03 12:11:49.761 DEBUG: Taking gradient step
2023-01-03 12:11:51.964 DEBUG: Loss 9: {'policy_loss': 0.22986282343623957, 'entropy_loss': -0.06471578311175108, 'vf_loss': 0.19860804626623332, 'total_loss': 0.1651470403244885, 'approx_kl': -0.05109240161255002, 'clip_fraction': 0.45703125, 'grad_norm': 77.16934204101562}
2023-01-03 12:11:54.186 DEBUG: Taking gradient step
2023-01-03 12:11:56.422 DEBUG: Loss 10: {'policy_loss': 0.21385997452481284, 'entropy_loss': -0.06529072299599648, 'vf_loss': 0.19943056179296895, 'total_loss': 0.1485692515288164, 'approx_kl': -0.003368993289768696, 'clip_fraction': 0.5065104216337204, 'grad_norm': 32.08696365356445}
2023-01-03 12:11:58.681 DEBUG: Taking gradient step
2023-01-03 12:12:00.903 DEBUG: Loss 11: {'policy_loss': 0.14254570449165876, 'entropy_loss': -0.06343846395611763, 'vf_loss': 0.19177876474338795, 'total_loss': 0.0791072405355411, 'approx_kl': -0.01893930067308247, 'clip_fraction': 0.5169270858168602, 'grad_norm': 24.346092224121094}
2023-01-03 12:12:03.108 DEBUG: Taking gradient step
2023-01-03 12:12:05.335 DEBUG: Loss 12: {'policy_loss': 0.13805696790830715, 'entropy_loss': -0.06530277617275715, 'vf_loss': 0.18395451770052107, 'total_loss': 0.07275419173554999, 'approx_kl': -0.021122292149811983, 'clip_fraction': 0.4791666716337204, 'grad_norm': 26.663801193237305}
2023-01-03 12:12:07.536 DEBUG: Early stopping at step 13 for reaching max KL.
2023-01-03 12:12:07.537 INFO: Optimization: policy loss=0.138, vf loss=0.184, entropy loss=-0.065, total loss=0.073, num steps=13
2023-01-03 12:12:07.538 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 12:12:09.534 INFO: Evaluation rollout: return=0.056 (0.0), episode length=6.0
2023-01-03 12:12:09.535 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 12:12:09.538 INFO: Iteration: 16/137, steps: 3456
2023-01-03 12:12:18.071 DEBUG: There is a single atom floating around
2023-01-03 12:12:21.843 DEBUG: There is a single atom floating around
2023-01-03 12:12:22.893 DEBUG: Atoms are too close
2023-01-03 12:12:23.231 DEBUG: Atoms are too close
2023-01-03 12:12:23.860 DEBUG: Atoms are too close
2023-01-03 12:12:26.396 DEBUG: Atoms are too close
2023-01-03 12:12:30.129 DEBUG: Atoms are too close
2023-01-03 12:12:41.908 DEBUG: Atoms are too close
2023-01-03 12:12:42.004 DEBUG: Atoms are too close
2023-01-03 12:12:42.005 DEBUG: There is a single atom floating around
2023-01-03 12:12:42.969 DEBUG: Atoms are too close
2023-01-03 12:12:42.970 DEBUG: Atoms are too close
2023-01-03 12:12:54.405 DEBUG: Atoms are too close
2023-01-03 12:12:54.736 DEBUG: There is a single atom floating around
2023-01-03 12:12:55.378 DEBUG: Atoms are too close
2023-01-03 12:12:55.975 DEBUG: There is a single atom floating around
2023-01-03 12:12:57.613 DEBUG: Atoms are too close
2023-01-03 12:13:00.622 DEBUG: There is a single atom floating around
2023-01-03 12:13:01.784 DEBUG: Atoms are too close
2023-01-03 12:13:05.920 INFO: Training rollout: return=-14.936 (15.1), episode length=5.2
2023-01-03 12:13:05.922 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 12:13:05.925 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-3456_train.pkl
2023-01-03 12:13:08.099 DEBUG: Taking gradient step
2023-01-03 12:13:10.328 DEBUG: Loss 0: {'policy_loss': -0.0017536299476459119, 'entropy_loss': -0.06496104970574379, 'vf_loss': 0.19191413210188918, 'total_loss': -0.0667146796533897, 'approx_kl': -6.24374187907506e-08, 'clip_fraction': 0.0, 'grad_norm': 11.688433647155762}
2023-01-03 12:13:12.473 DEBUG: Taking gradient step
2023-01-03 12:13:14.653 DEBUG: Loss 1: {'policy_loss': 0.07568160597412234, 'entropy_loss': -0.06352542340755463, 'vf_loss': 0.19917784340928016, 'total_loss': 0.012156182566567697, 'approx_kl': 0.035107923205941916, 'clip_fraction': 0.33984375, 'grad_norm': 18.92495346069336}
2023-01-03 12:13:16.906 DEBUG: Early stopping at step 2 for reaching max KL.
2023-01-03 12:13:16.907 INFO: Optimization: policy loss=0.076, vf loss=0.199, entropy loss=-0.064, total loss=0.012, num steps=2
2023-01-03 12:13:16.908 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 12:13:18.796 INFO: Evaluation rollout: return=0.306 (0.0), episode length=6.0
2023-01-03 12:13:18.797 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 12:13:18.799 INFO: Iteration: 17/137, steps: 3672
2023-01-03 12:13:30.576 DEBUG: Atoms are too close
2023-01-03 12:13:30.916 DEBUG: Atoms are too close
2023-01-03 12:13:31.659 DEBUG: Atoms are too close
2023-01-03 12:13:32.954 DEBUG: Atoms are too close
2023-01-03 12:13:32.955 DEBUG: Atoms are too close
2023-01-03 12:13:33.102 DEBUG: There is a single atom floating around
2023-01-03 12:13:34.152 DEBUG: Atoms are too close
2023-01-03 12:13:39.848 DEBUG: There is a single atom floating around
2023-01-03 12:13:53.509 DEBUG: Atoms are too close
2023-01-03 12:13:54.702 DEBUG: Atoms are too close
2023-01-03 12:13:55.007 DEBUG: Atoms are too close
2023-01-03 12:14:08.197 DEBUG: Atoms are too close
2023-01-03 12:14:08.826 DEBUG: Atoms are too close
2023-01-03 12:14:09.759 DEBUG: There is a single atom floating around
2023-01-03 12:14:12.061 DEBUG: Atoms are too close
2023-01-03 12:14:12.716 DEBUG: Atoms are too close
2023-01-03 12:14:13.125 DEBUG: Atoms are too close
2023-01-03 12:14:16.172 INFO: Training rollout: return=-13.195 (15.0), episode length=5.5
2023-01-03 12:14:16.174 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 12:14:16.177 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-3672_train.pkl
2023-01-03 12:14:18.437 DEBUG: Taking gradient step
2023-01-03 12:14:20.718 DEBUG: Loss 0: {'policy_loss': -0.048240071699113846, 'entropy_loss': -0.06494528986513615, 'vf_loss': 0.23688416213063657, 'total_loss': -0.11318536156424999, 'approx_kl': -7.25655506794709e-08, 'clip_fraction': 0.0, 'grad_norm': 13.093596458435059}
2023-01-03 12:14:22.923 DEBUG: Early stopping at step 1 for reaching max KL.
2023-01-03 12:14:22.923 INFO: Optimization: policy loss=-0.048, vf loss=0.237, entropy loss=-0.065, total loss=-0.113, num steps=1
2023-01-03 12:14:22.924 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 12:14:24.486 DEBUG: Atoms are too close
2023-01-03 12:14:24.488 INFO: Evaluation rollout: return=-29.605 (0.0), episode length=6.0
2023-01-03 12:14:24.489 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 12:14:24.491 INFO: Iteration: 18/137, steps: 3888
2023-01-03 12:14:32.581 DEBUG: There is a single atom floating around
2023-01-03 12:14:37.694 DEBUG: Atoms are too close
2023-01-03 12:14:39.958 DEBUG: Atoms are too close
2023-01-03 12:14:39.959 DEBUG: Atoms are too close
2023-01-03 12:14:43.711 DEBUG: There is a single atom floating around
2023-01-03 12:14:54.615 DEBUG: Atoms are too close
2023-01-03 12:14:55.270 DEBUG: Atoms are too close
2023-01-03 12:14:56.710 DEBUG: Atoms are too close
2023-01-03 12:14:56.802 DEBUG: Atoms are too close
2023-01-03 12:14:56.802 DEBUG: Atoms are too close
2023-01-03 12:14:57.263 DEBUG: Atoms are too close
2023-01-03 12:14:58.108 DEBUG: There is a single atom floating around
2023-01-03 12:14:59.776 DEBUG: Atoms are too close
2023-01-03 12:15:01.185 DEBUG: Atoms are too close
2023-01-03 12:15:09.043 DEBUG: There is a single atom floating around
2023-01-03 12:15:12.093 DEBUG: Atoms are too close
2023-01-03 12:15:15.860 DEBUG: There is a single atom floating around
2023-01-03 12:15:17.468 DEBUG: Atoms are too close
2023-01-03 12:15:17.469 DEBUG: Atoms are too close
2023-01-03 12:15:20.743 DEBUG: Atoms are too close
2023-01-03 12:15:21.153 INFO: Training rollout: return=-16.464 (15.1), episode length=5.5
2023-01-03 12:15:21.154 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 12:15:21.158 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-3888_train.pkl
2023-01-03 12:15:23.392 DEBUG: Taking gradient step
2023-01-03 12:15:25.695 DEBUG: Loss 0: {'policy_loss': 0.01110774802129971, 'entropy_loss': -0.0642595887184143, 'vf_loss': 0.24209233457649476, 'total_loss': -0.0531518406971146, 'approx_kl': -9.352030705400693e-09, 'clip_fraction': 0.0, 'grad_norm': 14.084663391113281}
2023-01-03 12:15:28.050 DEBUG: Taking gradient step
2023-01-03 12:15:30.315 DEBUG: Loss 1: {'policy_loss': 0.03738911767149668, 'entropy_loss': -0.06407688464969397, 'vf_loss': 0.23862581857934215, 'total_loss': -0.026687766978197285, 'approx_kl': 0.004510764265432954, 'clip_fraction': 0.2252604179084301, 'grad_norm': 19.23358726501465}
2023-01-03 12:15:32.581 DEBUG: Taking gradient step
2023-01-03 12:15:34.846 DEBUG: Loss 2: {'policy_loss': 0.0703403906653659, 'entropy_loss': -0.06316993199288845, 'vf_loss': 0.24271029008988138, 'total_loss': 0.00717045867247746, 'approx_kl': 0.013054451672360301, 'clip_fraction': 0.359375, 'grad_norm': 18.52927017211914}
2023-01-03 12:15:37.057 DEBUG: Early stopping at step 3 for reaching max KL.
2023-01-03 12:15:37.058 INFO: Optimization: policy loss=0.070, vf loss=0.243, entropy loss=-0.063, total loss=0.007, num steps=3
2023-01-03 12:15:37.059 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 12:15:38.968 INFO: Evaluation rollout: return=0.881 (0.0), episode length=6.0
2023-01-03 12:15:38.969 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 12:15:38.972 INFO: Iteration: 19/137, steps: 4104
2023-01-03 12:15:53.020 DEBUG: Atoms are too close
2023-01-03 12:15:53.631 DEBUG: Atoms are too close
2023-01-03 12:15:55.984 DEBUG: Atoms are too close
2023-01-03 12:15:56.142 DEBUG: Atoms are too close
2023-01-03 12:15:57.280 DEBUG: Atoms are too close
2023-01-03 12:15:57.281 DEBUG: Atoms are too close
2023-01-03 12:16:09.226 DEBUG: Atoms are too close
2023-01-03 12:16:12.451 DEBUG: Atoms are too close
2023-01-03 12:16:13.541 DEBUG: There is a single atom floating around
2023-01-03 12:16:16.341 DEBUG: Atoms are too close
2023-01-03 12:16:17.422 DEBUG: Atoms are too close
2023-01-03 12:16:28.156 DEBUG: There is a single atom floating around
2023-01-03 12:16:32.705 DEBUG: Atoms are too close
2023-01-03 12:16:34.529 DEBUG: Atoms are too close
2023-01-03 12:16:37.143 DEBUG: Atoms are too close
2023-01-03 12:16:37.376 INFO: Training rollout: return=-12.228 (14.8), episode length=5.8
2023-01-03 12:16:37.378 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 12:16:37.380 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-4104_train.pkl
2023-01-03 12:16:39.756 DEBUG: Taking gradient step
2023-01-03 12:16:42.079 DEBUG: Loss 0: {'policy_loss': -0.010736774543641903, 'entropy_loss': -0.06396550312638283, 'vf_loss': 0.22426039394029484, 'total_loss': -0.07470227767002473, 'approx_kl': 4.9088460407631374e-08, 'clip_fraction': 0.0, 'grad_norm': 17.295766830444336}
2023-01-03 12:16:44.337 DEBUG: Early stopping at step 1 for reaching max KL.
2023-01-03 12:16:44.337 INFO: Optimization: policy loss=-0.011, vf loss=0.224, entropy loss=-0.064, total loss=-0.075, num steps=1
2023-01-03 12:16:44.338 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 12:16:46.422 INFO: Evaluation rollout: return=0.796 (0.0), episode length=6.0
2023-01-03 12:16:46.423 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 12:16:46.426 INFO: Iteration: 20/137, steps: 4320
2023-01-03 12:16:53.138 DEBUG: Atoms are too close
2023-01-03 12:16:53.795 DEBUG: There is a single atom floating around
2023-01-03 12:16:58.579 DEBUG: Atoms are too close
2023-01-03 12:16:59.332 DEBUG: Atoms are too close
2023-01-03 12:17:02.480 DEBUG: Atoms are too close
2023-01-03 12:17:03.932 DEBUG: Atoms are too close
2023-01-03 12:17:03.933 DEBUG: There is a single atom floating around
2023-01-03 12:17:08.548 DEBUG: Atoms are too close
2023-01-03 12:17:12.924 DEBUG: Atoms are too close
2023-01-03 12:17:16.261 DEBUG: Atoms are too close
2023-01-03 12:17:18.129 DEBUG: Atoms are too close
2023-01-03 12:17:19.091 DEBUG: Atoms are too close
2023-01-03 12:17:23.400 DEBUG: Atoms are too close
2023-01-03 12:17:23.401 DEBUG: Atoms are too close
2023-01-03 12:17:31.926 DEBUG: Atoms are too close
2023-01-03 12:17:32.229 DEBUG: Atoms are too close
2023-01-03 12:17:32.848 DEBUG: There is a single atom floating around
2023-01-03 12:17:33.840 DEBUG: There is a single atom floating around
2023-01-03 12:17:33.841 DEBUG: There is a single atom floating around
2023-01-03 12:17:35.868 DEBUG: Atoms are too close
2023-01-03 12:17:37.683 DEBUG: There is a single atom floating around
2023-01-03 12:17:39.698 DEBUG: There is a single atom floating around
2023-01-03 12:17:42.075 INFO: Training rollout: return=-17.343 (14.7), episode length=5.3
2023-01-03 12:17:42.077 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 12:17:42.079 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-4320_train.pkl
2023-01-03 12:17:44.337 DEBUG: Taking gradient step
2023-01-03 12:17:46.582 DEBUG: Loss 0: {'policy_loss': -0.03232415176059697, 'entropy_loss': -0.0609132144600153, 'vf_loss': 0.22323753362473672, 'total_loss': -0.09323736622061227, 'approx_kl': -1.16803375860286e-08, 'clip_fraction': 0.0, 'grad_norm': 24.310712814331055}
2023-01-03 12:17:48.762 DEBUG: Early stopping at step 1 for reaching max KL.
2023-01-03 12:17:48.763 INFO: Optimization: policy loss=-0.032, vf loss=0.223, entropy loss=-0.061, total loss=-0.093, num steps=1
2023-01-03 12:17:48.763 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 12:17:50.676 INFO: Evaluation rollout: return=0.854 (0.0), episode length=6.0
2023-01-03 12:17:50.679 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 12:17:50.682 DEBUG: Deleting old model: runs/CH3NO_dna/models/CH3NO_dna_run-1_steps-2376.model
2023-01-03 12:17:50.686 DEBUG: Saving model: runs/CH3NO_dna/models/CH3NO_dna_run-1_steps-4536.model
2023-01-03 12:17:50.739 INFO: Iteration: 21/137, steps: 4536
2023-01-03 12:18:05.416 DEBUG: Atoms are too close
2023-01-03 12:18:06.365 DEBUG: Atoms are too close
2023-01-03 12:18:07.294 DEBUG: Atoms are too close
2023-01-03 12:18:08.544 DEBUG: Atoms are too close
2023-01-03 12:18:09.372 DEBUG: Atoms are too close
2023-01-03 12:18:09.373 DEBUG: Atoms are too close
2023-01-03 12:18:09.373 DEBUG: Atoms are too close
2023-01-03 12:18:16.885 DEBUG: There is a single atom floating around
2023-01-03 12:18:19.532 DEBUG: Atoms are too close
2023-01-03 12:18:19.861 DEBUG: Atoms are too close
2023-01-03 12:18:21.957 DEBUG: Atoms are too close
2023-01-03 12:18:25.374 DEBUG: Atoms are too close
2023-01-03 12:18:36.049 DEBUG: Atoms are too close
2023-01-03 12:18:38.905 DEBUG: Atoms are too close
2023-01-03 12:18:43.886 DEBUG: There is a single atom floating around
2023-01-03 12:18:45.805 DEBUG: Atoms are too close
2023-01-03 12:18:48.479 DEBUG: Atoms are too close
2023-01-03 12:18:49.034 INFO: Training rollout: return=-13.773 (14.9), episode length=5.6
2023-01-03 12:18:49.035 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 12:18:49.038 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-4536_train.pkl
2023-01-03 12:18:51.309 DEBUG: Taking gradient step
2023-01-03 12:18:53.609 DEBUG: Loss 0: {'policy_loss': 0.03881504152438202, 'entropy_loss': -0.06179835740476847, 'vf_loss': 0.20626032152190868, 'total_loss': -0.02298331588038645, 'approx_kl': -7.101334631443024e-08, 'clip_fraction': 0.0, 'grad_norm': 14.667709350585938}
2023-01-03 12:18:55.845 DEBUG: Taking gradient step
2023-01-03 12:18:58.122 DEBUG: Loss 1: {'policy_loss': 0.002645986166818083, 'entropy_loss': -0.061991301365196705, 'vf_loss': 0.2032197415505843, 'total_loss': -0.05934531519837862, 'approx_kl': 0.009045909158885479, 'clip_fraction': 0.31640625, 'grad_norm': 16.9238224029541}
2023-01-03 12:19:00.479 DEBUG: Taking gradient step
2023-01-03 12:19:02.759 DEBUG: Loss 2: {'policy_loss': 0.05864203409702453, 'entropy_loss': -0.06177999544888735, 'vf_loss': 0.20710701279260768, 'total_loss': -0.003137961351862832, 'approx_kl': 0.023333040066063404, 'clip_fraction': 0.4127604216337204, 'grad_norm': 21.506568908691406}
2023-01-03 12:19:05.075 DEBUG: Taking gradient step
2023-01-03 12:19:07.354 DEBUG: Loss 3: {'policy_loss': 0.014707511485559883, 'entropy_loss': -0.061802420765161514, 'vf_loss': 0.20673507215846923, 'total_loss': -0.047094909279601624, 'approx_kl': 0.0367566361092031, 'clip_fraction': 0.50390625, 'grad_norm': 17.205190658569336}
2023-01-03 12:19:09.599 DEBUG: Taking gradient step
2023-01-03 12:19:11.891 DEBUG: Loss 4: {'policy_loss': 0.05306227030204592, 'entropy_loss': -0.059688810259103775, 'vf_loss': 0.20895884628343658, 'total_loss': -0.006626539957057857, 'approx_kl': 0.012839968781918287, 'clip_fraction': 0.4856770858168602, 'grad_norm': 14.993949890136719}
2023-01-03 12:19:14.121 DEBUG: Taking gradient step
2023-01-03 12:19:16.397 DEBUG: Loss 5: {'policy_loss': 0.03763306221461671, 'entropy_loss': -0.0585670555010438, 'vf_loss': 0.20518103705022525, 'total_loss': -0.02093399328642708, 'approx_kl': 0.0015618540346622467, 'clip_fraction': 0.5533854216337204, 'grad_norm': 11.550597190856934}
2023-01-03 12:19:18.618 DEBUG: Taking gradient step
2023-01-03 12:19:20.936 DEBUG: Loss 6: {'policy_loss': 0.018505878049850856, 'entropy_loss': -0.05838631931692362, 'vf_loss': 0.19891490009519808, 'total_loss': -0.03988044126707276, 'approx_kl': -0.0007600490935146809, 'clip_fraction': 0.5130208358168602, 'grad_norm': 15.882454872131348}
2023-01-03 12:19:23.327 DEBUG: Taking gradient step
2023-01-03 12:19:25.570 DEBUG: Loss 7: {'policy_loss': 0.02018893832291519, 'entropy_loss': -0.05941866151988506, 'vf_loss': 0.20612906465347464, 'total_loss': -0.03922972319696987, 'approx_kl': -0.012144519481807947, 'clip_fraction': 0.38671875, 'grad_norm': 21.301939010620117}
2023-01-03 12:19:27.840 DEBUG: Taking gradient step
2023-01-03 12:19:30.111 DEBUG: Loss 8: {'policy_loss': 0.04503843902020223, 'entropy_loss': -0.059632619842886925, 'vf_loss': 0.2092586416344699, 'total_loss': -0.014594180822684696, 'approx_kl': -0.02881162241101265, 'clip_fraction': 0.3919270858168602, 'grad_norm': 13.392012596130371}
2023-01-03 12:19:32.439 DEBUG: Taking gradient step
2023-01-03 12:19:34.693 DEBUG: Loss 9: {'policy_loss': -0.01192532607646099, 'entropy_loss': -0.058403873816132545, 'vf_loss': 0.20052993847594225, 'total_loss': -0.07032919989259354, 'approx_kl': -0.032321066595613956, 'clip_fraction': 0.3359375, 'grad_norm': 8.899541854858398}
2023-01-03 12:19:36.987 DEBUG: Taking gradient step
2023-01-03 12:19:39.310 DEBUG: Loss 10: {'policy_loss': 0.02172750038658075, 'entropy_loss': -0.060720110312104225, 'vf_loss': 0.19900890803160481, 'total_loss': -0.03899260992552347, 'approx_kl': -0.046509940177202225, 'clip_fraction': 0.3697916716337204, 'grad_norm': 22.157981872558594}
2023-01-03 12:19:41.688 DEBUG: Taking gradient step
2023-01-03 12:19:43.932 DEBUG: Loss 11: {'policy_loss': 0.062054184356090204, 'entropy_loss': -0.05884723272174597, 'vf_loss': 0.2062309586824234, 'total_loss': 0.003206951634344247, 'approx_kl': -0.05461205542087555, 'clip_fraction': 0.4622395858168602, 'grad_norm': 19.033634185791016}
2023-01-03 12:19:46.190 DEBUG: Taking gradient step
2023-01-03 12:19:48.730 DEBUG: Loss 12: {'policy_loss': 0.06973608165224557, 'entropy_loss': -0.05915299989283085, 'vf_loss': 0.20357943264596803, 'total_loss': 0.01058308175941472, 'approx_kl': -0.06795268226414919, 'clip_fraction': 0.48828125, 'grad_norm': 9.336359024047852}
2023-01-03 12:19:50.967 DEBUG: Taking gradient step
2023-01-03 12:19:53.229 DEBUG: Loss 13: {'policy_loss': 0.09922674566112602, 'entropy_loss': -0.06074052955955267, 'vf_loss': 0.2042872877979287, 'total_loss': 0.038486216101573344, 'approx_kl': -0.06399844028055668, 'clip_fraction': 0.4296875, 'grad_norm': 16.81915855407715}
2023-01-03 12:19:55.473 DEBUG: Taking gradient step
2023-01-03 12:19:57.816 DEBUG: Loss 14: {'policy_loss': 0.048453349097890175, 'entropy_loss': -0.05962043721228838, 'vf_loss': 0.20508225153753284, 'total_loss': -0.011167088114398205, 'approx_kl': -0.05878464662237093, 'clip_fraction': 0.3997395858168602, 'grad_norm': 19.138961791992188}
2023-01-03 12:19:57.817 INFO: Optimization: policy loss=0.048, vf loss=0.205, entropy loss=-0.060, total loss=-0.011, num steps=15
2023-01-03 12:19:57.818 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 12:19:59.695 INFO: Evaluation rollout: return=0.831 (0.0), episode length=6.0
2023-01-03 12:19:59.696 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 12:19:59.699 INFO: Iteration: 22/137, steps: 4752
2023-01-03 12:20:13.476 DEBUG: There is a single atom floating around
2023-01-03 12:20:15.394 DEBUG: There is a single atom floating around
2023-01-03 12:20:15.395 DEBUG: Atoms are too close
2023-01-03 12:20:15.700 DEBUG: Atoms are too close
2023-01-03 12:20:16.609 DEBUG: Atoms are too close
2023-01-03 12:20:16.610 DEBUG: Atoms are too close
2023-01-03 12:20:17.266 DEBUG: Atoms are too close
2023-01-03 12:20:32.118 DEBUG: Atoms are too close
2023-01-03 12:20:32.119 DEBUG: Atoms are too close
2023-01-03 12:20:32.219 DEBUG: Atoms are too close
2023-01-03 12:20:32.220 DEBUG: Atoms are too close
2023-01-03 12:20:32.852 DEBUG: Atoms are too close
2023-01-03 12:20:33.176 DEBUG: Atoms are too close
2023-01-03 12:20:42.279 DEBUG: Atoms are too close
2023-01-03 12:20:46.795 DEBUG: There is a single atom floating around
2023-01-03 12:20:46.796 DEBUG: Atoms are too close
2023-01-03 12:20:50.783 DEBUG: Atoms are too close
2023-01-03 12:20:53.941 DEBUG: Atoms are too close
2023-01-03 12:20:57.662 INFO: Training rollout: return=-14.519 (15.0), episode length=5.5
2023-01-03 12:20:57.664 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 12:20:57.668 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-4752_train.pkl
2023-01-03 12:20:59.965 DEBUG: Taking gradient step
2023-01-03 12:21:02.225 DEBUG: Loss 0: {'policy_loss': -0.014509123568904783, 'entropy_loss': -0.059854515828192234, 'vf_loss': 0.20417872771322326, 'total_loss': -0.07436363939709702, 'approx_kl': -1.150183379650116e-07, 'clip_fraction': 0.0, 'grad_norm': 18.032913208007812}
2023-01-03 12:21:04.442 DEBUG: Taking gradient step
2023-01-03 12:21:06.698 DEBUG: Loss 1: {'policy_loss': -0.021840519933150122, 'entropy_loss': -0.059163729660212994, 'vf_loss': 0.20386419867552968, 'total_loss': -0.08100424959336311, 'approx_kl': -0.011596570257097483, 'clip_fraction': 0.2942708358168602, 'grad_norm': 22.432353973388672}
2023-01-03 12:21:08.950 DEBUG: Taking gradient step
2023-01-03 12:21:11.221 DEBUG: Loss 2: {'policy_loss': 0.07300045049614157, 'entropy_loss': -0.06010702811181545, 'vf_loss': 0.20438872311131628, 'total_loss': 0.012893422384326107, 'approx_kl': -0.05914450017735362, 'clip_fraction': 0.3828125, 'grad_norm': 32.058170318603516}
2023-01-03 12:21:13.429 DEBUG: Taking gradient step
2023-01-03 12:21:15.690 DEBUG: Loss 3: {'policy_loss': 0.17514422781631722, 'entropy_loss': -0.05981141049414873, 'vf_loss': 0.20956905069560924, 'total_loss': 0.11533281732216849, 'approx_kl': -0.03232228383421898, 'clip_fraction': 0.53515625, 'grad_norm': 22.13315200805664}
2023-01-03 12:21:17.899 DEBUG: Taking gradient step
2023-01-03 12:21:20.177 DEBUG: Loss 4: {'policy_loss': 0.15187170253738042, 'entropy_loss': -0.05994642246514559, 'vf_loss': 0.20885454908499457, 'total_loss': 0.09192528007223484, 'approx_kl': -0.03093659318983555, 'clip_fraction': 0.5390625, 'grad_norm': 24.270458221435547}
2023-01-03 12:21:22.406 DEBUG: Taking gradient step
2023-01-03 12:21:24.808 DEBUG: Loss 5: {'policy_loss': 0.11043180023542243, 'entropy_loss': -0.0611475370824337, 'vf_loss': 0.2070708625316384, 'total_loss': 0.04928426315298873, 'approx_kl': -0.02803694736212492, 'clip_fraction': 0.49609375, 'grad_norm': 21.785480499267578}
2023-01-03 12:21:26.997 DEBUG: Taking gradient step
2023-01-03 12:21:29.227 DEBUG: Loss 6: {'policy_loss': 0.10929638211203055, 'entropy_loss': -0.05992593802511692, 'vf_loss': 0.2063855055184963, 'total_loss': 0.04937044408691363, 'approx_kl': -0.05127333477139473, 'clip_fraction': 0.4934895858168602, 'grad_norm': 23.715707778930664}
2023-01-03 12:21:31.458 DEBUG: Taking gradient step
2023-01-03 12:21:33.708 DEBUG: Loss 7: {'policy_loss': 0.11798143636244217, 'entropy_loss': -0.060829686000943184, 'vf_loss': 0.2069240568955315, 'total_loss': 0.057151750361498985, 'approx_kl': -0.077681346796453, 'clip_fraction': 0.4895833358168602, 'grad_norm': 33.562686920166016}
2023-01-03 12:21:35.931 DEBUG: Taking gradient step
2023-01-03 12:21:38.167 DEBUG: Loss 8: {'policy_loss': 0.12283795696667034, 'entropy_loss': -0.0601784260943532, 'vf_loss': 0.2006979919134828, 'total_loss': 0.06265953087231713, 'approx_kl': -0.10401791706681252, 'clip_fraction': 0.4388020858168602, 'grad_norm': 19.10386085510254}
2023-01-03 12:21:40.441 DEBUG: Taking gradient step
2023-01-03 12:21:42.690 DEBUG: Loss 9: {'policy_loss': 0.1887481561153115, 'entropy_loss': -0.06148808542639017, 'vf_loss': 0.20310640731897872, 'total_loss': 0.12726007068892134, 'approx_kl': -0.09094095540058333, 'clip_fraction': 0.5403645932674408, 'grad_norm': 28.741708755493164}
2023-01-03 12:21:44.898 DEBUG: Taking gradient step
2023-01-03 12:21:47.172 DEBUG: Loss 10: {'policy_loss': 0.21796019240529335, 'entropy_loss': -0.05954110436141491, 'vf_loss': 0.20131214398670916, 'total_loss': 0.15841908804387844, 'approx_kl': -0.14216666761785746, 'clip_fraction': 0.5234375, 'grad_norm': 44.87785339355469}
2023-01-03 12:21:49.371 DEBUG: Taking gradient step
2023-01-03 12:21:51.707 DEBUG: Loss 11: {'policy_loss': 0.1779954603992046, 'entropy_loss': -0.06028830725699663, 'vf_loss': 0.20383197323960026, 'total_loss': 0.11770715314220796, 'approx_kl': -0.1428967509418726, 'clip_fraction': 0.4674479216337204, 'grad_norm': 39.488243103027344}
2023-01-03 12:21:53.892 DEBUG: Taking gradient step
2023-01-03 12:21:56.163 DEBUG: Loss 12: {'policy_loss': 0.17441225749117453, 'entropy_loss': -0.06033725291490555, 'vf_loss': 0.2076505656039199, 'total_loss': 0.11407500457626898, 'approx_kl': -0.14402340538799763, 'clip_fraction': 0.4986979216337204, 'grad_norm': 25.6217098236084}
2023-01-03 12:21:58.351 DEBUG: Taking gradient step
2023-01-03 12:22:00.649 DEBUG: Loss 13: {'policy_loss': 0.14052850654951426, 'entropy_loss': -0.060674505308270454, 'vf_loss': 0.2012351231315449, 'total_loss': 0.07985400124124378, 'approx_kl': -0.12139150314033031, 'clip_fraction': 0.5911458432674408, 'grad_norm': 24.914762496948242}
2023-01-03 12:22:02.874 DEBUG: Taking gradient step
2023-01-03 12:22:05.133 DEBUG: Loss 14: {'policy_loss': 0.059000492741270893, 'entropy_loss': -0.06199832446873188, 'vf_loss': 0.1949853408465067, 'total_loss': -0.0029978317274610006, 'approx_kl': -0.12046548165380955, 'clip_fraction': 0.50390625, 'grad_norm': 20.452011108398438}
2023-01-03 12:22:05.134 INFO: Optimization: policy loss=0.059, vf loss=0.195, entropy loss=-0.062, total loss=-0.003, num steps=15
2023-01-03 12:22:05.135 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 12:22:07.032 INFO: Evaluation rollout: return=0.815 (0.0), episode length=6.0
2023-01-03 12:22:07.034 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 12:22:07.038 INFO: Iteration: 23/137, steps: 4968
2023-01-03 12:22:20.882 DEBUG: Atoms are too close
2023-01-03 12:22:25.647 DEBUG: Atoms are too close
2023-01-03 12:22:26.901 DEBUG: There is a single atom floating around
2023-01-03 12:22:40.949 DEBUG: Atoms are too close
2023-01-03 12:22:41.854 DEBUG: Atoms are too close
2023-01-03 12:22:43.754 DEBUG: Atoms are too close
2023-01-03 12:22:44.495 DEBUG: Atoms are too close
2023-01-03 12:22:45.646 DEBUG: Atoms are too close
2023-01-03 12:22:57.363 DEBUG: Atoms are too close
2023-01-03 12:22:58.943 DEBUG: Atoms are too close
2023-01-03 12:22:59.902 DEBUG: Atoms are too close
2023-01-03 12:23:02.424 DEBUG: Atoms are too close
2023-01-03 12:23:05.678 DEBUG: Atoms are too close
2023-01-03 12:23:06.070 INFO: Training rollout: return=-10.274 (14.4), episode length=5.8
2023-01-03 12:23:06.071 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 12:23:06.074 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-4968_train.pkl
2023-01-03 12:23:08.357 DEBUG: Taking gradient step
2023-01-03 12:23:10.679 DEBUG: Loss 0: {'policy_loss': -0.0008582637622476356, 'entropy_loss': -0.06095232255756855, 'vf_loss': 0.20551520014209154, 'total_loss': -0.06181058631981619, 'approx_kl': 6.214637915391563e-08, 'clip_fraction': 0.0, 'grad_norm': 23.052690505981445}
2023-01-03 12:23:13.138 DEBUG: Taking gradient step
2023-01-03 12:23:15.462 DEBUG: Loss 1: {'policy_loss': -0.04935302167695968, 'entropy_loss': -0.060737513937056065, 'vf_loss': 0.1990420963290932, 'total_loss': -0.11009053561401574, 'approx_kl': 0.003512746188789606, 'clip_fraction': 0.10286458395421505, 'grad_norm': 17.44221305847168}
2023-01-03 12:23:17.697 DEBUG: Taking gradient step
2023-01-03 12:23:20.036 DEBUG: Loss 2: {'policy_loss': -0.0010986333218836845, 'entropy_loss': -0.06085465382784605, 'vf_loss': 0.19697409820704187, 'total_loss': -0.06195328714972974, 'approx_kl': -0.012548717902973294, 'clip_fraction': 0.2890625, 'grad_norm': 13.463521957397461}
2023-01-03 12:23:22.329 DEBUG: Taking gradient step
2023-01-03 12:23:24.653 DEBUG: Loss 3: {'policy_loss': -0.003625749636283311, 'entropy_loss': -0.05908811930567026, 'vf_loss': 0.19448753296037014, 'total_loss': -0.06271386894195358, 'approx_kl': -0.03412615321576595, 'clip_fraction': 0.40234375, 'grad_norm': 18.07041358947754}
2023-01-03 12:23:26.923 DEBUG: Taking gradient step
2023-01-03 12:23:29.237 DEBUG: Loss 4: {'policy_loss': 0.012755255797923172, 'entropy_loss': -0.05919329263269901, 'vf_loss': 0.19414809942967137, 'total_loss': -0.04643803683477584, 'approx_kl': -0.04344623349606991, 'clip_fraction': 0.4713541716337204, 'grad_norm': 17.284955978393555}
2023-01-03 12:23:31.473 DEBUG: Taking gradient step
2023-01-03 12:23:33.788 DEBUG: Loss 5: {'policy_loss': 0.01315589361083664, 'entropy_loss': -0.05824991129338741, 'vf_loss': 0.1921240257837295, 'total_loss': -0.04509401768255076, 'approx_kl': -0.04088054457679391, 'clip_fraction': 0.4361979216337204, 'grad_norm': 19.597801208496094}
2023-01-03 12:23:36.057 DEBUG: Taking gradient step
2023-01-03 12:23:38.349 DEBUG: Loss 6: {'policy_loss': -0.01978286527032899, 'entropy_loss': -0.05793633311986923, 'vf_loss': 0.1930908229789407, 'total_loss': -0.07771919839019822, 'approx_kl': -0.030879014946549432, 'clip_fraction': 0.41796875, 'grad_norm': 10.578624725341797}
2023-01-03 12:23:40.751 DEBUG: Taking gradient step
2023-01-03 12:23:43.206 DEBUG: Loss 7: {'policy_loss': 0.08633225412801539, 'entropy_loss': -0.05729413405060768, 'vf_loss': 0.2071792467632999, 'total_loss': 0.029038120077407706, 'approx_kl': -0.03261300572194159, 'clip_fraction': 0.3919270858168602, 'grad_norm': 21.384828567504883}
2023-01-03 12:23:45.444 DEBUG: Taking gradient step
2023-01-03 12:23:48.077 DEBUG: Loss 8: {'policy_loss': 0.015231969845106594, 'entropy_loss': -0.058056581765413284, 'vf_loss': 0.19392353245959046, 'total_loss': -0.04282461192030669, 'approx_kl': -0.07081557903438807, 'clip_fraction': 0.4231770858168602, 'grad_norm': 22.81913185119629}
2023-01-03 12:23:50.332 DEBUG: Taking gradient step
2023-01-03 12:23:52.660 DEBUG: Loss 9: {'policy_loss': 0.012173722793603915, 'entropy_loss': -0.0580566693097353, 'vf_loss': 0.19509169781025842, 'total_loss': -0.04588294651613138, 'approx_kl': -0.05616070772521198, 'clip_fraction': 0.3841145858168602, 'grad_norm': 17.23679542541504}
2023-01-03 12:23:54.895 DEBUG: Taking gradient step
2023-01-03 12:23:57.196 DEBUG: Loss 10: {'policy_loss': 0.0545955526679272, 'entropy_loss': -0.058761293068528175, 'vf_loss': 0.19287245749186438, 'total_loss': -0.004165740400600984, 'approx_kl': -0.05963965132832527, 'clip_fraction': 0.49609375, 'grad_norm': 17.162708282470703}
2023-01-03 12:23:59.688 DEBUG: Taking gradient step
2023-01-03 12:24:01.990 DEBUG: Loss 11: {'policy_loss': 0.06288560679291744, 'entropy_loss': -0.05828892905265093, 'vf_loss': 0.19565211182728254, 'total_loss': 0.004596677740266508, 'approx_kl': -0.07264535594731569, 'clip_fraction': 0.4921875, 'grad_norm': 20.558395385742188}
2023-01-03 12:24:04.331 DEBUG: Taking gradient step
2023-01-03 12:24:06.654 DEBUG: Loss 12: {'policy_loss': 0.06313498753751698, 'entropy_loss': -0.060151646845042706, 'vf_loss': 0.189993644195817, 'total_loss': 0.0029833406924742838, 'approx_kl': -0.08748814789578319, 'clip_fraction': 0.5026041716337204, 'grad_norm': 23.307540893554688}
2023-01-03 12:24:08.927 DEBUG: Taking gradient step
2023-01-03 12:24:11.242 DEBUG: Loss 13: {'policy_loss': 0.03735328027384784, 'entropy_loss': -0.058636425994336605, 'vf_loss': 0.1860100640514607, 'total_loss': -0.02128314572048876, 'approx_kl': -0.09127912670373917, 'clip_fraction': 0.4401041716337204, 'grad_norm': 28.4975643157959}
2023-01-03 12:24:13.482 DEBUG: Taking gradient step
2023-01-03 12:24:15.776 DEBUG: Loss 14: {'policy_loss': 0.03156260840645676, 'entropy_loss': -0.05813832487910986, 'vf_loss': 0.18712683591705945, 'total_loss': -0.0265757164726531, 'approx_kl': -0.090355534106493, 'clip_fraction': 0.4361979216337204, 'grad_norm': 16.479984283447266}
2023-01-03 12:24:15.776 INFO: Optimization: policy loss=0.032, vf loss=0.187, entropy loss=-0.058, total loss=-0.027, num steps=15
2023-01-03 12:24:15.778 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 12:24:17.665 INFO: Evaluation rollout: return=0.772 (0.0), episode length=6.0
2023-01-03 12:24:17.666 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 12:24:17.670 INFO: Iteration: 24/137, steps: 5184
2023-01-03 12:24:28.772 DEBUG: There is a single atom floating around
2023-01-03 12:24:33.528 DEBUG: Atoms are too close
2023-01-03 12:24:49.708 DEBUG: Atoms are too close
2023-01-03 12:24:52.317 DEBUG: Atoms are too close
2023-01-03 12:24:53.786 DEBUG: Atoms are too close
2023-01-03 12:24:54.417 DEBUG: Atoms are too close
2023-01-03 12:24:55.578 DEBUG: Atoms are too close
2023-01-03 12:25:04.697 DEBUG: There is a single atom floating around
2023-01-03 12:25:12.439 DEBUG: There is a single atom floating around
2023-01-03 12:25:13.214 DEBUG: Atoms are too close
2023-01-03 12:25:14.915 DEBUG: Atoms are too close
2023-01-03 12:25:16.004 DEBUG: Atoms are too close
2023-01-03 12:25:17.336 INFO: Training rollout: return=-9.485 (14.1), episode length=5.7
2023-01-03 12:25:17.338 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 12:25:17.341 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-5184_train.pkl
2023-01-03 12:25:19.619 DEBUG: Taking gradient step
2023-01-03 12:25:21.934 DEBUG: Loss 0: {'policy_loss': -0.00950966810549365, 'entropy_loss': -0.05661499686539173, 'vf_loss': 0.1806620388864518, 'total_loss': -0.06612466497088537, 'approx_kl': -1.2782402336597443e-07, 'clip_fraction': 0.0, 'grad_norm': 14.876238822937012}
2023-01-03 12:25:24.181 DEBUG: Taking gradient step
2023-01-03 12:25:26.481 DEBUG: Loss 1: {'policy_loss': 0.06304117691994378, 'entropy_loss': -0.05603407043963671, 'vf_loss': 0.1854260421443258, 'total_loss': 0.007007106480307071, 'approx_kl': -0.016825777012854815, 'clip_fraction': 0.18359375, 'grad_norm': 26.762317657470703}
2023-01-03 12:25:28.767 DEBUG: Taking gradient step
2023-01-03 12:25:31.209 DEBUG: Loss 2: {'policy_loss': 0.06413794956848869, 'entropy_loss': -0.05510621052235365, 'vf_loss': 0.18686685065606293, 'total_loss': 0.009031739046135037, 'approx_kl': -0.020723719149827957, 'clip_fraction': 0.328125, 'grad_norm': 26.81403350830078}
2023-01-03 12:25:33.432 DEBUG: Taking gradient step
2023-01-03 12:25:35.738 DEBUG: Loss 3: {'policy_loss': -0.0506819474160151, 'entropy_loss': -0.05401935335248709, 'vf_loss': 0.1724870461153722, 'total_loss': -0.10470130076850219, 'approx_kl': -0.03621672233566642, 'clip_fraction': 0.2486979179084301, 'grad_norm': 26.05276870727539}
2023-01-03 12:25:38.051 DEBUG: Taking gradient step
2023-01-03 12:25:40.358 DEBUG: Loss 4: {'policy_loss': -0.008810919069593408, 'entropy_loss': -0.053339545615017414, 'vf_loss': 0.1757398311688657, 'total_loss': -0.06215046468461082, 'approx_kl': -0.03434719191864133, 'clip_fraction': 0.3255208358168602, 'grad_norm': 24.5135440826416}
2023-01-03 12:25:42.598 DEBUG: Taking gradient step
2023-01-03 12:25:44.968 DEBUG: Loss 5: {'policy_loss': 0.023821102199899552, 'entropy_loss': -0.05310035217553377, 'vf_loss': 0.17749891737907447, 'total_loss': -0.02927924997563422, 'approx_kl': -0.05894438689574599, 'clip_fraction': 0.3111979216337204, 'grad_norm': 18.857580184936523}
2023-01-03 12:25:47.290 DEBUG: Taking gradient step
2023-01-03 12:25:49.766 DEBUG: Loss 6: {'policy_loss': -0.01679882213908889, 'entropy_loss': -0.05298560485243797, 'vf_loss': 0.1721114902038926, 'total_loss': -0.06978442699152686, 'approx_kl': -0.05289747822098434, 'clip_fraction': 0.3932291716337204, 'grad_norm': 19.271041870117188}
2023-01-03 12:25:52.011 DEBUG: Taking gradient step
2023-01-03 12:25:54.418 DEBUG: Loss 7: {'policy_loss': -0.009345553538237822, 'entropy_loss': -0.05398891121149063, 'vf_loss': 0.17142485421214307, 'total_loss': -0.06333446474972845, 'approx_kl': -0.05771190393716097, 'clip_fraction': 0.3932291716337204, 'grad_norm': 16.33433723449707}
2023-01-03 12:25:56.656 DEBUG: Taking gradient step
2023-01-03 12:25:58.966 DEBUG: Loss 8: {'policy_loss': -0.012911847309273798, 'entropy_loss': -0.053764588199555874, 'vf_loss': 0.17182173365383016, 'total_loss': -0.06667643550882967, 'approx_kl': -0.057117659132927656, 'clip_fraction': 0.4388020932674408, 'grad_norm': 19.34423065185547}
2023-01-03 12:26:01.235 DEBUG: Taking gradient step
2023-01-03 12:26:03.557 DEBUG: Loss 9: {'policy_loss': -0.033447427745142214, 'entropy_loss': -0.054683114401996136, 'vf_loss': 0.17390697967377416, 'total_loss': -0.08813054214713835, 'approx_kl': -0.04795971745625138, 'clip_fraction': 0.42578125, 'grad_norm': 18.196903228759766}
2023-01-03 12:26:05.809 DEBUG: Taking gradient step
2023-01-03 12:26:08.120 DEBUG: Loss 10: {'policy_loss': 0.050676153485495125, 'entropy_loss': -0.055633953772485256, 'vf_loss': 0.1842932933472453, 'total_loss': -0.004957800286990131, 'approx_kl': -0.05453458847478032, 'clip_fraction': 0.4127604216337204, 'grad_norm': 23.813819885253906}
2023-01-03 12:26:10.416 DEBUG: Taking gradient step
2023-01-03 12:26:12.715 DEBUG: Loss 11: {'policy_loss': 0.05208740584933818, 'entropy_loss': -0.054492224007844925, 'vf_loss': 0.1782473735551528, 'total_loss': -0.002404818158506747, 'approx_kl': -0.06894646771252155, 'clip_fraction': 0.4908854216337204, 'grad_norm': 23.42302894592285}
2023-01-03 12:26:14.962 DEBUG: Taking gradient step
2023-01-03 12:26:17.253 DEBUG: Loss 12: {'policy_loss': -0.028136507225609043, 'entropy_loss': -0.054825921542942524, 'vf_loss': 0.16617523737286727, 'total_loss': -0.08296242876855156, 'approx_kl': -0.06104629300534725, 'clip_fraction': 0.3932291716337204, 'grad_norm': 21.371686935424805}
2023-01-03 12:26:19.492 DEBUG: Taking gradient step
2023-01-03 12:26:21.782 DEBUG: Loss 13: {'policy_loss': 0.060994862186760944, 'entropy_loss': -0.05307572614401579, 'vf_loss': 0.1784970007518679, 'total_loss': 0.007919136042745155, 'approx_kl': -0.052563220902811736, 'clip_fraction': 0.3919270858168602, 'grad_norm': 22.200223922729492}
2023-01-03 12:26:24.036 DEBUG: Taking gradient step
2023-01-03 12:26:26.330 DEBUG: Loss 14: {'policy_loss': 0.06474432327939582, 'entropy_loss': -0.05353226885199547, 'vf_loss': 0.1793402905980471, 'total_loss': 0.01121205442740035, 'approx_kl': -0.06734347529709339, 'clip_fraction': 0.38671875, 'grad_norm': 22.61573028564453}
2023-01-03 12:26:26.331 INFO: Optimization: policy loss=0.065, vf loss=0.179, entropy loss=-0.054, total loss=0.011, num steps=15
2023-01-03 12:26:26.333 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 12:26:27.927 DEBUG: Atoms are too close
2023-01-03 12:26:27.929 INFO: Evaluation rollout: return=-29.180 (0.0), episode length=6.0
2023-01-03 12:26:27.930 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 12:26:27.933 INFO: Iteration: 25/137, steps: 5400
2023-01-03 12:26:34.526 DEBUG: Atoms are too close
2023-01-03 12:26:41.203 DEBUG: Atoms are too close
2023-01-03 12:26:45.018 DEBUG: There is a single atom floating around
2023-01-03 12:26:45.631 DEBUG: Atoms are too close
2023-01-03 12:26:46.586 DEBUG: There is a single atom floating around
2023-01-03 12:26:56.452 DEBUG: Atoms are too close
2023-01-03 12:26:58.594 DEBUG: Atoms are too close
2023-01-03 12:27:01.773 DEBUG: Atoms are too close
2023-01-03 12:27:05.599 DEBUG: Atoms are too close
2023-01-03 12:27:05.600 DEBUG: Atoms are too close
2023-01-03 12:27:05.601 DEBUG: Atoms are too close
2023-01-03 12:27:06.249 DEBUG: Atoms are too close
2023-01-03 12:27:06.249 DEBUG: Atoms are too close
2023-01-03 12:27:15.631 DEBUG: Atoms are too close
2023-01-03 12:27:16.694 DEBUG: Atoms are too close
2023-01-03 12:27:17.194 DEBUG: Atoms are too close
2023-01-03 12:27:22.303 DEBUG: Atoms are too close
2023-01-03 12:27:23.409 DEBUG: Atoms are too close
2023-01-03 12:27:24.726 DEBUG: Atoms are too close
2023-01-03 12:27:26.304 INFO: Training rollout: return=-15.307 (14.9), episode length=5.6
2023-01-03 12:27:26.305 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 12:27:26.308 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-5400_train.pkl
2023-01-03 12:27:28.568 DEBUG: Taking gradient step
2023-01-03 12:27:31.290 DEBUG: Loss 0: {'policy_loss': 0.026931909877665104, 'entropy_loss': -0.05333366896957159, 'vf_loss': 0.2417543380065002, 'total_loss': -0.026401759091906486, 'approx_kl': 2.2351741790771484e-08, 'clip_fraction': 0.0, 'grad_norm': 10.319205284118652}
2023-01-03 12:27:33.603 DEBUG: Taking gradient step
2023-01-03 12:27:35.935 DEBUG: Loss 1: {'policy_loss': -0.0009349308292571079, 'entropy_loss': -0.05310739576816559, 'vf_loss': 0.2324228201583208, 'total_loss': -0.054042326597422696, 'approx_kl': 0.009022739250212908, 'clip_fraction': 0.2526041716337204, 'grad_norm': 23.656431198120117}
2023-01-03 12:27:38.187 DEBUG: Taking gradient step
2023-01-03 12:27:40.609 DEBUG: Loss 2: {'policy_loss': 0.07053254337997776, 'entropy_loss': -0.05236567836254835, 'vf_loss': 0.2309331046451811, 'total_loss': 0.01816686501742942, 'approx_kl': -0.01180960237979889, 'clip_fraction': 0.5247395858168602, 'grad_norm': 32.822086334228516}
2023-01-03 12:27:42.867 DEBUG: Taking gradient step
2023-01-03 12:27:45.174 DEBUG: Loss 3: {'policy_loss': 0.1619312123958735, 'entropy_loss': -0.05215237382799387, 'vf_loss': 0.23396580892839014, 'total_loss': 0.10977883856787962, 'approx_kl': -0.01496789650991559, 'clip_fraction': 0.4375, 'grad_norm': 36.5529670715332}
2023-01-03 12:27:47.494 DEBUG: Taking gradient step
2023-01-03 12:27:49.836 DEBUG: Loss 4: {'policy_loss': 0.10667941476385193, 'entropy_loss': -0.05061433929949999, 'vf_loss': 0.22220040765215224, 'total_loss': 0.05606507546435194, 'approx_kl': 0.035445858258754015, 'clip_fraction': 0.4661458358168602, 'grad_norm': 21.860416412353516}
2023-01-03 12:27:52.053 DEBUG: Early stopping at step 5 for reaching max KL.
2023-01-03 12:27:52.054 INFO: Optimization: policy loss=0.107, vf loss=0.222, entropy loss=-0.051, total loss=0.056, num steps=5
2023-01-03 12:27:52.055 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 12:27:53.670 DEBUG: Atoms are too close
2023-01-03 12:27:53.672 INFO: Evaluation rollout: return=-29.180 (0.0), episode length=6.0
2023-01-03 12:27:53.672 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 12:27:53.677 INFO: Iteration: 26/137, steps: 5616
2023-01-03 12:28:08.427 DEBUG: Atoms are too close
2023-01-03 12:28:10.078 DEBUG: Atoms are too close
2023-01-03 12:28:10.431 DEBUG: Atoms are too close
2023-01-03 12:28:12.625 DEBUG: Atoms are too close
2023-01-03 12:28:24.471 DEBUG: Atoms are too close
2023-01-03 12:28:25.193 DEBUG: Atoms are too close
2023-01-03 12:28:28.122 DEBUG: Atoms are too close
2023-01-03 12:28:30.628 DEBUG: Atoms are too close
2023-01-03 12:28:56.639 INFO: Training rollout: return=-6.261 (12.5), episode length=5.8
2023-01-03 12:28:56.640 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 12:28:56.643 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-5616_train.pkl
2023-01-03 12:28:58.930 DEBUG: Taking gradient step
2023-01-03 12:29:01.294 DEBUG: Loss 0: {'policy_loss': -0.022464861068751705, 'entropy_loss': -0.0485776262357831, 'vf_loss': 0.22401706473924188, 'total_loss': -0.0710424873045348, 'approx_kl': 4.738103598356247e-08, 'clip_fraction': 0.0, 'grad_norm': 20.898256301879883}
2023-01-03 12:29:03.569 DEBUG: Early stopping at step 1 for reaching max KL.
2023-01-03 12:29:03.570 INFO: Optimization: policy loss=-0.022, vf loss=0.224, entropy loss=-0.049, total loss=-0.071, num steps=1
2023-01-03 12:29:03.571 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 12:29:04.886 DEBUG: There is a single atom floating around
2023-01-03 12:29:04.888 INFO: Evaluation rollout: return=-29.183 (0.0), episode length=5.0
2023-01-03 12:29:04.889 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 12:29:04.892 INFO: Iteration: 27/137, steps: 5832
2023-01-03 12:29:19.230 DEBUG: There is a single atom floating around
2023-01-03 12:29:19.883 DEBUG: Atoms are too close
2023-01-03 12:29:19.883 DEBUG: There is a single atom floating around
2023-01-03 12:29:19.884 DEBUG: Atoms are too close
2023-01-03 12:29:19.884 DEBUG: There is a single atom floating around
2023-01-03 12:29:19.885 DEBUG: There is a single atom floating around
2023-01-03 12:29:20.574 DEBUG: There is a single atom floating around
2023-01-03 12:29:21.446 DEBUG: There is a single atom floating around
2023-01-03 12:29:32.604 DEBUG: Atoms are too close
2023-01-03 12:29:34.275 DEBUG: Atoms are too close
2023-01-03 12:29:34.939 DEBUG: There is a single atom floating around
2023-01-03 12:29:37.873 DEBUG: Atoms are too close
2023-01-03 12:29:38.345 DEBUG: There is a single atom floating around
2023-01-03 12:29:38.688 DEBUG: Atoms are too close
2023-01-03 12:29:39.731 DEBUG: There is a single atom floating around
2023-01-03 12:29:40.057 DEBUG: There is a single atom floating around
2023-01-03 12:29:49.732 DEBUG: There is a single atom floating around
2023-01-03 12:29:50.389 DEBUG: There is a single atom floating around
2023-01-03 12:29:51.061 DEBUG: There is a single atom floating around
2023-01-03 12:29:53.231 DEBUG: There is a single atom floating around
2023-01-03 12:29:55.199 DEBUG: There is a single atom floating around
2023-01-03 12:29:55.298 DEBUG: There is a single atom floating around
2023-01-03 12:29:55.644 DEBUG: Atoms are too close
2023-01-03 12:29:56.122 DEBUG: There is a single atom floating around
2023-01-03 12:29:56.123 DEBUG: Atoms are too close
2023-01-03 12:29:59.786 DEBUG: There is a single atom floating around
2023-01-03 12:29:59.788 DEBUG: There is a single atom floating around
2023-01-03 12:30:00.210 INFO: Training rollout: return=-21.825 (13.0), episode length=5.5
2023-01-03 12:30:00.211 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 12:30:00.213 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-5832_train.pkl
2023-01-03 12:30:02.487 DEBUG: Taking gradient step
2023-01-03 12:30:04.716 DEBUG: Loss 0: {'policy_loss': -0.035783398617315554, 'entropy_loss': -0.04594847187399864, 'vf_loss': 0.18994252322861133, 'total_loss': -0.0817318704913142, 'approx_kl': 1.6104119371362913e-08, 'clip_fraction': 0.0, 'grad_norm': 23.480871200561523}
2023-01-03 12:30:06.956 DEBUG: Early stopping at step 1 for reaching max KL.
2023-01-03 12:30:06.957 INFO: Optimization: policy loss=-0.036, vf loss=0.190, entropy loss=-0.046, total loss=-0.082, num steps=1
2023-01-03 12:30:06.958 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 12:30:08.241 DEBUG: There is a single atom floating around
2023-01-03 12:30:08.243 INFO: Evaluation rollout: return=-29.380 (0.0), episode length=5.0
2023-01-03 12:30:08.244 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 12:30:08.247 INFO: Iteration: 28/137, steps: 6048
2023-01-03 12:30:15.556 DEBUG: There is a single atom floating around
2023-01-03 12:30:21.419 DEBUG: Atoms are too close
2023-01-03 12:30:22.185 DEBUG: There is a single atom floating around
2023-01-03 12:30:24.106 DEBUG: Atoms are too close
2023-01-03 12:30:24.107 DEBUG: There is a single atom floating around
2023-01-03 12:30:24.354 DEBUG: There is a single atom floating around
2023-01-03 12:30:24.355 DEBUG: There is a single atom floating around
2023-01-03 12:30:25.192 DEBUG: There is a single atom floating around
2023-01-03 12:30:40.765 DEBUG: There is a single atom floating around
2023-01-03 12:30:40.768 DEBUG: There is a single atom floating around
2023-01-03 12:30:40.865 DEBUG: There is a single atom floating around
2023-01-03 12:30:41.178 DEBUG: Atoms are too close
2023-01-03 12:30:41.835 DEBUG: Atoms are too close
2023-01-03 12:30:45.575 DEBUG: There is a single atom floating around
2023-01-03 12:30:47.407 DEBUG: Atoms are too close
2023-01-03 12:30:54.688 DEBUG: Atoms are too close
2023-01-03 12:30:56.028 DEBUG: There is a single atom floating around
2023-01-03 12:30:57.140 DEBUG: There is a single atom floating around
2023-01-03 12:30:59.421 DEBUG: Atoms are too close
2023-01-03 12:31:02.102 DEBUG: There is a single atom floating around
2023-01-03 12:31:02.103 DEBUG: There is a single atom floating around
2023-01-03 12:31:02.891 DEBUG: Atoms are too close
2023-01-03 12:31:04.232 DEBUG: There is a single atom floating around
2023-01-03 12:31:05.581 INFO: Training rollout: return=-18.463 (14.4), episode length=5.5
2023-01-03 12:31:05.582 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 12:31:05.585 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-6048_train.pkl
2023-01-03 12:31:07.831 DEBUG: Taking gradient step
2023-01-03 12:31:10.095 DEBUG: Loss 0: {'policy_loss': 0.029893488421893714, 'entropy_loss': -0.04871359374374151, 'vf_loss': 0.19651532793676638, 'total_loss': -0.018820105321847802, 'approx_kl': -1.3255824704572206e-07, 'clip_fraction': 0.0, 'grad_norm': 19.64291763305664}
2023-01-03 12:31:12.467 DEBUG: Taking gradient step
2023-01-03 12:31:14.716 DEBUG: Loss 1: {'policy_loss': 0.070559703611346, 'entropy_loss': -0.05021435022354126, 'vf_loss': 0.19983056568962446, 'total_loss': 0.02034535338780475, 'approx_kl': 0.002936353674158454, 'clip_fraction': 0.42578125, 'grad_norm': 31.52423095703125}
2023-01-03 12:31:16.954 DEBUG: Taking gradient step
2023-01-03 12:31:19.211 DEBUG: Loss 2: {'policy_loss': 0.08585859597954706, 'entropy_loss': -0.048578573390841484, 'vf_loss': 0.20183916344449282, 'total_loss': 0.03728002258870558, 'approx_kl': -0.04678288847208023, 'clip_fraction': 0.3932291679084301, 'grad_norm': 27.675514221191406}
2023-01-03 12:31:21.423 DEBUG: Taking gradient step
2023-01-03 12:31:23.705 DEBUG: Loss 3: {'policy_loss': 0.17270938621215268, 'entropy_loss': -0.05071309581398964, 'vf_loss': 0.2052470178935626, 'total_loss': 0.12199629039816304, 'approx_kl': -0.032343655824661255, 'clip_fraction': 0.48046875, 'grad_norm': 28.565603256225586}
2023-01-03 12:31:25.892 DEBUG: Taking gradient step
2023-01-03 12:31:28.171 DEBUG: Loss 4: {'policy_loss': 0.1930337263227637, 'entropy_loss': -0.05001144763082266, 'vf_loss': 0.20482275498044528, 'total_loss': 0.14302227869194103, 'approx_kl': -0.05102357920259237, 'clip_fraction': 0.5221354216337204, 'grad_norm': 47.47243118286133}
2023-01-03 12:31:30.377 DEBUG: Taking gradient step
2023-01-03 12:31:32.646 DEBUG: Loss 5: {'policy_loss': 0.14897475872636193, 'entropy_loss': -0.0492633106186986, 'vf_loss': 0.20689256762429592, 'total_loss': 0.09971144810766333, 'approx_kl': -0.059306337498128414, 'clip_fraction': 0.46875, 'grad_norm': 38.164432525634766}
2023-01-03 12:31:34.871 DEBUG: Taking gradient step
2023-01-03 12:31:37.245 DEBUG: Loss 6: {'policy_loss': 0.174594762950558, 'entropy_loss': -0.05046071670949459, 'vf_loss': 0.1956484090041595, 'total_loss': 0.12413404624106342, 'approx_kl': -0.05666823172941804, 'clip_fraction': 0.4830729216337204, 'grad_norm': 46.36396026611328}
2023-01-03 12:31:39.599 DEBUG: Taking gradient step
2023-01-03 12:31:41.870 DEBUG: Loss 7: {'policy_loss': 0.0621827276193118, 'entropy_loss': -0.04751589708030224, 'vf_loss': 0.20493307011027206, 'total_loss': 0.014666830539009565, 'approx_kl': -0.05602083230041899, 'clip_fraction': 0.4544270858168602, 'grad_norm': 34.91487503051758}
2023-01-03 12:31:44.108 DEBUG: Taking gradient step
2023-01-03 12:31:46.364 DEBUG: Loss 8: {'policy_loss': 0.06242085013316272, 'entropy_loss': -0.04738056380301714, 'vf_loss': 0.21176384188098366, 'total_loss': 0.015040286330145591, 'approx_kl': -0.08438002248294652, 'clip_fraction': 0.4700520858168602, 'grad_norm': 33.111305236816406}
2023-01-03 12:31:48.540 DEBUG: Taking gradient step
2023-01-03 12:31:50.798 DEBUG: Loss 9: {'policy_loss': 0.13466789349333677, 'entropy_loss': -0.04853121656924486, 'vf_loss': 0.20887205160144795, 'total_loss': 0.08613667692409191, 'approx_kl': -0.05418521910905838, 'clip_fraction': 0.4596354216337204, 'grad_norm': 42.577720642089844}
2023-01-03 12:31:53.030 DEBUG: Taking gradient step
2023-01-03 12:31:55.311 DEBUG: Loss 10: {'policy_loss': 0.1582672222201325, 'entropy_loss': -0.04767304752022028, 'vf_loss': 0.214905275601458, 'total_loss': 0.11059417469991223, 'approx_kl': -0.07783621363341808, 'clip_fraction': 0.3723958358168602, 'grad_norm': 42.321773529052734}
2023-01-03 12:31:57.627 DEBUG: Taking gradient step
2023-01-03 12:31:59.878 DEBUG: Loss 11: {'policy_loss': 0.12018142373154728, 'entropy_loss': -0.04904589243233204, 'vf_loss': 0.2113725417274284, 'total_loss': 0.07113553129921524, 'approx_kl': -0.06139809777960181, 'clip_fraction': 0.48828125, 'grad_norm': 33.41769027709961}
2023-01-03 12:32:02.090 DEBUG: Taking gradient step
2023-01-03 12:32:04.362 DEBUG: Loss 12: {'policy_loss': 0.11007657768297295, 'entropy_loss': -0.048581717535853386, 'vf_loss': 0.19417090097960246, 'total_loss': 0.061494860147119565, 'approx_kl': -0.04670484270900488, 'clip_fraction': 0.4453125, 'grad_norm': 27.981460571289062}
2023-01-03 12:32:06.589 DEBUG: Taking gradient step
2023-01-03 12:32:08.851 DEBUG: Loss 13: {'policy_loss': 0.13357642474880765, 'entropy_loss': -0.048311042599380016, 'vf_loss': 0.19266160809842148, 'total_loss': 0.08526538214942762, 'approx_kl': -0.09261834435164928, 'clip_fraction': 0.4049479216337204, 'grad_norm': 28.971330642700195}
2023-01-03 12:32:11.028 DEBUG: Taking gradient step
2023-01-03 12:32:13.347 DEBUG: Loss 14: {'policy_loss': 0.15379910591987472, 'entropy_loss': -0.049605777487158775, 'vf_loss': 0.19985738186979654, 'total_loss': 0.10419332843271595, 'approx_kl': -0.1011886429041624, 'clip_fraction': 0.5143229216337204, 'grad_norm': 37.573822021484375}
2023-01-03 12:32:13.347 INFO: Optimization: policy loss=0.154, vf loss=0.200, entropy loss=-0.050, total loss=0.104, num steps=15
2023-01-03 12:32:13.349 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 12:32:14.976 DEBUG: There is a single atom floating around
2023-01-03 12:32:14.978 INFO: Evaluation rollout: return=-29.114 (0.0), episode length=6.0
2023-01-03 12:32:14.979 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 12:32:14.981 INFO: Iteration: 29/137, steps: 6264
2023-01-03 12:32:21.266 DEBUG: There is a single atom floating around
2023-01-03 12:32:28.408 DEBUG: There is a single atom floating around
2023-01-03 12:32:29.086 DEBUG: There is a single atom floating around
2023-01-03 12:32:30.103 DEBUG: Atoms are too close
2023-01-03 12:32:30.104 DEBUG: There is a single atom floating around
2023-01-03 12:32:30.751 DEBUG: Atoms are too close
2023-01-03 12:32:31.320 DEBUG: There is a single atom floating around
2023-01-03 12:32:31.491 DEBUG: There is a single atom floating around
2023-01-03 12:32:43.124 DEBUG: Atoms are too close
2023-01-03 12:32:45.038 DEBUG: There is a single atom floating around
2023-01-03 12:32:45.974 DEBUG: There is a single atom floating around
2023-01-03 12:32:46.128 DEBUG: There is a single atom floating around
2023-01-03 12:32:47.507 DEBUG: There is a single atom floating around
2023-01-03 12:32:47.683 DEBUG: Atoms are too close
2023-01-03 12:32:50.883 DEBUG: Atoms are too close
2023-01-03 12:32:50.884 DEBUG: There is a single atom floating around
2023-01-03 12:32:51.851 DEBUG: Atoms are too close
2023-01-03 12:32:57.761 DEBUG: Atoms are too close
2023-01-03 12:32:59.447 DEBUG: There is a single atom floating around
2023-01-03 12:33:00.142 DEBUG: Atoms are too close
2023-01-03 12:33:02.827 DEBUG: There is a single atom floating around
2023-01-03 12:33:05.445 DEBUG: There is a single atom floating around
2023-01-03 12:33:06.728 DEBUG: There is a single atom floating around
2023-01-03 12:33:07.554 DEBUG: There is a single atom floating around
2023-01-03 12:33:11.362 INFO: Training rollout: return=-18.964 (15.4), episode length=5.4
2023-01-03 12:33:11.364 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 12:33:11.368 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-6264_train.pkl
2023-01-03 12:33:13.551 DEBUG: Taking gradient step
2023-01-03 12:33:15.950 DEBUG: Loss 0: {'policy_loss': -0.01177405516998882, 'entropy_loss': -0.047439089976251125, 'vf_loss': 0.23259301004881291, 'total_loss': -0.059213145146239946, 'approx_kl': 2.468004822731018e-08, 'clip_fraction': 0.0, 'grad_norm': 20.49768829345703}
2023-01-03 12:33:18.140 DEBUG: Taking gradient step
2023-01-03 12:33:20.487 DEBUG: Loss 1: {'policy_loss': 0.020261047619364064, 'entropy_loss': -0.050827208906412125, 'vf_loss': 0.25649747245798155, 'total_loss': -0.03056616128704806, 'approx_kl': -0.003431334625929594, 'clip_fraction': 0.3268229216337204, 'grad_norm': 36.02460861206055}
2023-01-03 12:33:22.654 DEBUG: Taking gradient step
2023-01-03 12:33:24.867 DEBUG: Loss 2: {'policy_loss': 0.053934720759131506, 'entropy_loss': -0.048688486218452454, 'vf_loss': 0.23871489486733088, 'total_loss': 0.005246234540679056, 'approx_kl': -0.030107802245765924, 'clip_fraction': 0.3059895858168602, 'grad_norm': 41.21183776855469}
2023-01-03 12:33:27.136 DEBUG: Taking gradient step
2023-01-03 12:33:29.422 DEBUG: Loss 3: {'policy_loss': -0.010228378704347153, 'entropy_loss': -0.04898703470826149, 'vf_loss': 0.23005846747707304, 'total_loss': -0.05921541341260865, 'approx_kl': -0.025872660102322698, 'clip_fraction': 0.26171875, 'grad_norm': 34.81425476074219}
2023-01-03 12:33:31.588 DEBUG: Taking gradient step
2023-01-03 12:33:33.803 DEBUG: Loss 4: {'policy_loss': 0.025280165841209512, 'entropy_loss': -0.04994960129261017, 'vf_loss': 0.26340733807770755, 'total_loss': -0.024669435451400656, 'approx_kl': -0.04453587904572487, 'clip_fraction': 0.4153645858168602, 'grad_norm': 55.43497085571289}
2023-01-03 12:33:35.943 DEBUG: Taking gradient step
2023-01-03 12:33:38.139 DEBUG: Loss 5: {'policy_loss': 0.048938365858949014, 'entropy_loss': -0.05027342587709427, 'vf_loss': 0.22971848728262714, 'total_loss': -0.0013350600181452482, 'approx_kl': -0.038669911213219166, 'clip_fraction': 0.4973958358168602, 'grad_norm': 45.57281494140625}
2023-01-03 12:33:40.293 DEBUG: Taking gradient step
2023-01-03 12:33:42.517 DEBUG: Loss 6: {'policy_loss': 0.08113362329066838, 'entropy_loss': -0.05100524332374334, 'vf_loss': 0.22480907205176728, 'total_loss': 0.030128379966925033, 'approx_kl': -0.03063631011173129, 'clip_fraction': 0.4296875, 'grad_norm': 38.247894287109375}
2023-01-03 12:33:44.682 DEBUG: Taking gradient step
2023-01-03 12:33:46.880 DEBUG: Loss 7: {'policy_loss': 0.0874220628549041, 'entropy_loss': -0.051690785214304924, 'vf_loss': 0.22642999306206474, 'total_loss': 0.03573127764059918, 'approx_kl': -0.039170311618363485, 'clip_fraction': 0.4075520858168602, 'grad_norm': 40.21903610229492}
2023-01-03 12:33:49.105 DEBUG: Taking gradient step
2023-01-03 12:33:51.310 DEBUG: Loss 8: {'policy_loss': 0.11673801905649092, 'entropy_loss': -0.05165561195462942, 'vf_loss': 0.23016684417480465, 'total_loss': 0.0650824071018615, 'approx_kl': -0.04014646401628852, 'clip_fraction': 0.375, 'grad_norm': 43.83412170410156}
2023-01-03 12:33:53.475 DEBUG: Taking gradient step
2023-01-03 12:33:55.689 DEBUG: Loss 9: {'policy_loss': -0.02597885903988542, 'entropy_loss': -0.051894137635827065, 'vf_loss': 0.2378203252663132, 'total_loss': -0.07787299667571249, 'approx_kl': -0.04516531154513359, 'clip_fraction': 0.3841145858168602, 'grad_norm': 34.60464859008789}
2023-01-03 12:33:57.865 DEBUG: Taking gradient step
2023-01-03 12:34:00.091 DEBUG: Loss 10: {'policy_loss': 0.12355800718364664, 'entropy_loss': -0.050722419284284115, 'vf_loss': 0.22209677833096647, 'total_loss': 0.07283558789936251, 'approx_kl': -0.045925674960017204, 'clip_fraction': 0.359375, 'grad_norm': 36.30622863769531}
2023-01-03 12:34:02.246 DEBUG: Taking gradient step
2023-01-03 12:34:04.460 DEBUG: Loss 11: {'policy_loss': 0.07967684427897914, 'entropy_loss': -0.050039226189255714, 'vf_loss': 0.22304660835540707, 'total_loss': 0.029637618089723435, 'approx_kl': -0.04039836023002863, 'clip_fraction': 0.3072916716337204, 'grad_norm': 42.9808349609375}
2023-01-03 12:34:06.637 DEBUG: Taking gradient step
2023-01-03 12:34:08.862 DEBUG: Loss 12: {'policy_loss': 0.06050393656274472, 'entropy_loss': -0.05003103893250227, 'vf_loss': 0.22908050355311144, 'total_loss': 0.01047289763024245, 'approx_kl': -0.04533091001212597, 'clip_fraction': 0.3098958358168602, 'grad_norm': 27.122591018676758}
2023-01-03 12:34:11.028 DEBUG: Taking gradient step
2023-01-03 12:34:13.239 DEBUG: Loss 13: {'policy_loss': 0.022365944529580392, 'entropy_loss': -0.04919516947120428, 'vf_loss': 0.26087307713423874, 'total_loss': -0.02682922494162389, 'approx_kl': -0.05174035392701626, 'clip_fraction': 0.3880208358168602, 'grad_norm': 44.21982192993164}
2023-01-03 12:34:15.384 DEBUG: Taking gradient step
2023-01-03 12:34:17.608 DEBUG: Loss 14: {'policy_loss': 0.1171702112556835, 'entropy_loss': -0.052065880969166756, 'vf_loss': 0.2298485211779447, 'total_loss': 0.06510433028651674, 'approx_kl': -0.05778894480317831, 'clip_fraction': 0.3229166716337204, 'grad_norm': 42.97148513793945}
2023-01-03 12:34:17.609 INFO: Optimization: policy loss=0.117, vf loss=0.230, entropy loss=-0.052, total loss=0.065, num steps=15
2023-01-03 12:34:17.611 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 12:34:19.187 DEBUG: There is a single atom floating around
2023-01-03 12:34:19.189 INFO: Evaluation rollout: return=-29.120 (0.0), episode length=6.0
2023-01-03 12:34:19.190 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 12:34:19.192 INFO: Iteration: 30/137, steps: 6480
2023-01-03 12:34:34.728 DEBUG: Atoms are too close
2023-01-03 12:34:35.955 DEBUG: There is a single atom floating around
2023-01-03 12:34:36.249 DEBUG: Atoms are too close
2023-01-03 12:34:39.262 DEBUG: There is a single atom floating around
2023-01-03 12:34:51.565 DEBUG: There is a single atom floating around
2023-01-03 12:34:53.949 DEBUG: There is a single atom floating around
2023-01-03 12:34:54.250 DEBUG: There is a single atom floating around
2023-01-03 12:34:54.996 DEBUG: There is a single atom floating around
2023-01-03 12:34:54.996 DEBUG: Atoms are too close
2023-01-03 12:34:55.309 DEBUG: There is a single atom floating around
2023-01-03 12:34:55.716 DEBUG: There is a single atom floating around
2023-01-03 12:34:55.883 DEBUG: There is a single atom floating around
2023-01-03 12:34:56.057 DEBUG: Atoms are too close
2023-01-03 12:34:56.383 DEBUG: There is a single atom floating around
2023-01-03 12:35:02.176 DEBUG: Atoms are too close
2023-01-03 12:35:08.419 DEBUG: There is a single atom floating around
2023-01-03 12:35:10.370 DEBUG: There is a single atom floating around
2023-01-03 12:35:12.006 DEBUG: There is a single atom floating around
2023-01-03 12:35:12.010 DEBUG: Atoms are too close
2023-01-03 12:35:12.011 DEBUG: Atoms are too close
2023-01-03 12:35:12.311 DEBUG: Atoms are too close
2023-01-03 12:35:12.312 DEBUG: There is a single atom floating around
2023-01-03 12:35:12.480 DEBUG: There is a single atom floating around
2023-01-03 12:35:12.481 DEBUG: There is a single atom floating around
2023-01-03 12:35:12.880 DEBUG: Atoms are too close
2023-01-03 12:35:15.464 INFO: Training rollout: return=-20.178 (13.8), episode length=5.6
2023-01-03 12:35:15.466 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 12:35:15.468 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-6480_train.pkl
2023-01-03 12:35:17.808 DEBUG: Taking gradient step
2023-01-03 12:35:20.319 DEBUG: Loss 0: {'policy_loss': 0.003466214226770681, 'entropy_loss': -0.05157823394984007, 'vf_loss': 0.19328003372091007, 'total_loss': -0.04811201972306939, 'approx_kl': -8.789356797933578e-08, 'clip_fraction': 0.0, 'grad_norm': 8.950366973876953}
2023-01-03 12:35:22.640 DEBUG: Taking gradient step
2023-01-03 12:35:24.905 DEBUG: Loss 1: {'policy_loss': 0.016950701179536048, 'entropy_loss': -0.050079899840056896, 'vf_loss': 0.19247640289191084, 'total_loss': -0.033129198660520845, 'approx_kl': -0.008294058963656425, 'clip_fraction': 0.2356770858168602, 'grad_norm': 25.59648323059082}
2023-01-03 12:35:27.154 DEBUG: Taking gradient step
2023-01-03 12:35:29.573 DEBUG: Loss 2: {'policy_loss': 0.08629841112315301, 'entropy_loss': -0.05042244866490364, 'vf_loss': 0.1879993387541467, 'total_loss': 0.035875962458249366, 'approx_kl': -0.024841933511197567, 'clip_fraction': 0.4713541716337204, 'grad_norm': 23.390247344970703}
2023-01-03 12:35:31.868 DEBUG: Taking gradient step
2023-01-03 12:35:34.257 DEBUG: Loss 3: {'policy_loss': 0.04220997550872483, 'entropy_loss': -0.04925135336816311, 'vf_loss': 0.18867919875997513, 'total_loss': -0.0070413778594382755, 'approx_kl': -0.027355751022696495, 'clip_fraction': 0.4505208358168602, 'grad_norm': 25.001245498657227}
2023-01-03 12:35:36.441 DEBUG: Taking gradient step
2023-01-03 12:35:38.746 DEBUG: Loss 4: {'policy_loss': 0.017106880916267803, 'entropy_loss': -0.050565581768751144, 'vf_loss': 0.1911791458289, 'total_loss': -0.03345870085248334, 'approx_kl': -0.027086005080491304, 'clip_fraction': 0.49609375, 'grad_norm': 29.899288177490234}
2023-01-03 12:35:41.018 DEBUG: Taking gradient step
2023-01-03 12:35:43.284 DEBUG: Loss 5: {'policy_loss': 0.022451235861243733, 'entropy_loss': -0.04997673165053129, 'vf_loss': 0.19971033667391647, 'total_loss': -0.027525495789287556, 'approx_kl': -0.013886591070331633, 'clip_fraction': 0.3893229216337204, 'grad_norm': 21.474538803100586}
2023-01-03 12:35:45.470 DEBUG: Taking gradient step
2023-01-03 12:35:47.718 DEBUG: Loss 6: {'policy_loss': 0.018849311307733353, 'entropy_loss': -0.05140300653874874, 'vf_loss': 0.22311068087702035, 'total_loss': -0.03255369523101539, 'approx_kl': -0.044125272892415524, 'clip_fraction': 0.3424479216337204, 'grad_norm': 21.675357818603516}
2023-01-03 12:35:49.972 DEBUG: Taking gradient step
2023-01-03 12:35:52.477 DEBUG: Loss 7: {'policy_loss': 0.04156484810921521, 'entropy_loss': -0.052177767269313335, 'vf_loss': 0.19811314047562137, 'total_loss': -0.010612919160098124, 'approx_kl': -0.03667546308133751, 'clip_fraction': 0.3072916716337204, 'grad_norm': 11.75676441192627}
2023-01-03 12:35:54.691 DEBUG: Taking gradient step
2023-01-03 12:35:56.943 DEBUG: Loss 8: {'policy_loss': 0.03866250544289679, 'entropy_loss': -0.05231884494423866, 'vf_loss': 0.19133690861401703, 'total_loss': -0.013656339501341874, 'approx_kl': -0.03582405997440219, 'clip_fraction': 0.3151041716337204, 'grad_norm': 27.769067764282227}
2023-01-03 12:35:59.183 DEBUG: Taking gradient step
2023-01-03 12:36:01.447 DEBUG: Loss 9: {'policy_loss': 0.03955499022480648, 'entropy_loss': -0.049304245971143246, 'vf_loss': 0.1884060069854374, 'total_loss': -0.009749255746336769, 'approx_kl': -0.04333993955515325, 'clip_fraction': 0.3854166716337204, 'grad_norm': 26.717153549194336}
2023-01-03 12:36:03.667 DEBUG: Taking gradient step
2023-01-03 12:36:05.913 DEBUG: Loss 10: {'policy_loss': 0.05032153188393082, 'entropy_loss': -0.049592808820307255, 'vf_loss': 0.19354778422240307, 'total_loss': 0.0007287230636235618, 'approx_kl': -0.05062470003031194, 'clip_fraction': 0.4114583358168602, 'grad_norm': 21.503231048583984}
2023-01-03 12:36:08.107 DEBUG: Taking gradient step
2023-01-03 12:36:10.369 DEBUG: Loss 11: {'policy_loss': 0.0744786236334586, 'entropy_loss': -0.04878359753638506, 'vf_loss': 0.207160018108178, 'total_loss': 0.02569502609707354, 'approx_kl': -0.029972211457788944, 'clip_fraction': 0.4192708358168602, 'grad_norm': 25.936283111572266}
2023-01-03 12:36:12.556 DEBUG: Taking gradient step
2023-01-03 12:36:14.812 DEBUG: Loss 12: {'policy_loss': 0.08490228561897137, 'entropy_loss': -0.049990023486316204, 'vf_loss': 0.21151951383529838, 'total_loss': 0.034912262132655164, 'approx_kl': -0.06133653735741973, 'clip_fraction': 0.4309895858168602, 'grad_norm': 18.479286193847656}
2023-01-03 12:36:17.034 DEBUG: Taking gradient step
2023-01-03 12:36:19.364 DEBUG: Loss 13: {'policy_loss': 0.03692631433289756, 'entropy_loss': -0.04953303653746843, 'vf_loss': 0.20604934434248862, 'total_loss': -0.012606722204570875, 'approx_kl': -0.04875576123595238, 'clip_fraction': 0.4114583358168602, 'grad_norm': 25.358814239501953}
2023-01-03 12:36:21.653 DEBUG: Taking gradient step
2023-01-03 12:36:23.890 DEBUG: Loss 14: {'policy_loss': 0.008946255683192787, 'entropy_loss': -0.050581022165715694, 'vf_loss': 0.19942414852665616, 'total_loss': -0.04163476648252291, 'approx_kl': -0.06054466776549816, 'clip_fraction': 0.40234375, 'grad_norm': 16.549964904785156}
2023-01-03 12:36:23.890 INFO: Optimization: policy loss=0.009, vf loss=0.199, entropy loss=-0.051, total loss=-0.042, num steps=15
2023-01-03 12:36:23.892 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 12:36:25.796 INFO: Evaluation rollout: return=0.924 (0.0), episode length=6.0
2023-01-03 12:36:25.797 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 12:36:25.801 DEBUG: Deleting old model: runs/CH3NO_dna/models/CH3NO_dna_run-1_steps-4536.model
2023-01-03 12:36:25.808 DEBUG: Saving model: runs/CH3NO_dna/models/CH3NO_dna_run-1_steps-6696.model
2023-01-03 12:36:25.861 INFO: Iteration: 31/137, steps: 6696
2023-01-03 12:36:37.752 DEBUG: Atoms are too close
2023-01-03 12:36:40.358 DEBUG: There is a single atom floating around
2023-01-03 12:36:42.829 DEBUG: Atoms are too close
2023-01-03 12:36:43.264 DEBUG: There is a single atom floating around
2023-01-03 12:36:45.010 DEBUG: There is a single atom floating around
2023-01-03 12:36:45.011 DEBUG: There is a single atom floating around
2023-01-03 12:36:58.881 DEBUG: There is a single atom floating around
2023-01-03 12:37:00.115 DEBUG: There is a single atom floating around
2023-01-03 12:37:00.838 DEBUG: There is a single atom floating around
2023-01-03 12:37:01.631 DEBUG: There is a single atom floating around
2023-01-03 12:37:02.534 DEBUG: Atoms are too close
2023-01-03 12:37:04.683 DEBUG: There is a single atom floating around
2023-01-03 12:37:14.547 DEBUG: There is a single atom floating around
2023-01-03 12:37:18.393 DEBUG: There is a single atom floating around
2023-01-03 12:37:21.092 DEBUG: There is a single atom floating around
2023-01-03 12:37:22.783 DEBUG: There is a single atom floating around
2023-01-03 12:37:24.109 DEBUG: There is a single atom floating around
2023-01-03 12:37:25.284 INFO: Training rollout: return=-13.551 (15.0), episode length=5.7
2023-01-03 12:37:25.285 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 12:37:25.289 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-6696_train.pkl
2023-01-03 12:37:27.553 DEBUG: Taking gradient step
2023-01-03 12:37:29.846 DEBUG: Loss 0: {'policy_loss': -0.024567455112251935, 'entropy_loss': -0.053395314142107964, 'vf_loss': 0.23228473055814158, 'total_loss': -0.0779627692543599, 'approx_kl': 4.221995730802064e-08, 'clip_fraction': 0.0, 'grad_norm': 19.766279220581055}
2023-01-03 12:37:32.166 DEBUG: Taking gradient step
2023-01-03 12:37:34.739 DEBUG: Loss 1: {'policy_loss': 0.030087887492592953, 'entropy_loss': -0.0525427358224988, 'vf_loss': 0.25503006960816116, 'total_loss': -0.022454848329905852, 'approx_kl': 0.0037531371926888824, 'clip_fraction': 0.16015625, 'grad_norm': 17.347427368164062}
2023-01-03 12:37:36.965 DEBUG: Taking gradient step
2023-01-03 12:37:39.386 DEBUG: Loss 2: {'policy_loss': 0.06024743237582373, 'entropy_loss': -0.05248140171170235, 'vf_loss': 0.28273144047378695, 'total_loss': 0.007766030664121388, 'approx_kl': 0.00733080692589283, 'clip_fraction': 0.38671875, 'grad_norm': 37.67121887207031}
2023-01-03 12:37:41.657 DEBUG: Taking gradient step
2023-01-03 12:37:43.913 DEBUG: Loss 3: {'policy_loss': 0.040846930601418835, 'entropy_loss': -0.05355880223214626, 'vf_loss': 0.2724696310795634, 'total_loss': -0.012711871630727425, 'approx_kl': 0.009278707206249237, 'clip_fraction': 0.3098958358168602, 'grad_norm': 20.082477569580078}
2023-01-03 12:37:46.128 DEBUG: Taking gradient step
2023-01-03 12:37:48.634 DEBUG: Loss 4: {'policy_loss': 0.052728391959698015, 'entropy_loss': -0.052683549001812935, 'vf_loss': 0.23737702172979583, 'total_loss': 4.484295788508008e-05, 'approx_kl': -0.01758345402777195, 'clip_fraction': 0.2109375, 'grad_norm': 18.787853240966797}
2023-01-03 12:37:50.845 DEBUG: Taking gradient step
2023-01-03 12:37:53.099 DEBUG: Loss 5: {'policy_loss': 0.003840408574962269, 'entropy_loss': -0.052629184909164906, 'vf_loss': 0.2120199048752453, 'total_loss': -0.048788776334202644, 'approx_kl': -0.010244116187095642, 'clip_fraction': 0.3515625, 'grad_norm': 29.109243392944336}
2023-01-03 12:37:55.312 DEBUG: Taking gradient step
2023-01-03 12:37:57.611 DEBUG: Loss 6: {'policy_loss': 0.02107745479834091, 'entropy_loss': -0.05237475596368313, 'vf_loss': 0.20720933585073004, 'total_loss': -0.03129730116534222, 'approx_kl': -0.010307342861779034, 'clip_fraction': 0.2526041716337204, 'grad_norm': 19.426517486572266}
2023-01-03 12:37:59.865 DEBUG: Taking gradient step
2023-01-03 12:38:02.144 DEBUG: Loss 7: {'policy_loss': -0.007513462337585035, 'entropy_loss': -0.052025468088686466, 'vf_loss': 0.21396993374793907, 'total_loss': -0.0595389304262715, 'approx_kl': -0.03317771106958389, 'clip_fraction': 0.2434895858168602, 'grad_norm': 19.9423770904541}
2023-01-03 12:38:04.505 DEBUG: Taking gradient step
2023-01-03 12:38:06.791 DEBUG: Loss 8: {'policy_loss': -0.03593153244481692, 'entropy_loss': -0.05120079778134823, 'vf_loss': 0.21951190680805605, 'total_loss': -0.08713233022616515, 'approx_kl': -0.030906617641448975, 'clip_fraction': 0.3059895858168602, 'grad_norm': 18.33375358581543}
2023-01-03 12:38:09.022 DEBUG: Taking gradient step
2023-01-03 12:38:11.314 DEBUG: Loss 9: {'policy_loss': 0.021919264647423758, 'entropy_loss': -0.05241033807396889, 'vf_loss': 0.24169545694368222, 'total_loss': -0.030491073426545133, 'approx_kl': -0.0382671058177948, 'clip_fraction': 0.3138020858168602, 'grad_norm': 20.831676483154297}
2023-01-03 12:38:13.820 DEBUG: Taking gradient step
2023-01-03 12:38:16.333 DEBUG: Loss 10: {'policy_loss': 0.020904272584896258, 'entropy_loss': -0.053505104035139084, 'vf_loss': 0.24913891646517908, 'total_loss': -0.032600831450242826, 'approx_kl': -0.050029858481138945, 'clip_fraction': 0.2864583358168602, 'grad_norm': 11.704739570617676}
2023-01-03 12:38:18.593 DEBUG: Taking gradient step
2023-01-03 12:38:20.883 DEBUG: Loss 11: {'policy_loss': 0.011725430310814485, 'entropy_loss': -0.052119639702141285, 'vf_loss': 0.2533665392773937, 'total_loss': -0.040394209391326805, 'approx_kl': -0.014525604114169255, 'clip_fraction': 0.2942708358168602, 'grad_norm': 17.930644989013672}
2023-01-03 12:38:23.173 DEBUG: Taking gradient step
2023-01-03 12:38:25.464 DEBUG: Loss 12: {'policy_loss': 0.054743149776832895, 'entropy_loss': -0.050550589337944984, 'vf_loss': 0.25295063008717655, 'total_loss': 0.00419256043888791, 'approx_kl': -0.04145151376724243, 'clip_fraction': 0.3138020858168602, 'grad_norm': 34.22863006591797}
2023-01-03 12:38:27.788 DEBUG: Taking gradient step
2023-01-03 12:38:30.143 DEBUG: Loss 13: {'policy_loss': -0.003227266079344992, 'entropy_loss': -0.05205481871962547, 'vf_loss': 0.24788313805272166, 'total_loss': -0.05528208479897047, 'approx_kl': -0.02408132329583168, 'clip_fraction': 0.33984375, 'grad_norm': 18.156503677368164}
2023-01-03 12:38:32.377 DEBUG: Taking gradient step
2023-01-03 12:38:34.831 DEBUG: Loss 14: {'policy_loss': 0.013512308671701905, 'entropy_loss': -0.052544841542840004, 'vf_loss': 0.24323037247242002, 'total_loss': -0.0390325328711381, 'approx_kl': -0.026467994786798954, 'clip_fraction': 0.3893229216337204, 'grad_norm': 14.403010368347168}
2023-01-03 12:38:34.831 INFO: Optimization: policy loss=0.014, vf loss=0.243, entropy loss=-0.053, total loss=-0.039, num steps=15
2023-01-03 12:38:34.833 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 12:38:36.496 DEBUG: Atoms are too close
2023-01-03 12:38:36.498 INFO: Evaluation rollout: return=-29.149 (0.0), episode length=6.0
2023-01-03 12:38:36.499 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 12:38:36.503 INFO: Iteration: 32/137, steps: 6912
2023-01-03 12:38:48.187 DEBUG: Atoms are too close
2023-01-03 12:38:52.237 DEBUG: Atoms are too close
2023-01-03 12:38:52.239 DEBUG: There is a single atom floating around
2023-01-03 12:38:52.571 DEBUG: There is a single atom floating around
2023-01-03 12:38:52.572 DEBUG: There is a single atom floating around
2023-01-03 12:38:53.333 DEBUG: There is a single atom floating around
2023-01-03 12:39:00.431 DEBUG: There is a single atom floating around
2023-01-03 12:39:09.303 DEBUG: There is a single atom floating around
2023-01-03 12:39:10.411 DEBUG: Atoms are too close
2023-01-03 12:39:10.783 DEBUG: There is a single atom floating around
2023-01-03 12:39:11.580 DEBUG: There is a single atom floating around
2023-01-03 12:39:11.581 DEBUG: There is a single atom floating around
2023-01-03 12:39:11.581 DEBUG: Atoms are too close
2023-01-03 12:39:11.758 DEBUG: Atoms are too close
2023-01-03 12:39:12.176 DEBUG: Atoms are too close
2023-01-03 12:39:14.522 DEBUG: Atoms are too close
2023-01-03 12:39:19.506 DEBUG: Atoms are too close
2023-01-03 12:39:20.452 DEBUG: Atoms are too close
2023-01-03 12:39:25.011 DEBUG: There is a single atom floating around
2023-01-03 12:39:25.328 DEBUG: Atoms are too close
2023-01-03 12:39:26.611 DEBUG: Atoms are too close
2023-01-03 12:39:26.960 DEBUG: There is a single atom floating around
2023-01-03 12:39:29.045 DEBUG: There is a single atom floating around
2023-01-03 12:39:31.541 DEBUG: There is a single atom floating around
2023-01-03 12:39:33.860 DEBUG: There is a single atom floating around
2023-01-03 12:39:33.940 INFO: Training rollout: return=-20.290 (13.9), episode length=5.5
2023-01-03 12:39:33.942 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 12:39:33.944 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-6912_train.pkl
2023-01-03 12:39:36.163 DEBUG: Taking gradient step
2023-01-03 12:39:38.412 DEBUG: Loss 0: {'policy_loss': -0.03471998226203574, 'entropy_loss': -0.05176731385290623, 'vf_loss': 0.2952679319431307, 'total_loss': -0.08648729611494195, 'approx_kl': 8.269368478863726e-08, 'clip_fraction': 0.0, 'grad_norm': 12.846405982971191}
2023-01-03 12:39:40.616 DEBUG: Taking gradient step
2023-01-03 12:39:42.866 DEBUG: Loss 1: {'policy_loss': -0.02857504303607493, 'entropy_loss': -0.05161010753363371, 'vf_loss': 0.2765826685088801, 'total_loss': -0.08018515056970864, 'approx_kl': 0.009186898590996861, 'clip_fraction': 0.10416666697710752, 'grad_norm': 14.033226013183594}
2023-01-03 12:39:45.070 DEBUG: Taking gradient step
2023-01-03 12:39:47.295 DEBUG: Loss 2: {'policy_loss': 0.04590615562273261, 'entropy_loss': -0.05129221174865961, 'vf_loss': 0.2532315324956896, 'total_loss': -0.005386056125926998, 'approx_kl': -0.00571868265978992, 'clip_fraction': 0.3046875, 'grad_norm': 27.021547317504883}
2023-01-03 12:39:49.481 DEBUG: Taking gradient step
2023-01-03 12:39:51.975 DEBUG: Loss 3: {'policy_loss': 0.0506255878954215, 'entropy_loss': -0.0511837275698781, 'vf_loss': 0.22865364858740447, 'total_loss': -0.0005581396744565939, 'approx_kl': 0.006132107228040695, 'clip_fraction': 0.359375, 'grad_norm': 17.404829025268555}
2023-01-03 12:39:54.199 DEBUG: Taking gradient step
2023-01-03 12:39:56.576 DEBUG: Loss 4: {'policy_loss': -0.005823232163323491, 'entropy_loss': -0.05220574978739023, 'vf_loss': 0.20760995568449833, 'total_loss': -0.05802898195071372, 'approx_kl': 0.0059450538828969, 'clip_fraction': 0.4231770858168602, 'grad_norm': 13.306236267089844}
2023-01-03 12:39:58.778 DEBUG: Taking gradient step
2023-01-03 12:40:01.055 DEBUG: Loss 5: {'policy_loss': 0.05918865612080111, 'entropy_loss': -0.05178363714367151, 'vf_loss': 0.19372159861817823, 'total_loss': 0.007405018977129599, 'approx_kl': -0.013707078993320465, 'clip_fraction': 0.4973958432674408, 'grad_norm': 15.52574348449707}
2023-01-03 12:40:03.397 DEBUG: Taking gradient step
2023-01-03 12:40:05.659 DEBUG: Loss 6: {'policy_loss': 0.08333816877505096, 'entropy_loss': -0.050174095667898655, 'vf_loss': 0.2061095125387413, 'total_loss': 0.03316407310715229, 'approx_kl': -0.011667326092720032, 'clip_fraction': 0.4309895858168602, 'grad_norm': 21.850566864013672}
2023-01-03 12:40:07.856 DEBUG: Taking gradient step
2023-01-03 12:40:10.193 DEBUG: Loss 7: {'policy_loss': 0.0609192036176022, 'entropy_loss': -0.05137391574680805, 'vf_loss': 0.22415890765808785, 'total_loss': 0.009545287870794152, 'approx_kl': -0.032453729305416346, 'clip_fraction': 0.515625, 'grad_norm': 16.630786895751953}
2023-01-03 12:40:12.380 DEBUG: Taking gradient step
2023-01-03 12:40:14.618 DEBUG: Loss 8: {'policy_loss': 0.06847121346703165, 'entropy_loss': -0.05008817557245493, 'vf_loss': 0.230785816379775, 'total_loss': 0.018383037894576727, 'approx_kl': -0.01819672016426921, 'clip_fraction': 0.4700520858168602, 'grad_norm': 25.91489601135254}
2023-01-03 12:40:16.822 DEBUG: Taking gradient step
2023-01-03 12:40:19.133 DEBUG: Loss 9: {'policy_loss': 0.03945165414778746, 'entropy_loss': -0.049528186209499836, 'vf_loss': 0.20935330825718151, 'total_loss': -0.01007653206171238, 'approx_kl': -0.023856795392930508, 'clip_fraction': 0.3736979216337204, 'grad_norm': 26.148563385009766}
2023-01-03 12:40:21.312 DEBUG: Taking gradient step
2023-01-03 12:40:23.588 DEBUG: Loss 10: {'policy_loss': 0.0452504136469789, 'entropy_loss': -0.049917218275368214, 'vf_loss': 0.19473169352967387, 'total_loss': -0.004666804628389318, 'approx_kl': -0.040529937483370304, 'clip_fraction': 0.4153645932674408, 'grad_norm': 21.438114166259766}
2023-01-03 12:40:25.776 DEBUG: Taking gradient step
2023-01-03 12:40:28.018 DEBUG: Loss 11: {'policy_loss': 0.03074989290938418, 'entropy_loss': -0.05196513421833515, 'vf_loss': 0.19800275120182853, 'total_loss': -0.02121524130895097, 'approx_kl': -0.045215033926069736, 'clip_fraction': 0.4661458358168602, 'grad_norm': 20.76488494873047}
2023-01-03 12:40:30.250 DEBUG: Taking gradient step
2023-01-03 12:40:32.669 DEBUG: Loss 12: {'policy_loss': 0.08603430158089011, 'entropy_loss': -0.05179843585938215, 'vf_loss': 0.2013765233598429, 'total_loss': 0.03423586572150795, 'approx_kl': -0.052695680409669876, 'clip_fraction': 0.51953125, 'grad_norm': 26.08258819580078}
2023-01-03 12:40:35.088 DEBUG: Taking gradient step
2023-01-03 12:40:37.351 DEBUG: Loss 13: {'policy_loss': 0.12975270327041596, 'entropy_loss': -0.051436083391308784, 'vf_loss': 0.20782525518662465, 'total_loss': 0.0783166198791072, 'approx_kl': -0.048154499381780624, 'clip_fraction': 0.5169270858168602, 'grad_norm': 19.655887603759766}
2023-01-03 12:40:39.610 DEBUG: Taking gradient step
2023-01-03 12:40:41.868 DEBUG: Loss 14: {'policy_loss': 0.10832999317671523, 'entropy_loss': -0.05304990988224745, 'vf_loss': 0.21054243409900877, 'total_loss': 0.05528008329446778, 'approx_kl': -0.061416865326464176, 'clip_fraction': 0.4674479216337204, 'grad_norm': 27.540708541870117}
2023-01-03 12:40:41.869 INFO: Optimization: policy loss=0.108, vf loss=0.211, entropy loss=-0.053, total loss=0.055, num steps=15
2023-01-03 12:40:41.870 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 12:40:43.782 INFO: Evaluation rollout: return=0.881 (0.0), episode length=6.0
2023-01-03 12:40:43.784 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 12:40:43.789 INFO: Iteration: 33/137, steps: 7128
2023-01-03 12:40:54.028 DEBUG: Atoms are too close
2023-01-03 12:40:58.871 DEBUG: There is a single atom floating around
2023-01-03 12:41:00.137 DEBUG: Atoms are too close
2023-01-03 12:41:01.199 DEBUG: There is a single atom floating around
2023-01-03 12:41:01.200 DEBUG: Atoms are too close
2023-01-03 12:41:02.004 DEBUG: Atoms are too close
2023-01-03 12:41:02.005 DEBUG: There is a single atom floating around
2023-01-03 12:41:09.518 DEBUG: There is a single atom floating around
2023-01-03 12:41:12.043 DEBUG: There is a single atom floating around
2023-01-03 12:41:13.883 DEBUG: There is a single atom floating around
2023-01-03 12:41:13.884 DEBUG: There is a single atom floating around
2023-01-03 12:41:16.807 DEBUG: Atoms are too close
2023-01-03 12:41:17.464 DEBUG: There is a single atom floating around
2023-01-03 12:41:19.536 DEBUG: There is a single atom floating around
2023-01-03 12:41:20.351 DEBUG: Atoms are too close
2023-01-03 12:41:24.322 DEBUG: Atoms are too close
2023-01-03 12:41:24.876 DEBUG: There is a single atom floating around
2023-01-03 12:41:29.241 DEBUG: There is a single atom floating around
2023-01-03 12:41:34.356 DEBUG: There is a single atom floating around
2023-01-03 12:41:37.502 DEBUG: There is a single atom floating around
2023-01-03 12:41:38.020 DEBUG: There is a single atom floating around
2023-01-03 12:41:41.814 INFO: Training rollout: return=-16.465 (14.9), episode length=5.5
2023-01-03 12:41:41.815 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 12:41:41.820 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-7128_train.pkl
2023-01-03 12:41:44.043 DEBUG: Taking gradient step
2023-01-03 12:41:46.359 DEBUG: Loss 0: {'policy_loss': 0.03127384199679236, 'entropy_loss': -0.05608287360519171, 'vf_loss': 0.2094701048229406, 'total_loss': -0.024809031608399347, 'approx_kl': -4.450945922940264e-08, 'clip_fraction': 0.0, 'grad_norm': 20.182052612304688}
2023-01-03 12:41:48.573 DEBUG: Taking gradient step
2023-01-03 12:41:50.813 DEBUG: Loss 1: {'policy_loss': 0.05340495464846106, 'entropy_loss': -0.053334799595177174, 'vf_loss': 0.1986239736925834, 'total_loss': 7.015505328388655e-05, 'approx_kl': -0.0008535601664334536, 'clip_fraction': 0.4049479216337204, 'grad_norm': 39.38349533081055}
2023-01-03 12:41:52.991 DEBUG: Taking gradient step
2023-01-03 12:41:55.251 DEBUG: Loss 2: {'policy_loss': 0.10890062406330026, 'entropy_loss': -0.05486965924501419, 'vf_loss': 0.20800140710397252, 'total_loss': 0.054030964818286065, 'approx_kl': -0.04029618017375469, 'clip_fraction': 0.5364583432674408, 'grad_norm': 46.79014587402344}
2023-01-03 12:41:57.463 DEBUG: Taking gradient step
2023-01-03 12:41:59.730 DEBUG: Loss 3: {'policy_loss': 0.07116155460047743, 'entropy_loss': -0.05432899761945009, 'vf_loss': 0.21107329698225707, 'total_loss': 0.01683255698102734, 'approx_kl': -0.021875082748010755, 'clip_fraction': 0.5455729216337204, 'grad_norm': 30.9624080657959}
2023-01-03 12:42:01.986 DEBUG: Taking gradient step
2023-01-03 12:42:04.513 DEBUG: Loss 4: {'policy_loss': 0.06635248126209684, 'entropy_loss': -0.0552997961640358, 'vf_loss': 0.22123111141930482, 'total_loss': 0.011052685098061038, 'approx_kl': -0.08633678359910846, 'clip_fraction': 0.5364583432674408, 'grad_norm': 42.326595306396484}
2023-01-03 12:42:06.717 DEBUG: Taking gradient step
2023-01-03 12:42:09.082 DEBUG: Loss 5: {'policy_loss': 0.11752824578268563, 'entropy_loss': -0.05549981817603111, 'vf_loss': 0.21631842245498237, 'total_loss': 0.062028427606654515, 'approx_kl': -0.0688068587332964, 'clip_fraction': 0.4986979216337204, 'grad_norm': 38.683128356933594}
2023-01-03 12:42:11.287 DEBUG: Taking gradient step
2023-01-03 12:42:13.637 DEBUG: Loss 6: {'policy_loss': 0.10465348836488154, 'entropy_loss': -0.05532303545624018, 'vf_loss': 0.21057006087859853, 'total_loss': 0.04933045290864137, 'approx_kl': -0.08163308259099722, 'clip_fraction': 0.4427083358168602, 'grad_norm': 31.503585815429688}
2023-01-03 12:42:15.977 DEBUG: Taking gradient step
2023-01-03 12:42:18.243 DEBUG: Loss 7: {'policy_loss': 0.12473707499750193, 'entropy_loss': -0.056005027145147324, 'vf_loss': 0.21133777303421514, 'total_loss': 0.06873204785235461, 'approx_kl': -0.09785167360678315, 'clip_fraction': 0.4921875, 'grad_norm': 48.64073181152344}
2023-01-03 12:42:20.443 DEBUG: Taking gradient step
2023-01-03 12:42:22.682 DEBUG: Loss 8: {'policy_loss': 0.11043978947349481, 'entropy_loss': -0.056600955314934254, 'vf_loss': 0.20564510084619947, 'total_loss': 0.053838834158560556, 'approx_kl': -0.05836368352174759, 'clip_fraction': 0.48046875, 'grad_norm': 25.010364532470703}
2023-01-03 12:42:24.884 DEBUG: Taking gradient step
2023-01-03 12:42:27.209 DEBUG: Loss 9: {'policy_loss': -0.00674603220391598, 'entropy_loss': -0.05606012046337128, 'vf_loss': 0.20433638750477004, 'total_loss': -0.06280615266728726, 'approx_kl': -0.07012180238962173, 'clip_fraction': 0.3515625, 'grad_norm': 17.222000122070312}
2023-01-03 12:42:29.545 DEBUG: Taking gradient step
2023-01-03 12:42:31.812 DEBUG: Loss 10: {'policy_loss': 0.0872367078515908, 'entropy_loss': -0.05738642066717148, 'vf_loss': 0.20998211137074405, 'total_loss': 0.029850287184419316, 'approx_kl': -0.07901811227202415, 'clip_fraction': 0.3736979216337204, 'grad_norm': 54.290809631347656}
2023-01-03 12:42:34.165 DEBUG: Taking gradient step
2023-01-03 12:42:36.428 DEBUG: Loss 11: {'policy_loss': 0.04995823624804828, 'entropy_loss': -0.05506218783557415, 'vf_loss': 0.2134944728094221, 'total_loss': -0.005103951587525878, 'approx_kl': -0.0742730088531971, 'clip_fraction': 0.421875, 'grad_norm': 25.36132049560547}
2023-01-03 12:42:38.677 DEBUG: Taking gradient step
2023-01-03 12:42:40.941 DEBUG: Loss 12: {'policy_loss': 0.052550278824957844, 'entropy_loss': -0.05349998641759157, 'vf_loss': 0.21433244787269856, 'total_loss': -0.0009497075926337278, 'approx_kl': -0.067054174374789, 'clip_fraction': 0.4140625, 'grad_norm': 15.474519729614258}
2023-01-03 12:42:43.136 DEBUG: Taking gradient step
2023-01-03 12:42:45.419 DEBUG: Loss 13: {'policy_loss': 0.07768850537813589, 'entropy_loss': -0.05550711415708065, 'vf_loss': 0.21652050450554097, 'total_loss': 0.022181391221055235, 'approx_kl': -0.08347395341843367, 'clip_fraction': 0.4622395932674408, 'grad_norm': 27.594091415405273}
2023-01-03 12:42:47.631 DEBUG: Taking gradient step
2023-01-03 12:42:49.900 DEBUG: Loss 14: {'policy_loss': 0.140167448568221, 'entropy_loss': -0.05431428179144859, 'vf_loss': 0.21472650929809395, 'total_loss': 0.0858531667767724, 'approx_kl': -0.05879370681941509, 'clip_fraction': 0.4361979216337204, 'grad_norm': 35.92980194091797}
2023-01-03 12:42:49.901 INFO: Optimization: policy loss=0.140, vf loss=0.215, entropy loss=-0.054, total loss=0.086, num steps=15
2023-01-03 12:42:49.903 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 12:42:51.802 INFO: Evaluation rollout: return=0.832 (0.0), episode length=6.0
2023-01-03 12:42:51.804 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 12:42:51.807 INFO: Iteration: 34/137, steps: 7344
2023-01-03 12:43:01.994 DEBUG: There is a single atom floating around
2023-01-03 12:43:07.324 DEBUG: There is a single atom floating around
2023-01-03 12:43:07.325 DEBUG: There is a single atom floating around
2023-01-03 12:43:09.660 DEBUG: There is a single atom floating around
2023-01-03 12:43:09.662 DEBUG: There is a single atom floating around
2023-01-03 12:43:09.662 DEBUG: There is a single atom floating around
2023-01-03 12:43:10.623 DEBUG: There is a single atom floating around
2023-01-03 12:43:11.002 DEBUG: There is a single atom floating around
2023-01-03 12:43:21.383 DEBUG: There is a single atom floating around
2023-01-03 12:43:22.959 DEBUG: There is a single atom floating around
2023-01-03 12:43:23.293 DEBUG: Atoms are too close
2023-01-03 12:43:25.908 DEBUG: Atoms are too close
2023-01-03 12:43:26.926 DEBUG: There is a single atom floating around
2023-01-03 12:43:27.666 DEBUG: Atoms are too close
2023-01-03 12:43:30.108 DEBUG: Atoms are too close
2023-01-03 12:43:37.036 DEBUG: There is a single atom floating around
2023-01-03 12:43:38.972 DEBUG: There is a single atom floating around
2023-01-03 12:43:41.434 DEBUG: There is a single atom floating around
2023-01-03 12:43:42.573 DEBUG: Atoms are too close
2023-01-03 12:43:44.744 DEBUG: There is a single atom floating around
2023-01-03 12:43:45.914 DEBUG: Atoms are too close
2023-01-03 12:43:45.916 DEBUG: There is a single atom floating around
2023-01-03 12:43:46.614 DEBUG: There is a single atom floating around
2023-01-03 12:43:46.615 DEBUG: Atoms are too close
2023-01-03 12:43:48.395 DEBUG: There is a single atom floating around
2023-01-03 12:43:48.476 INFO: Training rollout: return=-19.676 (14.1), episode length=5.4
2023-01-03 12:43:48.478 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 12:43:48.481 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-7344_train.pkl
2023-01-03 12:43:50.758 DEBUG: Taking gradient step
2023-01-03 12:43:53.005 DEBUG: Loss 0: {'policy_loss': 0.02619587171022867, 'entropy_loss': -0.05554644297808409, 'vf_loss': 0.22296544097360899, 'total_loss': -0.029350571267855417, 'approx_kl': 2.079953753675312e-08, 'clip_fraction': 0.0, 'grad_norm': 10.424005508422852}
2023-01-03 12:43:55.187 DEBUG: Taking gradient step
2023-01-03 12:43:57.418 DEBUG: Loss 1: {'policy_loss': 0.04175819042376028, 'entropy_loss': -0.05513683333992958, 'vf_loss': 0.21241777390234393, 'total_loss': -0.013378642916169303, 'approx_kl': -0.01477818621788174, 'clip_fraction': 0.21875, 'grad_norm': 19.331737518310547}
2023-01-03 12:43:59.789 DEBUG: Taking gradient step
2023-01-03 12:44:02.091 DEBUG: Loss 2: {'policy_loss': 0.08486246110999861, 'entropy_loss': -0.057460892014205456, 'vf_loss': 0.20619545916354476, 'total_loss': 0.027401569095793152, 'approx_kl': -0.03164789825677872, 'clip_fraction': 0.3333333358168602, 'grad_norm': 17.901809692382812}
2023-01-03 12:44:04.267 DEBUG: Taking gradient step
2023-01-03 12:44:06.625 DEBUG: Loss 3: {'policy_loss': 0.07031613005158041, 'entropy_loss': -0.05929371248930693, 'vf_loss': 0.19520544497303788, 'total_loss': 0.011022417562273496, 'approx_kl': -0.0593993510119617, 'clip_fraction': 0.3307291679084301, 'grad_norm': 11.174764633178711}
2023-01-03 12:44:08.815 DEBUG: Taking gradient step
2023-01-03 12:44:11.066 DEBUG: Loss 4: {'policy_loss': 0.13719229902549104, 'entropy_loss': -0.05817343946546316, 'vf_loss': 0.19129525617111373, 'total_loss': 0.07901885956002788, 'approx_kl': -0.1445152615197003, 'clip_fraction': 0.46484375, 'grad_norm': 27.240610122680664}
2023-01-03 12:44:13.247 DEBUG: Taking gradient step
2023-01-03 12:44:15.489 DEBUG: Loss 5: {'policy_loss': 0.12140438044423339, 'entropy_loss': -0.06050696596503258, 'vf_loss': 0.1899869679240489, 'total_loss': 0.060897414479200815, 'approx_kl': -0.06864980980753899, 'clip_fraction': 0.4010416716337204, 'grad_norm': 29.542617797851562}
2023-01-03 12:44:17.667 DEBUG: Taking gradient step
2023-01-03 12:44:19.904 DEBUG: Loss 6: {'policy_loss': 0.12938225216342866, 'entropy_loss': -0.0591304125264287, 'vf_loss': 0.20436555182913718, 'total_loss': 0.07025183963699996, 'approx_kl': -0.0700621628202498, 'clip_fraction': 0.51953125, 'grad_norm': 25.33604621887207}
2023-01-03 12:44:22.088 DEBUG: Taking gradient step
2023-01-03 12:44:24.571 DEBUG: Loss 7: {'policy_loss': 0.1701501028665831, 'entropy_loss': -0.059517049230635166, 'vf_loss': 0.20180911163921342, 'total_loss': 0.11063305363594793, 'approx_kl': -0.08587402012199163, 'clip_fraction': 0.6106770932674408, 'grad_norm': 28.604686737060547}
2023-01-03 12:44:26.773 DEBUG: Taking gradient step
2023-01-03 12:44:29.008 DEBUG: Loss 8: {'policy_loss': 0.09683956525698603, 'entropy_loss': -0.05938479024916887, 'vf_loss': 0.20438670076415927, 'total_loss': 0.03745477500781716, 'approx_kl': -0.06691841036081314, 'clip_fraction': 0.4713541716337204, 'grad_norm': 27.043378829956055}
2023-01-03 12:44:31.195 DEBUG: Taking gradient step
2023-01-03 12:44:33.472 DEBUG: Loss 9: {'policy_loss': 0.11629742398266552, 'entropy_loss': -0.05990618001669645, 'vf_loss': 0.19851470129225623, 'total_loss': 0.05639124396596906, 'approx_kl': -0.1134541667997837, 'clip_fraction': 0.4296875, 'grad_norm': 21.840360641479492}
2023-01-03 12:44:35.685 DEBUG: Taking gradient step
2023-01-03 12:44:37.955 DEBUG: Loss 10: {'policy_loss': 0.1321409487761238, 'entropy_loss': -0.05956440418958664, 'vf_loss': 0.19205875271441905, 'total_loss': 0.07257654458653716, 'approx_kl': -0.10900247469544411, 'clip_fraction': 0.5104166716337204, 'grad_norm': 20.82899284362793}
2023-01-03 12:44:40.150 DEBUG: Taking gradient step
2023-01-03 12:44:42.399 DEBUG: Loss 11: {'policy_loss': 0.16348591112887625, 'entropy_loss': -0.06031934730708599, 'vf_loss': 0.19011344284384965, 'total_loss': 0.10316656382179026, 'approx_kl': -0.08642683923244476, 'clip_fraction': 0.4635416716337204, 'grad_norm': 22.426525115966797}
2023-01-03 12:44:44.654 DEBUG: Taking gradient step
2023-01-03 12:44:46.928 DEBUG: Loss 12: {'policy_loss': 0.04921120344073549, 'entropy_loss': -0.057428752072155476, 'vf_loss': 0.1915311197439871, 'total_loss': -0.00821754863141998, 'approx_kl': -0.08488036855123937, 'clip_fraction': 0.359375, 'grad_norm': 14.044024467468262}
2023-01-03 12:44:49.144 DEBUG: Taking gradient step
2023-01-03 12:44:51.435 DEBUG: Loss 13: {'policy_loss': 0.0681935818877843, 'entropy_loss': -0.05669698677957058, 'vf_loss': 0.19771733930575744, 'total_loss': 0.011496595108213726, 'approx_kl': -0.06243589520454407, 'clip_fraction': 0.4361979216337204, 'grad_norm': 22.947471618652344}
2023-01-03 12:44:53.856 DEBUG: Taking gradient step
2023-01-03 12:44:56.209 DEBUG: Loss 14: {'policy_loss': 0.13333755480659398, 'entropy_loss': -0.05753216985613108, 'vf_loss': 0.19618114495020883, 'total_loss': 0.07580538495046289, 'approx_kl': -0.08582254499197006, 'clip_fraction': 0.41796875, 'grad_norm': 26.09144401550293}
2023-01-03 12:44:56.210 INFO: Optimization: policy loss=0.133, vf loss=0.196, entropy loss=-0.058, total loss=0.076, num steps=15
2023-01-03 12:44:56.211 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 12:44:59.082 INFO: Evaluation rollout: return=0.815 (0.0), episode length=6.0
2023-01-03 12:44:59.084 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 12:44:59.086 INFO: Iteration: 35/137, steps: 7560
2023-01-03 12:45:16.996 DEBUG: There is a single atom floating around
2023-01-03 12:45:18.931 DEBUG: Atoms are too close
2023-01-03 12:45:24.191 DEBUG: There is a single atom floating around
2023-01-03 12:45:25.551 DEBUG: There is a single atom floating around
2023-01-03 12:45:25.553 DEBUG: Atoms are too close
2023-01-03 12:45:26.182 DEBUG: Atoms are too close
2023-01-03 12:45:26.724 DEBUG: Atoms are too close
2023-01-03 12:45:27.052 DEBUG: There is a single atom floating around
2023-01-03 12:45:27.052 DEBUG: Atoms are too close
2023-01-03 12:45:28.527 DEBUG: Atoms are too close
2023-01-03 12:45:28.775 DEBUG: There is a single atom floating around
2023-01-03 12:45:44.925 DEBUG: There is a single atom floating around
2023-01-03 12:45:49.434 DEBUG: Atoms are too close
2023-01-03 12:45:50.947 DEBUG: There is a single atom floating around
2023-01-03 12:45:52.205 DEBUG: Atoms are too close
2023-01-03 12:46:04.328 DEBUG: There is a single atom floating around
2023-01-03 12:46:08.285 DEBUG: There is a single atom floating around
2023-01-03 12:46:08.454 DEBUG: There is a single atom floating around
2023-01-03 12:46:08.455 DEBUG: There is a single atom floating around
2023-01-03 12:46:09.708 DEBUG: Atoms are too close
2023-01-03 12:46:10.514 DEBUG: Atoms are too close
2023-01-03 12:46:11.799 DEBUG: Atoms are too close
2023-01-03 12:46:12.193 INFO: Training rollout: return=-17.772 (14.7), episode length=5.6
2023-01-03 12:46:12.194 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 12:46:12.197 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-7560_train.pkl
2023-01-03 12:46:14.603 DEBUG: Taking gradient step
2023-01-03 12:46:16.838 DEBUG: Loss 0: {'policy_loss': -0.006150226459124225, 'entropy_loss': -0.05784759670495987, 'vf_loss': 0.20074094196902897, 'total_loss': -0.0639978231640841, 'approx_kl': 1.3422686606645584e-07, 'clip_fraction': 0.0, 'grad_norm': 16.785734176635742}
2023-01-03 12:46:19.042 DEBUG: Taking gradient step
2023-01-03 12:46:21.387 DEBUG: Loss 1: {'policy_loss': 0.014077571815848362, 'entropy_loss': -0.0578365596011281, 'vf_loss': 0.20241161037108227, 'total_loss': -0.04375898778527974, 'approx_kl': -0.0012666734401136637, 'clip_fraction': 0.23046875, 'grad_norm': 16.95962142944336}
2023-01-03 12:46:23.648 DEBUG: Taking gradient step
2023-01-03 12:46:25.901 DEBUG: Loss 2: {'policy_loss': 0.022706371050137997, 'entropy_loss': -0.05686564091593027, 'vf_loss': 0.2040440725820436, 'total_loss': -0.03415926986579228, 'approx_kl': -0.01947163394652307, 'clip_fraction': 0.21484375, 'grad_norm': 19.717973709106445}
2023-01-03 12:46:28.264 DEBUG: Taking gradient step
2023-01-03 12:46:30.550 DEBUG: Loss 3: {'policy_loss': -0.008617969341323948, 'entropy_loss': -0.056543074548244476, 'vf_loss': 0.20690585867903746, 'total_loss': -0.06516104388956842, 'approx_kl': -0.01678702374920249, 'clip_fraction': 0.3502604216337204, 'grad_norm': 24.461206436157227}
2023-01-03 12:46:32.765 DEBUG: Taking gradient step
2023-01-03 12:46:35.074 DEBUG: Loss 4: {'policy_loss': 0.013811929780742385, 'entropy_loss': -0.056502774357795715, 'vf_loss': 0.20309670651416584, 'total_loss': -0.04269084457705333, 'approx_kl': -0.012680845335125923, 'clip_fraction': 0.3580729216337204, 'grad_norm': 16.0867977142334}
2023-01-03 12:46:37.282 DEBUG: Taking gradient step
2023-01-03 12:46:39.570 DEBUG: Loss 5: {'policy_loss': 0.022993429899823156, 'entropy_loss': -0.054319112561643124, 'vf_loss': 0.20786904492648953, 'total_loss': -0.03132568266181997, 'approx_kl': -0.036020510364323854, 'clip_fraction': 0.35546875, 'grad_norm': 17.353919982910156}
2023-01-03 12:46:41.778 DEBUG: Taking gradient step
2023-01-03 12:46:44.077 DEBUG: Loss 6: {'policy_loss': 0.038576393170911306, 'entropy_loss': -0.05363500490784645, 'vf_loss': 0.2058338215181935, 'total_loss': -0.015058611736935144, 'approx_kl': -0.012253138236701488, 'clip_fraction': 0.39453125, 'grad_norm': 27.463071823120117}
2023-01-03 12:46:46.373 DEBUG: Taking gradient step
2023-01-03 12:46:48.703 DEBUG: Loss 7: {'policy_loss': 0.07314727202103213, 'entropy_loss': -0.055246464908123016, 'vf_loss': 0.2064384454864835, 'total_loss': 0.017900807112909124, 'approx_kl': -0.012520581018179655, 'clip_fraction': 0.4348958432674408, 'grad_norm': 17.796194076538086}
2023-01-03 12:46:50.978 DEBUG: Taking gradient step
2023-01-03 12:46:53.333 DEBUG: Loss 8: {'policy_loss': 0.02861747502930144, 'entropy_loss': -0.05634037032723427, 'vf_loss': 0.20613347039339824, 'total_loss': -0.02772289529793283, 'approx_kl': -0.026259340345859528, 'clip_fraction': 0.4010416716337204, 'grad_norm': 17.914716720581055}
2023-01-03 12:46:55.622 DEBUG: Taking gradient step
2023-01-03 12:46:57.930 DEBUG: Loss 9: {'policy_loss': 0.037563261066054836, 'entropy_loss': -0.05548532493412495, 'vf_loss': 0.20295691701616264, 'total_loss': -0.01792206386807011, 'approx_kl': -0.017483888659626245, 'clip_fraction': 0.3763020858168602, 'grad_norm': 25.372148513793945}
2023-01-03 12:47:00.182 DEBUG: Taking gradient step
2023-01-03 12:47:02.459 DEBUG: Loss 10: {'policy_loss': 0.022237618068916526, 'entropy_loss': -0.05649954080581665, 'vf_loss': 0.2016904709802814, 'total_loss': -0.034261922736900124, 'approx_kl': -0.023386495653539896, 'clip_fraction': 0.3763020858168602, 'grad_norm': 13.787931442260742}
2023-01-03 12:47:04.646 DEBUG: Taking gradient step
2023-01-03 12:47:06.914 DEBUG: Loss 11: {'policy_loss': -0.028308576082422793, 'entropy_loss': -0.05582478363066912, 'vf_loss': 0.20459505967212166, 'total_loss': -0.08413335971309191, 'approx_kl': -0.035835423273965716, 'clip_fraction': 0.3815104216337204, 'grad_norm': 22.956851959228516}
2023-01-03 12:47:09.237 DEBUG: Taking gradient step
2023-01-03 12:47:11.534 DEBUG: Loss 12: {'policy_loss': 0.04436296699972096, 'entropy_loss': -0.055240544490516186, 'vf_loss': 0.20416956983421813, 'total_loss': -0.010877577490795227, 'approx_kl': -0.045599726028740406, 'clip_fraction': 0.36328125, 'grad_norm': 31.982521057128906}
2023-01-03 12:47:13.962 DEBUG: Taking gradient step
2023-01-03 12:47:16.233 DEBUG: Loss 13: {'policy_loss': 0.04781852738293185, 'entropy_loss': -0.05690508522093296, 'vf_loss': 0.20273883591868408, 'total_loss': -0.009086557838001122, 'approx_kl': -0.05299857724457979, 'clip_fraction': 0.3645833358168602, 'grad_norm': 16.78154182434082}
2023-01-03 12:47:18.480 DEBUG: Taking gradient step
2023-01-03 12:47:20.790 DEBUG: Loss 14: {'policy_loss': 0.06899688043781588, 'entropy_loss': -0.05540035478770733, 'vf_loss': 0.2030207366684235, 'total_loss': 0.013596525650108549, 'approx_kl': -0.026783816516399384, 'clip_fraction': 0.4127604216337204, 'grad_norm': 31.786453247070312}
2023-01-03 12:47:20.791 INFO: Optimization: policy loss=0.069, vf loss=0.203, entropy loss=-0.055, total loss=0.014, num steps=15
2023-01-03 12:47:20.792 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 12:47:22.715 INFO: Evaluation rollout: return=0.811 (0.0), episode length=6.0
2023-01-03 12:47:22.717 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 12:47:22.721 INFO: Iteration: 36/137, steps: 7776
2023-01-03 12:47:34.067 DEBUG: There is a single atom floating around
2023-01-03 12:47:37.325 DEBUG: Atoms are too close
2023-01-03 12:47:38.428 DEBUG: Atoms are too close
2023-01-03 12:47:38.429 DEBUG: There is a single atom floating around
2023-01-03 12:47:39.875 DEBUG: Atoms are too close
2023-01-03 12:47:41.651 DEBUG: There is a single atom floating around
2023-01-03 12:47:53.291 DEBUG: Atoms are too close
2023-01-03 12:47:53.614 DEBUG: Atoms are too close
2023-01-03 12:47:54.950 DEBUG: Atoms are too close
2023-01-03 12:47:57.398 DEBUG: There is a single atom floating around
2023-01-03 12:47:57.399 DEBUG: There is a single atom floating around
2023-01-03 12:48:00.013 DEBUG: There is a single atom floating around
2023-01-03 12:48:14.882 DEBUG: Atoms are too close
2023-01-03 12:48:16.202 DEBUG: There is a single atom floating around
2023-01-03 12:48:17.573 DEBUG: Atoms are too close
2023-01-03 12:48:18.529 DEBUG: Atoms are too close
2023-01-03 12:48:18.778 DEBUG: Atoms are too close
2023-01-03 12:48:21.630 INFO: Training rollout: return=-13.635 (14.9), episode length=5.6
2023-01-03 12:48:21.632 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 12:48:21.635 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-7776_train.pkl
2023-01-03 12:48:23.949 DEBUG: Taking gradient step
2023-01-03 12:48:26.215 DEBUG: Loss 0: {'policy_loss': -0.0017782966108879361, 'entropy_loss': -0.0565450144931674, 'vf_loss': 0.22696051357018063, 'total_loss': -0.058323311104055336, 'approx_kl': 1.275717949056343e-07, 'clip_fraction': 0.0, 'grad_norm': 11.591548919677734}
2023-01-03 12:48:28.427 DEBUG: Taking gradient step
2023-01-03 12:48:30.834 DEBUG: Loss 1: {'policy_loss': 0.035714808670847184, 'entropy_loss': -0.05583305563777685, 'vf_loss': 0.2221916017198695, 'total_loss': -0.020118246966929668, 'approx_kl': -0.004581646760925651, 'clip_fraction': 0.3151041716337204, 'grad_norm': 24.18170738220215}
2023-01-03 12:48:33.016 DEBUG: Taking gradient step
2023-01-03 12:48:35.312 DEBUG: Loss 2: {'policy_loss': 0.04533302568845155, 'entropy_loss': -0.05400168243795633, 'vf_loss': 0.22006926552577752, 'total_loss': -0.008668656749504783, 'approx_kl': -0.02406583121046424, 'clip_fraction': 0.3997395858168602, 'grad_norm': 32.17146682739258}
2023-01-03 12:48:37.591 DEBUG: Taking gradient step
2023-01-03 12:48:39.850 DEBUG: Loss 3: {'policy_loss': 0.05579288336575303, 'entropy_loss': -0.05552407819777727, 'vf_loss': 0.21348262262420942, 'total_loss': 0.00026880516797575527, 'approx_kl': -0.03530376171693206, 'clip_fraction': 0.375, 'grad_norm': 27.747541427612305}
2023-01-03 12:48:42.201 DEBUG: Taking gradient step
2023-01-03 12:48:44.448 DEBUG: Loss 4: {'policy_loss': 0.023311381856286596, 'entropy_loss': -0.052822692319750786, 'vf_loss': 0.20473076298607515, 'total_loss': -0.02951131046346419, 'approx_kl': -0.03586425050161779, 'clip_fraction': 0.3958333358168602, 'grad_norm': 14.294589042663574}
2023-01-03 12:48:46.702 DEBUG: Taking gradient step
2023-01-03 12:48:48.952 DEBUG: Loss 5: {'policy_loss': 0.033714573563240896, 'entropy_loss': -0.054815090261399746, 'vf_loss': 0.2026354325144661, 'total_loss': -0.021100516698158853, 'approx_kl': -0.06989425234496593, 'clip_fraction': 0.4322916716337204, 'grad_norm': 12.762737274169922}
2023-01-03 12:48:51.401 DEBUG: Taking gradient step
2023-01-03 12:48:53.684 DEBUG: Loss 6: {'policy_loss': 0.0009625318828267726, 'entropy_loss': -0.05492406617850065, 'vf_loss': 0.20267915174146206, 'total_loss': -0.05396153429567388, 'approx_kl': -0.06307044252753258, 'clip_fraction': 0.3697916716337204, 'grad_norm': 15.91100788116455}
2023-01-03 12:48:55.874 DEBUG: Taking gradient step
2023-01-03 12:48:58.112 DEBUG: Loss 7: {'policy_loss': 0.026413693068836848, 'entropy_loss': -0.055084528401494026, 'vf_loss': 0.20032933950405046, 'total_loss': -0.028670835332657185, 'approx_kl': -0.08978217979893088, 'clip_fraction': 0.3385416716337204, 'grad_norm': 14.479476928710938}
2023-01-03 12:49:00.318 DEBUG: Taking gradient step
2023-01-03 12:49:02.666 DEBUG: Loss 8: {'policy_loss': -0.003975122370812618, 'entropy_loss': -0.05388728156685829, 'vf_loss': 0.2112426895975788, 'total_loss': -0.057862403937670906, 'approx_kl': -0.05110818473622203, 'clip_fraction': 0.3046875, 'grad_norm': 10.07400894165039}
2023-01-03 12:49:05.163 DEBUG: Taking gradient step
2023-01-03 12:49:07.435 DEBUG: Loss 9: {'policy_loss': 0.016607875763442272, 'entropy_loss': -0.054041558876633644, 'vf_loss': 0.20848150766636092, 'total_loss': -0.03743368311319137, 'approx_kl': -0.06825815327465534, 'clip_fraction': 0.3736979216337204, 'grad_norm': 13.521820068359375}
2023-01-03 12:49:09.626 DEBUG: Taking gradient step
2023-01-03 12:49:11.876 DEBUG: Loss 10: {'policy_loss': 0.050067286212464354, 'entropy_loss': -0.05191265419125557, 'vf_loss': 0.20975496242763986, 'total_loss': -0.0018453679787912153, 'approx_kl': -0.07892147079110146, 'clip_fraction': 0.4036458358168602, 'grad_norm': 13.930745124816895}
2023-01-03 12:49:14.088 DEBUG: Taking gradient step
2023-01-03 12:49:16.323 DEBUG: Loss 11: {'policy_loss': 0.0015717526689202552, 'entropy_loss': -0.05220248829573393, 'vf_loss': 0.20355241605834842, 'total_loss': -0.05063073562681367, 'approx_kl': -0.08912438899278641, 'clip_fraction': 0.4244791716337204, 'grad_norm': 17.095046997070312}
2023-01-03 12:49:18.523 DEBUG: Taking gradient step
2023-01-03 12:49:20.804 DEBUG: Loss 12: {'policy_loss': 0.005813011558803021, 'entropy_loss': -0.05272823944687843, 'vf_loss': 0.20232212303603558, 'total_loss': -0.04691522788807541, 'approx_kl': -0.09642976522445679, 'clip_fraction': 0.4557291716337204, 'grad_norm': 15.250726699829102}
2023-01-03 12:49:23.018 DEBUG: Taking gradient step
2023-01-03 12:49:25.233 DEBUG: Loss 13: {'policy_loss': 0.04617143829525664, 'entropy_loss': -0.05280859116464853, 'vf_loss': 0.20377917834273956, 'total_loss': -0.006637152869391892, 'approx_kl': -0.09269292466342449, 'clip_fraction': 0.3919270858168602, 'grad_norm': 18.84088134765625}
2023-01-03 12:49:27.417 DEBUG: Taking gradient step
2023-01-03 12:49:29.665 DEBUG: Loss 14: {'policy_loss': 0.01372945117091116, 'entropy_loss': -0.051246266812086105, 'vf_loss': 0.19464316969865517, 'total_loss': -0.03751681564117494, 'approx_kl': -0.08201712928712368, 'clip_fraction': 0.4153645858168602, 'grad_norm': 16.306337356567383}
2023-01-03 12:49:29.666 INFO: Optimization: policy loss=0.014, vf loss=0.195, entropy loss=-0.051, total loss=-0.038, num steps=15
2023-01-03 12:49:29.667 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 12:49:31.669 INFO: Evaluation rollout: return=0.835 (0.0), episode length=6.0
2023-01-03 12:49:31.670 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 12:49:31.673 INFO: Iteration: 37/137, steps: 7992
2023-01-03 12:49:44.743 DEBUG: There is a single atom floating around
2023-01-03 12:49:47.364 DEBUG: Atoms are too close
2023-01-03 12:49:47.706 DEBUG: There is a single atom floating around
2023-01-03 12:49:49.879 DEBUG: There is a single atom floating around
2023-01-03 12:49:49.879 DEBUG: Atoms are too close
2023-01-03 12:49:50.042 DEBUG: Atoms are too close
2023-01-03 12:50:02.153 DEBUG: Atoms are too close
2023-01-03 12:50:03.457 DEBUG: There is a single atom floating around
2023-01-03 12:50:03.773 DEBUG: There is a single atom floating around
2023-01-03 12:50:08.725 DEBUG: Atoms are too close
2023-01-03 12:50:09.401 DEBUG: There is a single atom floating around
2023-01-03 12:50:16.146 DEBUG: Atoms are too close
2023-01-03 12:50:16.435 DEBUG: Atoms are too close
2023-01-03 12:50:19.977 DEBUG: Atoms are too close
2023-01-03 12:50:21.358 DEBUG: Atoms are too close
2023-01-03 12:50:22.636 DEBUG: Atoms are too close
2023-01-03 12:50:23.900 DEBUG: There is a single atom floating around
2023-01-03 12:50:24.800 DEBUG: Atoms are too close
2023-01-03 12:50:27.697 DEBUG: There is a single atom floating around
2023-01-03 12:50:29.078 DEBUG: Atoms are too close
2023-01-03 12:50:29.155 INFO: Training rollout: return=-16.046 (14.9), episode length=5.5
2023-01-03 12:50:29.156 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 12:50:29.159 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-7992_train.pkl
2023-01-03 12:50:31.548 DEBUG: Taking gradient step
2023-01-03 12:50:33.795 DEBUG: Loss 0: {'policy_loss': -0.006649574834506802, 'entropy_loss': -0.0538398576900363, 'vf_loss': 0.20794548707900887, 'total_loss': -0.0604894325245431, 'approx_kl': -1.1948093003866234e-07, 'clip_fraction': 0.0, 'grad_norm': 15.138261795043945}
2023-01-03 12:50:35.987 DEBUG: Taking gradient step
2023-01-03 12:50:38.648 DEBUG: Loss 1: {'policy_loss': 0.014938734425454354, 'entropy_loss': -0.054246402345597744, 'vf_loss': 0.2064839029243862, 'total_loss': -0.039307667920143397, 'approx_kl': 0.0012187408283352852, 'clip_fraction': 0.15625, 'grad_norm': 19.693214416503906}
2023-01-03 12:50:40.870 DEBUG: Taking gradient step
2023-01-03 12:50:43.251 DEBUG: Loss 2: {'policy_loss': 0.08412973237653831, 'entropy_loss': -0.054235308431088924, 'vf_loss': 0.20384755412499317, 'total_loss': 0.029894423945449382, 'approx_kl': 0.0015308065339922905, 'clip_fraction': 0.3736979216337204, 'grad_norm': 33.30976104736328}
2023-01-03 12:50:45.496 DEBUG: Taking gradient step
2023-01-03 12:50:47.722 DEBUG: Loss 3: {'policy_loss': 0.012271206362761739, 'entropy_loss': -0.05183356627821922, 'vf_loss': 0.20339679470543892, 'total_loss': -0.03956235991545748, 'approx_kl': -0.008996188407763839, 'clip_fraction': 0.2330729179084301, 'grad_norm': 19.58940315246582}
2023-01-03 12:50:50.059 DEBUG: Taking gradient step
2023-01-03 12:50:52.543 DEBUG: Loss 4: {'policy_loss': 0.032901560703415184, 'entropy_loss': -0.051390272565186024, 'vf_loss': 0.20758874270382444, 'total_loss': -0.01848871186177084, 'approx_kl': -0.019530612975358963, 'clip_fraction': 0.3580729179084301, 'grad_norm': 14.810543060302734}
2023-01-03 12:50:54.734 DEBUG: Taking gradient step
2023-01-03 12:50:56.981 DEBUG: Loss 5: {'policy_loss': 0.039196444405049796, 'entropy_loss': -0.049572418443858624, 'vf_loss': 0.2019504798285294, 'total_loss': -0.010375974038808827, 'approx_kl': -0.010774689260870218, 'clip_fraction': 0.3658854216337204, 'grad_norm': 26.453025817871094}
2023-01-03 12:50:59.313 DEBUG: Taking gradient step
2023-01-03 12:51:01.803 DEBUG: Loss 6: {'policy_loss': -0.05219407877511779, 'entropy_loss': -0.04919643420726061, 'vf_loss': 0.20292104565906027, 'total_loss': -0.10139051298237839, 'approx_kl': -0.03167277993634343, 'clip_fraction': 0.3203125, 'grad_norm': 18.124706268310547}
2023-01-03 12:51:03.993 DEBUG: Taking gradient step
2023-01-03 12:51:06.245 DEBUG: Loss 7: {'policy_loss': 0.031079581085781828, 'entropy_loss': -0.051318894140422344, 'vf_loss': 0.2017886808364897, 'total_loss': -0.020239313054640516, 'approx_kl': -0.02180082444101572, 'clip_fraction': 0.41015625, 'grad_norm': 22.309755325317383}
2023-01-03 12:51:08.474 DEBUG: Taking gradient step
2023-01-03 12:51:10.713 DEBUG: Loss 8: {'policy_loss': -0.020170860077951384, 'entropy_loss': -0.052305721677839756, 'vf_loss': 0.20574727817646926, 'total_loss': -0.07247658175579114, 'approx_kl': -0.052540727192535996, 'clip_fraction': 0.390625, 'grad_norm': 23.392786026000977}
2023-01-03 12:51:12.995 DEBUG: Taking gradient step
2023-01-03 12:51:15.522 DEBUG: Loss 9: {'policy_loss': 0.02918377732541166, 'entropy_loss': -0.051285346038639545, 'vf_loss': 0.19941333136803427, 'total_loss': -0.022101568713227885, 'approx_kl': -0.028722803806886077, 'clip_fraction': 0.3528645858168602, 'grad_norm': 21.66800880432129}
2023-01-03 12:51:17.732 DEBUG: Taking gradient step
2023-01-03 12:51:19.984 DEBUG: Loss 10: {'policy_loss': 0.01735331296048185, 'entropy_loss': -0.052055333741009235, 'vf_loss': 0.2032900765275564, 'total_loss': -0.03470202078052739, 'approx_kl': -0.04012398095801473, 'clip_fraction': 0.3645833358168602, 'grad_norm': 29.259952545166016}
2023-01-03 12:51:22.247 DEBUG: Taking gradient step
2023-01-03 12:51:24.543 DEBUG: Loss 11: {'policy_loss': 0.06745140184845158, 'entropy_loss': -0.0529538718983531, 'vf_loss': 0.20161350376509404, 'total_loss': 0.014497529950098481, 'approx_kl': -0.05577068403363228, 'clip_fraction': 0.3255208358168602, 'grad_norm': 20.287717819213867}
2023-01-03 12:51:26.744 DEBUG: Taking gradient step
2023-01-03 12:51:28.969 DEBUG: Loss 12: {'policy_loss': 0.0835128004952073, 'entropy_loss': -0.05141363199800253, 'vf_loss': 0.20139447039798453, 'total_loss': 0.032099168497204775, 'approx_kl': -0.03417437104508281, 'clip_fraction': 0.3919270858168602, 'grad_norm': 30.469711303710938}
2023-01-03 12:51:31.245 DEBUG: Taking gradient step
2023-01-03 12:51:33.489 DEBUG: Loss 13: {'policy_loss': 0.03676767514909309, 'entropy_loss': -0.050339906476438046, 'vf_loss': 0.2046124494656036, 'total_loss': -0.013572231327344957, 'approx_kl': -0.05622320622205734, 'clip_fraction': 0.3346354216337204, 'grad_norm': 17.99794578552246}
2023-01-03 12:51:35.681 DEBUG: Taking gradient step
2023-01-03 12:51:38.211 DEBUG: Loss 14: {'policy_loss': -0.0634468804850251, 'entropy_loss': -0.051618448458611965, 'vf_loss': 0.2056918138107024, 'total_loss': -0.11506532894363705, 'approx_kl': -0.05427680350840092, 'clip_fraction': 0.3736979216337204, 'grad_norm': 10.989036560058594}
2023-01-03 12:51:38.211 INFO: Optimization: policy loss=-0.063, vf loss=0.206, entropy loss=-0.052, total loss=-0.115, num steps=15
2023-01-03 12:51:38.212 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 12:51:39.854 DEBUG: Atoms are too close
2023-01-03 12:51:39.856 INFO: Evaluation rollout: return=-29.142 (0.0), episode length=6.0
2023-01-03 12:51:39.857 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 12:51:39.862 INFO: Iteration: 38/137, steps: 8208
2023-01-03 12:51:51.921 DEBUG: Atoms are too close
2023-01-03 12:51:53.614 DEBUG: Atoms are too close
2023-01-03 12:51:56.180 DEBUG: There is a single atom floating around
2023-01-03 12:51:57.122 DEBUG: Atoms are too close
2023-01-03 12:51:57.445 DEBUG: There is a single atom floating around
2023-01-03 12:51:57.775 DEBUG: Atoms are too close
2023-01-03 12:52:11.999 DEBUG: Atoms are too close
2023-01-03 12:52:13.327 DEBUG: There is a single atom floating around
2023-01-03 12:52:14.982 DEBUG: Atoms are too close
2023-01-03 12:52:15.481 DEBUG: There is a single atom floating around
2023-01-03 12:52:15.481 DEBUG: Atoms are too close
2023-01-03 12:52:16.200 DEBUG: Atoms are too close
2023-01-03 12:52:16.201 DEBUG: There is a single atom floating around
2023-01-03 12:52:16.501 DEBUG: There is a single atom floating around
2023-01-03 12:52:16.969 DEBUG: Atoms are too close
2023-01-03 12:52:17.291 DEBUG: Atoms are too close
2023-01-03 12:52:30.793 DEBUG: There is a single atom floating around
2023-01-03 12:52:30.794 DEBUG: There is a single atom floating around
2023-01-03 12:52:33.076 DEBUG: There is a single atom floating around
2023-01-03 12:52:33.078 DEBUG: There is a single atom floating around
2023-01-03 12:52:33.078 DEBUG: There is a single atom floating around
2023-01-03 12:52:33.593 DEBUG: There is a single atom floating around
2023-01-03 12:52:34.368 DEBUG: Atoms are too close
2023-01-03 12:52:36.386 DEBUG: Atoms are too close
2023-01-03 12:52:36.463 INFO: Training rollout: return=-19.307 (14.1), episode length=5.7
2023-01-03 12:52:36.465 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 12:52:36.467 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-8208_train.pkl
2023-01-03 12:52:38.738 DEBUG: Taking gradient step
2023-01-03 12:52:41.039 DEBUG: Loss 0: {'policy_loss': 0.030670858525797543, 'entropy_loss': -0.05261066183447838, 'vf_loss': 0.21007815030840182, 'total_loss': -0.02193980330868084, 'approx_kl': -6.441648991994953e-09, 'clip_fraction': 0.0, 'grad_norm': 21.171411514282227}
2023-01-03 12:52:43.255 DEBUG: Taking gradient step
2023-01-03 12:52:45.509 DEBUG: Loss 1: {'policy_loss': -0.026436224595654163, 'entropy_loss': -0.05190736707299948, 'vf_loss': 0.2107199779939582, 'total_loss': -0.07834359166865364, 'approx_kl': -0.019931779708713293, 'clip_fraction': 0.2734375, 'grad_norm': 25.699464797973633}
2023-01-03 12:52:47.731 DEBUG: Taking gradient step
2023-01-03 12:52:49.995 DEBUG: Loss 2: {'policy_loss': 0.010548256658118597, 'entropy_loss': -0.05077366717159748, 'vf_loss': 0.20475266936823128, 'total_loss': -0.04022541051347889, 'approx_kl': -0.01892971247434616, 'clip_fraction': 0.23046875, 'grad_norm': 10.947325706481934}
2023-01-03 12:52:52.318 DEBUG: Taking gradient step
2023-01-03 12:52:54.826 DEBUG: Loss 3: {'policy_loss': -0.035484203526208874, 'entropy_loss': -0.04872323200106621, 'vf_loss': 0.20234801409555836, 'total_loss': -0.08420743552727508, 'approx_kl': -0.01319980202242732, 'clip_fraction': 0.27734375, 'grad_norm': 16.810667037963867}
2023-01-03 12:52:57.085 DEBUG: Taking gradient step
2023-01-03 12:52:59.402 DEBUG: Loss 4: {'policy_loss': 0.01683731564460614, 'entropy_loss': -0.050022431649267673, 'vf_loss': 0.19949348805909978, 'total_loss': -0.033185116004661536, 'approx_kl': -0.01879184227436781, 'clip_fraction': 0.3932291716337204, 'grad_norm': 29.34556770324707}
2023-01-03 12:53:01.657 DEBUG: Taking gradient step
2023-01-03 12:53:03.917 DEBUG: Loss 5: {'policy_loss': 0.0007303978583772727, 'entropy_loss': -0.04914898797869682, 'vf_loss': 0.19684368663812124, 'total_loss': -0.04841859012031954, 'approx_kl': -0.029381034895777702, 'clip_fraction': 0.3020833358168602, 'grad_norm': 24.725969314575195}
2023-01-03 12:53:06.154 DEBUG: Taking gradient step
2023-01-03 12:53:08.462 DEBUG: Loss 6: {'policy_loss': -0.02784134464067927, 'entropy_loss': -0.051590146496891975, 'vf_loss': 0.196734295345548, 'total_loss': -0.07943149113757125, 'approx_kl': -0.05261185369454324, 'clip_fraction': 0.3111979216337204, 'grad_norm': 15.44510269165039}
2023-01-03 12:53:10.753 DEBUG: Taking gradient step
2023-01-03 12:53:13.072 DEBUG: Loss 7: {'policy_loss': 0.041566370474972476, 'entropy_loss': -0.052118427120149136, 'vf_loss': 0.19717176843421916, 'total_loss': -0.010552056645176645, 'approx_kl': -0.01508585549890995, 'clip_fraction': 0.4479166716337204, 'grad_norm': 33.381752014160156}
2023-01-03 12:53:15.748 DEBUG: Taking gradient step
2023-01-03 12:53:18.057 DEBUG: Loss 8: {'policy_loss': 0.04874894418052895, 'entropy_loss': -0.051616521552205086, 'vf_loss': 0.18627426230103433, 'total_loss': -0.0028675773716761374, 'approx_kl': -0.042099575977772474, 'clip_fraction': 0.2565104179084301, 'grad_norm': 18.491924285888672}
2023-01-03 12:53:20.373 DEBUG: Taking gradient step
2023-01-03 12:53:22.700 DEBUG: Loss 9: {'policy_loss': 0.03466267628873895, 'entropy_loss': -0.050416065379977226, 'vf_loss': 0.1888874354507296, 'total_loss': -0.015753389091238267, 'approx_kl': -0.02798785688355565, 'clip_fraction': 0.3424479216337204, 'grad_norm': 12.045297622680664}
2023-01-03 12:53:24.911 DEBUG: Taking gradient step
2023-01-03 12:53:27.206 DEBUG: Loss 10: {'policy_loss': -0.001959768457616272, 'entropy_loss': -0.050413270480930805, 'vf_loss': 0.1989035203194529, 'total_loss': -0.05237303893854708, 'approx_kl': -0.031002665869891644, 'clip_fraction': 0.4127604216337204, 'grad_norm': 32.602333068847656}
2023-01-03 12:53:29.419 DEBUG: Taking gradient step
2023-01-03 12:53:31.748 DEBUG: Loss 11: {'policy_loss': 0.0005774793604659476, 'entropy_loss': -0.05152978282421827, 'vf_loss': 0.197300589429093, 'total_loss': -0.050952303463752326, 'approx_kl': -0.03203508723527193, 'clip_fraction': 0.3684895858168602, 'grad_norm': 24.545795440673828}
2023-01-03 12:53:34.258 DEBUG: Taking gradient step
2023-01-03 12:53:36.529 DEBUG: Loss 12: {'policy_loss': 0.05364531289103712, 'entropy_loss': -0.04996454808861017, 'vf_loss': 0.1948777641937079, 'total_loss': 0.003680764802426951, 'approx_kl': -0.023998979479074478, 'clip_fraction': 0.3645833358168602, 'grad_norm': 19.483007431030273}
2023-01-03 12:53:38.768 DEBUG: Taking gradient step
2023-01-03 12:53:41.036 DEBUG: Loss 13: {'policy_loss': -0.0046259009733529005, 'entropy_loss': -0.0498061990365386, 'vf_loss': 0.19384482904249484, 'total_loss': -0.0544321000098915, 'approx_kl': -0.05635478300973773, 'clip_fraction': 0.40234375, 'grad_norm': 20.77039337158203}
2023-01-03 12:53:43.380 DEBUG: Taking gradient step
2023-01-03 12:53:45.665 DEBUG: Loss 14: {'policy_loss': 0.04263400331038485, 'entropy_loss': -0.050591740757226944, 'vf_loss': 0.19082771108645463, 'total_loss': -0.007957737446842094, 'approx_kl': -0.060479243285954, 'clip_fraction': 0.3411458358168602, 'grad_norm': 20.55242156982422}
2023-01-03 12:53:45.666 INFO: Optimization: policy loss=0.043, vf loss=0.191, entropy loss=-0.051, total loss=-0.008, num steps=15
2023-01-03 12:53:45.668 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 12:53:47.240 DEBUG: Atoms are too close
2023-01-03 12:53:47.242 INFO: Evaluation rollout: return=-29.151 (0.0), episode length=6.0
2023-01-03 12:53:47.243 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 12:53:47.246 INFO: Iteration: 39/137, steps: 8424
2023-01-03 12:53:58.734 DEBUG: Atoms are too close
2023-01-03 12:54:00.724 DEBUG: Atoms are too close
2023-01-03 12:54:01.022 DEBUG: Atoms are too close
2023-01-03 12:54:01.327 DEBUG: There is a single atom floating around
2023-01-03 12:54:01.489 DEBUG: There is a single atom floating around
2023-01-03 12:54:02.132 DEBUG: There is a single atom floating around
2023-01-03 12:54:10.880 DEBUG: There is a single atom floating around
2023-01-03 12:54:16.315 DEBUG: Atoms are too close
2023-01-03 12:54:16.614 DEBUG: Atoms are too close
2023-01-03 12:54:16.915 DEBUG: There is a single atom floating around
2023-01-03 12:54:16.916 DEBUG: There is a single atom floating around
2023-01-03 12:54:19.617 DEBUG: Atoms are too close
2023-01-03 12:54:22.327 DEBUG: Atoms are too close
2023-01-03 12:54:23.416 DEBUG: There is a single atom floating around
2023-01-03 12:54:37.346 DEBUG: There is a single atom floating around
2023-01-03 12:54:38.288 DEBUG: There is a single atom floating around
2023-01-03 12:54:38.669 DEBUG: There is a single atom floating around
2023-01-03 12:54:39.318 DEBUG: There is a single atom floating around
2023-01-03 12:54:40.717 DEBUG: Atoms are too close
2023-01-03 12:54:44.208 INFO: Training rollout: return=-14.192 (16.0), episode length=5.5
2023-01-03 12:54:44.209 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 12:54:44.212 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-8424_train.pkl
2023-01-03 12:54:46.428 DEBUG: Taking gradient step
2023-01-03 12:54:48.675 DEBUG: Loss 0: {'policy_loss': 0.04891162720504052, 'entropy_loss': -0.04988732282072306, 'vf_loss': 0.28130747743227746, 'total_loss': -0.0009756956156825314, 'approx_kl': 5.774199962615967e-08, 'clip_fraction': 0.0, 'grad_norm': 23.14828872680664}
2023-01-03 12:54:50.987 DEBUG: Taking gradient step
2023-01-03 12:54:53.253 DEBUG: Loss 1: {'policy_loss': 0.08474459379273763, 'entropy_loss': -0.04857449419796467, 'vf_loss': 0.2735351093925694, 'total_loss': 0.03617009959477296, 'approx_kl': -0.028373612090945244, 'clip_fraction': 0.2578125, 'grad_norm': 30.576501846313477}
2023-01-03 12:54:55.443 DEBUG: Taking gradient step
2023-01-03 12:54:57.812 DEBUG: Loss 2: {'policy_loss': 0.10830428139518437, 'entropy_loss': -0.05079967435449362, 'vf_loss': 0.2787315409154999, 'total_loss': 0.057504607040690756, 'approx_kl': -0.03998983511701226, 'clip_fraction': 0.453125, 'grad_norm': 37.99684143066406}
2023-01-03 12:55:00.080 DEBUG: Taking gradient step
2023-01-03 12:55:02.401 DEBUG: Loss 3: {'policy_loss': 0.1713134394288312, 'entropy_loss': -0.052890622057020664, 'vf_loss': 0.26130796541920587, 'total_loss': 0.11842281737181053, 'approx_kl': -0.0712108938023448, 'clip_fraction': 0.6041666716337204, 'grad_norm': 41.128089904785156}
2023-01-03 12:55:04.701 DEBUG: Taking gradient step
2023-01-03 12:55:07.366 DEBUG: Loss 4: {'policy_loss': 0.12765840802137515, 'entropy_loss': -0.051922811195254326, 'vf_loss': 0.25030545541504573, 'total_loss': 0.07573559682612083, 'approx_kl': -0.07035604119300842, 'clip_fraction': 0.5625, 'grad_norm': 27.929899215698242}
2023-01-03 12:55:09.551 DEBUG: Taking gradient step
2023-01-03 12:55:11.813 DEBUG: Loss 5: {'policy_loss': 0.13106958894387225, 'entropy_loss': -0.05243392754346132, 'vf_loss': 0.24430321906524516, 'total_loss': 0.07863566140041091, 'approx_kl': -0.05564490798860788, 'clip_fraction': 0.57421875, 'grad_norm': 29.803482055664062}
2023-01-03 12:55:14.037 DEBUG: Taking gradient step
2023-01-03 12:55:16.279 DEBUG: Loss 6: {'policy_loss': 0.09368527975926877, 'entropy_loss': -0.052911246195435524, 'vf_loss': 0.24933191297273175, 'total_loss': 0.04077403356383324, 'approx_kl': -0.07371404021978378, 'clip_fraction': 0.5703125, 'grad_norm': 30.8491268157959}
2023-01-03 12:55:18.480 DEBUG: Taking gradient step
2023-01-03 12:55:21.083 DEBUG: Loss 7: {'policy_loss': 0.11886748438895291, 'entropy_loss': -0.052819591015577316, 'vf_loss': 0.2548924666898188, 'total_loss': 0.0660478933733756, 'approx_kl': -0.0880696214735508, 'clip_fraction': 0.4791666716337204, 'grad_norm': 26.596254348754883}
2023-01-03 12:55:23.327 DEBUG: Taking gradient step
2023-01-03 12:55:25.618 DEBUG: Loss 8: {'policy_loss': 0.07182929928673175, 'entropy_loss': -0.053077482618391514, 'vf_loss': 0.2476447297961829, 'total_loss': 0.018751816668340235, 'approx_kl': -0.07502285204827785, 'clip_fraction': 0.4661458432674408, 'grad_norm': 24.874361038208008}
2023-01-03 12:55:27.876 DEBUG: Taking gradient step
2023-01-03 12:55:30.212 DEBUG: Loss 9: {'policy_loss': 0.06738109619609563, 'entropy_loss': -0.052688468247652054, 'vf_loss': 0.2653943916029117, 'total_loss': 0.014692627948443573, 'approx_kl': -0.060681444592773914, 'clip_fraction': 0.4427083432674408, 'grad_norm': 29.31051254272461}
2023-01-03 12:55:32.568 DEBUG: Taking gradient step
2023-01-03 12:55:34.803 DEBUG: Loss 10: {'policy_loss': 0.05942665331256003, 'entropy_loss': -0.05095480848103762, 'vf_loss': 0.2518194513335273, 'total_loss': 0.008471844831522413, 'approx_kl': -0.06458813464269042, 'clip_fraction': 0.3854166716337204, 'grad_norm': 28.126632690429688}
2023-01-03 12:55:36.977 DEBUG: Taking gradient step
2023-01-03 12:55:39.249 DEBUG: Loss 11: {'policy_loss': 0.04490629288856487, 'entropy_loss': -0.05078770313411951, 'vf_loss': 0.25176912595320095, 'total_loss': -0.005881410245554643, 'approx_kl': -0.05693424912169576, 'clip_fraction': 0.3828125, 'grad_norm': 23.253211975097656}
2023-01-03 12:55:41.427 DEBUG: Taking gradient step
2023-01-03 12:55:43.667 DEBUG: Loss 12: {'policy_loss': 0.0916232694674686, 'entropy_loss': -0.05139156337827444, 'vf_loss': 0.25947238898878333, 'total_loss': 0.040231706089194165, 'approx_kl': -0.04893398657441139, 'clip_fraction': 0.36328125, 'grad_norm': 22.01995849609375}
2023-01-03 12:55:45.862 DEBUG: Taking gradient step
2023-01-03 12:55:48.481 DEBUG: Loss 13: {'policy_loss': 0.1733599531749726, 'entropy_loss': -0.05161134619265795, 'vf_loss': 0.2635368211210732, 'total_loss': 0.12174860698231466, 'approx_kl': -0.09893176425248384, 'clip_fraction': 0.4075520858168602, 'grad_norm': 28.175308227539062}
2023-01-03 12:55:50.681 DEBUG: Taking gradient step
2023-01-03 12:55:52.932 DEBUG: Loss 14: {'policy_loss': 0.17666408612612816, 'entropy_loss': -0.052969315089285374, 'vf_loss': 0.2597717657696458, 'total_loss': 0.1236947710368428, 'approx_kl': -0.0761413685977459, 'clip_fraction': 0.4596354216337204, 'grad_norm': 26.516416549682617}
2023-01-03 12:55:52.932 INFO: Optimization: policy loss=0.177, vf loss=0.260, entropy loss=-0.053, total loss=0.124, num steps=15
2023-01-03 12:55:52.934 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 12:55:54.234 DEBUG: Atoms are too close
2023-01-03 12:55:54.236 INFO: Evaluation rollout: return=-29.119 (0.0), episode length=5.0
2023-01-03 12:55:54.237 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 12:55:54.239 INFO: Iteration: 40/137, steps: 8640
2023-01-03 12:56:05.628 DEBUG: There is a single atom floating around
2023-01-03 12:56:05.962 DEBUG: Atoms are too close
2023-01-03 12:56:06.281 DEBUG: Atoms are too close
2023-01-03 12:56:07.991 DEBUG: Atoms are too close
2023-01-03 12:56:07.992 DEBUG: Atoms are too close
2023-01-03 12:56:08.612 DEBUG: There is a single atom floating around
2023-01-03 12:56:09.842 DEBUG: There is a single atom floating around
2023-01-03 12:56:10.783 DEBUG: Atoms are too close
2023-01-03 12:56:21.378 DEBUG: Atoms are too close
2023-01-03 12:56:24.082 DEBUG: There is a single atom floating around
2023-01-03 12:56:26.254 DEBUG: There is a single atom floating around
2023-01-03 12:56:26.905 DEBUG: There is a single atom floating around
2023-01-03 12:56:28.389 DEBUG: There is a single atom floating around
2023-01-03 12:56:28.478 DEBUG: Atoms are too close
2023-01-03 12:56:28.968 DEBUG: Atoms are too close
2023-01-03 12:56:38.429 DEBUG: There is a single atom floating around
2023-01-03 12:56:39.770 DEBUG: There is a single atom floating around
2023-01-03 12:56:40.074 DEBUG: There is a single atom floating around
2023-01-03 12:56:46.750 DEBUG: Atoms are too close
2023-01-03 12:56:47.093 DEBUG: There is a single atom floating around
2023-01-03 12:56:47.647 DEBUG: There is a single atom floating around
2023-01-03 12:56:47.973 DEBUG: There is a single atom floating around
2023-01-03 12:56:47.974 DEBUG: There is a single atom floating around
2023-01-03 12:56:50.005 INFO: Training rollout: return=-18.448 (14.4), episode length=5.5
2023-01-03 12:56:50.006 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 12:56:50.009 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-8640_train.pkl
2023-01-03 12:56:52.233 DEBUG: Taking gradient step
2023-01-03 12:56:54.524 DEBUG: Loss 0: {'policy_loss': -0.031566093302952694, 'entropy_loss': -0.05377151630818844, 'vf_loss': 0.23795243820242803, 'total_loss': -0.08533760961114112, 'approx_kl': 7.279838154516938e-08, 'clip_fraction': 0.0, 'grad_norm': 18.953136444091797}
2023-01-03 12:56:56.731 DEBUG: Taking gradient step
2023-01-03 12:56:58.990 DEBUG: Loss 1: {'policy_loss': 0.042637710200245024, 'entropy_loss': -0.05206699017435312, 'vf_loss': 0.23683607180675387, 'total_loss': -0.009429279974108098, 'approx_kl': 0.0032317927107214928, 'clip_fraction': 0.08463541697710752, 'grad_norm': 24.010169982910156}
2023-01-03 12:57:01.325 DEBUG: Taking gradient step
2023-01-03 12:57:03.742 DEBUG: Loss 2: {'policy_loss': 0.03578624705965924, 'entropy_loss': -0.0520382160320878, 'vf_loss': 0.2261212528661522, 'total_loss': -0.01625196897242856, 'approx_kl': -0.011105863377451897, 'clip_fraction': 0.16796875, 'grad_norm': 19.073949813842773}
2023-01-03 12:57:06.030 DEBUG: Taking gradient step
2023-01-03 12:57:08.306 DEBUG: Loss 3: {'policy_loss': -0.027857872511241548, 'entropy_loss': -0.05288330465555191, 'vf_loss': 0.21358156868135472, 'total_loss': -0.08074117716679347, 'approx_kl': -0.009701402392238379, 'clip_fraction': 0.2760416716337204, 'grad_norm': 15.10797119140625}
2023-01-03 12:57:10.505 DEBUG: Taking gradient step
2023-01-03 12:57:12.833 DEBUG: Loss 4: {'policy_loss': -0.03413490866933057, 'entropy_loss': -0.052474524825811386, 'vf_loss': 0.20342960931838425, 'total_loss': -0.08660943349514195, 'approx_kl': -0.012020264752209187, 'clip_fraction': 0.3424479216337204, 'grad_norm': 21.295995712280273}
2023-01-03 12:57:15.088 DEBUG: Taking gradient step
2023-01-03 12:57:17.334 DEBUG: Loss 5: {'policy_loss': -0.03191190340885775, 'entropy_loss': -0.05117043573409319, 'vf_loss': 0.1992101427313987, 'total_loss': -0.08308233914295093, 'approx_kl': -0.0021129113156348467, 'clip_fraction': 0.359375, 'grad_norm': 14.866470336914062}
2023-01-03 12:57:19.532 DEBUG: Taking gradient step
2023-01-03 12:57:21.803 DEBUG: Loss 6: {'policy_loss': -0.040763023863832265, 'entropy_loss': -0.051461050286889076, 'vf_loss': 0.21194264381159697, 'total_loss': -0.09222407415072134, 'approx_kl': 0.008236395195126534, 'clip_fraction': 0.3645833358168602, 'grad_norm': 19.990636825561523}
2023-01-03 12:57:24.042 DEBUG: Taking gradient step
2023-01-03 12:57:26.313 DEBUG: Loss 7: {'policy_loss': 0.04439917170833255, 'entropy_loss': -0.051561079919338226, 'vf_loss': 0.208596395809145, 'total_loss': -0.007161908211005673, 'approx_kl': -0.016643172595649958, 'clip_fraction': 0.3997395858168602, 'grad_norm': 29.66650390625}
2023-01-03 12:57:28.504 DEBUG: Taking gradient step
2023-01-03 12:57:30.761 DEBUG: Loss 8: {'policy_loss': 0.04230624979367555, 'entropy_loss': -0.05119470413774252, 'vf_loss': 0.20914129011479904, 'total_loss': -0.008888454344066966, 'approx_kl': -0.010089053539559245, 'clip_fraction': 0.3736979216337204, 'grad_norm': 19.07618522644043}
2023-01-03 12:57:32.958 DEBUG: Taking gradient step
2023-01-03 12:57:35.330 DEBUG: Loss 9: {'policy_loss': -0.028982558910525, 'entropy_loss': -0.0526417912915349, 'vf_loss': 0.22781131784227215, 'total_loss': -0.08162435020205991, 'approx_kl': -0.02144495048560202, 'clip_fraction': 0.3502604216337204, 'grad_norm': 18.86433219909668}
2023-01-03 12:57:37.512 DEBUG: Taking gradient step
2023-01-03 12:57:40.230 DEBUG: Loss 10: {'policy_loss': 0.07704346579054773, 'entropy_loss': -0.05253893230110407, 'vf_loss': 0.21069774140261943, 'total_loss': 0.024504533489443668, 'approx_kl': -0.03504743170924485, 'clip_fraction': 0.359375, 'grad_norm': 40.863685607910156}
2023-01-03 12:57:42.472 DEBUG: Taking gradient step
2023-01-03 12:57:45.071 DEBUG: Loss 11: {'policy_loss': 0.014091833834298878, 'entropy_loss': -0.05160427838563919, 'vf_loss': 0.20899659240944723, 'total_loss': -0.03751244455134031, 'approx_kl': -0.03921036049723625, 'clip_fraction': 0.3684895858168602, 'grad_norm': 26.18854331970215}
2023-01-03 12:57:47.422 DEBUG: Taking gradient step
2023-01-03 12:57:49.648 DEBUG: Loss 12: {'policy_loss': 0.07020305352754729, 'entropy_loss': -0.05363583471626043, 'vf_loss': 0.20236210687006229, 'total_loss': 0.016567218811286852, 'approx_kl': -0.03902571741491556, 'clip_fraction': 0.3880208358168602, 'grad_norm': 15.252163887023926}
2023-01-03 12:57:51.843 DEBUG: Taking gradient step
2023-01-03 12:57:54.082 DEBUG: Loss 13: {'policy_loss': 0.07497941803983665, 'entropy_loss': -0.05396493710577488, 'vf_loss': 0.19281554074324553, 'total_loss': 0.02101448093406179, 'approx_kl': -0.05214990023523569, 'clip_fraction': 0.4453125, 'grad_norm': 14.426446914672852}
2023-01-03 12:57:56.262 DEBUG: Taking gradient step
2023-01-03 12:57:58.577 DEBUG: Loss 14: {'policy_loss': 0.048842647310055526, 'entropy_loss': -0.0532933222129941, 'vf_loss': 0.19963979542689414, 'total_loss': -0.004450674902938569, 'approx_kl': -0.014696522150188684, 'clip_fraction': 0.4596354216337204, 'grad_norm': 15.595427513122559}
2023-01-03 12:57:58.578 INFO: Optimization: policy loss=0.049, vf loss=0.200, entropy loss=-0.053, total loss=-0.004, num steps=15
2023-01-03 12:57:58.579 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 12:58:00.582 INFO: Evaluation rollout: return=0.901 (0.0), episode length=6.0
2023-01-03 12:58:00.583 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 12:58:00.587 DEBUG: Deleting old model: runs/CH3NO_dna/models/CH3NO_dna_run-1_steps-6696.model
2023-01-03 12:58:00.597 DEBUG: Saving model: runs/CH3NO_dna/models/CH3NO_dna_run-1_steps-8856.model
2023-01-03 12:58:00.651 INFO: Iteration: 41/137, steps: 8856
2023-01-03 12:58:16.375 DEBUG: There is a single atom floating around
2023-01-03 12:58:19.109 DEBUG: Atoms are too close
2023-01-03 12:58:19.110 DEBUG: There is a single atom floating around
2023-01-03 12:58:19.434 DEBUG: There is a single atom floating around
2023-01-03 12:58:21.001 DEBUG: There is a single atom floating around
2023-01-03 12:58:21.002 DEBUG: Atoms are too close
2023-01-03 12:58:36.462 DEBUG: There is a single atom floating around
2023-01-03 12:58:37.777 DEBUG: There is a single atom floating around
2023-01-03 12:58:55.610 DEBUG: There is a single atom floating around
2023-01-03 12:58:56.369 DEBUG: There is a single atom floating around
2023-01-03 12:58:56.686 DEBUG: Atoms are too close
2023-01-03 12:58:57.356 DEBUG: There is a single atom floating around
2023-01-03 12:58:57.967 DEBUG: Atoms are too close
2023-01-03 12:58:59.982 DEBUG: There is a single atom floating around
2023-01-03 12:59:00.735 DEBUG: There is a single atom floating around
2023-01-03 12:59:00.736 DEBUG: There is a single atom floating around
2023-01-03 12:59:00.805 INFO: Training rollout: return=-12.688 (14.9), episode length=5.8
2023-01-03 12:59:00.806 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 12:59:00.809 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-8856_train.pkl
2023-01-03 12:59:03.075 DEBUG: Taking gradient step
2023-01-03 12:59:05.393 DEBUG: Loss 0: {'policy_loss': 0.0006270687893083445, 'entropy_loss': -0.05382612068206072, 'vf_loss': 0.2140977818029613, 'total_loss': -0.053199051892752376, 'approx_kl': -3.861108055502882e-08, 'clip_fraction': 0.0, 'grad_norm': 16.738964080810547}
2023-01-03 12:59:07.644 DEBUG: Taking gradient step
2023-01-03 12:59:09.942 DEBUG: Loss 1: {'policy_loss': 0.017991492587241375, 'entropy_loss': -0.05403902102261782, 'vf_loss': 0.21284948639141968, 'total_loss': -0.036047528435376446, 'approx_kl': -0.01703322702087462, 'clip_fraction': 0.1588541679084301, 'grad_norm': 20.570472717285156}
2023-01-03 12:59:12.331 DEBUG: Taking gradient step
2023-01-03 12:59:14.799 DEBUG: Loss 2: {'policy_loss': 0.08814168782342818, 'entropy_loss': -0.05466594826430082, 'vf_loss': 0.21619941099919393, 'total_loss': 0.03347573955912735, 'approx_kl': -0.04183169174939394, 'clip_fraction': 0.2825520858168602, 'grad_norm': 20.708030700683594}
2023-01-03 12:59:17.048 DEBUG: Taking gradient step
2023-01-03 12:59:19.362 DEBUG: Loss 3: {'policy_loss': 0.03843125840625293, 'entropy_loss': -0.055679840967059135, 'vf_loss': 0.2148340019503411, 'total_loss': -0.01724858256080621, 'approx_kl': -0.03272942313924432, 'clip_fraction': 0.4739583432674408, 'grad_norm': 18.80630874633789}
2023-01-03 12:59:21.612 DEBUG: Taking gradient step
2023-01-03 12:59:23.914 DEBUG: Loss 4: {'policy_loss': -0.0639104377694667, 'entropy_loss': -0.055152553133666515, 'vf_loss': 0.2125971294896658, 'total_loss': -0.11906299090313321, 'approx_kl': -0.02516271811327897, 'clip_fraction': 0.3580729216337204, 'grad_norm': 22.96515655517578}
2023-01-03 12:59:26.270 DEBUG: Taking gradient step
2023-01-03 12:59:28.605 DEBUG: Loss 5: {'policy_loss': -0.009813229690000994, 'entropy_loss': -0.05583039950579405, 'vf_loss': 0.21195840897408214, 'total_loss': -0.06564362919579504, 'approx_kl': -0.061814651591703296, 'clip_fraction': 0.3619791716337204, 'grad_norm': 22.93621063232422}
2023-01-03 12:59:30.871 DEBUG: Taking gradient step
2023-01-03 12:59:33.288 DEBUG: Loss 6: {'policy_loss': 0.04695796659093573, 'entropy_loss': -0.05519944243133068, 'vf_loss': 0.21030212433763767, 'total_loss': -0.008241475840394953, 'approx_kl': -0.03618384129367769, 'clip_fraction': 0.4921875, 'grad_norm': 25.738325119018555}
2023-01-03 12:59:35.642 DEBUG: Taking gradient step
2023-01-03 12:59:38.156 DEBUG: Loss 7: {'policy_loss': 0.01563037495149537, 'entropy_loss': -0.05342927109450102, 'vf_loss': 0.20915046826344222, 'total_loss': -0.03779889614300565, 'approx_kl': -0.060414141742512584, 'clip_fraction': 0.45703125, 'grad_norm': 17.148344039916992}
2023-01-03 12:59:40.431 DEBUG: Taking gradient step
2023-01-03 12:59:42.730 DEBUG: Loss 8: {'policy_loss': 0.03847297389992771, 'entropy_loss': -0.053983899764716625, 'vf_loss': 0.21077347186660586, 'total_loss': -0.015510925864788916, 'approx_kl': -0.048199465963989496, 'clip_fraction': 0.3567708358168602, 'grad_norm': 31.6462459564209}
2023-01-03 12:59:44.975 DEBUG: Taking gradient step
2023-01-03 12:59:47.279 DEBUG: Loss 9: {'policy_loss': -0.02851726378519383, 'entropy_loss': -0.05423396825790405, 'vf_loss': 0.20842125821149488, 'total_loss': -0.0827512320430979, 'approx_kl': -0.06031657010316849, 'clip_fraction': 0.3971354216337204, 'grad_norm': 24.048980712890625}
2023-01-03 12:59:49.556 DEBUG: Taking gradient step
2023-01-03 12:59:51.851 DEBUG: Loss 10: {'policy_loss': 0.06380505850368508, 'entropy_loss': -0.05371012166142464, 'vf_loss': 0.2110414753921772, 'total_loss': 0.01009493684226044, 'approx_kl': -0.05798929464071989, 'clip_fraction': 0.4283854216337204, 'grad_norm': 19.292009353637695}
2023-01-03 12:59:54.219 DEBUG: Taking gradient step
2023-01-03 12:59:56.558 DEBUG: Loss 11: {'policy_loss': 0.05051732957311891, 'entropy_loss': -0.05418186541646719, 'vf_loss': 0.2099887634273245, 'total_loss': -0.0036645358433482784, 'approx_kl': -0.06618313770741224, 'clip_fraction': 0.4440104216337204, 'grad_norm': 20.537633895874023}
2023-01-03 12:59:58.802 DEBUG: Taking gradient step
2023-01-03 13:00:01.101 DEBUG: Loss 12: {'policy_loss': 0.0024151422939845957, 'entropy_loss': -0.05467021092772484, 'vf_loss': 0.20940231160323136, 'total_loss': -0.05225506863374024, 'approx_kl': -0.07327085733413696, 'clip_fraction': 0.4505208358168602, 'grad_norm': 12.28540325164795}
2023-01-03 13:00:03.344 DEBUG: Taking gradient step
2023-01-03 13:00:05.784 DEBUG: Loss 13: {'policy_loss': 0.08430769779763386, 'entropy_loss': -0.055401296354830265, 'vf_loss': 0.22051067178933387, 'total_loss': 0.02890640144280359, 'approx_kl': -0.0757991501595825, 'clip_fraction': 0.4361979216337204, 'grad_norm': 21.689964294433594}
2023-01-03 13:00:08.239 DEBUG: Taking gradient step
2023-01-03 13:00:10.578 DEBUG: Loss 14: {'policy_loss': 0.08536013157735413, 'entropy_loss': -0.0560290589928627, 'vf_loss': 0.21865972971275124, 'total_loss': 0.029331072584491427, 'approx_kl': -0.04979850910604, 'clip_fraction': 0.4348958358168602, 'grad_norm': 19.570959091186523}
2023-01-03 13:00:10.579 INFO: Optimization: policy loss=0.085, vf loss=0.219, entropy loss=-0.056, total loss=0.029, num steps=15
2023-01-03 13:00:10.581 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 13:00:12.688 INFO: Evaluation rollout: return=0.791 (0.0), episode length=6.0
2023-01-03 13:00:12.689 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 13:00:12.693 INFO: Iteration: 42/137, steps: 9072
2023-01-03 13:00:24.833 DEBUG: There is a single atom floating around
2023-01-03 13:00:26.832 DEBUG: There is a single atom floating around
2023-01-03 13:00:27.805 DEBUG: Atoms are too close
2023-01-03 13:00:29.363 DEBUG: There is a single atom floating around
2023-01-03 13:00:29.842 DEBUG: There is a single atom floating around
2023-01-03 13:00:29.843 DEBUG: Atoms are too close
2023-01-03 13:00:30.656 DEBUG: There is a single atom floating around
2023-01-03 13:00:30.657 DEBUG: Atoms are too close
2023-01-03 13:00:30.970 DEBUG: There is a single atom floating around
2023-01-03 13:00:39.746 DEBUG: There is a single atom floating around
2023-01-03 13:00:41.862 DEBUG: Atoms are too close
2023-01-03 13:00:44.706 DEBUG: There is a single atom floating around
2023-01-03 13:00:45.150 DEBUG: Atoms are too close
2023-01-03 13:00:45.784 DEBUG: There is a single atom floating around
2023-01-03 13:00:49.943 DEBUG: There is a single atom floating around
2023-01-03 13:00:49.944 DEBUG: There is a single atom floating around
2023-01-03 13:00:49.945 DEBUG: Atoms are too close
2023-01-03 13:00:53.354 DEBUG: Atoms are too close
2023-01-03 13:00:57.908 DEBUG: There is a single atom floating around
2023-01-03 13:01:00.594 DEBUG: Atoms are too close
2023-01-03 13:01:03.265 DEBUG: There is a single atom floating around
2023-01-03 13:01:03.741 DEBUG: Atoms are too close
2023-01-03 13:01:07.387 DEBUG: There is a single atom floating around
2023-01-03 13:01:08.117 DEBUG: There is a single atom floating around
2023-01-03 13:01:08.118 DEBUG: Atoms are too close
2023-01-03 13:01:08.424 DEBUG: Atoms are too close
2023-01-03 13:01:08.501 INFO: Training rollout: return=-21.041 (13.4), episode length=5.6
2023-01-03 13:01:08.503 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 13:01:08.508 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-9072_train.pkl
2023-01-03 13:01:10.892 DEBUG: Taking gradient step
2023-01-03 13:01:13.236 DEBUG: Loss 0: {'policy_loss': 0.010486758509030372, 'entropy_loss': -0.05524695571511984, 'vf_loss': 0.26643124417342146, 'total_loss': -0.04476019720608946, 'approx_kl': 1.1544519651351948e-07, 'clip_fraction': 0.0, 'grad_norm': 18.474639892578125}
2023-01-03 13:01:15.482 DEBUG: Taking gradient step
2023-01-03 13:01:17.784 DEBUG: Loss 1: {'policy_loss': -0.06444069113035822, 'entropy_loss': -0.053324791602790356, 'vf_loss': 0.2527509378107984, 'total_loss': -0.11776548273314857, 'approx_kl': -0.0019461308475001715, 'clip_fraction': 0.140625, 'grad_norm': 16.259315490722656}
2023-01-03 13:01:20.063 DEBUG: Taking gradient step
2023-01-03 13:01:22.359 DEBUG: Loss 2: {'policy_loss': -0.020412714957671493, 'entropy_loss': -0.05252485163509846, 'vf_loss': 0.23923787222296103, 'total_loss': -0.07293756659276995, 'approx_kl': 0.005166845861822367, 'clip_fraction': 0.3072916679084301, 'grad_norm': 21.681106567382812}
2023-01-03 13:01:24.597 DEBUG: Taking gradient step
2023-01-03 13:01:26.911 DEBUG: Loss 3: {'policy_loss': 0.03558433755494111, 'entropy_loss': -0.051381285302340984, 'vf_loss': 0.23448947266555528, 'total_loss': -0.015796947747399877, 'approx_kl': -0.014416674617677927, 'clip_fraction': 0.2630208358168602, 'grad_norm': 20.019092559814453}
2023-01-03 13:01:29.139 DEBUG: Taking gradient step
2023-01-03 13:01:31.517 DEBUG: Loss 4: {'policy_loss': 0.07750794348751172, 'entropy_loss': -0.0510493740439415, 'vf_loss': 0.21214291071616503, 'total_loss': 0.02645856944357023, 'approx_kl': -0.017297323793172836, 'clip_fraction': 0.3411458358168602, 'grad_norm': 24.65772247314453}
2023-01-03 13:01:33.769 DEBUG: Taking gradient step
2023-01-03 13:01:36.063 DEBUG: Loss 5: {'policy_loss': 0.050023488293921906, 'entropy_loss': -0.05340033024549484, 'vf_loss': 0.18668279919804714, 'total_loss': -0.0033768419515729405, 'approx_kl': -0.015090283006429672, 'clip_fraction': 0.3841145858168602, 'grad_norm': 31.424428939819336}
2023-01-03 13:01:38.290 DEBUG: Taking gradient step
2023-01-03 13:01:40.589 DEBUG: Loss 6: {'policy_loss': 0.06687083487219925, 'entropy_loss': -0.05363395530730486, 'vf_loss': 0.17373260966294163, 'total_loss': 0.013236879564894388, 'approx_kl': -0.024668583646416664, 'clip_fraction': 0.3046875, 'grad_norm': 18.855148315429688}
2023-01-03 13:01:42.800 DEBUG: Taking gradient step
2023-01-03 13:01:45.055 DEBUG: Loss 7: {'policy_loss': 0.013434120179155837, 'entropy_loss': -0.054006888531148434, 'vf_loss': 0.18992592788716084, 'total_loss': -0.0405727683519926, 'approx_kl': -0.017463116091676056, 'clip_fraction': 0.3177083358168602, 'grad_norm': 18.175674438476562}
2023-01-03 13:01:47.345 DEBUG: Taking gradient step
2023-01-03 13:01:49.629 DEBUG: Loss 8: {'policy_loss': -0.0023940979894336994, 'entropy_loss': -0.055360290221869946, 'vf_loss': 0.22737008168264342, 'total_loss': -0.05775438821130365, 'approx_kl': -0.0017207656055688858, 'clip_fraction': 0.3111979216337204, 'grad_norm': 31.95468521118164}
2023-01-03 13:01:51.918 DEBUG: Taking gradient step
2023-01-03 13:01:54.227 DEBUG: Loss 9: {'policy_loss': 0.03023575065323567, 'entropy_loss': -0.05263926927000284, 'vf_loss': 0.21519655190705259, 'total_loss': -0.022403518616767176, 'approx_kl': -0.03645499376580119, 'clip_fraction': 0.2604166716337204, 'grad_norm': 16.143407821655273}
2023-01-03 13:01:56.511 DEBUG: Taking gradient step
2023-01-03 13:01:58.830 DEBUG: Loss 10: {'policy_loss': 0.03986909441365199, 'entropy_loss': -0.05201198719441891, 'vf_loss': 0.21052841458054278, 'total_loss': -0.01214289278076692, 'approx_kl': -0.004598977044224739, 'clip_fraction': 0.4583333358168602, 'grad_norm': 15.712484359741211}
2023-01-03 13:02:01.115 DEBUG: Taking gradient step
2023-01-03 13:02:03.396 DEBUG: Loss 11: {'policy_loss': 0.04304254021473182, 'entropy_loss': -0.05038954317569733, 'vf_loss': 0.18882804881802712, 'total_loss': -0.007347002960965507, 'approx_kl': -0.01956350775435567, 'clip_fraction': 0.4049479216337204, 'grad_norm': 18.27826499938965}
2023-01-03 13:02:05.646 DEBUG: Taking gradient step
2023-01-03 13:02:07.924 DEBUG: Loss 12: {'policy_loss': 0.03417445627460229, 'entropy_loss': -0.051549049094319344, 'vf_loss': 0.1835590381107174, 'total_loss': -0.017374592819717052, 'approx_kl': -0.03532910533249378, 'clip_fraction': 0.49609375, 'grad_norm': 11.922992706298828}
2023-01-03 13:02:10.193 DEBUG: Taking gradient step
2023-01-03 13:02:12.441 DEBUG: Loss 13: {'policy_loss': -0.0018880575122187382, 'entropy_loss': -0.053580441512167454, 'vf_loss': 0.18729922884048994, 'total_loss': -0.0554684990243862, 'approx_kl': -0.02642663288861513, 'clip_fraction': 0.4270833358168602, 'grad_norm': 26.619089126586914}
2023-01-03 13:02:14.812 DEBUG: Taking gradient step
2023-01-03 13:02:17.236 DEBUG: Loss 14: {'policy_loss': 0.048174704238998556, 'entropy_loss': -0.054216702468693256, 'vf_loss': 0.19022586908157668, 'total_loss': -0.006041998229694699, 'approx_kl': -0.0514114685356617, 'clip_fraction': 0.3684895858168602, 'grad_norm': 20.28690528869629}
2023-01-03 13:02:17.241 INFO: Optimization: policy loss=0.048, vf loss=0.190, entropy loss=-0.054, total loss=-0.006, num steps=15
2023-01-03 13:02:17.243 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 13:02:19.193 INFO: Evaluation rollout: return=0.725 (0.0), episode length=6.0
2023-01-03 13:02:19.194 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 13:02:19.197 INFO: Iteration: 43/137, steps: 9288
2023-01-03 13:02:29.720 DEBUG: Atoms are too close
2023-01-03 13:02:29.724 DEBUG: Atoms are too close
2023-01-03 13:02:30.087 DEBUG: There is a single atom floating around
2023-01-03 13:02:33.608 DEBUG: Atoms are too close
2023-01-03 13:02:34.060 DEBUG: There is a single atom floating around
2023-01-03 13:02:34.061 DEBUG: There is a single atom floating around
2023-01-03 13:02:34.671 DEBUG: There is a single atom floating around
2023-01-03 13:02:34.672 DEBUG: Atoms are too close
2023-01-03 13:02:34.750 DEBUG: There is a single atom floating around
2023-01-03 13:02:36.739 DEBUG: There is a single atom floating around
2023-01-03 13:02:44.550 DEBUG: There is a single atom floating around
2023-01-03 13:02:44.551 DEBUG: There is a single atom floating around
2023-01-03 13:02:48.499 DEBUG: There is a single atom floating around
2023-01-03 13:02:49.739 DEBUG: Atoms are too close
2023-01-03 13:02:49.740 DEBUG: Atoms are too close
2023-01-03 13:02:50.169 DEBUG: There is a single atom floating around
2023-01-03 13:02:50.743 DEBUG: Atoms are too close
2023-01-03 13:02:52.480 DEBUG: There is a single atom floating around
2023-01-03 13:02:55.960 DEBUG: There is a single atom floating around
2023-01-03 13:03:03.014 DEBUG: Atoms are too close
2023-01-03 13:03:03.363 DEBUG: There is a single atom floating around
2023-01-03 13:03:05.574 DEBUG: There is a single atom floating around
2023-01-03 13:03:05.575 DEBUG: There is a single atom floating around
2023-01-03 13:03:06.952 DEBUG: There is a single atom floating around
2023-01-03 13:03:08.551 DEBUG: Atoms are too close
2023-01-03 13:03:11.040 DEBUG: Atoms are too close
2023-01-03 13:03:15.288 INFO: Training rollout: return=-21.091 (13.5), episode length=5.3
2023-01-03 13:03:15.290 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 13:03:15.292 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-9288_train.pkl
2023-01-03 13:03:17.500 DEBUG: Taking gradient step
2023-01-03 13:03:19.719 DEBUG: Loss 0: {'policy_loss': 0.009204103650147382, 'entropy_loss': -0.05431268457323313, 'vf_loss': 0.19167089627555764, 'total_loss': -0.04510858092308574, 'approx_kl': -6.461050361394882e-08, 'clip_fraction': 0.0, 'grad_norm': 18.40536117553711}
2023-01-03 13:03:21.880 DEBUG: Taking gradient step
2023-01-03 13:03:24.200 DEBUG: Loss 1: {'policy_loss': 0.008069924953666728, 'entropy_loss': -0.056528992019593716, 'vf_loss': 0.19295822586899097, 'total_loss': -0.04845906706592699, 'approx_kl': 0.0016171569004654884, 'clip_fraction': 0.2552083358168602, 'grad_norm': 26.822437286376953}
2023-01-03 13:03:26.399 DEBUG: Taking gradient step
2023-01-03 13:03:28.667 DEBUG: Loss 2: {'policy_loss': 0.0791984428782342, 'entropy_loss': -0.05393477249890566, 'vf_loss': 0.18124784423068196, 'total_loss': 0.025263670379328543, 'approx_kl': -0.02790303761139512, 'clip_fraction': 0.34765625, 'grad_norm': 21.48785972595215}
2023-01-03 13:03:30.895 DEBUG: Taking gradient step
2023-01-03 13:03:33.111 DEBUG: Loss 3: {'policy_loss': 0.07917323672867718, 'entropy_loss': -0.05789571348577738, 'vf_loss': 0.18073181647162778, 'total_loss': 0.02127752324289979, 'approx_kl': -0.03129187459126115, 'clip_fraction': 0.4765625, 'grad_norm': 21.84397315979004}
2023-01-03 13:03:35.284 DEBUG: Taking gradient step
2023-01-03 13:03:37.511 DEBUG: Loss 4: {'policy_loss': 0.06440334675670394, 'entropy_loss': -0.056927116587758064, 'vf_loss': 0.1789886703867825, 'total_loss': 0.0074762301689458716, 'approx_kl': -0.05958877922967076, 'clip_fraction': 0.4583333358168602, 'grad_norm': 22.540950775146484}
2023-01-03 13:03:39.648 DEBUG: Taking gradient step
2023-01-03 13:03:41.873 DEBUG: Loss 5: {'policy_loss': 0.0704295228564657, 'entropy_loss': -0.05796617455780506, 'vf_loss': 0.17533755863902456, 'total_loss': 0.01246334829866064, 'approx_kl': -0.03543574456125498, 'clip_fraction': 0.43359375, 'grad_norm': 21.71293830871582}
2023-01-03 13:03:44.075 DEBUG: Taking gradient step
2023-01-03 13:03:46.398 DEBUG: Loss 6: {'policy_loss': 0.08810108816043836, 'entropy_loss': -0.056436928920447826, 'vf_loss': 0.16770786188105757, 'total_loss': 0.03166415923999054, 'approx_kl': -0.0653913957066834, 'clip_fraction': 0.3658854216337204, 'grad_norm': 25.445348739624023}
2023-01-03 13:03:48.534 DEBUG: Taking gradient step
2023-01-03 13:03:50.745 DEBUG: Loss 7: {'policy_loss': 0.07672991744229012, 'entropy_loss': -0.05596549995243549, 'vf_loss': 0.17167524307022514, 'total_loss': 0.020764417489854622, 'approx_kl': -0.0340635571628809, 'clip_fraction': 0.44140625, 'grad_norm': 24.903074264526367}
2023-01-03 13:03:52.942 DEBUG: Taking gradient step
2023-01-03 13:03:55.149 DEBUG: Loss 8: {'policy_loss': 0.0484762621067604, 'entropy_loss': -0.05539927817881107, 'vf_loss': 0.18239458759809965, 'total_loss': -0.006923016072050673, 'approx_kl': -0.08148867078125477, 'clip_fraction': 0.4479166716337204, 'grad_norm': 25.250215530395508}
2023-01-03 13:03:57.341 DEBUG: Taking gradient step
2023-01-03 13:03:59.557 DEBUG: Loss 9: {'policy_loss': 0.0943989233072832, 'entropy_loss': -0.058120137080550194, 'vf_loss': 0.17091529400495362, 'total_loss': 0.03627878622673301, 'approx_kl': -0.07490753615275025, 'clip_fraction': 0.453125, 'grad_norm': 27.681724548339844}
2023-01-03 13:04:01.747 DEBUG: Taking gradient step
2023-01-03 13:04:03.955 DEBUG: Loss 10: {'policy_loss': 0.07221436920553431, 'entropy_loss': -0.0575224868953228, 'vf_loss': 0.170912793315443, 'total_loss': 0.014691882310211514, 'approx_kl': -0.07005835650488734, 'clip_fraction': 0.4609375, 'grad_norm': 16.383304595947266}
2023-01-03 13:04:06.091 DEBUG: Taking gradient step
2023-01-03 13:04:08.293 DEBUG: Loss 11: {'policy_loss': 0.07849211328151551, 'entropy_loss': -0.05840854998677969, 'vf_loss': 0.17781303644476007, 'total_loss': 0.02008356329473582, 'approx_kl': -0.08959051268175244, 'clip_fraction': 0.4427083358168602, 'grad_norm': 25.01618766784668}
2023-01-03 13:04:10.468 DEBUG: Taking gradient step
2023-01-03 13:04:12.657 DEBUG: Loss 12: {'policy_loss': 0.05223071423788836, 'entropy_loss': -0.05765966232866049, 'vf_loss': 0.18160261922794158, 'total_loss': -0.005428948090772129, 'approx_kl': -0.09211870282888412, 'clip_fraction': 0.4609375, 'grad_norm': 27.78246307373047}
2023-01-03 13:04:14.906 DEBUG: Taking gradient step
2023-01-03 13:04:17.134 DEBUG: Loss 13: {'policy_loss': 0.03767655802120244, 'entropy_loss': -0.05791844055056572, 'vf_loss': 0.17717595574748696, 'total_loss': -0.020241882529363278, 'approx_kl': -0.08242370502557606, 'clip_fraction': 0.4427083358168602, 'grad_norm': 17.779191970825195}
2023-01-03 13:04:19.361 DEBUG: Taking gradient step
2023-01-03 13:04:21.572 DEBUG: Loss 14: {'policy_loss': 0.10309426479662444, 'entropy_loss': -0.05771801993250847, 'vf_loss': 0.17394494235454258, 'total_loss': 0.04537624486411597, 'approx_kl': -0.11320283357053995, 'clip_fraction': 0.5026041716337204, 'grad_norm': 27.392553329467773}
2023-01-03 13:04:21.573 INFO: Optimization: policy loss=0.103, vf loss=0.174, entropy loss=-0.058, total loss=0.045, num steps=15
2023-01-03 13:04:21.574 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 13:04:23.489 INFO: Evaluation rollout: return=0.780 (0.0), episode length=6.0
2023-01-03 13:04:23.491 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 13:04:23.494 INFO: Iteration: 44/137, steps: 9504
2023-01-03 13:04:34.978 DEBUG: Atoms are too close
2023-01-03 13:04:36.234 DEBUG: Atoms are too close
2023-01-03 13:04:36.331 DEBUG: There is a single atom floating around
2023-01-03 13:04:36.636 DEBUG: There is a single atom floating around
2023-01-03 13:04:36.637 DEBUG: There is a single atom floating around
2023-01-03 13:04:37.398 DEBUG: There is a single atom floating around
2023-01-03 13:04:37.399 DEBUG: There is a single atom floating around
2023-01-03 13:04:37.400 DEBUG: There is a single atom floating around
2023-01-03 13:04:38.085 DEBUG: There is a single atom floating around
2023-01-03 13:04:38.407 DEBUG: There is a single atom floating around
2023-01-03 13:04:38.407 DEBUG: There is a single atom floating around
2023-01-03 13:04:47.069 DEBUG: There is a single atom floating around
2023-01-03 13:04:52.455 DEBUG: Atoms are too close
2023-01-03 13:04:52.456 DEBUG: Atoms are too close
2023-01-03 13:04:53.437 DEBUG: Atoms are too close
2023-01-03 13:04:55.699 DEBUG: There is a single atom floating around
2023-01-03 13:04:56.905 DEBUG: Atoms are too close
2023-01-03 13:04:57.196 DEBUG: Atoms are too close
2023-01-03 13:05:06.159 DEBUG: There is a single atom floating around
2023-01-03 13:05:08.472 DEBUG: Atoms are too close
2023-01-03 13:05:09.146 DEBUG: Atoms are too close
2023-01-03 13:05:10.060 DEBUG: Atoms are too close
2023-01-03 13:05:11.501 DEBUG: There is a single atom floating around
2023-01-03 13:05:13.467 DEBUG: Atoms are too close
2023-01-03 13:05:18.432 INFO: Training rollout: return=-19.397 (14.1), episode length=5.5
2023-01-03 13:05:18.434 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 13:05:18.437 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-9504_train.pkl
2023-01-03 13:05:20.691 DEBUG: Taking gradient step
2023-01-03 13:05:22.920 DEBUG: Loss 0: {'policy_loss': 0.03534043652635803, 'entropy_loss': -0.05733361095190048, 'vf_loss': 0.18373097486443782, 'total_loss': -0.02199317442554246, 'approx_kl': 3.709768492399235e-08, 'clip_fraction': 0.0, 'grad_norm': 27.615026473999023}
2023-01-03 13:05:25.103 DEBUG: Taking gradient step
2023-01-03 13:05:27.353 DEBUG: Loss 1: {'policy_loss': 0.022168751158920412, 'entropy_loss': -0.05924522876739502, 'vf_loss': 0.18794968343342877, 'total_loss': -0.03707647760847461, 'approx_kl': -0.0014515314251184464, 'clip_fraction': 0.2981770858168602, 'grad_norm': 34.64508056640625}
2023-01-03 13:05:29.541 DEBUG: Taking gradient step
2023-01-03 13:05:31.785 DEBUG: Loss 2: {'policy_loss': 0.07055839766371633, 'entropy_loss': -0.05881997290998697, 'vf_loss': 0.1863686004658013, 'total_loss': 0.011738424753729347, 'approx_kl': -0.03455715533345938, 'clip_fraction': 0.4518229216337204, 'grad_norm': 29.844520568847656}
2023-01-03 13:05:33.986 DEBUG: Taking gradient step
2023-01-03 13:05:36.361 DEBUG: Loss 3: {'policy_loss': 0.10668461193160056, 'entropy_loss': -0.05896749813109636, 'vf_loss': 0.198120262260328, 'total_loss': 0.04771711380050421, 'approx_kl': -0.028401663526892662, 'clip_fraction': 0.53125, 'grad_norm': 44.98292541503906}
2023-01-03 13:05:38.555 DEBUG: Taking gradient step
2023-01-03 13:05:40.780 DEBUG: Loss 4: {'policy_loss': 0.06343005709841058, 'entropy_loss': -0.05922271218150854, 'vf_loss': 0.18678740988072579, 'total_loss': 0.0042073449169020526, 'approx_kl': -0.04840732552111149, 'clip_fraction': 0.5572916716337204, 'grad_norm': 40.78255844116211}
2023-01-03 13:05:42.951 DEBUG: Taking gradient step
2023-01-03 13:05:45.215 DEBUG: Loss 5: {'policy_loss': 0.04695298764222106, 'entropy_loss': -0.059389641508460045, 'vf_loss': 0.19984800243957693, 'total_loss': -0.01243665386623898, 'approx_kl': -0.03595850896090269, 'clip_fraction': 0.4427083358168602, 'grad_norm': 33.39750289916992}
2023-01-03 13:05:47.384 DEBUG: Taking gradient step
2023-01-03 13:05:49.753 DEBUG: Loss 6: {'policy_loss': 0.09957394409289551, 'entropy_loss': -0.060430741868913174, 'vf_loss': 0.18320925525538906, 'total_loss': 0.039143202223982335, 'approx_kl': -0.020568599924445152, 'clip_fraction': 0.41015625, 'grad_norm': 39.4176139831543}
2023-01-03 13:05:52.010 DEBUG: Taking gradient step
2023-01-03 13:05:54.310 DEBUG: Loss 7: {'policy_loss': 0.09117046643492463, 'entropy_loss': -0.059826876036822796, 'vf_loss': 0.1935495114798543, 'total_loss': 0.03134359039810184, 'approx_kl': -0.049525875598192215, 'clip_fraction': 0.4036458358168602, 'grad_norm': 52.165016174316406}
2023-01-03 13:05:56.714 DEBUG: Taking gradient step
2023-01-03 13:05:58.963 DEBUG: Loss 8: {'policy_loss': 0.019308335566413162, 'entropy_loss': -0.05887599103152752, 'vf_loss': 0.19205633119104587, 'total_loss': -0.03956765546511436, 'approx_kl': -0.04089599475264549, 'clip_fraction': 0.4361979216337204, 'grad_norm': 29.338748931884766}
2023-01-03 13:06:01.153 DEBUG: Taking gradient step
2023-01-03 13:06:03.388 DEBUG: Loss 9: {'policy_loss': 0.06871881318880001, 'entropy_loss': -0.05672256741672754, 'vf_loss': 0.1852500046122327, 'total_loss': 0.011996245772072476, 'approx_kl': -0.04825291410088539, 'clip_fraction': 0.4544270858168602, 'grad_norm': 28.812978744506836}
2023-01-03 13:06:05.582 DEBUG: Taking gradient step
2023-01-03 13:06:07.815 DEBUG: Loss 10: {'policy_loss': 0.11749775740324345, 'entropy_loss': -0.05775163508951664, 'vf_loss': 0.19101437349206726, 'total_loss': 0.05974612231372682, 'approx_kl': -0.055347881047055125, 'clip_fraction': 0.4921875, 'grad_norm': 41.89452362060547}
2023-01-03 13:06:10.107 DEBUG: Taking gradient step
2023-01-03 13:06:12.434 DEBUG: Loss 11: {'policy_loss': 0.08588869090956154, 'entropy_loss': -0.06015051994472742, 'vf_loss': 0.19561848886098668, 'total_loss': 0.02573817096483412, 'approx_kl': -0.06781656108796597, 'clip_fraction': 0.4609375, 'grad_norm': 40.87294006347656}
2023-01-03 13:06:14.616 DEBUG: Taking gradient step
2023-01-03 13:06:16.864 DEBUG: Loss 12: {'policy_loss': 0.10983868847618077, 'entropy_loss': -0.059421198442578316, 'vf_loss': 0.18572872322915676, 'total_loss': 0.05041749003360245, 'approx_kl': -0.0623412299901247, 'clip_fraction': 0.4140625, 'grad_norm': 41.37758255004883}
2023-01-03 13:06:19.077 DEBUG: Taking gradient step
2023-01-03 13:06:21.310 DEBUG: Loss 13: {'policy_loss': 0.07703563859988469, 'entropy_loss': -0.05771459452807903, 'vf_loss': 0.1903979779607357, 'total_loss': 0.019321044071805654, 'approx_kl': -0.05712690018117428, 'clip_fraction': 0.4921875, 'grad_norm': 53.13285827636719}
2023-01-03 13:06:23.483 DEBUG: Taking gradient step
2023-01-03 13:06:25.718 DEBUG: Loss 14: {'policy_loss': 0.05839097049497889, 'entropy_loss': -0.059208594262599945, 'vf_loss': 0.19300260210157527, 'total_loss': -0.0008176237676210465, 'approx_kl': -0.08327864203602076, 'clip_fraction': 0.53125, 'grad_norm': 28.422405242919922}
2023-01-03 13:06:25.719 INFO: Optimization: policy loss=0.058, vf loss=0.193, entropy loss=-0.059, total loss=-0.001, num steps=15
2023-01-03 13:06:25.720 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 13:06:26.951 DEBUG: Atoms are too close
2023-01-03 13:06:26.953 INFO: Evaluation rollout: return=-29.482 (0.0), episode length=5.0
2023-01-03 13:06:26.954 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 13:06:26.958 INFO: Iteration: 45/137, steps: 9720
2023-01-03 13:06:39.082 DEBUG: Atoms are too close
2023-01-03 13:06:40.464 DEBUG: There is a single atom floating around
2023-01-03 13:06:42.525 DEBUG: There is a single atom floating around
2023-01-03 13:06:44.000 DEBUG: There is a single atom floating around
2023-01-03 13:06:44.001 DEBUG: There is a single atom floating around
2023-01-03 13:06:44.001 DEBUG: Atoms are too close
2023-01-03 13:06:44.002 DEBUG: Atoms are too close
2023-01-03 13:06:44.778 DEBUG: There is a single atom floating around
2023-01-03 13:06:55.691 DEBUG: Atoms are too close
2023-01-03 13:06:59.463 DEBUG: Atoms are too close
2023-01-03 13:07:04.035 DEBUG: There is a single atom floating around
2023-01-03 13:07:04.036 DEBUG: There is a single atom floating around
2023-01-03 13:07:10.321 DEBUG: There is a single atom floating around
2023-01-03 13:07:15.568 DEBUG: There is a single atom floating around
2023-01-03 13:07:15.885 DEBUG: Atoms are too close
2023-01-03 13:07:17.116 DEBUG: Atoms are too close
2023-01-03 13:07:17.456 DEBUG: Atoms are too close
2023-01-03 13:07:18.677 DEBUG: Atoms are too close
2023-01-03 13:07:20.284 DEBUG: Atoms are too close
2023-01-03 13:07:20.978 DEBUG: There is a single atom floating around
2023-01-03 13:07:21.789 DEBUG: Atoms are too close
2023-01-03 13:07:23.271 INFO: Training rollout: return=-16.968 (14.8), episode length=5.6
2023-01-03 13:07:23.273 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 13:07:23.275 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-9720_train.pkl
2023-01-03 13:07:25.521 DEBUG: Taking gradient step
2023-01-03 13:07:28.156 DEBUG: Loss 0: {'policy_loss': 0.040353264790830415, 'entropy_loss': -0.05689446534961462, 'vf_loss': 0.21115594940612373, 'total_loss': -0.016541200558784205, 'approx_kl': 5.4016709327697754e-08, 'clip_fraction': 0.0, 'grad_norm': 11.82096004486084}
2023-01-03 13:07:30.536 DEBUG: Taking gradient step
2023-01-03 13:07:32.845 DEBUG: Loss 1: {'policy_loss': 0.039326099631962944, 'entropy_loss': -0.058816853910684586, 'vf_loss': 0.21031751634246248, 'total_loss': -0.019490754278721642, 'approx_kl': -0.015813183272257447, 'clip_fraction': 0.2174479216337204, 'grad_norm': 19.670795440673828}
2023-01-03 13:07:35.071 DEBUG: Taking gradient step
2023-01-03 13:07:37.354 DEBUG: Loss 2: {'policy_loss': -0.024626096257288056, 'entropy_loss': -0.05948325525969267, 'vf_loss': 0.2154782011826318, 'total_loss': -0.08410935151698072, 'approx_kl': -0.013025677995756269, 'clip_fraction': 0.2747395858168602, 'grad_norm': 21.995559692382812}
2023-01-03 13:07:39.653 DEBUG: Taking gradient step
2023-01-03 13:07:41.909 DEBUG: Loss 3: {'policy_loss': -0.01834390604467291, 'entropy_loss': -0.058552494272589684, 'vf_loss': 0.21487307212402826, 'total_loss': -0.0768964003172626, 'approx_kl': -0.0067046694457530975, 'clip_fraction': 0.2630208358168602, 'grad_norm': 22.0286808013916}
2023-01-03 13:07:44.149 DEBUG: Taking gradient step
2023-01-03 13:07:46.435 DEBUG: Loss 4: {'policy_loss': 0.041728265716058234, 'entropy_loss': -0.059119461104273796, 'vf_loss': 0.20739169139360725, 'total_loss': -0.017391195388215562, 'approx_kl': -0.008930013747885823, 'clip_fraction': 0.24609375, 'grad_norm': 18.84674644470215}
2023-01-03 13:07:48.733 DEBUG: Taking gradient step
2023-01-03 13:07:51.122 DEBUG: Loss 5: {'policy_loss': 0.05293378510325654, 'entropy_loss': -0.05886055529117584, 'vf_loss': 0.2098276465764033, 'total_loss': -0.005926770187919303, 'approx_kl': -0.036695287097245455, 'clip_fraction': 0.2135416679084301, 'grad_norm': 18.695425033569336}
2023-01-03 13:07:53.336 DEBUG: Taking gradient step
2023-01-03 13:07:55.716 DEBUG: Loss 6: {'policy_loss': -0.0116650147995635, 'entropy_loss': -0.05957722570747137, 'vf_loss': 0.2090695358789415, 'total_loss': -0.07124224050703487, 'approx_kl': -0.02966861566528678, 'clip_fraction': 0.2526041679084301, 'grad_norm': 14.88547420501709}
2023-01-03 13:07:57.904 DEBUG: Taking gradient step
2023-01-03 13:08:00.148 DEBUG: Loss 7: {'policy_loss': 0.02561916674552128, 'entropy_loss': -0.05759072210639715, 'vf_loss': 0.21088774665076704, 'total_loss': -0.03197155536087587, 'approx_kl': -0.04008477879688144, 'clip_fraction': 0.2513020858168602, 'grad_norm': 13.712688446044922}
2023-01-03 13:08:02.342 DEBUG: Taking gradient step
2023-01-03 13:08:04.718 DEBUG: Loss 8: {'policy_loss': 0.07984091771149107, 'entropy_loss': -0.059506986290216446, 'vf_loss': 0.20713477079857406, 'total_loss': 0.020333931421274626, 'approx_kl': -0.05301141971722245, 'clip_fraction': 0.296875, 'grad_norm': 11.003150939941406}
2023-01-03 13:08:06.911 DEBUG: Taking gradient step
2023-01-03 13:08:09.181 DEBUG: Loss 9: {'policy_loss': 0.08633992509909047, 'entropy_loss': -0.058149488642811775, 'vf_loss': 0.21057668046296102, 'total_loss': 0.028190436456278688, 'approx_kl': -0.02905957493931055, 'clip_fraction': 0.3658854216337204, 'grad_norm': 21.541173934936523}
2023-01-03 13:08:11.375 DEBUG: Taking gradient step
2023-01-03 13:08:13.635 DEBUG: Loss 10: {'policy_loss': 0.020260540843015064, 'entropy_loss': -0.058372655883431435, 'vf_loss': 0.20710110986843583, 'total_loss': -0.03811211504041637, 'approx_kl': -0.0382622885517776, 'clip_fraction': 0.3033854179084301, 'grad_norm': 20.39311408996582}
2023-01-03 13:08:15.827 DEBUG: Taking gradient step
2023-01-03 13:08:18.204 DEBUG: Loss 11: {'policy_loss': 0.0071545709572588476, 'entropy_loss': -0.05976997874677181, 'vf_loss': 0.20713675581288943, 'total_loss': -0.05261540778951296, 'approx_kl': -0.04061917867511511, 'clip_fraction': 0.32421875, 'grad_norm': 18.678497314453125}
2023-01-03 13:08:20.473 DEBUG: Taking gradient step
2023-01-03 13:08:22.721 DEBUG: Loss 12: {'policy_loss': 0.07380522992579736, 'entropy_loss': -0.05760543327778578, 'vf_loss': 0.2025338948743664, 'total_loss': 0.016199796648011584, 'approx_kl': -0.01774392183870077, 'clip_fraction': 0.40625, 'grad_norm': 12.303400039672852}
2023-01-03 13:08:24.915 DEBUG: Taking gradient step
2023-01-03 13:08:27.150 DEBUG: Loss 13: {'policy_loss': 0.0067501235366918405, 'entropy_loss': -0.05923623777925968, 'vf_loss': 0.20119752505793373, 'total_loss': -0.05248611424256784, 'approx_kl': -0.05237535201013088, 'clip_fraction': 0.3619791716337204, 'grad_norm': 23.29078483581543}
2023-01-03 13:08:29.353 DEBUG: Taking gradient step
2023-01-03 13:08:31.610 DEBUG: Loss 14: {'policy_loss': 0.021643616365270485, 'entropy_loss': -0.05954819265753031, 'vf_loss': 0.20030027331623135, 'total_loss': -0.03790457629225982, 'approx_kl': -0.05435081431642175, 'clip_fraction': 0.375, 'grad_norm': 19.51584815979004}
2023-01-03 13:08:31.613 INFO: Optimization: policy loss=0.022, vf loss=0.200, entropy loss=-0.060, total loss=-0.038, num steps=15
2023-01-03 13:08:31.615 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 13:08:32.797 DEBUG: Atoms are too close
2023-01-03 13:08:32.799 INFO: Evaluation rollout: return=-29.370 (0.0), episode length=5.0
2023-01-03 13:08:32.800 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 13:08:32.802 INFO: Iteration: 46/137, steps: 9936
2023-01-03 13:08:46.316 DEBUG: Atoms are too close
2023-01-03 13:08:46.317 DEBUG: There is a single atom floating around
2023-01-03 13:08:46.317 DEBUG: There is a single atom floating around
2023-01-03 13:08:52.797 DEBUG: There is a single atom floating around
2023-01-03 13:09:03.931 DEBUG: There is a single atom floating around
2023-01-03 13:09:07.944 DEBUG: There is a single atom floating around
2023-01-03 13:09:07.946 DEBUG: There is a single atom floating around
2023-01-03 13:09:10.590 DEBUG: Atoms are too close
2023-01-03 13:09:10.909 DEBUG: There is a single atom floating around
2023-01-03 13:09:19.402 DEBUG: Atoms are too close
2023-01-03 13:09:22.631 DEBUG: Atoms are too close
2023-01-03 13:09:22.785 DEBUG: There is a single atom floating around
2023-01-03 13:09:22.786 DEBUG: Atoms are too close
2023-01-03 13:09:23.412 DEBUG: Atoms are too close
2023-01-03 13:09:25.827 DEBUG: Atoms are too close
2023-01-03 13:09:25.828 DEBUG: Atoms are too close
2023-01-03 13:09:26.297 DEBUG: There is a single atom floating around
2023-01-03 13:09:26.298 DEBUG: Atoms are too close
2023-01-03 13:09:26.299 DEBUG: There is a single atom floating around
2023-01-03 13:09:29.421 DEBUG: Atoms are too close
2023-01-03 13:09:29.501 INFO: Training rollout: return=-16.181 (14.8), episode length=5.6
2023-01-03 13:09:29.502 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 13:09:29.505 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-9936_train.pkl
2023-01-03 13:09:31.770 DEBUG: Taking gradient step
2023-01-03 13:09:34.073 DEBUG: Loss 0: {'policy_loss': 0.0038675320037584483, 'entropy_loss': -0.0594884529709816, 'vf_loss': 0.20846010742523186, 'total_loss': -0.05562092096722315, 'approx_kl': 4.8351163961513066e-08, 'clip_fraction': 0.0, 'grad_norm': 21.921722412109375}
2023-01-03 13:09:36.255 DEBUG: Taking gradient step
2023-01-03 13:09:38.526 DEBUG: Loss 1: {'policy_loss': 0.0848195429513468, 'entropy_loss': -0.05744499713182449, 'vf_loss': 0.21168751360116683, 'total_loss': 0.027374545819522297, 'approx_kl': -0.015283152228221297, 'clip_fraction': 0.3776041716337204, 'grad_norm': 38.430755615234375}
2023-01-03 13:09:40.771 DEBUG: Taking gradient step
2023-01-03 13:09:43.144 DEBUG: Loss 2: {'policy_loss': 0.20401532946266554, 'entropy_loss': -0.056405024603009224, 'vf_loss': 0.2112608134921222, 'total_loss': 0.14761030485965632, 'approx_kl': -0.02552678342908621, 'clip_fraction': 0.42578125, 'grad_norm': 55.19390869140625}
2023-01-03 13:09:45.344 DEBUG: Taking gradient step
2023-01-03 13:09:47.581 DEBUG: Loss 3: {'policy_loss': 0.10347362274439206, 'entropy_loss': -0.05737777426838875, 'vf_loss': 0.20999488409188843, 'total_loss': 0.046095848476003315, 'approx_kl': -0.05421241745352745, 'clip_fraction': 0.3697916716337204, 'grad_norm': 33.3187370300293}
2023-01-03 13:09:49.775 DEBUG: Taking gradient step
2023-01-03 13:09:52.045 DEBUG: Loss 4: {'policy_loss': 0.029766877322863372, 'entropy_loss': -0.05670570954680443, 'vf_loss': 0.21089538443639777, 'total_loss': -0.026938832223941063, 'approx_kl': -0.07820611773058772, 'clip_fraction': 0.5559895932674408, 'grad_norm': 29.06168556213379}
2023-01-03 13:09:54.268 DEBUG: Taking gradient step
2023-01-03 13:09:56.770 DEBUG: Loss 5: {'policy_loss': 0.09753990203118165, 'entropy_loss': -0.05590326339006424, 'vf_loss': 0.20698772395968787, 'total_loss': 0.04163663864111741, 'approx_kl': -0.07021012529730797, 'clip_fraction': 0.5104166716337204, 'grad_norm': 37.62493896484375}
2023-01-03 13:09:58.939 DEBUG: Taking gradient step
2023-01-03 13:10:01.192 DEBUG: Loss 6: {'policy_loss': 0.20839268263921618, 'entropy_loss': -0.05565919820219278, 'vf_loss': 0.20487766411543148, 'total_loss': 0.1527334844370234, 'approx_kl': -0.05745913274586201, 'clip_fraction': 0.5052083432674408, 'grad_norm': 48.81566619873047}
2023-01-03 13:10:03.412 DEBUG: Taking gradient step
2023-01-03 13:10:05.741 DEBUG: Loss 7: {'policy_loss': 0.20717600372034933, 'entropy_loss': -0.05835335701704025, 'vf_loss': 0.207716830370163, 'total_loss': 0.14882264670330908, 'approx_kl': -0.14022330939769745, 'clip_fraction': 0.49609375, 'grad_norm': 67.50192260742188}
2023-01-03 13:10:07.989 DEBUG: Taking gradient step
2023-01-03 13:10:10.293 DEBUG: Loss 8: {'policy_loss': 0.1931575129391069, 'entropy_loss': -0.05825934559106827, 'vf_loss': 0.20633437067255703, 'total_loss': 0.13489816734803864, 'approx_kl': -0.12570767849683762, 'clip_fraction': 0.4908854216337204, 'grad_norm': 41.309471130371094}
2023-01-03 13:10:12.510 DEBUG: Taking gradient step
2023-01-03 13:10:14.797 DEBUG: Loss 9: {'policy_loss': 0.19944612928125593, 'entropy_loss': -0.0594579242169857, 'vf_loss': 0.2109111494375367, 'total_loss': 0.13998820506427023, 'approx_kl': -0.12429616786539555, 'clip_fraction': 0.4466145858168602, 'grad_norm': 37.33955764770508}
2023-01-03 13:10:16.991 DEBUG: Taking gradient step
2023-01-03 13:10:19.206 DEBUG: Loss 10: {'policy_loss': 0.12549529267891135, 'entropy_loss': -0.05915123410522938, 'vf_loss': 0.2083694006985359, 'total_loss': 0.06634405857368196, 'approx_kl': -0.14470124058425426, 'clip_fraction': 0.4713541716337204, 'grad_norm': 32.9254264831543}
2023-01-03 13:10:21.399 DEBUG: Taking gradient step
2023-01-03 13:10:23.802 DEBUG: Loss 11: {'policy_loss': 0.1929314360214315, 'entropy_loss': -0.060135298408567905, 'vf_loss': 0.21046062515736513, 'total_loss': 0.1327961376128636, 'approx_kl': -0.15439223125576973, 'clip_fraction': 0.46875, 'grad_norm': 52.05442810058594}
2023-01-03 13:10:25.985 DEBUG: Taking gradient step
2023-01-03 13:10:28.239 DEBUG: Loss 12: {'policy_loss': 0.1746271801455811, 'entropy_loss': -0.05884758662432432, 'vf_loss': 0.21221837745754213, 'total_loss': 0.11577959352125676, 'approx_kl': -0.1774985110387206, 'clip_fraction': 0.4205729216337204, 'grad_norm': 60.59767532348633}
2023-01-03 13:10:30.433 DEBUG: Taking gradient step
2023-01-03 13:10:32.695 DEBUG: Loss 13: {'policy_loss': 0.14396485900911915, 'entropy_loss': -0.058571258559823036, 'vf_loss': 0.21025667612724108, 'total_loss': 0.08539360044929611, 'approx_kl': -0.13725950568914413, 'clip_fraction': 0.4596354216337204, 'grad_norm': 40.02703094482422}
2023-01-03 13:10:34.901 DEBUG: Taking gradient step
2023-01-03 13:10:37.127 DEBUG: Loss 14: {'policy_loss': 0.19652704311585506, 'entropy_loss': -0.05652699898928404, 'vf_loss': 0.2052696670765845, 'total_loss': 0.14000004412657105, 'approx_kl': -0.14271726086735725, 'clip_fraction': 0.5625, 'grad_norm': 39.66750717163086}
2023-01-03 13:10:37.131 INFO: Optimization: policy loss=0.197, vf loss=0.205, entropy loss=-0.057, total loss=0.140, num steps=15
2023-01-03 13:10:37.133 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 13:10:38.347 DEBUG: Atoms are too close
2023-01-03 13:10:38.349 INFO: Evaluation rollout: return=-29.378 (0.0), episode length=5.0
2023-01-03 13:10:38.350 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 13:10:38.352 INFO: Iteration: 47/137, steps: 10152
2023-01-03 13:10:50.088 DEBUG: Atoms are too close
2023-01-03 13:10:56.126 DEBUG: There is a single atom floating around
2023-01-03 13:10:57.364 DEBUG: There is a single atom floating around
2023-01-03 13:10:57.365 DEBUG: There is a single atom floating around
2023-01-03 13:10:57.679 DEBUG: Atoms are too close
2023-01-03 13:10:57.679 DEBUG: Atoms are too close
2023-01-03 13:11:09.499 DEBUG: Atoms are too close
2023-01-03 13:11:12.423 DEBUG: Atoms are too close
2023-01-03 13:11:12.915 DEBUG: Atoms are too close
2023-01-03 13:11:13.261 DEBUG: Atoms are too close
2023-01-03 13:11:14.635 DEBUG: Atoms are too close
2023-01-03 13:11:15.125 DEBUG: Atoms are too close
2023-01-03 13:11:25.137 DEBUG: There is a single atom floating around
2023-01-03 13:11:25.142 DEBUG: Atoms are too close
2023-01-03 13:11:27.803 DEBUG: There is a single atom floating around
2023-01-03 13:11:28.417 DEBUG: Atoms are too close
2023-01-03 13:11:30.403 DEBUG: There is a single atom floating around
2023-01-03 13:11:31.672 DEBUG: Atoms are too close
2023-01-03 13:11:32.007 DEBUG: Atoms are too close
2023-01-03 13:11:35.614 INFO: Training rollout: return=-15.348 (14.9), episode length=5.6
2023-01-03 13:11:35.616 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 13:11:35.618 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-10152_train.pkl
2023-01-03 13:11:37.865 DEBUG: Taking gradient step
2023-01-03 13:11:40.121 DEBUG: Loss 0: {'policy_loss': 0.0030344964110168545, 'entropy_loss': -0.05773838609457016, 'vf_loss': 0.2109944547657217, 'total_loss': -0.0547038896835533, 'approx_kl': 1.5444427958755114e-08, 'clip_fraction': 0.0, 'grad_norm': 26.982940673828125}
2023-01-03 13:11:42.357 DEBUG: Taking gradient step
2023-01-03 13:11:44.629 DEBUG: Loss 1: {'policy_loss': -0.071502835167124, 'entropy_loss': -0.058711535297334194, 'vf_loss': 0.20717897311404246, 'total_loss': -0.1302143704644582, 'approx_kl': -0.0035040597431361675, 'clip_fraction': 0.2057291679084301, 'grad_norm': 21.962770462036133}
2023-01-03 13:11:46.924 DEBUG: Taking gradient step
2023-01-03 13:11:49.301 DEBUG: Loss 2: {'policy_loss': 0.01676691329668297, 'entropy_loss': -0.06207587942481041, 'vf_loss': 0.20579535180770211, 'total_loss': -0.04530896612812744, 'approx_kl': -0.025729812041390687, 'clip_fraction': 0.24088541697710752, 'grad_norm': 23.076913833618164}
2023-01-03 13:11:51.570 DEBUG: Taking gradient step
2023-01-03 13:11:53.901 DEBUG: Loss 3: {'policy_loss': 0.008275164917461372, 'entropy_loss': -0.060926622711122036, 'vf_loss': 0.2061107831495162, 'total_loss': -0.052651457793660664, 'approx_kl': -0.04184426087886095, 'clip_fraction': 0.3138020858168602, 'grad_norm': 30.995607376098633}
2023-01-03 13:11:56.347 DEBUG: Taking gradient step
2023-01-03 13:11:58.637 DEBUG: Loss 4: {'policy_loss': 0.033804441642113554, 'entropy_loss': -0.06131913047283888, 'vf_loss': 0.2166990079163119, 'total_loss': -0.027514688830725324, 'approx_kl': -0.030177701613865793, 'clip_fraction': 0.4518229216337204, 'grad_norm': 10.93299674987793}
2023-01-03 13:12:00.918 DEBUG: Taking gradient step
2023-01-03 13:12:03.202 DEBUG: Loss 5: {'policy_loss': 0.06691357891859867, 'entropy_loss': -0.0645225141197443, 'vf_loss': 0.2038504812012058, 'total_loss': 0.0023910647988543594, 'approx_kl': -0.04758470645174384, 'clip_fraction': 0.4557291716337204, 'grad_norm': 28.349367141723633}
2023-01-03 13:12:05.459 DEBUG: Taking gradient step
2023-01-03 13:12:07.735 DEBUG: Loss 6: {'policy_loss': 0.09376801071291269, 'entropy_loss': -0.059085916727781296, 'vf_loss': 0.21121630233263478, 'total_loss': 0.03468209398513139, 'approx_kl': -0.05996111501008272, 'clip_fraction': 0.4635416716337204, 'grad_norm': 35.70484161376953}
2023-01-03 13:12:09.968 DEBUG: Taking gradient step
2023-01-03 13:12:12.278 DEBUG: Loss 7: {'policy_loss': 0.07238759494616946, 'entropy_loss': -0.06066343002021313, 'vf_loss': 0.20605890163353544, 'total_loss': 0.011724164925956331, 'approx_kl': -0.08379360567778349, 'clip_fraction': 0.4505208432674408, 'grad_norm': 22.860315322875977}
2023-01-03 13:12:14.510 DEBUG: Taking gradient step
2023-01-03 13:12:16.903 DEBUG: Loss 8: {'policy_loss': 0.00994253945641943, 'entropy_loss': -0.057224150747060776, 'vf_loss': 0.2069553142320339, 'total_loss': -0.047281611290641345, 'approx_kl': -0.06310817925259471, 'clip_fraction': 0.3619791716337204, 'grad_norm': 17.502531051635742}
2023-01-03 13:12:19.336 DEBUG: Taking gradient step
2023-01-03 13:12:21.603 DEBUG: Loss 9: {'policy_loss': 0.026893875960647337, 'entropy_loss': -0.061022648587822914, 'vf_loss': 0.21167054953189762, 'total_loss': -0.03412877262717558, 'approx_kl': -0.0796073186211288, 'clip_fraction': 0.4114583432674408, 'grad_norm': 38.89699172973633}
2023-01-03 13:12:23.807 DEBUG: Taking gradient step
2023-01-03 13:12:26.098 DEBUG: Loss 10: {'policy_loss': 0.024112789709017708, 'entropy_loss': -0.061056516133248806, 'vf_loss': 0.2116814569467877, 'total_loss': -0.036943726424231105, 'approx_kl': -0.07074792496860027, 'clip_fraction': 0.3776041716337204, 'grad_norm': 35.18987274169922}
2023-01-03 13:12:28.459 DEBUG: Taking gradient step
2023-01-03 13:12:31.106 DEBUG: Loss 11: {'policy_loss': 0.07507642389496169, 'entropy_loss': -0.06114662252366543, 'vf_loss': 0.2112431920268393, 'total_loss': 0.01392980137129627, 'approx_kl': -0.06752057839185, 'clip_fraction': 0.4401041716337204, 'grad_norm': 23.48787498474121}
2023-01-03 13:12:33.313 DEBUG: Taking gradient step
2023-01-03 13:12:35.587 DEBUG: Loss 12: {'policy_loss': 0.08439950977842015, 'entropy_loss': -0.061445572413504124, 'vf_loss': 0.21253378879871296, 'total_loss': 0.02295393736491603, 'approx_kl': -0.06956489942967892, 'clip_fraction': 0.5169270932674408, 'grad_norm': 31.447845458984375}
2023-01-03 13:12:37.837 DEBUG: Taking gradient step
2023-01-03 13:12:40.164 DEBUG: Loss 13: {'policy_loss': 0.06333537313296451, 'entropy_loss': -0.06074553728103638, 'vf_loss': 0.20898829182608009, 'total_loss': 0.002589835851928138, 'approx_kl': -0.08729120716452599, 'clip_fraction': 0.4192708358168602, 'grad_norm': 35.644718170166016}
2023-01-03 13:12:42.448 DEBUG: Taking gradient step
2023-01-03 13:12:44.712 DEBUG: Loss 14: {'policy_loss': 0.0934176608069733, 'entropy_loss': -0.06044994853436947, 'vf_loss': 0.20936803207595522, 'total_loss': 0.03296771227260383, 'approx_kl': -0.07207324262708426, 'clip_fraction': 0.46484375, 'grad_norm': 32.671348571777344}
2023-01-03 13:12:44.713 INFO: Optimization: policy loss=0.093, vf loss=0.209, entropy loss=-0.060, total loss=0.033, num steps=15
2023-01-03 13:12:44.714 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 13:12:45.961 DEBUG: Atoms are too close
2023-01-03 13:12:45.964 INFO: Evaluation rollout: return=-29.407 (0.0), episode length=5.0
2023-01-03 13:12:45.964 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 13:12:45.967 INFO: Iteration: 48/137, steps: 10368
2023-01-03 13:12:59.821 DEBUG: Atoms are too close
2023-01-03 13:13:00.762 DEBUG: Atoms are too close
2023-01-03 13:13:01.060 DEBUG: Atoms are too close
2023-01-03 13:13:01.664 DEBUG: Atoms are too close
2023-01-03 13:13:03.111 DEBUG: Atoms are too close
2023-01-03 13:13:04.037 DEBUG: Atoms are too close
2023-01-03 13:13:11.372 DEBUG: Atoms are too close
2023-01-03 13:13:15.147 DEBUG: Atoms are too close
2023-01-03 13:13:15.779 DEBUG: There is a single atom floating around
2023-01-03 13:13:17.340 DEBUG: There is a single atom floating around
2023-01-03 13:13:18.567 DEBUG: There is a single atom floating around
2023-01-03 13:13:19.656 DEBUG: Atoms are too close
2023-01-03 13:13:19.657 DEBUG: There is a single atom floating around
2023-01-03 13:13:19.897 DEBUG: Atoms are too close
2023-01-03 13:13:21.865 DEBUG: There is a single atom floating around
2023-01-03 13:13:22.713 DEBUG: Atoms are too close
2023-01-03 13:13:33.649 DEBUG: There is a single atom floating around
2023-01-03 13:13:33.650 DEBUG: Atoms are too close
2023-01-03 13:13:33.975 DEBUG: There is a single atom floating around
2023-01-03 13:13:34.311 DEBUG: There is a single atom floating around
2023-01-03 13:13:34.617 DEBUG: Atoms are too close
2023-01-03 13:13:34.618 DEBUG: Atoms are too close
2023-01-03 13:13:41.533 INFO: Training rollout: return=-17.807 (14.7), episode length=5.4
2023-01-03 13:13:41.535 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 13:13:41.538 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-10368_train.pkl
2023-01-03 13:13:43.938 DEBUG: Taking gradient step
2023-01-03 13:13:46.259 DEBUG: Loss 0: {'policy_loss': 0.008561200242756391, 'entropy_loss': -0.05900509934872389, 'vf_loss': 0.20233696455423195, 'total_loss': -0.05044389910596749, 'approx_kl': 8.669060980182053e-08, 'clip_fraction': 0.0, 'grad_norm': 14.372847557067871}
2023-01-03 13:13:48.562 DEBUG: Taking gradient step
2023-01-03 13:13:51.050 DEBUG: Loss 1: {'policy_loss': -0.002652530291504744, 'entropy_loss': -0.060889326967298985, 'vf_loss': 0.20067177073479, 'total_loss': -0.06354185725880372, 'approx_kl': -0.002207408891990781, 'clip_fraction': 0.2682291716337204, 'grad_norm': 31.468353271484375}
2023-01-03 13:13:53.334 DEBUG: Taking gradient step
2023-01-03 13:13:55.548 DEBUG: Loss 2: {'policy_loss': 0.059050070156745696, 'entropy_loss': -0.06046045199036598, 'vf_loss': 0.20114392912364004, 'total_loss': -0.0014103818336202861, 'approx_kl': -0.008778818417340517, 'clip_fraction': 0.21875, 'grad_norm': 17.822322845458984}
2023-01-03 13:13:57.732 DEBUG: Taking gradient step
2023-01-03 13:13:59.951 DEBUG: Loss 3: {'policy_loss': 0.04121135423099381, 'entropy_loss': -0.061905345879495144, 'vf_loss': 0.20231316557737428, 'total_loss': -0.02069399164850133, 'approx_kl': -0.015699768904596567, 'clip_fraction': 0.2838541716337204, 'grad_norm': 18.095060348510742}
2023-01-03 13:14:02.147 DEBUG: Taking gradient step
2023-01-03 13:14:04.395 DEBUG: Loss 4: {'policy_loss': 0.02435745118176892, 'entropy_loss': -0.06275214534252882, 'vf_loss': 0.19887323682509067, 'total_loss': -0.0383946941607599, 'approx_kl': -0.02639114025805611, 'clip_fraction': 0.41796875, 'grad_norm': 27.272180557250977}
2023-01-03 13:14:06.660 DEBUG: Taking gradient step
2023-01-03 13:14:08.864 DEBUG: Loss 5: {'policy_loss': -0.0008905585189887405, 'entropy_loss': -0.05977030750364065, 'vf_loss': 0.1976887887250363, 'total_loss': -0.06066086602262939, 'approx_kl': -0.03682482149451971, 'clip_fraction': 0.3450520858168602, 'grad_norm': 26.545909881591797}
2023-01-03 13:14:11.131 DEBUG: Taking gradient step
2023-01-03 13:14:13.373 DEBUG: Loss 6: {'policy_loss': -0.030838053011084457, 'entropy_loss': -0.06044061668217182, 'vf_loss': 0.20285008540244154, 'total_loss': -0.09127866969325629, 'approx_kl': -0.037377200555056334, 'clip_fraction': 0.3463541716337204, 'grad_norm': 21.826826095581055}
2023-01-03 13:14:15.587 DEBUG: Taking gradient step
2023-01-03 13:14:17.927 DEBUG: Loss 7: {'policy_loss': 0.0005588406767219542, 'entropy_loss': -0.0614404221996665, 'vf_loss': 0.19660710960258648, 'total_loss': -0.060881581522944546, 'approx_kl': -0.05331280594691634, 'clip_fraction': 0.2434895858168602, 'grad_norm': 15.412337303161621}
2023-01-03 13:14:20.108 DEBUG: Taking gradient step
2023-01-03 13:14:22.316 DEBUG: Loss 8: {'policy_loss': 0.07352544396374933, 'entropy_loss': -0.0611649788916111, 'vf_loss': 0.19702746462635828, 'total_loss': 0.012360465072138234, 'approx_kl': -0.03856872580945492, 'clip_fraction': 0.41015625, 'grad_norm': 37.58021926879883}
2023-01-03 13:14:24.596 DEBUG: Taking gradient step
2023-01-03 13:14:26.933 DEBUG: Loss 9: {'policy_loss': 0.02242454020972498, 'entropy_loss': -0.058519430458545685, 'vf_loss': 0.1968050374178571, 'total_loss': -0.036094890248820705, 'approx_kl': -0.05497997812926769, 'clip_fraction': 0.3111979179084301, 'grad_norm': 22.905475616455078}
2023-01-03 13:14:29.159 DEBUG: Taking gradient step
2023-01-03 13:14:31.404 DEBUG: Loss 10: {'policy_loss': 0.022904541713774297, 'entropy_loss': -0.060883818194270134, 'vf_loss': 0.20362669287754068, 'total_loss': -0.03797927648049584, 'approx_kl': -0.06981067452579737, 'clip_fraction': 0.34765625, 'grad_norm': 20.07504653930664}
2023-01-03 13:14:33.740 DEBUG: Taking gradient step
2023-01-03 13:14:36.027 DEBUG: Loss 11: {'policy_loss': 0.04632999037323683, 'entropy_loss': -0.059775397181510925, 'vf_loss': 0.19780401721491528, 'total_loss': -0.013445406808274094, 'approx_kl': -0.06583317182958126, 'clip_fraction': 0.2955729216337204, 'grad_norm': 23.661609649658203}
2023-01-03 13:14:38.200 DEBUG: Taking gradient step
2023-01-03 13:14:40.441 DEBUG: Loss 12: {'policy_loss': 0.013708453297223517, 'entropy_loss': -0.062361874617636204, 'vf_loss': 0.19420790969000798, 'total_loss': -0.048653421320412685, 'approx_kl': -0.054089630022645, 'clip_fraction': 0.3385416716337204, 'grad_norm': 17.762121200561523}
2023-01-03 13:14:42.610 DEBUG: Taking gradient step
2023-01-03 13:14:44.972 DEBUG: Loss 13: {'policy_loss': -0.0329897583982375, 'entropy_loss': -0.05963325034826994, 'vf_loss': 0.19653776680663207, 'total_loss': -0.09262300874650745, 'approx_kl': -0.048023661016486585, 'clip_fraction': 0.3046875, 'grad_norm': 13.629191398620605}
2023-01-03 13:14:47.176 DEBUG: Taking gradient step
2023-01-03 13:14:49.388 DEBUG: Loss 14: {'policy_loss': 0.056873540234949456, 'entropy_loss': -0.061405093409121037, 'vf_loss': 0.1920473322771542, 'total_loss': -0.004531553174171581, 'approx_kl': -0.048043725080788136, 'clip_fraction': 0.3880208358168602, 'grad_norm': 20.86323356628418}
2023-01-03 13:14:49.389 INFO: Optimization: policy loss=0.057, vf loss=0.192, entropy loss=-0.061, total loss=-0.005, num steps=15
2023-01-03 13:14:49.391 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 13:14:50.936 DEBUG: There is a single atom floating around
2023-01-03 13:14:50.939 INFO: Evaluation rollout: return=-29.706 (0.0), episode length=6.0
2023-01-03 13:14:50.940 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 13:14:50.943 INFO: Iteration: 49/137, steps: 10584
2023-01-03 13:15:01.392 DEBUG: Atoms are too close
2023-01-03 13:15:05.601 DEBUG: There is a single atom floating around
2023-01-03 13:15:06.528 DEBUG: There is a single atom floating around
2023-01-03 13:15:09.462 DEBUG: There is a single atom floating around
2023-01-03 13:15:09.462 DEBUG: Atoms are too close
2023-01-03 13:15:09.628 DEBUG: There is a single atom floating around
2023-01-03 13:15:09.629 DEBUG: Atoms are too close
2023-01-03 13:15:09.629 DEBUG: There is a single atom floating around
2023-01-03 13:15:16.623 DEBUG: Atoms are too close
2023-01-03 13:15:21.921 DEBUG: There is a single atom floating around
2023-01-03 13:15:22.236 DEBUG: There is a single atom floating around
2023-01-03 13:15:22.237 DEBUG: Atoms are too close
2023-01-03 13:15:22.326 DEBUG: Atoms are too close
2023-01-03 13:15:22.326 DEBUG: There is a single atom floating around
2023-01-03 13:15:22.632 DEBUG: There is a single atom floating around
2023-01-03 13:15:23.606 DEBUG: There is a single atom floating around
2023-01-03 13:15:25.739 DEBUG: There is a single atom floating around
2023-01-03 13:15:26.212 DEBUG: There is a single atom floating around
2023-01-03 13:15:27.561 DEBUG: Atoms are too close
2023-01-03 13:15:33.670 DEBUG: Atoms are too close
2023-01-03 13:15:35.881 DEBUG: There is a single atom floating around
2023-01-03 13:15:36.195 DEBUG: Atoms are too close
2023-01-03 13:15:37.419 DEBUG: Atoms are too close
2023-01-03 13:15:37.421 DEBUG: Atoms are too close
2023-01-03 13:15:39.820 DEBUG: Atoms are too close
2023-01-03 13:15:39.821 DEBUG: Atoms are too close
2023-01-03 13:15:40.469 DEBUG: Atoms are too close
2023-01-03 13:15:45.241 INFO: Training rollout: return=-21.405 (13.3), episode length=5.3
2023-01-03 13:15:45.243 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 13:15:45.246 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-10584_train.pkl
2023-01-03 13:15:47.560 DEBUG: Taking gradient step
2023-01-03 13:15:49.774 DEBUG: Loss 0: {'policy_loss': 0.0034083292674972525, 'entropy_loss': -0.059597612358629704, 'vf_loss': 0.18239535134798124, 'total_loss': -0.056189283091132455, 'approx_kl': 6.977158273357986e-08, 'clip_fraction': 0.0, 'grad_norm': 19.123851776123047}
2023-01-03 13:15:51.979 DEBUG: Taking gradient step
2023-01-03 13:15:54.204 DEBUG: Loss 1: {'policy_loss': 0.040292785477802226, 'entropy_loss': -0.06135339569300413, 'vf_loss': 0.18647129410899432, 'total_loss': -0.021060610215201912, 'approx_kl': -0.01196716958656907, 'clip_fraction': 0.1484375, 'grad_norm': 19.588911056518555}
2023-01-03 13:15:56.376 DEBUG: Taking gradient step
2023-01-03 13:15:58.617 DEBUG: Loss 2: {'policy_loss': 0.07580127546700893, 'entropy_loss': -0.05884711816906929, 'vf_loss': 0.19074565544872168, 'total_loss': 0.016954157297939643, 'approx_kl': -0.026767156552523375, 'clip_fraction': 0.3697916716337204, 'grad_norm': 38.01552200317383}
2023-01-03 13:16:00.849 DEBUG: Taking gradient step
2023-01-03 13:16:03.104 DEBUG: Loss 3: {'policy_loss': 0.13614732012024575, 'entropy_loss': -0.05693691875785589, 'vf_loss': 0.18228512200241098, 'total_loss': 0.07921040136238985, 'approx_kl': -0.036161764757707715, 'clip_fraction': 0.4270833358168602, 'grad_norm': 23.56482696533203}
2023-01-03 13:16:05.266 DEBUG: Taking gradient step
2023-01-03 13:16:07.463 DEBUG: Loss 4: {'policy_loss': 0.11416072616859922, 'entropy_loss': -0.055996038019657135, 'vf_loss': 0.18071696079845814, 'total_loss': 0.0581646881489421, 'approx_kl': -0.02397927874699235, 'clip_fraction': 0.4947916716337204, 'grad_norm': 21.569278717041016}
2023-01-03 13:16:09.617 DEBUG: Taking gradient step
2023-01-03 13:16:11.824 DEBUG: Loss 5: {'policy_loss': 0.130675119679742, 'entropy_loss': -0.05840257368981838, 'vf_loss': 0.17781776119634013, 'total_loss': 0.07227254598992361, 'approx_kl': -0.023572337813675404, 'clip_fraction': 0.4440104216337204, 'grad_norm': 39.149654388427734}
2023-01-03 13:16:14.026 DEBUG: Taking gradient step
2023-01-03 13:16:16.227 DEBUG: Loss 6: {'policy_loss': 0.03129795999737521, 'entropy_loss': -0.05837753228843212, 'vf_loss': 0.18274489305002348, 'total_loss': -0.02707957229105691, 'approx_kl': -0.03864228120073676, 'clip_fraction': 0.2643229169771075, 'grad_norm': 34.301944732666016}
2023-01-03 13:16:18.464 DEBUG: Taking gradient step
2023-01-03 13:16:20.910 DEBUG: Loss 7: {'policy_loss': 0.055696260667362454, 'entropy_loss': -0.05881813820451498, 'vf_loss': 0.17846670374562676, 'total_loss': -0.003121877537152526, 'approx_kl': -0.05809714924544096, 'clip_fraction': 0.3046875, 'grad_norm': 33.60585403442383}
2023-01-03 13:16:23.076 DEBUG: Taking gradient step
2023-01-03 13:16:25.358 DEBUG: Loss 8: {'policy_loss': 0.07564672654164944, 'entropy_loss': -0.0587392495945096, 'vf_loss': 0.17593697818164497, 'total_loss': 0.01690747694713984, 'approx_kl': -0.0761162368580699, 'clip_fraction': 0.33984375, 'grad_norm': 36.494815826416016}
2023-01-03 13:16:27.511 DEBUG: Taking gradient step
2023-01-03 13:16:29.710 DEBUG: Loss 9: {'policy_loss': 0.12019012447577507, 'entropy_loss': -0.05988385621458292, 'vf_loss': 0.19094819470439559, 'total_loss': 0.06030626826119214, 'approx_kl': -0.08775368984788656, 'clip_fraction': 0.3138020858168602, 'grad_norm': 43.86503219604492}
2023-01-03 13:16:31.857 DEBUG: Taking gradient step
2023-01-03 13:16:34.081 DEBUG: Loss 10: {'policy_loss': 0.18011326283873746, 'entropy_loss': -0.05826020799577236, 'vf_loss': 0.1764687773038475, 'total_loss': 0.1218530548429651, 'approx_kl': -0.07347060041502118, 'clip_fraction': 0.4036458358168602, 'grad_norm': 26.493553161621094}
2023-01-03 13:16:36.198 DEBUG: Taking gradient step
2023-01-03 13:16:38.445 DEBUG: Loss 11: {'policy_loss': 0.052667530030519064, 'entropy_loss': -0.057091912254691124, 'vf_loss': 0.19363703359648238, 'total_loss': -0.00442438222417206, 'approx_kl': -0.0795839645434171, 'clip_fraction': 0.4192708358168602, 'grad_norm': 30.44167709350586}
2023-01-03 13:16:40.709 DEBUG: Taking gradient step
2023-01-03 13:16:42.922 DEBUG: Loss 12: {'policy_loss': 0.20188227911154097, 'entropy_loss': -0.0602542906999588, 'vf_loss': 0.17394145068479142, 'total_loss': 0.14162798841158217, 'approx_kl': -0.09154483070597053, 'clip_fraction': 0.48046875, 'grad_norm': 47.975189208984375}
2023-01-03 13:16:45.095 DEBUG: Taking gradient step
2023-01-03 13:16:47.290 DEBUG: Loss 13: {'policy_loss': 0.15699150633738998, 'entropy_loss': -0.05694194138050079, 'vf_loss': 0.17372637062198137, 'total_loss': 0.1000495649568892, 'approx_kl': -0.08751794788986444, 'clip_fraction': 0.3541666716337204, 'grad_norm': 41.136444091796875}
2023-01-03 13:16:49.443 DEBUG: Taking gradient step
2023-01-03 13:16:51.632 DEBUG: Loss 14: {'policy_loss': 0.13534249801334747, 'entropy_loss': -0.05903958901762962, 'vf_loss': 0.17915986762347977, 'total_loss': 0.07630290899571786, 'approx_kl': -0.07339639822021127, 'clip_fraction': 0.4166666716337204, 'grad_norm': 17.885448455810547}
2023-01-03 13:16:51.632 INFO: Optimization: policy loss=0.135, vf loss=0.179, entropy loss=-0.059, total loss=0.076, num steps=15
2023-01-03 13:16:51.634 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 13:16:52.896 DEBUG: Atoms are too close
2023-01-03 13:16:52.899 INFO: Evaluation rollout: return=-29.389 (0.0), episode length=5.0
2023-01-03 13:16:52.899 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 13:16:52.902 INFO: Iteration: 50/137, steps: 10800
2023-01-03 13:17:05.107 DEBUG: Atoms are too close
2023-01-03 13:17:07.419 DEBUG: Atoms are too close
2023-01-03 13:17:07.755 DEBUG: There is a single atom floating around
2023-01-03 13:17:08.253 DEBUG: There is a single atom floating around
2023-01-03 13:17:08.254 DEBUG: Atoms are too close
2023-01-03 13:17:08.570 DEBUG: Atoms are too close
2023-01-03 13:17:09.778 DEBUG: Atoms are too close
2023-01-03 13:17:09.946 DEBUG: There is a single atom floating around
2023-01-03 13:17:18.921 DEBUG: Atoms are too close
2023-01-03 13:17:19.883 DEBUG: Atoms are too close
2023-01-03 13:17:20.186 DEBUG: Atoms are too close
2023-01-03 13:17:20.518 DEBUG: Atoms are too close
2023-01-03 13:17:20.603 DEBUG: There is a single atom floating around
2023-01-03 13:17:21.735 DEBUG: Atoms are too close
2023-01-03 13:17:22.187 DEBUG: There is a single atom floating around
2023-01-03 13:17:23.092 DEBUG: There is a single atom floating around
2023-01-03 13:17:23.722 DEBUG: Atoms are too close
2023-01-03 13:17:24.974 DEBUG: Atoms are too close
2023-01-03 13:17:26.946 DEBUG: There is a single atom floating around
2023-01-03 13:17:33.620 DEBUG: Atoms are too close
2023-01-03 13:17:35.242 DEBUG: Atoms are too close
2023-01-03 13:17:36.639 DEBUG: There is a single atom floating around
2023-01-03 13:17:37.480 DEBUG: There is a single atom floating around
2023-01-03 13:17:38.342 DEBUG: There is a single atom floating around
2023-01-03 13:17:38.344 DEBUG: Atoms are too close
2023-01-03 13:17:42.448 DEBUG: Atoms are too close
2023-01-03 13:17:47.650 INFO: Training rollout: return=-21.177 (13.5), episode length=5.2
2023-01-03 13:17:47.652 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 13:17:47.655 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-10800_train.pkl
2023-01-03 13:17:49.831 DEBUG: Taking gradient step
2023-01-03 13:17:52.029 DEBUG: Loss 0: {'policy_loss': -0.006132126996879143, 'entropy_loss': -0.05869070813059807, 'vf_loss': 0.16181348466389456, 'total_loss': -0.06482283512747722, 'approx_kl': 8.560406605795379e-08, 'clip_fraction': 0.0, 'grad_norm': 14.585896492004395}
2023-01-03 13:17:54.175 DEBUG: Taking gradient step
2023-01-03 13:17:56.524 DEBUG: Loss 1: {'policy_loss': 0.06218074160610117, 'entropy_loss': -0.05660505127161741, 'vf_loss': 0.1563450277603534, 'total_loss': 0.005575690334483754, 'approx_kl': -0.021895543904975057, 'clip_fraction': 0.19921875, 'grad_norm': 17.000953674316406}
2023-01-03 13:17:58.782 DEBUG: Taking gradient step
2023-01-03 13:18:00.973 DEBUG: Loss 2: {'policy_loss': 0.009936584443655541, 'entropy_loss': -0.05502758827060461, 'vf_loss': 0.15947465119433105, 'total_loss': -0.04509100382694907, 'approx_kl': -0.05171663826331496, 'clip_fraction': 0.3424479216337204, 'grad_norm': 27.593706130981445}
2023-01-03 13:18:03.103 DEBUG: Taking gradient step
2023-01-03 13:18:05.315 DEBUG: Loss 3: {'policy_loss': 0.07275534248448526, 'entropy_loss': -0.05574106425046921, 'vf_loss': 0.15132405840725366, 'total_loss': 0.017014278234016057, 'approx_kl': -0.040262963622808456, 'clip_fraction': 0.3763020858168602, 'grad_norm': 19.526180267333984}
2023-01-03 13:18:07.473 DEBUG: Taking gradient step
2023-01-03 13:18:09.675 DEBUG: Loss 4: {'policy_loss': 0.0664817227075574, 'entropy_loss': -0.05409249383956194, 'vf_loss': 0.1568659132639482, 'total_loss': 0.012389228867995462, 'approx_kl': -0.07862601918168366, 'clip_fraction': 0.3515625, 'grad_norm': 15.402935028076172}
2023-01-03 13:18:11.865 DEBUG: Taking gradient step
2023-01-03 13:18:14.040 DEBUG: Loss 5: {'policy_loss': 0.09171814614035748, 'entropy_loss': -0.05376663710922003, 'vf_loss': 0.15735776950268648, 'total_loss': 0.03795150903113744, 'approx_kl': -0.06724520679563284, 'clip_fraction': 0.46484375, 'grad_norm': 26.388504028320312}
2023-01-03 13:18:16.267 DEBUG: Taking gradient step
2023-01-03 13:18:18.456 DEBUG: Loss 6: {'policy_loss': 0.05456133367486689, 'entropy_loss': -0.05486640427261591, 'vf_loss': 0.16110104421798968, 'total_loss': -0.00030507059774902145, 'approx_kl': -0.06493319571018219, 'clip_fraction': 0.4283854216337204, 'grad_norm': 13.619911193847656}
2023-01-03 13:18:20.592 DEBUG: Taking gradient step
2023-01-03 13:18:22.961 DEBUG: Loss 7: {'policy_loss': 0.09842291064320595, 'entropy_loss': -0.053796255961060524, 'vf_loss': 0.14663996112531946, 'total_loss': 0.044626654682145425, 'approx_kl': -0.05984405009075999, 'clip_fraction': 0.4309895858168602, 'grad_norm': 14.567570686340332}
2023-01-03 13:18:25.127 DEBUG: Taking gradient step
2023-01-03 13:18:27.309 DEBUG: Loss 8: {'policy_loss': 0.09971189171934361, 'entropy_loss': -0.053670890629291534, 'vf_loss': 0.14738005865144121, 'total_loss': 0.04604100109005207, 'approx_kl': -0.09571743104606867, 'clip_fraction': 0.38671875, 'grad_norm': 21.220205307006836}
2023-01-03 13:18:29.439 DEBUG: Taking gradient step
2023-01-03 13:18:31.633 DEBUG: Loss 9: {'policy_loss': 0.07967910000976194, 'entropy_loss': -0.052954286336898804, 'vf_loss': 0.1556354270458006, 'total_loss': 0.026724813672863147, 'approx_kl': -0.061037815758027136, 'clip_fraction': 0.4192708358168602, 'grad_norm': 21.197473526000977}
2023-01-03 13:18:33.763 DEBUG: Taking gradient step
2023-01-03 13:18:35.975 DEBUG: Loss 10: {'policy_loss': 0.03328363906608639, 'entropy_loss': -0.05566816683858633, 'vf_loss': 0.15868879531668656, 'total_loss': -0.02238452777249994, 'approx_kl': -0.04894087091088295, 'clip_fraction': 0.421875, 'grad_norm': 12.700206756591797}
2023-01-03 13:18:38.110 DEBUG: Taking gradient step
2023-01-03 13:18:40.497 DEBUG: Loss 11: {'policy_loss': 0.03509770344935679, 'entropy_loss': -0.05674981418997049, 'vf_loss': 0.1538999495415438, 'total_loss': -0.021652110740613708, 'approx_kl': -0.07408575620502234, 'clip_fraction': 0.41796875, 'grad_norm': 18.969263076782227}
2023-01-03 13:18:42.692 DEBUG: Taking gradient step
2023-01-03 13:18:44.904 DEBUG: Loss 12: {'policy_loss': 0.02462875044828998, 'entropy_loss': -0.0554382698610425, 'vf_loss': 0.15304045242380426, 'total_loss': -0.03080951941275252, 'approx_kl': -0.0874775629490614, 'clip_fraction': 0.34765625, 'grad_norm': 10.385159492492676}
2023-01-03 13:18:47.055 DEBUG: Taking gradient step
2023-01-03 13:18:49.236 DEBUG: Loss 13: {'policy_loss': 0.06589041894753027, 'entropy_loss': -0.057645417749881744, 'vf_loss': 0.14819101906641008, 'total_loss': 0.008245001197648528, 'approx_kl': -0.08203166956081986, 'clip_fraction': 0.4440104216337204, 'grad_norm': 15.052311897277832}
2023-01-03 13:18:51.365 DEBUG: Taking gradient step
2023-01-03 13:18:53.534 DEBUG: Loss 14: {'policy_loss': 0.13024820740723378, 'entropy_loss': -0.05839882045984268, 'vf_loss': 0.1463483202036098, 'total_loss': 0.07184938694739111, 'approx_kl': -0.09504950419068336, 'clip_fraction': 0.3997395858168602, 'grad_norm': 21.19288444519043}
2023-01-03 13:18:53.535 INFO: Optimization: policy loss=0.130, vf loss=0.146, entropy loss=-0.058, total loss=0.072, num steps=15
2023-01-03 13:18:53.536 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 13:18:54.810 DEBUG: Atoms are too close
2023-01-03 13:18:54.812 INFO: Evaluation rollout: return=-29.375 (0.0), episode length=5.0
2023-01-03 13:18:54.813 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 13:18:54.815 DEBUG: Deleting old model: runs/CH3NO_dna/models/CH3NO_dna_run-1_steps-8856.model
2023-01-03 13:18:54.820 DEBUG: Saving model: runs/CH3NO_dna/models/CH3NO_dna_run-1_steps-11016.model
2023-01-03 13:18:54.871 INFO: Iteration: 51/137, steps: 11016
2023-01-03 13:19:06.712 DEBUG: Atoms are too close
2023-01-03 13:19:07.348 DEBUG: Atoms are too close
2023-01-03 13:19:07.349 DEBUG: Atoms are too close
2023-01-03 13:19:08.083 DEBUG: There is a single atom floating around
2023-01-03 13:19:08.083 DEBUG: Atoms are too close
2023-01-03 13:19:08.397 DEBUG: There is a single atom floating around
2023-01-03 13:19:08.899 DEBUG: There is a single atom floating around
2023-01-03 13:19:08.900 DEBUG: Atoms are too close
2023-01-03 13:19:10.317 DEBUG: There is a single atom floating around
2023-01-03 13:19:10.455 DEBUG: Atoms are too close
2023-01-03 13:19:19.896 DEBUG: There is a single atom floating around
2023-01-03 13:19:20.842 DEBUG: There is a single atom floating around
2023-01-03 13:19:22.790 DEBUG: Atoms are too close
2023-01-03 13:19:23.598 DEBUG: There is a single atom floating around
2023-01-03 13:19:25.093 DEBUG: Atoms are too close
2023-01-03 13:19:26.301 DEBUG: Atoms are too close
2023-01-03 13:19:27.058 DEBUG: There is a single atom floating around
2023-01-03 13:19:27.637 DEBUG: There is a single atom floating around
2023-01-03 13:19:31.317 DEBUG: Atoms are too close
2023-01-03 13:19:34.435 DEBUG: There is a single atom floating around
2023-01-03 13:19:35.547 DEBUG: Atoms are too close
2023-01-03 13:19:36.198 DEBUG: There is a single atom floating around
2023-01-03 13:19:39.595 DEBUG: Atoms are too close
2023-01-03 13:19:39.596 DEBUG: There is a single atom floating around
2023-01-03 13:19:39.680 DEBUG: Atoms are too close
2023-01-03 13:19:41.591 DEBUG: There is a single atom floating around
2023-01-03 13:19:43.438 DEBUG: There is a single atom floating around
2023-01-03 13:19:43.439 DEBUG: There is a single atom floating around
2023-01-03 13:19:44.049 DEBUG: There is a single atom floating around
2023-01-03 13:19:48.448 INFO: Training rollout: return=-23.618 (11.9), episode length=5.1
2023-01-03 13:19:48.450 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 13:19:48.452 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-11016_train.pkl
2023-01-03 13:19:50.603 DEBUG: Taking gradient step
2023-01-03 13:19:52.771 DEBUG: Loss 0: {'policy_loss': -0.002854478187408714, 'entropy_loss': -0.055031437426805496, 'vf_loss': 0.1287080080243213, 'total_loss': -0.05788591561421421, 'approx_kl': -7.388492484494691e-08, 'clip_fraction': 0.0, 'grad_norm': 19.06641960144043}
2023-01-03 13:19:54.938 DEBUG: Taking gradient step
2023-01-03 13:19:57.119 DEBUG: Loss 1: {'policy_loss': 0.002418192408584041, 'entropy_loss': -0.05550485569983721, 'vf_loss': 0.13612280285095565, 'total_loss': -0.05308666329125317, 'approx_kl': -0.005908563267439604, 'clip_fraction': 0.1783854179084301, 'grad_norm': 33.8006477355957}
2023-01-03 13:19:59.244 DEBUG: Taking gradient step
2023-01-03 13:20:01.449 DEBUG: Loss 2: {'policy_loss': 0.0070555152030945326, 'entropy_loss': -0.055489408783614635, 'vf_loss': 0.1253106380740828, 'total_loss': -0.0484338935805201, 'approx_kl': -0.032229633536189795, 'clip_fraction': 0.27734375, 'grad_norm': 22.02046775817871}
2023-01-03 13:20:03.589 DEBUG: Taking gradient step
2023-01-03 13:20:05.869 DEBUG: Loss 3: {'policy_loss': 0.006643439078474401, 'entropy_loss': -0.05469669587910175, 'vf_loss': 0.1328353311647257, 'total_loss': -0.04805325680062735, 'approx_kl': -0.048929057316854596, 'clip_fraction': 0.2747395858168602, 'grad_norm': 18.837665557861328}
2023-01-03 13:20:08.039 DEBUG: Taking gradient step
2023-01-03 13:20:10.213 DEBUG: Loss 4: {'policy_loss': 0.015801512990784205, 'entropy_loss': -0.05586337298154831, 'vf_loss': 0.13199342053170302, 'total_loss': -0.0400618599907641, 'approx_kl': -0.03385611064732075, 'clip_fraction': 0.3723958358168602, 'grad_norm': 19.706851959228516}
2023-01-03 13:20:12.423 DEBUG: Taking gradient step
2023-01-03 13:20:14.627 DEBUG: Loss 5: {'policy_loss': 0.05944304769068205, 'entropy_loss': -0.057717409916222095, 'vf_loss': 0.12148802084933763, 'total_loss': 0.0017256377744599635, 'approx_kl': -0.011870433576405048, 'clip_fraction': 0.4388020932674408, 'grad_norm': 17.853456497192383}
2023-01-03 13:20:16.753 DEBUG: Taking gradient step
2023-01-03 13:20:18.932 DEBUG: Loss 6: {'policy_loss': 0.03968676432578186, 'entropy_loss': -0.057318005710840225, 'vf_loss': 0.1257612140873096, 'total_loss': -0.017631241385058363, 'approx_kl': -0.021504960022866726, 'clip_fraction': 0.4270833358168602, 'grad_norm': 21.726778030395508}
2023-01-03 13:20:21.063 DEBUG: Taking gradient step
2023-01-03 13:20:23.533 DEBUG: Loss 7: {'policy_loss': 0.0028665930431332684, 'entropy_loss': -0.055575369857251644, 'vf_loss': 0.12633159464420532, 'total_loss': -0.05270877681411837, 'approx_kl': -0.04553397838026285, 'clip_fraction': 0.40234375, 'grad_norm': 22.43069839477539}
2023-01-03 13:20:25.748 DEBUG: Taking gradient step
2023-01-03 13:20:27.942 DEBUG: Loss 8: {'policy_loss': 0.026720962780796543, 'entropy_loss': -0.05650508962571621, 'vf_loss': 0.12219499039678601, 'total_loss': -0.029784126844919667, 'approx_kl': -0.03914360608905554, 'clip_fraction': 0.4205729216337204, 'grad_norm': 29.552724838256836}
2023-01-03 13:20:30.100 DEBUG: Taking gradient step
2023-01-03 13:20:32.628 DEBUG: Loss 9: {'policy_loss': 0.016969304716876178, 'entropy_loss': -0.056548441760241985, 'vf_loss': 0.1248360023961875, 'total_loss': -0.03957913704336581, 'approx_kl': -0.054174625780433416, 'clip_fraction': 0.2916666716337204, 'grad_norm': 18.3388671875}
2023-01-03 13:20:34.763 DEBUG: Taking gradient step
2023-01-03 13:20:36.916 DEBUG: Loss 10: {'policy_loss': -0.0016971706898013424, 'entropy_loss': -0.05666752904653549, 'vf_loss': 0.12807423490525346, 'total_loss': -0.05836469973633683, 'approx_kl': -0.07562327943742275, 'clip_fraction': 0.4140625, 'grad_norm': 21.06993865966797}
2023-01-03 13:20:39.081 DEBUG: Taking gradient step
2023-01-03 13:20:41.369 DEBUG: Loss 11: {'policy_loss': 0.04800061662841423, 'entropy_loss': -0.05759299639612436, 'vf_loss': 0.12501499753703854, 'total_loss': -0.009592379767710133, 'approx_kl': -0.05873036244884133, 'clip_fraction': 0.5182291716337204, 'grad_norm': 18.886625289916992}
2023-01-03 13:20:43.495 DEBUG: Taking gradient step
2023-01-03 13:20:45.739 DEBUG: Loss 12: {'policy_loss': 0.028904266986326463, 'entropy_loss': -0.055439879186451435, 'vf_loss': 0.12532101044988161, 'total_loss': -0.026535612200124972, 'approx_kl': -0.0631624108646065, 'clip_fraction': 0.4244791716337204, 'grad_norm': 15.32613468170166}
2023-01-03 13:20:48.003 DEBUG: Taking gradient step
2023-01-03 13:20:50.249 DEBUG: Loss 13: {'policy_loss': 0.011974034392010321, 'entropy_loss': -0.05445369891822338, 'vf_loss': 0.12305732983865042, 'total_loss': -0.04247966452621305, 'approx_kl': -0.07111714221537113, 'clip_fraction': 0.3736979216337204, 'grad_norm': 22.935827255249023}
2023-01-03 13:20:52.654 DEBUG: Taking gradient step
2023-01-03 13:20:54.838 DEBUG: Loss 14: {'policy_loss': 0.07919196323449579, 'entropy_loss': -0.05627892352640629, 'vf_loss': 0.1209368507900121, 'total_loss': 0.022913039708089507, 'approx_kl': -0.08071467466652393, 'clip_fraction': 0.41015625, 'grad_norm': 25.149646759033203}
2023-01-03 13:20:54.839 INFO: Optimization: policy loss=0.079, vf loss=0.121, entropy loss=-0.056, total loss=0.023, num steps=15
2023-01-03 13:20:54.840 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 13:20:56.215 DEBUG: Atoms are too close
2023-01-03 13:20:56.217 INFO: Evaluation rollout: return=-29.356 (0.0), episode length=5.0
2023-01-03 13:20:56.218 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 13:20:56.222 INFO: Iteration: 52/137, steps: 11232
2023-01-03 13:21:07.792 DEBUG: Atoms are too close
2023-01-03 13:21:07.794 DEBUG: Atoms are too close
2023-01-03 13:21:09.943 DEBUG: Atoms are too close
2023-01-03 13:21:14.263 DEBUG: There is a single atom floating around
2023-01-03 13:21:14.956 DEBUG: There is a single atom floating around
2023-01-03 13:21:15.293 DEBUG: There is a single atom floating around
2023-01-03 13:21:20.552 DEBUG: Atoms are too close
2023-01-03 13:21:23.978 DEBUG: There is a single atom floating around
2023-01-03 13:21:26.183 DEBUG: Atoms are too close
2023-01-03 13:21:26.875 DEBUG: Atoms are too close
2023-01-03 13:21:27.354 DEBUG: Atoms are too close
2023-01-03 13:21:28.010 DEBUG: There is a single atom floating around
2023-01-03 13:21:29.308 DEBUG: Atoms are too close
2023-01-03 13:21:30.325 DEBUG: Atoms are too close
2023-01-03 13:21:30.815 DEBUG: Atoms are too close
2023-01-03 13:21:32.713 DEBUG: Atoms are too close
2023-01-03 13:21:33.206 DEBUG: There is a single atom floating around
2023-01-03 13:21:35.384 DEBUG: Atoms are too close
2023-01-03 13:21:43.727 DEBUG: Atoms are too close
2023-01-03 13:21:44.055 DEBUG: There is a single atom floating around
2023-01-03 13:21:44.840 DEBUG: Atoms are too close
2023-01-03 13:21:45.202 DEBUG: Atoms are too close
2023-01-03 13:21:46.236 DEBUG: There is a single atom floating around
2023-01-03 13:21:47.777 DEBUG: Atoms are too close
2023-01-03 13:21:48.419 DEBUG: Atoms are too close
2023-01-03 13:21:48.953 DEBUG: There is a single atom floating around
2023-01-03 13:21:49.626 DEBUG: There is a single atom floating around
2023-01-03 13:21:52.980 INFO: Training rollout: return=-21.308 (13.4), episode length=5.2
2023-01-03 13:21:52.982 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 13:21:52.986 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-11232_train.pkl
2023-01-03 13:21:55.170 DEBUG: Taking gradient step
2023-01-03 13:21:57.541 DEBUG: Loss 0: {'policy_loss': -0.07036911013877464, 'entropy_loss': -0.05963736027479172, 'vf_loss': 0.17248645811170843, 'total_loss': -0.13000647041356636, 'approx_kl': -6.868503987789154e-08, 'clip_fraction': 0.0, 'grad_norm': 20.09295082092285}
2023-01-03 13:21:59.838 DEBUG: Taking gradient step
2023-01-03 13:22:02.046 DEBUG: Loss 1: {'policy_loss': 0.03500575824292623, 'entropy_loss': -0.058694819919764996, 'vf_loss': 0.16194540467016655, 'total_loss': -0.023689061676838763, 'approx_kl': -0.009576690848916769, 'clip_fraction': 0.18489583395421505, 'grad_norm': 22.30393409729004}
2023-01-03 13:22:04.227 DEBUG: Taking gradient step
2023-01-03 13:22:06.427 DEBUG: Loss 2: {'policy_loss': 0.033123992773989766, 'entropy_loss': -0.05729142855852842, 'vf_loss': 0.17214342588459336, 'total_loss': -0.024167435784538654, 'approx_kl': -0.028829920571297407, 'clip_fraction': 0.3229166716337204, 'grad_norm': 32.44565963745117}
2023-01-03 13:22:08.635 DEBUG: Taking gradient step
2023-01-03 13:22:10.884 DEBUG: Loss 3: {'policy_loss': 0.065150276754608, 'entropy_loss': -0.05677596665918827, 'vf_loss': 0.16287617800122484, 'total_loss': 0.008374310095419724, 'approx_kl': -0.028030171990394592, 'clip_fraction': 0.3541666716337204, 'grad_norm': 23.84479522705078}
2023-01-03 13:22:13.178 DEBUG: Taking gradient step
2023-01-03 13:22:15.399 DEBUG: Loss 4: {'policy_loss': 0.08781240421757444, 'entropy_loss': -0.05680640693753958, 'vf_loss': 0.15519760886512068, 'total_loss': 0.031005997280034867, 'approx_kl': -0.050611525774002075, 'clip_fraction': 0.44921875, 'grad_norm': 30.32200813293457}
2023-01-03 13:22:17.731 DEBUG: Taking gradient step
2023-01-03 13:22:19.951 DEBUG: Loss 5: {'policy_loss': 0.05062602607121018, 'entropy_loss': -0.05561414919793606, 'vf_loss': 0.1626448793207828, 'total_loss': -0.004988123126725877, 'approx_kl': -0.04714478272944689, 'clip_fraction': 0.4557291716337204, 'grad_norm': 23.243608474731445}
2023-01-03 13:22:22.142 DEBUG: Taking gradient step
2023-01-03 13:22:24.328 DEBUG: Loss 6: {'policy_loss': 0.05254357286077275, 'entropy_loss': -0.052513983100652695, 'vf_loss': 0.16577538712683093, 'total_loss': 2.958976012005371e-05, 'approx_kl': -0.029776987619698048, 'clip_fraction': 0.4674479216337204, 'grad_norm': 23.591039657592773}
2023-01-03 13:22:26.488 DEBUG: Taking gradient step
2023-01-03 13:22:28.701 DEBUG: Loss 7: {'policy_loss': 0.09720628484047168, 'entropy_loss': -0.05392674636095762, 'vf_loss': 0.1651775749826983, 'total_loss': 0.04327953847951406, 'approx_kl': -0.048950908705592155, 'clip_fraction': 0.4453125, 'grad_norm': 23.457246780395508}
2023-01-03 13:22:30.875 DEBUG: Taking gradient step
2023-01-03 13:22:33.072 DEBUG: Loss 8: {'policy_loss': 0.023061586195131586, 'entropy_loss': -0.053837960585951805, 'vf_loss': 0.16885449225404198, 'total_loss': -0.03077637439082022, 'approx_kl': -0.042897457955405116, 'clip_fraction': 0.3828125, 'grad_norm': 28.08627700805664}
2023-01-03 13:22:35.217 DEBUG: Taking gradient step
2023-01-03 13:22:37.445 DEBUG: Loss 9: {'policy_loss': 0.05689191614712996, 'entropy_loss': -0.05474501382559538, 'vf_loss': 0.16769573616250924, 'total_loss': 0.0021469023215345863, 'approx_kl': -0.044732335954904556, 'clip_fraction': 0.4010416716337204, 'grad_norm': 20.020715713500977}
2023-01-03 13:22:39.601 DEBUG: Taking gradient step
2023-01-03 13:22:41.796 DEBUG: Loss 10: {'policy_loss': 0.02764904497643759, 'entropy_loss': -0.05432435590773821, 'vf_loss': 0.16542461367877315, 'total_loss': -0.026675310931300607, 'approx_kl': -0.058742353692650795, 'clip_fraction': 0.3880208358168602, 'grad_norm': 16.27127456665039}
2023-01-03 13:22:43.956 DEBUG: Taking gradient step
2023-01-03 13:22:46.152 DEBUG: Loss 11: {'policy_loss': 0.0951270448090471, 'entropy_loss': -0.05556468013674021, 'vf_loss': 0.15182851537804976, 'total_loss': 0.03956236467230689, 'approx_kl': -0.07532855402678251, 'clip_fraction': 0.3671875, 'grad_norm': 24.07345962524414}
2023-01-03 13:22:48.335 DEBUG: Taking gradient step
2023-01-03 13:22:50.609 DEBUG: Loss 12: {'policy_loss': 0.13347754094653505, 'entropy_loss': -0.05695709213614464, 'vf_loss': 0.15404549485116617, 'total_loss': 0.0765204488103904, 'approx_kl': -0.065156658180058, 'clip_fraction': 0.4309895858168602, 'grad_norm': 16.99017333984375}
2023-01-03 13:22:52.824 DEBUG: Taking gradient step
2023-01-03 13:22:55.460 DEBUG: Loss 13: {'policy_loss': 0.009339747898050879, 'entropy_loss': -0.055956119671463966, 'vf_loss': 0.1654311851169573, 'total_loss': -0.04661637177341309, 'approx_kl': -0.05727272923104465, 'clip_fraction': 0.3307291716337204, 'grad_norm': 18.91716194152832}
2023-01-03 13:22:57.688 DEBUG: Taking gradient step
2023-01-03 13:22:59.908 DEBUG: Loss 14: {'policy_loss': 0.07493606803299643, 'entropy_loss': -0.05834862682968378, 'vf_loss': 0.16285052097457847, 'total_loss': 0.016587441203312656, 'approx_kl': -0.04988396228873171, 'clip_fraction': 0.3880208358168602, 'grad_norm': 28.087596893310547}
2023-01-03 13:22:59.909 INFO: Optimization: policy loss=0.075, vf loss=0.163, entropy loss=-0.058, total loss=0.017, num steps=15
2023-01-03 13:22:59.910 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 13:23:01.204 DEBUG: Atoms are too close
2023-01-03 13:23:01.206 INFO: Evaluation rollout: return=-29.359 (0.0), episode length=5.0
2023-01-03 13:23:01.207 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 13:23:01.210 INFO: Iteration: 53/137, steps: 11448
2023-01-03 13:23:14.679 DEBUG: Atoms are too close
2023-01-03 13:23:14.680 DEBUG: Atoms are too close
2023-01-03 13:23:15.130 DEBUG: Atoms are too close
2023-01-03 13:23:15.131 DEBUG: Atoms are too close
2023-01-03 13:23:15.132 DEBUG: Atoms are too close
2023-01-03 13:23:15.444 DEBUG: Atoms are too close
2023-01-03 13:23:17.097 DEBUG: There is a single atom floating around
2023-01-03 13:23:26.098 DEBUG: Atoms are too close
2023-01-03 13:23:26.828 DEBUG: There is a single atom floating around
2023-01-03 13:23:30.398 DEBUG: Atoms are too close
2023-01-03 13:23:31.326 DEBUG: Atoms are too close
2023-01-03 13:23:32.622 DEBUG: There is a single atom floating around
2023-01-03 13:23:34.166 DEBUG: Atoms are too close
2023-01-03 13:23:34.339 DEBUG: Atoms are too close
2023-01-03 13:23:34.642 DEBUG: Atoms are too close
2023-01-03 13:23:35.202 DEBUG: There is a single atom floating around
2023-01-03 13:23:35.987 DEBUG: Atoms are too close
2023-01-03 13:23:37.891 DEBUG: Atoms are too close
2023-01-03 13:23:40.138 DEBUG: There is a single atom floating around
2023-01-03 13:23:42.234 DEBUG: Atoms are too close
2023-01-03 13:23:44.374 DEBUG: Atoms are too close
2023-01-03 13:23:46.695 DEBUG: Atoms are too close
2023-01-03 13:23:46.779 DEBUG: There is a single atom floating around
2023-01-03 13:23:47.832 DEBUG: There is a single atom floating around
2023-01-03 13:23:50.816 DEBUG: Atoms are too close
2023-01-03 13:23:51.308 DEBUG: There is a single atom floating around
2023-01-03 13:23:54.656 DEBUG: Atoms are too close
2023-01-03 13:23:54.802 DEBUG: There is a single atom floating around
2023-01-03 13:23:55.187 INFO: Training rollout: return=-22.143 (12.9), episode length=5.2
2023-01-03 13:23:55.189 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 13:23:55.192 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-11448_train.pkl
2023-01-03 13:23:57.400 DEBUG: Taking gradient step
2023-01-03 13:23:59.600 DEBUG: Loss 0: {'policy_loss': -0.002490900512990975, 'entropy_loss': -0.05623818840831518, 'vf_loss': 0.16205062628375966, 'total_loss': -0.058729088921306155, 'approx_kl': 2.1420419216156006e-08, 'clip_fraction': 0.0, 'grad_norm': 19.96094512939453}
2023-01-03 13:24:01.807 DEBUG: Taking gradient step
2023-01-03 13:24:04.008 DEBUG: Loss 1: {'policy_loss': 0.0025558514007315743, 'entropy_loss': -0.054932442493736744, 'vf_loss': 0.16489471016958834, 'total_loss': -0.05237659109300517, 'approx_kl': -0.008939980529248714, 'clip_fraction': 0.03515625, 'grad_norm': 20.79842758178711}
2023-01-03 13:24:06.169 DEBUG: Taking gradient step
2023-01-03 13:24:08.565 DEBUG: Loss 2: {'policy_loss': 0.10226681147452821, 'entropy_loss': -0.057077339850366116, 'vf_loss': 0.15867268869001183, 'total_loss': 0.04518947162416209, 'approx_kl': -0.015085156075656414, 'clip_fraction': 0.3268229179084301, 'grad_norm': 20.66065216064453}
2023-01-03 13:24:10.725 DEBUG: Taking gradient step
2023-01-03 13:24:12.969 DEBUG: Loss 3: {'policy_loss': 0.0299193224464614, 'entropy_loss': -0.05695489328354597, 'vf_loss': 0.1629752512438557, 'total_loss': -0.02703557083708457, 'approx_kl': -0.045245587825775146, 'clip_fraction': 0.3776041716337204, 'grad_norm': 22.229928970336914}
2023-01-03 13:24:15.116 DEBUG: Taking gradient step
2023-01-03 13:24:17.437 DEBUG: Loss 4: {'policy_loss': 0.11271233938404901, 'entropy_loss': -0.05912612099200487, 'vf_loss': 0.16357706324875004, 'total_loss': 0.05358621839204414, 'approx_kl': -0.06076933164149523, 'clip_fraction': 0.42578125, 'grad_norm': 20.936452865600586}
2023-01-03 13:24:19.598 DEBUG: Taking gradient step
2023-01-03 13:24:21.802 DEBUG: Loss 5: {'policy_loss': 0.08974005688639877, 'entropy_loss': -0.0595104256644845, 'vf_loss': 0.16236813881572354, 'total_loss': 0.03022963122191427, 'approx_kl': -0.05051309522241354, 'clip_fraction': 0.4205729216337204, 'grad_norm': 21.076955795288086}
2023-01-03 13:24:24.045 DEBUG: Taking gradient step
2023-01-03 13:24:26.262 DEBUG: Loss 6: {'policy_loss': -0.030978914869621052, 'entropy_loss': -0.05749006289988756, 'vf_loss': 0.16711608811307777, 'total_loss': -0.0884689777695086, 'approx_kl': -0.05652048205956817, 'clip_fraction': 0.3776041716337204, 'grad_norm': 20.306364059448242}
2023-01-03 13:24:28.420 DEBUG: Taking gradient step
2023-01-03 13:24:30.660 DEBUG: Loss 7: {'policy_loss': 0.08235680019078911, 'entropy_loss': -0.056421381421387196, 'vf_loss': 0.15877673456156424, 'total_loss': 0.02593541876940192, 'approx_kl': -0.04782242700457573, 'clip_fraction': 0.3463541716337204, 'grad_norm': 32.74528884887695}
2023-01-03 13:24:32.849 DEBUG: Taking gradient step
2023-01-03 13:24:35.157 DEBUG: Loss 8: {'policy_loss': 0.010098438351197822, 'entropy_loss': -0.05910101067274809, 'vf_loss': 0.16291811802004655, 'total_loss': -0.04900257232155027, 'approx_kl': -0.061303093098104, 'clip_fraction': 0.3828125, 'grad_norm': 19.922725677490234}
2023-01-03 13:24:37.312 DEBUG: Taking gradient step
2023-01-03 13:24:39.650 DEBUG: Loss 9: {'policy_loss': 0.09491607389818503, 'entropy_loss': -0.056147207506000996, 'vf_loss': 0.15579393695716184, 'total_loss': 0.038768866392184034, 'approx_kl': -0.05272365640848875, 'clip_fraction': 0.4114583358168602, 'grad_norm': 19.090049743652344}
2023-01-03 13:24:42.003 DEBUG: Taking gradient step
2023-01-03 13:24:44.320 DEBUG: Loss 10: {'policy_loss': 0.07061443668980405, 'entropy_loss': -0.060303280130028725, 'vf_loss': 0.1633556164673383, 'total_loss': 0.010311156559775329, 'approx_kl': -0.07696270197629929, 'clip_fraction': 0.421875, 'grad_norm': 13.333163261413574}
2023-01-03 13:24:46.545 DEBUG: Taking gradient step
2023-01-03 13:24:48.750 DEBUG: Loss 11: {'policy_loss': 0.0425789453508023, 'entropy_loss': -0.062419417314231396, 'vf_loss': 0.16598162094790503, 'total_loss': -0.019840471963429106, 'approx_kl': -0.07450047601014376, 'clip_fraction': 0.4453125, 'grad_norm': 20.553882598876953}
2023-01-03 13:24:50.904 DEBUG: Taking gradient step
2023-01-03 13:24:53.117 DEBUG: Loss 12: {'policy_loss': 0.0913847507614777, 'entropy_loss': -0.05891675129532814, 'vf_loss': 0.15650639588391324, 'total_loss': 0.032467999466149554, 'approx_kl': -0.06158623471856117, 'clip_fraction': 0.4388020858168602, 'grad_norm': 21.909269332885742}
2023-01-03 13:24:55.277 DEBUG: Taking gradient step
2023-01-03 13:24:57.501 DEBUG: Loss 13: {'policy_loss': 0.09479821011163143, 'entropy_loss': -0.06099448259919882, 'vf_loss': 0.1556681709675634, 'total_loss': 0.033803727512432616, 'approx_kl': -0.08002950996160507, 'clip_fraction': 0.3606770858168602, 'grad_norm': 15.982476234436035}
2023-01-03 13:24:59.643 DEBUG: Taking gradient step
2023-01-03 13:25:01.847 DEBUG: Loss 14: {'policy_loss': 0.025920948088717824, 'entropy_loss': -0.05880798306316137, 'vf_loss': 0.17221981794098926, 'total_loss': -0.03288703497444355, 'approx_kl': -0.08857914293184876, 'clip_fraction': 0.3671875, 'grad_norm': 18.34093475341797}
2023-01-03 13:25:01.848 INFO: Optimization: policy loss=0.026, vf loss=0.172, entropy loss=-0.059, total loss=-0.033, num steps=15
2023-01-03 13:25:01.849 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 13:25:03.134 DEBUG: Atoms are too close
2023-01-03 13:25:03.138 INFO: Evaluation rollout: return=-29.369 (0.0), episode length=5.0
2023-01-03 13:25:03.139 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 13:25:03.142 INFO: Iteration: 54/137, steps: 11664
2023-01-03 13:25:12.957 DEBUG: Atoms are too close
2023-01-03 13:25:12.958 DEBUG: Atoms are too close
2023-01-03 13:25:12.959 DEBUG: Atoms are too close
2023-01-03 13:25:12.960 DEBUG: Atoms are too close
2023-01-03 13:25:13.262 DEBUG: Atoms are too close
2023-01-03 13:25:15.817 DEBUG: Atoms are too close
2023-01-03 13:25:16.966 DEBUG: Atoms are too close
2023-01-03 13:25:19.777 DEBUG: There is a single atom floating around
2023-01-03 13:25:25.691 DEBUG: Atoms are too close
2023-01-03 13:25:27.677 DEBUG: Atoms are too close
2023-01-03 13:25:28.295 DEBUG: There is a single atom floating around
2023-01-03 13:25:31.106 DEBUG: There is a single atom floating around
2023-01-03 13:25:33.478 DEBUG: There is a single atom floating around
2023-01-03 13:25:36.424 DEBUG: Atoms are too close
2023-01-03 13:25:38.345 DEBUG: There is a single atom floating around
2023-01-03 13:25:41.279 DEBUG: There is a single atom floating around
2023-01-03 13:25:43.077 DEBUG: There is a single atom floating around
2023-01-03 13:25:45.667 DEBUG: Atoms are too close
2023-01-03 13:25:48.648 DEBUG: Atoms are too close
2023-01-03 13:25:54.011 DEBUG: Atoms are too close
2023-01-03 13:25:57.938 DEBUG: There is a single atom floating around
2023-01-03 13:25:58.830 INFO: Training rollout: return=-17.041 (14.7), episode length=5.2
2023-01-03 13:25:58.831 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 13:25:58.835 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-11664_train.pkl
2023-01-03 13:26:01.001 DEBUG: Taking gradient step
2023-01-03 13:26:03.231 DEBUG: Loss 0: {'policy_loss': 0.0388830371683655, 'entropy_loss': -0.05861751548945904, 'vf_loss': 0.19519095285647256, 'total_loss': -0.01973447832109354, 'approx_kl': -6.022552678786042e-08, 'clip_fraction': 0.0, 'grad_norm': 20.00882911682129}
2023-01-03 13:26:05.439 DEBUG: Taking gradient step
2023-01-03 13:26:07.692 DEBUG: Loss 1: {'policy_loss': 0.04255164854261708, 'entropy_loss': -0.05554782226681709, 'vf_loss': 0.1855335648725704, 'total_loss': -0.012996173724200012, 'approx_kl': -0.0167657183483243, 'clip_fraction': 0.2018229179084301, 'grad_norm': 28.23152732849121}
2023-01-03 13:26:09.840 DEBUG: Taking gradient step
2023-01-03 13:26:12.051 DEBUG: Loss 2: {'policy_loss': -0.030968720148257155, 'entropy_loss': -0.05502680968493223, 'vf_loss': 0.20367462137304299, 'total_loss': -0.08599552983318938, 'approx_kl': -0.026588610373437405, 'clip_fraction': 0.2578125, 'grad_norm': 35.33101272583008}
2023-01-03 13:26:14.261 DEBUG: Taking gradient step
2023-01-03 13:26:16.507 DEBUG: Loss 3: {'policy_loss': -0.029430709340522596, 'entropy_loss': -0.0572733236476779, 'vf_loss': 0.19044672894851605, 'total_loss': -0.0867040329882005, 'approx_kl': -0.020927374251186848, 'clip_fraction': 0.2473958358168602, 'grad_norm': 24.669546127319336}
2023-01-03 13:26:19.040 DEBUG: Taking gradient step
2023-01-03 13:26:21.260 DEBUG: Loss 4: {'policy_loss': 0.013733637578558076, 'entropy_loss': -0.05877881217747927, 'vf_loss': 0.18147755060118226, 'total_loss': -0.045045174598921184, 'approx_kl': -0.04702820023521781, 'clip_fraction': 0.3424479216337204, 'grad_norm': 37.220890045166016}
2023-01-03 13:26:23.542 DEBUG: Taking gradient step
2023-01-03 13:26:25.781 DEBUG: Loss 5: {'policy_loss': 0.09579296341969844, 'entropy_loss': -0.05774409417062998, 'vf_loss': 0.17933763409431452, 'total_loss': 0.03804886924906846, 'approx_kl': -0.027935389429330826, 'clip_fraction': 0.3997395858168602, 'grad_norm': 33.31427764892578}
2023-01-03 13:26:28.044 DEBUG: Taking gradient step
2023-01-03 13:26:30.238 DEBUG: Loss 6: {'policy_loss': 0.04409805330677199, 'entropy_loss': -0.059263466857373714, 'vf_loss': 0.18094005653244483, 'total_loss': -0.01516541355060172, 'approx_kl': -0.04968496854417026, 'clip_fraction': 0.23046875, 'grad_norm': 33.69728469848633}
2023-01-03 13:26:32.385 DEBUG: Taking gradient step
2023-01-03 13:26:34.604 DEBUG: Loss 7: {'policy_loss': -0.031196618921639677, 'entropy_loss': -0.05864002741873264, 'vf_loss': 0.1827045292170521, 'total_loss': -0.08983664634037233, 'approx_kl': -0.035820987075567245, 'clip_fraction': 0.2473958358168602, 'grad_norm': 19.706506729125977}
2023-01-03 13:26:36.760 DEBUG: Taking gradient step
2023-01-03 13:26:39.072 DEBUG: Loss 8: {'policy_loss': 0.12441341115586052, 'entropy_loss': -0.06044997740536928, 'vf_loss': 0.1924736561823176, 'total_loss': 0.06396343375049124, 'approx_kl': -0.056403467897325754, 'clip_fraction': 0.4088541716337204, 'grad_norm': 44.14144515991211}
2023-01-03 13:26:41.270 DEBUG: Taking gradient step
2023-01-03 13:26:43.504 DEBUG: Loss 9: {'policy_loss': 0.14136654937240128, 'entropy_loss': -0.05711894854903221, 'vf_loss': 0.1935199846734204, 'total_loss': 0.08424760082336907, 'approx_kl': -0.06676182197406888, 'clip_fraction': 0.3997395858168602, 'grad_norm': 41.396453857421875}
2023-01-03 13:26:45.816 DEBUG: Taking gradient step
2023-01-03 13:26:48.003 DEBUG: Loss 10: {'policy_loss': 0.10133526703676303, 'entropy_loss': -0.058659874834120274, 'vf_loss': 0.19951184499132135, 'total_loss': 0.042675392202642756, 'approx_kl': -0.07501746714115143, 'clip_fraction': 0.3125, 'grad_norm': 25.48440170288086}
2023-01-03 13:26:50.325 DEBUG: Taking gradient step
2023-01-03 13:26:52.506 DEBUG: Loss 11: {'policy_loss': 0.049764548943335124, 'entropy_loss': -0.058939932845532894, 'vf_loss': 0.1902734138105358, 'total_loss': -0.009175383902197767, 'approx_kl': -0.07629331760108471, 'clip_fraction': 0.3033854216337204, 'grad_norm': 21.048603057861328}
2023-01-03 13:26:54.717 DEBUG: Taking gradient step
2023-01-03 13:26:56.958 DEBUG: Loss 12: {'policy_loss': 0.09041487809719367, 'entropy_loss': -0.057405900210142136, 'vf_loss': 0.1907538551104275, 'total_loss': 0.033008977887051545, 'approx_kl': -0.07190911937505007, 'clip_fraction': 0.4622395932674408, 'grad_norm': 39.93204879760742}
2023-01-03 13:26:59.115 DEBUG: Taking gradient step
2023-01-03 13:27:01.349 DEBUG: Loss 13: {'policy_loss': 0.15026736543395758, 'entropy_loss': -0.056199686601758, 'vf_loss': 0.18053686893213872, 'total_loss': 0.09406767883219959, 'approx_kl': -0.09428321244195104, 'clip_fraction': 0.4674479216337204, 'grad_norm': 40.479652404785156}
2023-01-03 13:27:03.544 DEBUG: Taking gradient step
2023-01-03 13:27:05.742 DEBUG: Loss 14: {'policy_loss': 0.03148214367037785, 'entropy_loss': -0.056803870014846325, 'vf_loss': 0.18578870036518974, 'total_loss': -0.02532172634446847, 'approx_kl': -0.11836693622171879, 'clip_fraction': 0.45703125, 'grad_norm': 31.319644927978516}
2023-01-03 13:27:05.743 INFO: Optimization: policy loss=0.031, vf loss=0.186, entropy loss=-0.057, total loss=-0.025, num steps=15
2023-01-03 13:27:05.745 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 13:27:06.964 DEBUG: Atoms are too close
2023-01-03 13:27:06.967 INFO: Evaluation rollout: return=-29.387 (0.0), episode length=5.0
2023-01-03 13:27:06.968 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 13:27:06.971 INFO: Iteration: 55/137, steps: 11880
2023-01-03 13:27:17.712 DEBUG: Atoms are too close
2023-01-03 13:27:21.032 DEBUG: There is a single atom floating around
2023-01-03 13:27:22.154 DEBUG: There is a single atom floating around
2023-01-03 13:27:22.155 DEBUG: Atoms are too close
2023-01-03 13:27:23.163 DEBUG: Atoms are too close
2023-01-03 13:27:25.267 DEBUG: There is a single atom floating around
2023-01-03 13:27:25.268 DEBUG: There is a single atom floating around
2023-01-03 13:27:29.323 DEBUG: Atoms are too close
2023-01-03 13:27:35.789 DEBUG: Atoms are too close
2023-01-03 13:27:40.110 DEBUG: There is a single atom floating around
2023-01-03 13:27:40.112 DEBUG: Atoms are too close
2023-01-03 13:27:40.807 DEBUG: There is a single atom floating around
2023-01-03 13:27:42.186 DEBUG: Atoms are too close
2023-01-03 13:27:43.771 DEBUG: There is a single atom floating around
2023-01-03 13:27:43.773 DEBUG: Atoms are too close
2023-01-03 13:27:44.618 DEBUG: There is a single atom floating around
2023-01-03 13:27:49.081 DEBUG: Atoms are too close
2023-01-03 13:27:58.644 DEBUG: Atoms are too close
2023-01-03 13:27:58.979 DEBUG: There is a single atom floating around
2023-01-03 13:27:58.980 DEBUG: Atoms are too close
2023-01-03 13:27:58.981 DEBUG: Atoms are too close
2023-01-03 13:27:58.982 DEBUG: There is a single atom floating around
2023-01-03 13:27:58.982 DEBUG: Atoms are too close
2023-01-03 13:27:59.350 DEBUG: Atoms are too close
2023-01-03 13:27:59.351 DEBUG: There is a single atom floating around
2023-01-03 13:28:05.559 DEBUG: There is a single atom floating around
2023-01-03 13:28:06.783 INFO: Training rollout: return=-20.564 (13.7), episode length=5.3
2023-01-03 13:28:06.785 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 13:28:06.788 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-11880_train.pkl
2023-01-03 13:28:15.588 DEBUG: Taking gradient step
2023-01-03 13:28:17.765 DEBUG: Loss 0: {'policy_loss': -0.002294238482278864, 'entropy_loss': -0.05317561235278845, 'vf_loss': 0.1695881396393811, 'total_loss': -0.05546985083506731, 'approx_kl': -7.916241884231567e-08, 'clip_fraction': 0.0, 'grad_norm': 23.72458267211914}
2023-01-03 13:28:20.065 DEBUG: Taking gradient step
2023-01-03 13:28:22.250 DEBUG: Loss 1: {'policy_loss': -0.008238441487250576, 'entropy_loss': -0.05734016839414835, 'vf_loss': 0.1759343310920854, 'total_loss': -0.06557860988139894, 'approx_kl': 0.0010318132117390633, 'clip_fraction': 0.234375, 'grad_norm': 12.150434494018555}
2023-01-03 13:28:24.473 DEBUG: Taking gradient step
2023-01-03 13:28:26.675 DEBUG: Loss 2: {'policy_loss': 0.02045992768953281, 'entropy_loss': -0.05767092760652304, 'vf_loss': 0.17403191320317432, 'total_loss': -0.03721099991699023, 'approx_kl': -0.030833549331873655, 'clip_fraction': 0.2864583358168602, 'grad_norm': 23.048871994018555}
2023-01-03 13:28:28.906 DEBUG: Taking gradient step
2023-01-03 13:28:31.105 DEBUG: Loss 3: {'policy_loss': 0.051342522856890054, 'entropy_loss': -0.05755795631557703, 'vf_loss': 0.16840494893387364, 'total_loss': -0.006215433458686977, 'approx_kl': -0.021941964398138225, 'clip_fraction': 0.3294270858168602, 'grad_norm': 27.901439666748047}
2023-01-03 13:28:33.259 DEBUG: Taking gradient step
2023-01-03 13:28:35.495 DEBUG: Loss 4: {'policy_loss': -0.008781927189337908, 'entropy_loss': -0.05884477775543928, 'vf_loss': 0.17802626041477404, 'total_loss': -0.06762670494477718, 'approx_kl': -0.05337276682257652, 'clip_fraction': 0.2161458358168602, 'grad_norm': 15.227422714233398}
2023-01-03 13:28:37.663 DEBUG: Taking gradient step
2023-01-03 13:28:39.857 DEBUG: Loss 5: {'policy_loss': 0.03529547054527257, 'entropy_loss': -0.05589293874800205, 'vf_loss': 0.17355891936377302, 'total_loss': -0.02059746820272948, 'approx_kl': -0.046903631649911404, 'clip_fraction': 0.2643229179084301, 'grad_norm': 12.647392272949219}
2023-01-03 13:28:42.302 DEBUG: Taking gradient step
2023-01-03 13:28:44.848 DEBUG: Loss 6: {'policy_loss': 0.02064193565046142, 'entropy_loss': -0.06027513649314642, 'vf_loss': 0.17878680371234842, 'total_loss': -0.039633200842685005, 'approx_kl': -0.050302430521696806, 'clip_fraction': 0.27734375, 'grad_norm': 21.517688751220703}
2023-01-03 13:28:47.133 DEBUG: Taking gradient step
2023-01-03 13:28:49.366 DEBUG: Loss 7: {'policy_loss': 0.05769079369726478, 'entropy_loss': -0.05700079631060362, 'vf_loss': 0.17331910168694664, 'total_loss': 0.0006899973866611592, 'approx_kl': -0.07540732529014349, 'clip_fraction': 0.2916666716337204, 'grad_norm': 22.304649353027344}
2023-01-03 13:28:51.526 DEBUG: Taking gradient step
2023-01-03 13:28:53.734 DEBUG: Loss 8: {'policy_loss': 0.04703817319125424, 'entropy_loss': -0.05575073882937431, 'vf_loss': 0.1677035536705358, 'total_loss': -0.008712565638120076, 'approx_kl': -0.0700923502445221, 'clip_fraction': 0.3854166716337204, 'grad_norm': 11.787079811096191}
2023-01-03 13:28:56.056 DEBUG: Taking gradient step
2023-01-03 13:28:58.269 DEBUG: Loss 9: {'policy_loss': 0.08399684699737148, 'entropy_loss': -0.057449137791991234, 'vf_loss': 0.16446258559337829, 'total_loss': 0.026547709205380247, 'approx_kl': -0.07609603740274906, 'clip_fraction': 0.34375, 'grad_norm': 24.491079330444336}
2023-01-03 13:29:00.433 DEBUG: Taking gradient step
2023-01-03 13:29:02.754 DEBUG: Loss 10: {'policy_loss': 0.07131975659630853, 'entropy_loss': -0.057414461858570576, 'vf_loss': 0.16872434192449115, 'total_loss': 0.01390529473773796, 'approx_kl': -0.07132252864539623, 'clip_fraction': 0.3450520858168602, 'grad_norm': 25.25751304626465}
2023-01-03 13:29:04.878 DEBUG: Taking gradient step
2023-01-03 13:29:07.295 DEBUG: Loss 11: {'policy_loss': 0.08589081558727955, 'entropy_loss': -0.05775536876171827, 'vf_loss': 0.16707353238273331, 'total_loss': 0.02813544682556128, 'approx_kl': -0.0667945072054863, 'clip_fraction': 0.3580729216337204, 'grad_norm': 10.744575500488281}
2023-01-03 13:29:09.466 DEBUG: Taking gradient step
2023-01-03 13:29:11.638 DEBUG: Loss 12: {'policy_loss': -0.010355889222022432, 'entropy_loss': -0.05968024209141731, 'vf_loss': 0.17697026013833653, 'total_loss': -0.07003613131343975, 'approx_kl': -0.09381089545786381, 'clip_fraction': 0.3541666716337204, 'grad_norm': 17.103700637817383}
2023-01-03 13:29:13.812 DEBUG: Taking gradient step
2023-01-03 13:29:15.997 DEBUG: Loss 13: {'policy_loss': -0.003549531972820888, 'entropy_loss': -0.05869704578071833, 'vf_loss': 0.17393472155123768, 'total_loss': -0.06224657775353921, 'approx_kl': -0.09657604061067104, 'clip_fraction': 0.2877604216337204, 'grad_norm': 23.843862533569336}
2023-01-03 13:29:18.207 DEBUG: Taking gradient step
2023-01-03 13:29:20.411 DEBUG: Loss 14: {'policy_loss': 0.0831110247123873, 'entropy_loss': -0.058092775754630566, 'vf_loss': 0.17099078699203657, 'total_loss': 0.025018248957756735, 'approx_kl': -0.08214856497943401, 'clip_fraction': 0.2942708358168602, 'grad_norm': 21.558191299438477}
2023-01-03 13:29:20.412 INFO: Optimization: policy loss=0.083, vf loss=0.171, entropy loss=-0.058, total loss=0.025, num steps=15
2023-01-03 13:29:20.413 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 13:29:21.659 DEBUG: Atoms are too close
2023-01-03 13:29:21.661 INFO: Evaluation rollout: return=-29.422 (0.0), episode length=5.0
2023-01-03 13:29:21.662 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 13:29:21.665 INFO: Iteration: 56/137, steps: 12096
2023-01-03 13:29:33.445 DEBUG: There is a single atom floating around
2023-01-03 13:29:33.817 DEBUG: Atoms are too close
2023-01-03 13:29:34.140 DEBUG: Atoms are too close
2023-01-03 13:29:34.536 DEBUG: Atoms are too close
2023-01-03 13:29:35.166 DEBUG: Atoms are too close
2023-01-03 13:29:35.168 DEBUG: There is a single atom floating around
2023-01-03 13:29:35.168 DEBUG: Atoms are too close
2023-01-03 13:29:48.855 DEBUG: There is a single atom floating around
2023-01-03 13:29:49.817 DEBUG: Atoms are too close
2023-01-03 13:29:50.838 DEBUG: Atoms are too close
2023-01-03 13:29:51.942 DEBUG: Atoms are too close
2023-01-03 13:29:51.944 DEBUG: There is a single atom floating around
2023-01-03 13:29:53.132 DEBUG: Atoms are too close
2023-01-03 13:29:53.295 DEBUG: Atoms are too close
2023-01-03 13:29:54.578 DEBUG: Atoms are too close
2023-01-03 13:29:57.871 DEBUG: Atoms are too close
2023-01-03 13:30:02.382 DEBUG: There is a single atom floating around
2023-01-03 13:30:05.666 DEBUG: Atoms are too close
2023-01-03 13:30:05.834 DEBUG: Atoms are too close
2023-01-03 13:30:07.181 DEBUG: Atoms are too close
2023-01-03 13:30:08.202 DEBUG: There is a single atom floating around
2023-01-03 13:30:09.173 DEBUG: There is a single atom floating around
2023-01-03 13:30:11.833 DEBUG: Atoms are too close
2023-01-03 13:30:17.797 INFO: Training rollout: return=-18.642 (14.4), episode length=5.2
2023-01-03 13:30:17.799 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 13:30:17.803 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-12096_train.pkl
2023-01-03 13:30:31.319 DEBUG: Taking gradient step
2023-01-03 13:30:45.314 DEBUG: Loss 0: {'policy_loss': 0.025296461010625063, 'entropy_loss': -0.056973811239004135, 'vf_loss': 0.17572278285695123, 'total_loss': -0.03167735022837907, 'approx_kl': 2.0760733576707935e-08, 'clip_fraction': 0.0, 'grad_norm': 17.81257438659668}
2023-01-03 13:30:59.015 DEBUG: Taking gradient step
2023-01-03 13:31:12.005 DEBUG: Loss 1: {'policy_loss': 0.018325176071479286, 'entropy_loss': -0.05466883443295956, 'vf_loss': 0.17303641156167257, 'total_loss': -0.03634365836148027, 'approx_kl': -0.027412818977609277, 'clip_fraction': 0.2434895858168602, 'grad_norm': 24.330453872680664}
2023-01-03 13:31:24.447 DEBUG: Taking gradient step
2023-01-03 13:31:37.143 DEBUG: Loss 2: {'policy_loss': 0.006415259083576, 'entropy_loss': -0.05785540957003832, 'vf_loss': 0.180183256338405, 'total_loss': -0.051440150486462326, 'approx_kl': -0.020046038320288062, 'clip_fraction': 0.28125, 'grad_norm': 24.617366790771484}
2023-01-03 13:31:50.207 DEBUG: Taking gradient step
2023-01-03 13:32:03.846 DEBUG: Loss 3: {'policy_loss': 0.11896544269301856, 'entropy_loss': -0.05603755824267864, 'vf_loss': 0.17695513625863984, 'total_loss': 0.06292788445033992, 'approx_kl': -0.017535190097987652, 'clip_fraction': 0.3072916716337204, 'grad_norm': 23.289077758789062}
2023-01-03 13:32:17.822 DEBUG: Taking gradient step
2023-01-03 13:32:31.551 DEBUG: Loss 4: {'policy_loss': 0.08747800100452294, 'entropy_loss': -0.05566865112632513, 'vf_loss': 0.1705007947214288, 'total_loss': 0.03180934987819781, 'approx_kl': -0.05660633463412523, 'clip_fraction': 0.33984375, 'grad_norm': 32.0953369140625}
2023-01-03 13:32:44.110 DEBUG: Taking gradient step
2023-01-03 13:32:57.692 DEBUG: Loss 5: {'policy_loss': 0.01604914440414896, 'entropy_loss': -0.0573649974539876, 'vf_loss': 0.1778102628462081, 'total_loss': -0.04131585304983865, 'approx_kl': -0.04334603063762188, 'clip_fraction': 0.3658854216337204, 'grad_norm': 19.174564361572266}
2023-01-03 13:33:11.042 DEBUG: Taking gradient step
2023-01-03 13:33:24.122 DEBUG: Loss 6: {'policy_loss': 0.019690426951144632, 'entropy_loss': -0.05671067722141743, 'vf_loss': 0.18175879432809, 'total_loss': -0.037020250270272795, 'approx_kl': -0.0355407299939543, 'clip_fraction': 0.3893229216337204, 'grad_norm': 24.56730079650879}
2023-01-03 13:33:37.597 DEBUG: Taking gradient step
2023-01-03 13:33:51.526 DEBUG: Loss 7: {'policy_loss': 0.04465577439893158, 'entropy_loss': -0.05511873867362738, 'vf_loss': 0.17707223525815646, 'total_loss': -0.010462964274695799, 'approx_kl': -0.04948404710739851, 'clip_fraction': 0.3294270858168602, 'grad_norm': 23.75588035583496}
2023-01-03 13:34:05.505 DEBUG: Taking gradient step
2023-01-03 13:34:19.233 DEBUG: Loss 8: {'policy_loss': 0.06102857336544818, 'entropy_loss': -0.05457566864788532, 'vf_loss': 0.17786441315412901, 'total_loss': 0.006452904717562859, 'approx_kl': -0.049921576865017414, 'clip_fraction': 0.3736979216337204, 'grad_norm': 23.278757095336914}
2023-01-03 13:34:31.857 DEBUG: Taking gradient step
2023-01-03 13:34:45.106 DEBUG: Loss 9: {'policy_loss': 0.028234046791662682, 'entropy_loss': -0.055904178880155087, 'vf_loss': 0.1758855526191461, 'total_loss': -0.027670132088492408, 'approx_kl': -0.04364190669730306, 'clip_fraction': 0.3111979216337204, 'grad_norm': 16.295120239257812}
2023-01-03 13:34:58.413 DEBUG: Taking gradient step
2023-01-03 13:35:10.955 DEBUG: Loss 10: {'policy_loss': 0.1028158409400988, 'entropy_loss': -0.05235326290130615, 'vf_loss': 0.17316146547100847, 'total_loss': 0.050462578038792644, 'approx_kl': -0.05496904253959656, 'clip_fraction': 0.3385416716337204, 'grad_norm': 30.761423110961914}
2023-01-03 13:35:24.724 DEBUG: Taking gradient step
2023-01-03 13:35:38.643 DEBUG: Loss 11: {'policy_loss': 0.135071774595099, 'entropy_loss': -0.054144883528351784, 'vf_loss': 0.1801757418042066, 'total_loss': 0.08092689106674723, 'approx_kl': -0.05921047832816839, 'clip_fraction': 0.3971354216337204, 'grad_norm': 38.11299514770508}
2023-01-03 13:35:52.376 DEBUG: Taking gradient step
2023-01-03 13:36:05.758 DEBUG: Loss 12: {'policy_loss': 0.03820524064704388, 'entropy_loss': -0.056384311988949776, 'vf_loss': 0.1716662436643957, 'total_loss': -0.018179071341905897, 'approx_kl': -0.07865995354950428, 'clip_fraction': 0.3880208432674408, 'grad_norm': 27.468355178833008}
2023-01-03 13:36:18.930 DEBUG: Taking gradient step
2023-01-03 13:36:31.749 DEBUG: Loss 13: {'policy_loss': 0.013596889621521058, 'entropy_loss': -0.05377632658928633, 'vf_loss': 0.18553635857685497, 'total_loss': -0.04017943696776527, 'approx_kl': -0.05477570556104183, 'clip_fraction': 0.3450520858168602, 'grad_norm': 22.350996017456055}
2023-01-03 13:36:45.183 DEBUG: Taking gradient step
2023-01-03 13:36:58.142 DEBUG: Loss 14: {'policy_loss': 0.07779495608569839, 'entropy_loss': -0.0553145557641983, 'vf_loss': 0.17876835840798394, 'total_loss': 0.022480400321500095, 'approx_kl': -0.06636375421658158, 'clip_fraction': 0.3229166716337204, 'grad_norm': 24.35938262939453}
2023-01-03 13:36:58.146 INFO: Optimization: policy loss=0.078, vf loss=0.179, entropy loss=-0.055, total loss=0.022, num steps=15
2023-01-03 13:36:58.148 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 13:36:59.439 DEBUG: Atoms are too close
2023-01-03 13:36:59.442 INFO: Evaluation rollout: return=-29.397 (0.0), episode length=4.0
2023-01-03 13:36:59.443 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 13:36:59.445 INFO: Iteration: 57/137, steps: 12312
2023-01-03 13:37:11.739 DEBUG: Atoms are too close
2023-01-03 13:37:11.741 DEBUG: Atoms are too close
2023-01-03 13:37:12.086 DEBUG: Atoms are too close
2023-01-03 13:37:14.961 DEBUG: There is a single atom floating around
2023-01-03 13:37:16.836 DEBUG: Atoms are too close
2023-01-03 13:37:20.226 DEBUG: Atoms are too close
2023-01-03 13:37:20.227 DEBUG: Atoms are too close
2023-01-03 13:37:26.456 DEBUG: Atoms are too close
2023-01-03 13:37:29.431 DEBUG: Atoms are too close
2023-01-03 13:37:29.767 DEBUG: There is a single atom floating around
2023-01-03 13:37:35.966 DEBUG: Atoms are too close
2023-01-03 13:37:36.293 DEBUG: Atoms are too close
2023-01-03 13:37:37.532 DEBUG: There is a single atom floating around
2023-01-03 13:37:37.865 DEBUG: Atoms are too close
2023-01-03 13:37:44.913 DEBUG: Atoms are too close
2023-01-03 13:37:45.233 DEBUG: Atoms are too close
2023-01-03 13:37:47.828 DEBUG: There is a single atom floating around
2023-01-03 13:37:52.046 DEBUG: Atoms are too close
2023-01-03 13:37:54.435 DEBUG: There is a single atom floating around
2023-01-03 13:37:57.381 DEBUG: There is a single atom floating around
2023-01-03 13:37:57.716 DEBUG: There is a single atom floating around
2023-01-03 13:37:59.186 DEBUG: Atoms are too close
2023-01-03 13:38:03.650 DEBUG: Atoms are too close
2023-01-03 13:38:05.929 INFO: Training rollout: return=-18.119 (14.5), episode length=5.1
2023-01-03 13:38:05.931 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 13:38:05.935 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-12312_train.pkl
2023-01-03 13:38:19.662 DEBUG: Taking gradient step
2023-01-03 13:38:33.843 DEBUG: Loss 0: {'policy_loss': -0.03917228530796768, 'entropy_loss': -0.05402324628084898, 'vf_loss': 0.19275082010407835, 'total_loss': -0.09319553158881666, 'approx_kl': -4.9515316291603995e-08, 'clip_fraction': 0.0, 'grad_norm': 16.848642349243164}
2023-01-03 13:38:47.670 DEBUG: Taking gradient step
2023-01-03 13:39:01.521 DEBUG: Loss 1: {'policy_loss': -0.027896439016151242, 'entropy_loss': -0.05679603852331638, 'vf_loss': 0.19441657681729574, 'total_loss': -0.08469247753946763, 'approx_kl': -0.011348338332027197, 'clip_fraction': 0.20703125, 'grad_norm': 15.182441711425781}
2023-01-03 13:39:14.075 DEBUG: Taking gradient step
2023-01-03 13:39:27.559 DEBUG: Loss 2: {'policy_loss': 0.028635262858119757, 'entropy_loss': -0.05532977357506752, 'vf_loss': 0.1897068304541207, 'total_loss': -0.026694510716947766, 'approx_kl': -0.024013484828174114, 'clip_fraction': 0.2942708358168602, 'grad_norm': 25.679100036621094}
2023-01-03 13:39:40.699 DEBUG: Taking gradient step
2023-01-03 13:39:53.306 DEBUG: Loss 3: {'policy_loss': 0.006193816224654092, 'entropy_loss': -0.056422033347189426, 'vf_loss': 0.19024455410838156, 'total_loss': -0.05022821712253533, 'approx_kl': -0.022985736839473248, 'clip_fraction': 0.2526041679084301, 'grad_norm': 22.644195556640625}
2023-01-03 13:40:07.113 DEBUG: Taking gradient step
2023-01-03 13:40:21.168 DEBUG: Loss 4: {'policy_loss': 0.08906593731868151, 'entropy_loss': -0.056503526866436005, 'vf_loss': 0.1847073568068883, 'total_loss': 0.0325624104522455, 'approx_kl': -0.039140196226071566, 'clip_fraction': 0.3203125, 'grad_norm': 38.13969421386719}
2023-01-03 13:40:34.833 DEBUG: Taking gradient step
2023-01-03 13:40:47.959 DEBUG: Loss 5: {'policy_loss': 0.008931396744628763, 'entropy_loss': -0.0553313996642828, 'vf_loss': 0.18491563825128182, 'total_loss': -0.04640000291965403, 'approx_kl': -0.03555938694626093, 'clip_fraction': 0.48046875, 'grad_norm': 18.423044204711914}
2023-01-03 13:41:00.965 DEBUG: Taking gradient step
2023-01-03 13:41:14.061 DEBUG: Loss 6: {'policy_loss': 0.03764403980591317, 'entropy_loss': -0.05493380967527628, 'vf_loss': 0.185735094656489, 'total_loss': -0.017289769869363113, 'approx_kl': -0.05178057495504618, 'clip_fraction': 0.4973958432674408, 'grad_norm': 19.062387466430664}
2023-01-03 13:41:27.152 DEBUG: Taking gradient step
2023-01-03 13:41:40.361 DEBUG: Loss 7: {'policy_loss': 0.0892827684015913, 'entropy_loss': -0.05479020904749632, 'vf_loss': 0.18938239878242882, 'total_loss': 0.03449255935409499, 'approx_kl': -0.07225213292986155, 'clip_fraction': 0.3776041716337204, 'grad_norm': 35.76164627075195}
2023-01-03 13:41:54.326 DEBUG: Taking gradient step
2023-01-03 13:42:08.069 DEBUG: Loss 8: {'policy_loss': 0.11000256001864891, 'entropy_loss': -0.05602655000984669, 'vf_loss': 0.18890586078476307, 'total_loss': 0.053976010008802235, 'approx_kl': -0.08300535660237074, 'clip_fraction': 0.4622395858168602, 'grad_norm': 36.07484436035156}
2023-01-03 13:42:21.976 DEBUG: Taking gradient step
2023-01-03 13:42:34.697 DEBUG: Loss 9: {'policy_loss': 0.04157351930242351, 'entropy_loss': -0.05038087069988251, 'vf_loss': 0.1847235614602236, 'total_loss': -0.008807351397458998, 'approx_kl': -0.04789254814386368, 'clip_fraction': 0.43359375, 'grad_norm': 17.601364135742188}
2023-01-03 13:42:47.899 DEBUG: Taking gradient step
2023-01-03 13:43:00.963 DEBUG: Loss 10: {'policy_loss': 0.03949112970445103, 'entropy_loss': -0.05101714190095663, 'vf_loss': 0.19137157431073218, 'total_loss': -0.011526012196505597, 'approx_kl': -0.055714309215545654, 'clip_fraction': 0.3385416716337204, 'grad_norm': 22.043500900268555}
2023-01-03 13:43:13.782 DEBUG: Taking gradient step
2023-01-03 13:43:27.420 DEBUG: Loss 11: {'policy_loss': 0.061661437519915416, 'entropy_loss': -0.05266059562563896, 'vf_loss': 0.18785436095957356, 'total_loss': 0.009000841894276447, 'approx_kl': -0.10074511624407023, 'clip_fraction': 0.4153645858168602, 'grad_norm': 18.789121627807617}
2023-01-03 13:43:41.657 DEBUG: Taking gradient step
2023-01-03 13:43:55.688 DEBUG: Loss 12: {'policy_loss': 0.13542062636159893, 'entropy_loss': -0.05272465571761131, 'vf_loss': 0.18285012514757598, 'total_loss': 0.08269597064398762, 'approx_kl': -0.05719334818422794, 'clip_fraction': 0.55078125, 'grad_norm': 51.03556442260742}
2023-01-03 13:44:09.386 DEBUG: Taking gradient step
2023-01-03 13:44:21.665 DEBUG: Loss 13: {'policy_loss': 0.06638723734973903, 'entropy_loss': -0.057382311671972275, 'vf_loss': 0.18722984473998752, 'total_loss': 0.009004925677766756, 'approx_kl': -0.06033591739833355, 'clip_fraction': 0.5169270932674408, 'grad_norm': 33.1987419128418}
2023-01-03 13:44:34.592 DEBUG: Taking gradient step
2023-01-03 13:44:47.546 DEBUG: Loss 14: {'policy_loss': 0.05954186389885033, 'entropy_loss': -0.0545715382322669, 'vf_loss': 0.19133767730301154, 'total_loss': 0.004970325666583425, 'approx_kl': -0.08341343235224485, 'clip_fraction': 0.4283854216337204, 'grad_norm': 48.683467864990234}
2023-01-03 13:44:47.582 INFO: Optimization: policy loss=0.060, vf loss=0.191, entropy loss=-0.055, total loss=0.005, num steps=15
2023-01-03 13:44:47.583 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 13:44:49.577 DEBUG: Atoms are too close
2023-01-03 13:44:49.579 INFO: Evaluation rollout: return=-29.630 (0.0), episode length=5.0
2023-01-03 13:44:49.580 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 13:44:49.584 INFO: Iteration: 58/137, steps: 12528
2023-01-03 13:45:01.400 DEBUG: There is a single atom floating around
2023-01-03 13:45:03.036 DEBUG: There is a single atom floating around
2023-01-03 13:45:04.114 DEBUG: There is a single atom floating around
2023-01-03 13:45:06.164 DEBUG: There is a single atom floating around
2023-01-03 13:45:06.648 DEBUG: There is a single atom floating around
2023-01-03 13:45:09.216 DEBUG: Atoms are too close
2023-01-03 13:45:19.901 DEBUG: There is a single atom floating around
2023-01-03 13:45:21.910 DEBUG: Atoms are too close
2023-01-03 13:45:24.073 DEBUG: There is a single atom floating around
2023-01-03 13:45:25.059 DEBUG: There is a single atom floating around
2023-01-03 13:45:28.353 DEBUG: There is a single atom floating around
2023-01-03 13:45:29.510 DEBUG: Atoms are too close
2023-01-03 13:45:30.887 DEBUG: Atoms are too close
2023-01-03 13:45:31.696 DEBUG: Atoms are too close
2023-01-03 13:45:33.251 DEBUG: There is a single atom floating around
2023-01-03 13:45:39.399 DEBUG: Atoms are too close
2023-01-03 13:45:42.574 DEBUG: Atoms are too close
2023-01-03 13:45:44.811 DEBUG: There is a single atom floating around
2023-01-03 13:45:45.845 DEBUG: Atoms are too close
2023-01-03 13:45:49.995 DEBUG: Atoms are too close
2023-01-03 13:45:50.328 DEBUG: Atoms are too close
2023-01-03 13:45:50.952 DEBUG: There is a single atom floating around
2023-01-03 13:45:51.613 DEBUG: Atoms are too close
2023-01-03 13:45:55.537 INFO: Training rollout: return=-19.458 (14.1), episode length=5.3
2023-01-03 13:45:55.539 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 13:45:55.544 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-12528_train.pkl
2023-01-03 13:46:08.431 DEBUG: Taking gradient step
2023-01-03 13:46:21.941 DEBUG: Loss 0: {'policy_loss': 0.036366901716368284, 'entropy_loss': -0.056361421942710876, 'vf_loss': 0.19119839227641344, 'total_loss': -0.019994520226342592, 'approx_kl': -7.826990255921373e-08, 'clip_fraction': 0.0, 'grad_norm': 25.16510581970215}
2023-01-03 13:46:36.217 DEBUG: Taking gradient step
2023-01-03 13:46:50.826 DEBUG: Loss 1: {'policy_loss': 0.011654453900229927, 'entropy_loss': -0.054873544722795486, 'vf_loss': 0.19017532581448865, 'total_loss': -0.04321909082256556, 'approx_kl': -0.012863265816122293, 'clip_fraction': 0.1783854179084301, 'grad_norm': 36.16143798828125}
2023-01-03 13:47:04.781 DEBUG: Taking gradient step
2023-01-03 13:47:18.189 DEBUG: Loss 2: {'policy_loss': 0.062124646728672205, 'entropy_loss': -0.055186862125992775, 'vf_loss': 0.19191182467296525, 'total_loss': 0.00693778460267943, 'approx_kl': -0.023443975020200014, 'clip_fraction': 0.29296875, 'grad_norm': 34.62456130981445}
2023-01-03 13:47:31.352 DEBUG: Taking gradient step
2023-01-03 13:47:44.059 DEBUG: Loss 3: {'policy_loss': 0.1166951077440482, 'entropy_loss': -0.056231969967484474, 'vf_loss': 0.17983351976785486, 'total_loss': 0.06046313777656372, 'approx_kl': -0.026907358318567276, 'clip_fraction': 0.3294270858168602, 'grad_norm': 31.04876708984375}
2023-01-03 13:47:57.133 DEBUG: Taking gradient step
2023-01-03 13:48:10.289 DEBUG: Loss 4: {'policy_loss': 0.09797434996437585, 'entropy_loss': -0.05505287181586027, 'vf_loss': 0.1850763506817699, 'total_loss': 0.04292147814851557, 'approx_kl': -0.05262881238013506, 'clip_fraction': 0.3489583358168602, 'grad_norm': 35.511558532714844}
2023-01-03 13:48:24.296 DEBUG: Taking gradient step
2023-01-03 13:48:38.431 DEBUG: Loss 5: {'policy_loss': 0.0782259241142136, 'entropy_loss': -0.05398568883538246, 'vf_loss': 0.19145433297711975, 'total_loss': 0.02424023527883114, 'approx_kl': -0.05793434800580144, 'clip_fraction': 0.3346354216337204, 'grad_norm': 35.748958587646484}
2023-01-03 13:48:52.497 DEBUG: Taking gradient step
2023-01-03 13:49:05.873 DEBUG: Loss 6: {'policy_loss': 0.0728152450764059, 'entropy_loss': -0.05128699541091919, 'vf_loss': 0.18649033940489634, 'total_loss': 0.021528249665486707, 'approx_kl': -0.05509853735566139, 'clip_fraction': 0.3059895858168602, 'grad_norm': 33.37779235839844}
2023-01-03 13:49:19.117 DEBUG: Taking gradient step
2023-01-03 13:49:31.874 DEBUG: Loss 7: {'policy_loss': 0.157067920821745, 'entropy_loss': -0.05295770149677992, 'vf_loss': 0.1959281778246194, 'total_loss': 0.10411021932496509, 'approx_kl': -0.0502250324934721, 'clip_fraction': 0.3072916716337204, 'grad_norm': 41.28733825683594}
2023-01-03 13:49:45.061 DEBUG: Taking gradient step
2023-01-03 13:49:58.507 DEBUG: Loss 8: {'policy_loss': 0.07178014091249686, 'entropy_loss': -0.053785935044288635, 'vf_loss': 0.18799428644703076, 'total_loss': 0.01799420586820822, 'approx_kl': -0.07800571946427226, 'clip_fraction': 0.3528645858168602, 'grad_norm': 43.098636627197266}
2023-01-03 13:50:12.449 DEBUG: Taking gradient step
2023-01-03 13:50:26.620 DEBUG: Loss 9: {'policy_loss': 0.04710612325165361, 'entropy_loss': -0.05422271881252527, 'vf_loss': 0.19828408068404946, 'total_loss': -0.007116595560871665, 'approx_kl': -0.034801829140633345, 'clip_fraction': 0.3489583358168602, 'grad_norm': 31.63724708557129}
2023-01-03 13:50:40.764 DEBUG: Taking gradient step
2023-01-03 13:50:54.570 DEBUG: Loss 10: {'policy_loss': 0.05891752163215248, 'entropy_loss': -0.05221576802432537, 'vf_loss': 0.18600328132400482, 'total_loss': 0.006701753607827106, 'approx_kl': -0.05418981658294797, 'clip_fraction': 0.3125, 'grad_norm': 24.597097396850586}
2023-01-03 13:51:07.970 DEBUG: Taking gradient step
2023-01-03 13:51:20.740 DEBUG: Loss 11: {'policy_loss': 0.10381782287846392, 'entropy_loss': -0.053652060218155384, 'vf_loss': 0.1983559010860697, 'total_loss': 0.05016576266030853, 'approx_kl': -0.06843845406547189, 'clip_fraction': 0.3541666716337204, 'grad_norm': 37.80024719238281}
2023-01-03 13:51:33.808 DEBUG: Taking gradient step
2023-01-03 13:51:46.419 DEBUG: Loss 12: {'policy_loss': 0.09867460941708782, 'entropy_loss': -0.05376626271754503, 'vf_loss': 0.18756297919602907, 'total_loss': 0.04490834669954279, 'approx_kl': -0.06754160113632679, 'clip_fraction': 0.3971354216337204, 'grad_norm': 37.19941711425781}
2023-01-03 13:52:00.101 DEBUG: Taking gradient step
2023-01-03 13:52:14.006 DEBUG: Loss 13: {'policy_loss': 0.19535364506242298, 'entropy_loss': -0.0542979696765542, 'vf_loss': 0.18325994825371017, 'total_loss': 0.1410556753858688, 'approx_kl': -0.047147255623713136, 'clip_fraction': 0.421875, 'grad_norm': 43.290740966796875}
2023-01-03 13:52:27.822 DEBUG: Taking gradient step
2023-01-03 13:52:41.320 DEBUG: Loss 14: {'policy_loss': 0.08416470003270796, 'entropy_loss': -0.0522844772785902, 'vf_loss': 0.18440169489320127, 'total_loss': 0.03188022275411775, 'approx_kl': -0.04601801745593548, 'clip_fraction': 0.3971354216337204, 'grad_norm': 38.4434700012207}
2023-01-03 13:52:41.321 INFO: Optimization: policy loss=0.084, vf loss=0.184, entropy loss=-0.052, total loss=0.032, num steps=15
2023-01-03 13:52:41.322 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 13:52:43.051 DEBUG: Atoms are too close
2023-01-03 13:52:43.054 INFO: Evaluation rollout: return=-29.551 (0.0), episode length=5.0
2023-01-03 13:52:43.054 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 13:52:43.058 INFO: Iteration: 59/137, steps: 12744
2023-01-03 13:52:55.756 DEBUG: Atoms are too close
2023-01-03 13:52:56.118 DEBUG: Atoms are too close
2023-01-03 13:52:56.458 DEBUG: There is a single atom floating around
2023-01-03 13:52:56.461 DEBUG: Atoms are too close
2023-01-03 13:52:57.817 DEBUG: There is a single atom floating around
2023-01-03 13:52:57.818 DEBUG: Atoms are too close
2023-01-03 13:52:58.334 DEBUG: There is a single atom floating around
2023-01-03 13:52:59.848 DEBUG: There is a single atom floating around
2023-01-03 13:53:01.724 DEBUG: There is a single atom floating around
2023-01-03 13:53:13.072 DEBUG: There is a single atom floating around
2023-01-03 13:53:15.399 DEBUG: There is a single atom floating around
2023-01-03 13:53:17.549 DEBUG: There is a single atom floating around
2023-01-03 13:53:17.871 DEBUG: There is a single atom floating around
2023-01-03 13:53:20.410 DEBUG: There is a single atom floating around
2023-01-03 13:53:21.926 DEBUG: There is a single atom floating around
2023-01-03 13:53:31.613 DEBUG: There is a single atom floating around
2023-01-03 13:53:31.965 DEBUG: There is a single atom floating around
2023-01-03 13:53:33.610 DEBUG: There is a single atom floating around
2023-01-03 13:53:34.177 DEBUG: Atoms are too close
2023-01-03 13:53:34.178 DEBUG: There is a single atom floating around
2023-01-03 13:53:34.179 DEBUG: There is a single atom floating around
2023-01-03 13:53:35.498 DEBUG: Atoms are too close
2023-01-03 13:53:37.543 DEBUG: Atoms are too close
2023-01-03 13:53:42.657 DEBUG: Atoms are too close
2023-01-03 13:53:44.839 DEBUG: Atoms are too close
2023-01-03 13:53:47.934 INFO: Training rollout: return=-20.516 (13.7), episode length=5.2
2023-01-03 13:53:47.936 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 13:53:47.938 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-12744_train.pkl
2023-01-03 13:54:00.692 DEBUG: Taking gradient step
2023-01-03 13:54:13.288 DEBUG: Loss 0: {'policy_loss': -0.015464548014099414, 'entropy_loss': -0.0555196525529027, 'vf_loss': 0.18191693263294176, 'total_loss': -0.07098420056700211, 'approx_kl': -7.989971706479082e-08, 'clip_fraction': 0.0, 'grad_norm': 17.85669708251953}
2023-01-03 13:54:26.191 DEBUG: Taking gradient step
2023-01-03 13:54:39.747 DEBUG: Loss 1: {'policy_loss': 0.039406815967270664, 'entropy_loss': -0.05382595304399729, 'vf_loss': 0.18414860264219704, 'total_loss': -0.014419137076726624, 'approx_kl': -0.035683792317286134, 'clip_fraction': 0.2591145858168602, 'grad_norm': 34.71104431152344}
2023-01-03 13:54:54.418 DEBUG: Taking gradient step
2023-01-03 13:55:08.943 DEBUG: Loss 2: {'policy_loss': 0.08814226096474498, 'entropy_loss': -0.05196344666182995, 'vf_loss': 0.17084457640707046, 'total_loss': 0.03617881430291503, 'approx_kl': -0.046738788951188326, 'clip_fraction': 0.4817708358168602, 'grad_norm': 29.64487075805664}
2023-01-03 13:55:22.615 DEBUG: Taking gradient step
2023-01-03 13:55:31.601 DEBUG: Loss 3: {'policy_loss': 0.13653223394211078, 'entropy_loss': -0.051048518158495426, 'vf_loss': 0.17571605489676373, 'total_loss': 0.08548371578361534, 'approx_kl': -0.04018757492303848, 'clip_fraction': 0.4674479216337204, 'grad_norm': 27.780603408813477}
2023-01-03 13:55:34.109 DEBUG: Taking gradient step
2023-01-03 13:55:36.302 DEBUG: Loss 4: {'policy_loss': 0.18560708649538413, 'entropy_loss': -0.04880369175225496, 'vf_loss': 0.1752431691291327, 'total_loss': 0.13680339474312916, 'approx_kl': -0.04639962688088417, 'clip_fraction': 0.4908854216337204, 'grad_norm': 37.508609771728516}
2023-01-03 13:55:38.634 DEBUG: Taking gradient step
2023-01-03 13:55:40.958 DEBUG: Loss 5: {'policy_loss': 0.08729416322741246, 'entropy_loss': -0.05042761657387018, 'vf_loss': 0.1720569694722552, 'total_loss': 0.036866546653542276, 'approx_kl': -0.0456826277077198, 'clip_fraction': 0.4348958358168602, 'grad_norm': 32.14271545410156}
2023-01-03 13:55:43.099 DEBUG: Taking gradient step
2023-01-03 13:55:45.316 DEBUG: Loss 6: {'policy_loss': 0.1381511508782856, 'entropy_loss': -0.05277590733021498, 'vf_loss': 0.1792589497009411, 'total_loss': 0.08537524354807062, 'approx_kl': -0.06824637949466705, 'clip_fraction': 0.47265625, 'grad_norm': 39.6371955871582}
2023-01-03 13:55:47.601 DEBUG: Taking gradient step
2023-01-03 13:55:49.829 DEBUG: Loss 7: {'policy_loss': 0.19330167886989247, 'entropy_loss': -0.05425496120005846, 'vf_loss': 0.17454252905859466, 'total_loss': 0.139046717669834, 'approx_kl': -0.06309035792946815, 'clip_fraction': 0.3841145858168602, 'grad_norm': 41.72397994995117}
2023-01-03 13:55:52.002 DEBUG: Taking gradient step
2023-01-03 13:55:54.189 DEBUG: Loss 8: {'policy_loss': 0.1258677750958776, 'entropy_loss': -0.052938894368708134, 'vf_loss': 0.17807600358000475, 'total_loss': 0.07292888072716947, 'approx_kl': -0.07285188045352697, 'clip_fraction': 0.3658854216337204, 'grad_norm': 33.67842102050781}
2023-01-03 13:55:56.338 DEBUG: Taking gradient step
2023-01-03 13:55:58.548 DEBUG: Loss 9: {'policy_loss': 0.029661207872902773, 'entropy_loss': -0.05297211371362209, 'vf_loss': 0.19712938213002873, 'total_loss': -0.023310905840719334, 'approx_kl': -0.06159762339666486, 'clip_fraction': 0.4583333358168602, 'grad_norm': 37.19709396362305}
2023-01-03 13:56:00.681 DEBUG: Taking gradient step
2023-01-03 13:56:03.009 DEBUG: Loss 10: {'policy_loss': 0.1490701612866514, 'entropy_loss': -0.051523991860449314, 'vf_loss': 0.1768049981942161, 'total_loss': 0.09754616942620209, 'approx_kl': -0.08702978864312172, 'clip_fraction': 0.4765625, 'grad_norm': 39.76327896118164}
2023-01-03 13:56:05.148 DEBUG: Taking gradient step
2023-01-03 13:56:07.437 DEBUG: Loss 11: {'policy_loss': 0.16068639270643112, 'entropy_loss': -0.0508883073925972, 'vf_loss': 0.1753383725550045, 'total_loss': 0.10979808531383392, 'approx_kl': -0.09686750778928399, 'clip_fraction': 0.56640625, 'grad_norm': 41.746612548828125}
2023-01-03 13:56:09.590 DEBUG: Taking gradient step
2023-01-03 13:56:11.893 DEBUG: Loss 12: {'policy_loss': 0.10638434183617726, 'entropy_loss': -0.05004113260656595, 'vf_loss': 0.17607502772159045, 'total_loss': 0.0563432092296113, 'approx_kl': -0.08196966350078583, 'clip_fraction': 0.5416666716337204, 'grad_norm': 28.483169555664062}
2023-01-03 13:56:14.024 DEBUG: Taking gradient step
2023-01-03 13:56:16.566 DEBUG: Loss 13: {'policy_loss': 0.11148773106234075, 'entropy_loss': -0.05193593446165323, 'vf_loss': 0.1741613539036635, 'total_loss': 0.05955179660068751, 'approx_kl': -0.08980796672403812, 'clip_fraction': 0.4622395858168602, 'grad_norm': 28.011838912963867}
2023-01-03 13:56:18.719 DEBUG: Taking gradient step
2023-01-03 13:56:20.910 DEBUG: Loss 14: {'policy_loss': 0.022321178517223164, 'entropy_loss': -0.0519337672740221, 'vf_loss': 0.17673742694862302, 'total_loss': -0.029612588756798938, 'approx_kl': -0.06283550895750523, 'clip_fraction': 0.5169270932674408, 'grad_norm': 16.833847045898438}
2023-01-03 13:56:20.910 INFO: Optimization: policy loss=0.022, vf loss=0.177, entropy loss=-0.052, total loss=-0.030, num steps=15
2023-01-03 13:56:20.911 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 13:56:22.176 DEBUG: Atoms are too close
2023-01-03 13:56:22.178 INFO: Evaluation rollout: return=-29.351 (0.0), episode length=5.0
2023-01-03 13:56:22.179 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 13:56:22.181 INFO: Iteration: 60/137, steps: 12960
2023-01-03 13:56:32.600 DEBUG: Atoms are too close
2023-01-03 13:56:34.221 DEBUG: There is a single atom floating around
2023-01-03 13:56:35.320 DEBUG: There is a single atom floating around
2023-01-03 13:56:35.791 DEBUG: There is a single atom floating around
2023-01-03 13:56:37.899 DEBUG: There is a single atom floating around
2023-01-03 13:56:48.797 DEBUG: There is a single atom floating around
2023-01-03 13:56:51.562 DEBUG: There is a single atom floating around
2023-01-03 13:56:52.724 DEBUG: There is a single atom floating around
2023-01-03 13:56:54.071 DEBUG: There is a single atom floating around
2023-01-03 13:56:54.971 DEBUG: Atoms are too close
2023-01-03 13:56:56.075 DEBUG: There is a single atom floating around
2023-01-03 13:56:58.563 DEBUG: Atoms are too close
2023-01-03 13:57:07.298 DEBUG: Atoms are too close
2023-01-03 13:57:07.697 DEBUG: There is a single atom floating around
2023-01-03 13:57:12.243 DEBUG: There is a single atom floating around
2023-01-03 13:57:13.219 DEBUG: There is a single atom floating around
2023-01-03 13:57:13.932 DEBUG: Atoms are too close
2023-01-03 13:57:15.239 DEBUG: Atoms are too close
2023-01-03 13:57:15.865 DEBUG: Atoms are too close
2023-01-03 13:57:19.469 INFO: Training rollout: return=-15.315 (15.0), episode length=5.4
2023-01-03 13:57:19.471 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 13:57:19.473 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-12960_train.pkl
2023-01-03 13:57:21.697 DEBUG: Taking gradient step
2023-01-03 13:57:23.931 DEBUG: Loss 0: {'policy_loss': 0.007493601592962095, 'entropy_loss': -0.05119744408875704, 'vf_loss': 0.20651354542397657, 'total_loss': -0.04370384249579494, 'approx_kl': -4.268567721510408e-10, 'clip_fraction': 0.0, 'grad_norm': 16.987083435058594}
2023-01-03 13:57:26.092 DEBUG: Taking gradient step
2023-01-03 13:57:28.294 DEBUG: Loss 1: {'policy_loss': 0.05790721536862443, 'entropy_loss': -0.051262267865240574, 'vf_loss': 0.21249200334042445, 'total_loss': 0.0066449475033838485, 'approx_kl': -0.016883711447007954, 'clip_fraction': 0.3502604216337204, 'grad_norm': 30.340482711791992}
2023-01-03 13:57:30.612 DEBUG: Taking gradient step
2023-01-03 13:57:32.842 DEBUG: Loss 2: {'policy_loss': 0.11127426097418984, 'entropy_loss': -0.05091686546802521, 'vf_loss': 0.207224705678427, 'total_loss': 0.060357395506164625, 'approx_kl': -0.019065783359110355, 'clip_fraction': 0.3958333358168602, 'grad_norm': 62.0443229675293}
2023-01-03 13:57:35.108 DEBUG: Taking gradient step
2023-01-03 13:57:37.337 DEBUG: Loss 3: {'policy_loss': 0.1022657395423015, 'entropy_loss': -0.05385155510157347, 'vf_loss': 0.20219796930012685, 'total_loss': 0.048414184440728036, 'approx_kl': -0.013512668199837208, 'clip_fraction': 0.4036458358168602, 'grad_norm': 33.96951675415039}
2023-01-03 13:57:39.513 DEBUG: Taking gradient step
2023-01-03 13:58:14.437 INFO: {
    "bag_scale": 6,
    "beta": "-10",
    "canvas_size": 6,
    "clip_ratio": 0.2,
    "cutoff": 4.0,
    "data_dir": "runs/CH3NO_dna/data",
    "device": "cuda",
    "discount": 0.85,
    "entropy_coef": 0.06,
    "eval_formulas": "CH3NO",
    "eval_freq": 1,
    "formulas": "CH3NO",
    "gradient_clip": 0.5,
    "keep_models": false,
    "lam": 0.95,
    "learning_rate": 0.0005,
    "load_latest": false,
    "load_model": null,
    "log_dir": "runs/CH3NO_dna/logs",
    "log_level": "DEBUG",
    "max_mean_distance": 1.8,
    "max_num_steps": 30000,
    "max_num_train_iters": 15,
    "max_solo_distance": 2.0,
    "maxl": 4,
    "min_atomic_distance": 0.6,
    "min_mean_distance": 0.8,
    "min_reward": -30.0,
    "mini_batch_size": 64,
    "model": "schnet_edge",
    "model_dir": "runs/CH3NO_dna/models",
    "name": "CH3NO_dna",
    "network_width": 128,
    "num_cg_levels": 3,
    "num_channels_hidden": 10,
    "num_channels_per_element": 4,
    "num_envs": 12,
    "num_eval_episodes": null,
    "num_gaussians": 3,
    "num_interactions": 3,
    "num_steps_per_iter": 216,
    "optimizer": "adam",
    "results_dir": "runs/CH3NO_dna/results",
    "save_freq": 10,
    "save_rollouts": "train",
    "seed": 1,
    "symbols": "X,H,C,N,O",
    "target_kl": 0.03,
    "update_edges": true,
    "vf_coef": 0.001
}
2023-01-03 13:58:14.485 INFO: CUDA Device: 0
2023-01-03 13:58:14.486 INFO: Training bags: ['CH3NO']
2023-01-03 13:58:14.486 INFO: Evaluation bags: ['CH3NO']
2023-01-03 13:58:16.362 INFO: Number of parameters: 549407
2023-01-03 13:58:16.378 INFO: Starting PPO
2023-01-03 13:58:16.378 INFO: Iteration: 0/137, steps: 0
2023-01-03 13:58:20.035 DEBUG: There is a single atom floating around
2023-01-03 13:58:21.377 DEBUG: There is a single atom floating around
2023-01-03 13:58:22.707 DEBUG: There is a single atom floating around
2023-01-03 13:58:25.758 DEBUG: Atoms are too close
2023-01-03 13:58:27.641 DEBUG: Atoms are too close
2023-01-03 13:58:28.291 DEBUG: Atoms are too close
2023-01-03 13:58:28.292 DEBUG: Atoms are too close
2023-01-03 13:58:30.982 DEBUG: Atoms are too close
2023-01-03 13:58:31.633 DEBUG: Atoms are too close
2023-01-03 13:58:32.057 DEBUG: There is a single atom floating around
2023-01-03 13:58:36.213 DEBUG: Atoms are too close
2023-01-03 13:58:39.930 DEBUG: There is a single atom floating around
2023-01-03 13:58:42.212 DEBUG: Atoms are too close
2023-01-03 13:58:42.533 DEBUG: Atoms are too close
2023-01-03 13:58:43.379 DEBUG: Atoms are too close
2023-01-03 13:58:44.149 DEBUG: Atoms are too close
2023-01-03 13:58:44.480 DEBUG: Atoms are too close
2023-01-03 13:58:44.629 DEBUG: Atoms are too close
2023-01-03 13:58:46.113 DEBUG: Atoms are too close
2023-01-03 13:58:49.593 DEBUG: Atoms are too close
2023-01-03 13:58:49.900 DEBUG: There is a single atom floating around
2023-01-03 13:58:53.780 DEBUG: Atoms are too close
2023-01-03 13:58:54.147 DEBUG: Atoms are too close
2023-01-03 13:58:54.148 DEBUG: Atoms are too close
2023-01-03 13:58:54.149 DEBUG: Atoms are too close
2023-01-03 13:58:55.471 DEBUG: There is a single atom floating around
2023-01-03 13:58:57.968 DEBUG: Atoms are too close
2023-01-03 13:58:58.131 DEBUG: Atoms are too close
2023-01-03 13:59:00.371 DEBUG: Atoms are too close
2023-01-03 13:59:00.456 DEBUG: Atoms are too close
2023-01-03 13:59:01.487 DEBUG: There is a single atom floating around
2023-01-03 13:59:01.833 DEBUG: There is a single atom floating around
2023-01-03 13:59:05.228 DEBUG: Atoms are too close
2023-01-03 13:59:09.332 DEBUG: Atoms are too close
2023-01-03 13:59:09.423 INFO: Training rollout: return=-14.909 (8.4), episode length=4.3
2023-01-03 13:59:09.424 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 13:59:09.428 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-0_train.pkl
2023-01-03 13:59:11.545 DEBUG: Taking gradient step
2023-01-03 13:59:13.697 DEBUG: Loss 0: {'policy_loss': 0.023892916656897994, 'entropy_loss': -0.0838059913367033, 'vf_loss': 0.37468974055697357, 'total_loss': -0.05991307467980531, 'approx_kl': -1.660858650609498e-08, 'clip_fraction': 0.0, 'grad_norm': 18.837032318115234}
2023-01-03 13:59:15.850 DEBUG: Taking gradient step
2023-01-03 13:59:17.998 DEBUG: Loss 1: {'policy_loss': -0.007663087814298093, 'entropy_loss': -0.08295593410730362, 'vf_loss': 0.37468085622212466, 'total_loss': -0.0906190219216017, 'approx_kl': 0.021631340496242046, 'clip_fraction': 0.3763020932674408, 'grad_norm': 14.528306007385254}
2023-01-03 13:59:20.137 DEBUG: Taking gradient step
2023-01-03 13:59:22.301 DEBUG: Loss 2: {'policy_loss': 0.036418486988119704, 'entropy_loss': -0.08193245530128479, 'vf_loss': 0.3423546307623712, 'total_loss': -0.04551396831316509, 'approx_kl': -0.03572928160429001, 'clip_fraction': 0.390625, 'grad_norm': 34.68494415283203}
2023-01-03 13:59:24.397 DEBUG: Taking gradient step
2023-01-03 13:59:26.561 DEBUG: Loss 3: {'policy_loss': 0.15440059486084667, 'entropy_loss': -0.08097670041024685, 'vf_loss': 0.33977172401245476, 'total_loss': 0.07342389445059981, 'approx_kl': -0.03458809247240424, 'clip_fraction': 0.4453125, 'grad_norm': 40.710567474365234}
2023-01-03 13:59:28.688 DEBUG: Taking gradient step
2023-01-03 13:59:30.862 DEBUG: Loss 4: {'policy_loss': 0.18620746250201453, 'entropy_loss': -0.08023495227098465, 'vf_loss': 0.33948053564270336, 'total_loss': 0.1059725102310299, 'approx_kl': -0.06628413870930672, 'clip_fraction': 0.47265625, 'grad_norm': 41.622093200683594}
2023-01-03 13:59:33.097 DEBUG: Taking gradient step
2023-01-03 13:59:35.264 DEBUG: Loss 5: {'policy_loss': 0.13741749960338995, 'entropy_loss': -0.07947717420756817, 'vf_loss': 0.3293643079186726, 'total_loss': 0.05794032539582178, 'approx_kl': -0.040768278762698174, 'clip_fraction': 0.51171875, 'grad_norm': 30.365766525268555}
2023-01-03 13:59:37.471 DEBUG: Taking gradient step
2023-01-03 13:59:39.645 DEBUG: Loss 6: {'policy_loss': 0.12808116387701543, 'entropy_loss': -0.07876071706414223, 'vf_loss': 0.3320692575038713, 'total_loss': 0.049320446812873196, 'approx_kl': -0.06873566657304764, 'clip_fraction': 0.4947916716337204, 'grad_norm': 20.378185272216797}
2023-01-03 13:59:41.787 DEBUG: Taking gradient step
2023-01-03 13:59:43.962 DEBUG: Loss 7: {'policy_loss': 0.11172756066081127, 'entropy_loss': -0.07926338352262974, 'vf_loss': 0.3153628516557451, 'total_loss': 0.032464177138181526, 'approx_kl': -0.08786503178998828, 'clip_fraction': 0.4348958358168602, 'grad_norm': 32.82493209838867}
2023-01-03 13:59:46.077 DEBUG: Taking gradient step
2023-01-03 13:59:48.204 DEBUG: Loss 8: {'policy_loss': 0.07164280501465753, 'entropy_loss': -0.07953484170138836, 'vf_loss': 0.3004340442359935, 'total_loss': -0.007892036686730834, 'approx_kl': -0.08915863931179047, 'clip_fraction': 0.4713541716337204, 'grad_norm': 33.04621887207031}
2023-01-03 13:59:50.473 DEBUG: Taking gradient step
2023-01-03 13:59:52.581 DEBUG: Loss 9: {'policy_loss': 0.1381814430081166, 'entropy_loss': -0.07904903404414654, 'vf_loss': 0.3026067622959673, 'total_loss': 0.059132408963970054, 'approx_kl': -0.10126576572656631, 'clip_fraction': 0.4401041716337204, 'grad_norm': 39.45329666137695}
2023-01-03 13:59:54.698 DEBUG: Taking gradient step
2023-01-03 13:59:57.186 DEBUG: Loss 10: {'policy_loss': 0.0577948810667212, 'entropy_loss': -0.07957055419683456, 'vf_loss': 0.2829351844309482, 'total_loss': -0.021775673130113353, 'approx_kl': -0.0927787683904171, 'clip_fraction': 0.3671875, 'grad_norm': 44.06671905517578}
2023-01-03 13:59:59.457 DEBUG: Taking gradient step
2023-01-03 14:00:01.565 DEBUG: Loss 11: {'policy_loss': 0.04112852328158108, 'entropy_loss': -0.07933416403830051, 'vf_loss': 0.2721395796070553, 'total_loss': -0.038205640756719436, 'approx_kl': -0.07252150680869818, 'clip_fraction': 0.421875, 'grad_norm': 31.474660873413086}
2023-01-03 14:00:03.630 DEBUG: Taking gradient step
2023-01-03 14:00:05.782 DEBUG: Loss 12: {'policy_loss': 0.11868520807206567, 'entropy_loss': -0.07890653423964977, 'vf_loss': 0.27622813224558224, 'total_loss': 0.039778673832415894, 'approx_kl': -0.1178364222869277, 'clip_fraction': 0.5494791716337204, 'grad_norm': 33.683319091796875}
2023-01-03 14:00:07.875 DEBUG: Taking gradient step
2023-01-03 14:00:09.965 DEBUG: Loss 13: {'policy_loss': 0.06957843018247037, 'entropy_loss': -0.07978533208370209, 'vf_loss': 0.26435017795564897, 'total_loss': -0.010206901901231719, 'approx_kl': -0.10272176563739777, 'clip_fraction': 0.4869791716337204, 'grad_norm': 31.470991134643555}
2023-01-03 14:00:12.028 DEBUG: Taking gradient step
2023-01-03 14:00:14.127 DEBUG: Loss 14: {'policy_loss': 0.08491507380495575, 'entropy_loss': -0.07998881116509438, 'vf_loss': 0.25574136296436856, 'total_loss': 0.004926262639861366, 'approx_kl': -0.10739840008318424, 'clip_fraction': 0.5, 'grad_norm': 36.896488189697266}
2023-01-03 14:00:14.128 INFO: Optimization: policy loss=0.085, vf loss=0.256, entropy loss=-0.080, total loss=0.005, num steps=15
2023-01-03 14:00:14.130 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 14:00:15.061 DEBUG: Atoms are too close
2023-01-03 14:00:15.064 INFO: Evaluation rollout: return=-18.129 (0.0), episode length=4.0
2023-01-03 14:00:15.064 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 14:00:15.067 DEBUG: Saving model: runs/CH3NO_dna/models/CH3NO_dna_run-1_steps-216.model
2023-01-03 14:00:15.121 INFO: Iteration: 1/137, steps: 216
2023-01-03 14:00:19.652 DEBUG: There is a single atom floating around
2023-01-03 14:00:25.377 DEBUG: Atoms are too close
2023-01-03 14:00:26.000 DEBUG: Atoms are too close
2023-01-03 14:00:27.291 DEBUG: Atoms are too close
2023-01-03 14:00:28.816 DEBUG: Atoms are too close
2023-01-03 14:00:29.624 DEBUG: Atoms are too close
2023-01-03 14:00:29.625 DEBUG: Atoms are too close
2023-01-03 14:00:30.226 DEBUG: Atoms are too close
2023-01-03 14:00:30.227 DEBUG: Atoms are too close
2023-01-03 14:00:30.228 DEBUG: There is a single atom floating around
2023-01-03 14:00:31.333 DEBUG: There is a single atom floating around
2023-01-03 14:00:31.638 DEBUG: There is a single atom floating around
2023-01-03 14:00:35.545 DEBUG: There is a single atom floating around
2023-01-03 14:00:36.495 DEBUG: There is a single atom floating around
2023-01-03 14:00:36.496 DEBUG: Atoms are too close
2023-01-03 14:00:41.420 DEBUG: Atoms are too close
2023-01-03 14:00:41.421 DEBUG: Atoms are too close
2023-01-03 14:00:45.444 DEBUG: Atoms are too close
2023-01-03 14:00:45.599 DEBUG: Atoms are too close
2023-01-03 14:00:52.242 DEBUG: Atoms are too close
2023-01-03 14:00:52.243 DEBUG: There is a single atom floating around
2023-01-03 14:00:52.571 DEBUG: Atoms are too close
2023-01-03 14:00:54.289 DEBUG: Atoms are too close
2023-01-03 14:00:55.251 DEBUG: Atoms are too close
2023-01-03 14:01:00.420 DEBUG: Atoms are too close
2023-01-03 14:01:03.069 DEBUG: Atoms are too close
2023-01-03 14:01:04.636 DEBUG: Atoms are too close
2023-01-03 14:01:07.312 DEBUG: Atoms are too close
2023-01-03 14:01:07.634 DEBUG: Atoms are too close
2023-01-03 14:01:10.285 INFO: Training rollout: return=-13.077 (9.1), episode length=4.7
2023-01-03 14:01:10.287 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 14:01:10.291 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-216_train.pkl
2023-01-03 14:01:20.635 DEBUG: Taking gradient step
2023-01-03 14:01:30.739 DEBUG: Loss 0: {'policy_loss': -0.012641737020958443, 'entropy_loss': -0.08173724450170994, 'vf_loss': 0.21199149942097248, 'total_loss': -0.09437898152266838, 'approx_kl': -9.320987004457493e-08, 'clip_fraction': 0.0, 'grad_norm': 14.895747184753418}
2023-01-03 14:01:41.437 DEBUG: Taking gradient step
2023-01-03 14:01:51.672 DEBUG: Loss 1: {'policy_loss': -0.0009660307204762304, 'entropy_loss': -0.08243332430720329, 'vf_loss': 0.20306884010445886, 'total_loss': -0.08339935502767953, 'approx_kl': -0.011902132857358083, 'clip_fraction': 0.10416666697710752, 'grad_norm': 19.03467559814453}
2023-01-03 14:02:02.572 DEBUG: Taking gradient step
2023-01-03 14:02:13.231 DEBUG: Loss 2: {'policy_loss': -0.008378878193760729, 'entropy_loss': -0.08260237239301205, 'vf_loss': 0.20426694514816843, 'total_loss': -0.09098125058677278, 'approx_kl': -0.01608574017882347, 'clip_fraction': 0.2291666716337204, 'grad_norm': 17.902446746826172}
2023-01-03 14:02:24.231 DEBUG: Taking gradient step
2023-01-03 14:02:34.830 DEBUG: Loss 3: {'policy_loss': 0.034866698314179316, 'entropy_loss': -0.08239165507256985, 'vf_loss': 0.20562928723338175, 'total_loss': -0.04752495675839054, 'approx_kl': -0.024496208876371384, 'clip_fraction': 0.2552083358168602, 'grad_norm': 14.766268730163574}
2023-01-03 14:02:45.620 DEBUG: Taking gradient step
2023-01-03 14:02:56.191 DEBUG: Loss 4: {'policy_loss': 0.0016906146008975262, 'entropy_loss': -0.08261913433670998, 'vf_loss': 0.19443224336967407, 'total_loss': -0.08092851973581244, 'approx_kl': -0.05314331455156207, 'clip_fraction': 0.29296875, 'grad_norm': 13.595819473266602}
2023-01-03 14:03:06.829 DEBUG: Taking gradient step
2023-01-03 14:03:17.747 DEBUG: Loss 5: {'policy_loss': -0.046814047202279135, 'entropy_loss': -0.08298403397202492, 'vf_loss': 0.1843022289188387, 'total_loss': -0.12979808117430405, 'approx_kl': -0.051227993331849575, 'clip_fraction': 0.33203125, 'grad_norm': 13.139249801635742}
2023-01-03 14:03:28.321 DEBUG: Taking gradient step
2023-01-03 14:03:39.090 DEBUG: Loss 6: {'policy_loss': -0.015009516096642707, 'entropy_loss': -0.0830885712057352, 'vf_loss': 0.18863029205008047, 'total_loss': -0.09809808730237791, 'approx_kl': -0.05411536747124046, 'clip_fraction': 0.3424479216337204, 'grad_norm': 18.808759689331055}
2023-01-03 14:03:49.376 DEBUG: Taking gradient step
2023-01-03 14:03:59.900 DEBUG: Loss 7: {'policy_loss': -0.017761686249111737, 'entropy_loss': -0.08275052160024643, 'vf_loss': 0.17869660009338476, 'total_loss': -0.10051220784935816, 'approx_kl': -0.03985811956226826, 'clip_fraction': 0.4192708358168602, 'grad_norm': 16.253814697265625}
2023-01-03 14:04:10.351 DEBUG: Taking gradient step
2023-01-03 14:04:21.220 DEBUG: Loss 8: {'policy_loss': -0.03855761797374398, 'entropy_loss': -0.08200525492429733, 'vf_loss': 0.1731463490294976, 'total_loss': -0.12056287289804131, 'approx_kl': -0.06664380710572004, 'clip_fraction': 0.4205729216337204, 'grad_norm': 11.390376091003418}
2023-01-03 14:04:31.391 DEBUG: Taking gradient step
2023-01-03 14:04:42.454 DEBUG: Loss 9: {'policy_loss': -0.023153250166020947, 'entropy_loss': -0.08157096989452839, 'vf_loss': 0.17097187393340607, 'total_loss': -0.10472422006054935, 'approx_kl': -0.06516638211905956, 'clip_fraction': 0.3971354216337204, 'grad_norm': 16.08531379699707}
2023-01-03 14:04:53.277 DEBUG: Taking gradient step
2023-01-03 14:05:04.177 DEBUG: Loss 10: {'policy_loss': -0.09512370217145469, 'entropy_loss': -0.08172797039151192, 'vf_loss': 0.15760091686592276, 'total_loss': -0.1768516725629666, 'approx_kl': -0.10359837114810944, 'clip_fraction': 0.4388020932674408, 'grad_norm': 11.621720314025879}
2023-01-03 14:05:14.694 DEBUG: Taking gradient step
2023-01-03 14:05:25.588 DEBUG: Loss 11: {'policy_loss': 0.023126692288231436, 'entropy_loss': -0.08042580075562, 'vf_loss': 0.1580505487100929, 'total_loss': -0.05729910846738856, 'approx_kl': -0.07936718268319964, 'clip_fraction': 0.3528645858168602, 'grad_norm': 14.532723426818848}
2023-01-03 14:05:35.881 DEBUG: Taking gradient step
2023-01-03 14:05:46.620 DEBUG: Loss 12: {'policy_loss': -0.0031059823361641765, 'entropy_loss': -0.0797528438270092, 'vf_loss': 0.15177908234082418, 'total_loss': -0.08285882616317337, 'approx_kl': -0.07171790557913482, 'clip_fraction': 0.2578125, 'grad_norm': 17.62938117980957}
2023-01-03 14:05:57.430 DEBUG: Taking gradient step
2023-01-03 14:06:07.691 DEBUG: Loss 13: {'policy_loss': -0.007409076452895409, 'entropy_loss': -0.08117243088781834, 'vf_loss': 0.1451351646549921, 'total_loss': -0.08858150734071374, 'approx_kl': -0.09854204021394253, 'clip_fraction': 0.34375, 'grad_norm': 13.214217185974121}
2023-01-03 14:06:18.946 DEBUG: Taking gradient step
2023-01-03 14:06:29.604 DEBUG: Loss 14: {'policy_loss': 0.018548772809606262, 'entropy_loss': -0.07977462187409401, 'vf_loss': 0.14224670735864794, 'total_loss': -0.06122584906448775, 'approx_kl': -0.07521208375692368, 'clip_fraction': 0.3997395858168602, 'grad_norm': 12.029168128967285}
2023-01-03 14:06:29.605 INFO: Optimization: policy loss=0.019, vf loss=0.142, entropy loss=-0.080, total loss=-0.061, num steps=15
2023-01-03 14:06:29.607 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 14:06:30.854 DEBUG: Atoms are too close
2023-01-03 14:06:30.857 INFO: Evaluation rollout: return=-18.134 (0.0), episode length=4.0
2023-01-03 14:06:30.857 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 14:06:30.860 INFO: Iteration: 2/137, steps: 432
2023-01-03 14:06:33.637 DEBUG: There is a single atom floating around
2023-01-03 14:06:34.642 DEBUG: There is a single atom floating around
2023-01-03 14:06:43.888 DEBUG: Atoms are too close
2023-01-03 14:06:44.225 DEBUG: Atoms are too close
2023-01-03 14:06:45.968 DEBUG: Atoms are too close
2023-01-03 14:06:46.291 DEBUG: Atoms are too close
2023-01-03 14:06:46.293 DEBUG: Atoms are too close
2023-01-03 14:06:48.421 DEBUG: Atoms are too close
2023-01-03 14:06:48.423 DEBUG: Atoms are too close
2023-01-03 14:06:49.932 DEBUG: Atoms are too close
2023-01-03 14:06:57.744 DEBUG: There is a single atom floating around
2023-01-03 14:06:58.983 DEBUG: Atoms are too close
2023-01-03 14:06:58.985 DEBUG: There is a single atom floating around
2023-01-03 14:07:00.664 DEBUG: Atoms are too close
2023-01-03 14:07:02.595 DEBUG: Atoms are too close
2023-01-03 14:07:02.596 DEBUG: Atoms are too close
2023-01-03 14:07:02.949 DEBUG: Atoms are too close
2023-01-03 14:07:02.950 DEBUG: Atoms are too close
2023-01-03 14:07:09.748 DEBUG: There is a single atom floating around
2023-01-03 14:07:14.525 DEBUG: Atoms are too close
2023-01-03 14:07:14.527 DEBUG: Atoms are too close
2023-01-03 14:07:15.741 DEBUG: Atoms are too close
2023-01-03 14:07:21.564 DEBUG: There is a single atom floating around
2023-01-03 14:07:25.109 DEBUG: Atoms are too close
2023-01-03 14:07:27.796 DEBUG: Atoms are too close
2023-01-03 14:07:29.878 DEBUG: Atoms are too close
2023-01-03 14:07:31.426 DEBUG: Atoms are too close
2023-01-03 14:07:33.389 INFO: Training rollout: return=-11.875 (9.2), episode length=4.8
2023-01-03 14:07:33.391 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 14:07:33.396 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-432_train.pkl
2023-01-03 14:07:44.229 DEBUG: Taking gradient step
2023-01-03 14:07:54.881 DEBUG: Loss 0: {'policy_loss': -0.026985725826392554, 'entropy_loss': -0.07863934338092804, 'vf_loss': 0.144000664243661, 'total_loss': -0.1056250692073206, 'approx_kl': -2.1692055263144994e-08, 'clip_fraction': 0.0, 'grad_norm': 24.41148567199707}
2023-01-03 14:08:01.610 DEBUG: Taking gradient step
2023-01-03 14:08:03.813 DEBUG: Loss 1: {'policy_loss': -0.06444431019536456, 'entropy_loss': -0.07727569155395031, 'vf_loss': 0.13910747292083547, 'total_loss': -0.14172000174931487, 'approx_kl': -0.020065738121047616, 'clip_fraction': 0.1419270858168602, 'grad_norm': 17.856796264648438}
2023-01-03 14:08:06.062 DEBUG: Taking gradient step
2023-01-03 14:08:08.267 DEBUG: Loss 2: {'policy_loss': -0.012596512390082013, 'entropy_loss': -0.07829761505126953, 'vf_loss': 0.13710440062289797, 'total_loss': -0.09089412744135154, 'approx_kl': -0.030829683877527714, 'clip_fraction': 0.2213541679084301, 'grad_norm': 14.977551460266113}
2023-01-03 14:08:10.595 DEBUG: Taking gradient step
2023-01-03 14:08:12.922 DEBUG: Loss 3: {'policy_loss': -0.01986020335663807, 'entropy_loss': -0.07669915445148945, 'vf_loss': 0.13122992062837302, 'total_loss': -0.09655935780812752, 'approx_kl': 0.013230355456471443, 'clip_fraction': 0.3307291716337204, 'grad_norm': 18.598281860351562}
2023-01-03 14:08:15.076 DEBUG: Taking gradient step
2023-01-03 14:08:17.401 DEBUG: Loss 4: {'policy_loss': 0.04239600072270241, 'entropy_loss': -0.07769125141203403, 'vf_loss': 0.1305934722855512, 'total_loss': -0.035295250689331634, 'approx_kl': -0.01154735591262579, 'clip_fraction': 0.375, 'grad_norm': 18.014406204223633}
2023-01-03 14:08:19.546 DEBUG: Taking gradient step
2023-01-03 14:08:21.783 DEBUG: Loss 5: {'policy_loss': 0.06327791023202749, 'entropy_loss': -0.07739217579364777, 'vf_loss': 0.13014729427894067, 'total_loss': -0.014114265561620279, 'approx_kl': -0.04228152986615896, 'clip_fraction': 0.39453125, 'grad_norm': 24.833890914916992}
2023-01-03 14:08:23.938 DEBUG: Taking gradient step
2023-01-03 14:08:26.150 DEBUG: Loss 6: {'policy_loss': 0.028204314487558817, 'entropy_loss': -0.07689650356769562, 'vf_loss': 0.13445478977468897, 'total_loss': -0.0486921890801368, 'approx_kl': -0.029863005504012108, 'clip_fraction': 0.4231770858168602, 'grad_norm': 16.625164031982422}
2023-01-03 14:08:28.329 DEBUG: Taking gradient step
2023-01-03 14:08:30.534 DEBUG: Loss 7: {'policy_loss': -0.010738778489299279, 'entropy_loss': -0.07883295975625515, 'vf_loss': 0.13026730612080503, 'total_loss': -0.08957173824555442, 'approx_kl': -0.07704839063808322, 'clip_fraction': 0.4309895858168602, 'grad_norm': 14.470572471618652}
2023-01-03 14:08:32.696 DEBUG: Taking gradient step
2023-01-03 14:08:34.901 DEBUG: Loss 8: {'policy_loss': 0.043173261403180535, 'entropy_loss': -0.07883384265005589, 'vf_loss': 0.13496832255374724, 'total_loss': -0.03566058124687535, 'approx_kl': -0.0799956051632762, 'clip_fraction': 0.4283854216337204, 'grad_norm': 20.29852867126465}
2023-01-03 14:08:37.088 DEBUG: Taking gradient step
2023-01-03 14:08:39.351 DEBUG: Loss 9: {'policy_loss': 0.06328623550593138, 'entropy_loss': -0.07790115289390087, 'vf_loss': 0.13031532068369867, 'total_loss': -0.014614917387969488, 'approx_kl': -0.054218901321291924, 'clip_fraction': 0.4361979216337204, 'grad_norm': 18.319517135620117}
2023-01-03 14:08:41.536 DEBUG: Taking gradient step
2023-01-03 14:08:43.796 DEBUG: Loss 10: {'policy_loss': -0.03507523722197223, 'entropy_loss': -0.07819027081131935, 'vf_loss': 0.1276914460366211, 'total_loss': -0.11326550803329158, 'approx_kl': -0.08792713563889265, 'clip_fraction': 0.4322916716337204, 'grad_norm': 15.716797828674316}
2023-01-03 14:08:46.024 DEBUG: Taking gradient step
2023-01-03 14:08:48.347 DEBUG: Loss 11: {'policy_loss': -0.021218355615606088, 'entropy_loss': -0.07725546509027481, 'vf_loss': 0.12945474932636375, 'total_loss': -0.0984738207058809, 'approx_kl': -0.10883178934454918, 'clip_fraction': 0.4296875, 'grad_norm': 13.420937538146973}
2023-01-03 14:08:50.654 DEBUG: Taking gradient step
2023-01-03 14:08:52.913 DEBUG: Loss 12: {'policy_loss': 0.060919117567241776, 'entropy_loss': -0.07762848772108555, 'vf_loss': 0.12956289836210777, 'total_loss': -0.016709370153843772, 'approx_kl': -0.11107593774795532, 'clip_fraction': 0.4817708432674408, 'grad_norm': 16.131752014160156}
2023-01-03 14:08:55.126 DEBUG: Taking gradient step
2023-01-03 14:09:04.915 DEBUG: Loss 13: {'policy_loss': 0.006090243732490702, 'entropy_loss': -0.07888813503086567, 'vf_loss': 0.12261883767451415, 'total_loss': -0.07279789129837497, 'approx_kl': -0.09219183307141066, 'clip_fraction': 0.5130208432674408, 'grad_norm': 17.608999252319336}
2023-01-03 14:09:15.371 DEBUG: Taking gradient step
2023-01-03 14:09:27.033 DEBUG: Loss 14: {'policy_loss': 0.018190442803165986, 'entropy_loss': -0.07882498949766159, 'vf_loss': 0.12815540818747526, 'total_loss': -0.060634546694495604, 'approx_kl': -0.10092270839959383, 'clip_fraction': 0.5338541716337204, 'grad_norm': 16.041933059692383}
2023-01-03 14:09:27.034 INFO: Optimization: policy loss=0.018, vf loss=0.128, entropy loss=-0.079, total loss=-0.061, num steps=15
2023-01-03 14:09:27.035 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 14:09:28.892 DEBUG: Atoms are too close
2023-01-03 14:09:28.894 INFO: Evaluation rollout: return=-12.911 (0.0), episode length=6.0
2023-01-03 14:09:28.894 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 14:09:28.897 INFO: Iteration: 3/137, steps: 648
2023-01-03 14:09:31.906 DEBUG: There is a single atom floating around
2023-01-03 14:09:32.763 DEBUG: There is a single atom floating around
2023-01-03 14:09:33.052 DEBUG: There is a single atom floating around
2023-01-03 14:09:33.053 DEBUG: There is a single atom floating around
2023-01-03 14:09:33.053 DEBUG: There is a single atom floating around
2023-01-03 14:09:38.382 DEBUG: There is a single atom floating around
2023-01-03 14:09:38.384 DEBUG: Atoms are too close
2023-01-03 14:09:39.680 DEBUG: Atoms are too close
2023-01-03 14:09:40.516 DEBUG: Atoms are too close
2023-01-03 14:09:43.385 DEBUG: Atoms are too close
2023-01-03 14:09:48.346 DEBUG: Atoms are too close
2023-01-03 14:09:50.965 DEBUG: Atoms are too close
2023-01-03 14:09:52.446 DEBUG: Atoms are too close
2023-01-03 14:09:55.521 DEBUG: Atoms are too close
2023-01-03 14:09:58.027 DEBUG: Atoms are too close
2023-01-03 14:10:02.498 DEBUG: Atoms are too close
2023-01-03 14:10:03.496 DEBUG: Atoms are too close
2023-01-03 14:10:03.497 DEBUG: Atoms are too close
2023-01-03 14:10:06.620 DEBUG: Atoms are too close
2023-01-03 14:10:08.490 DEBUG: There is a single atom floating around
2023-01-03 14:10:09.064 DEBUG: Atoms are too close
2023-01-03 14:10:10.964 DEBUG: Atoms are too close
2023-01-03 14:10:15.988 DEBUG: Atoms are too close
2023-01-03 14:10:18.707 DEBUG: There is a single atom floating around
2023-01-03 14:10:22.259 DEBUG: Atoms are too close
2023-01-03 14:10:22.802 DEBUG: Atoms are too close
2023-01-03 14:10:23.379 INFO: Training rollout: return=-11.914 (9.8), episode length=4.7
2023-01-03 14:10:23.380 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 14:10:23.382 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-648_train.pkl
2023-01-03 14:10:35.314 DEBUG: Taking gradient step
2023-01-03 14:10:46.663 DEBUG: Loss 0: {'policy_loss': 0.013688503052717352, 'entropy_loss': -0.07948845066130161, 'vf_loss': 0.13890149295942034, 'total_loss': -0.06579994760858426, 'approx_kl': -2.7474015951156616e-08, 'clip_fraction': 0.0, 'grad_norm': 21.71302032470703}
2023-01-03 14:10:57.767 DEBUG: Taking gradient step
2023-01-03 14:11:08.900 DEBUG: Loss 1: {'policy_loss': 0.04700487024799821, 'entropy_loss': -0.08053261041641235, 'vf_loss': 0.13891577046348463, 'total_loss': -0.03352774016841414, 'approx_kl': -0.012135402532294393, 'clip_fraction': 0.078125, 'grad_norm': 21.192201614379883}
2023-01-03 14:11:20.914 DEBUG: Taking gradient step
2023-01-03 14:11:31.851 DEBUG: Loss 2: {'policy_loss': 0.039838351873991304, 'entropy_loss': -0.08094349876046181, 'vf_loss': 0.1371581137857677, 'total_loss': -0.0411051468864705, 'approx_kl': -0.031607349403202534, 'clip_fraction': 0.3125, 'grad_norm': 24.178075790405273}
2023-01-03 14:11:43.811 DEBUG: Taking gradient step
2023-01-03 14:11:54.740 DEBUG: Loss 3: {'policy_loss': -0.029925312586357458, 'entropy_loss': -0.07931932806968689, 'vf_loss': 0.13947682016903634, 'total_loss': -0.10924464065604435, 'approx_kl': -0.061127218417823315, 'clip_fraction': 0.3971354216337204, 'grad_norm': 21.26144790649414}
2023-01-03 14:12:06.665 DEBUG: Taking gradient step
2023-01-03 14:12:15.514 DEBUG: Loss 4: {'policy_loss': 0.026363997318210656, 'entropy_loss': -0.0805647186934948, 'vf_loss': 0.13088486758871043, 'total_loss': -0.054200721375284144, 'approx_kl': -0.06318997777998447, 'clip_fraction': 0.39453125, 'grad_norm': 18.53507423400879}
2023-01-03 14:12:17.453 DEBUG: Taking gradient step
2023-01-03 14:12:19.452 DEBUG: Loss 5: {'policy_loss': -0.0007021363556745305, 'entropy_loss': -0.07938108034431934, 'vf_loss': 0.1275706609907099, 'total_loss': -0.08008321669999387, 'approx_kl': -0.055829368997365236, 'clip_fraction': 0.4388020932674408, 'grad_norm': 16.398969650268555}
2023-01-03 14:12:21.404 DEBUG: Taking gradient step
2023-01-03 14:12:23.408 DEBUG: Loss 6: {'policy_loss': 0.014554935864769095, 'entropy_loss': -0.0800420232117176, 'vf_loss': 0.13530285943006534, 'total_loss': -0.06548708734694851, 'approx_kl': -0.0555260144174099, 'clip_fraction': 0.44921875, 'grad_norm': 20.724266052246094}
2023-01-03 14:12:25.344 DEBUG: Taking gradient step
2023-01-03 14:12:27.353 DEBUG: Loss 7: {'policy_loss': 0.044488951462633576, 'entropy_loss': -0.0798178631812334, 'vf_loss': 0.13115189173051356, 'total_loss': -0.03532891171859984, 'approx_kl': -0.07103402190841734, 'clip_fraction': 0.4713541716337204, 'grad_norm': 20.179729461669922}
2023-01-03 14:12:29.302 DEBUG: Taking gradient step
2023-01-03 14:12:31.286 DEBUG: Loss 8: {'policy_loss': 0.032103357901715396, 'entropy_loss': -0.07813900895416737, 'vf_loss': 0.1268466123301874, 'total_loss': -0.04603565105245198, 'approx_kl': -0.10555214621126652, 'clip_fraction': 0.5690104216337204, 'grad_norm': 19.004934310913086}
2023-01-03 14:12:33.314 DEBUG: Taking gradient step
2023-01-03 14:12:35.310 DEBUG: Loss 9: {'policy_loss': 0.03179719503989351, 'entropy_loss': -0.07887015119194984, 'vf_loss': 0.13278884045408895, 'total_loss': -0.047072956152056325, 'approx_kl': -0.08264440670609474, 'clip_fraction': 0.53515625, 'grad_norm': 16.238149642944336}
2023-01-03 14:12:37.246 DEBUG: Taking gradient step
2023-01-03 14:12:39.225 DEBUG: Loss 10: {'policy_loss': 0.06578440688809074, 'entropy_loss': -0.07785360887646675, 'vf_loss': 0.13551674937915625, 'total_loss': -0.012069201988376008, 'approx_kl': -0.0795625252649188, 'clip_fraction': 0.55859375, 'grad_norm': 13.315347671508789}
2023-01-03 14:12:41.160 DEBUG: Taking gradient step
2023-01-03 14:12:43.141 DEBUG: Loss 11: {'policy_loss': -0.0019206553758253087, 'entropy_loss': -0.07864115387201309, 'vf_loss': 0.13081844157978503, 'total_loss': -0.0805618092478384, 'approx_kl': -0.09895530715584755, 'clip_fraction': 0.38671875, 'grad_norm': 15.762322425842285}
2023-01-03 14:12:45.077 DEBUG: Taking gradient step
2023-01-03 14:12:47.055 DEBUG: Loss 12: {'policy_loss': 0.022448135858288615, 'entropy_loss': -0.07834355160593987, 'vf_loss': 0.12904568964034427, 'total_loss': -0.05589541574765125, 'approx_kl': -0.11537149921059608, 'clip_fraction': 0.4205729216337204, 'grad_norm': 15.276993751525879}
2023-01-03 14:12:49.015 DEBUG: Taking gradient step
2023-01-03 14:12:51.042 DEBUG: Loss 13: {'policy_loss': 0.03455372301159562, 'entropy_loss': -0.07917639426887035, 'vf_loss': 0.12785631030526223, 'total_loss': -0.04462267125727474, 'approx_kl': -0.10589267127215862, 'clip_fraction': 0.5169270932674408, 'grad_norm': 16.74818992614746}
2023-01-03 14:12:52.996 DEBUG: Taking gradient step
2023-01-03 14:12:54.997 DEBUG: Loss 14: {'policy_loss': -0.01595119614222315, 'entropy_loss': -0.07816797867417336, 'vf_loss': 0.128115870476249, 'total_loss': -0.0941191748163965, 'approx_kl': -0.1255035512149334, 'clip_fraction': 0.51953125, 'grad_norm': 16.16606330871582}
2023-01-03 14:12:54.997 INFO: Optimization: policy loss=-0.016, vf loss=0.128, entropy loss=-0.078, total loss=-0.094, num steps=15
2023-01-03 14:12:54.998 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 14:12:55.786 DEBUG: Atoms are too close
2023-01-03 14:12:55.788 INFO: Evaluation rollout: return=-18.128 (0.0), episode length=4.0
2023-01-03 14:12:55.788 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 14:12:55.790 INFO: Iteration: 4/137, steps: 864
2023-01-03 14:13:04.554 DEBUG: Atoms are too close
2023-01-03 14:13:07.472 DEBUG: Atoms are too close
2023-01-03 14:13:10.637 DEBUG: Atoms are too close
2023-01-03 14:13:20.427 DEBUG: There is a single atom floating around
2023-01-03 14:13:20.715 DEBUG: Atoms are too close
2023-01-03 14:13:21.208 DEBUG: Atoms are too close
2023-01-03 14:13:21.209 DEBUG: Atoms are too close
2023-01-03 14:13:24.543 DEBUG: Atoms are too close
2023-01-03 14:13:25.969 DEBUG: There is a single atom floating around
2023-01-03 14:13:25.972 DEBUG: Atoms are too close
2023-01-03 14:13:26.760 DEBUG: There is a single atom floating around
2023-01-03 14:13:27.054 DEBUG: Atoms are too close
2023-01-03 14:13:32.401 DEBUG: Atoms are too close
2023-01-03 14:13:36.796 DEBUG: Atoms are too close
2023-01-03 14:13:44.464 DEBUG: Atoms are too close
2023-01-03 14:13:46.196 DEBUG: Atoms are too close
2023-01-03 14:13:47.235 DEBUG: Atoms are too close
2023-01-03 14:13:51.272 DEBUG: Atoms are too close
2023-01-03 14:13:51.273 DEBUG: Atoms are too close
2023-01-03 14:13:51.274 DEBUG: Atoms are too close
2023-01-03 14:13:52.643 INFO: Training rollout: return=-8.976 (9.3), episode length=5.1
2023-01-03 14:13:52.645 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 14:13:52.648 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-864_train.pkl
2023-01-03 14:14:05.109 DEBUG: Taking gradient step
2023-01-03 14:14:17.564 DEBUG: Loss 0: {'policy_loss': -0.0016752240917382597, 'entropy_loss': -0.0794454924762249, 'vf_loss': 0.13306593104311942, 'total_loss': -0.08112071656796316, 'approx_kl': -5.386149126707096e-08, 'clip_fraction': 0.0, 'grad_norm': 11.89826488494873}
2023-01-03 14:14:29.999 DEBUG: Taking gradient step
2023-01-03 14:14:42.356 DEBUG: Loss 1: {'policy_loss': -0.0010448106879832, 'entropy_loss': -0.0798225849866867, 'vf_loss': 0.1272177366234207, 'total_loss': -0.0808673956746699, 'approx_kl': -0.006122333230450749, 'clip_fraction': 0.15234375, 'grad_norm': 15.091898918151855}
2023-01-03 14:14:54.470 DEBUG: Taking gradient step
2023-01-03 14:15:06.937 DEBUG: Loss 2: {'policy_loss': -0.02116898396440028, 'entropy_loss': -0.0794424507766962, 'vf_loss': 0.12690320822460563, 'total_loss': -0.10061143474109649, 'approx_kl': -0.018414348363876343, 'clip_fraction': 0.29296875, 'grad_norm': 14.54416561126709}
2023-01-03 14:15:19.567 DEBUG: Taking gradient step
2023-01-03 14:15:32.274 DEBUG: Loss 3: {'policy_loss': 0.056876530631311956, 'entropy_loss': -0.07863420061767101, 'vf_loss': 0.1355396806386124, 'total_loss': -0.021757669986359057, 'approx_kl': -0.03145480528473854, 'clip_fraction': 0.4309895858168602, 'grad_norm': 21.136823654174805}
2023-01-03 14:15:45.278 DEBUG: Taking gradient step
2023-01-03 14:15:58.081 DEBUG: Loss 4: {'policy_loss': -0.0004340192777004051, 'entropy_loss': -0.08076098375022411, 'vf_loss': 0.12634003340207917, 'total_loss': -0.08119500302792451, 'approx_kl': -0.016360869398340583, 'clip_fraction': 0.4401041716337204, 'grad_norm': 14.947746276855469}
2023-01-03 14:16:10.822 DEBUG: Taking gradient step
2023-01-03 14:16:23.466 DEBUG: Loss 5: {'policy_loss': 0.09687287450810952, 'entropy_loss': -0.08000978641211987, 'vf_loss': 0.1403397966028475, 'total_loss': 0.016863088095989645, 'approx_kl': -0.032937795389443636, 'clip_fraction': 0.46484375, 'grad_norm': 23.01389503479004}
2023-01-03 14:16:26.526 DEBUG: Taking gradient step
2023-01-03 14:16:28.585 DEBUG: Loss 6: {'policy_loss': 0.046123767124645686, 'entropy_loss': -0.08019652217626572, 'vf_loss': 0.1251837301720033, 'total_loss': -0.03407275505162003, 'approx_kl': -0.042652343865484, 'clip_fraction': 0.5546875, 'grad_norm': 14.899724006652832}
2023-01-03 14:16:30.605 DEBUG: Taking gradient step
2023-01-03 14:16:32.722 DEBUG: Loss 7: {'policy_loss': 0.017770835199367972, 'entropy_loss': -0.08033832721412182, 'vf_loss': 0.12399869638148896, 'total_loss': -0.06256749201475385, 'approx_kl': -0.06487756362184882, 'clip_fraction': 0.5598958432674408, 'grad_norm': 10.743124961853027}
2023-01-03 14:16:34.709 DEBUG: Taking gradient step
2023-01-03 14:16:36.748 DEBUG: Loss 8: {'policy_loss': 0.02914721602323219, 'entropy_loss': -0.0798328872770071, 'vf_loss': 0.1287642687070184, 'total_loss': -0.05068567125377491, 'approx_kl': -0.0634330902248621, 'clip_fraction': 0.49609375, 'grad_norm': 20.6842041015625}
2023-01-03 14:16:38.726 DEBUG: Taking gradient step
2023-01-03 14:16:40.765 DEBUG: Loss 9: {'policy_loss': 0.009430092355315445, 'entropy_loss': -0.08046633191406727, 'vf_loss': 0.12237910112463755, 'total_loss': -0.07103623955875182, 'approx_kl': -0.05139509309083223, 'clip_fraction': 0.4440104216337204, 'grad_norm': 20.22700309753418}
2023-01-03 14:16:42.747 DEBUG: Taking gradient step
2023-01-03 14:16:44.768 DEBUG: Loss 10: {'policy_loss': 0.06590927523757818, 'entropy_loss': -0.07932893373072147, 'vf_loss': 0.13174935878739596, 'total_loss': -0.013419658493143298, 'approx_kl': -0.05296231247484684, 'clip_fraction': 0.3932291716337204, 'grad_norm': 16.660524368286133}
2023-01-03 14:16:46.831 DEBUG: Taking gradient step
2023-01-03 14:16:49.256 DEBUG: Loss 11: {'policy_loss': 0.03580993251262412, 'entropy_loss': -0.07974931225180626, 'vf_loss': 0.12891609159299447, 'total_loss': -0.04393937973918213, 'approx_kl': -0.06864647706970572, 'clip_fraction': 0.4375, 'grad_norm': 21.506654739379883}
2023-01-03 14:16:51.629 DEBUG: Taking gradient step
2023-01-03 14:16:54.077 DEBUG: Loss 12: {'policy_loss': 0.006218422822135403, 'entropy_loss': -0.08025571890175343, 'vf_loss': 0.1274524285520312, 'total_loss': -0.07403729607961802, 'approx_kl': -0.09960202313959599, 'clip_fraction': 0.4479166716337204, 'grad_norm': 17.9404296875}
2023-01-03 14:16:56.460 DEBUG: Taking gradient step
2023-01-03 14:16:58.891 DEBUG: Loss 13: {'policy_loss': 0.016286775662767636, 'entropy_loss': -0.07952546142041683, 'vf_loss': 0.12736116268983555, 'total_loss': -0.0632386857576492, 'approx_kl': -0.08803672716021538, 'clip_fraction': 0.4361979216337204, 'grad_norm': 17.903724670410156}
2023-01-03 14:17:01.252 DEBUG: Taking gradient step
2023-01-03 14:17:03.284 DEBUG: Loss 14: {'policy_loss': 0.013073583892651328, 'entropy_loss': -0.08052237704396248, 'vf_loss': 0.12346861766360334, 'total_loss': -0.06744879315131115, 'approx_kl': -0.10488896071910858, 'clip_fraction': 0.46484375, 'grad_norm': 15.64068603515625}
2023-01-03 14:17:03.284 INFO: Optimization: policy loss=0.013, vf loss=0.123, entropy loss=-0.081, total loss=-0.067, num steps=15
2023-01-03 14:17:03.285 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 14:17:04.057 DEBUG: Atoms are too close
2023-01-03 14:17:04.059 INFO: Evaluation rollout: return=-18.134 (0.0), episode length=4.0
2023-01-03 14:17:04.059 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 14:17:04.061 INFO: Iteration: 5/137, steps: 1080
2023-01-03 14:17:06.664 DEBUG: There is a single atom floating around
2023-01-03 14:17:23.857 INFO: {
    "bag_scale": 6,
    "beta": "-10",
    "canvas_size": 6,
    "clip_ratio": 0.2,
    "cutoff": 4.0,
    "data_dir": "runs/CH3NO_dna/data",
    "device": "cuda",
    "discount": 0.85,
    "entropy_coef": 0.06,
    "eval_formulas": "CH3NO",
    "eval_freq": 1,
    "formulas": "CH3NO",
    "gradient_clip": 0.5,
    "keep_models": false,
    "lam": 0.95,
    "learning_rate": 0.0005,
    "load_latest": false,
    "load_model": null,
    "log_dir": "runs/CH3NO_dna/logs",
    "log_level": "DEBUG",
    "max_mean_distance": 1.8,
    "max_num_steps": 30000,
    "max_num_train_iters": 15,
    "max_solo_distance": 2.0,
    "maxl": 4,
    "min_atomic_distance": 0.6,
    "min_mean_distance": 0.8,
    "min_reward": -30.0,
    "mini_batch_size": 64,
    "model": "schnet_edge",
    "model_dir": "runs/CH3NO_dna/models",
    "name": "CH3NO_dna",
    "network_width": 128,
    "num_cg_levels": 3,
    "num_channels_hidden": 10,
    "num_channels_per_element": 4,
    "num_envs": 12,
    "num_eval_episodes": null,
    "num_gaussians": 3,
    "num_interactions": 3,
    "num_steps_per_iter": 216,
    "optimizer": "adam",
    "results_dir": "runs/CH3NO_dna/results",
    "save_freq": 10,
    "save_rollouts": "train",
    "seed": 1,
    "symbols": "X,H,C,N,O",
    "target_kl": 0.03,
    "update_edges": true,
    "vf_coef": 0.0003
}
2023-01-03 14:17:23.899 INFO: CUDA Device: 0
2023-01-03 14:17:23.900 INFO: Training bags: ['CH3NO']
2023-01-03 14:17:23.900 INFO: Evaluation bags: ['CH3NO']
2023-01-03 14:17:25.778 INFO: Number of parameters: 549407
2023-01-03 14:17:25.792 INFO: Starting PPO
2023-01-03 14:17:25.792 INFO: Iteration: 0/137, steps: 0
2023-01-03 14:17:29.031 DEBUG: There is a single atom floating around
2023-01-03 14:17:30.164 DEBUG: There is a single atom floating around
2023-01-03 14:17:31.302 DEBUG: There is a single atom floating around
2023-01-03 14:17:33.933 DEBUG: Atoms are too close
2023-01-03 14:17:35.578 DEBUG: Atoms are too close
2023-01-03 14:17:36.151 DEBUG: Atoms are too close
2023-01-03 14:17:36.154 DEBUG: Atoms are too close
2023-01-03 14:17:38.516 DEBUG: Atoms are too close
2023-01-03 14:17:39.119 DEBUG: Atoms are too close
2023-01-03 14:17:39.473 DEBUG: There is a single atom floating around
2023-01-03 14:17:43.071 DEBUG: Atoms are too close
2023-01-03 14:17:46.431 DEBUG: There is a single atom floating around
2023-01-03 14:17:48.466 DEBUG: Atoms are too close
2023-01-03 14:17:48.748 DEBUG: Atoms are too close
2023-01-03 14:17:49.464 DEBUG: Atoms are too close
2023-01-03 14:17:50.100 DEBUG: Atoms are too close
2023-01-03 14:17:50.384 DEBUG: Atoms are too close
2023-01-03 14:17:50.529 DEBUG: Atoms are too close
2023-01-03 14:17:51.806 DEBUG: Atoms are too close
2023-01-03 14:17:54.882 DEBUG: Atoms are too close
2023-01-03 14:17:55.167 DEBUG: There is a single atom floating around
2023-01-03 14:17:58.608 DEBUG: Atoms are too close
2023-01-03 14:17:58.889 DEBUG: Atoms are too close
2023-01-03 14:17:58.891 DEBUG: Atoms are too close
2023-01-03 14:17:58.891 DEBUG: Atoms are too close
2023-01-03 14:18:00.077 DEBUG: There is a single atom floating around
2023-01-03 14:18:02.488 DEBUG: Atoms are too close
2023-01-03 14:18:02.633 DEBUG: Atoms are too close
2023-01-03 14:18:04.656 DEBUG: Atoms are too close
2023-01-03 14:18:04.726 DEBUG: Atoms are too close
2023-01-03 14:18:05.563 DEBUG: There is a single atom floating around
2023-01-03 14:18:05.882 DEBUG: There is a single atom floating around
2023-01-03 14:18:08.793 DEBUG: Atoms are too close
2023-01-03 14:18:12.556 DEBUG: Atoms are too close
2023-01-03 14:18:12.640 INFO: Training rollout: return=-14.909 (8.4), episode length=4.3
2023-01-03 14:18:12.641 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 14:18:12.644 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-0_train.pkl
2023-01-03 14:18:14.512 DEBUG: Taking gradient step
2023-01-03 14:18:23.309 DEBUG: Loss 0: {'policy_loss': 0.023892926914085927, 'entropy_loss': -0.0838059913367033, 'vf_loss': 0.11240692210993038, 'total_loss': -0.05991306442261737, 'approx_kl': -3.4924596548080444e-09, 'clip_fraction': 0.0, 'grad_norm': 18.828250885009766}
2023-01-03 14:18:34.640 DEBUG: Taking gradient step
2023-01-03 14:18:44.986 DEBUG: Loss 1: {'policy_loss': -0.007661375290858946, 'entropy_loss': -0.08295601047575474, 'vf_loss': 0.11240425874847143, 'total_loss': -0.09061738576661368, 'approx_kl': 0.02163858781568706, 'clip_fraction': 0.3763020932674408, 'grad_norm': 14.517477989196777}
2023-01-03 14:18:56.340 DEBUG: Taking gradient step
2023-01-03 14:19:08.241 DEBUG: Loss 2: {'policy_loss': 0.03640956213109731, 'entropy_loss': -0.08193276263773441, 'vf_loss': 0.10270649391862054, 'total_loss': -0.04552320050663711, 'approx_kl': -0.03572055883705616, 'clip_fraction': 0.390625, 'grad_norm': 34.68006896972656}
2023-01-03 14:19:19.253 DEBUG: Taking gradient step
2023-01-03 14:19:31.228 DEBUG: Loss 3: {'policy_loss': 0.1543817617420557, 'entropy_loss': -0.08097715862095356, 'vf_loss': 0.10193198178927178, 'total_loss': 0.07340460312110214, 'approx_kl': -0.034582579508423805, 'clip_fraction': 0.4453125, 'grad_norm': 40.70564270019531}
2023-01-03 14:19:43.495 DEBUG: Taking gradient step
2023-01-03 14:19:55.580 DEBUG: Loss 4: {'policy_loss': 0.18617777656513032, 'entropy_loss': -0.08023547753691673, 'vf_loss': 0.10184552517561991, 'total_loss': 0.10594229902821362, 'approx_kl': -0.06628132937476039, 'clip_fraction': 0.47265625, 'grad_norm': 41.617183685302734}
2023-01-03 14:20:08.006 DEBUG: Taking gradient step
2023-01-03 14:20:20.340 DEBUG: Loss 5: {'policy_loss': 0.13737728654567527, 'entropy_loss': -0.07947775721549988, 'vf_loss': 0.0988124771973197, 'total_loss': 0.05789952933017539, 'approx_kl': -0.04076854372397065, 'clip_fraction': 0.51171875, 'grad_norm': 30.3581485748291}
2023-01-03 14:20:33.219 DEBUG: Taking gradient step
2023-01-03 14:20:45.725 DEBUG: Loss 6: {'policy_loss': 0.12804292188324976, 'entropy_loss': -0.07876122370362282, 'vf_loss': 0.0996280416225114, 'total_loss': 0.04928169817962694, 'approx_kl': -0.06874470505863428, 'clip_fraction': 0.4947916716337204, 'grad_norm': 20.3663387298584}
2023-01-03 14:20:57.986 DEBUG: Taking gradient step
2023-01-03 14:21:10.423 DEBUG: Loss 7: {'policy_loss': 0.11167925559297431, 'entropy_loss': -0.07926384545862675, 'vf_loss': 0.0946239735133815, 'total_loss': 0.032415410134347566, 'approx_kl': -0.08788987179286778, 'clip_fraction': 0.4348958358168602, 'grad_norm': 32.82018280029297}
2023-01-03 14:21:22.668 DEBUG: Taking gradient step
2023-01-03 14:21:35.061 DEBUG: Loss 8: {'policy_loss': 0.07156527990139439, 'entropy_loss': -0.07953499630093575, 'vf_loss': 0.09015757976522773, 'total_loss': -0.007969716399541357, 'approx_kl': -0.08914883621037006, 'clip_fraction': 0.4713541716337204, 'grad_norm': 33.03278732299805}
2023-01-03 14:21:41.984 DEBUG: Taking gradient step
2023-01-03 14:21:43.858 DEBUG: Loss 9: {'policy_loss': 0.13783329487634682, 'entropy_loss': -0.07904940284788609, 'vf_loss': 0.09083775822843622, 'total_loss': 0.05878389202846073, 'approx_kl': -0.1012803427875042, 'clip_fraction': 0.4401041716337204, 'grad_norm': 39.42504119873047}
2023-01-03 14:21:45.676 DEBUG: Taking gradient step
2023-01-03 14:21:47.540 DEBUG: Loss 10: {'policy_loss': 0.05713112138488512, 'entropy_loss': -0.07957134209573269, 'vf_loss': 0.08497021376850238, 'total_loss': -0.02244022071084756, 'approx_kl': -0.0927591361105442, 'clip_fraction': 0.3671875, 'grad_norm': 43.944190979003906}
2023-01-03 14:21:49.356 DEBUG: Taking gradient step
2023-01-03 14:21:51.232 DEBUG: Loss 11: {'policy_loss': 0.04045462305560962, 'entropy_loss': -0.07933622784912586, 'vf_loss': 0.08178989130143482, 'total_loss': -0.03888160479351624, 'approx_kl': -0.07251753099262714, 'clip_fraction': 0.421875, 'grad_norm': 31.4239501953125}
2023-01-03 14:21:53.038 DEBUG: Taking gradient step
2023-01-03 14:21:54.892 DEBUG: Loss 12: {'policy_loss': 0.11747520988709807, 'entropy_loss': -0.0789111815392971, 'vf_loss': 0.08311159804329181, 'total_loss': 0.03856402834780097, 'approx_kl': -0.11783766141161323, 'clip_fraction': 0.5494791716337204, 'grad_norm': 33.57061004638672}
2023-01-03 14:21:56.712 DEBUG: Taking gradient step
2023-01-03 14:21:58.601 DEBUG: Loss 13: {'policy_loss': 0.06764726368312053, 'entropy_loss': -0.07979359291493893, 'vf_loss': 0.07961888920938874, 'total_loss': -0.012146329231818395, 'approx_kl': -0.10292251035571098, 'clip_fraction': 0.4908854216337204, 'grad_norm': 31.95208740234375}
2023-01-03 14:22:00.407 DEBUG: Taking gradient step
2023-01-03 14:22:02.282 DEBUG: Loss 14: {'policy_loss': 0.08127797693511957, 'entropy_loss': -0.08000694774091244, 'vf_loss': 0.07716890393186551, 'total_loss': 0.0012710291942071364, 'approx_kl': -0.10799778439104557, 'clip_fraction': 0.4934895858168602, 'grad_norm': 36.61528015136719}
2023-01-03 14:22:02.282 INFO: Optimization: policy loss=0.081, vf loss=0.077, entropy loss=-0.080, total loss=0.001, num steps=15
2023-01-03 14:22:02.283 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 14:22:03.098 DEBUG: Atoms are too close
2023-01-03 14:22:03.100 INFO: Evaluation rollout: return=-18.129 (0.0), episode length=4.0
2023-01-03 14:22:03.101 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 14:22:03.104 DEBUG: Saving model: runs/CH3NO_dna/models/CH3NO_dna_run-1_steps-216.model
2023-01-03 14:22:03.154 INFO: Iteration: 1/137, steps: 216
2023-01-03 14:22:07.368 DEBUG: There is a single atom floating around
2023-01-03 14:22:13.103 DEBUG: Atoms are too close
2023-01-03 14:22:13.686 DEBUG: Atoms are too close
2023-01-03 14:22:14.867 DEBUG: Atoms are too close
2023-01-03 14:22:16.697 DEBUG: Atoms are too close
2023-01-03 14:22:17.451 DEBUG: Atoms are too close
2023-01-03 14:22:17.452 DEBUG: Atoms are too close
2023-01-03 14:22:18.681 DEBUG: Atoms are too close
2023-01-03 14:22:18.683 DEBUG: There is a single atom floating around
2023-01-03 14:22:19.726 DEBUG: There is a single atom floating around
2023-01-03 14:22:20.025 DEBUG: There is a single atom floating around
2023-01-03 14:22:24.176 DEBUG: There is a single atom floating around
2023-01-03 14:22:25.067 DEBUG: There is a single atom floating around
2023-01-03 14:22:25.070 DEBUG: Atoms are too close
2023-01-03 14:22:30.321 DEBUG: Atoms are too close
2023-01-03 14:22:30.323 DEBUG: Atoms are too close
2023-01-03 14:22:34.292 DEBUG: Atoms are too close
2023-01-03 14:22:34.441 DEBUG: Atoms are too close
2023-01-03 14:22:41.116 DEBUG: Atoms are too close
2023-01-03 14:22:41.118 DEBUG: There is a single atom floating around
2023-01-03 14:22:41.405 DEBUG: Atoms are too close
2023-01-03 14:22:43.062 DEBUG: Atoms are too close
2023-01-03 14:22:43.964 DEBUG: Atoms are too close
2023-01-03 14:22:49.337 DEBUG: Atoms are too close
2023-01-03 14:22:51.638 DEBUG: Atoms are too close
2023-01-03 14:22:53.446 DEBUG: Atoms are too close
2023-01-03 14:22:55.830 DEBUG: Atoms are too close
2023-01-03 14:22:56.118 DEBUG: Atoms are too close
2023-01-03 14:22:58.610 INFO: Training rollout: return=-12.743 (9.3), episode length=4.7
2023-01-03 14:22:58.612 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 14:22:58.616 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-216_train.pkl
2023-01-03 14:23:10.733 DEBUG: Taking gradient step
2023-01-03 14:23:22.931 DEBUG: Loss 0: {'policy_loss': -0.005956007885173505, 'entropy_loss': -0.08180311694741249, 'vf_loss': 0.06308444171053729, 'total_loss': -0.087759124832586, 'approx_kl': -1.1951973633017587e-08, 'clip_fraction': 0.0, 'grad_norm': 14.134241104125977}
2023-01-03 14:23:35.376 DEBUG: Taking gradient step
2023-01-03 14:23:47.847 DEBUG: Loss 1: {'policy_loss': 0.0003702842020799598, 'entropy_loss': -0.08255987241864204, 'vf_loss': 0.060287405614066945, 'total_loss': -0.08218958821656208, 'approx_kl': -0.010914993472397327, 'clip_fraction': 0.10026041697710752, 'grad_norm': 18.076778411865234}
2023-01-03 14:23:59.829 DEBUG: Taking gradient step
2023-01-03 14:24:12.414 DEBUG: Loss 2: {'policy_loss': -0.001439025929025061, 'entropy_loss': -0.082834891974926, 'vf_loss': 0.060775962279492474, 'total_loss': -0.08427391790395106, 'approx_kl': -0.017315766774117947, 'clip_fraction': 0.21484375, 'grad_norm': 16.208358764648438}
2023-01-03 14:24:24.846 DEBUG: Taking gradient step
2023-01-03 14:24:37.100 DEBUG: Loss 3: {'policy_loss': 0.03769714048544586, 'entropy_loss': -0.08277499116957188, 'vf_loss': 0.061495415282652774, 'total_loss': -0.04507785068412601, 'approx_kl': -0.02314085327088833, 'clip_fraction': 0.2473958358168602, 'grad_norm': 14.57274341583252}
2023-01-03 14:24:49.358 DEBUG: Taking gradient step
2023-01-03 14:25:01.539 DEBUG: Loss 4: {'policy_loss': -0.012831451251180055, 'entropy_loss': -0.08306488394737244, 'vf_loss': 0.058039625695058286, 'total_loss': -0.0958963351985525, 'approx_kl': -0.052064209477975965, 'clip_fraction': 0.2760416716337204, 'grad_norm': 14.599686622619629}
2023-01-03 14:25:13.664 DEBUG: Taking gradient step
2023-01-03 14:25:25.160 DEBUG: Loss 5: {'policy_loss': -0.04932860369226131, 'entropy_loss': -0.08352264203131199, 'vf_loss': 0.055058734008663714, 'total_loss': -0.1328512457235733, 'approx_kl': -0.04739850596524775, 'clip_fraction': 0.34765625, 'grad_norm': 12.366338729858398}
2023-01-03 14:25:29.394 DEBUG: Taking gradient step
2023-01-03 14:25:31.355 DEBUG: Loss 6: {'policy_loss': -0.013079038559403906, 'entropy_loss': -0.08353014662861824, 'vf_loss': 0.05669056266460255, 'total_loss': -0.09660918518802215, 'approx_kl': -0.0464951756875962, 'clip_fraction': 0.3776041716337204, 'grad_norm': 18.987764358520508}
2023-01-03 14:25:33.255 DEBUG: Taking gradient step
2023-01-03 14:25:35.214 DEBUG: Loss 7: {'policy_loss': -0.02555633903695889, 'entropy_loss': -0.08325160294771194, 'vf_loss': 0.0539253175491769, 'total_loss': -0.10880794198467084, 'approx_kl': -0.03327074646949768, 'clip_fraction': 0.4635416716337204, 'grad_norm': 14.228889465332031}
2023-01-03 14:25:37.131 DEBUG: Taking gradient step
2023-01-03 14:25:39.078 DEBUG: Loss 8: {'policy_loss': -0.03454820296633988, 'entropy_loss': -0.08248056098818779, 'vf_loss': 0.05247825348900133, 'total_loss': -0.11702876395452769, 'approx_kl': -0.0643329992890358, 'clip_fraction': 0.4479166716337204, 'grad_norm': 15.368305206298828}
2023-01-03 14:25:40.974 DEBUG: Taking gradient step
2023-01-03 14:25:42.935 DEBUG: Loss 9: {'policy_loss': -0.017319109169150717, 'entropy_loss': -0.08202250115573406, 'vf_loss': 0.05183012121080359, 'total_loss': -0.09934161032488478, 'approx_kl': -0.06292233429849148, 'clip_fraction': 0.3515625, 'grad_norm': 16.277629852294922}
2023-01-03 14:25:44.837 DEBUG: Taking gradient step
2023-01-03 14:25:46.779 DEBUG: Loss 10: {'policy_loss': -0.10261518235709743, 'entropy_loss': -0.08213985897600651, 'vf_loss': 0.04821904621787685, 'total_loss': -0.18475504133310394, 'approx_kl': -0.10188192594796419, 'clip_fraction': 0.4361979216337204, 'grad_norm': 13.619257926940918}
2023-01-03 14:25:48.663 DEBUG: Taking gradient step
2023-01-03 14:25:50.632 DEBUG: Loss 11: {'policy_loss': 0.03265157630831827, 'entropy_loss': -0.08080151863396168, 'vf_loss': 0.04816894020544921, 'total_loss': -0.048149942325643416, 'approx_kl': -0.08043368137441576, 'clip_fraction': 0.3411458358168602, 'grad_norm': 17.823997497558594}
2023-01-03 14:25:52.536 DEBUG: Taking gradient step
2023-01-03 14:25:54.523 DEBUG: Loss 12: {'policy_loss': -0.007015163718319159, 'entropy_loss': -0.08000382594764233, 'vf_loss': 0.0468768032609691, 'total_loss': -0.08701898966596149, 'approx_kl': -0.07551241293549538, 'clip_fraction': 0.3697916716337204, 'grad_norm': 17.913846969604492}
2023-01-03 14:25:56.474 DEBUG: Taking gradient step
2023-01-03 14:25:58.492 DEBUG: Loss 13: {'policy_loss': -0.009852096421402518, 'entropy_loss': -0.08137320727109909, 'vf_loss': 0.04515303913157257, 'total_loss': -0.09122530369250162, 'approx_kl': -0.09771466627717018, 'clip_fraction': 0.3515625, 'grad_norm': 10.843350410461426}
2023-01-03 14:26:00.459 DEBUG: Taking gradient step
2023-01-03 14:26:02.470 DEBUG: Loss 14: {'policy_loss': 0.027950869657748095, 'entropy_loss': -0.0800583753734827, 'vf_loss': 0.04371165529153638, 'total_loss': -0.05210750571573461, 'approx_kl': -0.0782734788954258, 'clip_fraction': 0.41796875, 'grad_norm': 12.52425479888916}
2023-01-03 14:26:02.471 INFO: Optimization: policy loss=0.028, vf loss=0.044, entropy loss=-0.080, total loss=-0.052, num steps=15
2023-01-03 14:26:02.472 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 14:26:03.251 DEBUG: Atoms are too close
2023-01-03 14:26:03.253 INFO: Evaluation rollout: return=-18.133 (0.0), episode length=4.0
2023-01-03 14:26:03.253 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 14:26:03.256 INFO: Iteration: 2/137, steps: 432
2023-01-03 14:26:05.044 DEBUG: There is a single atom floating around
2023-01-03 14:26:05.865 DEBUG: There is a single atom floating around
2023-01-03 14:26:13.240 DEBUG: Atoms are too close
2023-01-03 14:26:13.243 DEBUG: Atoms are too close
2023-01-03 14:26:13.243 DEBUG: Atoms are too close
2023-01-03 14:26:14.813 DEBUG: Atoms are too close
2023-01-03 14:26:15.096 DEBUG: Atoms are too close
2023-01-03 14:26:15.098 DEBUG: Atoms are too close
2023-01-03 14:26:16.937 DEBUG: Atoms are too close
2023-01-03 14:26:16.938 DEBUG: Atoms are too close
2023-01-03 14:26:24.753 DEBUG: Atoms are too close
2023-01-03 14:26:25.338 DEBUG: There is a single atom floating around
2023-01-03 14:26:26.260 DEBUG: Atoms are too close
2023-01-03 14:26:26.262 DEBUG: There is a single atom floating around
2023-01-03 14:26:27.297 DEBUG: Atoms are too close
2023-01-03 14:26:27.298 DEBUG: Atoms are too close
2023-01-03 14:26:28.636 DEBUG: Atoms are too close
2023-01-03 14:26:28.637 DEBUG: Atoms are too close
2023-01-03 14:26:32.185 DEBUG: There is a single atom floating around
2023-01-03 14:26:38.572 DEBUG: Atoms are too close
2023-01-03 14:26:38.574 DEBUG: Atoms are too close
2023-01-03 14:26:39.367 DEBUG: Atoms are too close
2023-01-03 14:26:43.044 DEBUG: Atoms are too close
2023-01-03 14:26:43.752 DEBUG: There is a single atom floating around
2023-01-03 14:26:47.769 DEBUG: Atoms are too close
2023-01-03 14:26:50.575 DEBUG: Atoms are too close
2023-01-03 14:26:51.828 DEBUG: Atoms are too close
2023-01-03 14:26:53.190 INFO: Training rollout: return=-12.091 (9.3), episode length=4.8
2023-01-03 14:26:53.192 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 14:26:53.195 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-432_train.pkl
2023-01-03 14:26:55.106 DEBUG: Taking gradient step
2023-01-03 14:26:57.043 DEBUG: Loss 0: {'policy_loss': -0.037395340647950276, 'entropy_loss': -0.0791489090770483, 'vf_loss': 0.04379855465060005, 'total_loss': -0.11654424972499858, 'approx_kl': -4.89720477503397e-08, 'clip_fraction': 0.0, 'grad_norm': 24.449398040771484}
2023-01-03 14:26:58.939 DEBUG: Taking gradient step
2023-01-03 14:27:00.886 DEBUG: Loss 1: {'policy_loss': -0.06500308120960573, 'entropy_loss': -0.07852763310074806, 'vf_loss': 0.04271824283399667, 'total_loss': -0.1435307143103538, 'approx_kl': -0.01583301811479032, 'clip_fraction': 0.19921875, 'grad_norm': 18.12495231628418}
2023-01-03 14:27:02.774 DEBUG: Taking gradient step
2023-01-03 14:27:04.709 DEBUG: Loss 2: {'policy_loss': 0.016307098081312317, 'entropy_loss': -0.07904526218771935, 'vf_loss': 0.04110056961322486, 'total_loss': -0.06273816410640704, 'approx_kl': -0.026773080229759216, 'clip_fraction': 0.2786458358168602, 'grad_norm': 19.10361099243164}
2023-01-03 14:27:06.600 DEBUG: Taking gradient step
2023-01-03 14:27:08.542 DEBUG: Loss 3: {'policy_loss': -0.0004255743231782669, 'entropy_loss': -0.07761212438344955, 'vf_loss': 0.039768976375569316, 'total_loss': -0.07803769870662783, 'approx_kl': -0.012076713610440493, 'clip_fraction': 0.3515625, 'grad_norm': 22.764114379882812}
2023-01-03 14:27:10.430 DEBUG: Taking gradient step
2023-01-03 14:27:12.375 DEBUG: Loss 4: {'policy_loss': 0.025263885821652152, 'entropy_loss': -0.07752979546785355, 'vf_loss': 0.03924065313485443, 'total_loss': -0.05226590964620139, 'approx_kl': -0.03764264099299908, 'clip_fraction': 0.3359375, 'grad_norm': 18.516677856445312}
2023-01-03 14:27:14.264 DEBUG: Taking gradient step
2023-01-03 14:27:16.260 DEBUG: Loss 5: {'policy_loss': 0.05538148573777541, 'entropy_loss': -0.07735285721719265, 'vf_loss': 0.03926467764683042, 'total_loss': -0.02197137147941724, 'approx_kl': -0.052729686722159386, 'clip_fraction': 0.38671875, 'grad_norm': 20.38001251220703}
2023-01-03 14:27:18.190 DEBUG: Taking gradient step
2023-01-03 14:27:20.183 DEBUG: Loss 6: {'policy_loss': 0.01027346378772585, 'entropy_loss': -0.07568336464464664, 'vf_loss': 0.03996130904976696, 'total_loss': -0.0654099008569208, 'approx_kl': -0.06878443341702223, 'clip_fraction': 0.5026041716337204, 'grad_norm': 15.158588409423828}
2023-01-03 14:27:22.112 DEBUG: Taking gradient step
2023-01-03 14:27:24.046 DEBUG: Loss 7: {'policy_loss': 0.01338407361773395, 'entropy_loss': -0.0776261854916811, 'vf_loss': 0.039135531398218994, 'total_loss': -0.06424211187394716, 'approx_kl': -0.08842655457556248, 'clip_fraction': 0.5091145858168602, 'grad_norm': 14.934042930603027}
2023-01-03 14:27:25.933 DEBUG: Taking gradient step
2023-01-03 14:27:27.869 DEBUG: Loss 8: {'policy_loss': 0.01173576498702094, 'entropy_loss': -0.07696234434843063, 'vf_loss': 0.04091393059958094, 'total_loss': -0.0652265793614097, 'approx_kl': -0.09675303287804127, 'clip_fraction': 0.5078125, 'grad_norm': 19.766660690307617}
2023-01-03 14:27:29.754 DEBUG: Taking gradient step
2023-01-03 14:27:31.694 DEBUG: Loss 9: {'policy_loss': 0.0743088001156, 'entropy_loss': -0.07616898231208324, 'vf_loss': 0.039927970682744986, 'total_loss': -0.0018601821964832482, 'approx_kl': -0.09035851806402206, 'clip_fraction': 0.53515625, 'grad_norm': 15.52569580078125}
2023-01-03 14:27:33.571 DEBUG: Taking gradient step
2023-01-03 14:27:35.530 DEBUG: Loss 10: {'policy_loss': -0.01557211756610849, 'entropy_loss': -0.07724888995289803, 'vf_loss': 0.038471818982525684, 'total_loss': -0.09282100751900652, 'approx_kl': -0.1017620600759983, 'clip_fraction': 0.6106770932674408, 'grad_norm': 19.0721492767334}
2023-01-03 14:27:37.433 DEBUG: Taking gradient step
2023-01-03 14:27:39.479 DEBUG: Loss 11: {'policy_loss': 0.003084182234804611, 'entropy_loss': -0.07630208879709244, 'vf_loss': 0.039298094478344814, 'total_loss': -0.07321790656228783, 'approx_kl': -0.11137079074978828, 'clip_fraction': 0.5520833358168602, 'grad_norm': 16.001264572143555}
2023-01-03 14:27:41.366 DEBUG: Taking gradient step
2023-01-03 14:27:43.334 DEBUG: Loss 12: {'policy_loss': 0.08647932625205917, 'entropy_loss': -0.0764157809317112, 'vf_loss': 0.03962373692330844, 'total_loss': 0.010063545320347991, 'approx_kl': -0.10131671093404293, 'clip_fraction': 0.5338541716337204, 'grad_norm': 16.99701499938965}
2023-01-03 14:27:45.231 DEBUG: Taking gradient step
2023-01-03 14:27:55.499 DEBUG: Loss 13: {'policy_loss': 0.05759703208158325, 'entropy_loss': -0.07821553200483322, 'vf_loss': 0.03712318080144882, 'total_loss': -0.020618499923249975, 'approx_kl': -0.12190510239452124, 'clip_fraction': 0.5520833432674408, 'grad_norm': 14.7765474319458}
2023-01-03 14:27:59.433 DEBUG: Taking gradient step
2023-01-03 14:28:01.368 DEBUG: Loss 14: {'policy_loss': -0.006574888359847743, 'entropy_loss': -0.0775393657386303, 'vf_loss': 0.03919728018827263, 'total_loss': -0.08411425409847803, 'approx_kl': -0.11975141800940037, 'clip_fraction': 0.48828125, 'grad_norm': 16.534807205200195}
2023-01-03 14:28:01.369 INFO: Optimization: policy loss=-0.007, vf loss=0.039, entropy loss=-0.078, total loss=-0.084, num steps=15
2023-01-03 14:28:01.370 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 14:28:02.187 DEBUG: Atoms are too close
2023-01-03 14:28:02.189 INFO: Evaluation rollout: return=-18.131 (0.0), episode length=4.0
2023-01-03 14:28:02.189 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 14:28:02.192 INFO: Iteration: 3/137, steps: 648
2023-01-03 14:28:04.930 DEBUG: There is a single atom floating around
2023-01-03 14:28:05.828 DEBUG: There is a single atom floating around
2023-01-03 14:28:06.423 DEBUG: There is a single atom floating around
2023-01-03 14:28:06.424 DEBUG: There is a single atom floating around
2023-01-03 14:28:12.236 DEBUG: There is a single atom floating around
2023-01-03 14:28:12.239 DEBUG: Atoms are too close
2023-01-03 14:28:12.239 DEBUG: Atoms are too close
2023-01-03 14:28:13.183 DEBUG: Atoms are too close
2023-01-03 14:28:14.058 DEBUG: Atoms are too close
2023-01-03 14:28:16.506 DEBUG: Atoms are too close
2023-01-03 14:28:17.531 DEBUG: There is a single atom floating around
2023-01-03 14:28:17.824 DEBUG: Atoms are too close
2023-01-03 14:28:22.967 DEBUG: Atoms are too close
2023-01-03 14:28:24.224 DEBUG: Atoms are too close
2023-01-03 14:28:27.279 DEBUG: Atoms are too close
2023-01-03 14:28:29.616 DEBUG: Atoms are too close
2023-01-03 14:28:29.618 DEBUG: Atoms are too close
2023-01-03 14:28:31.696 DEBUG: Atoms are too close
2023-01-03 14:28:32.930 DEBUG: Atoms are too close
2023-01-03 14:28:33.937 DEBUG: Atoms are too close
2023-01-03 14:28:36.984 DEBUG: Atoms are too close
2023-01-03 14:28:38.480 DEBUG: There is a single atom floating around
2023-01-03 14:28:40.060 DEBUG: Atoms are too close
2023-01-03 14:28:40.695 DEBUG: Atoms are too close
2023-01-03 14:28:45.603 DEBUG: There is a single atom floating around
2023-01-03 14:28:47.666 DEBUG: Atoms are too close
2023-01-03 14:28:47.818 DEBUG: Atoms are too close
2023-01-03 14:28:47.819 DEBUG: Atoms are too close
2023-01-03 14:28:49.856 DEBUG: There is a single atom floating around
2023-01-03 14:28:51.055 INFO: Training rollout: return=-12.824 (9.8), episode length=4.5
2023-01-03 14:28:51.056 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 14:28:51.060 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-648_train.pkl
2023-01-03 14:28:52.929 DEBUG: Taking gradient step
2023-01-03 14:28:54.832 DEBUG: Loss 0: {'policy_loss': 0.02936020807204775, 'entropy_loss': -0.07796018943190575, 'vf_loss': 0.04274715679023523, 'total_loss': -0.04859998135985799, 'approx_kl': 8.82622188669302e-08, 'clip_fraction': 0.0, 'grad_norm': 20.122709274291992}
2023-01-03 14:28:56.689 DEBUG: Taking gradient step
2023-01-03 14:28:58.589 DEBUG: Loss 1: {'policy_loss': 0.04526444658402963, 'entropy_loss': -0.07960553653538227, 'vf_loss': 0.04156608837324406, 'total_loss': -0.03434108995135264, 'approx_kl': -0.008385913446545601, 'clip_fraction': 0.11848958395421505, 'grad_norm': 21.911073684692383}
2023-01-03 14:29:00.432 DEBUG: Taking gradient step
2023-01-03 14:29:02.349 DEBUG: Loss 2: {'policy_loss': 0.06448018121070873, 'entropy_loss': -0.07922750525176525, 'vf_loss': 0.04279399181072331, 'total_loss': -0.014747324041056518, 'approx_kl': -0.04409659281373024, 'clip_fraction': 0.2552083358168602, 'grad_norm': 27.220640182495117}
2023-01-03 14:29:04.216 DEBUG: Taking gradient step
2023-01-03 14:29:06.123 DEBUG: Loss 3: {'policy_loss': 0.06094032076554751, 'entropy_loss': -0.07905676774680614, 'vf_loss': 0.04345841018988039, 'total_loss': -0.01811644698125863, 'approx_kl': -0.0479070502333343, 'clip_fraction': 0.3606770858168602, 'grad_norm': 26.688827514648438}
2023-01-03 14:29:08.256 DEBUG: Taking gradient step
2023-01-03 14:29:10.541 DEBUG: Loss 4: {'policy_loss': 0.11140419480007487, 'entropy_loss': -0.07989178411662579, 'vf_loss': 0.039824163199935626, 'total_loss': 0.03151241068344908, 'approx_kl': -0.040331969037652016, 'clip_fraction': 0.3658854216337204, 'grad_norm': 28.275226593017578}
2023-01-03 14:29:12.765 DEBUG: Taking gradient step
2023-01-03 14:29:15.051 DEBUG: Loss 5: {'policy_loss': 0.21209342027660275, 'entropy_loss': -0.07829408906400204, 'vf_loss': 0.04075128470322216, 'total_loss': 0.1337993312126007, 'approx_kl': -0.0811044704169035, 'clip_fraction': 0.4752604216337204, 'grad_norm': 61.63893508911133}
2023-01-03 14:29:17.272 DEBUG: Taking gradient step
2023-01-03 14:29:19.570 DEBUG: Loss 6: {'policy_loss': 0.11071676255002294, 'entropy_loss': -0.07772506959736347, 'vf_loss': 0.04115393169193806, 'total_loss': 0.032991692952659454, 'approx_kl': -0.049416004214435816, 'clip_fraction': 0.5143229216337204, 'grad_norm': 31.86820411682129}
2023-01-03 14:29:21.789 DEBUG: Taking gradient step
2023-01-03 14:29:24.073 DEBUG: Loss 7: {'policy_loss': 0.16575413412010898, 'entropy_loss': -0.07686317712068558, 'vf_loss': 0.04073406881205657, 'total_loss': 0.08889095699942341, 'approx_kl': -0.07684902101755142, 'clip_fraction': 0.7317708432674408, 'grad_norm': 30.669050216674805}
2023-01-03 14:29:26.091 DEBUG: Taking gradient step
2023-01-03 14:29:27.989 DEBUG: Loss 8: {'policy_loss': 0.09413690283403621, 'entropy_loss': -0.07502209581434727, 'vf_loss': 0.040776755071628326, 'total_loss': 0.019114807019688956, 'approx_kl': -0.07909707259386778, 'clip_fraction': 0.7174479216337204, 'grad_norm': 30.585599899291992}
2023-01-03 14:29:29.933 DEBUG: Taking gradient step
2023-01-03 14:29:31.851 DEBUG: Loss 9: {'policy_loss': 0.09645008476657778, 'entropy_loss': -0.07569445297122002, 'vf_loss': 0.041451941521634075, 'total_loss': 0.020755631795357762, 'approx_kl': -0.06756192503962666, 'clip_fraction': 0.7044270932674408, 'grad_norm': 24.61978530883789}
2023-01-03 14:29:33.714 DEBUG: Taking gradient step
2023-01-03 14:29:35.613 DEBUG: Loss 10: {'policy_loss': 0.14468468786326805, 'entropy_loss': -0.07519319280982018, 'vf_loss': 0.03939328733667099, 'total_loss': 0.06949149505344787, 'approx_kl': -0.08632952906191349, 'clip_fraction': 0.7239583432674408, 'grad_norm': 17.719335556030273}
2023-01-03 14:29:37.459 DEBUG: Taking gradient step
2023-01-03 14:29:39.363 DEBUG: Loss 11: {'policy_loss': 0.06855312423220311, 'entropy_loss': -0.0760842114686966, 'vf_loss': 0.037548123792043545, 'total_loss': -0.007531087236493483, 'approx_kl': -0.1066666841506958, 'clip_fraction': 0.6197916716337204, 'grad_norm': 18.742477416992188}
2023-01-03 14:29:41.201 DEBUG: Taking gradient step
2023-01-03 14:29:43.096 DEBUG: Loss 12: {'policy_loss': 0.12003550305249461, 'entropy_loss': -0.07615882717072964, 'vf_loss': 0.03908730085857063, 'total_loss': 0.04387667588176497, 'approx_kl': -0.12245905306190252, 'clip_fraction': 0.5690104216337204, 'grad_norm': 22.5650577545166}
2023-01-03 14:29:44.956 DEBUG: Taking gradient step
2023-01-03 14:29:46.861 DEBUG: Loss 13: {'policy_loss': 0.15560959365847649, 'entropy_loss': -0.07706731930375099, 'vf_loss': 0.0402164845158292, 'total_loss': 0.0785422743547255, 'approx_kl': -0.12942012213170528, 'clip_fraction': 0.4127604216337204, 'grad_norm': 40.26417541503906}
2023-01-03 14:29:48.740 DEBUG: Taking gradient step
2023-01-03 14:29:50.695 DEBUG: Loss 14: {'policy_loss': 0.07715390740249112, 'entropy_loss': -0.07588442042469978, 'vf_loss': 0.03963715907957053, 'total_loss': 0.0012694869777913481, 'approx_kl': -0.12206481583416462, 'clip_fraction': 0.40625, 'grad_norm': 24.358367919921875}
2023-01-03 14:29:50.695 INFO: Optimization: policy loss=0.077, vf loss=0.040, entropy loss=-0.076, total loss=0.001, num steps=15
2023-01-03 14:29:50.697 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 14:29:51.491 DEBUG: Atoms are too close
2023-01-03 14:29:51.492 INFO: Evaluation rollout: return=-18.130 (0.0), episode length=4.0
2023-01-03 14:29:51.493 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 14:29:51.495 INFO: Iteration: 4/137, steps: 864
2023-01-03 14:30:01.407 DEBUG: Atoms are too close
2023-01-03 14:30:01.994 DEBUG: Atoms are too close
2023-01-03 14:30:03.426 DEBUG: Atoms are too close
2023-01-03 14:30:03.804 DEBUG: Atoms are too close
2023-01-03 14:30:04.469 DEBUG: Atoms are too close
2023-01-03 14:30:05.222 DEBUG: Atoms are too close
2023-01-03 14:30:05.568 DEBUG: Atoms are too close
2023-01-03 14:30:07.808 DEBUG: Atoms are too close
2023-01-03 14:30:07.944 DEBUG: Atoms are too close
2023-01-03 14:30:14.629 DEBUG: There is a single atom floating around
2023-01-03 14:30:14.913 DEBUG: Atoms are too close
2023-01-03 14:30:15.265 DEBUG: Atoms are too close
2023-01-03 14:30:15.266 DEBUG: Atoms are too close
2023-01-03 14:30:19.942 DEBUG: There is a single atom floating around
2023-01-03 14:30:19.945 DEBUG: Atoms are too close
2023-01-03 14:30:20.591 DEBUG: There is a single atom floating around
2023-01-03 14:30:25.805 DEBUG: Atoms are too close
2023-01-03 14:30:29.395 DEBUG: Atoms are too close
2023-01-03 14:30:29.396 DEBUG: Atoms are too close
2023-01-03 14:30:33.367 DEBUG: Atoms are too close
2023-01-03 14:30:37.010 DEBUG: Atoms are too close
2023-01-03 14:30:37.293 DEBUG: Atoms are too close
2023-01-03 14:30:37.643 DEBUG: Atoms are too close
2023-01-03 14:30:41.958 DEBUG: Atoms are too close
2023-01-03 14:30:42.870 INFO: Training rollout: return=-10.484 (9.1), episode length=5.0
2023-01-03 14:30:42.871 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 14:30:42.874 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-864_train.pkl
2023-01-03 14:30:44.832 DEBUG: Taking gradient step
2023-01-03 14:30:46.819 DEBUG: Loss 0: {'policy_loss': 0.010974483872304926, 'entropy_loss': -0.07521668449044228, 'vf_loss': 0.03905111209479263, 'total_loss': -0.06424220061813735, 'approx_kl': -4.718701029915451e-08, 'clip_fraction': 0.0, 'grad_norm': 26.03300666809082}
2023-01-03 14:30:48.758 DEBUG: Taking gradient step
2023-01-03 14:30:50.765 DEBUG: Loss 1: {'policy_loss': -0.006912900831517063, 'entropy_loss': -0.07686598598957062, 'vf_loss': 0.039250143689077685, 'total_loss': -0.08377888682108768, 'approx_kl': 0.02175914472900331, 'clip_fraction': 0.1419270858168602, 'grad_norm': 16.593751907348633}
2023-01-03 14:30:52.745 DEBUG: Taking gradient step
2023-01-03 14:30:54.773 DEBUG: Loss 2: {'policy_loss': 0.0195795065691942, 'entropy_loss': -0.07546377554535866, 'vf_loss': 0.037973794662926774, 'total_loss': -0.055884268976164456, 'approx_kl': -0.00027578044682741165, 'clip_fraction': 0.2682291716337204, 'grad_norm': 15.21302604675293}
2023-01-03 14:30:56.746 DEBUG: Taking gradient step
2023-01-03 14:30:58.756 DEBUG: Loss 3: {'policy_loss': 0.012967709774166284, 'entropy_loss': -0.07536701299250126, 'vf_loss': 0.03996844123404862, 'total_loss': -0.06239930321833498, 'approx_kl': -0.021937819896265864, 'clip_fraction': 0.3111979216337204, 'grad_norm': 22.420381546020508}
2023-01-03 14:31:00.682 DEBUG: Taking gradient step
2023-01-03 14:31:02.721 DEBUG: Loss 4: {'policy_loss': 0.09247052594497548, 'entropy_loss': -0.07589127123355865, 'vf_loss': 0.039814780839985436, 'total_loss': 0.01657925471141683, 'approx_kl': -0.024609774351119995, 'clip_fraction': 0.3932291716337204, 'grad_norm': 26.48193359375}
2023-01-03 14:31:04.647 DEBUG: Taking gradient step
2023-01-03 14:31:06.636 DEBUG: Loss 5: {'policy_loss': 0.06781620746112255, 'entropy_loss': -0.07384412549436092, 'vf_loss': 0.0391431325753374, 'total_loss': -0.0060279180332383706, 'approx_kl': -0.04116320610046387, 'clip_fraction': 0.51953125, 'grad_norm': 28.065265655517578}
2023-01-03 14:31:08.653 DEBUG: Taking gradient step
2023-01-03 14:31:10.670 DEBUG: Loss 6: {'policy_loss': 0.10100533427643535, 'entropy_loss': -0.07344660721719265, 'vf_loss': 0.0367081603300903, 'total_loss': 0.027558727059242713, 'approx_kl': -0.02881290204823017, 'clip_fraction': 0.51171875, 'grad_norm': 21.45092010498047}
2023-01-03 14:31:12.628 DEBUG: Taking gradient step
2023-01-03 14:31:14.655 DEBUG: Loss 7: {'policy_loss': 0.07504568156610632, 'entropy_loss': -0.07321370579302311, 'vf_loss': 0.03702173756979152, 'total_loss': 0.0018319757730832012, 'approx_kl': -0.051378201227635145, 'clip_fraction': 0.6236979216337204, 'grad_norm': 28.59479522705078}
2023-01-03 14:31:17.269 DEBUG: Taking gradient step
2023-01-03 14:31:19.235 DEBUG: Loss 8: {'policy_loss': 0.16200701968041847, 'entropy_loss': -0.07319357246160507, 'vf_loss': 0.03818065103390275, 'total_loss': 0.08881344721881342, 'approx_kl': -0.037658609449863434, 'clip_fraction': 0.6770833432674408, 'grad_norm': 27.148420333862305}
2023-01-03 14:31:21.153 DEBUG: Taking gradient step
2023-01-03 14:31:23.130 DEBUG: Loss 9: {'policy_loss': 0.08984661068620953, 'entropy_loss': -0.07346283830702305, 'vf_loss': 0.035888486135397656, 'total_loss': 0.016383772379186468, 'approx_kl': -0.07432096544653177, 'clip_fraction': 0.6744791716337204, 'grad_norm': 27.206499099731445}
2023-01-03 14:31:25.057 DEBUG: Taking gradient step
2023-01-03 14:31:27.030 DEBUG: Loss 10: {'policy_loss': 0.2110550330302326, 'entropy_loss': -0.07315516658127308, 'vf_loss': 0.039646515970460164, 'total_loss': 0.13789986644895952, 'approx_kl': -0.0729331923648715, 'clip_fraction': 0.5950520932674408, 'grad_norm': 32.933406829833984}
2023-01-03 14:31:28.942 DEBUG: Taking gradient step
2023-01-03 14:31:30.907 DEBUG: Loss 11: {'policy_loss': 0.15214515884075847, 'entropy_loss': -0.07301986403763294, 'vf_loss': 0.03820022601870896, 'total_loss': 0.07912529480312552, 'approx_kl': -0.07947980845347047, 'clip_fraction': 0.625, 'grad_norm': 46.142974853515625}
2023-01-03 14:31:32.806 DEBUG: Taking gradient step
2023-01-03 14:31:35.133 DEBUG: Loss 12: {'policy_loss': 0.05764694518329036, 'entropy_loss': -0.07357854582369328, 'vf_loss': 0.03779083747078583, 'total_loss': -0.015931600640402915, 'approx_kl': -0.10155482683330774, 'clip_fraction': 0.6497395932674408, 'grad_norm': 26.51211166381836}
2023-01-03 14:31:37.417 DEBUG: Taking gradient step
2023-01-03 14:31:39.764 DEBUG: Loss 13: {'policy_loss': 0.042226941961064704, 'entropy_loss': -0.0728890523314476, 'vf_loss': 0.03753058884124195, 'total_loss': -0.030662110370382904, 'approx_kl': -0.07721710484474897, 'clip_fraction': 0.6393229216337204, 'grad_norm': 19.770362854003906}
2023-01-03 14:31:42.041 DEBUG: Taking gradient step
2023-01-03 14:31:44.383 DEBUG: Loss 14: {'policy_loss': 0.042039641400085266, 'entropy_loss': -0.07512157037854195, 'vf_loss': 0.03753364709450982, 'total_loss': -0.03308192897845669, 'approx_kl': -0.07460217922925949, 'clip_fraction': 0.6302083432674408, 'grad_norm': 25.136079788208008}
2023-01-03 14:31:44.383 INFO: Optimization: policy loss=0.042, vf loss=0.038, entropy loss=-0.075, total loss=-0.033, num steps=15
2023-01-03 14:31:44.385 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 14:31:45.181 DEBUG: Atoms are too close
2023-01-03 14:31:45.183 INFO: Evaluation rollout: return=-18.135 (0.0), episode length=4.0
2023-01-03 14:31:45.184 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 14:31:45.186 INFO: Iteration: 5/137, steps: 1080
2023-01-03 14:31:47.849 DEBUG: There is a single atom floating around
2023-01-03 14:31:54.325 DEBUG: Atoms are too close
2023-01-03 14:31:57.982 DEBUG: Atoms are too close
2023-01-03 14:31:58.829 DEBUG: Atoms are too close
2023-01-03 14:31:58.831 DEBUG: Atoms are too close
2023-01-03 14:31:59.484 DEBUG: Atoms are too close
2023-01-03 14:32:05.558 DEBUG: Atoms are too close
2023-01-03 14:32:08.965 DEBUG: Atoms are too close
2023-01-03 14:32:10.163 DEBUG: Atoms are too close
2023-01-03 14:32:11.433 DEBUG: Atoms are too close
2023-01-03 14:32:15.989 DEBUG: Atoms are too close
2023-01-03 14:32:19.365 DEBUG: Atoms are too close
2023-01-03 14:32:22.162 DEBUG: Atoms are too close
2023-01-03 14:32:24.217 DEBUG: Atoms are too close
2023-01-03 14:32:28.510 DEBUG: Atoms are too close
2023-01-03 14:32:29.732 DEBUG: Atoms are too close
2023-01-03 14:32:32.037 DEBUG: Atoms are too close
2023-01-03 14:32:32.548 DEBUG: Atoms are too close
2023-01-03 14:32:34.259 DEBUG: Atoms are too close
2023-01-03 14:32:35.097 DEBUG: There is a single atom floating around
2023-01-03 14:32:35.530 DEBUG: Atoms are too close
2023-01-03 14:32:37.670 INFO: Training rollout: return=-9.340 (9.1), episode length=5.2
2023-01-03 14:32:37.671 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 14:32:37.674 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-1080_train.pkl
2023-01-03 14:32:39.653 DEBUG: Taking gradient step
2023-01-03 14:32:41.661 DEBUG: Loss 0: {'policy_loss': 0.006061766790180943, 'entropy_loss': -0.07521123997867107, 'vf_loss': 0.035533210676770774, 'total_loss': -0.06914947318849013, 'approx_kl': 5.39391020737412e-09, 'clip_fraction': 0.0, 'grad_norm': 29.007171630859375}
2023-01-03 14:32:43.607 DEBUG: Taking gradient step
2023-01-03 14:32:45.624 DEBUG: Loss 1: {'policy_loss': 0.010924432714921405, 'entropy_loss': -0.0736769512295723, 'vf_loss': 0.035814117440957374, 'total_loss': -0.0627525185146509, 'approx_kl': -0.00410558667499572, 'clip_fraction': 0.09505208395421505, 'grad_norm': 26.543594360351562}
2023-01-03 14:32:47.580 DEBUG: Taking gradient step
2023-01-03 14:32:49.579 DEBUG: Loss 2: {'policy_loss': 0.010634806038852248, 'entropy_loss': -0.07321947440505028, 'vf_loss': 0.03391895508873938, 'total_loss': -0.06258466836619803, 'approx_kl': -0.04049606528133154, 'clip_fraction': 0.34375, 'grad_norm': 20.54668617248535}
2023-01-03 14:32:51.534 DEBUG: Taking gradient step
2023-01-03 14:32:53.639 DEBUG: Loss 3: {'policy_loss': 0.07610816575290892, 'entropy_loss': -0.07495102472603321, 'vf_loss': 0.03618676469648456, 'total_loss': 0.001157141026875707, 'approx_kl': -0.03560657426714897, 'clip_fraction': 0.4244791716337204, 'grad_norm': 22.41901969909668}
2023-01-03 14:32:55.599 DEBUG: Taking gradient step
2023-01-03 14:32:57.598 DEBUG: Loss 4: {'policy_loss': 0.1330329889429153, 'entropy_loss': -0.07513011619448662, 'vf_loss': 0.0355128720172166, 'total_loss': 0.05790287274842868, 'approx_kl': -0.03206014788884204, 'clip_fraction': 0.4765625, 'grad_norm': 22.61374855041504}
2023-01-03 14:32:59.530 DEBUG: Taking gradient step
2023-01-03 14:33:01.529 DEBUG: Loss 5: {'policy_loss': 0.14460704624836676, 'entropy_loss': -0.07508226484060287, 'vf_loss': 0.03540319794656507, 'total_loss': 0.06952478140776389, 'approx_kl': -0.0702375159598887, 'clip_fraction': 0.421875, 'grad_norm': 35.936683654785156}
2023-01-03 14:33:03.482 DEBUG: Taking gradient step
2023-01-03 14:33:05.472 DEBUG: Loss 6: {'policy_loss': 0.12617719400547572, 'entropy_loss': -0.0730662140995264, 'vf_loss': 0.035920118788837004, 'total_loss': 0.053110979905949325, 'approx_kl': -0.09291867818683386, 'clip_fraction': 0.4127604216337204, 'grad_norm': 33.37820816040039}
2023-01-03 14:33:07.422 DEBUG: Taking gradient step
2023-01-03 14:33:09.427 DEBUG: Loss 7: {'policy_loss': 0.06673260351599111, 'entropy_loss': -0.07377231121063232, 'vf_loss': 0.03574085475874013, 'total_loss': -0.007039707694641219, 'approx_kl': -0.08711489522829652, 'clip_fraction': 0.42578125, 'grad_norm': 21.1646671295166}
2023-01-03 14:33:11.374 DEBUG: Taking gradient step
2023-01-03 14:33:13.381 DEBUG: Loss 8: {'policy_loss': 0.06059549512799582, 'entropy_loss': -0.07345723547041416, 'vf_loss': 0.0342377164195348, 'total_loss': -0.01286174034241834, 'approx_kl': -0.08562336582690477, 'clip_fraction': 0.4622395858168602, 'grad_norm': 25.07631492614746}
2023-01-03 14:33:15.330 DEBUG: Taking gradient step
2023-01-03 14:33:17.346 DEBUG: Loss 9: {'policy_loss': 0.042114845028269364, 'entropy_loss': -0.07289045676589012, 'vf_loss': 0.034372118896442164, 'total_loss': -0.030775611737620757, 'approx_kl': -0.08178076054900885, 'clip_fraction': 0.44140625, 'grad_norm': 18.333803176879883}
2023-01-03 14:33:19.293 DEBUG: Taking gradient step
2023-01-03 14:33:21.299 DEBUG: Loss 10: {'policy_loss': 0.03577348039009114, 'entropy_loss': -0.0710555650293827, 'vf_loss': 0.03504996179706133, 'total_loss': -0.03528208463929156, 'approx_kl': -0.08989497646689415, 'clip_fraction': 0.4596354216337204, 'grad_norm': 18.945579528808594}
2023-01-03 14:33:23.255 DEBUG: Taking gradient step
2023-01-03 14:33:25.263 DEBUG: Loss 11: {'policy_loss': 0.06548404618532153, 'entropy_loss': -0.07229593023657799, 'vf_loss': 0.035596625884359134, 'total_loss': -0.0068118840512564685, 'approx_kl': -0.11408207658678293, 'clip_fraction': 0.48828125, 'grad_norm': 22.528907775878906}
2023-01-03 14:33:27.220 DEBUG: Taking gradient step
2023-01-03 14:33:29.227 DEBUG: Loss 12: {'policy_loss': 0.048570428119360534, 'entropy_loss': -0.0699751004576683, 'vf_loss': 0.03415016367462356, 'total_loss': -0.02140467233830777, 'approx_kl': -0.10185204911977053, 'clip_fraction': 0.4830729216337204, 'grad_norm': 16.89924430847168}
2023-01-03 14:33:31.196 DEBUG: Taking gradient step
2023-01-03 14:33:33.303 DEBUG: Loss 13: {'policy_loss': 0.06048486110097906, 'entropy_loss': -0.0721230786293745, 'vf_loss': 0.033629818762865145, 'total_loss': -0.011638217528395445, 'approx_kl': -0.0997344870120287, 'clip_fraction': 0.5091145932674408, 'grad_norm': 21.35435676574707}
2023-01-03 14:33:35.251 DEBUG: Taking gradient step
2023-01-03 14:33:37.248 DEBUG: Loss 14: {'policy_loss': 0.016865825480060173, 'entropy_loss': -0.07046093046665192, 'vf_loss': 0.03415173359394607, 'total_loss': -0.05359510498659174, 'approx_kl': -0.11198532208800316, 'clip_fraction': 0.4375, 'grad_norm': 23.294952392578125}
2023-01-03 14:33:37.249 INFO: Optimization: policy loss=0.017, vf loss=0.034, entropy loss=-0.070, total loss=-0.054, num steps=15
2023-01-03 14:33:37.250 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 14:33:38.934 INFO: Evaluation rollout: return=0.452 (0.0), episode length=6.0
2023-01-03 14:33:38.936 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 14:33:38.939 INFO: Iteration: 6/137, steps: 1296
2023-01-03 14:33:49.918 DEBUG: Atoms are too close
2023-01-03 14:33:50.201 DEBUG: Atoms are too close
2023-01-03 14:33:50.484 DEBUG: Atoms are too close
2023-01-03 14:33:50.848 DEBUG: Atoms are too close
2023-01-03 14:33:50.850 DEBUG: Atoms are too close
2023-01-03 14:33:52.552 DEBUG: Atoms are too close
2023-01-03 14:33:53.624 DEBUG: Atoms are too close
2023-01-03 14:34:00.278 DEBUG: Atoms are too close
2023-01-03 14:34:00.559 DEBUG: Atoms are too close
2023-01-03 14:34:01.479 DEBUG: Atoms are too close
2023-01-03 14:34:03.477 DEBUG: Atoms are too close
2023-01-03 14:34:03.844 DEBUG: Atoms are too close
2023-01-03 14:34:07.489 DEBUG: Atoms are too close
2023-01-03 14:34:08.621 DEBUG: Atoms are too close
2023-01-03 14:34:10.254 DEBUG: Atoms are too close
2023-01-03 14:34:10.820 DEBUG: Atoms are too close
2023-01-03 14:34:17.952 DEBUG: Atoms are too close
2023-01-03 14:34:18.028 DEBUG: Atoms are too close
2023-01-03 14:34:18.029 DEBUG: Atoms are too close
2023-01-03 14:34:24.759 DEBUG: Atoms are too close
2023-01-03 14:34:25.622 DEBUG: Atoms are too close
2023-01-03 14:34:27.938 DEBUG: Atoms are too close
2023-01-03 14:34:29.419 INFO: Training rollout: return=-9.400 (8.3), episode length=5.3
2023-01-03 14:34:29.420 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 14:34:29.423 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-1296_train.pkl
2023-01-03 14:34:31.365 DEBUG: Taking gradient step
2023-01-03 14:34:33.339 DEBUG: Loss 0: {'policy_loss': 0.02421839529447676, 'entropy_loss': -0.07179525308310986, 'vf_loss': 0.03287052763593177, 'total_loss': -0.047576857788633097, 'approx_kl': -4.660493391206444e-08, 'clip_fraction': 0.0, 'grad_norm': 22.302120208740234}
2023-01-03 14:34:35.349 DEBUG: Taking gradient step
2023-01-03 14:34:37.336 DEBUG: Loss 1: {'policy_loss': 0.018766036277059323, 'entropy_loss': -0.07032234221696854, 'vf_loss': 0.03208072910503738, 'total_loss': -0.05155630593990922, 'approx_kl': -0.01566518552135676, 'clip_fraction': 0.10286458395421505, 'grad_norm': 27.64520835876465}
2023-01-03 14:34:39.272 DEBUG: Taking gradient step
2023-01-03 14:34:41.259 DEBUG: Loss 2: {'policy_loss': 0.022093127359801616, 'entropy_loss': -0.07015423476696014, 'vf_loss': 0.03219464500055263, 'total_loss': -0.04806110740715853, 'approx_kl': -0.04290591226890683, 'clip_fraction': 0.3294270858168602, 'grad_norm': 29.925657272338867}
2023-01-03 14:34:43.188 DEBUG: Taking gradient step
2023-01-03 14:34:45.176 DEBUG: Loss 3: {'policy_loss': 0.013918276819036648, 'entropy_loss': -0.07086776755750179, 'vf_loss': 0.034035330396310376, 'total_loss': -0.05694949073846514, 'approx_kl': -0.05720389075577259, 'clip_fraction': 0.3424479216337204, 'grad_norm': 20.576377868652344}
2023-01-03 14:34:47.112 DEBUG: Taking gradient step
2023-01-03 14:34:49.099 DEBUG: Loss 4: {'policy_loss': 0.006285105341196896, 'entropy_loss': -0.070219486951828, 'vf_loss': 0.03414564699682313, 'total_loss': -0.06393438161063111, 'approx_kl': -0.06481472193263471, 'clip_fraction': 0.34765625, 'grad_norm': 23.651456832885742}
2023-01-03 14:34:51.036 DEBUG: Taking gradient step
2023-01-03 14:34:53.027 DEBUG: Loss 5: {'policy_loss': 0.0037696456602408224, 'entropy_loss': -0.0694611445069313, 'vf_loss': 0.033685181579077614, 'total_loss': -0.06569149884669048, 'approx_kl': -0.023539893329143524, 'clip_fraction': 0.4583333358168602, 'grad_norm': 21.358068466186523}
2023-01-03 14:34:54.962 DEBUG: Taking gradient step
2023-01-03 14:34:56.942 DEBUG: Loss 6: {'policy_loss': 0.06552998468815081, 'entropy_loss': -0.06784612871706486, 'vf_loss': 0.031553845077734885, 'total_loss': -0.002316144028914044, 'approx_kl': -0.06965252989903092, 'clip_fraction': 0.48828125, 'grad_norm': 22.778528213500977}
2023-01-03 14:34:58.868 DEBUG: Taking gradient step
2023-01-03 14:35:00.845 DEBUG: Loss 7: {'policy_loss': 0.06324924901188667, 'entropy_loss': -0.06878876127302647, 'vf_loss': 0.03032898277879547, 'total_loss': -0.005539512261139794, 'approx_kl': -0.09114125743508339, 'clip_fraction': 0.5520833432674408, 'grad_norm': 21.875402450561523}
2023-01-03 14:35:02.773 DEBUG: Taking gradient step
2023-01-03 14:35:04.773 DEBUG: Loss 8: {'policy_loss': 0.06262829129645035, 'entropy_loss': -0.06808500364422798, 'vf_loss': 0.03120725067599868, 'total_loss': -0.005456712347777629, 'approx_kl': -0.10504452139139175, 'clip_fraction': 0.6510416716337204, 'grad_norm': 12.435328483581543}
2023-01-03 14:35:06.681 DEBUG: Taking gradient step
2023-01-03 14:35:08.669 DEBUG: Loss 9: {'policy_loss': 0.018309878330541526, 'entropy_loss': -0.06813150644302368, 'vf_loss': 0.03214398539662311, 'total_loss': -0.049821628112482155, 'approx_kl': -0.09808392729610205, 'clip_fraction': 0.6315104216337204, 'grad_norm': 17.32303810119629}
2023-01-03 14:35:10.591 DEBUG: Taking gradient step
2023-01-03 14:35:12.583 DEBUG: Loss 10: {'policy_loss': 0.11185656186917106, 'entropy_loss': -0.06913796998560429, 'vf_loss': 0.030766128414336864, 'total_loss': 0.042718591883566776, 'approx_kl': -0.12438857648521662, 'clip_fraction': 0.58203125, 'grad_norm': 22.81600570678711}
2023-01-03 14:35:14.570 DEBUG: Taking gradient step
2023-01-03 14:35:16.597 DEBUG: Loss 11: {'policy_loss': 0.05242308923204369, 'entropy_loss': -0.0691805649548769, 'vf_loss': 0.030482011075501685, 'total_loss': -0.01675747572283321, 'approx_kl': -0.09038494434207678, 'clip_fraction': 0.53125, 'grad_norm': 22.73415756225586}
2023-01-03 14:35:18.525 DEBUG: Taking gradient step
2023-01-03 14:35:20.491 DEBUG: Loss 12: {'policy_loss': -0.010043919039920343, 'entropy_loss': -0.07010497152805328, 'vf_loss': 0.031869816296228995, 'total_loss': -0.08014889056797363, 'approx_kl': -0.10588476527482271, 'clip_fraction': 0.4986979216337204, 'grad_norm': 18.92836570739746}
2023-01-03 14:35:22.427 DEBUG: Taking gradient step
2023-01-03 14:35:24.486 DEBUG: Loss 13: {'policy_loss': 0.0731512534117833, 'entropy_loss': -0.06923636794090271, 'vf_loss': 0.03063965180858424, 'total_loss': 0.003914885470880598, 'approx_kl': -0.08916614204645157, 'clip_fraction': 0.6158854216337204, 'grad_norm': 14.00969123840332}
2023-01-03 14:35:26.412 DEBUG: Taking gradient step
2023-01-03 14:35:28.400 DEBUG: Loss 14: {'policy_loss': 0.019238113359565517, 'entropy_loss': -0.06950678862631321, 'vf_loss': 0.030254168945643034, 'total_loss': -0.05026867526674769, 'approx_kl': -0.1051404420286417, 'clip_fraction': 0.5559895858168602, 'grad_norm': 19.679424285888672}
2023-01-03 14:35:28.440 INFO: Optimization: policy loss=0.019, vf loss=0.030, entropy loss=-0.070, total loss=-0.050, num steps=15
2023-01-03 14:35:28.442 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 14:35:30.091 DEBUG: Atoms are too close
2023-01-03 14:35:30.093 INFO: Evaluation rollout: return=-13.053 (0.0), episode length=6.0
2023-01-03 14:35:30.093 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 14:35:30.096 INFO: Iteration: 7/137, steps: 1512
2023-01-03 14:35:35.685 DEBUG: Atoms are too close
2023-01-03 14:35:41.022 DEBUG: Atoms are too close
2023-01-03 14:35:41.302 DEBUG: Atoms are too close
2023-01-03 14:35:41.941 DEBUG: Atoms are too close
2023-01-03 14:35:42.796 DEBUG: Atoms are too close
2023-01-03 14:35:43.090 DEBUG: Atoms are too close
2023-01-03 14:35:44.028 DEBUG: There is a single atom floating around
2023-01-03 14:35:44.752 DEBUG: Atoms are too close
2023-01-03 14:35:51.132 DEBUG: Atoms are too close
2023-01-03 14:35:51.701 DEBUG: Atoms are too close
2023-01-03 14:35:57.978 DEBUG: Atoms are too close
2023-01-03 14:35:58.637 DEBUG: Atoms are too close
2023-01-03 14:35:59.807 DEBUG: Atoms are too close
2023-01-03 14:36:10.569 DEBUG: Atoms are too close
2023-01-03 14:36:11.204 DEBUG: Atoms are too close
2023-01-03 14:36:11.807 DEBUG: Atoms are too close
2023-01-03 14:36:14.284 DEBUG: Atoms are too close
2023-01-03 14:36:19.593 DEBUG: Atoms are too close
2023-01-03 14:36:21.977 DEBUG: Atoms are too close
2023-01-03 14:36:24.239 DEBUG: Atoms are too close
2023-01-03 14:36:27.443 DEBUG: Atoms are too close
2023-01-03 14:36:29.441 DEBUG: Atoms are too close
2023-01-03 14:36:29.796 INFO: Training rollout: return=-9.448 (8.5), episode length=5.3
2023-01-03 14:36:29.797 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 14:36:29.800 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-1512_train.pkl
2023-01-03 14:36:31.771 DEBUG: Taking gradient step
2023-01-03 14:36:33.789 DEBUG: Loss 0: {'policy_loss': 0.0125870899757533, 'entropy_loss': -0.07198852486908436, 'vf_loss': 0.03408751576660069, 'total_loss': -0.05940143489333106, 'approx_kl': 6.402842700481415e-08, 'clip_fraction': 0.0, 'grad_norm': 23.14128875732422}
2023-01-03 14:36:35.723 DEBUG: Taking gradient step
2023-01-03 14:36:37.732 DEBUG: Loss 1: {'policy_loss': 0.02261970516037469, 'entropy_loss': -0.07166524231433868, 'vf_loss': 0.03089745105415458, 'total_loss': -0.049045537153963994, 'approx_kl': -0.0032616769894957542, 'clip_fraction': 0.08072916697710752, 'grad_norm': 23.342987060546875}
2023-01-03 14:36:39.684 DEBUG: Taking gradient step
2023-01-03 14:36:41.697 DEBUG: Loss 2: {'policy_loss': 0.028130802868703498, 'entropy_loss': -0.07084232941269875, 'vf_loss': 0.032685685825371305, 'total_loss': -0.04271152654399524, 'approx_kl': -0.02796982042491436, 'clip_fraction': 0.2278645858168602, 'grad_norm': 18.193740844726562}
2023-01-03 14:36:43.650 DEBUG: Taking gradient step
2023-01-03 14:36:45.950 DEBUG: Loss 3: {'policy_loss': 0.029579252094900164, 'entropy_loss': -0.06920874584466219, 'vf_loss': 0.033252471202348914, 'total_loss': -0.03962949374976203, 'approx_kl': -0.02357562305405736, 'clip_fraction': 0.2760416679084301, 'grad_norm': 15.461565017700195}
2023-01-03 14:36:48.286 DEBUG: Taking gradient step
2023-01-03 14:36:50.664 DEBUG: Loss 4: {'policy_loss': 0.0245420577583423, 'entropy_loss': -0.07036113925278187, 'vf_loss': 0.03337458895261551, 'total_loss': -0.04581908149443957, 'approx_kl': -0.029239804483950138, 'clip_fraction': 0.3307291716337204, 'grad_norm': 17.76462173461914}
2023-01-03 14:36:52.993 DEBUG: Taking gradient step
2023-01-03 14:36:55.392 DEBUG: Loss 5: {'policy_loss': -0.011838034470979204, 'entropy_loss': -0.07047200575470924, 'vf_loss': 0.03190275334446826, 'total_loss': -0.08231004022568844, 'approx_kl': -0.052516995929181576, 'clip_fraction': 0.3424479216337204, 'grad_norm': 21.28590965270996}
2023-01-03 14:36:57.726 DEBUG: Taking gradient step
2023-01-03 14:37:00.075 DEBUG: Loss 6: {'policy_loss': -0.012218576781362477, 'entropy_loss': -0.06887581199407578, 'vf_loss': 0.033736041978360505, 'total_loss': -0.08109438877543826, 'approx_kl': -0.06823871564120054, 'clip_fraction': 0.3111979179084301, 'grad_norm': 20.176422119140625}
2023-01-03 14:37:02.022 DEBUG: Taking gradient step
2023-01-03 14:37:04.037 DEBUG: Loss 7: {'policy_loss': -0.037830030828457054, 'entropy_loss': -0.06851688772439957, 'vf_loss': 0.032901702880807945, 'total_loss': -0.10634691855285662, 'approx_kl': -0.05845889449119568, 'clip_fraction': 0.2903645858168602, 'grad_norm': 13.380806922912598}
2023-01-03 14:37:05.993 DEBUG: Taking gradient step
2023-01-03 14:37:08.011 DEBUG: Loss 8: {'policy_loss': 0.027360971735362883, 'entropy_loss': -0.06857548281550407, 'vf_loss': 0.032414812673375995, 'total_loss': -0.04121451108014118, 'approx_kl': -0.07494805310852826, 'clip_fraction': 0.34765625, 'grad_norm': 19.648618698120117}
2023-01-03 14:37:09.969 DEBUG: Taking gradient step
2023-01-03 14:37:11.966 DEBUG: Loss 9: {'policy_loss': 0.02270110325496298, 'entropy_loss': -0.06820107065141201, 'vf_loss': 0.032329108400736384, 'total_loss': -0.04549996739644903, 'approx_kl': -0.07882248796522617, 'clip_fraction': 0.3997395858168602, 'grad_norm': 17.943443298339844}
2023-01-03 14:37:14.200 DEBUG: Taking gradient step
2023-01-03 14:37:16.601 DEBUG: Loss 10: {'policy_loss': 0.0015505383509264933, 'entropy_loss': -0.0694965273141861, 'vf_loss': 0.031223139155998506, 'total_loss': -0.06794598896325961, 'approx_kl': -0.07492487947456539, 'clip_fraction': 0.4140625, 'grad_norm': 16.24846839904785}
2023-01-03 14:37:19.030 DEBUG: Taking gradient step
2023-01-03 14:37:21.264 DEBUG: Loss 11: {'policy_loss': 0.005548451418189465, 'entropy_loss': -0.06715533323585987, 'vf_loss': 0.0308230257828186, 'total_loss': -0.061606881817670406, 'approx_kl': -0.06642417307011783, 'clip_fraction': 0.3893229216337204, 'grad_norm': 16.70285415649414}
2023-01-03 14:37:23.242 DEBUG: Taking gradient step
2023-01-03 14:37:25.248 DEBUG: Loss 12: {'policy_loss': -0.03385225725504837, 'entropy_loss': -0.06871264427900314, 'vf_loss': 0.031099656875936257, 'total_loss': -0.10256490153405151, 'approx_kl': -0.07454749150201678, 'clip_fraction': 0.359375, 'grad_norm': 15.008584976196289}
2023-01-03 14:37:27.221 DEBUG: Taking gradient step
2023-01-03 14:37:29.244 DEBUG: Loss 13: {'policy_loss': 0.009419251804750605, 'entropy_loss': -0.06801698077470064, 'vf_loss': 0.030273464958260776, 'total_loss': -0.05859772896995004, 'approx_kl': -0.08588603883981705, 'clip_fraction': 0.3619791716337204, 'grad_norm': 19.544464111328125}
2023-01-03 14:37:31.219 DEBUG: Taking gradient step
2023-01-03 14:37:33.227 DEBUG: Loss 14: {'policy_loss': 0.04747159690997102, 'entropy_loss': -0.06688986904919147, 'vf_loss': 0.03190390694450286, 'total_loss': -0.019418272139220455, 'approx_kl': -0.07856774982064962, 'clip_fraction': 0.4375, 'grad_norm': 23.819866180419922}
2023-01-03 14:37:33.228 INFO: Optimization: policy loss=0.047, vf loss=0.032, entropy loss=-0.067, total loss=-0.019, num steps=15
2023-01-03 14:37:33.229 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 14:37:34.933 INFO: Evaluation rollout: return=0.270 (0.0), episode length=6.0
2023-01-03 14:37:34.934 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 14:37:34.937 INFO: Iteration: 8/137, steps: 1728
2023-01-03 14:37:44.298 DEBUG: Atoms are too close
2023-01-03 14:37:46.603 DEBUG: Atoms are too close
2023-01-03 14:37:46.968 DEBUG: Atoms are too close
2023-01-03 14:37:47.111 DEBUG: Atoms are too close
2023-01-03 14:37:47.112 DEBUG: Atoms are too close
2023-01-03 14:37:48.238 DEBUG: Atoms are too close
2023-01-03 14:37:48.663 DEBUG: Atoms are too close
2023-01-03 14:38:00.587 DEBUG: Atoms are too close
2023-01-03 14:38:02.659 DEBUG: Atoms are too close
2023-01-03 14:38:04.743 DEBUG: Atoms are too close
2023-01-03 14:38:08.697 DEBUG: Atoms are too close
2023-01-03 14:38:09.930 DEBUG: Atoms are too close
2023-01-03 14:38:10.210 DEBUG: There is a single atom floating around
2023-01-03 14:38:14.547 DEBUG: Atoms are too close
2023-01-03 14:38:14.916 DEBUG: Atoms are too close
2023-01-03 14:38:16.326 DEBUG: Atoms are too close
2023-01-03 14:38:21.482 DEBUG: Atoms are too close
2023-01-03 14:38:22.048 DEBUG: Atoms are too close
2023-01-03 14:38:22.623 DEBUG: Atoms are too close
2023-01-03 14:38:23.823 DEBUG: Atoms are too close
2023-01-03 14:38:26.162 INFO: Training rollout: return=-8.638 (8.5), episode length=5.3
2023-01-03 14:38:26.163 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 14:38:26.166 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-1728_train.pkl
2023-01-03 14:38:28.122 DEBUG: Taking gradient step
2023-01-03 14:38:30.108 DEBUG: Loss 0: {'policy_loss': -0.03568561010094541, 'entropy_loss': -0.0687697771936655, 'vf_loss': 0.03190566645316596, 'total_loss': -0.10445538729461092, 'approx_kl': -1.7656326178894233e-08, 'clip_fraction': 0.0, 'grad_norm': 17.48797607421875}
2023-01-03 14:38:32.044 DEBUG: Taking gradient step
2023-01-03 14:38:34.068 DEBUG: Loss 1: {'policy_loss': 0.025839730216623513, 'entropy_loss': -0.06888382881879807, 'vf_loss': 0.03258275039598929, 'total_loss': -0.04304409860217455, 'approx_kl': -0.0019935023738071322, 'clip_fraction': 0.06510416697710752, 'grad_norm': 17.895709991455078}
2023-01-03 14:38:36.037 DEBUG: Taking gradient step
2023-01-03 14:38:38.026 DEBUG: Loss 2: {'policy_loss': 0.036447843801481146, 'entropy_loss': -0.07043351605534554, 'vf_loss': 0.03319409640607135, 'total_loss': -0.03398567225386438, 'approx_kl': -0.020077161490917206, 'clip_fraction': 0.2018229179084301, 'grad_norm': 25.553184509277344}
2023-01-03 14:38:39.980 DEBUG: Taking gradient step
2023-01-03 14:38:42.003 DEBUG: Loss 3: {'policy_loss': 0.03958635524613194, 'entropy_loss': -0.06952271610498428, 'vf_loss': 0.03182362369053683, 'total_loss': -0.02993636085885235, 'approx_kl': -0.04377589747309685, 'clip_fraction': 0.3919270858168602, 'grad_norm': 21.364383697509766}
2023-01-03 14:38:43.960 DEBUG: Taking gradient step
2023-01-03 14:38:45.978 DEBUG: Loss 4: {'policy_loss': 0.12250417249068296, 'entropy_loss': -0.06988128274679184, 'vf_loss': 0.03498572838675736, 'total_loss': 0.05262288974389113, 'approx_kl': -0.04537548962980509, 'clip_fraction': 0.4140625, 'grad_norm': 21.61559295654297}
2023-01-03 14:38:47.935 DEBUG: Taking gradient step
2023-01-03 14:38:49.943 DEBUG: Loss 5: {'policy_loss': 0.0890345825124604, 'entropy_loss': -0.06855100952088833, 'vf_loss': 0.032745675832167316, 'total_loss': 0.020483572991572063, 'approx_kl': -0.08501637354493141, 'clip_fraction': 0.4752604216337204, 'grad_norm': 23.60159683227539}
2023-01-03 14:38:51.888 DEBUG: Taking gradient step
2023-01-03 14:38:53.905 DEBUG: Loss 6: {'policy_loss': 0.03762930103101738, 'entropy_loss': -0.069579117000103, 'vf_loss': 0.031083693508812987, 'total_loss': -0.03194981596908562, 'approx_kl': -0.08647065656259656, 'clip_fraction': 0.515625, 'grad_norm': 17.583972930908203}
2023-01-03 14:38:55.864 DEBUG: Taking gradient step
2023-01-03 14:38:57.878 DEBUG: Loss 7: {'policy_loss': 0.10470174048840455, 'entropy_loss': -0.06778625585138798, 'vf_loss': 0.034273834199777614, 'total_loss': 0.03691548463701658, 'approx_kl': -0.0829717107117176, 'clip_fraction': 0.4739583358168602, 'grad_norm': 18.324125289916992}
2023-01-03 14:38:59.820 DEBUG: Taking gradient step
2023-01-03 14:39:01.918 DEBUG: Loss 8: {'policy_loss': 0.0525706430116033, 'entropy_loss': -0.06782097183167934, 'vf_loss': 0.034152750952095884, 'total_loss': -0.015250328820076042, 'approx_kl': -0.07255369704216719, 'clip_fraction': 0.5013020858168602, 'grad_norm': 24.61884307861328}
2023-01-03 14:39:03.865 DEBUG: Taking gradient step
2023-01-03 14:39:05.855 DEBUG: Loss 9: {'policy_loss': 0.04370391643201623, 'entropy_loss': -0.06750422343611717, 'vf_loss': 0.031356213519632886, 'total_loss': -0.02380030700410094, 'approx_kl': -0.08308400679379702, 'clip_fraction': 0.4739583358168602, 'grad_norm': 15.699664115905762}
2023-01-03 14:39:07.803 DEBUG: Taking gradient step
2023-01-03 14:39:09.800 DEBUG: Loss 10: {'policy_loss': 0.007486121848095086, 'entropy_loss': -0.06843489222228527, 'vf_loss': 0.03234078428582113, 'total_loss': -0.06094877037419018, 'approx_kl': -0.0854237973690033, 'clip_fraction': 0.4309895858168602, 'grad_norm': 23.89480972290039}
2023-01-03 14:39:11.743 DEBUG: Taking gradient step
2023-01-03 14:39:13.727 DEBUG: Loss 11: {'policy_loss': 0.011024905928122289, 'entropy_loss': -0.06656214967370033, 'vf_loss': 0.030906075584490336, 'total_loss': -0.055537243745578044, 'approx_kl': -0.10469478648155928, 'clip_fraction': 0.4192708358168602, 'grad_norm': 25.336275100708008}
2023-01-03 14:39:15.666 DEBUG: Taking gradient step
2023-01-03 14:39:17.657 DEBUG: Loss 12: {'policy_loss': -0.006962033136862628, 'entropy_loss': -0.06663785874843597, 'vf_loss': 0.02998986356895332, 'total_loss': -0.0735998918852986, 'approx_kl': -0.114939134567976, 'clip_fraction': 0.4192708358168602, 'grad_norm': 19.67671775817871}
2023-01-03 14:39:19.583 DEBUG: Taking gradient step
2023-01-03 14:39:21.562 DEBUG: Loss 13: {'policy_loss': 0.035832695281199166, 'entropy_loss': -0.06744686886668205, 'vf_loss': 0.030170265098267403, 'total_loss': -0.03161417358548288, 'approx_kl': -0.10908521432429552, 'clip_fraction': 0.45703125, 'grad_norm': 18.99262809753418}
2023-01-03 14:39:23.500 DEBUG: Taking gradient step
2023-01-03 14:39:25.537 DEBUG: Loss 14: {'policy_loss': 0.06295342566685654, 'entropy_loss': -0.0672947708517313, 'vf_loss': 0.03326283787375303, 'total_loss': -0.004341345184874779, 'approx_kl': -0.11626270506531, 'clip_fraction': 0.49609375, 'grad_norm': 24.097936630249023}
2023-01-03 14:39:25.538 INFO: Optimization: policy loss=0.063, vf loss=0.033, entropy loss=-0.067, total loss=-0.004, num steps=15
2023-01-03 14:39:25.539 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 14:39:26.650 DEBUG: Atoms are too close
2023-01-03 14:39:26.652 INFO: Evaluation rollout: return=-15.366 (0.0), episode length=5.0
2023-01-03 14:39:26.653 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 14:39:26.656 INFO: Iteration: 9/137, steps: 1944
2023-01-03 14:39:36.279 DEBUG: There is a single atom floating around
2023-01-03 14:39:36.564 DEBUG: Atoms are too close
2023-01-03 14:39:36.847 DEBUG: Atoms are too close
2023-01-03 14:39:40.218 DEBUG: Atoms are too close
2023-01-03 14:39:43.119 DEBUG: Atoms are too close
2023-01-03 14:39:43.273 DEBUG: Atoms are too close
2023-01-03 14:39:53.254 DEBUG: Atoms are too close
2023-01-03 14:39:57.876 DEBUG: Atoms are too close
2023-01-03 14:39:58.447 DEBUG: Atoms are too close
2023-01-03 14:39:58.521 DEBUG: Atoms are too close
2023-01-03 14:39:58.522 DEBUG: There is a single atom floating around
2023-01-03 14:39:58.523 DEBUG: Atoms are too close
2023-01-03 14:40:00.217 DEBUG: Atoms are too close
2023-01-03 14:40:04.428 DEBUG: Atoms are too close
2023-01-03 14:40:04.706 DEBUG: Atoms are too close
2023-01-03 14:40:08.179 DEBUG: Atoms are too close
2023-01-03 14:40:08.829 DEBUG: Atoms are too close
2023-01-03 14:40:10.838 DEBUG: Atoms are too close
2023-01-03 14:40:13.310 DEBUG: Atoms are too close
2023-01-03 14:40:13.746 DEBUG: Atoms are too close
2023-01-03 14:40:13.746 DEBUG: Atoms are too close
2023-01-03 14:40:16.861 INFO: Training rollout: return=-9.065 (8.8), episode length=5.3
2023-01-03 14:40:16.863 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 14:40:16.866 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-1944_train.pkl
2023-01-03 14:40:18.871 DEBUG: Taking gradient step
2023-01-03 14:40:20.935 DEBUG: Loss 0: {'policy_loss': 0.024556097727086015, 'entropy_loss': -0.06730460375547409, 'vf_loss': 0.04271863639114416, 'total_loss': -0.04274850602838808, 'approx_kl': -1.4668330550193787e-08, 'clip_fraction': 0.0, 'grad_norm': 20.95850372314453}
2023-01-03 14:40:22.934 DEBUG: Taking gradient step
2023-01-03 14:40:24.971 DEBUG: Loss 1: {'policy_loss': 0.02416970147496436, 'entropy_loss': -0.06679337006062269, 'vf_loss': 0.04161353381983349, 'total_loss': -0.04262366858565833, 'approx_kl': -0.005125526920892298, 'clip_fraction': 0.0859375, 'grad_norm': 35.2064208984375}
2023-01-03 14:40:26.897 DEBUG: Taking gradient step
2023-01-03 14:40:28.881 DEBUG: Loss 2: {'policy_loss': 0.022887009121779184, 'entropy_loss': -0.06586319766938686, 'vf_loss': 0.04132709058001754, 'total_loss': -0.04297618854760768, 'approx_kl': -0.025740694720298052, 'clip_fraction': 0.2825520858168602, 'grad_norm': 36.13508987426758}
2023-01-03 14:40:30.824 DEBUG: Taking gradient step
2023-01-03 14:40:32.818 DEBUG: Loss 3: {'policy_loss': -0.006631228443547681, 'entropy_loss': -0.0668122423812747, 'vf_loss': 0.04015236783244609, 'total_loss': -0.07344347082482237, 'approx_kl': -0.03550404775887728, 'clip_fraction': 0.3684895858168602, 'grad_norm': 32.14923095703125}
2023-01-03 14:40:34.763 DEBUG: Taking gradient step
2023-01-03 14:40:36.752 DEBUG: Loss 4: {'policy_loss': 0.03247177675481579, 'entropy_loss': -0.06592183839529753, 'vf_loss': 0.0420890984499868, 'total_loss': -0.03345006164048174, 'approx_kl': -0.048631091602146626, 'clip_fraction': 0.3815104216337204, 'grad_norm': 31.78632354736328}
2023-01-03 14:40:38.688 DEBUG: Taking gradient step
2023-01-03 14:40:40.676 DEBUG: Loss 5: {'policy_loss': 0.10042881891227301, 'entropy_loss': -0.0669018430635333, 'vf_loss': 0.041618385475032695, 'total_loss': 0.0335269758487397, 'approx_kl': -0.04461739305406809, 'clip_fraction': 0.39453125, 'grad_norm': 26.413835525512695}
2023-01-03 14:40:42.712 DEBUG: Taking gradient step
2023-01-03 14:40:44.710 DEBUG: Loss 6: {'policy_loss': 0.03978881103550246, 'entropy_loss': -0.06518979370594025, 'vf_loss': 0.04075490177438514, 'total_loss': -0.025400982670437784, 'approx_kl': -0.036635374184697866, 'clip_fraction': 0.3268229216337204, 'grad_norm': 22.718297958374023}
2023-01-03 14:40:46.658 DEBUG: Taking gradient step
2023-01-03 14:40:48.684 DEBUG: Loss 7: {'policy_loss': -0.0010113012605317065, 'entropy_loss': -0.0652978178113699, 'vf_loss': 0.04045106842211754, 'total_loss': -0.06630911907190161, 'approx_kl': -0.04333093808963895, 'clip_fraction': 0.3307291716337204, 'grad_norm': 19.992374420166016}
2023-01-03 14:40:50.640 DEBUG: Taking gradient step
2023-01-03 14:40:52.649 DEBUG: Loss 8: {'policy_loss': -0.011053090893722459, 'entropy_loss': -0.0639705965295434, 'vf_loss': 0.040209376725969394, 'total_loss': -0.07502368742326586, 'approx_kl': -0.05423041619360447, 'clip_fraction': 0.3072916679084301, 'grad_norm': 21.478439331054688}
2023-01-03 14:40:54.602 DEBUG: Taking gradient step
2023-01-03 14:40:56.606 DEBUG: Loss 9: {'policy_loss': 0.0886655279258784, 'entropy_loss': -0.06172687187790871, 'vf_loss': 0.04035937807526339, 'total_loss': 0.026938656047969682, 'approx_kl': -0.050463272258639336, 'clip_fraction': 0.4010416716337204, 'grad_norm': 30.518352508544922}
2023-01-03 14:40:58.545 DEBUG: Taking gradient step
2023-01-03 14:41:00.543 DEBUG: Loss 10: {'policy_loss': 0.0708539586616645, 'entropy_loss': -0.06530324649065733, 'vf_loss': 0.03933539906237053, 'total_loss': 0.005550712171007168, 'approx_kl': -0.0793173355050385, 'clip_fraction': 0.4557291716337204, 'grad_norm': 37.151702880859375}
2023-01-03 14:41:02.498 DEBUG: Taking gradient step
2023-01-03 14:41:04.515 DEBUG: Loss 11: {'policy_loss': -0.012026265647495732, 'entropy_loss': -0.06347076315432787, 'vf_loss': 0.039497474127960265, 'total_loss': -0.0754970288018236, 'approx_kl': -0.07374838646501303, 'clip_fraction': 0.41015625, 'grad_norm': 26.07488441467285}
2023-01-03 14:41:06.476 DEBUG: Taking gradient step
2023-01-03 14:41:08.495 DEBUG: Loss 12: {'policy_loss': -0.005047651720395868, 'entropy_loss': -0.06387111358344555, 'vf_loss': 0.0391655049019551, 'total_loss': -0.06891876530384142, 'approx_kl': -0.05240464932285249, 'clip_fraction': 0.3723958358168602, 'grad_norm': 21.071773529052734}
2023-01-03 14:41:10.444 DEBUG: Taking gradient step
2023-01-03 14:41:12.439 DEBUG: Loss 13: {'policy_loss': 0.07029543413520503, 'entropy_loss': -0.06274227239191532, 'vf_loss': 0.03920773203904807, 'total_loss': 0.00755316174328971, 'approx_kl': -0.057970537804067135, 'clip_fraction': 0.3333333358168602, 'grad_norm': 16.383296966552734}
2023-01-03 14:41:14.387 DEBUG: Taking gradient step
2023-01-03 14:41:16.373 DEBUG: Loss 14: {'policy_loss': 0.10762862064806444, 'entropy_loss': -0.06466057151556015, 'vf_loss': 0.039168976787283157, 'total_loss': 0.042968049132504293, 'approx_kl': -0.07726459484547377, 'clip_fraction': 0.4127604216337204, 'grad_norm': 28.295387268066406}
2023-01-03 14:41:16.373 INFO: Optimization: policy loss=0.108, vf loss=0.039, entropy loss=-0.065, total loss=0.043, num steps=15
2023-01-03 14:41:16.375 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 14:41:17.490 DEBUG: Atoms are too close
2023-01-03 14:41:17.492 INFO: Evaluation rollout: return=-15.458 (0.0), episode length=5.0
2023-01-03 14:41:17.493 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 14:41:17.497 INFO: Iteration: 10/137, steps: 2160
2023-01-03 14:41:26.574 DEBUG: Atoms are too close
2023-01-03 14:41:28.883 DEBUG: Atoms are too close
2023-01-03 14:41:30.552 DEBUG: Atoms are too close
2023-01-03 14:41:32.203 DEBUG: Atoms are too close
2023-01-03 14:41:42.413 DEBUG: Atoms are too close
2023-01-03 14:41:44.523 DEBUG: Atoms are too close
2023-01-03 14:41:44.525 DEBUG: Atoms are too close
2023-01-03 14:41:44.812 DEBUG: Atoms are too close
2023-01-03 14:41:44.957 DEBUG: Atoms are too close
2023-01-03 14:41:45.546 DEBUG: Atoms are too close
2023-01-03 14:41:45.833 DEBUG: Atoms are too close
2023-01-03 14:41:45.899 DEBUG: Atoms are too close
2023-01-03 14:41:47.054 DEBUG: Atoms are too close
2023-01-03 14:41:56.879 DEBUG: Atoms are too close
2023-01-03 14:41:59.264 DEBUG: Atoms are too close
2023-01-03 14:42:00.262 DEBUG: Atoms are too close
2023-01-03 14:42:02.904 DEBUG: Atoms are too close
2023-01-03 14:42:03.116 DEBUG: Atoms are too close
2023-01-03 14:42:08.995 INFO: Training rollout: return=-8.103 (8.4), episode length=5.4
2023-01-03 14:42:08.996 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 14:42:08.999 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-2160_train.pkl
2023-01-03 14:42:10.953 DEBUG: Taking gradient step
2023-01-03 14:42:12.952 DEBUG: Loss 0: {'policy_loss': -0.0028256080612943284, 'entropy_loss': -0.06458026822656393, 'vf_loss': 0.03372875243659898, 'total_loss': -0.06740587628785825, 'approx_kl': 1.5774276107549667e-08, 'clip_fraction': 0.0, 'grad_norm': 22.42215919494629}
2023-01-03 14:42:14.889 DEBUG: Taking gradient step
2023-01-03 14:42:16.897 DEBUG: Loss 1: {'policy_loss': 0.0574751489610426, 'entropy_loss': -0.06365824118256569, 'vf_loss': 0.0345659353849104, 'total_loss': -0.006183092221523079, 'approx_kl': -0.024743825662881136, 'clip_fraction': 0.1744791679084301, 'grad_norm': 22.435754776000977}
2023-01-03 14:42:18.852 DEBUG: Taking gradient step
2023-01-03 14:42:20.945 DEBUG: Loss 2: {'policy_loss': 0.05205589353803211, 'entropy_loss': -0.06331256777048111, 'vf_loss': 0.03382120771304681, 'total_loss': -0.011256674232448995, 'approx_kl': -0.030136657413095236, 'clip_fraction': 0.3971354216337204, 'grad_norm': 24.10452651977539}
2023-01-03 14:42:22.889 DEBUG: Taking gradient step
2023-01-03 14:42:24.896 DEBUG: Loss 3: {'policy_loss': 0.05821906969376011, 'entropy_loss': -0.062846883200109, 'vf_loss': 0.033237365313272864, 'total_loss': -0.004627813506348888, 'approx_kl': -0.05020696157589555, 'clip_fraction': 0.4192708358168602, 'grad_norm': 30.400178909301758}
2023-01-03 14:42:26.834 DEBUG: Taking gradient step
2023-01-03 14:42:28.830 DEBUG: Loss 4: {'policy_loss': 0.03953727755737388, 'entropy_loss': -0.06360161863267422, 'vf_loss': 0.032066961078144315, 'total_loss': -0.02406434107530033, 'approx_kl': -0.0627543618902564, 'clip_fraction': 0.4231770858168602, 'grad_norm': 26.334518432617188}
2023-01-03 14:42:30.759 DEBUG: Taking gradient step
2023-01-03 14:42:32.728 DEBUG: Loss 5: {'policy_loss': 0.06939396994693653, 'entropy_loss': -0.0633557066321373, 'vf_loss': 0.0331141150199988, 'total_loss': 0.006038263314799237, 'approx_kl': -0.04488085559569299, 'clip_fraction': 0.3919270858168602, 'grad_norm': 25.571229934692383}
2023-01-03 14:42:34.648 DEBUG: Taking gradient step
2023-01-03 14:42:36.609 DEBUG: Loss 6: {'policy_loss': 0.09228413606594103, 'entropy_loss': -0.06004041247069836, 'vf_loss': 0.033429981209345955, 'total_loss': 0.032243723595242677, 'approx_kl': -0.05117790214717388, 'clip_fraction': 0.3828125, 'grad_norm': 25.206249237060547}
2023-01-03 14:42:38.528 DEBUG: Taking gradient step
2023-01-03 14:42:40.494 DEBUG: Loss 7: {'policy_loss': 0.03451440625494255, 'entropy_loss': -0.062219698913395405, 'vf_loss': 0.033677593125806156, 'total_loss': -0.02770529265845285, 'approx_kl': -0.06682559847831726, 'clip_fraction': 0.34765625, 'grad_norm': 25.63570785522461}
2023-01-03 14:42:42.419 DEBUG: Taking gradient step
2023-01-03 14:42:44.412 DEBUG: Loss 8: {'policy_loss': 0.0024548892664515293, 'entropy_loss': -0.06183714605867863, 'vf_loss': 0.03348308296775531, 'total_loss': -0.059382256792227105, 'approx_kl': -0.050374590791761875, 'clip_fraction': 0.3854166716337204, 'grad_norm': 24.03835105895996}
2023-01-03 14:42:46.338 DEBUG: Taking gradient step
2023-01-03 14:42:48.320 DEBUG: Loss 9: {'policy_loss': 0.07589428036432358, 'entropy_loss': -0.0619765967130661, 'vf_loss': 0.03452946855146406, 'total_loss': 0.013917683651257472, 'approx_kl': -0.0651367511600256, 'clip_fraction': 0.3893229216337204, 'grad_norm': 26.79977035522461}
2023-01-03 14:42:50.234 DEBUG: Taking gradient step
2023-01-03 14:42:52.202 DEBUG: Loss 10: {'policy_loss': 0.11557929230890983, 'entropy_loss': -0.060925303027033806, 'vf_loss': 0.034381450731278726, 'total_loss': 0.05465398928187602, 'approx_kl': -0.06117229419760406, 'clip_fraction': 0.4440104216337204, 'grad_norm': 28.792360305786133}
2023-01-03 14:42:54.142 DEBUG: Taking gradient step
2023-01-03 14:42:56.505 DEBUG: Loss 11: {'policy_loss': 0.057094171333616175, 'entropy_loss': -0.06215052027255297, 'vf_loss': 0.03319872677594617, 'total_loss': -0.0050563489389367985, 'approx_kl': -0.07923834212124348, 'clip_fraction': 0.3736979216337204, 'grad_norm': 19.472257614135742}
2023-01-03 14:42:58.803 DEBUG: Taking gradient step
2023-01-03 14:43:01.159 DEBUG: Loss 12: {'policy_loss': -0.012227493528223499, 'entropy_loss': -0.060639845207333565, 'vf_loss': 0.033084337963632734, 'total_loss': -0.07286733873555706, 'approx_kl': -0.062102667056024075, 'clip_fraction': 0.4244791716337204, 'grad_norm': 23.29692268371582}
2023-01-03 14:43:03.454 DEBUG: Taking gradient step
2023-01-03 14:43:05.809 DEBUG: Loss 13: {'policy_loss': 0.0002819024393868261, 'entropy_loss': -0.06265976466238499, 'vf_loss': 0.0333303991867927, 'total_loss': -0.06237786222299816, 'approx_kl': -0.07883223611861467, 'clip_fraction': 0.4166666716337204, 'grad_norm': 25.205209732055664}
2023-01-03 14:43:08.091 DEBUG: Taking gradient step
2023-01-03 14:43:10.446 DEBUG: Loss 14: {'policy_loss': 0.02384377200575264, 'entropy_loss': -0.061501785181462765, 'vf_loss': 0.03295794976179159, 'total_loss': -0.037658013175710124, 'approx_kl': -0.09912879392504692, 'clip_fraction': 0.4713541716337204, 'grad_norm': 25.178974151611328}
2023-01-03 14:43:10.446 INFO: Optimization: policy loss=0.024, vf loss=0.033, entropy loss=-0.062, total loss=-0.038, num steps=15
2023-01-03 14:43:10.447 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 14:43:11.879 DEBUG: Atoms are too close
2023-01-03 14:43:11.881 INFO: Evaluation rollout: return=-13.348 (0.0), episode length=6.0
2023-01-03 14:43:11.882 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 14:43:11.885 DEBUG: Deleting old model: runs/CH3NO_dna/models/CH3NO_dna_run-1_steps-216.model
2023-01-03 14:43:11.890 DEBUG: Saving model: runs/CH3NO_dna/models/CH3NO_dna_run-1_steps-2376.model
2023-01-03 14:43:11.937 INFO: Iteration: 11/137, steps: 2376
2023-01-03 14:43:22.897 DEBUG: Atoms are too close
2023-01-03 14:43:24.693 DEBUG: Atoms are too close
2023-01-03 14:43:24.988 DEBUG: Atoms are too close
2023-01-03 14:43:25.701 DEBUG: Atoms are too close
2023-01-03 14:43:25.703 DEBUG: Atoms are too close
2023-01-03 14:43:25.704 DEBUG: Atoms are too close
2023-01-03 14:43:26.801 DEBUG: Atoms are too close
2023-01-03 14:43:38.897 DEBUG: Atoms are too close
2023-01-03 14:43:38.900 DEBUG: Atoms are too close
2023-01-03 14:43:39.777 DEBUG: Atoms are too close
2023-01-03 14:43:42.102 DEBUG: Atoms are too close
2023-01-03 14:43:49.958 DEBUG: Atoms are too close
2023-01-03 14:43:51.928 DEBUG: There is a single atom floating around
2023-01-03 14:43:53.675 DEBUG: Atoms are too close
2023-01-03 14:43:55.048 DEBUG: Atoms are too close
2023-01-03 14:43:55.889 DEBUG: Atoms are too close
2023-01-03 14:44:00.969 DEBUG: Atoms are too close
2023-01-03 14:44:01.121 DEBUG: There is a single atom floating around
2023-01-03 14:44:03.168 INFO: Training rollout: return=-7.954 (8.6), episode length=5.4
2023-01-03 14:44:03.170 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 14:44:03.173 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-2376_train.pkl
2023-01-03 14:44:05.117 DEBUG: Taking gradient step
2023-01-03 14:44:07.093 DEBUG: Loss 0: {'policy_loss': 0.008337405528315868, 'entropy_loss': -0.06393984705209732, 'vf_loss': 0.0382212017458364, 'total_loss': -0.05560244152378145, 'approx_kl': -4.652732599197407e-08, 'clip_fraction': 0.0, 'grad_norm': 19.45155143737793}
2023-01-03 14:44:09.000 DEBUG: Taking gradient step
2023-01-03 14:44:10.976 DEBUG: Loss 1: {'policy_loss': -0.026599661037379582, 'entropy_loss': -0.0624302988871932, 'vf_loss': 0.03575407524574483, 'total_loss': -0.08902995992457279, 'approx_kl': 0.011390474974177778, 'clip_fraction': 0.078125, 'grad_norm': 15.048737525939941}
2023-01-03 14:44:12.904 DEBUG: Taking gradient step
2023-01-03 14:44:14.892 DEBUG: Loss 2: {'policy_loss': 0.016747066595494423, 'entropy_loss': -0.06460928358137608, 'vf_loss': 0.03591621824416353, 'total_loss': -0.04786221698588165, 'approx_kl': -0.024065349251031876, 'clip_fraction': 0.13151041697710752, 'grad_norm': 19.758426666259766}
2023-01-03 14:44:16.829 DEBUG: Taking gradient step
2023-01-03 14:44:18.816 DEBUG: Loss 3: {'policy_loss': 0.011510523951406636, 'entropy_loss': -0.06644359137862921, 'vf_loss': 0.03753564529113496, 'total_loss': -0.054933067427222565, 'approx_kl': -0.039995403960347176, 'clip_fraction': 0.3125, 'grad_norm': 31.61065673828125}
2023-01-03 14:44:20.750 DEBUG: Taking gradient step
2023-01-03 14:44:22.736 DEBUG: Loss 4: {'policy_loss': 0.07268005055601368, 'entropy_loss': -0.06610416807234287, 'vf_loss': 0.036373480846579154, 'total_loss': 0.0065758824836707995, 'approx_kl': -0.040574859362095594, 'clip_fraction': 0.3984375, 'grad_norm': 19.139307022094727}
2023-01-03 14:44:24.670 DEBUG: Taking gradient step
2023-01-03 14:44:26.685 DEBUG: Loss 5: {'policy_loss': 0.03376621405157022, 'entropy_loss': -0.06630856543779373, 'vf_loss': 0.03534739459132938, 'total_loss': -0.03254235138622351, 'approx_kl': -0.06898390362039208, 'clip_fraction': 0.3450520858168602, 'grad_norm': 16.39703369140625}
2023-01-03 14:44:28.634 DEBUG: Taking gradient step
2023-01-03 14:44:30.628 DEBUG: Loss 6: {'policy_loss': 0.11228890187613481, 'entropy_loss': -0.0639323815703392, 'vf_loss': 0.03711597300473567, 'total_loss': 0.04835652030579561, 'approx_kl': -0.06231330940499902, 'clip_fraction': 0.3684895858168602, 'grad_norm': 20.91534423828125}
2023-01-03 14:44:32.606 DEBUG: Taking gradient step
2023-01-03 14:44:34.637 DEBUG: Loss 7: {'policy_loss': 0.06441954226773919, 'entropy_loss': -0.0629884609952569, 'vf_loss': 0.034915216713290155, 'total_loss': 0.0014310812724822788, 'approx_kl': -0.04128108103759587, 'clip_fraction': 0.3932291716337204, 'grad_norm': 24.28128433227539}
2023-01-03 14:44:36.593 DEBUG: Taking gradient step
2023-01-03 14:44:38.601 DEBUG: Loss 8: {'policy_loss': 0.1366159800752374, 'entropy_loss': -0.06457824911922216, 'vf_loss': 0.03833151523933413, 'total_loss': 0.07203773095601525, 'approx_kl': -0.07623511925339699, 'clip_fraction': 0.3841145858168602, 'grad_norm': 21.400558471679688}
2023-01-03 14:44:40.558 DEBUG: Taking gradient step
2023-01-03 14:44:42.548 DEBUG: Loss 9: {'policy_loss': 0.057601759244667906, 'entropy_loss': -0.06404578406363726, 'vf_loss': 0.03605646077653678, 'total_loss': -0.006444024818969352, 'approx_kl': -0.07237258832901716, 'clip_fraction': 0.4153645858168602, 'grad_norm': 14.078015327453613}
2023-01-03 14:44:44.496 DEBUG: Taking gradient step
2023-01-03 14:44:46.475 DEBUG: Loss 10: {'policy_loss': 0.015120051690932765, 'entropy_loss': -0.06167607940733433, 'vf_loss': 0.0349855373628421, 'total_loss': -0.04655602771640157, 'approx_kl': -0.05396623769775033, 'clip_fraction': 0.3828125, 'grad_norm': 24.792587280273438}
2023-01-03 14:44:48.401 DEBUG: Taking gradient step
2023-01-03 14:44:50.469 DEBUG: Loss 11: {'policy_loss': 0.008241373604283439, 'entropy_loss': -0.062427557073533535, 'vf_loss': 0.03481805182705526, 'total_loss': -0.054186183469250096, 'approx_kl': -0.07973376475274563, 'clip_fraction': 0.39453125, 'grad_norm': 24.53704071044922}
2023-01-03 14:44:52.386 DEBUG: Taking gradient step
2023-01-03 14:44:54.363 DEBUG: Loss 12: {'policy_loss': 0.0946793352330497, 'entropy_loss': -0.06243185978382826, 'vf_loss': 0.03680326230721899, 'total_loss': 0.032247475449221435, 'approx_kl': -0.08409320376813412, 'clip_fraction': 0.3203125, 'grad_norm': 21.411874771118164}
2023-01-03 14:44:56.289 DEBUG: Taking gradient step
2023-01-03 14:44:58.258 DEBUG: Loss 13: {'policy_loss': 0.07102263193725412, 'entropy_loss': -0.061111610382795334, 'vf_loss': 0.03620137058737803, 'total_loss': 0.00991102155445879, 'approx_kl': -0.08613061578944325, 'clip_fraction': 0.2981770858168602, 'grad_norm': 21.87632179260254}
2023-01-03 14:45:00.236 DEBUG: Taking gradient step
2023-01-03 14:45:02.275 DEBUG: Loss 14: {'policy_loss': 0.01597211244081464, 'entropy_loss': -0.062057606875896454, 'vf_loss': 0.035029391412412195, 'total_loss': -0.046085494435081815, 'approx_kl': -0.08898838143795729, 'clip_fraction': 0.2877604216337204, 'grad_norm': 19.881221771240234}
2023-01-03 14:45:02.275 INFO: Optimization: policy loss=0.016, vf loss=0.035, entropy loss=-0.062, total loss=-0.046, num steps=15
2023-01-03 14:45:02.277 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 14:45:03.357 DEBUG: Atoms are too close
2023-01-03 14:45:03.359 INFO: Evaluation rollout: return=-15.388 (0.0), episode length=5.0
2023-01-03 14:45:03.359 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 14:45:03.362 INFO: Iteration: 12/137, steps: 2592
2023-01-03 14:45:13.798 DEBUG: Atoms are too close
2023-01-03 14:45:14.642 DEBUG: Atoms are too close
2023-01-03 14:45:16.133 DEBUG: Atoms are too close
2023-01-03 14:45:16.560 DEBUG: Atoms are too close
2023-01-03 14:45:16.840 DEBUG: Atoms are too close
2023-01-03 14:45:17.931 DEBUG: Atoms are too close
2023-01-03 14:45:24.015 DEBUG: There is a single atom floating around
2023-01-03 14:45:24.017 DEBUG: Atoms are too close
2023-01-03 14:45:26.091 DEBUG: Atoms are too close
2023-01-03 14:45:29.151 DEBUG: Atoms are too close
2023-01-03 14:45:29.152 DEBUG: Atoms are too close
2023-01-03 14:45:30.585 DEBUG: Atoms are too close
2023-01-03 14:45:30.586 DEBUG: Atoms are too close
2023-01-03 14:45:33.569 DEBUG: Atoms are too close
2023-01-03 14:45:35.408 DEBUG: Atoms are too close
2023-01-03 14:45:55.488 INFO: Training rollout: return=-6.850 (8.6), episode length=5.4
2023-01-03 14:45:55.490 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 14:45:55.493 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-2592_train.pkl
2023-01-03 14:45:57.780 DEBUG: Taking gradient step
2023-01-03 14:46:00.177 DEBUG: Loss 0: {'policy_loss': -0.009609304507022897, 'entropy_loss': -0.05819973535835743, 'vf_loss': 0.02961264038321157, 'total_loss': -0.06780903986538032, 'approx_kl': 5.48316165804863e-08, 'clip_fraction': 0.0, 'grad_norm': 13.703768730163574}
2023-01-03 14:46:02.502 DEBUG: Taking gradient step
2023-01-03 14:46:04.878 DEBUG: Loss 1: {'policy_loss': 0.00285580251929406, 'entropy_loss': -0.06048610247671604, 'vf_loss': 0.03072067533760347, 'total_loss': -0.057630299957421985, 'approx_kl': -0.0049460728187114, 'clip_fraction': 0.045572916977107525, 'grad_norm': 15.482359886169434}
2023-01-03 14:46:06.909 DEBUG: Taking gradient step
2023-01-03 14:46:09.117 DEBUG: Loss 2: {'policy_loss': 0.01648296985717818, 'entropy_loss': -0.05985241290181875, 'vf_loss': 0.03005764554668927, 'total_loss': -0.04336944304464058, 'approx_kl': -0.02109824726358056, 'clip_fraction': 0.1705729179084301, 'grad_norm': 18.548728942871094}
2023-01-03 14:46:11.419 DEBUG: Taking gradient step
2023-01-03 14:46:13.797 DEBUG: Loss 3: {'policy_loss': 0.05197261953544099, 'entropy_loss': -0.06180645618587732, 'vf_loss': 0.03014604028300629, 'total_loss': -0.009833836650436342, 'approx_kl': -0.029906548792496324, 'clip_fraction': 0.4453125, 'grad_norm': 23.90467643737793}
2023-01-03 14:46:16.112 DEBUG: Taking gradient step
2023-01-03 14:46:18.496 DEBUG: Loss 4: {'policy_loss': 0.06990145816988556, 'entropy_loss': -0.05970135051757097, 'vf_loss': 0.029935856263222614, 'total_loss': 0.010200107652314591, 'approx_kl': -0.026218924904242158, 'clip_fraction': 0.4791666716337204, 'grad_norm': 23.57747459411621}
2023-01-03 14:46:20.820 DEBUG: Taking gradient step
2023-01-03 14:46:23.229 DEBUG: Loss 5: {'policy_loss': 0.06890396872677129, 'entropy_loss': -0.058282921090722084, 'vf_loss': 0.030319870513893538, 'total_loss': 0.010621047636049208, 'approx_kl': -0.01405899552628398, 'clip_fraction': 0.44140625, 'grad_norm': 21.078521728515625}
2023-01-03 14:46:25.543 DEBUG: Taking gradient step
2023-01-03 14:46:27.732 DEBUG: Loss 6: {'policy_loss': 0.12159720212969034, 'entropy_loss': -0.06053568236529827, 'vf_loss': 0.030658248509277355, 'total_loss': 0.06106151976439207, 'approx_kl': 0.01991323009133339, 'clip_fraction': 0.5455729216337204, 'grad_norm': 23.349891662597656}
2023-01-03 14:46:29.679 DEBUG: Taking gradient step
2023-01-03 14:46:31.704 DEBUG: Loss 7: {'policy_loss': 0.12877550645948913, 'entropy_loss': -0.05993902217596769, 'vf_loss': 0.02910702759414152, 'total_loss': 0.06883648428352145, 'approx_kl': 0.004808816127479076, 'clip_fraction': 0.6080729216337204, 'grad_norm': 26.51222801208496}
2023-01-03 14:46:33.661 DEBUG: Taking gradient step
2023-01-03 14:46:35.782 DEBUG: Loss 8: {'policy_loss': 0.11523728537461232, 'entropy_loss': -0.05978495813906193, 'vf_loss': 0.03020579391825652, 'total_loss': 0.055452327235550394, 'approx_kl': 0.01745573617517948, 'clip_fraction': 0.6328125, 'grad_norm': 25.49407958984375}
2023-01-03 14:46:37.739 DEBUG: Taking gradient step
2023-01-03 14:46:39.758 DEBUG: Loss 9: {'policy_loss': 0.07096060279570007, 'entropy_loss': -0.05944090522825718, 'vf_loss': 0.02948876819144794, 'total_loss': 0.011519697567442894, 'approx_kl': 0.0048864539712667465, 'clip_fraction': 0.58984375, 'grad_norm': 20.18471908569336}
2023-01-03 14:46:41.713 DEBUG: Taking gradient step
2023-01-03 14:46:43.714 DEBUG: Loss 10: {'policy_loss': 0.03930947448084669, 'entropy_loss': -0.05888698808848858, 'vf_loss': 0.02842964995563861, 'total_loss': -0.019577513607641886, 'approx_kl': -0.027604810893535614, 'clip_fraction': 0.5651041716337204, 'grad_norm': 23.693222045898438}
2023-01-03 14:46:45.661 DEBUG: Taking gradient step
2023-01-03 14:46:47.658 DEBUG: Loss 11: {'policy_loss': 0.10978428142177163, 'entropy_loss': -0.05956782307475805, 'vf_loss': 0.028162819516865573, 'total_loss': 0.050216458347013576, 'approx_kl': -0.0388750871643424, 'clip_fraction': 0.4908854216337204, 'grad_norm': 24.1622314453125}
2023-01-03 14:46:49.602 DEBUG: Taking gradient step
2023-01-03 14:46:51.590 DEBUG: Loss 12: {'policy_loss': 0.10527905835301889, 'entropy_loss': -0.06026372406631708, 'vf_loss': 0.028965278243960627, 'total_loss': 0.045015334286701805, 'approx_kl': -0.02414740202948451, 'clip_fraction': 0.4752604216337204, 'grad_norm': 19.585668563842773}
2023-01-03 14:46:53.516 DEBUG: Taking gradient step
2023-01-03 14:46:55.509 DEBUG: Loss 13: {'policy_loss': 0.06802741280072408, 'entropy_loss': -0.060692825354635715, 'vf_loss': 0.029970018792587344, 'total_loss': 0.007334587446088357, 'approx_kl': -0.007656735368072987, 'clip_fraction': 0.4127604216337204, 'grad_norm': 16.134721755981445}
2023-01-03 14:46:57.455 DEBUG: Taking gradient step
2023-01-03 14:46:59.446 DEBUG: Loss 14: {'policy_loss': -0.0010117479416437355, 'entropy_loss': -0.060461984016001225, 'vf_loss': 0.02960582328733162, 'total_loss': -0.06147373195764495, 'approx_kl': -0.057496597059071064, 'clip_fraction': 0.35546875, 'grad_norm': 17.80333137512207}
2023-01-03 14:46:59.447 INFO: Optimization: policy loss=-0.001, vf loss=0.030, entropy loss=-0.060, total loss=-0.061, num steps=15
2023-01-03 14:46:59.448 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 14:47:01.163 INFO: Evaluation rollout: return=0.233 (0.0), episode length=6.0
2023-01-03 14:47:01.164 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 14:47:01.166 INFO: Iteration: 13/137, steps: 2808
2023-01-03 14:47:11.052 DEBUG: Atoms are too close
2023-01-03 14:47:13.381 DEBUG: Atoms are too close
2023-01-03 14:47:25.880 DEBUG: Atoms are too close
2023-01-03 14:47:30.084 DEBUG: Atoms are too close
2023-01-03 14:47:31.852 DEBUG: Atoms are too close
2023-01-03 14:47:42.411 DEBUG: There is a single atom floating around
2023-01-03 14:47:45.047 DEBUG: Atoms are too close
2023-01-03 14:47:46.401 DEBUG: Atoms are too close
2023-01-03 14:47:53.787 DEBUG: Atoms are too close
2023-01-03 14:47:54.636 DEBUG: Atoms are too close
2023-01-03 14:47:55.000 INFO: Training rollout: return=-4.623 (8.1), episode length=5.6
2023-01-03 14:47:55.001 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 14:47:55.005 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-2808_train.pkl
2023-01-03 14:47:56.983 DEBUG: Taking gradient step
2023-01-03 14:47:59.010 DEBUG: Loss 0: {'policy_loss': -0.005716587983845993, 'entropy_loss': -0.06547076255083084, 'vf_loss': 0.026539846470456714, 'total_loss': -0.07118735053467683, 'approx_kl': -4.3616942946300696e-08, 'clip_fraction': 0.0, 'grad_norm': 24.23719024658203}
2023-01-03 14:48:00.971 DEBUG: Taking gradient step
2023-01-03 14:48:03.006 DEBUG: Loss 1: {'policy_loss': 0.09941886223908444, 'entropy_loss': -0.06348776072263718, 'vf_loss': 0.025835964652912685, 'total_loss': 0.03593110151644727, 'approx_kl': -0.021863177185878158, 'clip_fraction': 0.2630208358168602, 'grad_norm': 29.698062896728516}
2023-01-03 14:48:04.984 DEBUG: Taking gradient step
2023-01-03 14:48:07.009 DEBUG: Loss 2: {'policy_loss': 0.03901986289899804, 'entropy_loss': -0.06220480054616928, 'vf_loss': 0.022576688335432707, 'total_loss': -0.023184937647171243, 'approx_kl': -0.025032131001353264, 'clip_fraction': 0.3893229216337204, 'grad_norm': 19.90297508239746}
2023-01-03 14:48:08.973 DEBUG: Taking gradient step
2023-01-03 14:48:11.066 DEBUG: Loss 3: {'policy_loss': 0.16395049448554494, 'entropy_loss': -0.06346804555505514, 'vf_loss': 0.023890863407750304, 'total_loss': 0.10048244893048981, 'approx_kl': -0.06479665357619524, 'clip_fraction': 0.4713541716337204, 'grad_norm': 38.432979583740234}
2023-01-03 14:48:13.051 DEBUG: Taking gradient step
2023-01-03 14:48:15.109 DEBUG: Loss 4: {'policy_loss': 0.0741122563865518, 'entropy_loss': -0.06415738351643085, 'vf_loss': 0.02293649679037131, 'total_loss': 0.009954872870120951, 'approx_kl': -0.04645346384495497, 'clip_fraction': 0.4973958432674408, 'grad_norm': 27.81741714477539}
2023-01-03 14:48:17.126 DEBUG: Taking gradient step
2023-01-03 14:48:19.193 DEBUG: Loss 5: {'policy_loss': 0.04382942786509567, 'entropy_loss': -0.06691181100904942, 'vf_loss': 0.022765290831588545, 'total_loss': -0.023082383143953743, 'approx_kl': -0.047613247064873576, 'clip_fraction': 0.46875, 'grad_norm': 17.974790573120117}
2023-01-03 14:48:21.301 DEBUG: Taking gradient step
2023-01-03 14:48:23.371 DEBUG: Loss 6: {'policy_loss': 0.01833899080771985, 'entropy_loss': -0.06628026440739632, 'vf_loss': 0.022483404356608585, 'total_loss': -0.047941273599676475, 'approx_kl': -0.06932220747694373, 'clip_fraction': 0.4505208358168602, 'grad_norm': 18.992040634155273}
2023-01-03 14:48:25.367 DEBUG: Taking gradient step
2023-01-03 14:48:27.425 DEBUG: Loss 7: {'policy_loss': 0.03681653229895748, 'entropy_loss': -0.06671667750924826, 'vf_loss': 0.020839000113772817, 'total_loss': -0.02990014521029077, 'approx_kl': -0.0801004022359848, 'clip_fraction': 0.4947916716337204, 'grad_norm': 19.51410484313965}
2023-01-03 14:48:29.444 DEBUG: Taking gradient step
2023-01-03 14:48:31.490 DEBUG: Loss 8: {'policy_loss': 0.09402844778915374, 'entropy_loss': -0.06629516836255789, 'vf_loss': 0.022383578533018915, 'total_loss': 0.027733279426595852, 'approx_kl': -0.08022194355726242, 'clip_fraction': 0.4765625, 'grad_norm': 34.46796798706055}
2023-01-03 14:48:33.486 DEBUG: Taking gradient step
2023-01-03 14:48:35.553 DEBUG: Loss 9: {'policy_loss': 0.04494285272071121, 'entropy_loss': -0.06796121317893267, 'vf_loss': 0.022741585110664292, 'total_loss': -0.023018360458221452, 'approx_kl': -0.08391426876187325, 'clip_fraction': 0.4895833432674408, 'grad_norm': 25.29712677001953}
2023-01-03 14:48:37.756 DEBUG: Taking gradient step
2023-01-03 14:48:40.186 DEBUG: Loss 10: {'policy_loss': 0.15388511405415603, 'entropy_loss': -0.06673420779407024, 'vf_loss': 0.02230863784738809, 'total_loss': 0.08715090626008579, 'approx_kl': -0.13523150328546762, 'clip_fraction': 0.4270833358168602, 'grad_norm': 48.77717208862305}
2023-01-03 14:48:42.548 DEBUG: Taking gradient step
2023-01-03 14:48:44.953 DEBUG: Loss 11: {'policy_loss': 0.07554816687899657, 'entropy_loss': -0.06809666939079762, 'vf_loss': 0.021849643771795303, 'total_loss': 0.007451497488198958, 'approx_kl': -0.11253340728580952, 'clip_fraction': 0.3815104216337204, 'grad_norm': 27.080839157104492}
2023-01-03 14:48:47.307 DEBUG: Taking gradient step
2023-01-03 14:48:49.714 DEBUG: Loss 12: {'policy_loss': 0.16362319063111747, 'entropy_loss': -0.06659805774688721, 'vf_loss': 0.025635212412485446, 'total_loss': 0.09702513288423027, 'approx_kl': -0.13133523426949978, 'clip_fraction': 0.4661458358168602, 'grad_norm': 32.87005615234375}
2023-01-03 14:48:52.068 DEBUG: Taking gradient step
2023-01-03 14:48:54.477 DEBUG: Loss 13: {'policy_loss': 0.07397392787147988, 'entropy_loss': -0.06719195563346148, 'vf_loss': 0.022490285733790562, 'total_loss': 0.006781972238018408, 'approx_kl': -0.1229226291179657, 'clip_fraction': 0.4856770858168602, 'grad_norm': 24.59214973449707}
2023-01-03 14:48:56.850 DEBUG: Taking gradient step
2023-01-03 14:48:59.260 DEBUG: Loss 14: {'policy_loss': 0.16867893602970135, 'entropy_loss': -0.06682939268648624, 'vf_loss': 0.022281108962326462, 'total_loss': 0.10184954334321511, 'approx_kl': -0.15948118455708027, 'clip_fraction': 0.4635416716337204, 'grad_norm': 41.70322036743164}
2023-01-03 14:48:59.261 INFO: Optimization: policy loss=0.169, vf loss=0.022, entropy loss=-0.067, total loss=0.102, num steps=15
2023-01-03 14:48:59.262 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 14:49:00.992 INFO: Evaluation rollout: return=0.534 (0.0), episode length=6.0
2023-01-03 14:49:00.994 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 14:49:00.997 INFO: Iteration: 14/137, steps: 3024
2023-01-03 14:49:03.633 DEBUG: There is a single atom floating around
2023-01-03 14:49:13.975 DEBUG: Atoms are too close
2023-01-03 14:49:16.335 DEBUG: Atoms are too close
2023-01-03 14:49:18.479 DEBUG: Atoms are too close
2023-01-03 14:49:25.367 DEBUG: Atoms are too close
2023-01-03 14:49:29.878 DEBUG: Atoms are too close
2023-01-03 14:49:33.022 DEBUG: Atoms are too close
2023-01-03 14:49:33.459 DEBUG: Atoms are too close
2023-01-03 14:49:33.541 DEBUG: Atoms are too close
2023-01-03 14:49:34.678 DEBUG: Atoms are too close
2023-01-03 14:49:34.959 DEBUG: Atoms are too close
2023-01-03 14:49:46.787 DEBUG: Atoms are too close
2023-01-03 14:49:47.366 DEBUG: Atoms are too close
2023-01-03 14:49:49.144 DEBUG: There is a single atom floating around
2023-01-03 14:49:49.858 DEBUG: Atoms are too close
2023-01-03 14:49:53.720 INFO: Training rollout: return=-6.391 (8.5), episode length=5.5
2023-01-03 14:49:53.721 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 14:49:53.724 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-3024_train.pkl
2023-01-03 14:49:55.701 DEBUG: Taking gradient step
2023-01-03 14:49:57.784 DEBUG: Loss 0: {'policy_loss': 0.048278258228388875, 'entropy_loss': -0.06729676201939583, 'vf_loss': 0.04112970031379823, 'total_loss': -0.019018503791006947, 'approx_kl': 4.3888576328754425e-08, 'clip_fraction': 0.0, 'grad_norm': 26.02758026123047}
2023-01-03 14:49:59.732 DEBUG: Taking gradient step
2023-01-03 14:50:01.741 DEBUG: Loss 1: {'policy_loss': 0.046780002732135784, 'entropy_loss': -0.06633109040558338, 'vf_loss': 0.03871747848352768, 'total_loss': -0.019551087673447598, 'approx_kl': -0.027575510554015636, 'clip_fraction': 0.13541666697710752, 'grad_norm': 31.923715591430664}
2023-01-03 14:50:03.699 DEBUG: Taking gradient step
2023-01-03 14:50:05.714 DEBUG: Loss 2: {'policy_loss': 0.02291734617611252, 'entropy_loss': -0.06636537611484528, 'vf_loss': 0.03674041064729902, 'total_loss': -0.043448029938732764, 'approx_kl': -0.05452376790344715, 'clip_fraction': 0.3697916716337204, 'grad_norm': 20.9307804107666}
2023-01-03 14:50:07.678 DEBUG: Taking gradient step
2023-01-03 14:50:09.773 DEBUG: Loss 3: {'policy_loss': 0.054014105652208357, 'entropy_loss': -0.0673438012599945, 'vf_loss': 0.03754960420271519, 'total_loss': -0.01332969560778615, 'approx_kl': -0.07867774739861488, 'clip_fraction': 0.4713541716337204, 'grad_norm': 23.83303451538086}
2023-01-03 14:50:11.733 DEBUG: Taking gradient step
2023-01-03 14:50:13.750 DEBUG: Loss 4: {'policy_loss': 0.04922776031774399, 'entropy_loss': -0.06594242341816425, 'vf_loss': 0.036081838742370226, 'total_loss': -0.01671466310042026, 'approx_kl': -0.05312180705368519, 'clip_fraction': 0.42578125, 'grad_norm': 16.954734802246094}
2023-01-03 14:50:15.718 DEBUG: Taking gradient step
2023-01-03 14:50:17.744 DEBUG: Loss 5: {'policy_loss': 0.08023906259994096, 'entropy_loss': -0.06561415269970894, 'vf_loss': 0.03606131425182512, 'total_loss': 0.014624909900232026, 'approx_kl': -0.08718658238649368, 'clip_fraction': 0.4622395858168602, 'grad_norm': 22.453411102294922}
2023-01-03 14:50:19.714 DEBUG: Taking gradient step
2023-01-03 14:50:21.739 DEBUG: Loss 6: {'policy_loss': 0.08254665561987397, 'entropy_loss': -0.0664582122117281, 'vf_loss': 0.03807699857278046, 'total_loss': 0.016088443408145872, 'approx_kl': -0.08798043802380562, 'clip_fraction': 0.4505208358168602, 'grad_norm': 22.19831657409668}
2023-01-03 14:50:23.706 DEBUG: Taking gradient step
2023-01-03 14:50:25.723 DEBUG: Loss 7: {'policy_loss': 0.10639153167482807, 'entropy_loss': -0.06620257534086704, 'vf_loss': 0.038016519401953476, 'total_loss': 0.04018895633396102, 'approx_kl': -0.09921192191541195, 'clip_fraction': 0.4596354216337204, 'grad_norm': 25.798521041870117}
2023-01-03 14:50:27.685 DEBUG: Taking gradient step
2023-01-03 14:50:29.708 DEBUG: Loss 8: {'policy_loss': 0.075767086181944, 'entropy_loss': -0.06588661205023527, 'vf_loss': 0.036199540457644876, 'total_loss': 0.009880474131708724, 'approx_kl': -0.0907637532800436, 'clip_fraction': 0.4283854216337204, 'grad_norm': 19.33445930480957}
2023-01-03 14:50:31.659 DEBUG: Taking gradient step
2023-01-03 14:50:33.661 DEBUG: Loss 9: {'policy_loss': 0.08790227657009864, 'entropy_loss': -0.068363256752491, 'vf_loss': 0.038600444414847654, 'total_loss': 0.019539019817607646, 'approx_kl': -0.09887631051242352, 'clip_fraction': 0.4661458432674408, 'grad_norm': 20.264949798583984}
2023-01-03 14:50:35.618 DEBUG: Taking gradient step
2023-01-03 14:50:37.625 DEBUG: Loss 10: {'policy_loss': -0.035845592164547996, 'entropy_loss': -0.06644687335938215, 'vf_loss': 0.03455618713562933, 'total_loss': -0.10229246552393015, 'approx_kl': -0.11036927253007889, 'clip_fraction': 0.4205729216337204, 'grad_norm': 18.85186195373535}
2023-01-03 14:50:39.594 DEBUG: Taking gradient step
2023-01-03 14:50:41.610 DEBUG: Loss 11: {'policy_loss': 0.046997624400791145, 'entropy_loss': -0.0670462790876627, 'vf_loss': 0.03422945404507174, 'total_loss': -0.020048654686871552, 'approx_kl': -0.07461881125345826, 'clip_fraction': 0.4127604216337204, 'grad_norm': 17.0748233795166}
2023-01-03 14:50:43.566 DEBUG: Taking gradient step
2023-01-03 14:50:45.569 DEBUG: Loss 12: {'policy_loss': 0.013711724099871099, 'entropy_loss': -0.06643247604370117, 'vf_loss': 0.03443345511478984, 'total_loss': -0.05272075194383007, 'approx_kl': -0.07831661030650139, 'clip_fraction': 0.45703125, 'grad_norm': 17.479829788208008}
2023-01-03 14:50:47.534 DEBUG: Taking gradient step
2023-01-03 14:50:49.553 DEBUG: Loss 13: {'policy_loss': 0.04988971847425262, 'entropy_loss': -0.06698439922183752, 'vf_loss': 0.03502221333359587, 'total_loss': -0.017094680747584894, 'approx_kl': -0.09123131074011326, 'clip_fraction': 0.4518229216337204, 'grad_norm': 25.778236389160156}
2023-01-03 14:50:51.514 DEBUG: Taking gradient step
2023-01-03 14:50:53.555 DEBUG: Loss 14: {'policy_loss': 0.11093405376858376, 'entropy_loss': -0.0660230964422226, 'vf_loss': 0.0342746406319448, 'total_loss': 0.04491095732636117, 'approx_kl': -0.0788314938545227, 'clip_fraction': 0.4361979216337204, 'grad_norm': 26.525510787963867}
2023-01-03 14:50:53.555 INFO: Optimization: policy loss=0.111, vf loss=0.034, entropy loss=-0.066, total loss=0.045, num steps=15
2023-01-03 14:50:53.557 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 14:50:55.278 INFO: Evaluation rollout: return=0.519 (0.0), episode length=6.0
2023-01-03 14:50:55.279 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 14:50:55.282 INFO: Iteration: 15/137, steps: 3240
2023-01-03 14:51:07.793 DEBUG: Atoms are too close
2023-01-03 14:51:08.636 DEBUG: Atoms are too close
2023-01-03 14:51:08.918 DEBUG: Atoms are too close
2023-01-03 14:51:11.155 DEBUG: Atoms are too close
2023-01-03 14:51:12.558 DEBUG: Atoms are too close
2023-01-03 14:51:18.538 DEBUG: Atoms are too close
2023-01-03 14:51:22.677 DEBUG: Atoms are too close
2023-01-03 14:51:22.959 DEBUG: Atoms are too close
2023-01-03 14:51:25.744 DEBUG: Atoms are too close
2023-01-03 14:51:27.660 DEBUG: Atoms are too close
2023-01-03 14:51:28.664 DEBUG: There is a single atom floating around
2023-01-03 14:51:43.126 DEBUG: Atoms are too close
2023-01-03 14:51:43.128 DEBUG: Atoms are too close
2023-01-03 14:51:43.278 DEBUG: Atoms are too close
2023-01-03 14:51:43.839 DEBUG: Atoms are too close
2023-01-03 14:51:47.082 DEBUG: Atoms are too close
2023-01-03 14:51:47.146 INFO: Training rollout: return=-6.432 (8.0), episode length=5.6
2023-01-03 14:51:47.147 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 14:51:47.150 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-3240_train.pkl
2023-01-03 14:51:49.131 DEBUG: Taking gradient step
2023-01-03 14:51:51.281 DEBUG: Loss 0: {'policy_loss': -0.00790596407729273, 'entropy_loss': -0.06407954823225737, 'vf_loss': 0.037697618051157684, 'total_loss': -0.07198551230955008, 'approx_kl': -2.7124769985675812e-08, 'clip_fraction': 0.0, 'grad_norm': 19.93794822692871}
2023-01-03 14:51:53.240 DEBUG: Taking gradient step
2023-01-03 14:51:55.253 DEBUG: Loss 1: {'policy_loss': -0.04277742843928643, 'entropy_loss': -0.0660054599866271, 'vf_loss': 0.03629456043780894, 'total_loss': -0.10878288842591352, 'approx_kl': 0.012127694208174944, 'clip_fraction': 0.2005208358168602, 'grad_norm': 11.253035545349121}
2023-01-03 14:51:57.204 DEBUG: Taking gradient step
2023-01-03 14:51:59.208 DEBUG: Loss 2: {'policy_loss': 0.04353084331211207, 'entropy_loss': -0.06457489170134068, 'vf_loss': 0.03963212672258654, 'total_loss': -0.021044048389228603, 'approx_kl': -0.024503587977960706, 'clip_fraction': 0.3138020858168602, 'grad_norm': 21.45397186279297}
2023-01-03 14:52:01.163 DEBUG: Taking gradient step
2023-01-03 14:52:03.171 DEBUG: Loss 3: {'policy_loss': 0.02499459119380401, 'entropy_loss': -0.06471032649278641, 'vf_loss': 0.037715100274656174, 'total_loss': -0.039715735298982396, 'approx_kl': -0.008058546110987663, 'clip_fraction': 0.3828125, 'grad_norm': 23.07158851623535}
2023-01-03 14:52:05.150 DEBUG: Taking gradient step
2023-01-03 14:52:07.220 DEBUG: Loss 4: {'policy_loss': 0.07270473971823929, 'entropy_loss': -0.0654798848554492, 'vf_loss': 0.0384394179471425, 'total_loss': 0.007224854862790092, 'approx_kl': -0.04997913632541895, 'clip_fraction': 0.4088541716337204, 'grad_norm': 21.399381637573242}
2023-01-03 14:52:09.226 DEBUG: Taking gradient step
2023-01-03 14:52:11.347 DEBUG: Loss 5: {'policy_loss': 0.022718562056109844, 'entropy_loss': -0.06699761189520359, 'vf_loss': 0.037754695033810765, 'total_loss': -0.04427904983909374, 'approx_kl': -0.04251517076045275, 'clip_fraction': 0.38671875, 'grad_norm': 11.543600082397461}
2023-01-03 14:52:13.373 DEBUG: Taking gradient step
2023-01-03 14:52:15.462 DEBUG: Loss 6: {'policy_loss': -0.05734004364836193, 'entropy_loss': -0.06546013243496418, 'vf_loss': 0.03498534050270612, 'total_loss': -0.1228001760833261, 'approx_kl': -0.03761488292366266, 'clip_fraction': 0.3268229216337204, 'grad_norm': 9.766569137573242}
2023-01-03 14:52:17.489 DEBUG: Taking gradient step
2023-01-03 14:52:19.554 DEBUG: Loss 7: {'policy_loss': 0.025408096741398045, 'entropy_loss': -0.06524806004017591, 'vf_loss': 0.0375095602116132, 'total_loss': -0.03983996329877787, 'approx_kl': -0.05494071915745735, 'clip_fraction': 0.33984375, 'grad_norm': 14.939568519592285}
2023-01-03 14:52:21.584 DEBUG: Taking gradient step
2023-01-03 14:52:23.661 DEBUG: Loss 8: {'policy_loss': 0.08717284879855972, 'entropy_loss': -0.06514574959874153, 'vf_loss': 0.03833039735771322, 'total_loss': 0.022027099199818184, 'approx_kl': -0.03900803765282035, 'clip_fraction': 0.3828125, 'grad_norm': 30.462831497192383}
2023-01-03 14:52:25.657 DEBUG: Taking gradient step
2023-01-03 14:52:27.693 DEBUG: Loss 9: {'policy_loss': 0.030587155609201624, 'entropy_loss': -0.06529839895665646, 'vf_loss': 0.03762854795143387, 'total_loss': -0.03471124334745483, 'approx_kl': -0.06585630122572184, 'clip_fraction': 0.3828125, 'grad_norm': 12.905625343322754}
2023-01-03 14:52:29.660 DEBUG: Taking gradient step
2023-01-03 14:52:31.679 DEBUG: Loss 10: {'policy_loss': 0.020305883041912644, 'entropy_loss': -0.06303749140352011, 'vf_loss': 0.03626308589470669, 'total_loss': -0.04273160836160746, 'approx_kl': -0.05745929013937712, 'clip_fraction': 0.3958333358168602, 'grad_norm': 11.672289848327637}
2023-01-03 14:52:33.646 DEBUG: Taking gradient step
2023-01-03 14:52:35.672 DEBUG: Loss 11: {'policy_loss': 0.0005802188146229043, 'entropy_loss': -0.06382634676992893, 'vf_loss': 0.03591582295826684, 'total_loss': -0.06324612795530603, 'approx_kl': -0.060602637473493814, 'clip_fraction': 0.4036458358168602, 'grad_norm': 9.711881637573242}
2023-01-03 14:52:37.647 DEBUG: Taking gradient step
2023-01-03 14:52:39.664 DEBUG: Loss 12: {'policy_loss': 0.02348608901942032, 'entropy_loss': -0.06331818923354149, 'vf_loss': 0.03523821399182431, 'total_loss': -0.03983210021412117, 'approx_kl': -0.0562336053699255, 'clip_fraction': 0.4348958358168602, 'grad_norm': 18.96379852294922}
2023-01-03 14:52:41.631 DEBUG: Taking gradient step
2023-01-03 14:52:43.730 DEBUG: Loss 13: {'policy_loss': 0.06019389629290281, 'entropy_loss': -0.06586966197937727, 'vf_loss': 0.03669457946334797, 'total_loss': -0.005675765686474463, 'approx_kl': -0.03266989719122648, 'clip_fraction': 0.4973958358168602, 'grad_norm': 18.948974609375}
2023-01-03 14:52:45.695 DEBUG: Taking gradient step
2023-01-03 14:52:47.725 DEBUG: Loss 14: {'policy_loss': 0.06460640337978671, 'entropy_loss': -0.06451307144016027, 'vf_loss': 0.0358391379253291, 'total_loss': 9.333193962642733e-05, 'approx_kl': -0.05714249983429909, 'clip_fraction': 0.5208333432674408, 'grad_norm': 19.80329132080078}
2023-01-03 14:52:47.725 INFO: Optimization: policy loss=0.065, vf loss=0.036, entropy loss=-0.065, total loss=0.000, num steps=15
2023-01-03 14:52:47.726 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 14:52:49.422 INFO: Evaluation rollout: return=0.476 (0.0), episode length=6.0
2023-01-03 14:52:49.423 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 14:52:49.426 INFO: Iteration: 16/137, steps: 3456
2023-01-03 14:53:00.139 DEBUG: Atoms are too close
2023-01-03 14:53:02.205 DEBUG: Atoms are too close
2023-01-03 14:53:02.758 DEBUG: Atoms are too close
2023-01-03 14:53:06.103 DEBUG: Atoms are too close
2023-01-03 14:53:22.911 DEBUG: Atoms are too close
2023-01-03 14:53:38.964 DEBUG: Atoms are too close
2023-01-03 14:53:41.399 DEBUG: Atoms are too close
2023-01-03 14:53:44.361 INFO: Training rollout: return=-2.628 (6.2), episode length=5.8
2023-01-03 14:53:44.363 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 14:53:44.365 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-3456_train.pkl
2023-01-03 14:53:46.393 DEBUG: Taking gradient step
2023-01-03 14:53:48.452 DEBUG: Loss 0: {'policy_loss': -0.005037907094841868, 'entropy_loss': -0.06626279093325138, 'vf_loss': 0.02589435500693658, 'total_loss': -0.07130069802809325, 'approx_kl': 0.0, 'clip_fraction': 0.0, 'grad_norm': 22.4086856842041}
2023-01-03 14:53:50.440 DEBUG: Taking gradient step
2023-01-03 14:53:52.481 DEBUG: Loss 1: {'policy_loss': 0.020157699703015432, 'entropy_loss': -0.06511703319847584, 'vf_loss': 0.026720352226302948, 'total_loss': -0.04495933349546041, 'approx_kl': -0.016809817403554916, 'clip_fraction': 0.1770833358168602, 'grad_norm': 13.735885620117188}
2023-01-03 14:53:54.477 DEBUG: Taking gradient step
2023-01-03 14:53:56.524 DEBUG: Loss 2: {'policy_loss': -0.017140281397023453, 'entropy_loss': -0.06595314387232065, 'vf_loss': 0.027569919243303685, 'total_loss': -0.08309342526934411, 'approx_kl': -0.02805682271718979, 'clip_fraction': 0.3372395858168602, 'grad_norm': 14.153014183044434}
2023-01-03 14:53:58.560 DEBUG: Taking gradient step
2023-01-03 14:54:00.608 DEBUG: Loss 3: {'policy_loss': -0.05179272014687805, 'entropy_loss': -0.06637121923267841, 'vf_loss': 0.025347108042597363, 'total_loss': -0.11816393937955647, 'approx_kl': -0.03612968418747187, 'clip_fraction': 0.3502604216337204, 'grad_norm': 14.874897956848145}
2023-01-03 14:54:02.604 DEBUG: Taking gradient step
2023-01-03 14:54:04.650 DEBUG: Loss 4: {'policy_loss': -0.007517813553879489, 'entropy_loss': -0.06656063161790371, 'vf_loss': 0.025480396410631788, 'total_loss': -0.07407844517178319, 'approx_kl': -0.03465217724442482, 'clip_fraction': 0.359375, 'grad_norm': 18.449159622192383}
2023-01-03 14:54:06.618 DEBUG: Taking gradient step
2023-01-03 14:54:08.674 DEBUG: Loss 5: {'policy_loss': 0.0021511882957546066, 'entropy_loss': -0.06662985309958458, 'vf_loss': 0.022984403351761745, 'total_loss': -0.06447866480382997, 'approx_kl': -0.003698900807648897, 'clip_fraction': 0.48046875, 'grad_norm': 15.796478271484375}
2023-01-03 14:54:10.670 DEBUG: Taking gradient step
2023-01-03 14:54:12.709 DEBUG: Loss 6: {'policy_loss': 0.013396522841191753, 'entropy_loss': -0.06598951946943998, 'vf_loss': 0.021888262200441346, 'total_loss': -0.05259299662824822, 'approx_kl': 0.0021038143895566463, 'clip_fraction': 0.4609375, 'grad_norm': 12.70651626586914}
2023-01-03 14:54:14.685 DEBUG: Taking gradient step
2023-01-03 14:54:16.734 DEBUG: Loss 7: {'policy_loss': -0.0045428948773237115, 'entropy_loss': -0.06574136763811111, 'vf_loss': 0.02155637752656589, 'total_loss': -0.07028426251543482, 'approx_kl': 0.040708512999117374, 'clip_fraction': 0.5286458432674408, 'grad_norm': 9.497953414916992}
2023-01-03 14:54:18.737 DEBUG: Taking gradient step
2023-01-03 14:54:20.787 DEBUG: Loss 8: {'policy_loss': 0.058545509205465904, 'entropy_loss': -0.06415715999901295, 'vf_loss': 0.021725709069760665, 'total_loss': -0.005611650793547043, 'approx_kl': 0.0345295462757349, 'clip_fraction': 0.5221354216337204, 'grad_norm': 14.313770294189453}
2023-01-03 14:54:22.773 DEBUG: Taking gradient step
2023-01-03 14:54:24.829 DEBUG: Loss 9: {'policy_loss': -0.00943303358327325, 'entropy_loss': -0.06597717851400375, 'vf_loss': 0.019793239553229376, 'total_loss': -0.07541021209727701, 'approx_kl': 0.03151072142645717, 'clip_fraction': 0.5442708358168602, 'grad_norm': 12.272478103637695}
2023-01-03 14:54:26.826 DEBUG: Taking gradient step
2023-01-03 14:54:28.968 DEBUG: Loss 10: {'policy_loss': -0.008256624372032575, 'entropy_loss': -0.06812009401619434, 'vf_loss': 0.02152126335009108, 'total_loss': -0.07637671838822692, 'approx_kl': 0.03180542401969433, 'clip_fraction': 0.5520833432674408, 'grad_norm': 14.96841812133789}
2023-01-03 14:54:30.955 DEBUG: Taking gradient step
2023-01-03 14:54:33.041 DEBUG: Loss 11: {'policy_loss': -0.022345665672400282, 'entropy_loss': -0.06777809374034405, 'vf_loss': 0.020265338157087923, 'total_loss': -0.09012375941274434, 'approx_kl': 0.015143435448408127, 'clip_fraction': 0.5026041716337204, 'grad_norm': 16.23150062561035}
2023-01-03 14:54:35.079 DEBUG: Taking gradient step
2023-01-03 14:54:37.145 DEBUG: Loss 12: {'policy_loss': 0.05435712445155173, 'entropy_loss': -0.06675553973764181, 'vf_loss': 0.0229799957563842, 'total_loss': -0.012398415286090078, 'approx_kl': 0.03815987519919872, 'clip_fraction': 0.4869791716337204, 'grad_norm': 21.906864166259766}
2023-01-03 14:54:39.132 DEBUG: Early stopping at step 13 for reaching max KL.
2023-01-03 14:54:39.133 INFO: Optimization: policy loss=0.054, vf loss=0.023, entropy loss=-0.067, total loss=-0.012, num steps=13
2023-01-03 14:54:39.134 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 14:54:40.849 INFO: Evaluation rollout: return=0.570 (0.0), episode length=6.0
2023-01-03 14:54:40.850 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 14:54:40.852 INFO: Iteration: 17/137, steps: 3672
2023-01-03 14:54:54.137 DEBUG: Atoms are too close
2023-01-03 14:54:54.707 DEBUG: Atoms are too close
2023-01-03 14:54:56.469 DEBUG: Atoms are too close
2023-01-03 14:54:57.888 DEBUG: Atoms are too close
2023-01-03 14:54:57.890 DEBUG: Atoms are too close
2023-01-03 14:54:58.173 DEBUG: Atoms are too close
2023-01-03 14:55:14.061 DEBUG: Atoms are too close
2023-01-03 14:55:16.705 DEBUG: Atoms are too close
2023-01-03 14:55:26.088 DEBUG: Atoms are too close
2023-01-03 14:55:28.922 DEBUG: Atoms are too close
2023-01-03 14:55:29.996 DEBUG: Atoms are too close
2023-01-03 14:55:29.997 DEBUG: Atoms are too close
2023-01-03 14:55:29.998 DEBUG: Atoms are too close
2023-01-03 14:55:30.842 DEBUG: Atoms are too close
2023-01-03 14:55:32.474 DEBUG: Atoms are too close
2023-01-03 14:55:33.506 INFO: Training rollout: return=-5.733 (7.3), episode length=5.8
2023-01-03 14:55:33.507 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 14:55:33.510 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-3672_train.pkl
2023-01-03 14:55:35.501 DEBUG: Taking gradient step
2023-01-03 14:55:37.518 DEBUG: Loss 0: {'policy_loss': -0.021885082008851326, 'entropy_loss': -0.06932019628584385, 'vf_loss': 0.043528297084041004, 'total_loss': -0.09120527829469517, 'approx_kl': -8.226682979284305e-08, 'clip_fraction': 0.0, 'grad_norm': 10.701587677001953}
2023-01-03 14:55:39.487 DEBUG: Taking gradient step
2023-01-03 14:55:41.507 DEBUG: Loss 1: {'policy_loss': 0.03958825849273086, 'entropy_loss': -0.07043522596359253, 'vf_loss': 0.04722615250164166, 'total_loss': -0.030846967470861672, 'approx_kl': 0.03198344632983208, 'clip_fraction': 0.1770833358168602, 'grad_norm': 19.63128089904785}
2023-01-03 14:55:43.504 DEBUG: Taking gradient step
2023-01-03 14:55:45.927 DEBUG: Loss 2: {'policy_loss': 0.03846124739411924, 'entropy_loss': -0.0698334090411663, 'vf_loss': 0.04541793207433274, 'total_loss': -0.031372161647047064, 'approx_kl': -0.002504721633158624, 'clip_fraction': 0.3268229216337204, 'grad_norm': 17.050046920776367}
2023-01-03 14:55:48.275 DEBUG: Early stopping at step 3 for reaching max KL.
2023-01-03 14:55:48.275 INFO: Optimization: policy loss=0.038, vf loss=0.045, entropy loss=-0.070, total loss=-0.031, num steps=3
2023-01-03 14:55:48.276 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 14:55:49.707 DEBUG: Atoms are too close
2023-01-03 14:55:49.709 INFO: Evaluation rollout: return=-12.749 (0.0), episode length=6.0
2023-01-03 14:55:49.710 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 14:55:49.712 INFO: Iteration: 18/137, steps: 3888
2023-01-03 14:56:02.026 DEBUG: Atoms are too close
2023-01-03 14:56:04.389 DEBUG: Atoms are too close
2023-01-03 14:56:04.667 DEBUG: Atoms are too close
2023-01-03 14:56:05.466 DEBUG: Atoms are too close
2023-01-03 14:56:06.315 DEBUG: Atoms are too close
2023-01-03 14:56:06.736 DEBUG: Atoms are too close
2023-01-03 14:56:09.068 DEBUG: There is a single atom floating around
2023-01-03 14:56:14.752 DEBUG: Atoms are too close
2023-01-03 14:56:17.564 DEBUG: Atoms are too close
2023-01-03 14:56:21.063 DEBUG: Atoms are too close
2023-01-03 14:56:22.609 DEBUG: Atoms are too close
2023-01-03 14:56:24.866 DEBUG: Atoms are too close
2023-01-03 14:56:28.691 DEBUG: Atoms are too close
2023-01-03 14:56:32.588 DEBUG: Atoms are too close
2023-01-03 14:56:34.095 DEBUG: Atoms are too close
2023-01-03 14:56:34.380 DEBUG: Atoms are too close
2023-01-03 14:56:34.382 DEBUG: There is a single atom floating around
2023-01-03 14:56:35.370 DEBUG: Atoms are too close
2023-01-03 14:56:36.006 DEBUG: Atoms are too close
2023-01-03 14:56:37.556 DEBUG: Atoms are too close
2023-01-03 14:56:39.606 DEBUG: Atoms are too close
2023-01-03 14:56:40.806 INFO: Training rollout: return=-8.776 (8.5), episode length=5.3
2023-01-03 14:56:40.808 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 14:56:40.812 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-3888_train.pkl
2023-01-03 14:56:42.742 DEBUG: Taking gradient step
2023-01-03 14:56:44.749 DEBUG: Loss 0: {'policy_loss': 0.03778980431479498, 'entropy_loss': -0.06708936020731926, 'vf_loss': 0.05816645431363899, 'total_loss': -0.02929955589252428, 'approx_kl': -3.405148163437843e-08, 'clip_fraction': 0.0, 'grad_norm': 32.30989074707031}
2023-01-03 14:56:46.705 DEBUG: Taking gradient step
2023-01-03 14:56:48.722 DEBUG: Loss 1: {'policy_loss': 0.012784773378924405, 'entropy_loss': -0.06999133341014385, 'vf_loss': 0.058446592093267316, 'total_loss': -0.05720656003121945, 'approx_kl': 0.031791203655302525, 'clip_fraction': 0.3046875, 'grad_norm': 27.66928482055664}
2023-01-03 14:56:50.676 DEBUG: Early stopping at step 2 for reaching max KL.
2023-01-03 14:56:50.676 INFO: Optimization: policy loss=0.013, vf loss=0.058, entropy loss=-0.070, total loss=-0.057, num steps=2
2023-01-03 14:56:50.677 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 14:56:52.359 INFO: Evaluation rollout: return=0.575 (0.0), episode length=6.0
2023-01-03 14:56:52.360 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 14:56:52.363 INFO: Iteration: 19/137, steps: 4104
2023-01-03 14:57:03.382 DEBUG: Atoms are too close
2023-01-03 14:57:05.742 DEBUG: Atoms are too close
2023-01-03 14:57:13.347 DEBUG: There is a single atom floating around
2023-01-03 14:57:14.218 DEBUG: There is a single atom floating around
2023-01-03 14:57:19.757 DEBUG: Atoms are too close
2023-01-03 14:57:27.098 DEBUG: Atoms are too close
2023-01-03 14:57:27.382 DEBUG: Atoms are too close
2023-01-03 14:57:38.062 DEBUG: There is a single atom floating around
2023-01-03 14:57:40.783 DEBUG: Atoms are too close
2023-01-03 14:57:41.485 DEBUG: Atoms are too close
2023-01-03 14:57:43.546 DEBUG: Atoms are too close
2023-01-03 14:57:44.245 DEBUG: There is a single atom floating around
2023-01-03 14:57:45.736 INFO: Training rollout: return=-5.118 (8.5), episode length=5.5
2023-01-03 14:57:45.738 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 14:57:45.741 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-4104_train.pkl
2023-01-03 14:57:47.745 DEBUG: Taking gradient step
2023-01-03 14:57:50.173 DEBUG: Loss 0: {'policy_loss': -0.010486453900971507, 'entropy_loss': -0.07274631969630718, 'vf_loss': 0.03795922777766563, 'total_loss': -0.08323277359727868, 'approx_kl': -9.204571682630558e-08, 'clip_fraction': 0.0, 'grad_norm': 18.372774124145508}
2023-01-03 14:57:52.461 DEBUG: Early stopping at step 1 for reaching max KL.
2023-01-03 14:57:52.462 INFO: Optimization: policy loss=-0.010, vf loss=0.038, entropy loss=-0.073, total loss=-0.083, num steps=1
2023-01-03 14:57:52.463 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 14:57:54.156 INFO: Evaluation rollout: return=0.549 (0.0), episode length=6.0
2023-01-03 14:57:54.157 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 14:57:54.160 INFO: Iteration: 20/137, steps: 4320
2023-01-03 14:58:01.113 DEBUG: There is a single atom floating around
2023-01-03 14:58:09.163 DEBUG: Atoms are too close
2023-01-03 14:58:09.272 DEBUG: Atoms are too close
2023-01-03 14:58:23.761 DEBUG: Atoms are too close
2023-01-03 14:58:24.336 DEBUG: Atoms are too close
2023-01-03 14:58:24.994 DEBUG: Atoms are too close
2023-01-03 14:58:26.557 DEBUG: Atoms are too close
2023-01-03 14:58:27.064 DEBUG: Atoms are too close
2023-01-03 14:58:27.496 DEBUG: Atoms are too close
2023-01-03 14:58:33.019 DEBUG: There is a single atom floating around
2023-01-03 14:58:35.925 DEBUG: Atoms are too close
2023-01-03 14:58:36.632 DEBUG: Atoms are too close
2023-01-03 14:58:42.500 DEBUG: Atoms are too close
2023-01-03 14:58:47.484 INFO: Training rollout: return=-5.549 (8.3), episode length=5.6
2023-01-03 14:58:47.485 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 14:58:47.488 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-4320_train.pkl
2023-01-03 14:58:49.471 DEBUG: Taking gradient step
2023-01-03 14:58:51.479 DEBUG: Loss 0: {'policy_loss': -0.037766168376714045, 'entropy_loss': -0.07356144301593304, 'vf_loss': 0.034572769553448894, 'total_loss': -0.11132761139264707, 'approx_kl': 4.307366907596588e-09, 'clip_fraction': 0.0, 'grad_norm': 24.49384880065918}
2023-01-03 14:58:53.438 DEBUG: Taking gradient step
2023-01-03 14:58:55.539 DEBUG: Loss 1: {'policy_loss': 0.08029150856919887, 'entropy_loss': -0.0707635935395956, 'vf_loss': 0.035475454179949226, 'total_loss': 0.009527915029603255, 'approx_kl': 0.03180328290909529, 'clip_fraction': 0.3645833358168602, 'grad_norm': 14.320906639099121}
2023-01-03 14:58:57.488 DEBUG: Early stopping at step 2 for reaching max KL.
2023-01-03 14:58:57.489 INFO: Optimization: policy loss=0.080, vf loss=0.035, entropy loss=-0.071, total loss=0.010, num steps=2
2023-01-03 14:58:57.489 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 14:58:59.204 INFO: Evaluation rollout: return=0.371 (0.0), episode length=6.0
2023-01-03 14:58:59.205 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 14:58:59.207 DEBUG: Deleting old model: runs/CH3NO_dna/models/CH3NO_dna_run-1_steps-2376.model
2023-01-03 14:58:59.211 DEBUG: Saving model: runs/CH3NO_dna/models/CH3NO_dna_run-1_steps-4536.model
2023-01-03 14:58:59.258 INFO: Iteration: 21/137, steps: 4536
2023-01-03 14:59:03.622 DEBUG: There is a single atom floating around
2023-01-03 14:59:07.890 DEBUG: Atoms are too close
2023-01-03 14:59:09.016 DEBUG: Atoms are too close
2023-01-03 14:59:09.488 DEBUG: Atoms are too close
2023-01-03 14:59:13.709 DEBUG: Atoms are too close
2023-01-03 14:59:22.603 DEBUG: Atoms are too close
2023-01-03 14:59:22.604 DEBUG: There is a single atom floating around
2023-01-03 14:59:31.289 DEBUG: Atoms are too close
2023-01-03 14:59:34.135 DEBUG: Atoms are too close
2023-01-03 14:59:35.591 DEBUG: Atoms are too close
2023-01-03 14:59:35.880 DEBUG: Atoms are too close
2023-01-03 14:59:41.473 DEBUG: Atoms are too close
2023-01-03 14:59:53.541 DEBUG: Atoms are too close
2023-01-03 14:59:56.087 INFO: Training rollout: return=-5.564 (8.5), episode length=5.5
2023-01-03 14:59:56.089 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 14:59:56.092 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-4536_train.pkl
2023-01-03 14:59:58.114 DEBUG: Taking gradient step
2023-01-03 15:00:00.132 DEBUG: Loss 0: {'policy_loss': 0.0032190062947551126, 'entropy_loss': -0.06998710334300995, 'vf_loss': 0.034558952310563995, 'total_loss': -0.06676809704825484, 'approx_kl': -2.173086599555063e-09, 'clip_fraction': 0.0, 'grad_norm': 19.402467727661133}
2023-01-03 15:00:02.096 DEBUG: Early stopping at step 1 for reaching max KL.
2023-01-03 15:00:02.097 INFO: Optimization: policy loss=0.003, vf loss=0.035, entropy loss=-0.070, total loss=-0.067, num steps=1
2023-01-03 15:00:02.098 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 15:00:03.858 INFO: Evaluation rollout: return=0.559 (0.0), episode length=6.0
2023-01-03 15:00:03.859 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 15:00:03.861 INFO: Iteration: 22/137, steps: 4752
2023-01-03 15:00:10.979 DEBUG: There is a single atom floating around
2023-01-03 15:00:14.431 DEBUG: Atoms are too close
2023-01-03 15:00:18.732 DEBUG: Atoms are too close
2023-01-03 15:00:18.734 DEBUG: Atoms are too close
2023-01-03 15:00:29.458 DEBUG: Atoms are too close
2023-01-03 15:00:34.099 DEBUG: Atoms are too close
2023-01-03 15:00:40.195 DEBUG: Atoms are too close
2023-01-03 15:00:40.860 DEBUG: Atoms are too close
2023-01-03 15:00:41.153 DEBUG: Atoms are too close
2023-01-03 15:00:45.813 DEBUG: Atoms are too close
2023-01-03 15:00:46.705 DEBUG: Atoms are too close
2023-01-03 15:00:54.319 DEBUG: Atoms are too close
2023-01-03 15:00:57.726 DEBUG: Atoms are too close
2023-01-03 15:00:58.695 DEBUG: Atoms are too close
2023-01-03 15:01:01.238 INFO: Training rollout: return=-6.050 (8.4), episode length=5.5
2023-01-03 15:01:01.239 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 15:01:01.243 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-4752_train.pkl
2023-01-03 15:01:03.210 DEBUG: Taking gradient step
2023-01-03 15:01:05.236 DEBUG: Loss 0: {'policy_loss': 0.016776953158529544, 'entropy_loss': -0.06770502589643002, 'vf_loss': 0.03319355861718591, 'total_loss': -0.05092807273790047, 'approx_kl': -5.0407834351062775e-08, 'clip_fraction': 0.0, 'grad_norm': 24.399009704589844}
2023-01-03 15:01:07.223 DEBUG: Taking gradient step
2023-01-03 15:01:09.219 DEBUG: Loss 1: {'policy_loss': 0.004671254588246944, 'entropy_loss': -0.06832394562661648, 'vf_loss': 0.03282435805517667, 'total_loss': -0.06365269103836954, 'approx_kl': 0.02137630805373192, 'clip_fraction': 0.3450520858168602, 'grad_norm': 23.897289276123047}
2023-01-03 15:01:11.214 DEBUG: Taking gradient step
2023-01-03 15:01:13.612 DEBUG: Loss 2: {'policy_loss': 0.0031482516390940116, 'entropy_loss': -0.0676484014838934, 'vf_loss': 0.03195522176729224, 'total_loss': -0.06450014984479938, 'approx_kl': 0.040843259543180466, 'clip_fraction': 0.3971354216337204, 'grad_norm': 15.871560096740723}
2023-01-03 15:01:15.948 DEBUG: Taking gradient step
2023-01-03 15:01:18.186 DEBUG: Loss 3: {'policy_loss': 0.006179785852282919, 'entropy_loss': -0.06813270039856434, 'vf_loss': 0.030615776516449318, 'total_loss': -0.06195291454628142, 'approx_kl': -0.014886902645230293, 'clip_fraction': 0.4075520858168602, 'grad_norm': 12.197847366333008}
2023-01-03 15:01:20.142 DEBUG: Taking gradient step
2023-01-03 15:01:22.139 DEBUG: Loss 4: {'policy_loss': 0.06073932038302913, 'entropy_loss': -0.0704228738322854, 'vf_loss': 0.03065967238987006, 'total_loss': -0.009683553449256276, 'approx_kl': 0.005505241919308901, 'clip_fraction': 0.546875, 'grad_norm': 21.059795379638672}
2023-01-03 15:01:24.097 DEBUG: Taking gradient step
2023-01-03 15:01:26.115 DEBUG: Loss 5: {'policy_loss': 0.028192200492414804, 'entropy_loss': -0.06930582690984011, 'vf_loss': 0.030575645203244593, 'total_loss': -0.0411136264174253, 'approx_kl': 0.0020962320268154144, 'clip_fraction': 0.5091145858168602, 'grad_norm': 16.816316604614258}
2023-01-03 15:01:28.110 DEBUG: Taking gradient step
2023-01-03 15:01:30.176 DEBUG: Loss 6: {'policy_loss': -0.001567482801696718, 'entropy_loss': -0.06557686906307936, 'vf_loss': 0.028634180926525532, 'total_loss': -0.06714435186477608, 'approx_kl': -0.031087317503988743, 'clip_fraction': 0.4479166716337204, 'grad_norm': 24.563417434692383}
2023-01-03 15:01:32.177 DEBUG: Taking gradient step
2023-01-03 15:01:34.261 DEBUG: Loss 7: {'policy_loss': 0.06787044965742081, 'entropy_loss': -0.06768900156021118, 'vf_loss': 0.030213737586360187, 'total_loss': 0.00018144809720962649, 'approx_kl': -0.0026029865257441998, 'clip_fraction': 0.46875, 'grad_norm': 32.09831619262695}
2023-01-03 15:01:36.265 DEBUG: Early stopping at step 8 for reaching max KL.
2023-01-03 15:01:36.265 INFO: Optimization: policy loss=0.068, vf loss=0.030, entropy loss=-0.068, total loss=0.000, num steps=8
2023-01-03 15:01:36.266 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 15:01:38.018 INFO: Evaluation rollout: return=0.533 (0.0), episode length=6.0
2023-01-03 15:01:38.019 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 15:01:38.022 INFO: Iteration: 23/137, steps: 4968
2023-01-03 15:01:49.665 DEBUG: Atoms are too close
2023-01-03 15:01:53.681 DEBUG: Atoms are too close
2023-01-03 15:01:53.962 DEBUG: Atoms are too close
2023-01-03 15:02:05.506 DEBUG: Atoms are too close
2023-01-03 15:02:06.646 DEBUG: Atoms are too close
2023-01-03 15:02:10.910 DEBUG: Atoms are too close
2023-01-03 15:02:13.279 DEBUG: Atoms are too close
2023-01-03 15:02:23.926 DEBUG: Atoms are too close
2023-01-03 15:02:28.115 DEBUG: Atoms are too close
2023-01-03 15:02:32.376 INFO: Training rollout: return=-3.592 (7.1), episode length=5.7
2023-01-03 15:02:32.378 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 15:02:32.380 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-4968_train.pkl
2023-01-03 15:02:34.428 DEBUG: Taking gradient step
2023-01-03 15:02:36.516 DEBUG: Loss 0: {'policy_loss': 0.016739514325357113, 'entropy_loss': -0.06610478740185499, 'vf_loss': 0.026784361937232392, 'total_loss': -0.04936527307649788, 'approx_kl': 1.6453366669111347e-08, 'clip_fraction': 0.0, 'grad_norm': 17.599702835083008}
2023-01-03 15:02:38.535 DEBUG: Taking gradient step
2023-01-03 15:02:40.640 DEBUG: Loss 1: {'policy_loss': 0.03040348378245263, 'entropy_loss': -0.06417255848646164, 'vf_loss': 0.02456272265003656, 'total_loss': -0.033769074704009014, 'approx_kl': 0.0055915131233632565, 'clip_fraction': 0.36328125, 'grad_norm': 13.826945304870605}
2023-01-03 15:02:42.608 DEBUG: Taking gradient step
2023-01-03 15:02:44.636 DEBUG: Loss 2: {'policy_loss': 0.07789696393304195, 'entropy_loss': -0.06488429382443428, 'vf_loss': 0.02668032451762022, 'total_loss': 0.013012670108607668, 'approx_kl': 0.018999780993908644, 'clip_fraction': 0.4322916716337204, 'grad_norm': 18.6177978515625}
2023-01-03 15:02:46.623 DEBUG: Taking gradient step
2023-01-03 15:02:48.663 DEBUG: Loss 3: {'policy_loss': 0.014053276289423053, 'entropy_loss': -0.06478484161198139, 'vf_loss': 0.024670804076779566, 'total_loss': -0.05073156532255834, 'approx_kl': -0.009301227517426014, 'clip_fraction': 0.42578125, 'grad_norm': 12.489530563354492}
2023-01-03 15:02:50.655 DEBUG: Taking gradient step
2023-01-03 15:02:52.698 DEBUG: Loss 4: {'policy_loss': -0.04206605415160465, 'entropy_loss': -0.06294563505798578, 'vf_loss': 0.022322682423264475, 'total_loss': -0.10501168920959043, 'approx_kl': -0.03686761553399265, 'clip_fraction': 0.3854166716337204, 'grad_norm': 9.292468070983887}
2023-01-03 15:02:54.676 DEBUG: Taking gradient step
2023-01-03 15:02:56.953 DEBUG: Loss 5: {'policy_loss': -0.005353513283537864, 'entropy_loss': -0.06480902805924416, 'vf_loss': 0.022137351437367368, 'total_loss': -0.07016254134278202, 'approx_kl': -0.05305424612015486, 'clip_fraction': 0.4036458358168602, 'grad_norm': 11.264004707336426}
2023-01-03 15:02:59.318 DEBUG: Taking gradient step
2023-01-03 15:03:01.735 DEBUG: Loss 6: {'policy_loss': 0.022729562000943775, 'entropy_loss': -0.06334040779620409, 'vf_loss': 0.024226948479330716, 'total_loss': -0.040610845795260316, 'approx_kl': -0.04703415255062282, 'clip_fraction': 0.3880208358168602, 'grad_norm': 12.074722290039062}
2023-01-03 15:03:04.089 DEBUG: Taking gradient step
2023-01-03 15:03:06.504 DEBUG: Loss 7: {'policy_loss': 0.055693361258746125, 'entropy_loss': -0.06471763551235199, 'vf_loss': 0.024437000924718545, 'total_loss': -0.009024274253605871, 'approx_kl': -0.04322353913448751, 'clip_fraction': 0.3528645858168602, 'grad_norm': 12.473978042602539}
2023-01-03 15:03:08.862 DEBUG: Taking gradient step
2023-01-03 15:03:11.278 DEBUG: Loss 8: {'policy_loss': 0.023120356672154677, 'entropy_loss': -0.06341836694628, 'vf_loss': 0.02333779788433858, 'total_loss': -0.04029801027412532, 'approx_kl': -0.008965434972196817, 'clip_fraction': 0.4296875, 'grad_norm': 13.660497665405273}
2023-01-03 15:03:13.312 DEBUG: Taking gradient step
2023-01-03 15:03:15.346 DEBUG: Loss 9: {'policy_loss': -0.023292720355541564, 'entropy_loss': -0.06432175170630217, 'vf_loss': 0.021214797898672588, 'total_loss': -0.08761447206184372, 'approx_kl': 0.026588494889438152, 'clip_fraction': 0.4479166716337204, 'grad_norm': 11.268733978271484}
2023-01-03 15:03:17.323 DEBUG: Taking gradient step
2023-01-03 15:03:19.341 DEBUG: Loss 10: {'policy_loss': -0.01601530845685515, 'entropy_loss': -0.06392670329660177, 'vf_loss': 0.02398183064908369, 'total_loss': -0.07994201175345692, 'approx_kl': -0.021251392550766468, 'clip_fraction': 0.4596354216337204, 'grad_norm': 15.051345825195312}
2023-01-03 15:03:21.316 DEBUG: Taking gradient step
2023-01-03 15:03:23.331 DEBUG: Loss 11: {'policy_loss': -0.0329024405460526, 'entropy_loss': -0.06603810377418995, 'vf_loss': 0.022213656567610342, 'total_loss': -0.09894054432024255, 'approx_kl': 0.005884410813450813, 'clip_fraction': 0.5208333432674408, 'grad_norm': 11.466588973999023}
2023-01-03 15:03:25.329 DEBUG: Taking gradient step
2023-01-03 15:03:27.357 DEBUG: Loss 12: {'policy_loss': -0.009438801999596375, 'entropy_loss': -0.06206801626831293, 'vf_loss': 0.023346701070250202, 'total_loss': -0.0715068182679093, 'approx_kl': 0.005258792778477073, 'clip_fraction': 0.4661458358168602, 'grad_norm': 7.719118595123291}
2023-01-03 15:03:29.342 DEBUG: Taking gradient step
2023-01-03 15:03:31.370 DEBUG: Loss 13: {'policy_loss': 0.007088535952039496, 'entropy_loss': -0.06342612579464912, 'vf_loss': 0.022288380241584353, 'total_loss': -0.05633758984260963, 'approx_kl': -0.0016452698037028313, 'clip_fraction': 0.4856770932674408, 'grad_norm': 15.310260772705078}
2023-01-03 15:03:33.356 DEBUG: Taking gradient step
2023-01-03 15:03:35.475 DEBUG: Loss 14: {'policy_loss': -0.013563758659839307, 'entropy_loss': -0.06419576704502106, 'vf_loss': 0.02228740551317401, 'total_loss': -0.07775952570486036, 'approx_kl': 0.009883118444122374, 'clip_fraction': 0.4505208358168602, 'grad_norm': 15.936800956726074}
2023-01-03 15:03:35.475 INFO: Optimization: policy loss=-0.014, vf loss=0.022, entropy loss=-0.064, total loss=-0.078, num steps=15
2023-01-03 15:03:35.476 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 15:03:37.176 INFO: Evaluation rollout: return=0.551 (0.0), episode length=6.0
2023-01-03 15:03:37.177 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 15:03:37.180 INFO: Iteration: 24/137, steps: 5184
2023-01-03 15:03:44.956 DEBUG: There is a single atom floating around
2023-01-03 15:03:55.420 DEBUG: Atoms are too close
2023-01-03 15:04:07.864 DEBUG: Atoms are too close
2023-01-03 15:04:07.865 DEBUG: Atoms are too close
2023-01-03 15:04:07.866 DEBUG: Atoms are too close
2023-01-03 15:04:32.667 INFO: Training rollout: return=-1.908 (5.9), episode length=5.8
2023-01-03 15:04:32.668 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 15:04:32.671 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-5184_train.pkl
2023-01-03 15:04:34.697 DEBUG: Taking gradient step
2023-01-03 15:04:36.755 DEBUG: Loss 0: {'policy_loss': -0.03193915873303127, 'entropy_loss': -0.0645702201873064, 'vf_loss': 0.016878705340254062, 'total_loss': -0.09650937892033767, 'approx_kl': 3.1626150587271695e-09, 'clip_fraction': 0.0, 'grad_norm': 18.435962677001953}
2023-01-03 15:04:38.760 DEBUG: Taking gradient step
2023-01-03 15:04:40.818 DEBUG: Loss 1: {'policy_loss': 0.07822236841258177, 'entropy_loss': -0.06509709917008877, 'vf_loss': 0.019454747470944216, 'total_loss': 0.013125269242493007, 'approx_kl': -0.008228473830968142, 'clip_fraction': 0.1197916679084301, 'grad_norm': 17.97088050842285}
2023-01-03 15:04:42.819 DEBUG: Taking gradient step
2023-01-03 15:04:44.939 DEBUG: Loss 2: {'policy_loss': -0.06163526152834685, 'entropy_loss': -0.06322204228490591, 'vf_loss': 0.01714370944133545, 'total_loss': -0.12485730381325276, 'approx_kl': -0.04473318066447973, 'clip_fraction': 0.3671875, 'grad_norm': 13.85413932800293}
2023-01-03 15:04:46.985 DEBUG: Taking gradient step
2023-01-03 15:04:49.122 DEBUG: Loss 3: {'policy_loss': -0.03055344206711927, 'entropy_loss': -0.06280191242694855, 'vf_loss': 0.016844939493436205, 'total_loss': -0.09335535449406782, 'approx_kl': -0.03728414233773947, 'clip_fraction': 0.53125, 'grad_norm': 8.971054077148438}
2023-01-03 15:04:51.135 DEBUG: Taking gradient step
2023-01-03 15:04:53.207 DEBUG: Loss 4: {'policy_loss': 0.08287662882750196, 'entropy_loss': -0.0639981934800744, 'vf_loss': 0.01903084512628954, 'total_loss': 0.018878435347427558, 'approx_kl': 0.018563115503638983, 'clip_fraction': 0.5286458358168602, 'grad_norm': 12.196677207946777}
2023-01-03 15:04:55.234 DEBUG: Early stopping at step 5 for reaching max KL.
2023-01-03 15:04:55.235 INFO: Optimization: policy loss=0.083, vf loss=0.019, entropy loss=-0.064, total loss=0.019, num steps=5
2023-01-03 15:04:55.236 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 15:04:56.925 INFO: Evaluation rollout: return=0.558 (0.0), episode length=6.0
2023-01-03 15:04:56.926 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 15:04:56.928 INFO: Iteration: 25/137, steps: 5400
2023-01-03 15:05:11.497 DEBUG: There is a single atom floating around
2023-01-03 15:05:11.499 DEBUG: Atoms are too close
2023-01-03 15:05:12.727 DEBUG: Atoms are too close
2023-01-03 15:05:22.880 DEBUG: Atoms are too close
2023-01-03 15:05:33.901 DEBUG: Atoms are too close
2023-01-03 15:05:44.595 DEBUG: Atoms are too close
2023-01-03 15:05:50.142 DEBUG: Atoms are too close
2023-01-03 15:05:51.551 DEBUG: Atoms are too close
2023-01-03 15:05:52.899 INFO: Training rollout: return=-2.914 (6.4), episode length=5.8
2023-01-03 15:05:52.903 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 15:05:52.906 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-5400_train.pkl
2023-01-03 15:05:54.941 DEBUG: Taking gradient step
2023-01-03 15:05:57.009 DEBUG: Loss 0: {'policy_loss': -0.02157453869145433, 'entropy_loss': -0.06258143950253725, 'vf_loss': 0.023613276923084674, 'total_loss': -0.08415597819399157, 'approx_kl': -3.438132445410247e-08, 'clip_fraction': 0.0, 'grad_norm': 24.936975479125977}
2023-01-03 15:05:59.019 DEBUG: Taking gradient step
2023-01-03 15:06:01.167 DEBUG: Loss 1: {'policy_loss': 0.056779707182342154, 'entropy_loss': -0.06094092782586813, 'vf_loss': 0.02705013943633897, 'total_loss': -0.004161220643525976, 'approx_kl': -0.015836043749004602, 'clip_fraction': 0.2018229216337204, 'grad_norm': 32.44768524169922}
2023-01-03 15:06:03.224 DEBUG: Taking gradient step
2023-01-03 15:06:05.336 DEBUG: Loss 2: {'policy_loss': 0.08942217739575013, 'entropy_loss': -0.0607264107093215, 'vf_loss': 0.026384657667002563, 'total_loss': 0.028695766686428634, 'approx_kl': -0.034151039784774184, 'clip_fraction': 0.3072916679084301, 'grad_norm': 54.17723846435547}
2023-01-03 15:06:07.413 DEBUG: Taking gradient step
2023-01-03 15:06:09.541 DEBUG: Loss 3: {'policy_loss': 0.08737978844012384, 'entropy_loss': -0.06316319108009338, 'vf_loss': 0.026155600831605952, 'total_loss': 0.024216597360030456, 'approx_kl': -0.041436873376369476, 'clip_fraction': 0.48046875, 'grad_norm': 44.66329574584961}
2023-01-03 15:06:11.565 DEBUG: Taking gradient step
2023-01-03 15:06:13.635 DEBUG: Loss 4: {'policy_loss': 0.06177400820675802, 'entropy_loss': -0.061432176269590855, 'vf_loss': 0.022838794978860558, 'total_loss': 0.0003418319371671641, 'approx_kl': -0.04930089437402785, 'clip_fraction': 0.4739583358168602, 'grad_norm': 42.64096450805664}
2023-01-03 15:06:15.651 DEBUG: Taking gradient step
2023-01-03 15:06:17.809 DEBUG: Loss 5: {'policy_loss': 0.12307288047593101, 'entropy_loss': -0.06243711430579424, 'vf_loss': 0.025809692126595726, 'total_loss': 0.06063576617013677, 'approx_kl': -0.0469755451194942, 'clip_fraction': 0.5130208358168602, 'grad_norm': 43.63386535644531}
2023-01-03 15:06:19.808 DEBUG: Taking gradient step
2023-01-03 15:06:21.876 DEBUG: Loss 6: {'policy_loss': 0.10452968468672041, 'entropy_loss': -0.059654838405549526, 'vf_loss': 0.023410402993158913, 'total_loss': 0.0448748462811709, 'approx_kl': -0.05286168120801449, 'clip_fraction': 0.53125, 'grad_norm': 42.37527084350586}
2023-01-03 15:06:23.882 DEBUG: Taking gradient step
2023-01-03 15:06:25.941 DEBUG: Loss 7: {'policy_loss': 0.1436489516811344, 'entropy_loss': -0.06189333088696003, 'vf_loss': 0.023908550086604207, 'total_loss': 0.08175562079417437, 'approx_kl': -0.04507621843367815, 'clip_fraction': 0.4947916716337204, 'grad_norm': 50.46555709838867}
2023-01-03 15:06:28.017 DEBUG: Taking gradient step
2023-01-03 15:06:30.126 DEBUG: Loss 8: {'policy_loss': 0.18903675806672368, 'entropy_loss': -0.06285281013697386, 'vf_loss': 0.023014101124724774, 'total_loss': 0.12618394792974982, 'approx_kl': -0.07552378997206688, 'clip_fraction': 0.5677083432674408, 'grad_norm': 55.08893585205078}
2023-01-03 15:06:32.438 DEBUG: Taking gradient step
2023-01-03 15:06:34.890 DEBUG: Loss 9: {'policy_loss': 0.4153734865397786, 'entropy_loss': -0.06031843367964029, 'vf_loss': 0.025110254490433054, 'total_loss': 0.35505505286013833, 'approx_kl': -0.07221183739602566, 'clip_fraction': 0.5872395932674408, 'grad_norm': 130.30010986328125}
2023-01-03 15:06:37.114 DEBUG: Taking gradient step
2023-01-03 15:06:39.160 DEBUG: Loss 10: {'policy_loss': 0.2044285783995609, 'entropy_loss': -0.06139546167105436, 'vf_loss': 0.024379265507888277, 'total_loss': 0.14303311672850655, 'approx_kl': -0.06765813287347555, 'clip_fraction': 0.5651041716337204, 'grad_norm': 53.067203521728516}
2023-01-03 15:06:41.158 DEBUG: Taking gradient step
2023-01-03 15:06:43.252 DEBUG: Loss 11: {'policy_loss': 0.16069745358158655, 'entropy_loss': -0.061480666510760784, 'vf_loss': 0.023656916493051648, 'total_loss': 0.09921678707082572, 'approx_kl': -0.10192342847585678, 'clip_fraction': 0.5052083432674408, 'grad_norm': 40.80215835571289}
2023-01-03 15:06:45.303 DEBUG: Taking gradient step
2023-01-03 15:06:47.393 DEBUG: Loss 12: {'policy_loss': 0.19511829781531181, 'entropy_loss': -0.06110560800880194, 'vf_loss': 0.023784171931118675, 'total_loss': 0.13401268980650988, 'approx_kl': -0.10531628411263227, 'clip_fraction': 0.421875, 'grad_norm': 42.70574951171875}
2023-01-03 15:06:49.406 DEBUG: Taking gradient step
2023-01-03 15:06:51.479 DEBUG: Loss 13: {'policy_loss': 0.23726708038447664, 'entropy_loss': -0.06213128846138716, 'vf_loss': 0.023935246372163224, 'total_loss': 0.17513579192308948, 'approx_kl': -0.11747748218476772, 'clip_fraction': 0.4557291716337204, 'grad_norm': 49.758853912353516}
2023-01-03 15:06:53.478 DEBUG: Taking gradient step
2023-01-03 15:06:55.534 DEBUG: Loss 14: {'policy_loss': 0.17228340006560897, 'entropy_loss': -0.06048913765698671, 'vf_loss': 0.0219964118801191, 'total_loss': 0.11179426240862228, 'approx_kl': -0.10242353845387697, 'clip_fraction': 0.4583333358168602, 'grad_norm': 46.401771545410156}
2023-01-03 15:06:55.534 INFO: Optimization: policy loss=0.172, vf loss=0.022, entropy loss=-0.060, total loss=0.112, num steps=15
2023-01-03 15:06:55.535 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 15:06:57.292 INFO: Evaluation rollout: return=0.522 (0.0), episode length=6.0
2023-01-03 15:06:57.293 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 15:06:57.296 INFO: Iteration: 26/137, steps: 5616
2023-01-03 15:07:11.080 DEBUG: Atoms are too close
2023-01-03 15:07:14.014 DEBUG: Atoms are too close
2023-01-03 15:07:15.579 DEBUG: Atoms are too close
2023-01-03 15:07:25.427 DEBUG: Atoms are too close
2023-01-03 15:07:30.795 DEBUG: There is a single atom floating around
2023-01-03 15:07:32.740 DEBUG: Atoms are too close
2023-01-03 15:07:32.742 DEBUG: Atoms are too close
2023-01-03 15:07:45.912 DEBUG: Atoms are too close
2023-01-03 15:07:48.724 DEBUG: Atoms are too close
2023-01-03 15:07:51.387 DEBUG: Atoms are too close
2023-01-03 15:07:51.868 INFO: Training rollout: return=-3.693 (6.7), episode length=5.8
2023-01-03 15:07:51.869 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 15:07:51.872 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-5616_train.pkl
2023-01-03 15:07:53.891 DEBUG: Taking gradient step
2023-01-03 15:07:55.948 DEBUG: Loss 0: {'policy_loss': -0.011147438166658823, 'entropy_loss': -0.06317279115319252, 'vf_loss': 0.027986571406464295, 'total_loss': -0.07432022931985134, 'approx_kl': 1.591009368695495e-08, 'clip_fraction': 0.0, 'grad_norm': 14.306652069091797}
2023-01-03 15:07:57.942 DEBUG: Taking gradient step
2023-01-03 15:08:00.031 DEBUG: Loss 1: {'policy_loss': 0.022693866602789336, 'entropy_loss': -0.06279457546770573, 'vf_loss': 0.02938202877895238, 'total_loss': -0.0401007088649164, 'approx_kl': -0.0013869544491171837, 'clip_fraction': 0.22265625, 'grad_norm': 11.317710876464844}
2023-01-03 15:08:02.050 DEBUG: Taking gradient step
2023-01-03 15:08:04.120 DEBUG: Loss 2: {'policy_loss': -0.008812484745605899, 'entropy_loss': -0.06363900937139988, 'vf_loss': 0.027936961982260693, 'total_loss': -0.07245149411700577, 'approx_kl': -0.0046146283857524395, 'clip_fraction': 0.3151041716337204, 'grad_norm': 12.604436874389648}
2023-01-03 15:08:06.219 DEBUG: Taking gradient step
2023-01-03 15:08:08.275 DEBUG: Loss 3: {'policy_loss': -0.0065843947730476506, 'entropy_loss': -0.0630096010863781, 'vf_loss': 0.02654006121632065, 'total_loss': -0.06959399585942574, 'approx_kl': -0.006448874715715647, 'clip_fraction': 0.4283854216337204, 'grad_norm': 16.844141006469727}
2023-01-03 15:08:10.291 DEBUG: Taking gradient step
2023-01-03 15:08:12.349 DEBUG: Loss 4: {'policy_loss': -0.022872029511763176, 'entropy_loss': -0.06511278171092272, 'vf_loss': 0.02657618268846304, 'total_loss': -0.0879848112226859, 'approx_kl': -0.011830211617052555, 'clip_fraction': 0.3958333358168602, 'grad_norm': 14.98406982421875}
2023-01-03 15:08:14.346 DEBUG: Taking gradient step
2023-01-03 15:08:16.407 DEBUG: Loss 5: {'policy_loss': 0.0601083270498812, 'entropy_loss': -0.06497585121542215, 'vf_loss': 0.02935874658744895, 'total_loss': -0.004867524165540954, 'approx_kl': -0.04013752075843513, 'clip_fraction': 0.43359375, 'grad_norm': 22.00783920288086}
2023-01-03 15:08:18.417 DEBUG: Taking gradient step
2023-01-03 15:08:20.471 DEBUG: Loss 6: {'policy_loss': 0.09431958429031126, 'entropy_loss': -0.06413169950246811, 'vf_loss': 0.028234196351293376, 'total_loss': 0.03018788478784315, 'approx_kl': -0.04996184492483735, 'clip_fraction': 0.4908854216337204, 'grad_norm': 24.379697799682617}
2023-01-03 15:08:22.501 DEBUG: Taking gradient step
2023-01-03 15:08:24.545 DEBUG: Loss 7: {'policy_loss': 0.11330661992474991, 'entropy_loss': -0.06398487091064453, 'vf_loss': 0.027961801158819796, 'total_loss': 0.04932174901410538, 'approx_kl': -0.022078577429056168, 'clip_fraction': 0.4934895858168602, 'grad_norm': 25.164730072021484}
2023-01-03 15:08:26.562 DEBUG: Taking gradient step
2023-01-03 15:08:28.608 DEBUG: Loss 8: {'policy_loss': 0.1355179697219559, 'entropy_loss': -0.0646506492048502, 'vf_loss': 0.027553696290259607, 'total_loss': 0.0708673205171057, 'approx_kl': -0.040694911032915115, 'clip_fraction': 0.5390625, 'grad_norm': 34.21288299560547}
2023-01-03 15:08:30.626 DEBUG: Taking gradient step
2023-01-03 15:08:32.667 DEBUG: Loss 9: {'policy_loss': 0.10838015864038408, 'entropy_loss': -0.06385860778391361, 'vf_loss': 0.027459676955407013, 'total_loss': 0.044521550856470464, 'approx_kl': -0.0728590376675129, 'clip_fraction': 0.4713541716337204, 'grad_norm': 44.173492431640625}
2023-01-03 15:08:34.663 DEBUG: Taking gradient step
2023-01-03 15:08:36.704 DEBUG: Loss 10: {'policy_loss': 0.0676195230689616, 'entropy_loss': -0.062280019745230675, 'vf_loss': 0.026672366241596746, 'total_loss': 0.005339503323730926, 'approx_kl': -0.040515429340302944, 'clip_fraction': 0.46484375, 'grad_norm': 18.54971694946289}
2023-01-03 15:08:38.692 DEBUG: Taking gradient step
2023-01-03 15:08:40.740 DEBUG: Loss 11: {'policy_loss': 0.053051310203376306, 'entropy_loss': -0.06351123843342066, 'vf_loss': 0.026758270322392155, 'total_loss': -0.010459928230044345, 'approx_kl': -0.08637818694114685, 'clip_fraction': 0.48828125, 'grad_norm': 18.705400466918945}
2023-01-03 15:08:42.729 DEBUG: Taking gradient step
2023-01-03 15:08:44.798 DEBUG: Loss 12: {'policy_loss': 0.17691508837602854, 'entropy_loss': -0.06219209358096123, 'vf_loss': 0.02672774579261753, 'total_loss': 0.11472299479506731, 'approx_kl': -0.08045438025146723, 'clip_fraction': 0.5260416716337204, 'grad_norm': 21.223478317260742}
2023-01-03 15:08:46.818 DEBUG: Taking gradient step
2023-01-03 15:08:48.914 DEBUG: Loss 13: {'policy_loss': 0.14099138222766877, 'entropy_loss': -0.062425331212580204, 'vf_loss': 0.025541721261798038, 'total_loss': 0.07856605101508857, 'approx_kl': -0.07231028215028346, 'clip_fraction': 0.5377604216337204, 'grad_norm': 27.246660232543945}
2023-01-03 15:08:50.973 DEBUG: Taking gradient step
2023-01-03 15:08:53.088 DEBUG: Loss 14: {'policy_loss': 0.28294591563307653, 'entropy_loss': -0.06208172254264355, 'vf_loss': 0.02873650794414392, 'total_loss': 0.22086419309043298, 'approx_kl': -0.11584732122719288, 'clip_fraction': 0.5677083432674408, 'grad_norm': 36.33283996582031}
2023-01-03 15:08:53.088 INFO: Optimization: policy loss=0.283, vf loss=0.029, entropy loss=-0.062, total loss=0.221, num steps=15
2023-01-03 15:08:53.089 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 15:08:54.831 INFO: Evaluation rollout: return=0.494 (0.0), episode length=6.0
2023-01-03 15:08:54.832 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 15:08:54.836 INFO: Iteration: 27/137, steps: 5832
2023-01-03 15:09:29.062 DEBUG: Atoms are too close
2023-01-03 15:09:46.840 DEBUG: Atoms are too close
2023-01-03 15:09:51.534 INFO: Training rollout: return=-0.435 (3.6), episode length=5.9
2023-01-03 15:09:51.536 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 15:09:51.539 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-5832_train.pkl
2023-01-03 15:09:53.624 DEBUG: Taking gradient step
2023-01-03 15:09:55.719 DEBUG: Loss 0: {'policy_loss': 0.027399207046847885, 'entropy_loss': -0.06381604261696339, 'vf_loss': 0.015756809160199427, 'total_loss': -0.036416835570115505, 'approx_kl': 1.2611671706963534e-09, 'clip_fraction': 0.0, 'grad_norm': 28.327425003051758}
2023-01-03 15:09:57.736 DEBUG: Early stopping at step 1 for reaching max KL.
2023-01-03 15:09:57.736 INFO: Optimization: policy loss=0.027, vf loss=0.016, entropy loss=-0.064, total loss=-0.036, num steps=1
2023-01-03 15:09:57.737 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 15:09:59.455 INFO: Evaluation rollout: return=0.554 (0.0), episode length=6.0
2023-01-03 15:09:59.456 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 15:09:59.459 INFO: Iteration: 28/137, steps: 6048
2023-01-03 15:10:32.628 DEBUG: Atoms are too close
2023-01-03 15:10:34.706 DEBUG: Atoms are too close
2023-01-03 15:10:43.973 DEBUG: Atoms are too close
2023-01-03 15:10:47.283 DEBUG: Atoms are too close
2023-01-03 15:10:48.703 DEBUG: Atoms are too close
2023-01-03 15:10:49.360 DEBUG: Atoms are too close
2023-01-03 15:10:51.709 DEBUG: Atoms are too close
2023-01-03 15:10:51.710 DEBUG: Atoms are too close
2023-01-03 15:10:51.850 DEBUG: There is a single atom floating around
2023-01-03 15:10:54.188 INFO: Training rollout: return=-3.853 (7.1), episode length=5.8
2023-01-03 15:10:54.189 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 15:10:54.192 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-6048_train.pkl
2023-01-03 15:10:56.218 DEBUG: Taking gradient step
2023-01-03 15:10:58.266 DEBUG: Loss 0: {'policy_loss': -0.03319531337181667, 'entropy_loss': -0.06088622286915779, 'vf_loss': 0.027190490823910562, 'total_loss': -0.09408153624097446, 'approx_kl': 5.3318217396736145e-08, 'clip_fraction': 0.0, 'grad_norm': 23.348495483398438}
2023-01-03 15:11:00.262 DEBUG: Early stopping at step 1 for reaching max KL.
2023-01-03 15:11:00.263 INFO: Optimization: policy loss=-0.033, vf loss=0.027, entropy loss=-0.061, total loss=-0.094, num steps=1
2023-01-03 15:11:00.264 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 15:11:02.210 INFO: Evaluation rollout: return=0.497 (0.0), episode length=6.0
2023-01-03 15:11:02.211 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 15:11:02.214 INFO: Iteration: 29/137, steps: 6264
2023-01-03 15:11:13.764 DEBUG: Atoms are too close
2023-01-03 15:11:15.567 DEBUG: Atoms are too close
2023-01-03 15:11:16.140 DEBUG: There is a single atom floating around
2023-01-03 15:11:16.934 DEBUG: Atoms are too close
2023-01-03 15:11:17.545 DEBUG: There is a single atom floating around
2023-01-03 15:11:18.302 DEBUG: There is a single atom floating around
2023-01-03 15:11:27.210 DEBUG: Atoms are too close
2023-01-03 15:11:36.597 DEBUG: Atoms are too close
2023-01-03 15:11:42.372 DEBUG: Atoms are too close
2023-01-03 15:11:47.108 DEBUG: There is a single atom floating around
2023-01-03 15:11:53.970 DEBUG: Atoms are too close
2023-01-03 15:11:54.055 DEBUG: There is a single atom floating around
2023-01-03 15:11:56.030 DEBUG: Atoms are too close
2023-01-03 15:11:56.525 INFO: Training rollout: return=-5.130 (7.4), episode length=5.7
2023-01-03 15:11:56.527 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 15:11:56.529 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-6264_train.pkl
2023-01-03 15:11:58.537 DEBUG: Taking gradient step
2023-01-03 15:12:00.599 DEBUG: Loss 0: {'policy_loss': 0.005782010696783241, 'entropy_loss': -0.057151191867887974, 'vf_loss': 0.03470954738808412, 'total_loss': -0.05136918117110473, 'approx_kl': 1.3969838619232178e-08, 'clip_fraction': 0.0, 'grad_norm': 16.64691162109375}
2023-01-03 15:12:02.594 DEBUG: Early stopping at step 1 for reaching max KL.
2023-01-03 15:12:02.595 INFO: Optimization: policy loss=0.006, vf loss=0.035, entropy loss=-0.057, total loss=-0.051, num steps=1
2023-01-03 15:12:02.595 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 15:12:04.307 INFO: Evaluation rollout: return=0.498 (0.0), episode length=6.0
2023-01-03 15:12:04.308 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 15:12:04.311 INFO: Iteration: 30/137, steps: 6480
2023-01-03 15:12:15.936 DEBUG: Atoms are too close
2023-01-03 15:12:22.833 DEBUG: There is a single atom floating around
2023-01-03 15:12:39.137 DEBUG: There is a single atom floating around
2023-01-03 15:12:39.138 DEBUG: There is a single atom floating around
2023-01-03 15:12:39.139 DEBUG: Atoms are too close
2023-01-03 15:12:55.846 DEBUG: Atoms are too close
2023-01-03 15:12:56.925 DEBUG: Atoms are too close
2023-01-03 15:12:59.346 DEBUG: There is a single atom floating around
2023-01-03 15:12:59.401 INFO: Training rollout: return=-2.729 (6.0), episode length=5.9
2023-01-03 15:12:59.403 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 15:12:59.405 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-6480_train.pkl
2023-01-03 15:13:01.454 DEBUG: Taking gradient step
2023-01-03 15:13:03.531 DEBUG: Loss 0: {'policy_loss': -0.04302079003337744, 'entropy_loss': -0.06282730400562286, 'vf_loss': 0.02370138235624743, 'total_loss': -0.1058480940390003, 'approx_kl': -9.352030883036377e-08, 'clip_fraction': 0.0, 'grad_norm': 11.065862655639648}
2023-01-03 15:13:05.550 DEBUG: Early stopping at step 1 for reaching max KL.
2023-01-03 15:13:05.551 INFO: Optimization: policy loss=-0.043, vf loss=0.024, entropy loss=-0.063, total loss=-0.106, num steps=1
2023-01-03 15:13:05.551 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 15:13:07.225 INFO: Evaluation rollout: return=0.485 (0.0), episode length=6.0
2023-01-03 15:13:07.226 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 15:13:07.229 DEBUG: Deleting old model: runs/CH3NO_dna/models/CH3NO_dna_run-1_steps-4536.model
2023-01-03 15:13:07.234 DEBUG: Saving model: runs/CH3NO_dna/models/CH3NO_dna_run-1_steps-6696.model
2023-01-03 15:13:07.282 INFO: Iteration: 31/137, steps: 6696
2023-01-03 15:13:20.050 DEBUG: Atoms are too close
2023-01-03 15:13:25.652 DEBUG: Atoms are too close
2023-01-03 15:13:59.509 DEBUG: There is a single atom floating around
2023-01-03 15:14:00.946 DEBUG: Atoms are too close
2023-01-03 15:14:03.123 DEBUG: Atoms are too close
2023-01-03 15:14:03.886 INFO: Training rollout: return=-1.618 (5.1), episode length=5.9
2023-01-03 15:14:03.887 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 15:14:03.890 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-6696_train.pkl
2023-01-03 15:14:05.927 DEBUG: Taking gradient step
2023-01-03 15:14:07.996 DEBUG: Loss 0: {'policy_loss': -0.0470590917911568, 'entropy_loss': -0.06587638426572084, 'vf_loss': 0.016193998969052506, 'total_loss': -0.11293547605687765, 'approx_kl': -3.8455862494402027e-08, 'clip_fraction': 0.0, 'grad_norm': 11.902194023132324}
2023-01-03 15:14:10.034 DEBUG: Early stopping at step 1 for reaching max KL.
2023-01-03 15:14:10.035 INFO: Optimization: policy loss=-0.047, vf loss=0.016, entropy loss=-0.066, total loss=-0.113, num steps=1
2023-01-03 15:14:10.036 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 15:14:11.762 INFO: Evaluation rollout: return=0.511 (0.0), episode length=6.0
2023-01-03 15:14:11.763 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 15:14:11.766 INFO: Iteration: 32/137, steps: 6912
2023-01-03 15:14:28.444 DEBUG: Atoms are too close
2023-01-03 15:15:00.442 DEBUG: Atoms are too close
2023-01-03 15:15:05.657 DEBUG: Atoms are too close
2023-01-03 15:15:08.913 INFO: Training rollout: return=-0.811 (4.3), episode length=5.9
2023-01-03 15:15:08.914 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 15:15:08.917 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-6912_train.pkl
2023-01-03 15:15:10.969 DEBUG: Taking gradient step
2023-01-03 15:15:13.057 DEBUG: Loss 0: {'policy_loss': -0.00951445597030909, 'entropy_loss': -0.06596251204609871, 'vf_loss': 0.012185978472110033, 'total_loss': -0.0754769680164078, 'approx_kl': -1.5211602644171762e-08, 'clip_fraction': 0.0, 'grad_norm': 17.270042419433594}
2023-01-03 15:15:15.088 DEBUG: Taking gradient step
2023-01-03 15:15:17.222 DEBUG: Loss 1: {'policy_loss': -0.01700756662400935, 'entropy_loss': -0.0650192117318511, 'vf_loss': 0.012623938026712734, 'total_loss': -0.08202677835586045, 'approx_kl': 0.03997590090148151, 'clip_fraction': 0.265625, 'grad_norm': 14.206714630126953}
2023-01-03 15:15:19.311 DEBUG: Early stopping at step 2 for reaching max KL.
2023-01-03 15:15:19.311 INFO: Optimization: policy loss=-0.017, vf loss=0.013, entropy loss=-0.065, total loss=-0.082, num steps=2
2023-01-03 15:15:19.312 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 15:15:21.044 INFO: Evaluation rollout: return=0.541 (0.0), episode length=6.0
2023-01-03 15:15:21.045 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 15:15:21.047 INFO: Iteration: 33/137, steps: 7128
2023-01-03 15:15:32.327 DEBUG: Atoms are too close
2023-01-03 15:15:34.157 DEBUG: Atoms are too close
2023-01-03 15:15:35.478 DEBUG: There is a single atom floating around
2023-01-03 15:15:56.358 DEBUG: Atoms are too close
2023-01-03 15:16:14.278 DEBUG: Atoms are too close
2023-01-03 15:16:15.204 DEBUG: Atoms are too close
2023-01-03 15:16:15.872 DEBUG: Atoms are too close
2023-01-03 15:16:16.022 DEBUG: Atoms are too close
2023-01-03 15:16:17.158 DEBUG: Atoms are too close
2023-01-03 15:16:17.360 INFO: Training rollout: return=-3.330 (6.5), episode length=5.8
2023-01-03 15:16:17.361 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 15:16:17.364 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-7128_train.pkl
2023-01-03 15:16:19.427 DEBUG: Taking gradient step
2023-01-03 15:16:21.565 DEBUG: Loss 0: {'policy_loss': -0.027923041940554266, 'entropy_loss': -0.06264239549636841, 'vf_loss': 0.02581375908715225, 'total_loss': -0.09056543743692268, 'approx_kl': -7.380731403827667e-08, 'clip_fraction': 0.0, 'grad_norm': 15.2583589553833}
2023-01-03 15:16:23.571 DEBUG: Taking gradient step
2023-01-03 15:16:25.600 DEBUG: Loss 1: {'policy_loss': -0.00048053546532153893, 'entropy_loss': -0.06191759742796421, 'vf_loss': 0.028332267666987123, 'total_loss': -0.062398132893285746, 'approx_kl': 0.005739482818171382, 'clip_fraction': 0.2565104216337204, 'grad_norm': 12.57716178894043}
2023-01-03 15:16:27.577 DEBUG: Taking gradient step
2023-01-03 15:16:29.623 DEBUG: Loss 2: {'policy_loss': 0.039476874520344596, 'entropy_loss': -0.06213988829404116, 'vf_loss': 0.027334403518615217, 'total_loss': -0.022663013773696554, 'approx_kl': -0.003622320480644703, 'clip_fraction': 0.3880208358168602, 'grad_norm': 21.766334533691406}
2023-01-03 15:16:31.658 DEBUG: Taking gradient step
2023-01-03 15:16:33.729 DEBUG: Loss 3: {'policy_loss': 0.03707725072622041, 'entropy_loss': -0.06092680152505636, 'vf_loss': 0.02778476334002255, 'total_loss': -0.023849550798835956, 'approx_kl': -0.03811846440657973, 'clip_fraction': 0.4296875, 'grad_norm': 15.089783668518066}
2023-01-03 15:16:35.725 DEBUG: Taking gradient step
2023-01-03 15:16:37.787 DEBUG: Loss 4: {'policy_loss': 0.07172758698989821, 'entropy_loss': -0.06177108455449343, 'vf_loss': 0.02770426215201228, 'total_loss': 0.009956502435404784, 'approx_kl': -0.0192133350064978, 'clip_fraction': 0.453125, 'grad_norm': 15.931384086608887}
2023-01-03 15:16:39.781 DEBUG: Taking gradient step
2023-01-03 15:16:41.862 DEBUG: Loss 5: {'policy_loss': 0.0717953653288066, 'entropy_loss': -0.0626938808709383, 'vf_loss': 0.02796782178988335, 'total_loss': 0.009101484457868306, 'approx_kl': -0.028494689613580704, 'clip_fraction': 0.44921875, 'grad_norm': 20.079736709594727}
2023-01-03 15:16:43.928 DEBUG: Taking gradient step
2023-01-03 15:16:46.040 DEBUG: Loss 6: {'policy_loss': 0.06204389836882646, 'entropy_loss': -0.06317565124481916, 'vf_loss': 0.02775255707736102, 'total_loss': -0.001131752875992693, 'approx_kl': -0.04664021194912493, 'clip_fraction': 0.40625, 'grad_norm': 22.25432777404785}
2023-01-03 15:16:48.094 DEBUG: Taking gradient step
2023-01-03 15:16:50.143 DEBUG: Loss 7: {'policy_loss': 0.07040954248320201, 'entropy_loss': -0.062307821586728096, 'vf_loss': 0.028732503936938963, 'total_loss': 0.008101720896473916, 'approx_kl': -0.04443044122308493, 'clip_fraction': 0.3971354216337204, 'grad_norm': 11.63580322265625}
2023-01-03 15:16:52.165 DEBUG: Taking gradient step
2023-01-03 15:16:54.473 DEBUG: Loss 8: {'policy_loss': 0.1273699733597277, 'entropy_loss': -0.0633839750662446, 'vf_loss': 0.03170120710547256, 'total_loss': 0.06398599829348309, 'approx_kl': -0.05671687703579664, 'clip_fraction': 0.3671875, 'grad_norm': 23.81174087524414}
2023-01-03 15:16:56.852 DEBUG: Taking gradient step
2023-01-03 15:16:59.290 DEBUG: Loss 9: {'policy_loss': 0.03363059396060202, 'entropy_loss': -0.0631893565878272, 'vf_loss': 0.02691824944863399, 'total_loss': -0.02955876262722518, 'approx_kl': -0.06187058240175247, 'clip_fraction': 0.3645833358168602, 'grad_norm': 15.176698684692383}
2023-01-03 15:17:01.655 DEBUG: Taking gradient step
2023-01-03 15:17:04.087 DEBUG: Loss 10: {'policy_loss': 0.0034807416545940897, 'entropy_loss': -0.0630962522700429, 'vf_loss': 0.026244168704911405, 'total_loss': -0.05961551061544881, 'approx_kl': -0.06496174912899733, 'clip_fraction': 0.3776041716337204, 'grad_norm': 17.1249942779541}
2023-01-03 15:17:06.474 DEBUG: Taking gradient step
2023-01-03 15:17:08.921 DEBUG: Loss 11: {'policy_loss': 0.017375848467232367, 'entropy_loss': -0.0630161389708519, 'vf_loss': 0.0271868020277198, 'total_loss': -0.045640290503619535, 'approx_kl': -0.07281615771353245, 'clip_fraction': 0.3984375, 'grad_norm': 11.522366523742676}
2023-01-03 15:17:11.003 DEBUG: Taking gradient step
2023-01-03 15:17:13.050 DEBUG: Loss 12: {'policy_loss': 0.001956426237257978, 'entropy_loss': -0.06223376374691725, 'vf_loss': 0.02635992308294702, 'total_loss': -0.060277337509659266, 'approx_kl': -0.056289846543222666, 'clip_fraction': 0.3619791716337204, 'grad_norm': 16.389928817749023}
2023-01-03 15:17:15.119 DEBUG: Taking gradient step
2023-01-03 15:17:17.159 DEBUG: Loss 13: {'policy_loss': 0.0717563406844916, 'entropy_loss': -0.06299529131501913, 'vf_loss': 0.02881051249858675, 'total_loss': 0.00876104936947246, 'approx_kl': -0.07644250523298979, 'clip_fraction': 0.3776041716337204, 'grad_norm': 20.449495315551758}
2023-01-03 15:17:19.147 DEBUG: Taking gradient step
2023-01-03 15:17:21.194 DEBUG: Loss 14: {'policy_loss': 0.06475211676416961, 'entropy_loss': -0.06158369779586792, 'vf_loss': 0.027982092881506212, 'total_loss': 0.003168418968301695, 'approx_kl': -0.08639131672680378, 'clip_fraction': 0.3450520858168602, 'grad_norm': 15.2916841506958}
2023-01-03 15:17:21.194 INFO: Optimization: policy loss=0.065, vf loss=0.028, entropy loss=-0.062, total loss=0.003, num steps=15
2023-01-03 15:17:21.195 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 15:17:22.291 DEBUG: Atoms are too close
2023-01-03 15:17:22.294 INFO: Evaluation rollout: return=-15.233 (0.0), episode length=5.0
2023-01-03 15:17:22.294 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 15:17:22.297 INFO: Iteration: 34/137, steps: 7344
2023-01-03 15:17:31.597 DEBUG: Atoms are too close
2023-01-03 15:17:34.222 DEBUG: Atoms are too close
2023-01-03 15:17:40.328 DEBUG: Atoms are too close
2023-01-03 15:17:46.423 DEBUG: Atoms are too close
2023-01-03 15:17:53.172 DEBUG: Atoms are too close
2023-01-03 15:17:54.019 DEBUG: Atoms are too close
2023-01-03 15:17:54.586 DEBUG: Atoms are too close
2023-01-03 15:18:16.976 INFO: Training rollout: return=-2.646 (6.3), episode length=5.8
2023-01-03 15:18:16.977 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 15:18:16.980 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-7344_train.pkl
2023-01-03 15:18:18.993 DEBUG: Taking gradient step
2023-01-03 15:18:21.038 DEBUG: Loss 0: {'policy_loss': 0.09667197982649108, 'entropy_loss': -0.06255925633013248, 'vf_loss': 0.02508430291039515, 'total_loss': 0.03411272349635859, 'approx_kl': 5.636927014052162e-08, 'clip_fraction': 0.0, 'grad_norm': 30.171802520751953}
2023-01-03 15:18:23.048 DEBUG: Taking gradient step
2023-01-03 15:18:25.097 DEBUG: Loss 1: {'policy_loss': -0.014467891359589497, 'entropy_loss': -0.06257870700210333, 'vf_loss': 0.019570638246180095, 'total_loss': -0.07704659836169284, 'approx_kl': -0.011828296352177858, 'clip_fraction': 0.053385416977107525, 'grad_norm': 15.735148429870605}
2023-01-03 15:18:27.092 DEBUG: Taking gradient step
2023-01-03 15:18:29.159 DEBUG: Loss 2: {'policy_loss': 0.021877853990763214, 'entropy_loss': -0.06334360595792532, 'vf_loss': 0.02035566577830434, 'total_loss': -0.04146575196716211, 'approx_kl': -0.021631716983392835, 'clip_fraction': 0.26171875, 'grad_norm': 29.98586082458496}
2023-01-03 15:18:31.186 DEBUG: Taking gradient step
2023-01-03 15:18:33.248 DEBUG: Loss 3: {'policy_loss': -0.005426845916746359, 'entropy_loss': -0.0627182750031352, 'vf_loss': 0.019197265751423914, 'total_loss': -0.06814512091988156, 'approx_kl': -0.04875327507033944, 'clip_fraction': 0.31640625, 'grad_norm': 28.646268844604492}
2023-01-03 15:18:35.244 DEBUG: Taking gradient step
2023-01-03 15:18:37.291 DEBUG: Loss 4: {'policy_loss': 0.05757302921858639, 'entropy_loss': -0.06262802332639694, 'vf_loss': 0.022876351232481232, 'total_loss': -0.005054994107810556, 'approx_kl': -0.06051710247993469, 'clip_fraction': 0.3450520858168602, 'grad_norm': 23.46989631652832}
2023-01-03 15:18:39.292 DEBUG: Taking gradient step
2023-01-03 15:18:41.378 DEBUG: Loss 5: {'policy_loss': 0.08086361977706388, 'entropy_loss': -0.06343896221369505, 'vf_loss': 0.022089221588090114, 'total_loss': 0.017424657563368834, 'approx_kl': -0.06122320517897606, 'clip_fraction': 0.359375, 'grad_norm': 39.52141189575195}
2023-01-03 15:18:43.375 DEBUG: Taking gradient step
2023-01-03 15:18:45.426 DEBUG: Loss 6: {'policy_loss': -0.021679831273842, 'entropy_loss': -0.06336992420256138, 'vf_loss': 0.020537974698099527, 'total_loss': -0.08504975547640338, 'approx_kl': -0.06012247153557837, 'clip_fraction': 0.3502604216337204, 'grad_norm': 27.007272720336914}
2023-01-03 15:18:47.449 DEBUG: Taking gradient step
2023-01-03 15:18:49.492 DEBUG: Loss 7: {'policy_loss': -0.036175001305883234, 'entropy_loss': -0.06423994712531567, 'vf_loss': 0.019519513787225766, 'total_loss': -0.1004149484311989, 'approx_kl': -0.08368242718279362, 'clip_fraction': 0.4479166716337204, 'grad_norm': 20.182212829589844}
2023-01-03 15:18:51.477 DEBUG: Taking gradient step
2023-01-03 15:18:53.516 DEBUG: Loss 8: {'policy_loss': -0.034071719611012866, 'entropy_loss': -0.06292993016541004, 'vf_loss': 0.01951334005931663, 'total_loss': -0.09700164977642292, 'approx_kl': -0.0952483145520091, 'clip_fraction': 0.48828125, 'grad_norm': 18.1931095123291}
2023-01-03 15:18:55.515 DEBUG: Taking gradient step
2023-01-03 15:18:57.556 DEBUG: Loss 9: {'policy_loss': 0.05635950104437156, 'entropy_loss': -0.06362259853631258, 'vf_loss': 0.02238484864281122, 'total_loss': -0.007263097491941026, 'approx_kl': -0.09274652972817421, 'clip_fraction': 0.4596354216337204, 'grad_norm': 24.764982223510742}
2023-01-03 15:18:59.564 DEBUG: Taking gradient step
2023-01-03 15:19:01.702 DEBUG: Loss 10: {'policy_loss': -0.024351284921697303, 'entropy_loss': -0.06565345544368029, 'vf_loss': 0.019662145494747357, 'total_loss': -0.09000474036537759, 'approx_kl': -0.12593961600214243, 'clip_fraction': 0.5052083432674408, 'grad_norm': 23.03678321838379}
2023-01-03 15:19:03.711 DEBUG: Taking gradient step
2023-01-03 15:19:05.769 DEBUG: Loss 11: {'policy_loss': 0.01385647879055503, 'entropy_loss': -0.06529810838401318, 'vf_loss': 0.019799618863061953, 'total_loss': -0.05144162959345815, 'approx_kl': -0.12184735760092735, 'clip_fraction': 0.6328125, 'grad_norm': 20.880184173583984}
2023-01-03 15:19:07.829 DEBUG: Taking gradient step
2023-01-03 15:19:09.930 DEBUG: Loss 12: {'policy_loss': 0.060380195292463086, 'entropy_loss': -0.06465260591357946, 'vf_loss': 0.0206747329654074, 'total_loss': -0.004272410621116378, 'approx_kl': -0.12788883224129677, 'clip_fraction': 0.6041666716337204, 'grad_norm': 34.30721664428711}
2023-01-03 15:19:11.916 DEBUG: Taking gradient step
2023-01-03 15:19:13.955 DEBUG: Loss 13: {'policy_loss': 0.028535683391461366, 'entropy_loss': -0.06515760254114866, 'vf_loss': 0.020370431073319546, 'total_loss': -0.03662191914968729, 'approx_kl': -0.12177923694252968, 'clip_fraction': 0.6432291716337204, 'grad_norm': 29.84052276611328}
2023-01-03 15:19:15.952 DEBUG: Taking gradient step
2023-01-03 15:19:18.013 DEBUG: Loss 14: {'policy_loss': 0.07178499694318534, 'entropy_loss': -0.06643389165401459, 'vf_loss': 0.021518148750413944, 'total_loss': 0.005351105289170745, 'approx_kl': -0.11719364859163761, 'clip_fraction': 0.6236979216337204, 'grad_norm': 30.03203773498535}
2023-01-03 15:19:18.014 INFO: Optimization: policy loss=0.072, vf loss=0.022, entropy loss=-0.066, total loss=0.005, num steps=15
2023-01-03 15:19:18.015 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 15:19:19.127 DEBUG: Atoms are too close
2023-01-03 15:19:19.129 INFO: Evaluation rollout: return=-15.230 (0.0), episode length=5.0
2023-01-03 15:19:19.130 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 15:19:19.132 INFO: Iteration: 35/137, steps: 7560
2023-01-03 15:19:51.984 DEBUG: Atoms are too close
2023-01-03 15:20:09.477 DEBUG: Atoms are too close
2023-01-03 15:20:12.438 DEBUG: Atoms are too close
2023-01-03 15:20:15.339 INFO: Training rollout: return=-0.826 (4.2), episode length=5.9
2023-01-03 15:20:15.340 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 15:20:15.344 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-7560_train.pkl
2023-01-03 15:20:17.373 DEBUG: Taking gradient step
2023-01-03 15:20:19.468 DEBUG: Loss 0: {'policy_loss': 0.04315878582899459, 'entropy_loss': -0.07039236649870872, 'vf_loss': 0.013028617085467792, 'total_loss': -0.027233580669714125, 'approx_kl': 6.71328592716236e-09, 'clip_fraction': 0.0, 'grad_norm': 13.4775390625}
2023-01-03 15:20:21.516 DEBUG: Taking gradient step
2023-01-03 15:20:23.605 DEBUG: Loss 1: {'policy_loss': -0.009850855606533603, 'entropy_loss': -0.07024582102894783, 'vf_loss': 0.011061724609901905, 'total_loss': -0.08009667663548144, 'approx_kl': -0.005282808851916343, 'clip_fraction': 0.08333333395421505, 'grad_norm': 8.299659729003906}
2023-01-03 15:20:25.651 DEBUG: Taking gradient step
2023-01-03 15:20:27.752 DEBUG: Loss 2: {'policy_loss': 0.01854588084136608, 'entropy_loss': -0.06982658244669437, 'vf_loss': 0.012355323923647837, 'total_loss': -0.051280701605328285, 'approx_kl': -0.010570544982329011, 'clip_fraction': 0.2591145858168602, 'grad_norm': 12.013542175292969}
2023-01-03 15:20:29.806 DEBUG: Taking gradient step
2023-01-03 15:20:31.913 DEBUG: Loss 3: {'policy_loss': 0.011826790939262392, 'entropy_loss': -0.0658407174050808, 'vf_loss': 0.011303480234481845, 'total_loss': -0.05401392646581841, 'approx_kl': -0.046539015136659145, 'clip_fraction': 0.3307291716337204, 'grad_norm': 13.281396865844727}
2023-01-03 15:20:33.963 DEBUG: Taking gradient step
2023-01-03 15:20:36.059 DEBUG: Loss 4: {'policy_loss': 0.06120649198434449, 'entropy_loss': -0.06724896840751171, 'vf_loss': 0.011109337524456732, 'total_loss': -0.0060424764231672284, 'approx_kl': -0.06945594493299723, 'clip_fraction': 0.3854166716337204, 'grad_norm': 9.476670265197754}
2023-01-03 15:20:38.106 DEBUG: Taking gradient step
2023-01-03 15:20:40.205 DEBUG: Loss 5: {'policy_loss': 0.029081109299463767, 'entropy_loss': -0.06468209344893694, 'vf_loss': 0.01030781605206548, 'total_loss': -0.03560098414947318, 'approx_kl': -0.08415661565959454, 'clip_fraction': 0.50390625, 'grad_norm': 8.693251609802246}
2023-01-03 15:20:42.254 DEBUG: Taking gradient step
2023-01-03 15:20:44.324 DEBUG: Loss 6: {'policy_loss': 0.03735888855532352, 'entropy_loss': -0.06591426022350788, 'vf_loss': 0.010057480412256908, 'total_loss': -0.028555371668184358, 'approx_kl': -0.08987532183527946, 'clip_fraction': 0.5690104216337204, 'grad_norm': 9.06309986114502}
2023-01-03 15:20:46.358 DEBUG: Taking gradient step
2023-01-03 15:20:48.446 DEBUG: Loss 7: {'policy_loss': 0.05438434191887866, 'entropy_loss': -0.0670660212635994, 'vf_loss': 0.010524125194985648, 'total_loss': -0.012681679344720725, 'approx_kl': -0.10842449963092804, 'clip_fraction': 0.5807291716337204, 'grad_norm': 9.441885948181152}
2023-01-03 15:20:50.575 DEBUG: Taking gradient step
2023-01-03 15:20:52.655 DEBUG: Loss 8: {'policy_loss': 0.06213422303225326, 'entropy_loss': -0.06760584190487862, 'vf_loss': 0.011063586191745248, 'total_loss': -0.005471618872625362, 'approx_kl': -0.09567595459520817, 'clip_fraction': 0.5755208432674408, 'grad_norm': 8.122819900512695}
2023-01-03 15:20:54.704 DEBUG: Taking gradient step
2023-01-03 15:20:56.822 DEBUG: Loss 9: {'policy_loss': 0.05017390326739941, 'entropy_loss': -0.06900279223918915, 'vf_loss': 0.011051401730748478, 'total_loss': -0.018828888971789737, 'approx_kl': -0.09209362603724003, 'clip_fraction': 0.5143229216337204, 'grad_norm': 10.40270709991455}
2023-01-03 15:20:58.888 DEBUG: Taking gradient step
2023-01-03 15:21:01.001 DEBUG: Loss 10: {'policy_loss': 0.12049656823023856, 'entropy_loss': -0.0692918710410595, 'vf_loss': 0.014050780982001609, 'total_loss': 0.05120469718917908, 'approx_kl': -0.08586793672293425, 'clip_fraction': 0.53515625, 'grad_norm': 14.8760986328125}
2023-01-03 15:21:03.055 DEBUG: Taking gradient step
2023-01-03 15:21:05.120 DEBUG: Loss 11: {'policy_loss': 0.005763224065979296, 'entropy_loss': -0.06937319971621037, 'vf_loss': 0.009366839692628581, 'total_loss': -0.06360997565023108, 'approx_kl': -0.10743351886048913, 'clip_fraction': 0.5091145858168602, 'grad_norm': 7.0165300369262695}
2023-01-03 15:21:07.125 DEBUG: Taking gradient step
2023-01-03 15:21:09.200 DEBUG: Loss 12: {'policy_loss': 0.080341088591112, 'entropy_loss': -0.06871989369392395, 'vf_loss': 0.012091240025968791, 'total_loss': 0.011621194897188047, 'approx_kl': -0.11546511016786098, 'clip_fraction': 0.5481770932674408, 'grad_norm': 11.73550796508789}
2023-01-03 15:21:11.232 DEBUG: Taking gradient step
2023-01-03 15:21:13.302 DEBUG: Loss 13: {'policy_loss': 0.08854094793070919, 'entropy_loss': -0.07004613429307938, 'vf_loss': 0.011125791169317558, 'total_loss': 0.018494813637629805, 'approx_kl': -0.12136963056400418, 'clip_fraction': 0.53125, 'grad_norm': 9.457376480102539}
2023-01-03 15:21:15.378 DEBUG: Taking gradient step
2023-01-03 15:21:17.467 DEBUG: Loss 14: {'policy_loss': 0.015904620233696168, 'entropy_loss': -0.06877071596682072, 'vf_loss': 0.009227087457159687, 'total_loss': -0.05286609573312455, 'approx_kl': -0.10980437509715557, 'clip_fraction': 0.5286458358168602, 'grad_norm': 8.916452407836914}
2023-01-03 15:21:17.468 INFO: Optimization: policy loss=0.016, vf loss=0.009, entropy loss=-0.069, total loss=-0.053, num steps=15
2023-01-03 15:21:17.469 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 15:21:18.565 DEBUG: Atoms are too close
2023-01-03 15:21:18.567 INFO: Evaluation rollout: return=-15.233 (0.0), episode length=5.0
2023-01-03 15:21:18.568 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 15:21:18.571 INFO: Iteration: 36/137, steps: 7776
2023-01-03 15:21:31.606 DEBUG: Atoms are too close
2023-01-03 15:21:33.017 DEBUG: Atoms are too close
2023-01-03 15:21:33.708 DEBUG: Atoms are too close
2023-01-03 15:21:35.567 DEBUG: Atoms are too close
2023-01-03 15:22:05.968 DEBUG: Atoms are too close
2023-01-03 15:22:06.827 DEBUG: Atoms are too close
2023-01-03 15:22:10.698 DEBUG: Atoms are too close
2023-01-03 15:22:13.710 INFO: Training rollout: return=-2.538 (6.0), episode length=5.9
2023-01-03 15:22:13.711 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 15:22:13.714 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-7776_train.pkl
2023-01-03 15:22:15.755 DEBUG: Taking gradient step
2023-01-03 15:22:17.829 DEBUG: Loss 0: {'policy_loss': 0.028273078455613627, 'entropy_loss': -0.06233247648924589, 'vf_loss': 0.022821246829625063, 'total_loss': -0.03405939803363226, 'approx_kl': -8.07146349757204e-09, 'clip_fraction': 0.0, 'grad_norm': 27.675024032592773}
2023-01-03 15:22:19.846 DEBUG: Taking gradient step
2023-01-03 15:22:21.922 DEBUG: Loss 1: {'policy_loss': -0.010806227016407032, 'entropy_loss': -0.06268112920224667, 'vf_loss': 0.02233436520316446, 'total_loss': -0.0734873562186537, 'approx_kl': 0.00015784159768372774, 'clip_fraction': 0.00390625, 'grad_norm': 15.749889373779297}
2023-01-03 15:22:23.934 DEBUG: Taking gradient step
2023-01-03 15:22:25.996 DEBUG: Loss 2: {'policy_loss': 0.0010361983843136906, 'entropy_loss': -0.06315118074417114, 'vf_loss': 0.022380554758613593, 'total_loss': -0.06211498235985745, 'approx_kl': -0.021607648581266403, 'clip_fraction': 0.03125, 'grad_norm': 18.63512420654297}
2023-01-03 15:22:28.003 DEBUG: Taking gradient step
2023-01-03 15:22:30.081 DEBUG: Loss 3: {'policy_loss': -0.028921761159253562, 'entropy_loss': -0.06059034634381533, 'vf_loss': 0.02076008794927526, 'total_loss': -0.0895121075030689, 'approx_kl': -0.043704915791749954, 'clip_fraction': 0.1783854179084301, 'grad_norm': 20.217830657958984}
2023-01-03 15:22:32.102 DEBUG: Taking gradient step
2023-01-03 15:22:34.269 DEBUG: Loss 4: {'policy_loss': -0.008916663703166561, 'entropy_loss': -0.059278794564306736, 'vf_loss': 0.021503075428721992, 'total_loss': -0.0681954582674733, 'approx_kl': -0.057060773484408855, 'clip_fraction': 0.2994791679084301, 'grad_norm': 27.500778198242188}
2023-01-03 15:22:36.306 DEBUG: Taking gradient step
2023-01-03 15:22:38.382 DEBUG: Loss 5: {'policy_loss': 0.044983241180717656, 'entropy_loss': -0.059925418347120285, 'vf_loss': 0.02326828178135621, 'total_loss': -0.014942177166402629, 'approx_kl': -0.0756470337510109, 'clip_fraction': 0.4986979216337204, 'grad_norm': 26.736980438232422}
2023-01-03 15:22:40.409 DEBUG: Taking gradient step
2023-01-03 15:22:42.468 DEBUG: Loss 6: {'policy_loss': 0.045914064657850376, 'entropy_loss': -0.05774539150297642, 'vf_loss': 0.02268897798570517, 'total_loss': -0.011831326845126038, 'approx_kl': -0.1054106499068439, 'clip_fraction': 0.52734375, 'grad_norm': 28.526487350463867}
2023-01-03 15:22:44.475 DEBUG: Taking gradient step
2023-01-03 15:22:46.536 DEBUG: Loss 7: {'policy_loss': 0.07137697987863807, 'entropy_loss': -0.057990786619484425, 'vf_loss': 0.021525641816194985, 'total_loss': 0.013386193259153648, 'approx_kl': -0.10617318842560053, 'clip_fraction': 0.5130208358168602, 'grad_norm': 34.065345764160156}
2023-01-03 15:22:48.524 DEBUG: Taking gradient step
2023-01-03 15:22:50.573 DEBUG: Loss 8: {'policy_loss': 0.1319494284812792, 'entropy_loss': -0.05768259055912495, 'vf_loss': 0.0250080617695577, 'total_loss': 0.07426683792215423, 'approx_kl': -0.11924879997968674, 'clip_fraction': 0.5625, 'grad_norm': 36.18928146362305}
2023-01-03 15:22:52.580 DEBUG: Taking gradient step
2023-01-03 15:22:54.631 DEBUG: Loss 9: {'policy_loss': 0.01867425841189424, 'entropy_loss': -0.05908607877790928, 'vf_loss': 0.020223041646089825, 'total_loss': -0.04041182036601504, 'approx_kl': -0.11901764757931232, 'clip_fraction': 0.50390625, 'grad_norm': 22.819875717163086}
2023-01-03 15:22:56.626 DEBUG: Taking gradient step
2023-01-03 15:22:58.690 DEBUG: Loss 10: {'policy_loss': 0.07364884377257548, 'entropy_loss': -0.05875968933105469, 'vf_loss': 0.023331742149440768, 'total_loss': 0.014889154441520794, 'approx_kl': -0.11318740528076887, 'clip_fraction': 0.4739583358168602, 'grad_norm': 17.54379653930664}
2023-01-03 15:23:00.715 DEBUG: Taking gradient step
2023-01-03 15:23:02.795 DEBUG: Loss 11: {'policy_loss': 0.11579291373217526, 'entropy_loss': -0.05723468214273453, 'vf_loss': 0.024400776580925078, 'total_loss': 0.05855823158944074, 'approx_kl': -0.12155001424252987, 'clip_fraction': 0.5677083432674408, 'grad_norm': 34.66196823120117}
2023-01-03 15:23:04.791 DEBUG: Taking gradient step
2023-01-03 15:23:06.852 DEBUG: Loss 12: {'policy_loss': 0.06934524397971847, 'entropy_loss': -0.05708054266870022, 'vf_loss': 0.02154418643170941, 'total_loss': 0.012264701311018252, 'approx_kl': -0.12103510089218616, 'clip_fraction': 0.5625, 'grad_norm': 36.800540924072266}
2023-01-03 15:23:08.848 DEBUG: Taking gradient step
2023-01-03 15:23:10.889 DEBUG: Loss 13: {'policy_loss': 0.07584100342340692, 'entropy_loss': -0.056991688907146454, 'vf_loss': 0.022791512909974432, 'total_loss': 0.018849314516260474, 'approx_kl': -0.13044961541891098, 'clip_fraction': 0.5924479216337204, 'grad_norm': 33.96498107910156}
2023-01-03 15:23:12.884 DEBUG: Taking gradient step
2023-01-03 15:23:14.945 DEBUG: Loss 14: {'policy_loss': 0.01105652114179291, 'entropy_loss': -0.05675531271845102, 'vf_loss': 0.019743356635385918, 'total_loss': -0.04569879157665811, 'approx_kl': -0.12104053050279617, 'clip_fraction': 0.63671875, 'grad_norm': 26.482189178466797}
2023-01-03 15:23:14.946 INFO: Optimization: policy loss=0.011, vf loss=0.020, entropy loss=-0.057, total loss=-0.046, num steps=15
2023-01-03 15:23:14.947 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 15:23:16.645 INFO: Evaluation rollout: return=0.521 (0.0), episode length=6.0
2023-01-03 15:23:16.646 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 15:23:16.649 INFO: Iteration: 37/137, steps: 7992
2023-01-03 15:23:30.272 DEBUG: Atoms are too close
2023-01-03 15:23:30.834 DEBUG: Atoms are too close
2023-01-03 15:23:31.402 DEBUG: Atoms are too close
2023-01-03 15:23:45.406 DEBUG: Atoms are too close
2023-01-03 15:23:49.735 DEBUG: Atoms are too close
2023-01-03 15:23:50.410 DEBUG: Atoms are too close
2023-01-03 15:23:50.711 DEBUG: Atoms are too close
2023-01-03 15:24:00.473 DEBUG: Atoms are too close
2023-01-03 15:24:09.960 DEBUG: Atoms are too close
2023-01-03 15:24:11.586 INFO: Training rollout: return=-3.513 (6.8), episode length=5.8
2023-01-03 15:24:11.588 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 15:24:11.591 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-7992_train.pkl
2023-01-03 15:24:13.625 DEBUG: Taking gradient step
2023-01-03 15:24:15.672 DEBUG: Loss 0: {'policy_loss': -0.03791600353626484, 'entropy_loss': -0.0585862472653389, 'vf_loss': 0.023934023358352645, 'total_loss': -0.09650225080160374, 'approx_kl': -2.762923578814025e-08, 'clip_fraction': 0.0, 'grad_norm': 12.016879081726074}
2023-01-03 15:24:17.670 DEBUG: Taking gradient step
2023-01-03 15:24:19.810 DEBUG: Loss 1: {'policy_loss': 0.021354871204616342, 'entropy_loss': -0.0574513329192996, 'vf_loss': 0.02697387885456753, 'total_loss': -0.03609646171468326, 'approx_kl': -0.020850815577432513, 'clip_fraction': 0.2408854216337204, 'grad_norm': 17.334089279174805}
2023-01-03 15:24:21.821 DEBUG: Taking gradient step
2023-01-03 15:24:23.873 DEBUG: Loss 2: {'policy_loss': 0.06473429617401229, 'entropy_loss': -0.05785288941115141, 'vf_loss': 0.025833014346494796, 'total_loss': 0.006881406762860878, 'approx_kl': -0.03337355516850948, 'clip_fraction': 0.4036458358168602, 'grad_norm': 25.44854164123535}
2023-01-03 15:24:25.898 DEBUG: Taking gradient step
2023-01-03 15:24:27.980 DEBUG: Loss 3: {'policy_loss': 0.05081870212091428, 'entropy_loss': -0.05718338303267956, 'vf_loss': 0.02571706588006799, 'total_loss': -0.006364680911765279, 'approx_kl': -0.04455782379955053, 'clip_fraction': 0.43359375, 'grad_norm': 16.088088989257812}
2023-01-03 15:24:30.016 DEBUG: Taking gradient step
2023-01-03 15:24:32.055 DEBUG: Loss 4: {'policy_loss': 0.008900138164926855, 'entropy_loss': -0.0580048942938447, 'vf_loss': 0.023217205157503792, 'total_loss': -0.04910475612891785, 'approx_kl': -0.0531093580648303, 'clip_fraction': 0.40625, 'grad_norm': 14.133273124694824}
2023-01-03 15:24:34.050 DEBUG: Taking gradient step
2023-01-03 15:24:36.087 DEBUG: Loss 5: {'policy_loss': 0.0038211495632244144, 'entropy_loss': -0.05939279031008482, 'vf_loss': 0.02389619925336277, 'total_loss': -0.055571640746860405, 'approx_kl': -0.06817016657441854, 'clip_fraction': 0.38671875, 'grad_norm': 13.123085975646973}
2023-01-03 15:24:38.067 DEBUG: Taking gradient step
2023-01-03 15:24:40.102 DEBUG: Loss 6: {'policy_loss': -0.03766821037704056, 'entropy_loss': -0.05813859682530165, 'vf_loss': 0.02178002506285046, 'total_loss': -0.0958068072023422, 'approx_kl': -0.0640083085745573, 'clip_fraction': 0.41796875, 'grad_norm': 10.34085750579834}
2023-01-03 15:24:42.074 DEBUG: Taking gradient step
2023-01-03 15:24:44.135 DEBUG: Loss 7: {'policy_loss': 0.03753387614177248, 'entropy_loss': -0.056772506795823574, 'vf_loss': 0.024313242339862273, 'total_loss': -0.01923863065405109, 'approx_kl': -0.06825333833694458, 'clip_fraction': 0.4309895858168602, 'grad_norm': 10.879056930541992}
2023-01-03 15:24:46.146 DEBUG: Taking gradient step
2023-01-03 15:24:48.195 DEBUG: Loss 8: {'policy_loss': 0.040312825789412934, 'entropy_loss': -0.05784559529274702, 'vf_loss': 0.025823519799454284, 'total_loss': -0.017532769503334086, 'approx_kl': -0.08309401199221611, 'clip_fraction': 0.4322916716337204, 'grad_norm': 11.70396900177002}
2023-01-03 15:24:50.184 DEBUG: Taking gradient step
2023-01-03 15:24:52.231 DEBUG: Loss 9: {'policy_loss': -0.024675436277696756, 'entropy_loss': -0.05810774303972721, 'vf_loss': 0.02218175313189395, 'total_loss': -0.08278317931742396, 'approx_kl': -0.08775796927511692, 'clip_fraction': 0.4479166716337204, 'grad_norm': 13.516979217529297}
2023-01-03 15:24:54.219 DEBUG: Taking gradient step
2023-01-03 15:24:56.249 DEBUG: Loss 10: {'policy_loss': -0.017921904104226807, 'entropy_loss': -0.056746711023151875, 'vf_loss': 0.0226564210447664, 'total_loss': -0.07466861512737868, 'approx_kl': -0.09813358169049025, 'clip_fraction': 0.40625, 'grad_norm': 11.731796264648438}
2023-01-03 15:24:58.225 DEBUG: Taking gradient step
2023-01-03 15:25:00.252 DEBUG: Loss 11: {'policy_loss': -0.004981968973957238, 'entropy_loss': -0.057045675814151764, 'vf_loss': 0.02286297989781485, 'total_loss': -0.062027644788109, 'approx_kl': -0.1163194989785552, 'clip_fraction': 0.4505208432674408, 'grad_norm': 15.757085800170898}
2023-01-03 15:25:02.238 DEBUG: Taking gradient step
2023-01-03 15:25:04.291 DEBUG: Loss 12: {'policy_loss': 0.04903751638260334, 'entropy_loss': -0.0579629261046648, 'vf_loss': 0.024830978636044047, 'total_loss': -0.008925409722061461, 'approx_kl': -0.08183099702000618, 'clip_fraction': 0.41796875, 'grad_norm': 19.836971282958984}
2023-01-03 15:25:06.268 DEBUG: Taking gradient step
2023-01-03 15:25:08.344 DEBUG: Loss 13: {'policy_loss': 0.03867136437450884, 'entropy_loss': -0.057348743081092834, 'vf_loss': 0.024470976911853556, 'total_loss': -0.018677378706583994, 'approx_kl': -0.08588790521025658, 'clip_fraction': 0.3815104216337204, 'grad_norm': 10.802870750427246}
2023-01-03 15:25:10.654 DEBUG: Taking gradient step
2023-01-03 15:25:13.082 DEBUG: Loss 14: {'policy_loss': 0.04788500427639922, 'entropy_loss': -0.05810036975890398, 'vf_loss': 0.02567565027537482, 'total_loss': -0.010215365482504762, 'approx_kl': -0.09886772558093071, 'clip_fraction': 0.3997395858168602, 'grad_norm': 15.116083145141602}
2023-01-03 15:25:13.083 INFO: Optimization: policy loss=0.048, vf loss=0.026, entropy loss=-0.058, total loss=-0.010, num steps=15
2023-01-03 15:25:13.084 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 15:25:14.861 INFO: Evaluation rollout: return=0.537 (0.0), episode length=6.0
2023-01-03 15:25:14.862 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 15:25:14.866 INFO: Iteration: 38/137, steps: 8208
2023-01-03 15:25:25.253 DEBUG: Atoms are too close
2023-01-03 15:25:28.177 DEBUG: Atoms are too close
2023-01-03 15:25:30.675 DEBUG: Atoms are too close
2023-01-03 15:25:45.995 DEBUG: Atoms are too close
2023-01-03 15:25:57.283 DEBUG: Atoms are too close
2023-01-03 15:26:13.904 DEBUG: Atoms are too close
2023-01-03 15:26:14.821 INFO: Training rollout: return=-2.262 (6.0), episode length=5.8
2023-01-03 15:26:14.822 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 15:26:14.825 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-8208_train.pkl
2023-01-03 15:26:16.855 DEBUG: Taking gradient step
2023-01-03 15:26:19.044 DEBUG: Loss 0: {'policy_loss': 0.018870477979677242, 'entropy_loss': -0.057877651415765285, 'vf_loss': 0.020311785249335444, 'total_loss': -0.03900717343608803, 'approx_kl': -9.623665420122052e-09, 'clip_fraction': 0.0, 'grad_norm': 19.842342376708984}
2023-01-03 15:26:21.440 DEBUG: Taking gradient step
2023-01-03 15:26:23.905 DEBUG: Loss 1: {'policy_loss': -0.024660177141313515, 'entropy_loss': -0.0578084634616971, 'vf_loss': 0.019186081600113956, 'total_loss': -0.08246864060301061, 'approx_kl': -0.0037717565428465605, 'clip_fraction': 0.17578125, 'grad_norm': 24.328556060791016}
2023-01-03 15:26:26.008 DEBUG: Taking gradient step
2023-01-03 15:26:28.067 DEBUG: Loss 2: {'policy_loss': 0.09048894387185645, 'entropy_loss': -0.05765129439532757, 'vf_loss': 0.02246263891677603, 'total_loss': 0.03283764947652888, 'approx_kl': -0.0047539129154756665, 'clip_fraction': 0.26171875, 'grad_norm': 20.59467124938965}
2023-01-03 15:26:30.104 DEBUG: Taking gradient step
2023-01-03 15:26:32.193 DEBUG: Loss 3: {'policy_loss': 0.04373826479809002, 'entropy_loss': -0.05817975290119648, 'vf_loss': 0.02067445859363288, 'total_loss': -0.01444148810310647, 'approx_kl': -0.006382628809660673, 'clip_fraction': 0.3802083358168602, 'grad_norm': 33.24950408935547}
2023-01-03 15:26:34.195 DEBUG: Taking gradient step
2023-01-03 15:26:36.249 DEBUG: Loss 4: {'policy_loss': 0.005179083461070048, 'entropy_loss': -0.05835749115794897, 'vf_loss': 0.01952462358597238, 'total_loss': -0.05317840769687893, 'approx_kl': -0.020513857249170542, 'clip_fraction': 0.2838541716337204, 'grad_norm': 28.82051658630371}
2023-01-03 15:26:38.254 DEBUG: Taking gradient step
2023-01-03 15:26:40.306 DEBUG: Loss 5: {'policy_loss': -0.0028094897303985586, 'entropy_loss': -0.05705070588737726, 'vf_loss': 0.018741640506967732, 'total_loss': -0.05986019561777582, 'approx_kl': -0.01571246050298214, 'clip_fraction': 0.3736979216337204, 'grad_norm': 15.677993774414062}
2023-01-03 15:26:42.322 DEBUG: Taking gradient step
2023-01-03 15:26:44.413 DEBUG: Loss 6: {'policy_loss': 0.039777957704150685, 'entropy_loss': -0.057865059934556484, 'vf_loss': 0.020012149820543057, 'total_loss': -0.0180871022304058, 'approx_kl': -0.005955852218903601, 'clip_fraction': 0.40234375, 'grad_norm': 15.562128067016602}
2023-01-03 15:26:46.419 DEBUG: Taking gradient step
2023-01-03 15:26:48.577 DEBUG: Loss 7: {'policy_loss': 0.008044573104550309, 'entropy_loss': -0.05478093773126602, 'vf_loss': 0.0185644552359644, 'total_loss': -0.04673636462671572, 'approx_kl': -0.00852474314160645, 'clip_fraction': 0.3255208358168602, 'grad_norm': 7.576813220977783}
2023-01-03 15:26:50.619 DEBUG: Taking gradient step
2023-01-03 15:26:52.729 DEBUG: Loss 8: {'policy_loss': 0.026370433599617413, 'entropy_loss': -0.056901633739471436, 'vf_loss': 0.01959053131333274, 'total_loss': -0.03053120013985402, 'approx_kl': -0.018658454879187047, 'clip_fraction': 0.31640625, 'grad_norm': 19.241796493530273}
2023-01-03 15:26:54.759 DEBUG: Taking gradient step
2023-01-03 15:26:56.849 DEBUG: Loss 9: {'policy_loss': -0.007319749310067493, 'entropy_loss': -0.05666053853929043, 'vf_loss': 0.018709722636067, 'total_loss': -0.06398028784935791, 'approx_kl': -0.0021315328776836395, 'clip_fraction': 0.3658854216337204, 'grad_norm': 14.145079612731934}
2023-01-03 15:26:59.390 DEBUG: Taking gradient step
2023-01-03 15:27:01.948 DEBUG: Loss 10: {'policy_loss': 0.00604495972761771, 'entropy_loss': -0.05618074629455805, 'vf_loss': 0.019592837114239075, 'total_loss': -0.05013578656694034, 'approx_kl': -0.0239584781229496, 'clip_fraction': 0.40625, 'grad_norm': 22.662511825561523}
2023-01-03 15:27:04.057 DEBUG: Taking gradient step
2023-01-03 15:27:06.148 DEBUG: Loss 11: {'policy_loss': 0.002784335554291764, 'entropy_loss': -0.05612496379762888, 'vf_loss': 0.017299768605735295, 'total_loss': -0.053340628243337115, 'approx_kl': -0.035826473496854305, 'clip_fraction': 0.375, 'grad_norm': 27.80221939086914}
2023-01-03 15:27:08.200 DEBUG: Taking gradient step
2023-01-03 15:27:10.307 DEBUG: Loss 12: {'policy_loss': 0.07133447501187345, 'entropy_loss': -0.054154304787516594, 'vf_loss': 0.018260332743671753, 'total_loss': 0.017180170224356854, 'approx_kl': -0.022963464609347284, 'clip_fraction': 0.3997395858168602, 'grad_norm': 34.24779510498047}
2023-01-03 15:27:12.360 DEBUG: Taking gradient step
2023-01-03 15:27:14.461 DEBUG: Loss 13: {'policy_loss': 0.006072026343586431, 'entropy_loss': -0.05311070941388607, 'vf_loss': 0.018272224364640918, 'total_loss': -0.04703868307029964, 'approx_kl': -0.052199583034962416, 'clip_fraction': 0.4127604216337204, 'grad_norm': 20.864023208618164}
2023-01-03 15:27:16.498 DEBUG: Taking gradient step
2023-01-03 15:27:18.586 DEBUG: Loss 14: {'policy_loss': -0.007803820282236057, 'entropy_loss': -0.053645350970327854, 'vf_loss': 0.018392560599522996, 'total_loss': -0.06144917125256391, 'approx_kl': -0.05858433013781905, 'clip_fraction': 0.4075520858168602, 'grad_norm': 14.591349601745605}
2023-01-03 15:27:18.587 INFO: Optimization: policy loss=-0.008, vf loss=0.018, entropy loss=-0.054, total loss=-0.061, num steps=15
2023-01-03 15:27:18.588 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 15:27:19.995 DEBUG: Atoms are too close
2023-01-03 15:27:19.997 INFO: Evaluation rollout: return=-12.909 (0.0), episode length=6.0
2023-01-03 15:27:19.997 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 15:27:20.000 INFO: Iteration: 39/137, steps: 8424
2023-01-03 15:27:53.016 DEBUG: Atoms are too close
2023-01-03 15:27:56.027 DEBUG: Atoms are too close
2023-01-03 15:28:10.655 DEBUG: Atoms are too close
2023-01-03 15:28:11.913 DEBUG: Atoms are too close
2023-01-03 15:28:17.595 DEBUG: Atoms are too close
2023-01-03 15:28:17.654 INFO: Training rollout: return=-1.699 (5.3), episode length=5.9
2023-01-03 15:28:17.655 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 15:28:17.658 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-8424_train.pkl
2023-01-03 15:28:19.728 DEBUG: Taking gradient step
2023-01-03 15:28:21.839 DEBUG: Loss 0: {'policy_loss': -0.011688272282196745, 'entropy_loss': -0.054683745838701725, 'vf_loss': 0.01498828746207116, 'total_loss': -0.06637201812089846, 'approx_kl': -3.294553607702255e-08, 'clip_fraction': 0.0, 'grad_norm': 17.636615753173828}
2023-01-03 15:28:23.869 DEBUG: Taking gradient step
2023-01-03 15:28:25.967 DEBUG: Loss 1: {'policy_loss': 0.008496249235356305, 'entropy_loss': -0.05522662028670311, 'vf_loss': 0.016435124001672297, 'total_loss': -0.04673037105134681, 'approx_kl': -0.0039454951183870435, 'clip_fraction': 0.0, 'grad_norm': 16.837970733642578}
2023-01-03 15:28:28.005 DEBUG: Taking gradient step
2023-01-03 15:28:30.094 DEBUG: Loss 2: {'policy_loss': -0.03198304417828964, 'entropy_loss': -0.054866294376552105, 'vf_loss': 0.015264192331846647, 'total_loss': -0.08684933855484175, 'approx_kl': -0.017343781189993024, 'clip_fraction': 0.10286458395421505, 'grad_norm': 14.708650588989258}
2023-01-03 15:28:32.121 DEBUG: Taking gradient step
2023-01-03 15:28:34.238 DEBUG: Loss 3: {'policy_loss': 0.11521408824193574, 'entropy_loss': -0.05570022575557232, 'vf_loss': 0.021360444822702444, 'total_loss': 0.05951386248636342, 'approx_kl': -0.024355697096325457, 'clip_fraction': 0.2239583358168602, 'grad_norm': 21.41361427307129}
2023-01-03 15:28:36.288 DEBUG: Taking gradient step
2023-01-03 15:28:38.377 DEBUG: Loss 4: {'policy_loss': -0.031113209648753224, 'entropy_loss': -0.054882257245481014, 'vf_loss': 0.014080854131427581, 'total_loss': -0.08599546689423423, 'approx_kl': -0.03842306509613991, 'clip_fraction': 0.30859375, 'grad_norm': 15.659017562866211}
2023-01-03 15:28:40.435 DEBUG: Taking gradient step
2023-01-03 15:28:42.564 DEBUG: Loss 5: {'policy_loss': 0.010652062540258574, 'entropy_loss': -0.05578359588980675, 'vf_loss': 0.01600509217126283, 'total_loss': -0.045131533349548184, 'approx_kl': -0.04909732285887003, 'clip_fraction': 0.3125, 'grad_norm': 22.300418853759766}
2023-01-03 15:28:44.619 DEBUG: Taking gradient step
2023-01-03 15:28:46.716 DEBUG: Loss 6: {'policy_loss': -0.03585437957339148, 'entropy_loss': -0.05431405082345009, 'vf_loss': 0.014717857756184593, 'total_loss': -0.09016843039684155, 'approx_kl': -0.05233877943828702, 'clip_fraction': 0.3294270858168602, 'grad_norm': 11.772210121154785}
2023-01-03 15:28:48.727 DEBUG: Taking gradient step
2023-01-03 15:28:50.895 DEBUG: Loss 7: {'policy_loss': -0.0670543583815981, 'entropy_loss': -0.05422831978648901, 'vf_loss': 0.014215140933834487, 'total_loss': -0.1212826781680871, 'approx_kl': -0.05323695531114936, 'clip_fraction': 0.36328125, 'grad_norm': 8.434100151062012}
2023-01-03 15:28:52.923 DEBUG: Taking gradient step
2023-01-03 15:28:55.001 DEBUG: Loss 8: {'policy_loss': -0.060055059948245434, 'entropy_loss': -0.0551679152995348, 'vf_loss': 0.013848848809750024, 'total_loss': -0.11522297524778023, 'approx_kl': -0.059898847714066505, 'clip_fraction': 0.4596354216337204, 'grad_norm': 10.45559310913086}
2023-01-03 15:28:57.037 DEBUG: Taking gradient step
2023-01-03 15:28:59.158 DEBUG: Loss 9: {'policy_loss': -0.053644469498101276, 'entropy_loss': -0.05489369481801987, 'vf_loss': 0.014305538005611356, 'total_loss': -0.10853816431612115, 'approx_kl': -0.07071573100984097, 'clip_fraction': 0.4231770858168602, 'grad_norm': 15.146251678466797}
2023-01-03 15:29:01.203 DEBUG: Taking gradient step
2023-01-03 15:29:03.335 DEBUG: Loss 10: {'policy_loss': -0.019623608550605746, 'entropy_loss': -0.05377760622650385, 'vf_loss': 0.015202205243288995, 'total_loss': -0.07340121477710959, 'approx_kl': -0.08245300874114037, 'clip_fraction': 0.4557291716337204, 'grad_norm': 17.939838409423828}
2023-01-03 15:29:05.762 DEBUG: Taking gradient step
2023-01-03 15:29:08.254 DEBUG: Loss 11: {'policy_loss': -0.025380443564493465, 'entropy_loss': -0.05335663817822933, 'vf_loss': 0.014617323950141413, 'total_loss': -0.0787370817427228, 'approx_kl': -0.0815613679587841, 'clip_fraction': 0.546875, 'grad_norm': 20.50080680847168}
2023-01-03 15:29:10.684 DEBUG: Taking gradient step
2023-01-03 15:29:13.140 DEBUG: Loss 12: {'policy_loss': 0.024903544522160273, 'entropy_loss': -0.05450290348380804, 'vf_loss': 0.016176745583882487, 'total_loss': -0.029599358961647768, 'approx_kl': -0.08369332947768271, 'clip_fraction': 0.5611979216337204, 'grad_norm': 25.50336456298828}
2023-01-03 15:29:15.158 DEBUG: Taking gradient step
2023-01-03 15:29:17.225 DEBUG: Loss 13: {'policy_loss': 0.03950933995952639, 'entropy_loss': -0.05282876640558243, 'vf_loss': 0.016428490065527816, 'total_loss': -0.013319426446056035, 'approx_kl': -0.08081720769405365, 'clip_fraction': 0.5716145932674408, 'grad_norm': 15.542612075805664}
2023-01-03 15:29:19.232 DEBUG: Taking gradient step
2023-01-03 15:29:21.289 DEBUG: Loss 14: {'policy_loss': -0.024052731520246, 'entropy_loss': -0.052335805259644985, 'vf_loss': 0.0152709863433089, 'total_loss': -0.07638853677989096, 'approx_kl': -0.10336946696043015, 'clip_fraction': 0.5794270932674408, 'grad_norm': 13.366905212402344}
2023-01-03 15:29:21.290 INFO: Optimization: policy loss=-0.024, vf loss=0.015, entropy loss=-0.052, total loss=-0.076, num steps=15
2023-01-03 15:29:21.291 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 15:29:22.969 INFO: Evaluation rollout: return=0.492 (0.0), episode length=6.0
2023-01-03 15:29:22.970 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 15:29:22.973 INFO: Iteration: 40/137, steps: 8640
2023-01-03 15:29:35.241 DEBUG: Atoms are too close
2023-01-03 15:29:40.339 DEBUG: Atoms are too close
2023-01-03 15:29:56.408 DEBUG: Atoms are too close
2023-01-03 15:30:09.235 DEBUG: Atoms are too close
2023-01-03 15:30:12.578 DEBUG: There is a single atom floating around
2023-01-03 15:30:12.579 DEBUG: Atoms are too close
2023-01-03 15:30:16.903 DEBUG: Atoms are too close
2023-01-03 15:30:17.970 INFO: Training rollout: return=-2.564 (5.9), episode length=5.9
2023-01-03 15:30:17.972 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 15:30:17.975 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-8640_train.pkl
2023-01-03 15:30:19.998 DEBUG: Taking gradient step
2023-01-03 15:30:22.055 DEBUG: Loss 0: {'policy_loss': -0.04384304912111431, 'entropy_loss': -0.05346546974033117, 'vf_loss': 0.019353428179644486, 'total_loss': -0.09730851886144548, 'approx_kl': 5.50062395632267e-09, 'clip_fraction': 0.0, 'grad_norm': 10.361104965209961}
2023-01-03 15:30:24.056 DEBUG: Taking gradient step
2023-01-03 15:30:26.111 DEBUG: Loss 1: {'policy_loss': -0.01941067131987896, 'entropy_loss': -0.05342551227658987, 'vf_loss': 0.021479686917838445, 'total_loss': -0.07283618359646883, 'approx_kl': -0.01509206765331328, 'clip_fraction': 0.1341145858168602, 'grad_norm': 6.76123571395874}
2023-01-03 15:30:28.139 DEBUG: Taking gradient step
2023-01-03 15:30:30.218 DEBUG: Loss 2: {'policy_loss': -0.0166230332573164, 'entropy_loss': -0.05524315778166056, 'vf_loss': 0.020859774644943416, 'total_loss': -0.07186619103897696, 'approx_kl': -0.01268821582198143, 'clip_fraction': 0.3307291716337204, 'grad_norm': 12.487508773803711}
2023-01-03 15:30:32.243 DEBUG: Taking gradient step
2023-01-03 15:30:34.316 DEBUG: Loss 3: {'policy_loss': 0.008734310850535644, 'entropy_loss': -0.054890154860913754, 'vf_loss': 0.021795641419369575, 'total_loss': -0.04615584401037811, 'approx_kl': -0.022718914318829775, 'clip_fraction': 0.390625, 'grad_norm': 11.625374794006348}
2023-01-03 15:30:36.322 DEBUG: Taking gradient step
2023-01-03 15:30:38.400 DEBUG: Loss 4: {'policy_loss': -0.0029788410968880925, 'entropy_loss': -0.05392064433544874, 'vf_loss': 0.021909108625450667, 'total_loss': -0.05689948543233683, 'approx_kl': -0.022450198302976787, 'clip_fraction': 0.4140625, 'grad_norm': 17.55554962158203}
2023-01-03 15:30:40.497 DEBUG: Taking gradient step
2023-01-03 15:30:42.554 DEBUG: Loss 5: {'policy_loss': -0.025831257724456304, 'entropy_loss': -0.05428540427237749, 'vf_loss': 0.01961867307638618, 'total_loss': -0.08011666199683379, 'approx_kl': -0.03412991750519723, 'clip_fraction': 0.4296875, 'grad_norm': 10.281196594238281}
2023-01-03 15:30:44.573 DEBUG: Taking gradient step
2023-01-03 15:30:46.674 DEBUG: Loss 6: {'policy_loss': -0.004626534139187277, 'entropy_loss': -0.053054410964250565, 'vf_loss': 0.020788752270691324, 'total_loss': -0.05768094510343784, 'approx_kl': -0.0454456121660769, 'clip_fraction': 0.3489583358168602, 'grad_norm': 16.094181060791016}
2023-01-03 15:30:48.712 DEBUG: Taking gradient step
2023-01-03 15:30:50.818 DEBUG: Loss 7: {'policy_loss': 0.026699916035571498, 'entropy_loss': -0.052331309765577316, 'vf_loss': 0.022447002602847696, 'total_loss': -0.025631393730005815, 'approx_kl': -0.05834333738312125, 'clip_fraction': 0.4361979216337204, 'grad_norm': 15.286699295043945}
2023-01-03 15:30:52.880 DEBUG: Taking gradient step
2023-01-03 15:30:54.996 DEBUG: Loss 8: {'policy_loss': -0.010283792979431175, 'entropy_loss': -0.05141738895326853, 'vf_loss': 0.020312535552373064, 'total_loss': -0.06170118193269971, 'approx_kl': -0.04191139340400696, 'clip_fraction': 0.4557291716337204, 'grad_norm': 10.33311939239502}
2023-01-03 15:30:57.024 DEBUG: Taking gradient step
2023-01-03 15:30:59.082 DEBUG: Loss 9: {'policy_loss': -0.00120466533890351, 'entropy_loss': -0.0517709543928504, 'vf_loss': 0.02036961552237721, 'total_loss': -0.05297561973175391, 'approx_kl': -0.0715523511171341, 'clip_fraction': 0.4583333358168602, 'grad_norm': 18.843730926513672}
2023-01-03 15:31:01.115 DEBUG: Taking gradient step
2023-01-03 15:31:03.194 DEBUG: Loss 10: {'policy_loss': -0.04009677196456963, 'entropy_loss': -0.05249722581356764, 'vf_loss': 0.02084096481231798, 'total_loss': -0.09259399777813726, 'approx_kl': -0.08331167232245207, 'clip_fraction': 0.5221354216337204, 'grad_norm': 8.683341026306152}
2023-01-03 15:31:05.197 DEBUG: Taking gradient step
2023-01-03 15:31:07.284 DEBUG: Loss 11: {'policy_loss': -0.029854576689438285, 'entropy_loss': -0.050997729413211346, 'vf_loss': 0.02048531109489052, 'total_loss': -0.08085230610264962, 'approx_kl': -0.08156345621682703, 'clip_fraction': 0.52734375, 'grad_norm': 7.972761631011963}
2023-01-03 15:31:09.301 DEBUG: Taking gradient step
2023-01-03 15:31:11.377 DEBUG: Loss 12: {'policy_loss': -0.038617951785737986, 'entropy_loss': -0.05285163689404726, 'vf_loss': 0.019288743583193543, 'total_loss': -0.09146958867978525, 'approx_kl': -0.07244416465982795, 'clip_fraction': 0.5546875, 'grad_norm': 12.443221092224121}
2023-01-03 15:31:13.423 DEBUG: Taking gradient step
2023-01-03 15:31:15.494 DEBUG: Loss 13: {'policy_loss': 0.010145331651450151, 'entropy_loss': -0.0518273189663887, 'vf_loss': 0.021365918841725666, 'total_loss': -0.04168198731493855, 'approx_kl': -0.08309950679540634, 'clip_fraction': 0.41796875, 'grad_norm': 17.223011016845703}
2023-01-03 15:31:17.540 DEBUG: Taking gradient step
2023-01-03 15:31:19.620 DEBUG: Loss 14: {'policy_loss': -0.07701523640417457, 'entropy_loss': -0.05099399387836456, 'vf_loss': 0.019067202990330795, 'total_loss': -0.12800923028253913, 'approx_kl': -0.09098588488996029, 'clip_fraction': 0.3880208358168602, 'grad_norm': 8.560430526733398}
2023-01-03 15:31:19.620 INFO: Optimization: policy loss=-0.077, vf loss=0.019, entropy loss=-0.051, total loss=-0.128, num steps=15
2023-01-03 15:31:19.621 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 15:31:21.380 INFO: Evaluation rollout: return=0.360 (0.0), episode length=6.0
2023-01-03 15:31:21.381 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 15:31:21.384 DEBUG: Deleting old model: runs/CH3NO_dna/models/CH3NO_dna_run-1_steps-6696.model
2023-01-03 15:31:21.389 DEBUG: Saving model: runs/CH3NO_dna/models/CH3NO_dna_run-1_steps-8856.model
2023-01-03 15:31:21.438 INFO: Iteration: 41/137, steps: 8856
2023-01-03 15:31:37.207 DEBUG: Atoms are too close
2023-01-03 15:31:58.857 DEBUG: Atoms are too close
2023-01-03 15:32:16.846 DEBUG: Atoms are too close
2023-01-03 15:32:17.126 DEBUG: Atoms are too close
2023-01-03 15:32:18.178 INFO: Training rollout: return=-1.211 (4.4), episode length=6.0
2023-01-03 15:32:18.179 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 15:32:18.182 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-8856_train.pkl
2023-01-03 15:32:20.235 DEBUG: Taking gradient step
2023-01-03 15:32:22.316 DEBUG: Loss 0: {'policy_loss': 0.0016762142815778674, 'entropy_loss': -0.05385154113173485, 'vf_loss': 0.01570087346853998, 'total_loss': -0.05217532685015698, 'approx_kl': -7.859974537893777e-08, 'clip_fraction': 0.0, 'grad_norm': 19.529579162597656}
2023-01-03 15:32:24.345 DEBUG: Taking gradient step
2023-01-03 15:32:26.504 DEBUG: Loss 1: {'policy_loss': -0.019379279455857427, 'entropy_loss': -0.05461069941520691, 'vf_loss': 0.014719468866863082, 'total_loss': -0.07398997887106434, 'approx_kl': 0.0018424023874104023, 'clip_fraction': 0.06770833395421505, 'grad_norm': 17.7044734954834}
2023-01-03 15:32:28.551 DEBUG: Taking gradient step
2023-01-03 15:32:30.641 DEBUG: Loss 2: {'policy_loss': -0.0035559194086778726, 'entropy_loss': -0.054374522529542446, 'vf_loss': 0.01527250227475773, 'total_loss': -0.05793044193822031, 'approx_kl': -0.014834519010037184, 'clip_fraction': 0.2005208358168602, 'grad_norm': 13.80893325805664}
2023-01-03 15:32:32.686 DEBUG: Taking gradient step
2023-01-03 15:32:34.783 DEBUG: Loss 3: {'policy_loss': -0.03966690012709297, 'entropy_loss': -0.05239796359091997, 'vf_loss': 0.014133826433756816, 'total_loss': -0.09206486371801295, 'approx_kl': -0.031644325237721205, 'clip_fraction': 0.2994791716337204, 'grad_norm': 12.33906364440918}
2023-01-03 15:32:36.814 DEBUG: Taking gradient step
2023-01-03 15:32:38.890 DEBUG: Loss 4: {'policy_loss': -0.02811206687928766, 'entropy_loss': -0.05118151847273111, 'vf_loss': 0.01438218321429552, 'total_loss': -0.07929358535201878, 'approx_kl': -0.047155740670859814, 'clip_fraction': 0.3411458358168602, 'grad_norm': 18.36187171936035}
2023-01-03 15:32:40.918 DEBUG: Taking gradient step
2023-01-03 15:32:43.007 DEBUG: Loss 5: {'policy_loss': -0.005164144428294375, 'entropy_loss': -0.05235706828534603, 'vf_loss': 0.015010779523565995, 'total_loss': -0.05752121271364041, 'approx_kl': -0.03626325912773609, 'clip_fraction': 0.3802083358168602, 'grad_norm': 11.783998489379883}
2023-01-03 15:32:45.042 DEBUG: Taking gradient step
2023-01-03 15:32:47.120 DEBUG: Loss 6: {'policy_loss': -0.012437730104435258, 'entropy_loss': -0.05170936603099108, 'vf_loss': 0.014723760904530668, 'total_loss': -0.06414709613542632, 'approx_kl': -0.04890825692564249, 'clip_fraction': 0.3528645858168602, 'grad_norm': 7.423107624053955}
2023-01-03 15:32:49.136 DEBUG: Taking gradient step
2023-01-03 15:32:51.205 DEBUG: Loss 7: {'policy_loss': 0.07855078670399773, 'entropy_loss': -0.05451098829507828, 'vf_loss': 0.01918024813541644, 'total_loss': 0.024039798408919455, 'approx_kl': -0.04584977496415377, 'clip_fraction': 0.3385416716337204, 'grad_norm': 10.394354820251465}
2023-01-03 15:32:53.212 DEBUG: Taking gradient step
2023-01-03 15:32:55.283 DEBUG: Loss 8: {'policy_loss': -0.009233387391357092, 'entropy_loss': -0.05271364748477936, 'vf_loss': 0.014851542933322713, 'total_loss': -0.06194703487613645, 'approx_kl': -0.08116892538964748, 'clip_fraction': 0.3190104216337204, 'grad_norm': 13.15102481842041}
2023-01-03 15:32:57.314 DEBUG: Taking gradient step
2023-01-03 15:32:59.397 DEBUG: Loss 9: {'policy_loss': -0.027839179567094592, 'entropy_loss': -0.05485304817557335, 'vf_loss': 0.014051803753551532, 'total_loss': -0.08269222774266793, 'approx_kl': -0.09685472305864096, 'clip_fraction': 0.3645833432674408, 'grad_norm': 18.208980560302734}
2023-01-03 15:33:01.410 DEBUG: Taking gradient step
2023-01-03 15:33:03.470 DEBUG: Loss 10: {'policy_loss': 0.003705516441145302, 'entropy_loss': -0.05272172391414642, 'vf_loss': 0.016024548614989823, 'total_loss': -0.049016207473001124, 'approx_kl': -0.06620119139552116, 'clip_fraction': 0.3580729216337204, 'grad_norm': 17.358598709106445}
2023-01-03 15:33:05.476 DEBUG: Taking gradient step
2023-01-03 15:33:07.554 DEBUG: Loss 11: {'policy_loss': 0.027910359362837228, 'entropy_loss': -0.05493240896612406, 'vf_loss': 0.014982074639737438, 'total_loss': -0.02702204960328683, 'approx_kl': -0.06961505021899939, 'clip_fraction': 0.375, 'grad_norm': 11.790572166442871}
2023-01-03 15:33:09.591 DEBUG: Taking gradient step
2023-01-03 15:33:11.669 DEBUG: Loss 12: {'policy_loss': -0.004606016805363312, 'entropy_loss': -0.05348234251141548, 'vf_loss': 0.014397960762075678, 'total_loss': -0.05808835931677879, 'approx_kl': -0.050532715395092964, 'clip_fraction': 0.4231770858168602, 'grad_norm': 12.363256454467773}
2023-01-03 15:33:13.697 DEBUG: Taking gradient step
2023-01-03 15:33:15.784 DEBUG: Loss 13: {'policy_loss': 0.04299430706209398, 'entropy_loss': -0.05214888881891966, 'vf_loss': 0.015706716512961797, 'total_loss': -0.00915458175682568, 'approx_kl': -0.0801816787570715, 'clip_fraction': 0.3919270858168602, 'grad_norm': 15.165478706359863}
2023-01-03 15:33:17.892 DEBUG: Taking gradient step
2023-01-03 15:33:19.980 DEBUG: Loss 14: {'policy_loss': 0.03718667679299523, 'entropy_loss': -0.05413070600479841, 'vf_loss': 0.014503804045701528, 'total_loss': -0.016944029211803185, 'approx_kl': -0.09587915148586035, 'clip_fraction': 0.43359375, 'grad_norm': 18.721683502197266}
2023-01-03 15:33:19.981 INFO: Optimization: policy loss=0.037, vf loss=0.015, entropy loss=-0.054, total loss=-0.017, num steps=15
2023-01-03 15:33:19.982 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 15:33:21.690 INFO: Evaluation rollout: return=0.458 (0.0), episode length=6.0
2023-01-03 15:33:21.692 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 15:33:21.694 INFO: Iteration: 42/137, steps: 9072
2023-01-03 15:33:34.582 DEBUG: Atoms are too close
2023-01-03 15:33:39.538 DEBUG: Atoms are too close
2023-01-03 15:33:51.780 DEBUG: Atoms are too close
2023-01-03 15:33:57.057 DEBUG: Atoms are too close
2023-01-03 15:34:00.552 DEBUG: Atoms are too close
2023-01-03 15:34:05.062 DEBUG: Atoms are too close
2023-01-03 15:34:12.128 DEBUG: Atoms are too close
2023-01-03 15:34:12.130 DEBUG: Atoms are too close
2023-01-03 15:34:14.608 DEBUG: Atoms are too close
2023-01-03 15:34:16.658 INFO: Training rollout: return=-3.748 (7.3), episode length=5.7
2023-01-03 15:34:16.659 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 15:34:16.663 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-9072_train.pkl
2023-01-03 15:34:18.653 DEBUG: Taking gradient step
2023-01-03 15:34:20.689 DEBUG: Loss 0: {'policy_loss': 0.006284869420386127, 'entropy_loss': -0.05168130807578564, 'vf_loss': 0.02605886278391506, 'total_loss': -0.04539643865539951, 'approx_kl': 3.484698629652172e-08, 'clip_fraction': 0.0, 'grad_norm': 27.29014015197754}
2023-01-03 15:34:22.668 DEBUG: Taking gradient step
2023-01-03 15:34:24.706 DEBUG: Loss 1: {'policy_loss': -0.04705059650570099, 'entropy_loss': -0.051415289752185345, 'vf_loss': 0.0235148923920529, 'total_loss': -0.09846588625788633, 'approx_kl': -0.00427447073161602, 'clip_fraction': 0.01171875, 'grad_norm': 23.221851348876953}
2023-01-03 15:34:26.682 DEBUG: Taking gradient step
2023-01-03 15:34:28.720 DEBUG: Loss 2: {'policy_loss': 0.07381401473865573, 'entropy_loss': -0.05083739757537842, 'vf_loss': 0.0264344823975231, 'total_loss': 0.022976617163277327, 'approx_kl': -0.024094365071505308, 'clip_fraction': 0.2005208358168602, 'grad_norm': 42.38981246948242}
2023-01-03 15:34:30.711 DEBUG: Taking gradient step
2023-01-03 15:34:32.761 DEBUG: Loss 3: {'policy_loss': 0.14934145141987792, 'entropy_loss': -0.05030919145792723, 'vf_loss': 0.027120175609324976, 'total_loss': 0.09903225996195071, 'approx_kl': -0.024389395955950022, 'clip_fraction': 0.26953125, 'grad_norm': 66.06632995605469}
2023-01-03 15:34:34.790 DEBUG: Taking gradient step
2023-01-03 15:34:36.879 DEBUG: Loss 4: {'policy_loss': 0.20299085102913572, 'entropy_loss': -0.05039274599403143, 'vf_loss': 0.028523680118679527, 'total_loss': 0.1525981050351043, 'approx_kl': -0.04513929458335042, 'clip_fraction': 0.2721354179084301, 'grad_norm': 70.15097045898438}
2023-01-03 15:34:38.873 DEBUG: Taking gradient step
2023-01-03 15:34:40.910 DEBUG: Loss 5: {'policy_loss': 0.05730866647805929, 'entropy_loss': -0.05098222382366657, 'vf_loss': 0.025233839822925385, 'total_loss': 0.006326442654392715, 'approx_kl': -0.0445370520465076, 'clip_fraction': 0.26171875, 'grad_norm': 45.87509536743164}
2023-01-03 15:34:42.886 DEBUG: Taking gradient step
2023-01-03 15:34:45.245 DEBUG: Loss 6: {'policy_loss': 0.023313510127924614, 'entropy_loss': -0.05012077372521162, 'vf_loss': 0.024711767592981965, 'total_loss': -0.026807263597287002, 'approx_kl': -0.04705279320478439, 'clip_fraction': 0.1953125, 'grad_norm': 42.10034942626953}
2023-01-03 15:34:47.610 DEBUG: Taking gradient step
2023-01-03 15:34:50.023 DEBUG: Loss 7: {'policy_loss': 0.07607252138990522, 'entropy_loss': -0.05024204310029745, 'vf_loss': 0.026797813337722336, 'total_loss': 0.025830478289607772, 'approx_kl': -0.057944552041590214, 'clip_fraction': 0.21484375, 'grad_norm': 39.05823516845703}
2023-01-03 15:34:52.390 DEBUG: Taking gradient step
2023-01-03 15:34:54.537 DEBUG: Loss 8: {'policy_loss': 0.07643270474919399, 'entropy_loss': -0.04937750566750765, 'vf_loss': 0.02340940616631027, 'total_loss': 0.02705519908168634, 'approx_kl': -0.08548983605578542, 'clip_fraction': 0.28125, 'grad_norm': 62.52647399902344}
2023-01-03 15:34:56.515 DEBUG: Taking gradient step
2023-01-03 15:34:58.560 DEBUG: Loss 9: {'policy_loss': 0.21767293916919397, 'entropy_loss': -0.05219062604010105, 'vf_loss': 0.026800504228040027, 'total_loss': 0.16548231312909292, 'approx_kl': -0.06771713308990002, 'clip_fraction': 0.3229166716337204, 'grad_norm': 73.73358154296875}
2023-01-03 15:35:00.546 DEBUG: Taking gradient step
2023-01-03 15:35:02.665 DEBUG: Loss 10: {'policy_loss': 0.16614310947693214, 'entropy_loss': -0.05088431388139725, 'vf_loss': 0.02554268159951696, 'total_loss': 0.11525879559553491, 'approx_kl': -0.07931192219257355, 'clip_fraction': 0.3841145858168602, 'grad_norm': 85.36389923095703}
2023-01-03 15:35:04.664 DEBUG: Taking gradient step
2023-01-03 15:35:06.689 DEBUG: Loss 11: {'policy_loss': 0.08854212300616869, 'entropy_loss': -0.050949858501553535, 'vf_loss': 0.024808141873463047, 'total_loss': 0.03759226450461516, 'approx_kl': -0.08009696309454739, 'clip_fraction': 0.3776041716337204, 'grad_norm': 58.866424560546875}
2023-01-03 15:35:08.678 DEBUG: Taking gradient step
2023-01-03 15:35:10.968 DEBUG: Loss 12: {'policy_loss': 0.05014199215954712, 'entropy_loss': -0.05132309254258871, 'vf_loss': 0.02547844652211242, 'total_loss': -0.0011811003830415924, 'approx_kl': -0.07510680053383112, 'clip_fraction': 0.359375, 'grad_norm': 51.645389556884766}
2023-01-03 15:35:12.975 DEBUG: Taking gradient step
2023-01-03 15:35:15.023 DEBUG: Loss 13: {'policy_loss': 0.1291309924704992, 'entropy_loss': -0.051213644444942474, 'vf_loss': 0.026746447486286774, 'total_loss': 0.07791734802555673, 'approx_kl': -0.0849988404661417, 'clip_fraction': 0.4075520858168602, 'grad_norm': 59.37598419189453}
2023-01-03 15:35:17.253 DEBUG: Taking gradient step
2023-01-03 15:35:19.677 DEBUG: Loss 14: {'policy_loss': 0.20346396241287704, 'entropy_loss': -0.04884245805442333, 'vf_loss': 0.026116669844119807, 'total_loss': 0.15462150435845368, 'approx_kl': -0.09054637979716063, 'clip_fraction': 0.4427083432674408, 'grad_norm': 98.83707427978516}
2023-01-03 15:35:19.678 INFO: Optimization: policy loss=0.203, vf loss=0.026, entropy loss=-0.049, total loss=0.155, num steps=15
2023-01-03 15:35:19.679 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 15:35:21.390 INFO: Evaluation rollout: return=0.544 (0.0), episode length=6.0
2023-01-03 15:35:21.392 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 15:35:21.395 INFO: Iteration: 43/137, steps: 9288
2023-01-03 15:35:53.945 DEBUG: Atoms are too close
2023-01-03 15:36:08.328 DEBUG: Atoms are too close
2023-01-03 15:36:18.681 INFO: Training rollout: return=-0.543 (3.9), episode length=5.9
2023-01-03 15:36:18.682 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 15:36:18.685 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-9288_train.pkl
2023-01-03 15:36:20.712 DEBUG: Taking gradient step
2023-01-03 15:36:22.786 DEBUG: Loss 0: {'policy_loss': -0.0065608864470433, 'entropy_loss': -0.04864560905843973, 'vf_loss': 0.008569915651383073, 'total_loss': -0.05520649550548303, 'approx_kl': 2.713447122548729e-08, 'clip_fraction': 0.0, 'grad_norm': 8.284042358398438}
2023-01-03 15:36:24.817 DEBUG: Taking gradient step
2023-01-03 15:36:26.888 DEBUG: Loss 1: {'policy_loss': -0.029109630127545437, 'entropy_loss': -0.049657320603728294, 'vf_loss': 0.008706835985797004, 'total_loss': -0.07876695073127374, 'approx_kl': -0.00953750210464932, 'clip_fraction': 0.0625, 'grad_norm': 8.860191345214844}
2023-01-03 15:36:28.926 DEBUG: Taking gradient step
2023-01-03 15:36:31.011 DEBUG: Loss 2: {'policy_loss': 0.05346788091456221, 'entropy_loss': -0.0491448687389493, 'vf_loss': 0.010364869166677584, 'total_loss': 0.004323012175612914, 'approx_kl': -0.025047770235687494, 'clip_fraction': 0.2447916679084301, 'grad_norm': 11.217283248901367}
2023-01-03 15:36:33.048 DEBUG: Taking gradient step
2023-01-03 15:36:35.158 DEBUG: Loss 3: {'policy_loss': -0.025271513905302162, 'entropy_loss': -0.04849300906062126, 'vf_loss': 0.008442379905223448, 'total_loss': -0.07376452296592342, 'approx_kl': -0.03890933794900775, 'clip_fraction': 0.39453125, 'grad_norm': 10.805693626403809}
2023-01-03 15:36:37.223 DEBUG: Taking gradient step
2023-01-03 15:36:39.320 DEBUG: Loss 4: {'policy_loss': 0.012952236444041032, 'entropy_loss': -0.04707505740225315, 'vf_loss': 0.00854846592482937, 'total_loss': -0.03412282095821212, 'approx_kl': -0.0669323937036097, 'clip_fraction': 0.3776041716337204, 'grad_norm': 8.33730411529541}
2023-01-03 15:36:41.369 DEBUG: Taking gradient step
2023-01-03 15:36:43.478 DEBUG: Loss 5: {'policy_loss': 0.038076679110956684, 'entropy_loss': -0.04921889957040548, 'vf_loss': 0.008639186816779124, 'total_loss': -0.0111422204594488, 'approx_kl': -0.04265103954821825, 'clip_fraction': 0.3098958358168602, 'grad_norm': 10.002272605895996}
2023-01-03 15:36:45.531 DEBUG: Taking gradient step
2023-01-03 15:36:47.611 DEBUG: Loss 6: {'policy_loss': 0.014310200906167657, 'entropy_loss': -0.047560976818203926, 'vf_loss': 0.008107883535312553, 'total_loss': -0.033250775912036276, 'approx_kl': -0.034326245076954365, 'clip_fraction': 0.2942708358168602, 'grad_norm': 8.614035606384277}
2023-01-03 15:36:49.638 DEBUG: Taking gradient step
2023-01-03 15:36:51.806 DEBUG: Loss 7: {'policy_loss': 0.01272082787162215, 'entropy_loss': -0.04911668039858341, 'vf_loss': 0.008167058247607054, 'total_loss': -0.03639585252696126, 'approx_kl': -0.05723611207213253, 'clip_fraction': 0.3567708358168602, 'grad_norm': 9.068182945251465}
2023-01-03 15:36:53.831 DEBUG: Taking gradient step
2023-01-03 15:36:55.911 DEBUG: Loss 8: {'policy_loss': -0.03134468081583298, 'entropy_loss': -0.05152591969817877, 'vf_loss': 0.006526026594790585, 'total_loss': -0.08287060051401174, 'approx_kl': -0.05079048918560147, 'clip_fraction': 0.3619791716337204, 'grad_norm': 8.751140594482422}
2023-01-03 15:36:57.960 DEBUG: Taking gradient step
2023-01-03 15:37:00.048 DEBUG: Loss 9: {'policy_loss': -0.022539488345931915, 'entropy_loss': -0.05080013629049063, 'vf_loss': 0.007929885211570866, 'total_loss': -0.07333962463642255, 'approx_kl': -0.02664059493690729, 'clip_fraction': 0.34765625, 'grad_norm': 13.194406509399414}
2023-01-03 15:37:02.097 DEBUG: Taking gradient step
2023-01-03 15:37:04.187 DEBUG: Loss 10: {'policy_loss': -0.02306530945507855, 'entropy_loss': -0.05156440380960703, 'vf_loss': 0.007341222811858086, 'total_loss': -0.07462971326468558, 'approx_kl': -0.0542307598516345, 'clip_fraction': 0.3450520858168602, 'grad_norm': 6.149306297302246}
2023-01-03 15:37:06.228 DEBUG: Taking gradient step
2023-01-03 15:37:08.303 DEBUG: Loss 11: {'policy_loss': -0.023824356971092427, 'entropy_loss': -0.049788317643105984, 'vf_loss': 0.00658308686282006, 'total_loss': -0.0736126746141984, 'approx_kl': -0.07992771128192544, 'clip_fraction': 0.3984375, 'grad_norm': 8.851541519165039}
2023-01-03 15:37:10.315 DEBUG: Taking gradient step
2023-01-03 15:37:12.383 DEBUG: Loss 12: {'policy_loss': 0.03465320219308088, 'entropy_loss': -0.05084132216870785, 'vf_loss': 0.008818070016443066, 'total_loss': -0.01618811997562697, 'approx_kl': -0.07015740964561701, 'clip_fraction': 0.4088541716337204, 'grad_norm': 11.929688453674316}
2023-01-03 15:37:14.411 DEBUG: Taking gradient step
2023-01-03 15:37:16.484 DEBUG: Loss 13: {'policy_loss': -0.01446643155251262, 'entropy_loss': -0.050600526854395866, 'vf_loss': 0.005922923594225937, 'total_loss': -0.06506695840690849, 'approx_kl': -0.05818967125378549, 'clip_fraction': 0.3776041716337204, 'grad_norm': 10.596085548400879}
2023-01-03 15:37:18.517 DEBUG: Taking gradient step
2023-01-03 15:37:20.600 DEBUG: Loss 14: {'policy_loss': -0.01400744695890467, 'entropy_loss': -0.04978851694613695, 'vf_loss': 0.005915401034477127, 'total_loss': -0.06379596390504164, 'approx_kl': -0.04831974674016237, 'clip_fraction': 0.41015625, 'grad_norm': 12.11149787902832}
2023-01-03 15:37:20.600 INFO: Optimization: policy loss=-0.014, vf loss=0.006, entropy loss=-0.050, total loss=-0.064, num steps=15
2023-01-03 15:37:20.602 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 15:37:22.280 INFO: Evaluation rollout: return=0.405 (0.0), episode length=6.0
2023-01-03 15:37:22.281 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 15:37:22.284 INFO: Iteration: 44/137, steps: 9504
2023-01-03 15:37:34.658 DEBUG: Atoms are too close
2023-01-03 15:37:52.326 DEBUG: Atoms are too close
2023-01-03 15:37:54.395 DEBUG: Atoms are too close
2023-01-03 15:37:56.445 DEBUG: Atoms are too close
2023-01-03 15:38:10.294 DEBUG: Atoms are too close
2023-01-03 15:38:17.587 INFO: Training rollout: return=-3.101 (6.4), episode length=5.8
2023-01-03 15:38:17.589 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 15:38:17.591 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-9504_train.pkl
2023-01-03 15:38:19.617 DEBUG: Taking gradient step
2023-01-03 15:38:21.701 DEBUG: Loss 0: {'policy_loss': 0.028914962197963513, 'entropy_loss': -0.04812116641551256, 'vf_loss': 0.02944424569375505, 'total_loss': -0.019206204217549053, 'approx_kl': -4.410200443727419e-08, 'clip_fraction': 0.0, 'grad_norm': 18.085874557495117}
2023-01-03 15:38:23.712 DEBUG: Taking gradient step
2023-01-03 15:38:25.772 DEBUG: Loss 1: {'policy_loss': 0.007459073737821268, 'entropy_loss': -0.04884261917322874, 'vf_loss': 0.02883470478684906, 'total_loss': -0.04138354543540747, 'approx_kl': -0.010299122426658869, 'clip_fraction': 0.02864583395421505, 'grad_norm': 14.104325294494629}
2023-01-03 15:38:27.780 DEBUG: Taking gradient step
2023-01-03 15:38:29.848 DEBUG: Loss 2: {'policy_loss': 0.054380008945390176, 'entropy_loss': -0.048018607310950756, 'vf_loss': 0.03151483190719548, 'total_loss': 0.006361401634439406, 'approx_kl': -0.022212779469555244, 'clip_fraction': 0.2408854179084301, 'grad_norm': 10.576199531555176}
2023-01-03 15:38:31.855 DEBUG: Taking gradient step
2023-01-03 15:38:33.913 DEBUG: Loss 3: {'policy_loss': -0.02459055083372136, 'entropy_loss': -0.04869292303919792, 'vf_loss': 0.02620505427049402, 'total_loss': -0.07328347387291928, 'approx_kl': -0.03004278987646103, 'clip_fraction': 0.3854166716337204, 'grad_norm': 12.620038986206055}
2023-01-03 15:38:35.929 DEBUG: Taking gradient step
2023-01-03 15:38:37.996 DEBUG: Loss 4: {'policy_loss': -0.029335062214202397, 'entropy_loss': -0.04887974914163351, 'vf_loss': 0.0252223434224236, 'total_loss': -0.07821481135583591, 'approx_kl': -0.04372648801654577, 'clip_fraction': 0.4244791716337204, 'grad_norm': 8.643513679504395}
2023-01-03 15:38:40.007 DEBUG: Taking gradient step
2023-01-03 15:38:42.157 DEBUG: Loss 5: {'policy_loss': -0.0659433173578545, 'entropy_loss': -0.04808713402599096, 'vf_loss': 0.023970841929211856, 'total_loss': -0.11403045138384546, 'approx_kl': -0.05189405684359372, 'clip_fraction': 0.3606770858168602, 'grad_norm': 7.719466686248779}
2023-01-03 15:38:44.150 DEBUG: Taking gradient step
2023-01-03 15:38:46.221 DEBUG: Loss 6: {'policy_loss': -0.03013094856163395, 'entropy_loss': -0.04788718931376934, 'vf_loss': 0.026301652848902752, 'total_loss': -0.07801813787540329, 'approx_kl': -0.05912978574633598, 'clip_fraction': 0.3828125, 'grad_norm': 7.410900115966797}
2023-01-03 15:38:48.239 DEBUG: Taking gradient step
2023-01-03 15:38:50.534 DEBUG: Loss 7: {'policy_loss': -0.05573971576837231, 'entropy_loss': -0.048671222291886806, 'vf_loss': 0.02461158603105269, 'total_loss': -0.10441093806025911, 'approx_kl': -0.04940365697257221, 'clip_fraction': 0.3229166716337204, 'grad_norm': 6.616162300109863}
2023-01-03 15:38:52.625 DEBUG: Taking gradient step
2023-01-03 15:38:54.695 DEBUG: Loss 8: {'policy_loss': -0.026151244621766816, 'entropy_loss': -0.05033347196877003, 'vf_loss': 0.027172227542518614, 'total_loss': -0.07648471659053684, 'approx_kl': -0.043568669963860884, 'clip_fraction': 0.30078125, 'grad_norm': 13.790995597839355}
2023-01-03 15:38:56.712 DEBUG: Taking gradient step
2023-01-03 15:38:58.770 DEBUG: Loss 9: {'policy_loss': -0.0738621342216334, 'entropy_loss': -0.04962435457855463, 'vf_loss': 0.023289773081874354, 'total_loss': -0.12348648880018803, 'approx_kl': -0.0636638158466667, 'clip_fraction': 0.3815104216337204, 'grad_norm': 8.444695472717285}
2023-01-03 15:39:00.789 DEBUG: Taking gradient step
2023-01-03 15:39:02.854 DEBUG: Loss 10: {'policy_loss': -0.06116059508406957, 'entropy_loss': -0.0493791438639164, 'vf_loss': 0.023229619625517124, 'total_loss': -0.11053973894798597, 'approx_kl': -0.07102840766310692, 'clip_fraction': 0.3841145858168602, 'grad_norm': 12.552103042602539}
2023-01-03 15:39:04.882 DEBUG: Taking gradient step
2023-01-03 15:39:06.949 DEBUG: Loss 11: {'policy_loss': -0.04818031563236236, 'entropy_loss': -0.050150008872151375, 'vf_loss': 0.024141400615046438, 'total_loss': -0.09833032450451372, 'approx_kl': -0.06401669405749999, 'clip_fraction': 0.3515625, 'grad_norm': 11.021337509155273}
2023-01-03 15:39:08.971 DEBUG: Taking gradient step
2023-01-03 15:39:11.044 DEBUG: Loss 12: {'policy_loss': 0.027521275957223777, 'entropy_loss': -0.05079848226159811, 'vf_loss': 0.026902222963705605, 'total_loss': -0.023277206304374333, 'approx_kl': -0.0749598816037178, 'clip_fraction': 0.4440104216337204, 'grad_norm': 12.257936477661133}
2023-01-03 15:39:13.088 DEBUG: Taking gradient step
2023-01-03 15:39:15.181 DEBUG: Loss 13: {'policy_loss': 0.04509580015944607, 'entropy_loss': -0.05143288988620043, 'vf_loss': 0.025663005219759873, 'total_loss': -0.006337089726754355, 'approx_kl': -0.07401545532047749, 'clip_fraction': 0.4557291716337204, 'grad_norm': 14.259719848632812}
2023-01-03 15:39:17.186 DEBUG: Taking gradient step
2023-01-03 15:39:19.237 DEBUG: Loss 14: {'policy_loss': 0.01886043626748972, 'entropy_loss': -0.0512379826977849, 'vf_loss': 0.024861712711250157, 'total_loss': -0.03237754643029518, 'approx_kl': -0.06014780141413212, 'clip_fraction': 0.4973958358168602, 'grad_norm': 16.313472747802734}
2023-01-03 15:39:19.238 INFO: Optimization: policy loss=0.019, vf loss=0.025, entropy loss=-0.051, total loss=-0.032, num steps=15
2023-01-03 15:39:19.239 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 15:39:20.946 INFO: Evaluation rollout: return=0.446 (0.0), episode length=6.0
2023-01-03 15:39:20.947 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 15:39:20.950 INFO: Iteration: 45/137, steps: 9720
2023-01-03 15:39:30.518 DEBUG: Atoms are too close
2023-01-03 15:39:31.642 DEBUG: Atoms are too close
2023-01-03 15:39:32.228 DEBUG: Atoms are too close
2023-01-03 15:39:33.604 DEBUG: Atoms are too close
2023-01-03 15:39:34.634 DEBUG: Atoms are too close
2023-01-03 15:39:47.704 DEBUG: Atoms are too close
2023-01-03 15:39:54.202 DEBUG: Atoms are too close
2023-01-03 15:40:07.298 DEBUG: Atoms are too close
2023-01-03 15:40:11.375 DEBUG: Atoms are too close
2023-01-03 15:40:13.497 DEBUG: Atoms are too close
2023-01-03 15:40:15.108 INFO: Training rollout: return=-4.065 (7.3), episode length=5.7
2023-01-03 15:40:15.109 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 15:40:15.113 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-9720_train.pkl
2023-01-03 15:40:17.089 DEBUG: Taking gradient step
2023-01-03 15:40:19.114 DEBUG: Loss 0: {'policy_loss': 0.0019133581073990102, 'entropy_loss': -0.0498528853058815, 'vf_loss': 0.02801850557180897, 'total_loss': -0.04793952719848249, 'approx_kl': -6.752088665962219e-09, 'clip_fraction': 0.0, 'grad_norm': 19.133888244628906}
2023-01-03 15:40:21.079 DEBUG: Taking gradient step
2023-01-03 15:40:23.101 DEBUG: Loss 1: {'policy_loss': 0.02665174417625648, 'entropy_loss': -0.05180323030799627, 'vf_loss': 0.02993294526400744, 'total_loss': -0.025151486131739793, 'approx_kl': -0.018673320882953703, 'clip_fraction': 0.14583333395421505, 'grad_norm': 12.004846572875977}
2023-01-03 15:40:25.068 DEBUG: Taking gradient step
2023-01-03 15:40:27.086 DEBUG: Loss 2: {'policy_loss': -0.03681663136033052, 'entropy_loss': -0.04962289519608021, 'vf_loss': 0.02698464670875305, 'total_loss': -0.08643952655641073, 'approx_kl': -0.04414877388626337, 'clip_fraction': 0.3541666716337204, 'grad_norm': 18.74934196472168}
2023-01-03 15:40:29.135 DEBUG: Taking gradient step
2023-01-03 15:40:31.153 DEBUG: Loss 3: {'policy_loss': -0.007343769210958627, 'entropy_loss': -0.05170358903706074, 'vf_loss': 0.027891978016832245, 'total_loss': -0.05904735824801936, 'approx_kl': -0.03904791595414281, 'clip_fraction': 0.3932291716337204, 'grad_norm': 17.081180572509766}
2023-01-03 15:40:33.139 DEBUG: Taking gradient step
2023-01-03 15:40:35.161 DEBUG: Loss 4: {'policy_loss': 0.04556216096828489, 'entropy_loss': -0.04983477294445038, 'vf_loss': 0.028916040493094704, 'total_loss': -0.004272611976165491, 'approx_kl': -0.04947633808478713, 'clip_fraction': 0.3697916716337204, 'grad_norm': 16.72530746459961}
2023-01-03 15:40:37.115 DEBUG: Taking gradient step
2023-01-03 15:40:39.128 DEBUG: Loss 5: {'policy_loss': -0.026801981764870465, 'entropy_loss': -0.04815033636987209, 'vf_loss': 0.02592526034604574, 'total_loss': -0.07495231813474257, 'approx_kl': -0.07509514410048723, 'clip_fraction': 0.35546875, 'grad_norm': 19.77171516418457}
2023-01-03 15:40:41.091 DEBUG: Taking gradient step
2023-01-03 15:40:43.098 DEBUG: Loss 6: {'policy_loss': -0.029300396872266873, 'entropy_loss': -0.050010151229798794, 'vf_loss': 0.026357846714733298, 'total_loss': -0.07931054810206567, 'approx_kl': -0.06547391414642334, 'clip_fraction': 0.3932291716337204, 'grad_norm': 19.163330078125}
2023-01-03 15:40:45.083 DEBUG: Taking gradient step
2023-01-03 15:40:47.104 DEBUG: Loss 7: {'policy_loss': -0.018774043773608078, 'entropy_loss': -0.047856914810836315, 'vf_loss': 0.025759565364638443, 'total_loss': -0.0666309585844444, 'approx_kl': -0.08725017309188843, 'clip_fraction': 0.4010416716337204, 'grad_norm': 23.15178108215332}
2023-01-03 15:40:49.067 DEBUG: Taking gradient step
2023-01-03 15:40:51.086 DEBUG: Loss 8: {'policy_loss': -0.06358864979135337, 'entropy_loss': -0.04850694816559553, 'vf_loss': 0.023934575101832462, 'total_loss': -0.1120955979569489, 'approx_kl': -0.11131655424833298, 'clip_fraction': 0.421875, 'grad_norm': 21.545499801635742}
2023-01-03 15:40:53.079 DEBUG: Taking gradient step
2023-01-03 15:40:55.119 DEBUG: Loss 9: {'policy_loss': -0.015197487855090286, 'entropy_loss': -0.04912553075700998, 'vf_loss': 0.02646932381475752, 'total_loss': -0.06432301861210027, 'approx_kl': -0.10999441333115101, 'clip_fraction': 0.46875, 'grad_norm': 15.352254867553711}
2023-01-03 15:40:57.115 DEBUG: Taking gradient step
2023-01-03 15:40:59.174 DEBUG: Loss 10: {'policy_loss': 0.014296287525379106, 'entropy_loss': -0.04793732147663832, 'vf_loss': 0.026255083103115834, 'total_loss': -0.03364103395125921, 'approx_kl': -0.10001105163246393, 'clip_fraction': 0.51171875, 'grad_norm': 13.44323444366455}
2023-01-03 15:41:01.161 DEBUG: Taking gradient step
2023-01-03 15:41:03.190 DEBUG: Loss 11: {'policy_loss': 0.017414788523205924, 'entropy_loss': -0.049341288395226, 'vf_loss': 0.026607192138281714, 'total_loss': -0.03192649987202008, 'approx_kl': -0.11950727459043264, 'clip_fraction': 0.4739583432674408, 'grad_norm': 24.593969345092773}
2023-01-03 15:41:05.175 DEBUG: Taking gradient step
2023-01-03 15:41:07.210 DEBUG: Loss 12: {'policy_loss': 0.09804045944103117, 'entropy_loss': -0.04936997313052416, 'vf_loss': 0.027883034998169767, 'total_loss': 0.04867048631050701, 'approx_kl': -0.1048793364316225, 'clip_fraction': 0.453125, 'grad_norm': 27.688020706176758}
2023-01-03 15:41:09.198 DEBUG: Taking gradient step
2023-01-03 15:41:11.228 DEBUG: Loss 13: {'policy_loss': 0.08630463331339262, 'entropy_loss': -0.04701490607112646, 'vf_loss': 0.026851413588189554, 'total_loss': 0.039289727242266155, 'approx_kl': -0.1211583036929369, 'clip_fraction': 0.4674479216337204, 'grad_norm': 35.779335021972656}
2023-01-03 15:41:13.212 DEBUG: Taking gradient step
2023-01-03 15:41:15.259 DEBUG: Loss 14: {'policy_loss': 0.10325594907434618, 'entropy_loss': -0.04606850445270538, 'vf_loss': 0.02724057173757504, 'total_loss': 0.0571874446216408, 'approx_kl': -0.1232827939093113, 'clip_fraction': 0.3997395858168602, 'grad_norm': 26.094738006591797}
2023-01-03 15:41:15.260 INFO: Optimization: policy loss=0.103, vf loss=0.027, entropy loss=-0.046, total loss=0.057, num steps=15
2023-01-03 15:41:15.261 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 15:41:17.001 INFO: Evaluation rollout: return=0.428 (0.0), episode length=6.0
2023-01-03 15:41:17.002 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 15:41:17.006 INFO: Iteration: 46/137, steps: 9936
2023-01-03 15:41:27.942 DEBUG: Atoms are too close
2023-01-03 15:41:27.943 DEBUG: Atoms are too close
2023-01-03 15:41:30.360 DEBUG: Atoms are too close
2023-01-03 15:41:31.222 DEBUG: Atoms are too close
2023-01-03 15:41:31.501 DEBUG: There is a single atom floating around
2023-01-03 15:41:32.428 DEBUG: Atoms are too close
2023-01-03 15:41:41.314 DEBUG: Atoms are too close
2023-01-03 15:41:42.170 DEBUG: Atoms are too close
2023-01-03 15:41:43.964 DEBUG: Atoms are too close
2023-01-03 15:41:46.242 DEBUG: Atoms are too close
2023-01-03 15:41:46.320 DEBUG: Atoms are too close
2023-01-03 15:41:46.743 DEBUG: Atoms are too close
2023-01-03 15:42:00.492 DEBUG: Atoms are too close
2023-01-03 15:42:02.733 DEBUG: Atoms are too close
2023-01-03 15:42:03.312 DEBUG: Atoms are too close
2023-01-03 15:42:06.366 DEBUG: Atoms are too close
2023-01-03 15:42:09.303 DEBUG: Atoms are too close
2023-01-03 15:42:09.664 INFO: Training rollout: return=-7.306 (8.3), episode length=5.4
2023-01-03 15:42:09.666 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 15:42:09.668 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-9936_train.pkl
2023-01-03 15:42:11.652 DEBUG: Taking gradient step
2023-01-03 15:42:13.677 DEBUG: Loss 0: {'policy_loss': -0.035208986420022875, 'entropy_loss': -0.04649032838642597, 'vf_loss': 0.03892135951407074, 'total_loss': -0.08169931480644885, 'approx_kl': -5.364807265095806e-09, 'clip_fraction': 0.0, 'grad_norm': 22.190397262573242}
2023-01-03 15:42:15.644 DEBUG: Taking gradient step
2023-01-03 15:42:17.680 DEBUG: Loss 1: {'policy_loss': -0.02228215195269287, 'entropy_loss': -0.04587790463119745, 'vf_loss': 0.03774963861338384, 'total_loss': -0.06816005658389032, 'approx_kl': 0.003180238767527044, 'clip_fraction': 0.06380208395421505, 'grad_norm': 17.448619842529297}
2023-01-03 15:42:19.635 DEBUG: Taking gradient step
2023-01-03 15:42:21.689 DEBUG: Loss 2: {'policy_loss': 0.030968464333731547, 'entropy_loss': -0.04576277267187834, 'vf_loss': 0.03981406889000387, 'total_loss': -0.014794308338146794, 'approx_kl': -0.024531466886401176, 'clip_fraction': 0.15625, 'grad_norm': 29.35828399658203}
2023-01-03 15:42:23.645 DEBUG: Taking gradient step
2023-01-03 15:42:25.644 DEBUG: Loss 3: {'policy_loss': 0.03196931501705514, 'entropy_loss': -0.04587186686694622, 'vf_loss': 0.03812594729488405, 'total_loss': -0.013902551849891075, 'approx_kl': -0.030164037365466356, 'clip_fraction': 0.23046875, 'grad_norm': 34.006813049316406}
2023-01-03 15:42:27.581 DEBUG: Taking gradient step
2023-01-03 15:42:29.568 DEBUG: Loss 4: {'policy_loss': 0.07844468723424808, 'entropy_loss': -0.04458148777484894, 'vf_loss': 0.036937670130146386, 'total_loss': 0.03386319945939914, 'approx_kl': -0.040005884133279324, 'clip_fraction': 0.3932291716337204, 'grad_norm': 34.564334869384766}
2023-01-03 15:42:31.505 DEBUG: Taking gradient step
2023-01-03 15:42:33.493 DEBUG: Loss 5: {'policy_loss': 0.07074574586922133, 'entropy_loss': -0.04602528549730778, 'vf_loss': 0.03408056170774899, 'total_loss': 0.02472046037191356, 'approx_kl': -0.05083058471791446, 'clip_fraction': 0.3723958358168602, 'grad_norm': 37.96221160888672}
2023-01-03 15:42:35.439 DEBUG: Taking gradient step
2023-01-03 15:42:37.426 DEBUG: Loss 6: {'policy_loss': 0.020938934738118947, 'entropy_loss': -0.04554742854088545, 'vf_loss': 0.034234712106659154, 'total_loss': -0.0246084938027665, 'approx_kl': -0.020919046830385923, 'clip_fraction': 0.39453125, 'grad_norm': 22.04763412475586}
2023-01-03 15:42:39.373 DEBUG: Taking gradient step
2023-01-03 15:42:41.370 DEBUG: Loss 7: {'policy_loss': 0.044260863837369706, 'entropy_loss': -0.04565980285406113, 'vf_loss': 0.03392209432279462, 'total_loss': -0.0013989390166914278, 'approx_kl': -0.02499528939370066, 'clip_fraction': 0.38671875, 'grad_norm': 18.95797348022461}
2023-01-03 15:42:43.289 DEBUG: Taking gradient step
2023-01-03 15:42:45.278 DEBUG: Loss 8: {'policy_loss': 0.0082685554196983, 'entropy_loss': -0.04684989992529154, 'vf_loss': 0.03450146500045362, 'total_loss': -0.03858134450559324, 'approx_kl': -0.014328458812087774, 'clip_fraction': 0.3736979216337204, 'grad_norm': 24.141733169555664}
2023-01-03 15:42:47.194 DEBUG: Taking gradient step
2023-01-03 15:42:49.159 DEBUG: Loss 9: {'policy_loss': 0.1345176752118018, 'entropy_loss': -0.045449952594935894, 'vf_loss': 0.03767724002590521, 'total_loss': 0.08906772261686592, 'approx_kl': -0.045085380552336574, 'clip_fraction': 0.3658854216337204, 'grad_norm': 37.69907760620117}
2023-01-03 15:42:51.080 DEBUG: Taking gradient step
2023-01-03 15:42:53.051 DEBUG: Loss 10: {'policy_loss': 0.031395107367331594, 'entropy_loss': -0.04519840329885483, 'vf_loss': 0.03588401316442821, 'total_loss': -0.013803295931523237, 'approx_kl': -0.027014683466404676, 'clip_fraction': 0.28515625, 'grad_norm': 22.05008316040039}
2023-01-03 15:42:54.968 DEBUG: Taking gradient step
2023-01-03 15:42:57.027 DEBUG: Loss 11: {'policy_loss': 0.06658343311911544, 'entropy_loss': -0.043862554244697094, 'vf_loss': 0.03331152345193034, 'total_loss': 0.022720878874418343, 'approx_kl': -0.03804805316030979, 'clip_fraction': 0.3567708358168602, 'grad_norm': 27.45528793334961}
2023-01-03 15:42:58.934 DEBUG: Taking gradient step
2023-01-03 15:43:00.907 DEBUG: Loss 12: {'policy_loss': -0.000290788471365086, 'entropy_loss': -0.04453407507389784, 'vf_loss': 0.0333021754955912, 'total_loss': -0.044824863545262925, 'approx_kl': -0.004999722354114056, 'clip_fraction': 0.4752604216337204, 'grad_norm': 19.187681198120117}
2023-01-03 15:43:02.823 DEBUG: Taking gradient step
2023-01-03 15:43:04.800 DEBUG: Loss 13: {'policy_loss': 0.05752821495637951, 'entropy_loss': -0.04580647312104702, 'vf_loss': 0.03309426491224254, 'total_loss': 0.011721741835332488, 'approx_kl': 0.005396212916821241, 'clip_fraction': 0.484375, 'grad_norm': 24.66486358642578}
2023-01-03 15:43:06.720 DEBUG: Taking gradient step
2023-01-03 15:43:08.692 DEBUG: Loss 14: {'policy_loss': 0.04726736653635851, 'entropy_loss': -0.046019308269023895, 'vf_loss': 0.031705055941910254, 'total_loss': 0.0012480582673346091, 'approx_kl': 0.010531819891184568, 'clip_fraction': 0.4739583358168602, 'grad_norm': 20.368078231811523}
2023-01-03 15:43:08.693 INFO: Optimization: policy loss=0.047, vf loss=0.032, entropy loss=-0.046, total loss=0.001, num steps=15
2023-01-03 15:43:08.694 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 15:43:10.421 INFO: Evaluation rollout: return=0.394 (0.0), episode length=6.0
2023-01-03 15:43:10.423 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 15:43:10.426 INFO: Iteration: 47/137, steps: 10152
2023-01-03 15:43:19.128 DEBUG: Atoms are too close
2023-01-03 15:43:27.762 DEBUG: Atoms are too close
2023-01-03 15:43:37.100 DEBUG: Atoms are too close
2023-01-03 15:43:37.703 DEBUG: Atoms are too close
2023-01-03 15:43:46.963 DEBUG: Atoms are too close
2023-01-03 15:43:50.124 DEBUG: Atoms are too close
2023-01-03 15:44:03.501 DEBUG: Atoms are too close
2023-01-03 15:44:05.910 DEBUG: Atoms are too close
2023-01-03 15:44:06.689 INFO: Training rollout: return=-3.409 (7.3), episode length=5.7
2023-01-03 15:44:06.691 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 15:44:06.695 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-10152_train.pkl
2023-01-03 15:44:08.713 DEBUG: Taking gradient step
2023-01-03 15:44:10.755 DEBUG: Loss 0: {'policy_loss': -0.007812805271327258, 'entropy_loss': -0.04784311447292566, 'vf_loss': 0.02539019794339246, 'total_loss': -0.05565591974425292, 'approx_kl': -3.880510757170441e-08, 'clip_fraction': 0.0, 'grad_norm': 27.896345138549805}
2023-01-03 15:44:12.752 DEBUG: Taking gradient step
2023-01-03 15:44:14.820 DEBUG: Loss 1: {'policy_loss': 0.029988183164205075, 'entropy_loss': -0.04947851970791817, 'vf_loss': 0.023860451536488716, 'total_loss': -0.0194903365437131, 'approx_kl': -0.010554492066148669, 'clip_fraction': 0.061197916977107525, 'grad_norm': 17.83349609375}
2023-01-03 15:44:16.808 DEBUG: Taking gradient step
2023-01-03 15:44:18.857 DEBUG: Loss 2: {'policy_loss': -0.0539843869576431, 'entropy_loss': -0.04822433926165104, 'vf_loss': 0.024255542725096894, 'total_loss': -0.10220872621929414, 'approx_kl': -0.02669481188058853, 'clip_fraction': 0.3736979216337204, 'grad_norm': 10.406551361083984}
2023-01-03 15:44:20.855 DEBUG: Taking gradient step
2023-01-03 15:44:22.910 DEBUG: Loss 3: {'policy_loss': -0.019386869324007242, 'entropy_loss': -0.04841415956616402, 'vf_loss': 0.024868352147118945, 'total_loss': -0.06780102889017126, 'approx_kl': -0.029901182278990746, 'clip_fraction': 0.4869791716337204, 'grad_norm': 12.359358787536621}
2023-01-03 15:44:24.905 DEBUG: Taking gradient step
2023-01-03 15:44:26.944 DEBUG: Loss 4: {'policy_loss': -0.023042247753844267, 'entropy_loss': -0.0484813554212451, 'vf_loss': 0.022927788572161108, 'total_loss': -0.07152360317508936, 'approx_kl': -0.02406397368758917, 'clip_fraction': 0.4713541716337204, 'grad_norm': 13.055508613586426}
2023-01-03 15:44:28.935 DEBUG: Taking gradient step
2023-01-03 15:44:31.004 DEBUG: Loss 5: {'policy_loss': -0.0993324302809779, 'entropy_loss': -0.04878230765461922, 'vf_loss': 0.02053479645504303, 'total_loss': -0.1481147379355971, 'approx_kl': -0.024479566141963005, 'clip_fraction': 0.578125, 'grad_norm': 10.02528190612793}
2023-01-03 15:44:32.994 DEBUG: Taking gradient step
2023-01-03 15:44:35.026 DEBUG: Loss 6: {'policy_loss': -0.04637691186363026, 'entropy_loss': -0.048849742859601974, 'vf_loss': 0.01994985386789938, 'total_loss': -0.09522665472323223, 'approx_kl': -0.018071556463837624, 'clip_fraction': 0.5221354216337204, 'grad_norm': 5.636775493621826}
2023-01-03 15:44:37.009 DEBUG: Taking gradient step
2023-01-03 15:44:39.062 DEBUG: Loss 7: {'policy_loss': -0.06589998440648742, 'entropy_loss': -0.0486516198143363, 'vf_loss': 0.019199181612453795, 'total_loss': -0.11455160422082372, 'approx_kl': 0.034604658372700214, 'clip_fraction': 0.5, 'grad_norm': 4.256412506103516}
2023-01-03 15:44:41.058 DEBUG: Taking gradient step
2023-01-03 15:44:43.106 DEBUG: Loss 8: {'policy_loss': -0.03291293153629193, 'entropy_loss': -0.048453330993652344, 'vf_loss': 0.02001620190070562, 'total_loss': -0.08136626252994426, 'approx_kl': 0.020343869924545288, 'clip_fraction': 0.5, 'grad_norm': 8.97281551361084}
2023-01-03 15:44:45.183 DEBUG: Taking gradient step
2023-01-03 15:44:47.217 DEBUG: Loss 9: {'policy_loss': -0.027268372399269145, 'entropy_loss': -0.04942272510379553, 'vf_loss': 0.0193592208011747, 'total_loss': -0.07669109750306466, 'approx_kl': 0.02381111355498433, 'clip_fraction': 0.6263020932674408, 'grad_norm': 11.901732444763184}
2023-01-03 15:44:49.202 DEBUG: Early stopping at step 10 for reaching max KL.
2023-01-03 15:44:49.202 INFO: Optimization: policy loss=-0.027, vf loss=0.019, entropy loss=-0.049, total loss=-0.077, num steps=10
2023-01-03 15:44:49.203 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 15:44:50.952 INFO: Evaluation rollout: return=0.346 (0.0), episode length=6.0
2023-01-03 15:44:50.953 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 15:44:50.956 INFO: Iteration: 48/137, steps: 10368
2023-01-03 15:44:57.537 DEBUG: Atoms are too close
2023-01-03 15:44:59.276 DEBUG: Atoms are too close
2023-01-03 15:45:12.842 DEBUG: Atoms are too close
2023-01-03 15:45:14.917 DEBUG: Atoms are too close
2023-01-03 15:45:16.192 DEBUG: Atoms are too close
2023-01-03 15:45:18.411 DEBUG: Atoms are too close
2023-01-03 15:45:18.696 DEBUG: Atoms are too close
2023-01-03 15:45:19.117 DEBUG: Atoms are too close
2023-01-03 15:45:24.348 DEBUG: Atoms are too close
2023-01-03 15:45:30.486 DEBUG: Atoms are too close
2023-01-03 15:45:36.065 DEBUG: Atoms are too close
2023-01-03 15:45:37.908 DEBUG: Atoms are too close
2023-01-03 15:45:44.509 INFO: Training rollout: return=-5.956 (9.1), episode length=5.3
2023-01-03 15:45:44.511 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 15:45:44.514 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-10368_train.pkl
2023-01-03 15:45:46.445 DEBUG: Taking gradient step
2023-01-03 15:45:48.400 DEBUG: Loss 0: {'policy_loss': 0.03403167044111423, 'entropy_loss': -0.04676646552979946, 'vf_loss': 0.028229898250657758, 'total_loss': -0.012734795088685233, 'approx_kl': 1.0337680578231812e-07, 'clip_fraction': 0.0, 'grad_norm': 27.44918441772461}
2023-01-03 15:45:50.316 DEBUG: Taking gradient step
2023-01-03 15:45:52.284 DEBUG: Loss 1: {'policy_loss': -0.005496969234735102, 'entropy_loss': -0.045875479467213154, 'vf_loss': 0.027345251643450218, 'total_loss': -0.05137244870194826, 'approx_kl': 0.007369648665189743, 'clip_fraction': 0.1328125, 'grad_norm': 30.2794132232666}
2023-01-03 15:45:54.200 DEBUG: Taking gradient step
2023-01-03 15:45:56.155 DEBUG: Loss 2: {'policy_loss': 0.02563941090358424, 'entropy_loss': -0.04627066757529974, 'vf_loss': 0.029639395937996492, 'total_loss': -0.020631256671715503, 'approx_kl': 0.006865910021588206, 'clip_fraction': 0.3203125, 'grad_norm': 22.051586151123047}
2023-01-03 15:45:58.084 DEBUG: Taking gradient step
2023-01-03 15:46:00.080 DEBUG: Loss 3: {'policy_loss': 0.004572869063099845, 'entropy_loss': -0.04608084727078676, 'vf_loss': 0.027832957071929353, 'total_loss': -0.041507978207686924, 'approx_kl': -0.006843334995210171, 'clip_fraction': 0.3203125, 'grad_norm': 28.27284812927246}
2023-01-03 15:46:02.001 DEBUG: Taking gradient step
2023-01-03 15:46:04.025 DEBUG: Loss 4: {'policy_loss': 0.029638992035532434, 'entropy_loss': -0.04441320151090622, 'vf_loss': 0.028546217441381482, 'total_loss': -0.014774209475373787, 'approx_kl': -0.013953915797173977, 'clip_fraction': 0.3450520858168602, 'grad_norm': 24.321821212768555}
2023-01-03 15:46:06.004 DEBUG: Taking gradient step
2023-01-03 15:46:07.980 DEBUG: Loss 5: {'policy_loss': 0.018002717147812063, 'entropy_loss': -0.04343112278729677, 'vf_loss': 0.02713198475003198, 'total_loss': -0.02542840563948471, 'approx_kl': -0.03943380294367671, 'clip_fraction': 0.3346354216337204, 'grad_norm': 26.299175262451172}
2023-01-03 15:46:09.922 DEBUG: Taking gradient step
2023-01-03 15:46:11.914 DEBUG: Loss 6: {'policy_loss': 0.07004000431023347, 'entropy_loss': -0.04527950473129749, 'vf_loss': 0.028999587999431947, 'total_loss': 0.02476049957893598, 'approx_kl': -0.03585878782905638, 'clip_fraction': 0.3671875, 'grad_norm': 29.62607765197754}
2023-01-03 15:46:13.830 DEBUG: Taking gradient step
2023-01-03 15:46:15.817 DEBUG: Loss 7: {'policy_loss': 0.03833673979144437, 'entropy_loss': -0.044217013753950596, 'vf_loss': 0.02768677248534739, 'total_loss': -0.005880273962506226, 'approx_kl': -0.05456371046602726, 'clip_fraction': 0.33203125, 'grad_norm': 28.59086036682129}
2023-01-03 15:46:17.740 DEBUG: Taking gradient step
2023-01-03 15:46:19.705 DEBUG: Loss 8: {'policy_loss': 0.0415027285074284, 'entropy_loss': -0.04503351915627718, 'vf_loss': 0.028470855602750325, 'total_loss': -0.003530790648848779, 'approx_kl': -0.05831516906619072, 'clip_fraction': 0.3177083358168602, 'grad_norm': 29.46118927001953}
2023-01-03 15:46:21.628 DEBUG: Taking gradient step
2023-01-03 15:46:23.664 DEBUG: Loss 9: {'policy_loss': 0.04651801909411423, 'entropy_loss': -0.04425040818750858, 'vf_loss': 0.028794012520186076, 'total_loss': 0.002267610906605648, 'approx_kl': -0.05033962521702051, 'clip_fraction': 0.3502604216337204, 'grad_norm': 21.257732391357422}
2023-01-03 15:46:25.652 DEBUG: Taking gradient step
2023-01-03 15:46:27.714 DEBUG: Loss 10: {'policy_loss': 0.09426434859694888, 'entropy_loss': -0.044779540970921516, 'vf_loss': 0.029439426559908145, 'total_loss': 0.04948480762602736, 'approx_kl': -0.07073346339166164, 'clip_fraction': 0.4127604216337204, 'grad_norm': 23.51866340637207}
2023-01-03 15:46:29.620 DEBUG: Taking gradient step
2023-01-03 15:46:31.585 DEBUG: Loss 11: {'policy_loss': -0.030290430033601518, 'entropy_loss': -0.04510999005287886, 'vf_loss': 0.02457718277580742, 'total_loss': -0.07540042008648037, 'approx_kl': -0.059638962149620056, 'clip_fraction': 0.3971354216337204, 'grad_norm': 21.973777770996094}
2023-01-03 15:46:33.494 DEBUG: Taking gradient step
2023-01-03 15:46:35.461 DEBUG: Loss 12: {'policy_loss': 0.07021091980854964, 'entropy_loss': -0.044881973415613174, 'vf_loss': 0.027871889055753312, 'total_loss': 0.025328946392936466, 'approx_kl': -0.09058204619213939, 'clip_fraction': 0.3828125, 'grad_norm': 23.34208106994629}
2023-01-03 15:46:37.357 DEBUG: Taking gradient step
2023-01-03 15:46:39.329 DEBUG: Loss 13: {'policy_loss': -0.0019657954515513824, 'entropy_loss': -0.04450976103544235, 'vf_loss': 0.024472742859655568, 'total_loss': -0.04647555648699373, 'approx_kl': -0.07779022213071585, 'clip_fraction': 0.3424479216337204, 'grad_norm': 23.464460372924805}
2023-01-03 15:46:41.232 DEBUG: Taking gradient step
2023-01-03 15:46:43.209 DEBUG: Loss 14: {'policy_loss': -0.008443783451998636, 'entropy_loss': -0.04607216827571392, 'vf_loss': 0.02439972950795778, 'total_loss': -0.05451595172771256, 'approx_kl': -0.06782926176674664, 'clip_fraction': 0.34375, 'grad_norm': 23.35687255859375}
2023-01-03 15:46:43.210 INFO: Optimization: policy loss=-0.008, vf loss=0.024, entropy loss=-0.046, total loss=-0.055, num steps=15
2023-01-03 15:46:43.211 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 15:46:44.869 INFO: Evaluation rollout: return=0.503 (0.0), episode length=6.0
2023-01-03 15:46:44.870 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 15:46:44.873 INFO: Iteration: 49/137, steps: 10584
2023-01-03 15:46:52.777 DEBUG: Atoms are too close
2023-01-03 15:46:54.277 DEBUG: Atoms are too close
2023-01-03 15:46:59.290 DEBUG: Atoms are too close
2023-01-03 15:47:08.954 DEBUG: Atoms are too close
2023-01-03 15:47:21.951 DEBUG: Atoms are too close
2023-01-03 15:47:32.227 DEBUG: Atoms are too close
2023-01-03 15:47:35.849 DEBUG: Atoms are too close
2023-01-03 15:47:35.850 DEBUG: Atoms are too close
2023-01-03 15:47:40.012 INFO: Training rollout: return=-3.606 (7.5), episode length=5.6
2023-01-03 15:47:40.013 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 15:47:40.016 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-10584_train.pkl
2023-01-03 15:47:42.038 DEBUG: Taking gradient step
2023-01-03 15:47:44.034 DEBUG: Loss 0: {'policy_loss': 0.0088169137627546, 'entropy_loss': -0.04682869464159012, 'vf_loss': 0.02299295880966196, 'total_loss': -0.03801178087883552, 'approx_kl': -5.4249539971351624e-08, 'clip_fraction': 0.0, 'grad_norm': 16.395679473876953}
2023-01-03 15:47:45.976 DEBUG: Taking gradient step
2023-01-03 15:47:47.975 DEBUG: Loss 1: {'policy_loss': -0.037741207963771964, 'entropy_loss': -0.04675038903951645, 'vf_loss': 0.022201175719562767, 'total_loss': -0.08449159700328841, 'approx_kl': -0.004947409615851939, 'clip_fraction': 0.0859375, 'grad_norm': 12.426316261291504}
2023-01-03 15:47:49.921 DEBUG: Taking gradient step
2023-01-03 15:47:51.926 DEBUG: Loss 2: {'policy_loss': -0.003736178780354066, 'entropy_loss': -0.04715999495238066, 'vf_loss': 0.02569485282091604, 'total_loss': -0.05089617373273472, 'approx_kl': -0.009724744129925966, 'clip_fraction': 0.2838541716337204, 'grad_norm': 10.302865982055664}
2023-01-03 15:47:53.874 DEBUG: Taking gradient step
2023-01-03 15:47:55.880 DEBUG: Loss 3: {'policy_loss': -0.030185398050768586, 'entropy_loss': -0.04795204475522041, 'vf_loss': 0.023882591348106837, 'total_loss': -0.078137442805989, 'approx_kl': -0.0146067189052701, 'clip_fraction': 0.2955729216337204, 'grad_norm': 10.225156784057617}
2023-01-03 15:47:57.858 DEBUG: Taking gradient step
2023-01-03 15:47:59.926 DEBUG: Loss 4: {'policy_loss': -0.022546668114729915, 'entropy_loss': -0.04635723866522312, 'vf_loss': 0.024833790083781625, 'total_loss': -0.06890390677995303, 'approx_kl': -0.0069784140214324, 'clip_fraction': 0.3020833358168602, 'grad_norm': 16.75676155090332}
2023-01-03 15:48:01.922 DEBUG: Taking gradient step
2023-01-03 15:48:03.962 DEBUG: Loss 5: {'policy_loss': 0.017447118365023422, 'entropy_loss': -0.046186862513422966, 'vf_loss': 0.02474897597679519, 'total_loss': -0.02873974414839954, 'approx_kl': -0.017990809632465243, 'clip_fraction': 0.2890625, 'grad_norm': 20.312976837158203}
2023-01-03 15:48:05.928 DEBUG: Taking gradient step
2023-01-03 15:48:07.945 DEBUG: Loss 6: {'policy_loss': -0.003067112770530761, 'entropy_loss': -0.04720669612288475, 'vf_loss': 0.02517513228387088, 'total_loss': -0.05027380889341551, 'approx_kl': -0.01090653007850051, 'clip_fraction': 0.3255208358168602, 'grad_norm': 13.858367919921875}
2023-01-03 15:48:09.913 DEBUG: Taking gradient step
2023-01-03 15:48:12.032 DEBUG: Loss 7: {'policy_loss': 0.009248796194446005, 'entropy_loss': -0.046993437223136425, 'vf_loss': 0.02401482318760005, 'total_loss': -0.03774464102869042, 'approx_kl': -0.02612184244208038, 'clip_fraction': 0.3697916716337204, 'grad_norm': 10.723523139953613}
2023-01-03 15:48:13.997 DEBUG: Taking gradient step
2023-01-03 15:48:16.008 DEBUG: Loss 8: {'policy_loss': -0.039179473579879914, 'entropy_loss': -0.04768487811088562, 'vf_loss': 0.02232688151037729, 'total_loss': -0.08686435169076553, 'approx_kl': -0.010320611763745546, 'clip_fraction': 0.37890625, 'grad_norm': 11.557549476623535}
2023-01-03 15:48:17.971 DEBUG: Taking gradient step
2023-01-03 15:48:20.009 DEBUG: Loss 9: {'policy_loss': -0.015420924634529983, 'entropy_loss': -0.04518715385347605, 'vf_loss': 0.023639855896034852, 'total_loss': -0.06060807848800603, 'approx_kl': -0.011066580191254616, 'clip_fraction': 0.2994791679084301, 'grad_norm': 13.485913276672363}
2023-01-03 15:48:22.026 DEBUG: Taking gradient step
2023-01-03 15:48:24.231 DEBUG: Loss 10: {'policy_loss': 0.05424525371596896, 'entropy_loss': -0.04586005583405495, 'vf_loss': 0.025371799266344454, 'total_loss': 0.008385197881914011, 'approx_kl': -0.014486100524663925, 'clip_fraction': 0.34765625, 'grad_norm': 18.558740615844727}
2023-01-03 15:48:26.577 DEBUG: Taking gradient step
2023-01-03 15:48:28.905 DEBUG: Loss 11: {'policy_loss': -0.02319368305112135, 'entropy_loss': -0.04521518014371395, 'vf_loss': 0.021847175699964756, 'total_loss': -0.0684088631948353, 'approx_kl': -0.017535913735628128, 'clip_fraction': 0.3229166716337204, 'grad_norm': 11.703438758850098}
2023-01-03 15:48:30.884 DEBUG: Taking gradient step
2023-01-03 15:48:32.962 DEBUG: Loss 12: {'policy_loss': 0.006016172590722416, 'entropy_loss': -0.044456630013883114, 'vf_loss': 0.021785332749194232, 'total_loss': -0.0384404574231607, 'approx_kl': -0.02821906143799424, 'clip_fraction': 0.2760416679084301, 'grad_norm': 16.044700622558594}
2023-01-03 15:48:34.916 DEBUG: Taking gradient step
2023-01-03 15:48:37.006 DEBUG: Loss 13: {'policy_loss': 0.019332755890036232, 'entropy_loss': -0.04325506743043661, 'vf_loss': 0.02316611801437839, 'total_loss': -0.02392231154040038, 'approx_kl': -0.04621949698776007, 'clip_fraction': 0.28125, 'grad_norm': 23.47942352294922}
2023-01-03 15:48:39.105 DEBUG: Taking gradient step
2023-01-03 15:48:41.511 DEBUG: Loss 14: {'policy_loss': 0.015459277560280607, 'entropy_loss': -0.04515790566802025, 'vf_loss': 0.022072015373055164, 'total_loss': -0.02969862810773964, 'approx_kl': -0.055740838404744864, 'clip_fraction': 0.26953125, 'grad_norm': 27.91342544555664}
2023-01-03 15:48:41.512 INFO: Optimization: policy loss=0.015, vf loss=0.022, entropy loss=-0.045, total loss=-0.030, num steps=15
2023-01-03 15:48:41.513 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 15:48:43.243 INFO: Evaluation rollout: return=0.502 (0.0), episode length=6.0
2023-01-03 15:48:43.244 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 15:48:43.247 INFO: Iteration: 50/137, steps: 10800
2023-01-03 15:48:53.659 DEBUG: Atoms are too close
2023-01-03 15:49:13.254 DEBUG: Atoms are too close
2023-01-03 15:49:17.523 DEBUG: Atoms are too close
2023-01-03 15:49:31.223 DEBUG: Atoms are too close
2023-01-03 15:49:33.852 DEBUG: Atoms are too close
2023-01-03 15:49:35.695 DEBUG: Atoms are too close
2023-01-03 15:49:38.969 INFO: Training rollout: return=-2.495 (6.3), episode length=5.8
2023-01-03 15:49:38.970 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 15:49:38.973 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-10800_train.pkl
2023-01-03 15:49:40.972 DEBUG: Taking gradient step
2023-01-03 15:49:43.053 DEBUG: Loss 0: {'policy_loss': 0.049666484578928916, 'entropy_loss': -0.04688688740134239, 'vf_loss': 0.02244108000932779, 'total_loss': 0.0027795971775865097, 'approx_kl': -3.4099988610591936e-08, 'clip_fraction': 0.0, 'grad_norm': 31.035823822021484}
2023-01-03 15:49:45.048 DEBUG: Taking gradient step
2023-01-03 15:49:47.156 DEBUG: Loss 1: {'policy_loss': -0.001289066634913782, 'entropy_loss': -0.045502880588173866, 'vf_loss': 0.02022834700081302, 'total_loss': -0.04679194722308765, 'approx_kl': -0.011979011062067002, 'clip_fraction': 0.022135416977107525, 'grad_norm': 20.291244506835938}
2023-01-03 15:49:49.190 DEBUG: Taking gradient step
2023-01-03 15:49:51.284 DEBUG: Loss 2: {'policy_loss': -0.0135685079134746, 'entropy_loss': -0.04613748472183943, 'vf_loss': 0.020040509961604502, 'total_loss': -0.05970599263531402, 'approx_kl': -0.014191262889653444, 'clip_fraction': 0.2591145858168602, 'grad_norm': 16.81343650817871}
2023-01-03 15:49:53.301 DEBUG: Taking gradient step
2023-01-03 15:49:55.348 DEBUG: Loss 3: {'policy_loss': 0.011313765505042395, 'entropy_loss': -0.04842827748507261, 'vf_loss': 0.01898509669089512, 'total_loss': -0.03711451198003022, 'approx_kl': -0.03249041526578367, 'clip_fraction': 0.3502604216337204, 'grad_norm': 10.614816665649414}
2023-01-03 15:49:57.350 DEBUG: Taking gradient step
2023-01-03 15:49:59.476 DEBUG: Loss 4: {'policy_loss': -0.018043856642162907, 'entropy_loss': -0.046724844723939896, 'vf_loss': 0.018013106136461992, 'total_loss': -0.0647687013661028, 'approx_kl': -0.04254146106541157, 'clip_fraction': 0.359375, 'grad_norm': 10.442583084106445}
2023-01-03 15:50:01.462 DEBUG: Taking gradient step
2023-01-03 15:50:03.516 DEBUG: Loss 5: {'policy_loss': 0.05178365537078417, 'entropy_loss': -0.04915959946811199, 'vf_loss': 0.022117233535716995, 'total_loss': 0.0026240559026721733, 'approx_kl': -0.05696462746709585, 'clip_fraction': 0.33203125, 'grad_norm': 11.67951774597168}
2023-01-03 15:50:05.505 DEBUG: Taking gradient step
2023-01-03 15:50:07.551 DEBUG: Loss 6: {'policy_loss': 0.06766368813724732, 'entropy_loss': -0.049600173719227314, 'vf_loss': 0.022285937666817794, 'total_loss': 0.01806351441802001, 'approx_kl': -0.060850758105516434, 'clip_fraction': 0.3125, 'grad_norm': 11.258609771728516}
2023-01-03 15:50:09.521 DEBUG: Taking gradient step
2023-01-03 15:50:11.559 DEBUG: Loss 7: {'policy_loss': -0.026600523828692765, 'entropy_loss': -0.04985002987086773, 'vf_loss': 0.018274607642275967, 'total_loss': -0.0764505536995605, 'approx_kl': -0.05227804742753506, 'clip_fraction': 0.25390625, 'grad_norm': 10.844759941101074}
2023-01-03 15:50:13.535 DEBUG: Taking gradient step
2023-01-03 15:50:15.553 DEBUG: Loss 8: {'policy_loss': 0.029129903673779663, 'entropy_loss': -0.049174522049725056, 'vf_loss': 0.020904156398637533, 'total_loss': -0.0200446183759454, 'approx_kl': -0.07324576773680747, 'clip_fraction': 0.2408854179084301, 'grad_norm': 19.397966384887695}
2023-01-03 15:50:17.538 DEBUG: Taking gradient step
2023-01-03 15:50:19.568 DEBUG: Loss 9: {'policy_loss': 0.012737597572249612, 'entropy_loss': -0.049039874225854874, 'vf_loss': 0.01994051194497395, 'total_loss': -0.03630227665360527, 'approx_kl': -0.09297518618404865, 'clip_fraction': 0.2916666716337204, 'grad_norm': 10.861370086669922}
2023-01-03 15:50:21.548 DEBUG: Taking gradient step
2023-01-03 15:50:23.592 DEBUG: Loss 10: {'policy_loss': 0.03106095080720707, 'entropy_loss': -0.049483662471175194, 'vf_loss': 0.022633024686900524, 'total_loss': -0.018422711663968125, 'approx_kl': -0.06645486690104008, 'clip_fraction': 0.3111979216337204, 'grad_norm': 22.595285415649414}
2023-01-03 15:50:25.589 DEBUG: Taking gradient step
2023-01-03 15:50:27.649 DEBUG: Loss 11: {'policy_loss': -0.032820917161281424, 'entropy_loss': -0.050054049119353294, 'vf_loss': 0.01768732037736992, 'total_loss': -0.08287496628063472, 'approx_kl': -0.07175644068047404, 'clip_fraction': 0.3255208358168602, 'grad_norm': 10.091493606567383}
2023-01-03 15:50:29.643 DEBUG: Taking gradient step
2023-01-03 15:50:31.701 DEBUG: Loss 12: {'policy_loss': -0.03719813321144376, 'entropy_loss': -0.049128797836601734, 'vf_loss': 0.018414155279610853, 'total_loss': -0.0863269310480455, 'approx_kl': -0.06470293225720525, 'clip_fraction': 0.3580729216337204, 'grad_norm': 10.748678207397461}
2023-01-03 15:50:33.709 DEBUG: Taking gradient step
2023-01-03 15:50:35.764 DEBUG: Loss 13: {'policy_loss': -0.012393011019623654, 'entropy_loss': -0.050790807232260704, 'vf_loss': 0.019569435087436204, 'total_loss': -0.06318381825188436, 'approx_kl': -0.08051006775349379, 'clip_fraction': 0.33203125, 'grad_norm': 11.292966842651367}
2023-01-03 15:50:37.755 DEBUG: Taking gradient step
2023-01-03 15:50:39.800 DEBUG: Loss 14: {'policy_loss': -0.04958233504961364, 'entropy_loss': -0.04948880523443222, 'vf_loss': 0.01788296441556507, 'total_loss': -0.09907114028404586, 'approx_kl': -0.057933324947953224, 'clip_fraction': 0.3815104216337204, 'grad_norm': 5.023342609405518}
2023-01-03 15:50:39.801 INFO: Optimization: policy loss=-0.050, vf loss=0.018, entropy loss=-0.049, total loss=-0.099, num steps=15
2023-01-03 15:50:39.802 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 15:50:41.517 INFO: Evaluation rollout: return=0.459 (0.0), episode length=6.0
2023-01-03 15:50:41.519 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 15:50:41.523 DEBUG: Deleting old model: runs/CH3NO_dna/models/CH3NO_dna_run-1_steps-8856.model
2023-01-03 15:50:41.529 DEBUG: Saving model: runs/CH3NO_dna/models/CH3NO_dna_run-1_steps-11016.model
2023-01-03 15:50:41.582 INFO: Iteration: 51/137, steps: 11016
2023-01-03 15:50:52.034 DEBUG: Atoms are too close
2023-01-03 15:50:55.665 DEBUG: Atoms are too close
2023-01-03 15:51:10.942 DEBUG: Atoms are too close
2023-01-03 15:51:27.289 DEBUG: Atoms are too close
2023-01-03 15:51:29.125 DEBUG: Atoms are too close
2023-01-03 15:51:32.483 DEBUG: Atoms are too close
2023-01-03 15:51:38.100 DEBUG: Atoms are too close
2023-01-03 15:51:38.161 INFO: Training rollout: return=-2.865 (6.6), episode length=5.8
2023-01-03 15:51:38.162 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 15:51:38.165 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-11016_train.pkl
2023-01-03 15:51:40.150 DEBUG: Taking gradient step
2023-01-03 15:51:42.188 DEBUG: Loss 0: {'policy_loss': -0.021853327555195416, 'entropy_loss': -0.0482671232894063, 'vf_loss': 0.017610574115217423, 'total_loss': -0.07012045084460172, 'approx_kl': -2.2337189875543118e-08, 'clip_fraction': 0.0, 'grad_norm': 10.599493980407715}
2023-01-03 15:51:44.164 DEBUG: Taking gradient step
2023-01-03 15:51:46.202 DEBUG: Loss 1: {'policy_loss': -0.034561623363971485, 'entropy_loss': -0.04843975882977247, 'vf_loss': 0.01747462476209246, 'total_loss': -0.08300138219374395, 'approx_kl': -0.010811520391143858, 'clip_fraction': 0.061197916977107525, 'grad_norm': 8.808514595031738}
2023-01-03 15:51:48.178 DEBUG: Taking gradient step
2023-01-03 15:51:50.296 DEBUG: Loss 2: {'policy_loss': -0.013119522314285623, 'entropy_loss': -0.04863000754266977, 'vf_loss': 0.019995606205233947, 'total_loss': -0.06174952985695539, 'approx_kl': -0.028729117941111326, 'clip_fraction': 0.2799479216337204, 'grad_norm': 8.504571914672852}
2023-01-03 15:51:52.281 DEBUG: Taking gradient step
2023-01-03 15:51:54.309 DEBUG: Loss 3: {'policy_loss': 0.036539448409180775, 'entropy_loss': -0.0481528090313077, 'vf_loss': 0.020706690268304614, 'total_loss': -0.011613360622126923, 'approx_kl': -0.030779528431594372, 'clip_fraction': 0.3489583358168602, 'grad_norm': 12.365607261657715}
2023-01-03 15:51:56.290 DEBUG: Taking gradient step
2023-01-03 15:51:58.326 DEBUG: Loss 4: {'policy_loss': -0.014799882357466071, 'entropy_loss': -0.04892344959080219, 'vf_loss': 0.01762518099985038, 'total_loss': -0.06372333194826826, 'approx_kl': -0.039472215343266726, 'clip_fraction': 0.3815104216337204, 'grad_norm': 12.732291221618652}
2023-01-03 15:52:00.291 DEBUG: Taking gradient step
2023-01-03 15:52:02.310 DEBUG: Loss 5: {'policy_loss': 0.03127344975140559, 'entropy_loss': -0.04796800948679447, 'vf_loss': 0.018769130462111806, 'total_loss': -0.01669455973538888, 'approx_kl': -0.050068971933797, 'clip_fraction': 0.4296875, 'grad_norm': 12.645343780517578}
2023-01-03 15:52:04.286 DEBUG: Taking gradient step
2023-01-03 15:52:06.305 DEBUG: Loss 6: {'policy_loss': -0.035374515031799475, 'entropy_loss': -0.047307428903877735, 'vf_loss': 0.017575555094000616, 'total_loss': -0.08268194393567721, 'approx_kl': -0.0893004322424531, 'clip_fraction': 0.3567708358168602, 'grad_norm': 10.219072341918945}
2023-01-03 15:52:08.271 DEBUG: Taking gradient step
2023-01-03 15:52:10.299 DEBUG: Loss 7: {'policy_loss': 0.008724701850114409, 'entropy_loss': -0.04622152913361788, 'vf_loss': 0.01874506125907044, 'total_loss': -0.03749682728350347, 'approx_kl': -0.07817531656473875, 'clip_fraction': 0.2903645858168602, 'grad_norm': 10.572641372680664}
2023-01-03 15:52:12.274 DEBUG: Taking gradient step
2023-01-03 15:52:14.293 DEBUG: Loss 8: {'policy_loss': 0.028375178603574365, 'entropy_loss': -0.04784755315631628, 'vf_loss': 0.020531242929220313, 'total_loss': -0.019472374552741915, 'approx_kl': -0.07670652400702238, 'clip_fraction': 0.3802083358168602, 'grad_norm': 12.61719799041748}
2023-01-03 15:52:16.272 DEBUG: Taking gradient step
2023-01-03 15:52:18.298 DEBUG: Loss 9: {'policy_loss': 0.0024583519108791543, 'entropy_loss': -0.046986861154437065, 'vf_loss': 0.018832622628965703, 'total_loss': -0.04452850924355792, 'approx_kl': -0.08003972191363573, 'clip_fraction': 0.4361979216337204, 'grad_norm': 16.7672119140625}
2023-01-03 15:52:20.285 DEBUG: Taking gradient step
2023-01-03 15:52:22.295 DEBUG: Loss 10: {'policy_loss': -0.0011338904214914028, 'entropy_loss': -0.04716748185455799, 'vf_loss': 0.01785403691793184, 'total_loss': -0.0483013722760494, 'approx_kl': -0.0977339232340455, 'clip_fraction': 0.5169270932674408, 'grad_norm': 19.19601058959961}
2023-01-03 15:52:24.285 DEBUG: Taking gradient step
2023-01-03 15:52:26.329 DEBUG: Loss 11: {'policy_loss': 0.07804692641130634, 'entropy_loss': -0.04530606418848038, 'vf_loss': 0.021630554296331872, 'total_loss': 0.03274086222282596, 'approx_kl': -0.07429803221020848, 'clip_fraction': 0.4778645858168602, 'grad_norm': 32.529510498046875}
2023-01-03 15:52:28.332 DEBUG: Taking gradient step
2023-01-03 15:52:30.430 DEBUG: Loss 12: {'policy_loss': -0.005037397206487649, 'entropy_loss': -0.046904442831873894, 'vf_loss': 0.017026682390038437, 'total_loss': -0.05194184003836154, 'approx_kl': -0.10986229032278061, 'clip_fraction': 0.50390625, 'grad_norm': 9.143909454345703}
2023-01-03 15:52:32.449 DEBUG: Taking gradient step
2023-01-03 15:52:34.501 DEBUG: Loss 13: {'policy_loss': -0.003653480397484501, 'entropy_loss': -0.046457127667963505, 'vf_loss': 0.017646550845612494, 'total_loss': -0.050110608065447995, 'approx_kl': -0.09763241745531559, 'clip_fraction': 0.4921875, 'grad_norm': 6.969729423522949}
2023-01-03 15:52:36.490 DEBUG: Taking gradient step
2023-01-03 15:52:38.517 DEBUG: Loss 14: {'policy_loss': 0.015827983002612955, 'entropy_loss': -0.04591729585081339, 'vf_loss': 0.01853085118555015, 'total_loss': -0.030089312848200434, 'approx_kl': -0.08765890588983893, 'clip_fraction': 0.47265625, 'grad_norm': 9.326205253601074}
2023-01-03 15:52:38.518 INFO: Optimization: policy loss=0.016, vf loss=0.019, entropy loss=-0.046, total loss=-0.030, num steps=15
2023-01-03 15:52:38.519 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 15:52:40.298 INFO: Evaluation rollout: return=0.426 (0.0), episode length=6.0
2023-01-03 15:52:40.299 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 15:52:40.302 INFO: Iteration: 52/137, steps: 11232
2023-01-03 15:53:15.296 DEBUG: Atoms are too close
2023-01-03 15:53:16.252 DEBUG: Atoms are too close
2023-01-03 15:53:28.124 DEBUG: Atoms are too close
2023-01-03 15:53:30.876 DEBUG: Atoms are too close
2023-01-03 15:53:35.231 DEBUG: Atoms are too close
2023-01-03 15:53:36.640 INFO: Training rollout: return=-1.693 (5.3), episode length=5.9
2023-01-03 15:53:36.642 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 15:53:36.644 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-11232_train.pkl
2023-01-03 15:53:38.690 DEBUG: Taking gradient step
2023-01-03 15:53:40.772 DEBUG: Loss 0: {'policy_loss': -0.04087032310550686, 'entropy_loss': -0.046435076743364334, 'vf_loss': 0.015353086094369032, 'total_loss': -0.08730539984887119, 'approx_kl': 1.528921211857437e-08, 'clip_fraction': 0.0, 'grad_norm': 17.93649673461914}
2023-01-03 15:53:42.808 DEBUG: Taking gradient step
2023-01-03 15:53:44.897 DEBUG: Loss 1: {'policy_loss': 0.0015292235529808492, 'entropy_loss': -0.04529088828712702, 'vf_loss': 0.01759666160301085, 'total_loss': -0.043761664734146166, 'approx_kl': -0.010437753750011325, 'clip_fraction': 0.1588541679084301, 'grad_norm': 21.86735725402832}
2023-01-03 15:53:46.916 DEBUG: Taking gradient step
2023-01-03 15:53:48.996 DEBUG: Loss 2: {'policy_loss': -0.04973520520859688, 'entropy_loss': -0.04763616342097521, 'vf_loss': 0.015516440477545992, 'total_loss': -0.09737136862957209, 'approx_kl': -0.035033305175602436, 'clip_fraction': 0.2643229216337204, 'grad_norm': 15.919456481933594}
2023-01-03 15:53:51.016 DEBUG: Taking gradient step
2023-01-03 15:53:53.113 DEBUG: Loss 3: {'policy_loss': -0.03682354962074562, 'entropy_loss': -0.04664388578385115, 'vf_loss': 0.016268333865605306, 'total_loss': -0.08346743540459678, 'approx_kl': -0.034814408514648676, 'clip_fraction': 0.2447916679084301, 'grad_norm': 11.506281852722168}
2023-01-03 15:53:55.198 DEBUG: Taking gradient step
2023-01-03 15:53:57.347 DEBUG: Loss 4: {'policy_loss': 0.005466797551274709, 'entropy_loss': -0.04689016751945019, 'vf_loss': 0.019145074562713565, 'total_loss': -0.041423369968175486, 'approx_kl': -0.026919005438685417, 'clip_fraction': 0.3580729216337204, 'grad_norm': 9.659825325012207}
2023-01-03 15:53:59.466 DEBUG: Taking gradient step
2023-01-03 15:54:01.571 DEBUG: Loss 5: {'policy_loss': 0.00047867816064177393, 'entropy_loss': -0.04575182497501373, 'vf_loss': 0.01813481758942192, 'total_loss': -0.04527314681437196, 'approx_kl': -0.023839025991037488, 'clip_fraction': 0.33203125, 'grad_norm': 11.92174243927002}
2023-01-03 15:54:03.570 DEBUG: Taking gradient step
2023-01-03 15:54:05.619 DEBUG: Loss 6: {'policy_loss': 0.03166408477240491, 'entropy_loss': -0.045248132199048996, 'vf_loss': 0.01791957812266986, 'total_loss': -0.013584047426644083, 'approx_kl': -0.021770373452454805, 'clip_fraction': 0.3567708358168602, 'grad_norm': 35.421512603759766}
2023-01-03 15:54:07.624 DEBUG: Taking gradient step
2023-01-03 15:54:09.692 DEBUG: Loss 7: {'policy_loss': 0.011099772795564667, 'entropy_loss': -0.0446625892072916, 'vf_loss': 0.01686277248646843, 'total_loss': -0.03356281641172694, 'approx_kl': -0.020672686863690615, 'clip_fraction': 0.4205729216337204, 'grad_norm': 18.58144187927246}
2023-01-03 15:54:11.683 DEBUG: Taking gradient step
2023-01-03 15:54:13.737 DEBUG: Loss 8: {'policy_loss': -0.016145112503366678, 'entropy_loss': -0.04246114753186703, 'vf_loss': 0.016465213417919636, 'total_loss': -0.0586062600352337, 'approx_kl': -0.019435225054621696, 'clip_fraction': 0.3997395858168602, 'grad_norm': 17.60079574584961}
2023-01-03 15:54:15.737 DEBUG: Taking gradient step
2023-01-03 15:54:17.795 DEBUG: Loss 9: {'policy_loss': -0.06462350356476348, 'entropy_loss': -0.04384387470781803, 'vf_loss': 0.016064684913073307, 'total_loss': -0.10846737827258152, 'approx_kl': -0.04017632640898228, 'clip_fraction': 0.3984375, 'grad_norm': 15.193662643432617}
2023-01-03 15:54:19.810 DEBUG: Taking gradient step
2023-01-03 15:54:21.870 DEBUG: Loss 10: {'policy_loss': -0.042693274396022336, 'entropy_loss': -0.04608457814902067, 'vf_loss': 0.015246523904630662, 'total_loss': -0.088777852545043, 'approx_kl': -0.023420060984790325, 'clip_fraction': 0.4153645858168602, 'grad_norm': 13.349855422973633}
2023-01-03 15:54:23.882 DEBUG: Taking gradient step
2023-01-03 15:54:26.026 DEBUG: Loss 11: {'policy_loss': -0.03308816706815024, 'entropy_loss': -0.04496920946985483, 'vf_loss': 0.018083495551772594, 'total_loss': -0.07805737653800507, 'approx_kl': -0.02891422063112259, 'clip_fraction': 0.3880208358168602, 'grad_norm': 15.65732479095459}
2023-01-03 15:54:28.032 DEBUG: Taking gradient step
2023-01-03 15:54:30.083 DEBUG: Loss 12: {'policy_loss': -0.02542535510674368, 'entropy_loss': -0.045252468436956406, 'vf_loss': 0.015739141627745392, 'total_loss': -0.07067782354370009, 'approx_kl': -0.0580776073038578, 'clip_fraction': 0.33984375, 'grad_norm': 10.0086669921875}
2023-01-03 15:54:32.095 DEBUG: Taking gradient step
2023-01-03 15:54:34.165 DEBUG: Loss 13: {'policy_loss': -0.04421747174175858, 'entropy_loss': -0.045637683011591434, 'vf_loss': 0.015864212408035386, 'total_loss': -0.08985515475335001, 'approx_kl': -0.07626804802566767, 'clip_fraction': 0.3463541716337204, 'grad_norm': 14.32080078125}
2023-01-03 15:54:36.197 DEBUG: Taking gradient step
2023-01-03 15:54:38.255 DEBUG: Loss 14: {'policy_loss': -0.05048950065354136, 'entropy_loss': -0.04428378492593765, 'vf_loss': 0.015061446424111592, 'total_loss': -0.094773285579479, 'approx_kl': -0.07441403530538082, 'clip_fraction': 0.3151041716337204, 'grad_norm': 15.132420539855957}
2023-01-03 15:54:38.255 INFO: Optimization: policy loss=-0.050, vf loss=0.015, entropy loss=-0.044, total loss=-0.095, num steps=15
2023-01-03 15:54:38.257 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 15:54:40.156 INFO: Evaluation rollout: return=0.443 (0.0), episode length=6.0
2023-01-03 15:54:40.157 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 15:54:40.160 INFO: Iteration: 53/137, steps: 11448
2023-01-03 15:54:52.610 DEBUG: Atoms are too close
2023-01-03 15:54:52.900 DEBUG: Atoms are too close
2023-01-03 15:55:01.647 DEBUG: Atoms are too close
2023-01-03 15:55:05.841 DEBUG: Atoms are too close
2023-01-03 15:55:06.121 DEBUG: Atoms are too close
2023-01-03 15:55:18.054 DEBUG: Atoms are too close
2023-01-03 15:55:23.148 DEBUG: Atoms are too close
2023-01-03 15:55:28.375 DEBUG: Atoms are too close
2023-01-03 15:55:28.735 DEBUG: Atoms are too close
2023-01-03 15:55:29.313 DEBUG: Atoms are too close
2023-01-03 15:55:34.007 INFO: Training rollout: return=-5.134 (8.4), episode length=5.5
2023-01-03 15:55:34.008 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 15:55:34.011 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-11448_train.pkl
2023-01-03 15:55:36.047 DEBUG: Taking gradient step
2023-01-03 15:55:38.045 DEBUG: Loss 0: {'policy_loss': -0.04406345528340107, 'entropy_loss': -0.04241256695240736, 'vf_loss': 0.026549334361103957, 'total_loss': -0.08647602223580844, 'approx_kl': -5.6927092373371124e-08, 'clip_fraction': 0.0, 'grad_norm': 29.906627655029297}
2023-01-03 15:55:40.023 DEBUG: Taking gradient step
2023-01-03 15:55:42.021 DEBUG: Loss 1: {'policy_loss': -0.03208915360283858, 'entropy_loss': -0.04271296411752701, 'vf_loss': 0.027262788901528716, 'total_loss': -0.07480211772036559, 'approx_kl': -0.011910550063475966, 'clip_fraction': 0.05989583395421505, 'grad_norm': 29.143497467041016}
2023-01-03 15:55:43.957 DEBUG: Taking gradient step
2023-01-03 15:55:45.975 DEBUG: Loss 2: {'policy_loss': -0.01293402011534317, 'entropy_loss': -0.04434551391750574, 'vf_loss': 0.02794556706324087, 'total_loss': -0.05727953403284891, 'approx_kl': -0.03314132196828723, 'clip_fraction': 0.23828125, 'grad_norm': 37.83285903930664}
2023-01-03 15:55:47.952 DEBUG: Taking gradient step
2023-01-03 15:55:49.992 DEBUG: Loss 3: {'policy_loss': 0.10735895766623174, 'entropy_loss': -0.0450977087020874, 'vf_loss': 0.03296853486322782, 'total_loss': 0.06226124896414434, 'approx_kl': -0.03343847021460533, 'clip_fraction': 0.3346354216337204, 'grad_norm': 45.040611267089844}
2023-01-03 15:55:51.978 DEBUG: Taking gradient step
2023-01-03 15:55:54.030 DEBUG: Loss 4: {'policy_loss': -0.012329314353938095, 'entropy_loss': -0.04433762189000845, 'vf_loss': 0.027759505661691112, 'total_loss': -0.056666936243946545, 'approx_kl': -0.04240602068603039, 'clip_fraction': 0.38671875, 'grad_norm': 16.956478118896484}
2023-01-03 15:55:55.992 DEBUG: Taking gradient step
2023-01-03 15:55:58.001 DEBUG: Loss 5: {'policy_loss': 0.003542797026899386, 'entropy_loss': -0.0445242915302515, 'vf_loss': 0.02769980367376331, 'total_loss': -0.04098149450335212, 'approx_kl': -0.01725230342708528, 'clip_fraction': 0.41015625, 'grad_norm': 12.128170013427734}
2023-01-03 15:55:59.949 DEBUG: Taking gradient step
2023-01-03 15:56:01.939 DEBUG: Loss 6: {'policy_loss': 0.03365538544521415, 'entropy_loss': -0.046227375976741314, 'vf_loss': 0.028901514494105426, 'total_loss': -0.012571990531527164, 'approx_kl': -0.05238366685807705, 'clip_fraction': 0.4986979216337204, 'grad_norm': 14.967607498168945}
2023-01-03 15:56:03.882 DEBUG: Taking gradient step
2023-01-03 15:56:05.876 DEBUG: Loss 7: {'policy_loss': 0.018074260513835934, 'entropy_loss': -0.04375369939953089, 'vf_loss': 0.030049337901804564, 'total_loss': -0.025679438885694954, 'approx_kl': -0.06426355289295316, 'clip_fraction': 0.453125, 'grad_norm': 18.657331466674805}
2023-01-03 15:56:07.817 DEBUG: Taking gradient step
2023-01-03 15:56:09.846 DEBUG: Loss 8: {'policy_loss': 0.10849072599144778, 'entropy_loss': -0.043881576508283615, 'vf_loss': 0.032916588130109, 'total_loss': 0.06460914948316417, 'approx_kl': -0.05931441951543093, 'clip_fraction': 0.4518229216337204, 'grad_norm': 28.199872970581055}
2023-01-03 15:56:11.821 DEBUG: Taking gradient step
2023-01-03 15:56:13.953 DEBUG: Loss 9: {'policy_loss': 0.03431816354405604, 'entropy_loss': -0.04437105171382427, 'vf_loss': 0.02972386999502684, 'total_loss': -0.01005288816976823, 'approx_kl': -0.057290482334792614, 'clip_fraction': 0.3697916716337204, 'grad_norm': 36.860313415527344}
2023-01-03 15:56:15.887 DEBUG: Taking gradient step
2023-01-03 15:56:17.875 DEBUG: Loss 10: {'policy_loss': -0.0009639477233976471, 'entropy_loss': -0.042863572016358376, 'vf_loss': 0.029467808809417368, 'total_loss': -0.043827519739756016, 'approx_kl': -0.05778346862643957, 'clip_fraction': 0.3411458358168602, 'grad_norm': 24.297138214111328}
2023-01-03 15:56:19.819 DEBUG: Taking gradient step
2023-01-03 15:56:21.807 DEBUG: Loss 11: {'policy_loss': 0.009787151851481372, 'entropy_loss': -0.04356579389423132, 'vf_loss': 0.029769753176736233, 'total_loss': -0.03377864204274995, 'approx_kl': -0.05207059998065233, 'clip_fraction': 0.2630208358168602, 'grad_norm': 30.097543716430664}
2023-01-03 15:56:23.764 DEBUG: Taking gradient step
2023-01-03 15:56:25.753 DEBUG: Loss 12: {'policy_loss': -0.015096090212862219, 'entropy_loss': -0.041787030175328255, 'vf_loss': 0.029628202657599616, 'total_loss': -0.056883120388190475, 'approx_kl': -0.05430369917303324, 'clip_fraction': 0.3385416716337204, 'grad_norm': 22.073650360107422}
2023-01-03 15:56:27.702 DEBUG: Taking gradient step
2023-01-03 15:56:29.724 DEBUG: Loss 13: {'policy_loss': 0.017312695297904638, 'entropy_loss': -0.04395805858075619, 'vf_loss': 0.029106237389684944, 'total_loss': -0.026645363282851553, 'approx_kl': -0.06284120446071029, 'clip_fraction': 0.453125, 'grad_norm': 23.62385368347168}
2023-01-03 15:56:31.668 DEBUG: Taking gradient step
2023-01-03 15:56:33.653 DEBUG: Loss 14: {'policy_loss': 0.06950371262146574, 'entropy_loss': -0.04348845221102238, 'vf_loss': 0.031470971033926265, 'total_loss': 0.026015260410443358, 'approx_kl': -0.05583851435221732, 'clip_fraction': 0.41015625, 'grad_norm': 37.18210983276367}
2023-01-03 15:56:33.653 INFO: Optimization: policy loss=0.070, vf loss=0.031, entropy loss=-0.043, total loss=0.026, num steps=15
2023-01-03 15:56:33.654 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 15:56:35.371 INFO: Evaluation rollout: return=0.446 (0.0), episode length=6.0
2023-01-03 15:56:35.372 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 15:56:35.375 INFO: Iteration: 54/137, steps: 11664
2023-01-03 15:57:07.843 DEBUG: Atoms are too close
2023-01-03 15:57:09.045 DEBUG: Atoms are too close
2023-01-03 15:57:24.669 DEBUG: Atoms are too close
2023-01-03 15:57:31.909 DEBUG: Atoms are too close
2023-01-03 15:57:32.250 INFO: Training rollout: return=-1.343 (5.0), episode length=5.9
2023-01-03 15:57:32.251 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 15:57:32.254 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-11664_train.pkl
2023-01-03 15:57:34.285 DEBUG: Taking gradient step
2023-01-03 15:57:36.345 DEBUG: Loss 0: {'policy_loss': 0.0014208878490220844, 'entropy_loss': -0.04478361364454031, 'vf_loss': 0.01416234240195973, 'total_loss': -0.043362725795518225, 'approx_kl': 1.0100969438653351e-07, 'clip_fraction': 0.0, 'grad_norm': 22.073307037353516}
2023-01-03 15:57:38.370 DEBUG: Taking gradient step
2023-01-03 15:57:40.452 DEBUG: Loss 1: {'policy_loss': -0.01721680207509576, 'entropy_loss': -0.045765623450279236, 'vf_loss': 0.013169653598543355, 'total_loss': -0.062982425525375, 'approx_kl': -0.010596552048809826, 'clip_fraction': 0.049479166977107525, 'grad_norm': 18.46975326538086}
2023-01-03 15:57:42.457 DEBUG: Taking gradient step
2023-01-03 15:57:44.512 DEBUG: Loss 2: {'policy_loss': -0.03669178025301852, 'entropy_loss': -0.04607850592583418, 'vf_loss': 0.01383402168886797, 'total_loss': -0.08277028617885271, 'approx_kl': -0.024776469450443983, 'clip_fraction': 0.3255208358168602, 'grad_norm': 8.745790481567383}
2023-01-03 15:57:46.511 DEBUG: Taking gradient step
2023-01-03 15:57:48.581 DEBUG: Loss 3: {'policy_loss': 0.04655485342884477, 'entropy_loss': -0.04597545228898525, 'vf_loss': 0.016585416610535055, 'total_loss': 0.00057940113985952, 'approx_kl': -0.023752778535708785, 'clip_fraction': 0.4322916716337204, 'grad_norm': 15.307205200195312}
2023-01-03 15:57:50.582 DEBUG: Taking gradient step
2023-01-03 15:57:52.688 DEBUG: Loss 4: {'policy_loss': -0.05206946304154446, 'entropy_loss': -0.0450027734041214, 'vf_loss': 0.013318024129719549, 'total_loss': -0.09707223644566586, 'approx_kl': -0.056514760944992304, 'clip_fraction': 0.4088541716337204, 'grad_norm': 9.42015552520752}
2023-01-03 15:57:54.721 DEBUG: Taking gradient step
2023-01-03 15:57:56.774 DEBUG: Loss 5: {'policy_loss': -0.001092421493836447, 'entropy_loss': -0.04448943492025137, 'vf_loss': 0.01590573369326075, 'total_loss': -0.04558185641408782, 'approx_kl': -0.050546628423035145, 'clip_fraction': 0.3684895858168602, 'grad_norm': 7.768231391906738}
2023-01-03 15:57:58.772 DEBUG: Taking gradient step
2023-01-03 15:58:00.909 DEBUG: Loss 6: {'policy_loss': 0.024178074887138176, 'entropy_loss': -0.0455790963023901, 'vf_loss': 0.01664466655066, 'total_loss': -0.021401021415251922, 'approx_kl': -0.059670062735676765, 'clip_fraction': 0.3151041716337204, 'grad_norm': 18.425548553466797}
2023-01-03 15:58:02.897 DEBUG: Taking gradient step
2023-01-03 15:58:04.965 DEBUG: Loss 7: {'policy_loss': -0.023132378660001483, 'entropy_loss': -0.04438157007098198, 'vf_loss': 0.013840812685389073, 'total_loss': -0.06751394873098346, 'approx_kl': -0.03896182612515986, 'clip_fraction': 0.3190104216337204, 'grad_norm': 8.419628143310547}
2023-01-03 15:58:06.973 DEBUG: Taking gradient step
2023-01-03 15:58:09.001 DEBUG: Loss 8: {'policy_loss': -0.011520101013400086, 'entropy_loss': -0.04561755619943142, 'vf_loss': 0.01334947713837279, 'total_loss': -0.057137657212831504, 'approx_kl': -0.05009664432145655, 'clip_fraction': 0.359375, 'grad_norm': 7.824888706207275}
2023-01-03 15:58:11.015 DEBUG: Taking gradient step
2023-01-03 15:58:13.068 DEBUG: Loss 9: {'policy_loss': 0.0072099068245798925, 'entropy_loss': -0.04548537451773882, 'vf_loss': 0.013988340452672905, 'total_loss': -0.03827546769315893, 'approx_kl': -0.04825663520023227, 'clip_fraction': 0.3723958358168602, 'grad_norm': 8.194950103759766}
2023-01-03 15:58:15.062 DEBUG: Taking gradient step
2023-01-03 15:58:17.120 DEBUG: Loss 10: {'policy_loss': -0.00893374813416853, 'entropy_loss': -0.04663641192018986, 'vf_loss': 0.01379653020038515, 'total_loss': -0.055570160054358386, 'approx_kl': -0.05696952110156417, 'clip_fraction': 0.37109375, 'grad_norm': 7.381855487823486}
2023-01-03 15:58:19.137 DEBUG: Taking gradient step
2023-01-03 15:58:21.194 DEBUG: Loss 11: {'policy_loss': 0.03254772521066905, 'entropy_loss': -0.04478099849075079, 'vf_loss': 0.015077619168201674, 'total_loss': -0.012233273280081738, 'approx_kl': -0.04876225255429745, 'clip_fraction': 0.3346354216337204, 'grad_norm': 10.678858757019043}
2023-01-03 15:58:23.196 DEBUG: Taking gradient step
2023-01-03 15:58:25.252 DEBUG: Loss 12: {'policy_loss': -0.029210873538305985, 'entropy_loss': -0.04775731451809406, 'vf_loss': 0.011826637663018972, 'total_loss': -0.07696818805640004, 'approx_kl': -0.07959222025237978, 'clip_fraction': 0.36328125, 'grad_norm': 6.324605464935303}
2023-01-03 15:58:27.261 DEBUG: Taking gradient step
2023-01-03 15:58:29.325 DEBUG: Loss 13: {'policy_loss': -0.00039697716433819905, 'entropy_loss': -0.045301403850317, 'vf_loss': 0.013691870692924529, 'total_loss': -0.045698381014655204, 'approx_kl': -0.06723801419138908, 'clip_fraction': 0.3893229216337204, 'grad_norm': 8.476037979125977}
2023-01-03 15:58:31.336 DEBUG: Taking gradient step
2023-01-03 15:58:33.455 DEBUG: Loss 14: {'policy_loss': -0.03104658137836129, 'entropy_loss': -0.04571098834276199, 'vf_loss': 0.012007185017169136, 'total_loss': -0.07675756972112328, 'approx_kl': -0.0745410742238164, 'clip_fraction': 0.3658854216337204, 'grad_norm': 7.0048441886901855}
2023-01-03 15:58:33.456 INFO: Optimization: policy loss=-0.031, vf loss=0.012, entropy loss=-0.046, total loss=-0.077, num steps=15
2023-01-03 15:58:33.457 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 15:58:35.369 INFO: Evaluation rollout: return=0.394 (0.0), episode length=6.0
2023-01-03 15:58:35.371 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 15:58:35.374 INFO: Iteration: 55/137, steps: 11880
2023-01-03 15:59:05.025 DEBUG: Atoms are too close
2023-01-03 15:59:09.345 DEBUG: Atoms are too close
2023-01-03 15:59:09.347 DEBUG: Atoms are too close
2023-01-03 15:59:27.623 DEBUG: Atoms are too close
2023-01-03 15:59:27.626 DEBUG: Atoms are too close
2023-01-03 15:59:32.063 INFO: Training rollout: return=-1.824 (5.6), episode length=5.8
2023-01-03 15:59:32.064 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 15:59:32.068 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-11880_train.pkl
2023-01-03 15:59:34.102 DEBUG: Taking gradient step
2023-01-03 15:59:36.150 DEBUG: Loss 0: {'policy_loss': 0.016527166398126934, 'entropy_loss': -0.044005570001900196, 'vf_loss': 0.01615222302860651, 'total_loss': -0.02747840360377326, 'approx_kl': -1.0042761822148805e-07, 'clip_fraction': 0.0, 'grad_norm': 13.06666374206543}
2023-01-03 15:59:38.147 DEBUG: Taking gradient step
2023-01-03 15:59:40.199 DEBUG: Loss 1: {'policy_loss': 0.020632966822163167, 'entropy_loss': -0.044070303440093994, 'vf_loss': 0.017070846342329284, 'total_loss': -0.023437336617930828, 'approx_kl': -0.007931775646284223, 'clip_fraction': 0.033854166977107525, 'grad_norm': 17.698993682861328}
2023-01-03 15:59:42.186 DEBUG: Taking gradient step
2023-01-03 15:59:44.230 DEBUG: Loss 2: {'policy_loss': 0.04118906552663963, 'entropy_loss': -0.044051334261894226, 'vf_loss': 0.017866268661556706, 'total_loss': -0.0028622687352545945, 'approx_kl': -0.030115388333797455, 'clip_fraction': 0.15234375, 'grad_norm': 14.443184852600098}
2023-01-03 15:59:46.202 DEBUG: Taking gradient step
2023-01-03 15:59:48.226 DEBUG: Loss 3: {'policy_loss': -0.04191819440742891, 'entropy_loss': -0.04583204444497824, 'vf_loss': 0.014112812950931678, 'total_loss': -0.08775023885240715, 'approx_kl': -0.04074242990463972, 'clip_fraction': 0.31640625, 'grad_norm': 9.871603965759277}
2023-01-03 15:59:50.307 DEBUG: Taking gradient step
2023-01-03 15:59:52.346 DEBUG: Loss 4: {'policy_loss': 0.01303253767626908, 'entropy_loss': -0.04480062983930111, 'vf_loss': 0.016461791383572257, 'total_loss': -0.03176809216303203, 'approx_kl': -0.04500641534104943, 'clip_fraction': 0.37109375, 'grad_norm': 11.801990509033203}
2023-01-03 15:59:54.342 DEBUG: Taking gradient step
2023-01-03 15:59:56.391 DEBUG: Loss 5: {'policy_loss': 0.009070774573239838, 'entropy_loss': -0.04474411252886057, 'vf_loss': 0.01623357557421997, 'total_loss': -0.03567333795562073, 'approx_kl': -0.07191645819693804, 'clip_fraction': 0.4283854216337204, 'grad_norm': 12.942177772521973}
2023-01-03 15:59:58.380 DEBUG: Taking gradient step
2023-01-03 16:00:00.418 DEBUG: Loss 6: {'policy_loss': -0.062363645747510604, 'entropy_loss': -0.04514592792838812, 'vf_loss': 0.013713062067560877, 'total_loss': -0.10750957367589872, 'approx_kl': -0.06378910131752491, 'clip_fraction': 0.4166666716337204, 'grad_norm': 12.190954208374023}
2023-01-03 16:00:02.427 DEBUG: Taking gradient step
2023-01-03 16:00:04.463 DEBUG: Loss 7: {'policy_loss': -0.01978749480654786, 'entropy_loss': -0.04546594060957432, 'vf_loss': 0.014620389215719582, 'total_loss': -0.06525343541612218, 'approx_kl': -0.06934039294719696, 'clip_fraction': 0.4270833358168602, 'grad_norm': 11.71249771118164}
2023-01-03 16:00:06.462 DEBUG: Taking gradient step
2023-01-03 16:00:08.502 DEBUG: Loss 8: {'policy_loss': -0.011400253315464362, 'entropy_loss': -0.04483869578689337, 'vf_loss': 0.016013043410995825, 'total_loss': -0.05623894910235773, 'approx_kl': -0.07428956869989634, 'clip_fraction': 0.4244791716337204, 'grad_norm': 11.41260051727295}
2023-01-03 16:00:10.488 DEBUG: Taking gradient step
2023-01-03 16:00:12.526 DEBUG: Loss 9: {'policy_loss': 0.028306877514652946, 'entropy_loss': -0.04397585056722164, 'vf_loss': 0.018271142201861375, 'total_loss': -0.015668973052568702, 'approx_kl': -0.06475896359188482, 'clip_fraction': 0.4010416716337204, 'grad_norm': 22.16345977783203}
2023-01-03 16:00:14.524 DEBUG: Taking gradient step
2023-01-03 16:00:16.749 DEBUG: Loss 10: {'policy_loss': 0.03244855453347098, 'entropy_loss': -0.043892355635762215, 'vf_loss': 0.017966467109982162, 'total_loss': -0.011443801102291234, 'approx_kl': -0.07138578873127699, 'clip_fraction': 0.359375, 'grad_norm': 12.466314315795898}
2023-01-03 16:00:18.905 DEBUG: Taking gradient step
2023-01-03 16:00:20.946 DEBUG: Loss 11: {'policy_loss': -0.04970483239272512, 'entropy_loss': -0.04408652428537607, 'vf_loss': 0.014073449583323877, 'total_loss': -0.09379135667810119, 'approx_kl': -0.08434063382446766, 'clip_fraction': 0.3919270858168602, 'grad_norm': 9.29416561126709}
2023-01-03 16:00:22.936 DEBUG: Taking gradient step
2023-01-03 16:00:24.969 DEBUG: Loss 12: {'policy_loss': 0.012481680566407551, 'entropy_loss': -0.044442481361329556, 'vf_loss': 0.01614295576197282, 'total_loss': -0.031960800794922015, 'approx_kl': -0.08508945070207119, 'clip_fraction': 0.4036458358168602, 'grad_norm': 17.45973014831543}
2023-01-03 16:00:26.956 DEBUG: Taking gradient step
2023-01-03 16:00:28.993 DEBUG: Loss 13: {'policy_loss': 0.051210239855973845, 'entropy_loss': -0.044165488332509995, 'vf_loss': 0.017216986404860857, 'total_loss': 0.0070447515234638505, 'approx_kl': -0.10111035732552409, 'clip_fraction': 0.3763020858168602, 'grad_norm': 20.242143630981445}
2023-01-03 16:00:30.982 DEBUG: Taking gradient step
2023-01-03 16:00:33.008 DEBUG: Loss 14: {'policy_loss': 0.011530010279748079, 'entropy_loss': -0.04525161162018776, 'vf_loss': 0.01549545939938857, 'total_loss': -0.03372160134043968, 'approx_kl': -0.07136487681418657, 'clip_fraction': 0.4114583358168602, 'grad_norm': 15.06037712097168}
2023-01-03 16:00:33.009 INFO: Optimization: policy loss=0.012, vf loss=0.015, entropy loss=-0.045, total loss=-0.034, num steps=15
2023-01-03 16:00:33.010 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 16:00:34.133 DEBUG: Atoms are too close
2023-01-03 16:00:34.135 INFO: Evaluation rollout: return=-15.258 (0.0), episode length=5.0
2023-01-03 16:00:34.135 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 16:00:34.139 INFO: Iteration: 56/137, steps: 12096
2023-01-03 16:00:40.299 DEBUG: Atoms are too close
2023-01-03 16:00:42.638 DEBUG: Atoms are too close
2023-01-03 16:00:44.493 DEBUG: Atoms are too close
2023-01-03 16:00:47.353 DEBUG: Atoms are too close
2023-01-03 16:01:07.143 DEBUG: Atoms are too close
2023-01-03 16:01:30.269 INFO: Training rollout: return=-2.418 (6.5), episode length=5.8
2023-01-03 16:01:30.271 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 16:01:30.274 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-12096_train.pkl
2023-01-03 16:01:32.275 DEBUG: Taking gradient step
2023-01-03 16:01:34.410 DEBUG: Loss 0: {'policy_loss': -0.0075240608787538, 'entropy_loss': -0.04355239123106003, 'vf_loss': 0.018474251476221795, 'total_loss': -0.051076452109813826, 'approx_kl': 8.240264515180229e-08, 'clip_fraction': 0.0, 'grad_norm': 16.2721004486084}
2023-01-03 16:01:36.373 DEBUG: Taking gradient step
2023-01-03 16:01:38.387 DEBUG: Loss 1: {'policy_loss': 0.0586207403658675, 'entropy_loss': -0.04446649830788374, 'vf_loss': 0.02220135437851059, 'total_loss': 0.014154242057983768, 'approx_kl': -0.010109946480952203, 'clip_fraction': 0.1432291679084301, 'grad_norm': 16.821014404296875}
2023-01-03 16:01:40.377 DEBUG: Taking gradient step
2023-01-03 16:01:42.395 DEBUG: Loss 2: {'policy_loss': 0.010864921214307311, 'entropy_loss': -0.0441187908872962, 'vf_loss': 0.018177058537677523, 'total_loss': -0.03325386967298889, 'approx_kl': -0.03536703484132886, 'clip_fraction': 0.3098958358168602, 'grad_norm': 19.7282772064209}
2023-01-03 16:01:44.379 DEBUG: Taking gradient step
2023-01-03 16:01:46.413 DEBUG: Loss 3: {'policy_loss': 0.059789316315726586, 'entropy_loss': -0.04340518265962601, 'vf_loss': 0.0198223599618831, 'total_loss': 0.01638413365610058, 'approx_kl': -0.03229960519820452, 'clip_fraction': 0.3541666679084301, 'grad_norm': 26.819700241088867}
2023-01-03 16:01:48.396 DEBUG: Taking gradient step
2023-01-03 16:01:50.436 DEBUG: Loss 4: {'policy_loss': 0.011266605241846528, 'entropy_loss': -0.04504472855478525, 'vf_loss': 0.017799879384934734, 'total_loss': -0.033778123312938724, 'approx_kl': -0.03760330379009247, 'clip_fraction': 0.3828125, 'grad_norm': 19.81944465637207}
2023-01-03 16:01:52.413 DEBUG: Taking gradient step
2023-01-03 16:01:54.451 DEBUG: Loss 5: {'policy_loss': -0.007902266421100763, 'entropy_loss': -0.04618664085865021, 'vf_loss': 0.017092015992054663, 'total_loss': -0.05408890727975097, 'approx_kl': -0.04835312534123659, 'clip_fraction': 0.359375, 'grad_norm': 23.668941497802734}
2023-01-03 16:01:56.450 DEBUG: Taking gradient step
2023-01-03 16:01:58.495 DEBUG: Loss 6: {'policy_loss': 0.0515971215535127, 'entropy_loss': -0.04454284254461527, 'vf_loss': 0.021008376811614018, 'total_loss': 0.007054279008897428, 'approx_kl': -0.049406028469093144, 'clip_fraction': 0.3190104216337204, 'grad_norm': 34.10581970214844}
2023-01-03 16:02:00.477 DEBUG: Taking gradient step
2023-01-03 16:02:02.602 DEBUG: Loss 7: {'policy_loss': -0.00022382756835218932, 'entropy_loss': -0.044775666669011116, 'vf_loss': 0.017719386429264673, 'total_loss': -0.04499949423736331, 'approx_kl': -0.03954584849998355, 'clip_fraction': 0.2682291679084301, 'grad_norm': 16.484506607055664}
2023-01-03 16:02:04.657 DEBUG: Taking gradient step
2023-01-03 16:02:06.738 DEBUG: Loss 8: {'policy_loss': 0.009599038443984456, 'entropy_loss': -0.04469619505107403, 'vf_loss': 0.018087269319598136, 'total_loss': -0.03509715660708957, 'approx_kl': -0.04889335483312607, 'clip_fraction': 0.2721354216337204, 'grad_norm': 13.538128852844238}
2023-01-03 16:02:08.755 DEBUG: Taking gradient step
2023-01-03 16:02:10.865 DEBUG: Loss 9: {'policy_loss': 0.03494247013684816, 'entropy_loss': -0.045331764966249466, 'vf_loss': 0.019232580008854097, 'total_loss': -0.010389294829401305, 'approx_kl': -0.05649751238524914, 'clip_fraction': 0.3190104216337204, 'grad_norm': 19.601625442504883}
2023-01-03 16:02:13.065 DEBUG: Taking gradient step
2023-01-03 16:02:15.155 DEBUG: Loss 10: {'policy_loss': -0.03056756493537395, 'entropy_loss': -0.04374662600457668, 'vf_loss': 0.016012642010033423, 'total_loss': -0.07431419093995063, 'approx_kl': -0.08039726968854666, 'clip_fraction': 0.3528645858168602, 'grad_norm': 17.415922164916992}
2023-01-03 16:02:17.193 DEBUG: Taking gradient step
2023-01-03 16:02:19.279 DEBUG: Loss 11: {'policy_loss': 0.03002608473368029, 'entropy_loss': -0.043975504115223885, 'vf_loss': 0.01817804516230647, 'total_loss': -0.0139494193815436, 'approx_kl': -0.06768501363694668, 'clip_fraction': 0.3385416716337204, 'grad_norm': 33.61589050292969}
2023-01-03 16:02:21.300 DEBUG: Taking gradient step
2023-01-03 16:02:23.385 DEBUG: Loss 12: {'policy_loss': -0.0432627550448561, 'entropy_loss': -0.04422380402684212, 'vf_loss': 0.016146924828682487, 'total_loss': -0.08748655907169822, 'approx_kl': -0.07101122010499239, 'clip_fraction': 0.4127604216337204, 'grad_norm': 19.87681770324707}
2023-01-03 16:02:25.420 DEBUG: Taking gradient step
2023-01-03 16:02:27.588 DEBUG: Loss 13: {'policy_loss': 0.02592551801760249, 'entropy_loss': -0.044499523006379604, 'vf_loss': 0.019167345063376685, 'total_loss': -0.018574004988777114, 'approx_kl': -0.0776679259724915, 'clip_fraction': 0.41015625, 'grad_norm': 25.12152862548828}
2023-01-03 16:02:29.617 DEBUG: Taking gradient step
2023-01-03 16:02:31.705 DEBUG: Loss 14: {'policy_loss': -0.032713243580605934, 'entropy_loss': -0.043988198041915894, 'vf_loss': 0.016164398145554145, 'total_loss': -0.07670144162252183, 'approx_kl': -0.0705231111496687, 'clip_fraction': 0.3763020858168602, 'grad_norm': 18.249351501464844}
2023-01-03 16:02:31.706 INFO: Optimization: policy loss=-0.033, vf loss=0.016, entropy loss=-0.044, total loss=-0.077, num steps=15
2023-01-03 16:02:31.707 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 16:02:33.445 INFO: Evaluation rollout: return=0.514 (0.0), episode length=6.0
2023-01-03 16:02:33.446 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 16:02:33.449 INFO: Iteration: 57/137, steps: 12312
2023-01-03 16:02:43.294 DEBUG: Atoms are too close
2023-01-03 16:02:46.184 DEBUG: Atoms are too close
2023-01-03 16:02:47.191 DEBUG: Atoms are too close
2023-01-03 16:03:03.823 DEBUG: Atoms are too close
2023-01-03 16:03:22.259 DEBUG: Atoms are too close
2023-01-03 16:03:28.633 INFO: Training rollout: return=-2.300 (6.1), episode length=5.8
2023-01-03 16:03:28.635 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 16:03:28.638 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-12312_train.pkl
2023-01-03 16:03:30.718 DEBUG: Taking gradient step
2023-01-03 16:03:32.844 DEBUG: Loss 0: {'policy_loss': 0.013481981366003292, 'entropy_loss': -0.04460970312356949, 'vf_loss': 0.019395783768952367, 'total_loss': -0.031127721757566198, 'approx_kl': 8.58368984779645e-08, 'clip_fraction': 0.0, 'grad_norm': 14.742374420166016}
2023-01-03 16:03:34.891 DEBUG: Taking gradient step
2023-01-03 16:03:37.001 DEBUG: Loss 1: {'policy_loss': -0.004419034447371047, 'entropy_loss': -0.04361626598984003, 'vf_loss': 0.01866217936828728, 'total_loss': -0.048035300437211076, 'approx_kl': 0.000196681241504848, 'clip_fraction': 0.0859375, 'grad_norm': 10.40817928314209}
2023-01-03 16:03:39.035 DEBUG: Taking gradient step
2023-01-03 16:03:41.083 DEBUG: Loss 2: {'policy_loss': -0.011298386073138213, 'entropy_loss': -0.043611583299934864, 'vf_loss': 0.01774076862987745, 'total_loss': -0.054909969373073075, 'approx_kl': -0.027311684098094702, 'clip_fraction': 0.2083333358168602, 'grad_norm': 10.959433555603027}
2023-01-03 16:03:43.074 DEBUG: Taking gradient step
2023-01-03 16:03:45.111 DEBUG: Loss 3: {'policy_loss': -0.002931393091884619, 'entropy_loss': -0.04463799670338631, 'vf_loss': 0.017091542283176834, 'total_loss': -0.04756938979527092, 'approx_kl': -0.04873036174103618, 'clip_fraction': 0.3138020858168602, 'grad_norm': 13.945903778076172}
2023-01-03 16:03:47.093 DEBUG: Taking gradient step
2023-01-03 16:03:49.135 DEBUG: Loss 4: {'policy_loss': 0.02967571309663413, 'entropy_loss': -0.044000101275742054, 'vf_loss': 0.019275855652134532, 'total_loss': -0.014324388179107923, 'approx_kl': -0.051850884687155485, 'clip_fraction': 0.3684895858168602, 'grad_norm': 15.97130298614502}
2023-01-03 16:03:51.125 DEBUG: Taking gradient step
2023-01-03 16:03:53.183 DEBUG: Loss 5: {'policy_loss': -0.0023449385203941735, 'entropy_loss': -0.04576768632978201, 'vf_loss': 0.017753905091058706, 'total_loss': -0.048112624850176186, 'approx_kl': -0.06299460446462035, 'clip_fraction': 0.4010416716337204, 'grad_norm': 22.664825439453125}
2023-01-03 16:03:55.168 DEBUG: Taking gradient step
2023-01-03 16:03:57.214 DEBUG: Loss 6: {'policy_loss': 0.006276837620558966, 'entropy_loss': -0.04529933352023363, 'vf_loss': 0.017337650230209563, 'total_loss': -0.039022495899674665, 'approx_kl': -0.03800462931394577, 'clip_fraction': 0.4348958358168602, 'grad_norm': 8.472601890563965}
2023-01-03 16:03:59.209 DEBUG: Taking gradient step
2023-01-03 16:04:01.244 DEBUG: Loss 7: {'policy_loss': 0.021556755895891427, 'entropy_loss': -0.04516630154103041, 'vf_loss': 0.01783738626661936, 'total_loss': -0.023609545645138976, 'approx_kl': -0.08655492961406708, 'clip_fraction': 0.3828125, 'grad_norm': 12.56693172454834}
2023-01-03 16:04:03.234 DEBUG: Taking gradient step
2023-01-03 16:04:05.267 DEBUG: Loss 8: {'policy_loss': 0.02444754845118523, 'entropy_loss': -0.048721324652433395, 'vf_loss': 0.01918938358857612, 'total_loss': -0.024273776201248164, 'approx_kl': -0.07280442770570517, 'clip_fraction': 0.3411458358168602, 'grad_norm': 12.354658126831055}
2023-01-03 16:04:07.252 DEBUG: Taking gradient step
2023-01-03 16:04:09.283 DEBUG: Loss 9: {'policy_loss': -0.027130253093284186, 'entropy_loss': -0.04614548571407795, 'vf_loss': 0.01684481618774561, 'total_loss': -0.07327573880736213, 'approx_kl': -0.07965143211185932, 'clip_fraction': 0.328125, 'grad_norm': 11.071654319763184}
2023-01-03 16:04:11.270 DEBUG: Taking gradient step
2023-01-03 16:04:13.385 DEBUG: Loss 10: {'policy_loss': -0.002588629478559354, 'entropy_loss': -0.04687521047890186, 'vf_loss': 0.01727572495965004, 'total_loss': -0.04946383995746121, 'approx_kl': -0.08045250084251165, 'clip_fraction': 0.3138020858168602, 'grad_norm': 12.423013687133789}
2023-01-03 16:04:15.366 DEBUG: Taking gradient step
2023-01-03 16:04:17.394 DEBUG: Loss 11: {'policy_loss': -0.008989870382366663, 'entropy_loss': -0.04597317986190319, 'vf_loss': 0.018739256855523516, 'total_loss': -0.054963050244269854, 'approx_kl': -0.08267161622643471, 'clip_fraction': 0.3111979216337204, 'grad_norm': 20.678863525390625}
2023-01-03 16:04:19.368 DEBUG: Taking gradient step
2023-01-03 16:04:21.399 DEBUG: Loss 12: {'policy_loss': 0.021790477015860066, 'entropy_loss': -0.04572537820786238, 'vf_loss': 0.018262159021653485, 'total_loss': -0.02393490119200231, 'approx_kl': -0.09509529639035463, 'clip_fraction': 0.3606770858168602, 'grad_norm': 9.760093688964844}
2023-01-03 16:04:23.383 DEBUG: Taking gradient step
2023-01-03 16:04:25.415 DEBUG: Loss 13: {'policy_loss': -0.008136363240244904, 'entropy_loss': -0.045984250493347645, 'vf_loss': 0.018240014600382944, 'total_loss': -0.054120613733592546, 'approx_kl': -0.10209793597459793, 'clip_fraction': 0.35546875, 'grad_norm': 14.581708908081055}
2023-01-03 16:04:27.420 DEBUG: Taking gradient step
2023-01-03 16:04:29.480 DEBUG: Loss 14: {'policy_loss': -0.00644147653128533, 'entropy_loss': -0.0456159021705389, 'vf_loss': 0.01747042074025567, 'total_loss': -0.05205737870182423, 'approx_kl': -0.08673328626900911, 'clip_fraction': 0.3880208358168602, 'grad_norm': 11.418978691101074}
2023-01-03 16:04:29.481 INFO: Optimization: policy loss=-0.006, vf loss=0.017, entropy loss=-0.046, total loss=-0.052, num steps=15
2023-01-03 16:04:29.482 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 16:04:31.189 INFO: Evaluation rollout: return=0.449 (0.0), episode length=6.0
2023-01-03 16:04:31.189 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 16:04:31.192 INFO: Iteration: 58/137, steps: 12528
2023-01-03 16:04:39.234 DEBUG: Atoms are too close
2023-01-03 16:04:45.474 DEBUG: Atoms are too close
2023-01-03 16:05:02.824 DEBUG: There is a single atom floating around
2023-01-03 16:05:04.822 DEBUG: Atoms are too close
2023-01-03 16:05:13.475 DEBUG: Atoms are too close
2023-01-03 16:05:26.982 INFO: Training rollout: return=-2.421 (6.6), episode length=5.8
2023-01-03 16:05:26.983 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 16:05:26.987 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-12528_train.pkl
2023-01-03 16:05:29.021 DEBUG: Taking gradient step
2023-01-03 16:05:31.082 DEBUG: Loss 0: {'policy_loss': -0.01638328341216611, 'entropy_loss': -0.04628566652536392, 'vf_loss': 0.017120084254073326, 'total_loss': -0.06266894993753003, 'approx_kl': -1.1369896579793703e-08, 'clip_fraction': 0.0, 'grad_norm': 13.993520736694336}
2023-01-03 16:05:33.107 DEBUG: Taking gradient step
2023-01-03 16:05:35.209 DEBUG: Loss 1: {'policy_loss': -0.04390209424887837, 'entropy_loss': -0.046954790130257607, 'vf_loss': 0.01659912325068916, 'total_loss': -0.09085688437913597, 'approx_kl': 0.004602352622896433, 'clip_fraction': 0.08984375, 'grad_norm': 11.966221809387207}
2023-01-03 16:05:37.265 DEBUG: Taking gradient step
2023-01-03 16:05:39.376 DEBUG: Loss 2: {'policy_loss': -0.01253018900427804, 'entropy_loss': -0.046639811247587204, 'vf_loss': 0.017040756935596625, 'total_loss': -0.05917000025186524, 'approx_kl': -0.019640991697087884, 'clip_fraction': 0.22265625, 'grad_norm': 13.436800003051758}
2023-01-03 16:05:41.410 DEBUG: Taking gradient step
2023-01-03 16:05:43.445 DEBUG: Loss 3: {'policy_loss': 0.0024694808009159664, 'entropy_loss': -0.0462688934057951, 'vf_loss': 0.01725357716429763, 'total_loss': -0.04379941260487913, 'approx_kl': -0.030232298595365137, 'clip_fraction': 0.3958333358168602, 'grad_norm': 19.218711853027344}
2023-01-03 16:05:45.443 DEBUG: Taking gradient step
2023-01-03 16:05:47.494 DEBUG: Loss 4: {'policy_loss': 0.10355155458626096, 'entropy_loss': -0.044365848414599895, 'vf_loss': 0.020730722245547527, 'total_loss': 0.059185706171661065, 'approx_kl': -0.04018670227378607, 'clip_fraction': 0.42578125, 'grad_norm': 38.68242645263672}
2023-01-03 16:05:49.528 DEBUG: Taking gradient step
2023-01-03 16:05:51.598 DEBUG: Loss 5: {'policy_loss': -0.0007174694591323486, 'entropy_loss': -0.04486638493835926, 'vf_loss': 0.01621874563585237, 'total_loss': -0.045583854397491616, 'approx_kl': -0.047650019405409694, 'clip_fraction': 0.4283854216337204, 'grad_norm': 22.695703506469727}
2023-01-03 16:05:53.612 DEBUG: Taking gradient step
2023-01-03 16:05:55.692 DEBUG: Loss 6: {'policy_loss': 0.03832813057729626, 'entropy_loss': -0.04507057182490826, 'vf_loss': 0.01807747844735838, 'total_loss': -0.006742441247611997, 'approx_kl': -0.08351864572614431, 'clip_fraction': 0.4466145858168602, 'grad_norm': 21.888017654418945}
2023-01-03 16:05:57.681 DEBUG: Taking gradient step
2023-01-03 16:05:59.807 DEBUG: Loss 7: {'policy_loss': 0.059184338969844395, 'entropy_loss': -0.043204473331570625, 'vf_loss': 0.019176490547729207, 'total_loss': 0.01597986563827377, 'approx_kl': -0.052489486057311296, 'clip_fraction': 0.390625, 'grad_norm': 28.92545509338379}
2023-01-03 16:06:01.792 DEBUG: Taking gradient step
2023-01-03 16:06:03.831 DEBUG: Loss 8: {'policy_loss': 0.05848473623297201, 'entropy_loss': -0.04455048497766256, 'vf_loss': 0.01863425688316611, 'total_loss': 0.013934251255309449, 'approx_kl': -0.06772095058113337, 'clip_fraction': 0.3606770858168602, 'grad_norm': 14.338418960571289}
2023-01-03 16:06:05.826 DEBUG: Taking gradient step
2023-01-03 16:06:07.867 DEBUG: Loss 9: {'policy_loss': 0.04907396715698874, 'entropy_loss': -0.043988640420138836, 'vf_loss': 0.019207820097728624, 'total_loss': 0.005085326736849902, 'approx_kl': -0.052292272448539734, 'clip_fraction': 0.3658854216337204, 'grad_norm': 12.640616416931152}
2023-01-03 16:06:09.855 DEBUG: Taking gradient step
2023-01-03 16:06:11.889 DEBUG: Loss 10: {'policy_loss': -0.034338495591768686, 'entropy_loss': -0.043019755743443966, 'vf_loss': 0.016477745526590204, 'total_loss': -0.07735825133521265, 'approx_kl': -0.08923535607755184, 'clip_fraction': 0.4427083358168602, 'grad_norm': 18.650653839111328}
2023-01-03 16:06:13.865 DEBUG: Taking gradient step
2023-01-03 16:06:15.904 DEBUG: Loss 11: {'policy_loss': 0.05106130192022852, 'entropy_loss': -0.04278783220797777, 'vf_loss': 0.018495248650300035, 'total_loss': 0.008273469712250753, 'approx_kl': -0.08355801831930876, 'clip_fraction': 0.5013020858168602, 'grad_norm': 37.500877380371094}
2023-01-03 16:06:17.905 DEBUG: Taking gradient step
2023-01-03 16:06:20.032 DEBUG: Loss 12: {'policy_loss': 0.035335274275610444, 'entropy_loss': -0.04345139302313328, 'vf_loss': 0.018579135347799806, 'total_loss': -0.008116118747522834, 'approx_kl': -0.08585235755890608, 'clip_fraction': 0.4908854216337204, 'grad_norm': 20.58124351501465}
2023-01-03 16:06:22.091 DEBUG: Taking gradient step
2023-01-03 16:06:24.222 DEBUG: Loss 13: {'policy_loss': -0.045331337004234876, 'entropy_loss': -0.04334022291004658, 'vf_loss': 0.01571446628641529, 'total_loss': -0.08867155991428145, 'approx_kl': -0.07902265153825283, 'clip_fraction': 0.48046875, 'grad_norm': 11.124135971069336}
2023-01-03 16:06:26.320 DEBUG: Taking gradient step
2023-01-03 16:06:28.449 DEBUG: Loss 14: {'policy_loss': 0.0013557970745476204, 'entropy_loss': -0.04264582321047783, 'vf_loss': 0.017738185428165888, 'total_loss': -0.04129002613593021, 'approx_kl': -0.10242103599011898, 'clip_fraction': 0.390625, 'grad_norm': 10.724807739257812}
2023-01-03 16:06:28.449 INFO: Optimization: policy loss=0.001, vf loss=0.018, entropy loss=-0.043, total loss=-0.041, num steps=15
2023-01-03 16:06:28.451 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 16:06:30.216 INFO: Evaluation rollout: return=0.518 (0.0), episode length=6.0
2023-01-03 16:06:30.217 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 16:06:30.220 INFO: Iteration: 59/137, steps: 12744
2023-01-03 16:06:42.342 DEBUG: Atoms are too close
2023-01-03 16:07:27.605 INFO: Training rollout: return=-0.088 (3.0), episode length=5.9
2023-01-03 16:07:27.607 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 16:07:27.610 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-12744_train.pkl
2023-01-03 16:07:29.662 DEBUG: Taking gradient step
2023-01-03 16:07:31.749 DEBUG: Loss 0: {'policy_loss': -0.019770294665377934, 'entropy_loss': -0.04459806811064482, 'vf_loss': 0.0046253996104252265, 'total_loss': -0.06436836277602276, 'approx_kl': 6.189414758495104e-09, 'clip_fraction': 0.0, 'grad_norm': 12.9694185256958}
2023-01-03 16:07:33.777 DEBUG: Taking gradient step
2023-01-03 16:07:35.856 DEBUG: Loss 1: {'policy_loss': -0.015581719092035439, 'entropy_loss': -0.04337231442332268, 'vf_loss': 0.004619212881230114, 'total_loss': -0.05895403351535812, 'approx_kl': -0.011838855687528849, 'clip_fraction': 0.06510416697710752, 'grad_norm': 18.257787704467773}
2023-01-03 16:07:37.876 DEBUG: Taking gradient step
2023-01-03 16:07:39.953 DEBUG: Loss 2: {'policy_loss': -0.006085953900881826, 'entropy_loss': -0.04360540024936199, 'vf_loss': 0.0045998789785793946, 'total_loss': -0.04969135415024382, 'approx_kl': -0.03189920913428068, 'clip_fraction': 0.2669270858168602, 'grad_norm': 22.821128845214844}
2023-01-03 16:07:41.991 DEBUG: Taking gradient step
2023-01-03 16:07:44.070 DEBUG: Loss 3: {'policy_loss': 0.01124389400712985, 'entropy_loss': -0.044048127718269825, 'vf_loss': 0.004454095796218848, 'total_loss': -0.032804233711139975, 'approx_kl': -0.032927727326750755, 'clip_fraction': 0.4049479216337204, 'grad_norm': 17.23189353942871}
2023-01-03 16:07:46.088 DEBUG: Taking gradient step
2023-01-03 16:07:48.167 DEBUG: Loss 4: {'policy_loss': 0.003377028793014901, 'entropy_loss': -0.04359293635934591, 'vf_loss': 0.004411007619293543, 'total_loss': -0.040215907566331005, 'approx_kl': -0.03101552790030837, 'clip_fraction': 0.4075520858168602, 'grad_norm': 11.695517539978027}
2023-01-03 16:07:50.276 DEBUG: Taking gradient step
2023-01-03 16:07:52.353 DEBUG: Loss 5: {'policy_loss': 0.04610748830999907, 'entropy_loss': -0.043375623412430286, 'vf_loss': 0.004989627087462735, 'total_loss': 0.0027318648975687768, 'approx_kl': -0.04207678185775876, 'clip_fraction': 0.40234375, 'grad_norm': 16.78801155090332}
2023-01-03 16:07:54.371 DEBUG: Taking gradient step
2023-01-03 16:07:56.448 DEBUG: Loss 6: {'policy_loss': -0.00565012373316944, 'entropy_loss': -0.04444160405546427, 'vf_loss': 0.004201518634538079, 'total_loss': -0.0500917277886337, 'approx_kl': -0.03411850892007351, 'clip_fraction': 0.4049479216337204, 'grad_norm': 7.7439703941345215}
2023-01-03 16:07:58.465 DEBUG: Taking gradient step
2023-01-03 16:08:00.577 DEBUG: Loss 7: {'policy_loss': -0.022342450379234997, 'entropy_loss': -0.043467286974191666, 'vf_loss': 0.004072993329430813, 'total_loss': -0.06580973735342666, 'approx_kl': -0.032853020122274756, 'clip_fraction': 0.38671875, 'grad_norm': 6.180119514465332}
2023-01-03 16:08:02.745 DEBUG: Taking gradient step
2023-01-03 16:08:04.880 DEBUG: Loss 8: {'policy_loss': 0.025662170731327802, 'entropy_loss': -0.04349910840392113, 'vf_loss': 0.0048631324894459005, 'total_loss': -0.017836937672593325, 'approx_kl': -0.029859038069844246, 'clip_fraction': 0.2838541679084301, 'grad_norm': 9.24397087097168}
2023-01-03 16:08:06.965 DEBUG: Taking gradient step
2023-01-03 16:08:09.211 DEBUG: Loss 9: {'policy_loss': 0.02484745137119152, 'entropy_loss': -0.04294984322041273, 'vf_loss': 0.004526561217585221, 'total_loss': -0.01810239184922121, 'approx_kl': -0.04898527218028903, 'clip_fraction': 0.30078125, 'grad_norm': 22.056406021118164}
2023-01-03 16:08:11.459 DEBUG: Taking gradient step
2023-01-03 16:08:13.538 DEBUG: Loss 10: {'policy_loss': -0.009530585329363676, 'entropy_loss': -0.04276037123054266, 'vf_loss': 0.003726082240210123, 'total_loss': -0.05229095655990633, 'approx_kl': -0.068321093916893, 'clip_fraction': 0.390625, 'grad_norm': 20.52362823486328}
2023-01-03 16:08:15.574 DEBUG: Taking gradient step
2023-01-03 16:08:17.653 DEBUG: Loss 11: {'policy_loss': 0.07722298758019282, 'entropy_loss': -0.04392492305487394, 'vf_loss': 0.005075140548243022, 'total_loss': 0.033298064525318874, 'approx_kl': -0.07647449430078268, 'clip_fraction': 0.359375, 'grad_norm': 35.79179382324219}
2023-01-03 16:08:19.682 DEBUG: Taking gradient step
2023-01-03 16:08:21.778 DEBUG: Loss 12: {'policy_loss': -0.021848089220979208, 'entropy_loss': -0.042945208959281445, 'vf_loss': 0.0035410893771900833, 'total_loss': -0.06479329818026065, 'approx_kl': -0.06615215912461281, 'clip_fraction': 0.4140625, 'grad_norm': 11.346708297729492}
2023-01-03 16:08:23.813 DEBUG: Taking gradient step
2023-01-03 16:08:25.893 DEBUG: Loss 13: {'policy_loss': 0.021040375068396604, 'entropy_loss': -0.042776985093951225, 'vf_loss': 0.004506982183762013, 'total_loss': -0.02173661002555462, 'approx_kl': -0.07416357658803463, 'clip_fraction': 0.55078125, 'grad_norm': 7.735860347747803}
2023-01-03 16:08:27.913 DEBUG: Taking gradient step
2023-01-03 16:08:30.041 DEBUG: Loss 14: {'policy_loss': -0.025313543002895417, 'entropy_loss': -0.041954451240599155, 'vf_loss': 0.003470751850925155, 'total_loss': -0.06726799424349457, 'approx_kl': -0.059678987483493984, 'clip_fraction': 0.5130208358168602, 'grad_norm': 12.53769302368164}
2023-01-03 16:08:30.041 INFO: Optimization: policy loss=-0.025, vf loss=0.003, entropy loss=-0.042, total loss=-0.067, num steps=15
2023-01-03 16:08:30.042 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 16:08:31.737 INFO: Evaluation rollout: return=0.365 (0.0), episode length=6.0
2023-01-03 16:08:31.738 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 16:08:31.741 INFO: Iteration: 60/137, steps: 12960
2023-01-03 16:08:42.414 DEBUG: Atoms are too close
2023-01-03 16:09:01.161 DEBUG: Atoms are too close
2023-01-03 16:09:03.615 DEBUG: Atoms are too close
2023-01-03 16:09:03.617 DEBUG: Atoms are too close
2023-01-03 16:09:05.838 DEBUG: Atoms are too close
2023-01-03 16:09:28.908 INFO: Training rollout: return=-1.884 (5.7), episode length=5.8
2023-01-03 16:09:28.909 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 16:09:28.913 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-12960_train.pkl
2023-01-03 16:09:30.956 DEBUG: Taking gradient step
2023-01-03 16:09:33.065 DEBUG: Loss 0: {'policy_loss': -0.009674608385115569, 'entropy_loss': -0.04262866638600826, 'vf_loss': 0.015225314078964863, 'total_loss': -0.05230327477112383, 'approx_kl': 2.11099777658319e-08, 'clip_fraction': 0.0, 'grad_norm': 16.26329231262207}
2023-01-03 16:09:35.223 DEBUG: Taking gradient step
2023-01-03 16:09:37.463 DEBUG: Loss 1: {'policy_loss': 0.0006386293982488939, 'entropy_loss': -0.04327932558953762, 'vf_loss': 0.01679383092336734, 'total_loss': -0.04264069619128873, 'approx_kl': -0.0190110340481624, 'clip_fraction': 0.1744791679084301, 'grad_norm': 16.530183792114258}
2023-01-03 16:09:39.558 DEBUG: Taking gradient step
2023-01-03 16:09:41.707 DEBUG: Loss 2: {'policy_loss': -0.016802650528832303, 'entropy_loss': -0.04299580957740545, 'vf_loss': 0.014758369349177018, 'total_loss': -0.05979846010623775, 'approx_kl': -0.03322394797578454, 'clip_fraction': 0.34765625, 'grad_norm': 14.422469139099121}
2023-01-03 16:09:43.721 DEBUG: Taking gradient step
2023-01-03 16:09:45.984 DEBUG: Loss 3: {'policy_loss': -0.008021308981910082, 'entropy_loss': -0.042419807985424995, 'vf_loss': 0.01520546782681697, 'total_loss': -0.05044111696733507, 'approx_kl': -0.035102568566799164, 'clip_fraction': 0.4296875, 'grad_norm': 14.8893404006958}
2023-01-03 16:09:48.012 DEBUG: Taking gradient step
2023-01-03 16:09:50.100 DEBUG: Loss 4: {'policy_loss': 0.025438846545794105, 'entropy_loss': -0.042177353985607624, 'vf_loss': 0.01744119738649866, 'total_loss': -0.016738507439813515, 'approx_kl': -0.05193779803812504, 'clip_fraction': 0.4348958358168602, 'grad_norm': 14.303709983825684}
2023-01-03 16:09:52.089 DEBUG: Taking gradient step
2023-01-03 16:09:54.167 DEBUG: Loss 5: {'policy_loss': 3.341248820259296e-05, 'entropy_loss': -0.04442295525223017, 'vf_loss': 0.014630090466770327, 'total_loss': -0.044389542764027574, 'approx_kl': -0.06694408692419529, 'clip_fraction': 0.4270833358168602, 'grad_norm': 15.102925300598145}
2023-01-03 16:09:56.186 DEBUG: Taking gradient step
2023-01-03 16:09:58.224 DEBUG: Loss 6: {'policy_loss': 0.0361526897360349, 'entropy_loss': -0.04386854823678732, 'vf_loss': 0.015175404958961563, 'total_loss': -0.007715858500752416, 'approx_kl': -0.05562460282817483, 'clip_fraction': 0.45703125, 'grad_norm': 21.422252655029297}
2023-01-03 16:10:00.255 DEBUG: Taking gradient step
2023-01-03 16:10:02.332 DEBUG: Loss 7: {'policy_loss': -0.017785848629936894, 'entropy_loss': -0.04362041316926479, 'vf_loss': 0.01418344457945476, 'total_loss': -0.061406261799201695, 'approx_kl': -0.06921374215744436, 'clip_fraction': 0.4505208358168602, 'grad_norm': 15.277936935424805}
2023-01-03 16:10:04.330 DEBUG: Taking gradient step
2023-01-03 16:10:06.427 DEBUG: Loss 8: {'policy_loss': 0.03914398184580121, 'entropy_loss': -0.04392418731004, 'vf_loss': 0.0174273213062071, 'total_loss': -0.004780205464238789, 'approx_kl': -0.07401890167966485, 'clip_fraction': 0.3958333358168602, 'grad_norm': 17.76643180847168}
2023-01-03 16:10:08.434 DEBUG: Taking gradient step
2023-01-03 16:10:10.503 DEBUG: Loss 9: {'policy_loss': -0.05277053708948566, 'entropy_loss': -0.04314956162124872, 'vf_loss': 0.013888266795045238, 'total_loss': -0.09592009871073438, 'approx_kl': -0.05402727052569389, 'clip_fraction': 0.41015625, 'grad_norm': 11.251890182495117}
2023-01-03 16:10:12.508 DEBUG: Taking gradient step
2023-01-03 16:10:14.548 DEBUG: Loss 10: {'policy_loss': -0.016642989464921102, 'entropy_loss': -0.04476359952241182, 'vf_loss': 0.016379989955852665, 'total_loss': -0.06140658898733292, 'approx_kl': -0.07914377981796861, 'clip_fraction': 0.3997395858168602, 'grad_norm': 12.910508155822754}
2023-01-03 16:10:16.571 DEBUG: Taking gradient step
2023-01-03 16:10:18.650 DEBUG: Loss 11: {'policy_loss': -0.04693869465535428, 'entropy_loss': -0.043353818356990814, 'vf_loss': 0.014419755388477513, 'total_loss': -0.09029251301234509, 'approx_kl': -0.045592318288981915, 'clip_fraction': 0.3697916716337204, 'grad_norm': 9.774332046508789}
2023-01-03 16:10:20.661 DEBUG: Taking gradient step
2023-01-03 16:10:22.706 DEBUG: Loss 12: {'policy_loss': -0.0012160480741947814, 'entropy_loss': -0.04420015309005976, 'vf_loss': 0.016809288295534616, 'total_loss': -0.04541620116425454, 'approx_kl': -0.08140472788363695, 'clip_fraction': 0.34765625, 'grad_norm': 14.077153205871582}
2023-01-03 16:10:24.706 DEBUG: Taking gradient step
2023-01-03 16:10:26.759 DEBUG: Loss 13: {'policy_loss': -0.020008805508370427, 'entropy_loss': -0.04541355650871992, 'vf_loss': 0.01547657392165997, 'total_loss': -0.06542236201709034, 'approx_kl': -0.06922223139554262, 'clip_fraction': 0.3893229216337204, 'grad_norm': 17.61970329284668}
2023-01-03 16:10:28.767 DEBUG: Taking gradient step
2023-01-03 16:10:30.908 DEBUG: Loss 14: {'policy_loss': -0.030026617747136414, 'entropy_loss': -0.04450386669486761, 'vf_loss': 0.014616936910571492, 'total_loss': -0.07453048444200402, 'approx_kl': -0.08157155103981495, 'clip_fraction': 0.4231770858168602, 'grad_norm': 16.494754791259766}
2023-01-03 16:10:30.909 INFO: Optimization: policy loss=-0.030, vf loss=0.015, entropy loss=-0.045, total loss=-0.075, num steps=15
2023-01-03 16:10:30.910 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 16:10:32.594 INFO: Evaluation rollout: return=0.401 (0.0), episode length=6.0
2023-01-03 16:10:32.595 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 16:10:32.597 DEBUG: Deleting old model: runs/CH3NO_dna/models/CH3NO_dna_run-1_steps-11016.model
2023-01-03 16:10:32.604 DEBUG: Saving model: runs/CH3NO_dna/models/CH3NO_dna_run-1_steps-13176.model
2023-01-03 16:10:32.652 INFO: Iteration: 61/137, steps: 13176
2023-01-03 16:10:46.791 DEBUG: Atoms are too close
2023-01-03 16:10:47.069 DEBUG: Atoms are too close
2023-01-03 16:11:00.390 DEBUG: There is a single atom floating around
2023-01-03 16:11:05.786 DEBUG: Atoms are too close
2023-01-03 16:11:22.761 DEBUG: Atoms are too close
2023-01-03 16:11:28.707 INFO: Training rollout: return=-1.863 (5.7), episode length=5.8
2023-01-03 16:11:28.709 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 16:11:28.711 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-13176_train.pkl
2023-01-03 16:11:31.166 DEBUG: Taking gradient step
2023-01-03 16:11:33.711 DEBUG: Loss 0: {'policy_loss': 0.12426742536805842, 'entropy_loss': -0.04300456587225199, 'vf_loss': 0.022408043598664613, 'total_loss': 0.08126285949580643, 'approx_kl': 7.761080667023634e-11, 'clip_fraction': 0.0, 'grad_norm': 20.267793655395508}
2023-01-03 16:11:36.138 DEBUG: Taking gradient step
2023-01-03 16:11:38.651 DEBUG: Loss 1: {'policy_loss': -0.026620792633046723, 'entropy_loss': -0.04185052029788494, 'vf_loss': 0.014770849073517658, 'total_loss': -0.06847131293093167, 'approx_kl': -0.0015329504385590553, 'clip_fraction': 0.06510416697710752, 'grad_norm': 16.74563217163086}
2023-01-03 16:11:41.332 DEBUG: Taking gradient step
2023-01-03 16:11:43.827 DEBUG: Loss 2: {'policy_loss': 0.03645562131413708, 'entropy_loss': -0.04304071981459856, 'vf_loss': 0.017947839401326684, 'total_loss': -0.006585098500461482, 'approx_kl': -0.0023535462096333504, 'clip_fraction': 0.1822916679084301, 'grad_norm': 17.01932144165039}
2023-01-03 16:11:46.235 DEBUG: Taking gradient step
2023-01-03 16:11:48.669 DEBUG: Loss 3: {'policy_loss': 0.026920977610185394, 'entropy_loss': -0.04336331319063902, 'vf_loss': 0.017555855146173523, 'total_loss': -0.016442335580453632, 'approx_kl': -0.015056878328323364, 'clip_fraction': 0.15104166697710752, 'grad_norm': 27.258241653442383}
2023-01-03 16:11:51.056 DEBUG: Taking gradient step
2023-01-03 16:11:53.523 DEBUG: Loss 4: {'policy_loss': -0.01782554335087643, 'entropy_loss': -0.04129147529602051, 'vf_loss': 0.015061710545356502, 'total_loss': -0.05911701864689694, 'approx_kl': -0.011279827682301402, 'clip_fraction': 0.203125, 'grad_norm': 12.803043365478516}
2023-01-03 16:11:55.917 DEBUG: Taking gradient step
2023-01-03 16:11:58.351 DEBUG: Loss 5: {'policy_loss': -0.010083528875015684, 'entropy_loss': -0.04326668754220009, 'vf_loss': 0.015311221261532459, 'total_loss': -0.05335021641721577, 'approx_kl': -0.01503512216731906, 'clip_fraction': 0.26171875, 'grad_norm': 12.131036758422852}
2023-01-03 16:12:00.727 DEBUG: Taking gradient step
2023-01-03 16:12:03.180 DEBUG: Loss 6: {'policy_loss': 0.014116300527224082, 'entropy_loss': -0.042344365268945694, 'vf_loss': 0.0167979924788771, 'total_loss': -0.028228064741721612, 'approx_kl': -0.025344333611428738, 'clip_fraction': 0.2239583358168602, 'grad_norm': 13.590794563293457}
2023-01-03 16:12:05.560 DEBUG: Taking gradient step
2023-01-03 16:12:08.035 DEBUG: Loss 7: {'policy_loss': -0.010755783712184067, 'entropy_loss': -0.0432847049087286, 'vf_loss': 0.015794530149793515, 'total_loss': -0.054040488620912666, 'approx_kl': -0.01896216720342636, 'clip_fraction': 0.1731770858168602, 'grad_norm': 13.345736503601074}
2023-01-03 16:12:10.080 DEBUG: Taking gradient step
2023-01-03 16:12:12.143 DEBUG: Loss 8: {'policy_loss': 0.020880340277480893, 'entropy_loss': -0.04363223258405924, 'vf_loss': 0.017496951144613734, 'total_loss': -0.02275189230657835, 'approx_kl': -0.02446014992892742, 'clip_fraction': 0.16927083395421505, 'grad_norm': 15.378799438476562}
2023-01-03 16:12:14.131 DEBUG: Taking gradient step
2023-01-03 16:12:16.159 DEBUG: Loss 9: {'policy_loss': 0.02266836289039814, 'entropy_loss': -0.04298489820212126, 'vf_loss': 0.01652698799698988, 'total_loss': -0.020316535311723116, 'approx_kl': -0.0428624558262527, 'clip_fraction': 0.2122395858168602, 'grad_norm': 19.609342575073242}
2023-01-03 16:12:18.165 DEBUG: Taking gradient step
2023-01-03 16:12:20.202 DEBUG: Loss 10: {'policy_loss': 0.010427974046508793, 'entropy_loss': -0.04176444746553898, 'vf_loss': 0.016204689186230255, 'total_loss': -0.03133647341903019, 'approx_kl': -0.032651510555297136, 'clip_fraction': 0.1731770858168602, 'grad_norm': 18.730133056640625}
2023-01-03 16:12:22.208 DEBUG: Taking gradient step
2023-01-03 16:12:24.355 DEBUG: Loss 11: {'policy_loss': -0.051200803069799225, 'entropy_loss': -0.043573424220085144, 'vf_loss': 0.013616705691537312, 'total_loss': -0.09477422728988437, 'approx_kl': -0.052813324611634016, 'clip_fraction': 0.1848958358168602, 'grad_norm': 12.427639961242676}
2023-01-03 16:12:26.353 DEBUG: Taking gradient step
2023-01-03 16:12:28.408 DEBUG: Loss 12: {'policy_loss': 0.006271355519576312, 'entropy_loss': -0.041865771636366844, 'vf_loss': 0.016571506208327966, 'total_loss': -0.03559441611679053, 'approx_kl': -0.04459336772561073, 'clip_fraction': 0.25, 'grad_norm': 12.332596778869629}
2023-01-03 16:12:30.396 DEBUG: Taking gradient step
2023-01-03 16:12:32.452 DEBUG: Loss 13: {'policy_loss': 0.017890981152043014, 'entropy_loss': -0.04325205460190773, 'vf_loss': 0.01627017580868627, 'total_loss': -0.025361073449864713, 'approx_kl': -0.05870278796646744, 'clip_fraction': 0.2864583358168602, 'grad_norm': 11.554113388061523}
2023-01-03 16:12:34.441 DEBUG: Taking gradient step
2023-01-03 16:12:36.498 DEBUG: Loss 14: {'policy_loss': 0.03013953148167542, 'entropy_loss': -0.04125591181218624, 'vf_loss': 0.01613783460084621, 'total_loss': -0.011116380330510822, 'approx_kl': -0.03813815303146839, 'clip_fraction': 0.25, 'grad_norm': 14.040916442871094}
2023-01-03 16:12:36.499 INFO: Optimization: policy loss=0.030, vf loss=0.016, entropy loss=-0.041, total loss=-0.011, num steps=15
2023-01-03 16:12:36.500 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 16:12:38.223 INFO: Evaluation rollout: return=0.434 (0.0), episode length=6.0
2023-01-03 16:12:38.224 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 16:12:38.227 INFO: Iteration: 62/137, steps: 13392
2023-01-03 16:12:49.312 DEBUG: Atoms are too close
2023-01-03 16:13:05.253 DEBUG: Atoms are too close
2023-01-03 16:13:10.616 DEBUG: Atoms are too close
2023-01-03 16:13:26.444 DEBUG: Atoms are too close
2023-01-03 16:13:31.325 DEBUG: Atoms are too close
2023-01-03 16:13:34.616 INFO: Training rollout: return=-2.308 (6.1), episode length=5.8
2023-01-03 16:13:34.618 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 16:13:34.620 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-13392_train.pkl
2023-01-03 16:13:36.646 DEBUG: Taking gradient step
2023-01-03 16:13:38.853 DEBUG: Loss 0: {'policy_loss': -0.026352881333431007, 'entropy_loss': -0.04094322118908167, 'vf_loss': 0.017208274966533408, 'total_loss': -0.06729610252251267, 'approx_kl': 5.814945325255394e-08, 'clip_fraction': 0.0, 'grad_norm': 12.201991081237793}
2023-01-03 16:13:40.888 DEBUG: Taking gradient step
2023-01-03 16:13:42.968 DEBUG: Loss 1: {'policy_loss': 0.020456549570623667, 'entropy_loss': -0.03952509583905339, 'vf_loss': 0.020762464850480594, 'total_loss': -0.01906854626842973, 'approx_kl': -0.009066933766007423, 'clip_fraction': 0.026041666977107525, 'grad_norm': 17.984560012817383}
2023-01-03 16:13:45.002 DEBUG: Taking gradient step
2023-01-03 16:13:47.093 DEBUG: Loss 2: {'policy_loss': -0.0030222270485312334, 'entropy_loss': -0.040565687231719494, 'vf_loss': 0.020832966787094287, 'total_loss': -0.04358791428025072, 'approx_kl': -0.008975678123533726, 'clip_fraction': 0.2486979216337204, 'grad_norm': 11.076180458068848}
2023-01-03 16:13:49.351 DEBUG: Taking gradient step
2023-01-03 16:13:51.398 DEBUG: Loss 3: {'policy_loss': -0.03938130205855753, 'entropy_loss': -0.04091783706098795, 'vf_loss': 0.017905546161397556, 'total_loss': -0.08029913911954548, 'approx_kl': -0.03097774786874652, 'clip_fraction': 0.3671875, 'grad_norm': 7.743630886077881}
2023-01-03 16:13:53.393 DEBUG: Taking gradient step
2023-01-03 16:13:55.452 DEBUG: Loss 4: {'policy_loss': -0.0703412733856182, 'entropy_loss': -0.04148881323635578, 'vf_loss': 0.017109915098039285, 'total_loss': -0.11183008662197398, 'approx_kl': -0.03286014392506331, 'clip_fraction': 0.37109375, 'grad_norm': 7.76212215423584}
2023-01-03 16:13:57.436 DEBUG: Taking gradient step
2023-01-03 16:13:59.473 DEBUG: Loss 5: {'policy_loss': -0.03637020541817086, 'entropy_loss': -0.04323226306587458, 'vf_loss': 0.01832571102217343, 'total_loss': -0.07960246848404544, 'approx_kl': -0.04341281880624592, 'clip_fraction': 0.4036458358168602, 'grad_norm': 5.292002201080322}
2023-01-03 16:14:01.460 DEBUG: Taking gradient step
2023-01-03 16:14:03.507 DEBUG: Loss 6: {'policy_loss': -0.01786204226123789, 'entropy_loss': -0.04270146042108536, 'vf_loss': 0.019338539594106766, 'total_loss': -0.060563502682323245, 'approx_kl': -0.038691038731485605, 'clip_fraction': 0.3893229216337204, 'grad_norm': 9.666646003723145}
2023-01-03 16:14:05.485 DEBUG: Taking gradient step
2023-01-03 16:14:07.549 DEBUG: Loss 7: {'policy_loss': -0.00830053089776429, 'entropy_loss': -0.04327409062534571, 'vf_loss': 0.01923360988932423, 'total_loss': -0.051574621523109994, 'approx_kl': -0.05293951649218798, 'clip_fraction': 0.3606770858168602, 'grad_norm': 12.34373950958252}
2023-01-03 16:14:09.606 DEBUG: Taking gradient step
2023-01-03 16:14:11.667 DEBUG: Loss 8: {'policy_loss': -0.004827215035328937, 'entropy_loss': -0.04154470097273588, 'vf_loss': 0.02023280684201402, 'total_loss': -0.04637191600806481, 'approx_kl': -0.05172148160636425, 'clip_fraction': 0.37890625, 'grad_norm': 15.361875534057617}
2023-01-03 16:14:13.783 DEBUG: Taking gradient step
2023-01-03 16:14:15.842 DEBUG: Loss 9: {'policy_loss': 0.004293924295966783, 'entropy_loss': -0.043256672099232674, 'vf_loss': 0.02045763884484329, 'total_loss': -0.038962747803265904, 'approx_kl': -0.053347282111644745, 'clip_fraction': 0.3919270858168602, 'grad_norm': 13.138922691345215}
2023-01-03 16:14:17.860 DEBUG: Taking gradient step
2023-01-03 16:14:19.950 DEBUG: Loss 10: {'policy_loss': -0.01630739654245677, 'entropy_loss': -0.04220299329608679, 'vf_loss': 0.018721552298107815, 'total_loss': -0.05851038983854355, 'approx_kl': -0.04425607342272997, 'clip_fraction': 0.4231770858168602, 'grad_norm': 7.9958882331848145}
2023-01-03 16:14:21.977 DEBUG: Taking gradient step
2023-01-03 16:14:24.072 DEBUG: Loss 11: {'policy_loss': -0.0048264097282303756, 'entropy_loss': -0.042133355513215065, 'vf_loss': 0.019911165765939643, 'total_loss': -0.046959765241445434, 'approx_kl': -0.07396819163113832, 'clip_fraction': 0.48046875, 'grad_norm': 6.018207550048828}
2023-01-03 16:14:26.111 DEBUG: Taking gradient step
2023-01-03 16:14:28.155 DEBUG: Loss 12: {'policy_loss': 0.005023280274664851, 'entropy_loss': -0.0419998150318861, 'vf_loss': 0.019852047087327063, 'total_loss': -0.036976534757221256, 'approx_kl': -0.05557557940483093, 'clip_fraction': 0.3802083358168602, 'grad_norm': 12.850860595703125}
2023-01-03 16:14:30.146 DEBUG: Taking gradient step
2023-01-03 16:14:32.193 DEBUG: Loss 13: {'policy_loss': -0.013554362921331869, 'entropy_loss': -0.04222003556787968, 'vf_loss': 0.020333599805459072, 'total_loss': -0.05577439848921155, 'approx_kl': -0.048029376193881035, 'clip_fraction': 0.4401041716337204, 'grad_norm': 11.96949577331543}
2023-01-03 16:14:34.199 DEBUG: Taking gradient step
2023-01-03 16:14:36.251 DEBUG: Loss 14: {'policy_loss': -0.04002580116780974, 'entropy_loss': -0.042124442756175995, 'vf_loss': 0.019029011684782125, 'total_loss': -0.08215024392398573, 'approx_kl': -0.08119125477969646, 'clip_fraction': 0.42578125, 'grad_norm': 12.815886497497559}
2023-01-03 16:14:36.251 INFO: Optimization: policy loss=-0.040, vf loss=0.019, entropy loss=-0.042, total loss=-0.082, num steps=15
2023-01-03 16:14:36.253 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 16:14:37.999 INFO: Evaluation rollout: return=0.430 (0.0), episode length=6.0
2023-01-03 16:14:38.000 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 16:14:38.002 INFO: Iteration: 63/137, steps: 13608
2023-01-03 16:14:48.032 DEBUG: Atoms are too close
2023-01-03 16:14:52.869 DEBUG: Atoms are too close
2023-01-03 16:15:07.096 DEBUG: Atoms are too close
2023-01-03 16:15:25.472 DEBUG: Atoms are too close
2023-01-03 16:15:30.630 DEBUG: Atoms are too close
2023-01-03 16:15:32.146 DEBUG: Atoms are too close
2023-01-03 16:15:34.160 INFO: Training rollout: return=-2.328 (6.3), episode length=5.8
2023-01-03 16:15:34.161 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 16:15:34.164 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-13608_train.pkl
2023-01-03 16:15:36.158 DEBUG: Taking gradient step
2023-01-03 16:15:38.194 DEBUG: Loss 0: {'policy_loss': 0.04406725994940428, 'entropy_loss': -0.0421413267031312, 'vf_loss': 0.021107402636662952, 'total_loss': 0.001925933246273083, 'approx_kl': -1.3285898603498936e-08, 'clip_fraction': 0.0, 'grad_norm': 21.12384796142578}
2023-01-03 16:15:40.181 DEBUG: Taking gradient step
2023-01-03 16:15:42.208 DEBUG: Loss 1: {'policy_loss': -0.0005933108630494822, 'entropy_loss': -0.04218100570142269, 'vf_loss': 0.01737966062610133, 'total_loss': -0.04277431656447218, 'approx_kl': -0.03007481200620532, 'clip_fraction': 0.13411458395421505, 'grad_norm': 31.124677658081055}
2023-01-03 16:15:44.195 DEBUG: Taking gradient step
2023-01-03 16:15:46.220 DEBUG: Loss 2: {'policy_loss': 0.0014952645214051652, 'entropy_loss': -0.041536398231983185, 'vf_loss': 0.017005571757006902, 'total_loss': -0.04004113371057802, 'approx_kl': -0.05817733518779278, 'clip_fraction': 0.39453125, 'grad_norm': 27.870269775390625}
2023-01-03 16:15:48.206 DEBUG: Taking gradient step
2023-01-03 16:15:50.245 DEBUG: Loss 3: {'policy_loss': 0.06672582664559777, 'entropy_loss': -0.04095167387276888, 'vf_loss': 0.017163747005446175, 'total_loss': 0.025774152772828893, 'approx_kl': -0.06647313199937344, 'clip_fraction': 0.4986979216337204, 'grad_norm': 28.03765869140625}
2023-01-03 16:15:52.241 DEBUG: Taking gradient step
2023-01-03 16:15:54.352 DEBUG: Loss 4: {'policy_loss': 0.14112406019091409, 'entropy_loss': -0.04135769046843052, 'vf_loss': 0.02036519259672634, 'total_loss': 0.09976636972248357, 'approx_kl': -0.08062127185985446, 'clip_fraction': 0.5208333432674408, 'grad_norm': 32.421958923339844}
2023-01-03 16:15:56.396 DEBUG: Taking gradient step
2023-01-03 16:15:58.705 DEBUG: Loss 5: {'policy_loss': 0.19280532878191176, 'entropy_loss': -0.04114012327045202, 'vf_loss': 0.023136284787300565, 'total_loss': 0.15166520551145973, 'approx_kl': -0.07513737957924604, 'clip_fraction': 0.4583333358168602, 'grad_norm': 27.56932258605957}
2023-01-03 16:16:00.894 DEBUG: Taking gradient step
2023-01-03 16:16:03.454 DEBUG: Loss 6: {'policy_loss': 0.02073851561219446, 'entropy_loss': -0.04123333562165499, 'vf_loss': 0.017027910801806757, 'total_loss': -0.02049482000946052, 'approx_kl': -0.0882816594094038, 'clip_fraction': 0.34505208395421505, 'grad_norm': 13.934571266174316}
2023-01-03 16:16:05.898 DEBUG: Taking gradient step
2023-01-03 16:16:08.597 DEBUG: Loss 7: {'policy_loss': 0.04429040023160556, 'entropy_loss': -0.04111630469560623, 'vf_loss': 0.017647837374833376, 'total_loss': 0.0031740955359993335, 'approx_kl': -0.0936218872666359, 'clip_fraction': 0.4322916716337204, 'grad_norm': 12.227938652038574}
2023-01-03 16:16:10.930 DEBUG: Taking gradient step
2023-01-03 16:16:13.001 DEBUG: Loss 8: {'policy_loss': 0.12634219582267164, 'entropy_loss': -0.042174079455435276, 'vf_loss': 0.019565575822821313, 'total_loss': 0.08416811636723637, 'approx_kl': -0.09150802902877331, 'clip_fraction': 0.4674479216337204, 'grad_norm': 15.761970520019531}
2023-01-03 16:16:14.979 DEBUG: Taking gradient step
2023-01-03 16:16:17.023 DEBUG: Loss 9: {'policy_loss': 0.03129733804113965, 'entropy_loss': -0.042331570759415627, 'vf_loss': 0.017502449353450494, 'total_loss': -0.011034232718275978, 'approx_kl': -0.1204683892428875, 'clip_fraction': 0.4049479216337204, 'grad_norm': 17.09725570678711}
2023-01-03 16:16:19.000 DEBUG: Taking gradient step
2023-01-03 16:16:21.038 DEBUG: Loss 10: {'policy_loss': 0.04688935936776525, 'entropy_loss': -0.040535676293075085, 'vf_loss': 0.01868066200529902, 'total_loss': 0.006353683074690163, 'approx_kl': -0.12475330382585526, 'clip_fraction': 0.4075520858168602, 'grad_norm': 23.123531341552734}
2023-01-03 16:16:23.027 DEBUG: Taking gradient step
2023-01-03 16:16:25.070 DEBUG: Loss 11: {'policy_loss': 0.02650459405896044, 'entropy_loss': -0.040242078714072704, 'vf_loss': 0.01734228699951868, 'total_loss': -0.013737484655112268, 'approx_kl': -0.11096049286425114, 'clip_fraction': 0.4466145858168602, 'grad_norm': 27.43404769897461}
2023-01-03 16:16:27.093 DEBUG: Taking gradient step
2023-01-03 16:16:29.516 DEBUG: Loss 12: {'policy_loss': 0.05100846120697249, 'entropy_loss': -0.039535355754196644, 'vf_loss': 0.01751080279101424, 'total_loss': 0.01147310545277585, 'approx_kl': -0.11017001792788506, 'clip_fraction': 0.5130208432674408, 'grad_norm': 23.5684757232666}
2023-01-03 16:16:31.872 DEBUG: Taking gradient step
2023-01-03 16:16:34.296 DEBUG: Loss 13: {'policy_loss': 0.11649721204754204, 'entropy_loss': -0.04011097643524408, 'vf_loss': 0.019305330616289335, 'total_loss': 0.07638623561229796, 'approx_kl': -0.11327923461794853, 'clip_fraction': 0.5, 'grad_norm': 28.023082733154297}
2023-01-03 16:16:36.439 DEBUG: Taking gradient step
2023-01-03 16:16:38.456 DEBUG: Loss 14: {'policy_loss': 0.0372112401701054, 'entropy_loss': -0.03823091508820653, 'vf_loss': 0.01818853828008654, 'total_loss': -0.0010196749181011246, 'approx_kl': -0.08704991824924946, 'clip_fraction': 0.46875, 'grad_norm': 21.928239822387695}
2023-01-03 16:16:38.457 INFO: Optimization: policy loss=0.037, vf loss=0.018, entropy loss=-0.038, total loss=-0.001, num steps=15
2023-01-03 16:16:38.458 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 16:16:40.194 INFO: Evaluation rollout: return=0.511 (0.0), episode length=6.0
2023-01-03 16:16:40.195 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 16:16:40.198 INFO: Iteration: 64/137, steps: 13824
2023-01-03 16:16:54.904 DEBUG: Atoms are too close
2023-01-03 16:17:12.295 DEBUG: Atoms are too close
2023-01-03 16:17:27.063 DEBUG: Atoms are too close
2023-01-03 16:17:29.611 DEBUG: Atoms are too close
2023-01-03 16:17:36.117 INFO: Training rollout: return=-1.863 (5.7), episode length=5.8
2023-01-03 16:17:36.118 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 16:17:36.121 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-13824_train.pkl
2023-01-03 16:17:38.138 DEBUG: Taking gradient step
2023-01-03 16:17:40.185 DEBUG: Loss 0: {'policy_loss': 0.0212469342811882, 'entropy_loss': -0.037719218991696835, 'vf_loss': 0.01691501557314867, 'total_loss': -0.016472284710508635, 'approx_kl': -1.2964786400004868e-07, 'clip_fraction': 0.0, 'grad_norm': 16.00116729736328}
2023-01-03 16:17:42.174 DEBUG: Taking gradient step
2023-01-03 16:17:44.221 DEBUG: Loss 1: {'policy_loss': -0.004348600630269708, 'entropy_loss': -0.038872720673680305, 'vf_loss': 0.015665907256182, 'total_loss': -0.04322132130395001, 'approx_kl': 0.0011064786231145263, 'clip_fraction': 0.037760416977107525, 'grad_norm': 17.024946212768555}
2023-01-03 16:17:46.229 DEBUG: Taking gradient step
2023-01-03 16:17:48.368 DEBUG: Loss 2: {'policy_loss': 0.017745394882975836, 'entropy_loss': -0.03869158122688532, 'vf_loss': 0.016736615332532803, 'total_loss': -0.020946186343909483, 'approx_kl': 0.002074246760457754, 'clip_fraction': 0.1328125, 'grad_norm': 25.0883731842041}
2023-01-03 16:17:50.368 DEBUG: Taking gradient step
2023-01-03 16:17:52.824 DEBUG: Loss 3: {'policy_loss': -0.015187460342861945, 'entropy_loss': -0.041606735438108444, 'vf_loss': 0.015471310604695537, 'total_loss': -0.05679419578097039, 'approx_kl': -0.008686200948432088, 'clip_fraction': 0.1966145858168602, 'grad_norm': 17.87487030029297}
2023-01-03 16:17:55.227 DEBUG: Taking gradient step
2023-01-03 16:17:57.677 DEBUG: Loss 4: {'policy_loss': -0.009280906170806812, 'entropy_loss': -0.03961528465151787, 'vf_loss': 0.015061693125900815, 'total_loss': -0.04889619082232468, 'approx_kl': -0.01051422394812107, 'clip_fraction': 0.2278645858168602, 'grad_norm': 14.019543647766113}
2023-01-03 16:18:00.064 DEBUG: Taking gradient step
2023-01-03 16:18:02.344 DEBUG: Loss 5: {'policy_loss': 0.0050404972895290705, 'entropy_loss': -0.03861761558800936, 'vf_loss': 0.01628238693944301, 'total_loss': -0.033577118298480285, 'approx_kl': -0.015273206867277622, 'clip_fraction': 0.2408854179084301, 'grad_norm': 13.69347858428955}
2023-01-03 16:18:04.349 DEBUG: Taking gradient step
2023-01-03 16:18:06.390 DEBUG: Loss 6: {'policy_loss': 0.08046056213539207, 'entropy_loss': -0.040488677099347115, 'vf_loss': 0.01868320711192702, 'total_loss': 0.03997188503604496, 'approx_kl': -0.01720211049541831, 'clip_fraction': 0.2864583358168602, 'grad_norm': 14.937413215637207}
2023-01-03 16:18:08.387 DEBUG: Taking gradient step
2023-01-03 16:18:10.431 DEBUG: Loss 7: {'policy_loss': -0.026247855792768893, 'entropy_loss': -0.040375267155468464, 'vf_loss': 0.013800376557265051, 'total_loss': -0.06662312294823736, 'approx_kl': -0.02695132023654878, 'clip_fraction': 0.3072916716337204, 'grad_norm': 11.242541313171387}
2023-01-03 16:18:12.431 DEBUG: Taking gradient step
2023-01-03 16:18:14.461 DEBUG: Loss 8: {'policy_loss': 0.007711786919813575, 'entropy_loss': -0.03966935910284519, 'vf_loss': 0.01564265414489899, 'total_loss': -0.031957572183031614, 'approx_kl': -0.033887608209624887, 'clip_fraction': 0.2434895858168602, 'grad_norm': 17.533287048339844}
2023-01-03 16:18:16.455 DEBUG: Taking gradient step
2023-01-03 16:18:18.494 DEBUG: Loss 9: {'policy_loss': 0.002930941565076485, 'entropy_loss': -0.040517156943678856, 'vf_loss': 0.015569623606932368, 'total_loss': -0.037586215378602364, 'approx_kl': -0.03887594537809491, 'clip_fraction': 0.2239583358168602, 'grad_norm': 25.383974075317383}
2023-01-03 16:18:20.490 DEBUG: Taking gradient step
2023-01-03 16:18:22.559 DEBUG: Loss 10: {'policy_loss': 0.03933587190453361, 'entropy_loss': -0.03872418124228716, 'vf_loss': 0.015622251226046002, 'total_loss': 0.0006116906622464571, 'approx_kl': -0.020868256455287337, 'clip_fraction': 0.2942708358168602, 'grad_norm': 25.680849075317383}
2023-01-03 16:18:24.559 DEBUG: Taking gradient step
2023-01-03 16:18:26.618 DEBUG: Loss 11: {'policy_loss': 0.01665455260718842, 'entropy_loss': -0.03908401541411877, 'vf_loss': 0.01600246642200928, 'total_loss': -0.02242946280693034, 'approx_kl': -0.04477905249223113, 'clip_fraction': 0.31640625, 'grad_norm': 21.759689331054688}
2023-01-03 16:18:28.609 DEBUG: Taking gradient step
2023-01-03 16:18:30.678 DEBUG: Loss 12: {'policy_loss': -0.038516760837109, 'entropy_loss': -0.039793603122234344, 'vf_loss': 0.013668972792614401, 'total_loss': -0.07831036395934335, 'approx_kl': -0.04562242701649666, 'clip_fraction': 0.2591145858168602, 'grad_norm': 9.620170593261719}
2023-01-03 16:18:32.672 DEBUG: Taking gradient step
2023-01-03 16:18:34.701 DEBUG: Loss 13: {'policy_loss': -0.015292687924783124, 'entropy_loss': -0.04025692958384752, 'vf_loss': 0.014069704098830807, 'total_loss': -0.05554961750863065, 'approx_kl': -0.05218894500285387, 'clip_fraction': 0.40625, 'grad_norm': 12.08928108215332}
2023-01-03 16:18:36.697 DEBUG: Taking gradient step
2023-01-03 16:18:38.757 DEBUG: Loss 14: {'policy_loss': 0.0116783431622051, 'entropy_loss': -0.03957193996757269, 'vf_loss': 0.014436466730726913, 'total_loss': -0.02789359680536759, 'approx_kl': -0.045553209725767374, 'clip_fraction': 0.3893229216337204, 'grad_norm': 21.074905395507812}
2023-01-03 16:18:38.758 INFO: Optimization: policy loss=0.012, vf loss=0.014, entropy loss=-0.040, total loss=-0.028, num steps=15
2023-01-03 16:18:38.759 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 16:18:40.476 INFO: Evaluation rollout: return=0.465 (0.0), episode length=6.0
2023-01-03 16:18:40.477 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 16:18:40.480 INFO: Iteration: 65/137, steps: 14040
2023-01-03 16:19:14.665 DEBUG: Atoms are too close
2023-01-03 16:19:29.729 DEBUG: There is a single atom floating around
2023-01-03 16:19:30.287 DEBUG: There is a single atom floating around
2023-01-03 16:19:32.761 DEBUG: Atoms are too close
2023-01-03 16:19:38.279 INFO: Training rollout: return=-1.355 (5.2), episode length=5.9
2023-01-03 16:19:38.280 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 16:19:38.283 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-14040_train.pkl
2023-01-03 16:19:40.370 DEBUG: Taking gradient step
2023-01-03 16:19:42.448 DEBUG: Loss 0: {'policy_loss': -0.025453372414465193, 'entropy_loss': -0.04024715535342693, 'vf_loss': 0.012430937298740695, 'total_loss': -0.06570052776789213, 'approx_kl': 2.045029168229462e-08, 'clip_fraction': 0.0, 'grad_norm': 12.900481224060059}
2023-01-03 16:19:44.465 DEBUG: Taking gradient step
2023-01-03 16:19:46.653 DEBUG: Loss 1: {'policy_loss': 0.03686090132511738, 'entropy_loss': -0.040008057840168476, 'vf_loss': 0.01511993017343834, 'total_loss': -0.003147156515051097, 'approx_kl': -0.01727566448971629, 'clip_fraction': 0.13671875, 'grad_norm': 17.909713745117188}
2023-01-03 16:19:48.741 DEBUG: Taking gradient step
2023-01-03 16:19:50.891 DEBUG: Loss 2: {'policy_loss': 0.034115039071643136, 'entropy_loss': -0.04246868658810854, 'vf_loss': 0.013766752843082743, 'total_loss': -0.008353647516465404, 'approx_kl': -0.03187381010502577, 'clip_fraction': 0.3424479216337204, 'grad_norm': 13.876136779785156}
2023-01-03 16:19:52.967 DEBUG: Taking gradient step
2023-01-03 16:19:55.108 DEBUG: Loss 3: {'policy_loss': 0.061675189924013225, 'entropy_loss': -0.04283929988741875, 'vf_loss': 0.014707292408848698, 'total_loss': 0.01883589003659448, 'approx_kl': -0.006807656958699226, 'clip_fraction': 0.41015625, 'grad_norm': 14.28237533569336}
2023-01-03 16:19:57.390 DEBUG: Taking gradient step
2023-01-03 16:19:59.447 DEBUG: Loss 4: {'policy_loss': 0.034926605687151877, 'entropy_loss': -0.03948002541437745, 'vf_loss': 0.013990744498575663, 'total_loss': -0.004553419727225574, 'approx_kl': -0.0002999489661306143, 'clip_fraction': 0.4700520932674408, 'grad_norm': 14.76927375793457}
2023-01-03 16:20:01.468 DEBUG: Taking gradient step
2023-01-03 16:20:03.521 DEBUG: Loss 5: {'policy_loss': 0.019362346145971654, 'entropy_loss': -0.04110117722302675, 'vf_loss': 0.013884319612080014, 'total_loss': -0.0217388310770551, 'approx_kl': -0.035750911105424166, 'clip_fraction': 0.4166666716337204, 'grad_norm': 11.346887588500977}
2023-01-03 16:20:05.517 DEBUG: Taking gradient step
2023-01-03 16:20:07.586 DEBUG: Loss 6: {'policy_loss': 0.002120941630286744, 'entropy_loss': -0.04041396826505661, 'vf_loss': 0.013020472219793704, 'total_loss': -0.03829302663476987, 'approx_kl': -0.03258056938648224, 'clip_fraction': 0.4166666716337204, 'grad_norm': 11.607426643371582}
2023-01-03 16:20:09.595 DEBUG: Taking gradient step
2023-01-03 16:20:11.652 DEBUG: Loss 7: {'policy_loss': 0.008922804215564496, 'entropy_loss': -0.03965867217630148, 'vf_loss': 0.014378966462751146, 'total_loss': -0.030735867960736983, 'approx_kl': -0.055742742493748665, 'clip_fraction': 0.3841145858168602, 'grad_norm': 16.948348999023438}
2023-01-03 16:20:13.658 DEBUG: Taking gradient step
2023-01-03 16:20:15.708 DEBUG: Loss 8: {'policy_loss': -0.013713708613283623, 'entropy_loss': -0.03866776917129755, 'vf_loss': 0.013699676180894758, 'total_loss': -0.052381477784581174, 'approx_kl': -0.05467372480779886, 'clip_fraction': 0.3294270858168602, 'grad_norm': 9.871346473693848}
2023-01-03 16:20:17.710 DEBUG: Taking gradient step
2023-01-03 16:20:19.770 DEBUG: Loss 9: {'policy_loss': -0.04668311840482488, 'entropy_loss': -0.04015878215432167, 'vf_loss': 0.011092897467881913, 'total_loss': -0.08684190055914655, 'approx_kl': -0.05320944497361779, 'clip_fraction': 0.3828125, 'grad_norm': 10.224885940551758}
2023-01-03 16:20:21.783 DEBUG: Taking gradient step
2023-01-03 16:20:23.833 DEBUG: Loss 10: {'policy_loss': 0.03129744109385362, 'entropy_loss': -0.0383111210539937, 'vf_loss': 0.013567472354281927, 'total_loss': -0.0070136799601400734, 'approx_kl': -0.05990883521735668, 'clip_fraction': 0.4036458358168602, 'grad_norm': 17.477989196777344}
2023-01-03 16:20:25.842 DEBUG: Taking gradient step
2023-01-03 16:20:27.981 DEBUG: Loss 11: {'policy_loss': -0.014739640676438157, 'entropy_loss': -0.03857966884970665, 'vf_loss': 0.013193436299326384, 'total_loss': -0.053319309526144804, 'approx_kl': -0.06696630315855145, 'clip_fraction': 0.4231770858168602, 'grad_norm': 14.037935256958008}
2023-01-03 16:20:29.986 DEBUG: Taking gradient step
2023-01-03 16:20:32.043 DEBUG: Loss 12: {'policy_loss': -0.0008189509187306824, 'entropy_loss': -0.03962901793420315, 'vf_loss': 0.014489797849161566, 'total_loss': -0.040447968852933835, 'approx_kl': -0.08515702467411757, 'clip_fraction': 0.4908854216337204, 'grad_norm': 15.743783950805664}
2023-01-03 16:20:34.051 DEBUG: Taking gradient step
2023-01-03 16:20:36.107 DEBUG: Loss 13: {'policy_loss': 0.03531877283182082, 'entropy_loss': -0.03733359929174185, 'vf_loss': 0.014148179333339879, 'total_loss': -0.002014826459921029, 'approx_kl': -0.07832935079932213, 'clip_fraction': 0.5130208432674408, 'grad_norm': 19.361169815063477}
2023-01-03 16:20:38.116 DEBUG: Taking gradient step
2023-01-03 16:20:40.185 DEBUG: Loss 14: {'policy_loss': -0.02150511355828478, 'entropy_loss': -0.03837534226477146, 'vf_loss': 0.012975027141850148, 'total_loss': -0.05988045582305624, 'approx_kl': -0.07272710464894772, 'clip_fraction': 0.54296875, 'grad_norm': 10.219852447509766}
2023-01-03 16:20:40.185 INFO: Optimization: policy loss=-0.022, vf loss=0.013, entropy loss=-0.038, total loss=-0.060, num steps=15
2023-01-03 16:20:40.187 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 16:20:41.885 INFO: Evaluation rollout: return=0.500 (0.0), episode length=6.0
2023-01-03 16:20:41.887 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 16:20:41.890 INFO: Iteration: 66/137, steps: 14256
2023-01-03 16:21:13.139 DEBUG: Atoms are too close
2023-01-03 16:21:15.461 DEBUG: Atoms are too close
2023-01-03 16:21:15.462 DEBUG: There is a single atom floating around
2023-01-03 16:21:38.834 INFO: Training rollout: return=-0.838 (4.3), episode length=5.9
2023-01-03 16:21:38.836 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 16:21:38.839 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-14256_train.pkl
2023-01-03 16:21:40.876 DEBUG: Taking gradient step
2023-01-03 16:21:42.939 DEBUG: Loss 0: {'policy_loss': -0.027540758209611275, 'entropy_loss': -0.04017759673297405, 'vf_loss': 0.008539036089084035, 'total_loss': -0.06771835494258532, 'approx_kl': -2.336067428387878e-08, 'clip_fraction': 0.0, 'grad_norm': 16.052526473999023}
2023-01-03 16:21:44.944 DEBUG: Taking gradient step
2023-01-03 16:21:47.024 DEBUG: Loss 1: {'policy_loss': -0.015001270507742547, 'entropy_loss': -0.03962129820138216, 'vf_loss': 0.009374070745598578, 'total_loss': -0.05462256870912471, 'approx_kl': -0.00895084155490622, 'clip_fraction': 0.05989583395421505, 'grad_norm': 16.520875930786133}
2023-01-03 16:21:49.040 DEBUG: Taking gradient step
2023-01-03 16:21:51.108 DEBUG: Loss 2: {'policy_loss': 0.005971913980031274, 'entropy_loss': -0.0384253915399313, 'vf_loss': 0.010125682769481054, 'total_loss': -0.032453477559900024, 'approx_kl': -0.009326312225311995, 'clip_fraction': 0.13541666697710752, 'grad_norm': 9.616905212402344}
2023-01-03 16:21:53.116 DEBUG: Taking gradient step
2023-01-03 16:21:55.194 DEBUG: Loss 3: {'policy_loss': 0.015934491647426587, 'entropy_loss': -0.03879334591329098, 'vf_loss': 0.010675017969545113, 'total_loss': -0.02285885426586439, 'approx_kl': -0.020081471651792526, 'clip_fraction': 0.2838541716337204, 'grad_norm': 14.555767059326172}
2023-01-03 16:21:57.206 DEBUG: Taking gradient step
2023-01-03 16:21:59.293 DEBUG: Loss 4: {'policy_loss': 0.01499264660512202, 'entropy_loss': -0.038462307304143906, 'vf_loss': 0.010475564914657664, 'total_loss': -0.023469660699021885, 'approx_kl': -0.05617911322042346, 'clip_fraction': 0.3697916716337204, 'grad_norm': 15.536809921264648}
2023-01-03 16:22:01.329 DEBUG: Taking gradient step
2023-01-03 16:22:03.418 DEBUG: Loss 5: {'policy_loss': 0.01736072786939518, 'entropy_loss': -0.038852280005812645, 'vf_loss': 0.009862338124705501, 'total_loss': -0.021491552136417465, 'approx_kl': -0.04118836484849453, 'clip_fraction': 0.37109375, 'grad_norm': 18.323772430419922}
2023-01-03 16:22:05.459 DEBUG: Taking gradient step
2023-01-03 16:22:07.553 DEBUG: Loss 6: {'policy_loss': 0.014141180513453925, 'entropy_loss': -0.03753773961216211, 'vf_loss': 0.010033910057453473, 'total_loss': -0.02339655909870819, 'approx_kl': -0.045237075770273805, 'clip_fraction': 0.37109375, 'grad_norm': 18.623598098754883}
2023-01-03 16:22:09.594 DEBUG: Taking gradient step
2023-01-03 16:22:11.689 DEBUG: Loss 7: {'policy_loss': 0.02041048098513218, 'entropy_loss': -0.037068755365908146, 'vf_loss': 0.010902562999381731, 'total_loss': -0.016658274380775967, 'approx_kl': -0.0367886321619153, 'clip_fraction': 0.3802083358168602, 'grad_norm': 21.22443199157715}
2023-01-03 16:22:13.704 DEBUG: Taking gradient step
2023-01-03 16:22:15.874 DEBUG: Loss 8: {'policy_loss': 0.03864829074911835, 'entropy_loss': -0.03794589452445507, 'vf_loss': 0.010259618384427448, 'total_loss': 0.0007023962246632855, 'approx_kl': -0.05931322183459997, 'clip_fraction': 0.3893229216337204, 'grad_norm': 27.50482940673828}
2023-01-03 16:22:17.901 DEBUG: Taking gradient step
2023-01-03 16:22:19.968 DEBUG: Loss 9: {'policy_loss': 0.057330707785898855, 'entropy_loss': -0.036942276172339916, 'vf_loss': 0.010806891243536936, 'total_loss': 0.02038843161355894, 'approx_kl': -0.052943759597837925, 'clip_fraction': 0.4075520858168602, 'grad_norm': 28.58711814880371}
2023-01-03 16:22:22.021 DEBUG: Taking gradient step
2023-01-03 16:22:24.101 DEBUG: Loss 10: {'policy_loss': 0.005553344829244685, 'entropy_loss': -0.03797093126922846, 'vf_loss': 0.009681036292586116, 'total_loss': -0.03241758643998377, 'approx_kl': -0.05681200511753559, 'clip_fraction': 0.3580729216337204, 'grad_norm': 17.923812866210938}
2023-01-03 16:22:26.121 DEBUG: Taking gradient step
2023-01-03 16:22:28.200 DEBUG: Loss 11: {'policy_loss': 0.013951582529571719, 'entropy_loss': -0.03651725873351097, 'vf_loss': 0.009869459748126537, 'total_loss': -0.022565676203939254, 'approx_kl': -0.06066206004470587, 'clip_fraction': 0.3502604216337204, 'grad_norm': 20.421417236328125}
2023-01-03 16:22:30.227 DEBUG: Taking gradient step
2023-01-03 16:22:32.286 DEBUG: Loss 12: {'policy_loss': -0.01309636047101148, 'entropy_loss': -0.03720097243785858, 'vf_loss': 0.009084881094581969, 'total_loss': -0.05029733290887006, 'approx_kl': -0.06666152318939567, 'clip_fraction': 0.36328125, 'grad_norm': 7.938973903656006}
2023-01-03 16:22:34.295 DEBUG: Taking gradient step
2023-01-03 16:22:36.383 DEBUG: Loss 13: {'policy_loss': -0.014008392721921687, 'entropy_loss': -0.038430689834058285, 'vf_loss': 0.008873386327071001, 'total_loss': -0.05243908255597997, 'approx_kl': -0.04857378313317895, 'clip_fraction': 0.3880208358168602, 'grad_norm': 7.23193883895874}
2023-01-03 16:22:38.422 DEBUG: Taking gradient step
2023-01-03 16:22:40.562 DEBUG: Loss 14: {'policy_loss': 0.0035332495734430557, 'entropy_loss': -0.03791504353284836, 'vf_loss': 0.010242754347673381, 'total_loss': -0.0343817939594053, 'approx_kl': -0.07934408355504274, 'clip_fraction': 0.375, 'grad_norm': 19.844388961791992}
2023-01-03 16:22:40.563 INFO: Optimization: policy loss=0.004, vf loss=0.010, entropy loss=-0.038, total loss=-0.034, num steps=15
2023-01-03 16:22:40.564 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 16:22:42.319 INFO: Evaluation rollout: return=0.583 (0.0), episode length=6.0
2023-01-03 16:22:42.320 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 16:22:42.323 INFO: Iteration: 67/137, steps: 14472
2023-01-03 16:22:56.274 DEBUG: Atoms are too close
2023-01-03 16:22:56.851 DEBUG: Atoms are too close
2023-01-03 16:23:16.952 DEBUG: Atoms are too close
2023-01-03 16:23:39.121 INFO: Training rollout: return=-0.761 (4.1), episode length=5.9
2023-01-03 16:23:39.122 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 16:23:39.126 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-14472_train.pkl
2023-01-03 16:23:41.166 DEBUG: Taking gradient step
2023-01-03 16:23:43.273 DEBUG: Loss 0: {'policy_loss': -0.010686319630963375, 'entropy_loss': -0.03970373794436455, 'vf_loss': 0.01023651713390431, 'total_loss': -0.050390057575327926, 'approx_kl': 7.939524948596954e-08, 'clip_fraction': 0.0, 'grad_norm': 11.451409339904785}
2023-01-03 16:23:45.331 DEBUG: Taking gradient step
2023-01-03 16:23:47.448 DEBUG: Loss 1: {'policy_loss': -0.001224254065524219, 'entropy_loss': -0.03878767043352127, 'vf_loss': 0.011565847640214892, 'total_loss': -0.04001192449904549, 'approx_kl': -0.00560018396936357, 'clip_fraction': 0.08984375, 'grad_norm': 18.82054328918457}
2023-01-03 16:23:49.505 DEBUG: Taking gradient step
2023-01-03 16:23:51.631 DEBUG: Loss 2: {'policy_loss': 0.06187094157764686, 'entropy_loss': -0.03941046725958586, 'vf_loss': 0.013387839990786278, 'total_loss': 0.022460474318061002, 'approx_kl': 0.014479206642135978, 'clip_fraction': 0.3502604216337204, 'grad_norm': 16.90686798095703}
2023-01-03 16:23:53.688 DEBUG: Taking gradient step
2023-01-03 16:23:55.810 DEBUG: Loss 3: {'policy_loss': 0.0025416138628061996, 'entropy_loss': -0.03913423791527748, 'vf_loss': 0.010808616862877233, 'total_loss': -0.03659262405247128, 'approx_kl': -0.00036036153323948383, 'clip_fraction': 0.3515625, 'grad_norm': 16.846529006958008}
2023-01-03 16:23:57.868 DEBUG: Taking gradient step
2023-01-03 16:23:59.985 DEBUG: Loss 4: {'policy_loss': -0.04100238003879165, 'entropy_loss': -0.03905724361538887, 'vf_loss': 0.009326151670823003, 'total_loss': -0.08005962365418051, 'approx_kl': -0.018314129833015613, 'clip_fraction': 0.21484375, 'grad_norm': 9.033238410949707}
2023-01-03 16:24:02.024 DEBUG: Taking gradient step
2023-01-03 16:24:04.179 DEBUG: Loss 5: {'policy_loss': -0.04191311681093212, 'entropy_loss': -0.038578327745199203, 'vf_loss': 0.0096191052118033, 'total_loss': -0.08049144455613133, 'approx_kl': -0.014146026223897934, 'clip_fraction': 0.20703125, 'grad_norm': 4.565221786499023}
2023-01-03 16:24:06.195 DEBUG: Taking gradient step
2023-01-03 16:24:08.274 DEBUG: Loss 6: {'policy_loss': -0.045018517300900646, 'entropy_loss': -0.039692722260951996, 'vf_loss': 0.009663099109507505, 'total_loss': -0.08471123956185264, 'approx_kl': -0.024479140527546406, 'clip_fraction': 0.2356770858168602, 'grad_norm': 6.76419734954834}
2023-01-03 16:24:10.312 DEBUG: Taking gradient step
2023-01-03 16:24:12.401 DEBUG: Loss 7: {'policy_loss': -0.0027029268833116057, 'entropy_loss': -0.03779895231127739, 'vf_loss': 0.010869593673012386, 'total_loss': -0.04050187919458899, 'approx_kl': -0.02364649693481624, 'clip_fraction': 0.30859375, 'grad_norm': 9.033975601196289}
2023-01-03 16:24:14.447 DEBUG: Taking gradient step
2023-01-03 16:24:16.530 DEBUG: Loss 8: {'policy_loss': -3.957397235624521e-05, 'entropy_loss': -0.03908974397927523, 'vf_loss': 0.01199925346420903, 'total_loss': -0.03912931795163147, 'approx_kl': -0.0363816088065505, 'clip_fraction': 0.3151041716337204, 'grad_norm': 5.259364128112793}
2023-01-03 16:24:18.565 DEBUG: Taking gradient step
2023-01-03 16:24:20.656 DEBUG: Loss 9: {'policy_loss': 0.014649842364427942, 'entropy_loss': -0.04028497450053692, 'vf_loss': 0.012886496500654002, 'total_loss': -0.025635132136108962, 'approx_kl': -0.03014636179432273, 'clip_fraction': 0.3020833358168602, 'grad_norm': 11.216187477111816}
2023-01-03 16:24:22.714 DEBUG: Taking gradient step
2023-01-03 16:24:24.812 DEBUG: Loss 10: {'policy_loss': -0.06722257992729082, 'entropy_loss': -0.04088492784649134, 'vf_loss': 0.009171862911089094, 'total_loss': -0.10810750777378215, 'approx_kl': -0.0577455498278141, 'clip_fraction': 0.3033854216337204, 'grad_norm': 5.237181186676025}
2023-01-03 16:24:26.868 DEBUG: Taking gradient step
2023-01-03 16:24:29.013 DEBUG: Loss 11: {'policy_loss': -0.0008313521665611334, 'entropy_loss': -0.040121559984982014, 'vf_loss': 0.011762497764413437, 'total_loss': -0.04095291215154315, 'approx_kl': -0.07149783102795482, 'clip_fraction': 0.3333333358168602, 'grad_norm': 13.362850189208984}
2023-01-03 16:24:31.108 DEBUG: Taking gradient step
2023-01-03 16:24:33.250 DEBUG: Loss 12: {'policy_loss': -0.009678237629409687, 'entropy_loss': -0.04102687817066908, 'vf_loss': 0.01087756769308254, 'total_loss': -0.05070511580007876, 'approx_kl': -0.057267055846750736, 'clip_fraction': 0.3645833358168602, 'grad_norm': 10.797221183776855}
2023-01-03 16:24:35.335 DEBUG: Taking gradient step
2023-01-03 16:24:37.494 DEBUG: Loss 13: {'policy_loss': -0.042648117719777466, 'entropy_loss': -0.04089538659900427, 'vf_loss': 0.009502243473096207, 'total_loss': -0.08354350431878174, 'approx_kl': -0.04404854914173484, 'clip_fraction': 0.3072916679084301, 'grad_norm': 5.287684917449951}
2023-01-03 16:24:39.552 DEBUG: Taking gradient step
2023-01-03 16:24:41.792 DEBUG: Loss 14: {'policy_loss': -0.018041935728940323, 'entropy_loss': -0.04168124869465828, 'vf_loss': 0.010255578392651368, 'total_loss': -0.0597231844235986, 'approx_kl': -0.07074613403528929, 'clip_fraction': 0.3776041716337204, 'grad_norm': 10.288163185119629}
2023-01-03 16:24:41.793 INFO: Optimization: policy loss=-0.018, vf loss=0.010, entropy loss=-0.042, total loss=-0.060, num steps=15
2023-01-03 16:24:41.794 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 16:24:43.782 INFO: Evaluation rollout: return=0.587 (0.0), episode length=6.0
2023-01-03 16:24:43.783 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 16:24:43.787 INFO: Iteration: 68/137, steps: 14688
2023-01-03 16:24:58.002 DEBUG: Atoms are too close
2023-01-03 16:25:17.797 DEBUG: There is a single atom floating around
2023-01-03 16:25:20.800 DEBUG: Atoms are too close
2023-01-03 16:25:31.906 DEBUG: Atoms are too close
2023-01-03 16:25:41.486 INFO: Training rollout: return=-1.648 (5.4), episode length=5.9
2023-01-03 16:25:41.487 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 16:25:41.490 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-14688_train.pkl
2023-01-03 16:25:43.531 DEBUG: Taking gradient step
2023-01-03 16:25:45.595 DEBUG: Loss 0: {'policy_loss': -0.01151640951948752, 'entropy_loss': -0.03934952151030302, 'vf_loss': 0.015582652412615059, 'total_loss': -0.05086593102979054, 'approx_kl': 1.369820168406477e-08, 'clip_fraction': 0.0, 'grad_norm': 24.124622344970703}
2023-01-03 16:25:47.630 DEBUG: Taking gradient step
2023-01-03 16:25:49.701 DEBUG: Loss 1: {'policy_loss': -0.0400811580579104, 'entropy_loss': -0.040769172832369804, 'vf_loss': 0.014630464721186372, 'total_loss': -0.08085033089028021, 'approx_kl': -0.00987077335594222, 'clip_fraction': 0.10677083395421505, 'grad_norm': 12.993280410766602}
2023-01-03 16:25:51.718 DEBUG: Taking gradient step
2023-01-03 16:25:53.786 DEBUG: Loss 2: {'policy_loss': -0.017321328546652234, 'entropy_loss': -0.04002312384545803, 'vf_loss': 0.014798363658475725, 'total_loss': -0.05734445239211026, 'approx_kl': -0.015011409763246775, 'clip_fraction': 0.3098958358168602, 'grad_norm': 12.631717681884766}
2023-01-03 16:25:55.802 DEBUG: Taking gradient step
2023-01-03 16:25:57.953 DEBUG: Loss 3: {'policy_loss': 0.0034164322276236253, 'entropy_loss': -0.03977322205901146, 'vf_loss': 0.015388909912345351, 'total_loss': -0.036356789831387834, 'approx_kl': -0.04918035864830017, 'clip_fraction': 0.4049479216337204, 'grad_norm': 20.295425415039062}
2023-01-03 16:25:59.970 DEBUG: Taking gradient step
2023-01-03 16:26:02.028 DEBUG: Loss 4: {'policy_loss': 0.020365296368320504, 'entropy_loss': -0.04095940291881561, 'vf_loss': 0.01540986896542094, 'total_loss': -0.02059410655049511, 'approx_kl': -0.03666753286961466, 'clip_fraction': 0.4375, 'grad_norm': 23.57036781311035}
2023-01-03 16:26:04.107 DEBUG: Taking gradient step
2023-01-03 16:26:06.174 DEBUG: Loss 5: {'policy_loss': 0.040966954925786205, 'entropy_loss': -0.042155700735747814, 'vf_loss': 0.015842179038393953, 'total_loss': -0.0011887458099616097, 'approx_kl': -0.045320010744035244, 'clip_fraction': 0.43359375, 'grad_norm': 24.482120513916016}
2023-01-03 16:26:08.230 DEBUG: Taking gradient step
2023-01-03 16:26:10.291 DEBUG: Loss 6: {'policy_loss': 0.025073471854203767, 'entropy_loss': -0.04165985528379679, 'vf_loss': 0.017202294922382316, 'total_loss': -0.01658638342959302, 'approx_kl': -0.02924419194459915, 'clip_fraction': 0.4140625, 'grad_norm': 17.394384384155273}
2023-01-03 16:26:12.300 DEBUG: Taking gradient step
2023-01-03 16:26:14.358 DEBUG: Loss 7: {'policy_loss': 0.006610125667985115, 'entropy_loss': -0.040478761307895184, 'vf_loss': 0.01615571641460118, 'total_loss': -0.03386863563991007, 'approx_kl': -0.028248634189367294, 'clip_fraction': 0.3802083358168602, 'grad_norm': 16.773550033569336}
2023-01-03 16:26:16.365 DEBUG: Taking gradient step
2023-01-03 16:26:18.421 DEBUG: Loss 8: {'policy_loss': 0.033791148436658654, 'entropy_loss': -0.04030222911387682, 'vf_loss': 0.016731869219631823, 'total_loss': -0.006511080677218166, 'approx_kl': -0.041733176447451115, 'clip_fraction': 0.3307291716337204, 'grad_norm': 22.15631103515625}
2023-01-03 16:26:20.410 DEBUG: Taking gradient step
2023-01-03 16:26:22.464 DEBUG: Loss 9: {'policy_loss': 0.04172872267823072, 'entropy_loss': -0.040345688350498676, 'vf_loss': 0.017838805233344118, 'total_loss': 0.0013830343277320446, 'approx_kl': -0.06612637313082814, 'clip_fraction': 0.4075520932674408, 'grad_norm': 29.765714645385742}
2023-01-03 16:26:24.469 DEBUG: Taking gradient step
2023-01-03 16:26:26.520 DEBUG: Loss 10: {'policy_loss': 0.006500880547818361, 'entropy_loss': -0.04031357355415821, 'vf_loss': 0.01574640069435107, 'total_loss': -0.03381269300633985, 'approx_kl': -0.07731509604491293, 'clip_fraction': 0.4296875, 'grad_norm': 28.681337356567383}
2023-01-03 16:26:28.516 DEBUG: Taking gradient step
2023-01-03 16:26:30.573 DEBUG: Loss 11: {'policy_loss': 0.005737154571158955, 'entropy_loss': -0.040327087976038456, 'vf_loss': 0.015988895869855968, 'total_loss': -0.0345899334048795, 'approx_kl': -0.04954804154112935, 'clip_fraction': 0.42578125, 'grad_norm': 21.185260772705078}
2023-01-03 16:26:32.642 DEBUG: Taking gradient step
2023-01-03 16:26:34.831 DEBUG: Loss 12: {'policy_loss': -0.007030877577611694, 'entropy_loss': -0.041218722239136696, 'vf_loss': 0.015782339248930126, 'total_loss': -0.04824959981674839, 'approx_kl': -0.06647224631160498, 'clip_fraction': 0.45703125, 'grad_norm': 14.000490188598633}
2023-01-03 16:26:36.948 DEBUG: Taking gradient step
2023-01-03 16:26:39.084 DEBUG: Loss 13: {'policy_loss': 0.023817186090123257, 'entropy_loss': -0.0410901689901948, 'vf_loss': 0.01714127463354563, 'total_loss': -0.017272982900071537, 'approx_kl': -0.0550481672398746, 'clip_fraction': 0.4205729216337204, 'grad_norm': 14.412393569946289}
2023-01-03 16:26:41.162 DEBUG: Taking gradient step
2023-01-03 16:26:43.283 DEBUG: Loss 14: {'policy_loss': -0.01290501713475855, 'entropy_loss': -0.040840537287294865, 'vf_loss': 0.015573559683672307, 'total_loss': -0.053745554422053414, 'approx_kl': -0.07394810765981674, 'clip_fraction': 0.4049479216337204, 'grad_norm': 20.796201705932617}
2023-01-03 16:26:43.284 INFO: Optimization: policy loss=-0.013, vf loss=0.016, entropy loss=-0.041, total loss=-0.054, num steps=15
2023-01-03 16:26:43.285 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 16:26:45.272 INFO: Evaluation rollout: return=0.591 (0.0), episode length=6.0
2023-01-03 16:26:45.274 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 16:26:45.277 INFO: Iteration: 69/137, steps: 14904
2023-01-03 16:27:19.191 DEBUG: Atoms are too close
2023-01-03 16:27:36.618 DEBUG: Atoms are too close
2023-01-03 16:27:36.621 DEBUG: There is a single atom floating around
2023-01-03 16:27:42.334 INFO: Training rollout: return=-1.190 (4.8), episode length=5.9
2023-01-03 16:27:42.335 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 16:27:42.339 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-14904_train.pkl
2023-01-03 16:27:44.379 DEBUG: Taking gradient step
2023-01-03 16:27:46.447 DEBUG: Loss 0: {'policy_loss': 0.02181190592380941, 'entropy_loss': -0.04076727107167244, 'vf_loss': 0.013963470108002918, 'total_loss': -0.01895536514786303, 'approx_kl': -2.60770320892334e-08, 'clip_fraction': 0.0, 'grad_norm': 14.28698444366455}
2023-01-03 16:27:48.547 DEBUG: Taking gradient step
2023-01-03 16:27:50.614 DEBUG: Loss 1: {'policy_loss': -0.01966979164934952, 'entropy_loss': -0.04062514193356037, 'vf_loss': 0.012370518764485371, 'total_loss': -0.060294933582909896, 'approx_kl': -0.005662805982865393, 'clip_fraction': 0.02734375, 'grad_norm': 9.017329216003418}
2023-01-03 16:27:52.633 DEBUG: Taking gradient step
2023-01-03 16:27:54.694 DEBUG: Loss 2: {'policy_loss': 0.01699500789899171, 'entropy_loss': -0.040107994340360165, 'vf_loss': 0.014482185633099543, 'total_loss': -0.023112986441368458, 'approx_kl': -0.02267563808709383, 'clip_fraction': 0.2057291679084301, 'grad_norm': 8.142284393310547}
2023-01-03 16:27:56.710 DEBUG: Taking gradient step
2023-01-03 16:27:58.780 DEBUG: Loss 3: {'policy_loss': 0.026110766996843747, 'entropy_loss': -0.0407385490834713, 'vf_loss': 0.01495777273131289, 'total_loss': -0.014627782086627558, 'approx_kl': -0.008847981691360474, 'clip_fraction': 0.3424479216337204, 'grad_norm': 7.549404144287109}
2023-01-03 16:28:00.808 DEBUG: Taking gradient step
2023-01-03 16:28:02.866 DEBUG: Loss 4: {'policy_loss': 0.009264036590810674, 'entropy_loss': -0.03883589804172516, 'vf_loss': 0.014274438498503478, 'total_loss': -0.029571861450914484, 'approx_kl': -0.05016956990584731, 'clip_fraction': 0.4244791716337204, 'grad_norm': 7.626469135284424}
2023-01-03 16:28:04.876 DEBUG: Taking gradient step
2023-01-03 16:28:06.954 DEBUG: Loss 5: {'policy_loss': -0.0344215596796194, 'entropy_loss': -0.04008292965590954, 'vf_loss': 0.012480267701271728, 'total_loss': -0.07450448933552895, 'approx_kl': -0.03938219370320439, 'clip_fraction': 0.4388020858168602, 'grad_norm': 7.9538984298706055}
2023-01-03 16:28:08.970 DEBUG: Taking gradient step
2023-01-03 16:28:11.031 DEBUG: Loss 6: {'policy_loss': 0.014137168918129953, 'entropy_loss': -0.03936070669442415, 'vf_loss': 0.014350093516870024, 'total_loss': -0.0252235377762942, 'approx_kl': -0.04967586975544691, 'clip_fraction': 0.3932291716337204, 'grad_norm': 9.50967788696289}
2023-01-03 16:28:13.033 DEBUG: Taking gradient step
2023-01-03 16:28:15.103 DEBUG: Loss 7: {'policy_loss': -0.04776397802711306, 'entropy_loss': -0.038333636708557606, 'vf_loss': 0.01210123666097809, 'total_loss': -0.08609761473567067, 'approx_kl': -0.06234362255781889, 'clip_fraction': 0.3541666716337204, 'grad_norm': 7.385099411010742}
2023-01-03 16:28:17.122 DEBUG: Taking gradient step
2023-01-03 16:28:19.197 DEBUG: Loss 8: {'policy_loss': -0.040196714571159246, 'entropy_loss': -0.03757066838443279, 'vf_loss': 0.012158030161014858, 'total_loss': -0.07776738295559203, 'approx_kl': -0.05747980996966362, 'clip_fraction': 0.3033854179084301, 'grad_norm': 6.945577621459961}
2023-01-03 16:28:21.234 DEBUG: Taking gradient step
2023-01-03 16:28:23.323 DEBUG: Loss 9: {'policy_loss': 0.0019922810074870408, 'entropy_loss': -0.03874265216290951, 'vf_loss': 0.014413006707741143, 'total_loss': -0.03675037115542247, 'approx_kl': -0.08097929041832685, 'clip_fraction': 0.3385416716337204, 'grad_norm': 7.014386177062988}
2023-01-03 16:28:25.338 DEBUG: Taking gradient step
2023-01-03 16:28:27.411 DEBUG: Loss 10: {'policy_loss': 0.009435415997353855, 'entropy_loss': -0.03769905399531126, 'vf_loss': 0.01471039851972519, 'total_loss': -0.028263637997957405, 'approx_kl': -0.07518511079251766, 'clip_fraction': 0.4166666716337204, 'grad_norm': 10.326833724975586}
2023-01-03 16:28:29.427 DEBUG: Taking gradient step
2023-01-03 16:28:31.474 DEBUG: Loss 11: {'policy_loss': -0.010356263921357998, 'entropy_loss': -0.03852826915681362, 'vf_loss': 0.013817140240831378, 'total_loss': -0.048884533078171616, 'approx_kl': -0.09090795367956161, 'clip_fraction': 0.4127604216337204, 'grad_norm': 8.302816390991211}
2023-01-03 16:28:33.508 DEBUG: Taking gradient step
2023-01-03 16:28:35.613 DEBUG: Loss 12: {'policy_loss': -0.020866268607298906, 'entropy_loss': -0.038220345973968506, 'vf_loss': 0.012801972103622354, 'total_loss': -0.05908661458126741, 'approx_kl': -0.06800511665642262, 'clip_fraction': 0.37109375, 'grad_norm': 12.963789939880371}
2023-01-03 16:28:37.640 DEBUG: Taking gradient step
2023-01-03 16:28:39.790 DEBUG: Loss 13: {'policy_loss': 0.011819640106867514, 'entropy_loss': -0.03836723044514656, 'vf_loss': 0.0143546796288447, 'total_loss': -0.026547590338279047, 'approx_kl': -0.0670943409204483, 'clip_fraction': 0.4166666716337204, 'grad_norm': 11.988536834716797}
2023-01-03 16:28:41.816 DEBUG: Taking gradient step
2023-01-03 16:28:43.885 DEBUG: Loss 14: {'policy_loss': 0.06330168322874902, 'entropy_loss': -0.0370864924043417, 'vf_loss': 0.015196528145503482, 'total_loss': 0.02621519082440732, 'approx_kl': -0.08201221376657486, 'clip_fraction': 0.4075520858168602, 'grad_norm': 13.132740020751953}
2023-01-03 16:28:43.885 INFO: Optimization: policy loss=0.063, vf loss=0.015, entropy loss=-0.037, total loss=0.026, num steps=15
2023-01-03 16:28:43.887 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 16:28:45.790 INFO: Evaluation rollout: return=0.593 (0.0), episode length=6.0
2023-01-03 16:28:45.791 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 16:28:45.795 INFO: Iteration: 70/137, steps: 15120
2023-01-03 16:29:19.039 DEBUG: Atoms are too close
2023-01-03 16:29:19.604 DEBUG: Atoms are too close
2023-01-03 16:29:19.606 DEBUG: Atoms are too close
2023-01-03 16:29:20.844 DEBUG: Atoms are too close
2023-01-03 16:29:42.377 INFO: Training rollout: return=-1.198 (4.8), episode length=5.9
2023-01-03 16:29:42.378 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 16:29:42.381 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-15120_train.pkl
2023-01-03 16:29:44.442 DEBUG: Taking gradient step
2023-01-03 16:29:46.612 DEBUG: Loss 0: {'policy_loss': 0.008825422387290942, 'entropy_loss': -0.03685100842267275, 'vf_loss': 0.013767533980056194, 'total_loss': -0.028025586035381807, 'approx_kl': 4.357813532251953e-08, 'clip_fraction': 0.0, 'grad_norm': 15.950203895568848}
2023-01-03 16:29:48.700 DEBUG: Taking gradient step
2023-01-03 16:29:50.831 DEBUG: Loss 1: {'policy_loss': 0.020523006674057258, 'entropy_loss': -0.03740839287638664, 'vf_loss': 0.01416862573464846, 'total_loss': -0.016885386202329385, 'approx_kl': -0.0072950918693095446, 'clip_fraction': 0.0234375, 'grad_norm': 13.8384370803833}
2023-01-03 16:29:52.890 DEBUG: Taking gradient step
2023-01-03 16:29:54.966 DEBUG: Loss 2: {'policy_loss': -0.028661877207066193, 'entropy_loss': -0.03832643013447523, 'vf_loss': 0.012026205670504497, 'total_loss': -0.06698830734154143, 'approx_kl': -0.022630592109635472, 'clip_fraction': 0.1653645858168602, 'grad_norm': 11.972542762756348}
2023-01-03 16:29:57.004 DEBUG: Taking gradient step
2023-01-03 16:29:59.133 DEBUG: Loss 3: {'policy_loss': -0.005523206364426242, 'entropy_loss': -0.03667106479406357, 'vf_loss': 0.012386739947897525, 'total_loss': -0.04219427115848981, 'approx_kl': -0.028421575902029872, 'clip_fraction': 0.25, 'grad_norm': 12.984854698181152}
2023-01-03 16:30:01.142 DEBUG: Taking gradient step
2023-01-03 16:30:03.509 DEBUG: Loss 4: {'policy_loss': 0.07819318640979629, 'entropy_loss': -0.03722031228244305, 'vf_loss': 0.015045835630146675, 'total_loss': 0.040972874127353245, 'approx_kl': -0.03388170525431633, 'clip_fraction': 0.2916666716337204, 'grad_norm': 22.90412712097168}
2023-01-03 16:30:05.662 DEBUG: Taking gradient step
2023-01-03 16:30:07.760 DEBUG: Loss 5: {'policy_loss': 0.026328107658060415, 'entropy_loss': -0.037606571801006794, 'vf_loss': 0.013871994842677496, 'total_loss': -0.011278464142946379, 'approx_kl': -0.04541371506638825, 'clip_fraction': 0.32421875, 'grad_norm': 12.604948997497559}
2023-01-03 16:30:09.767 DEBUG: Taking gradient step
2023-01-03 16:30:11.821 DEBUG: Loss 6: {'policy_loss': 0.011021150469934205, 'entropy_loss': -0.03735655266791582, 'vf_loss': 0.013215299387714652, 'total_loss': -0.026335402197981618, 'approx_kl': -0.048460953403264284, 'clip_fraction': 0.3919270858168602, 'grad_norm': 20.076906204223633}
2023-01-03 16:30:13.826 DEBUG: Taking gradient step
2023-01-03 16:30:15.871 DEBUG: Loss 7: {'policy_loss': -0.014235933854464533, 'entropy_loss': -0.03652875777333975, 'vf_loss': 0.012348287686732221, 'total_loss': -0.05076469162780428, 'approx_kl': -0.04814662761054933, 'clip_fraction': 0.3125, 'grad_norm': 12.958968162536621}
2023-01-03 16:30:17.872 DEBUG: Taking gradient step
2023-01-03 16:30:19.938 DEBUG: Loss 8: {'policy_loss': 0.026220989264539567, 'entropy_loss': -0.03549266653135419, 'vf_loss': 0.014374394747893244, 'total_loss': -0.009271677266814618, 'approx_kl': -0.04715660773217678, 'clip_fraction': 0.18229166697710752, 'grad_norm': 9.788476943969727}
2023-01-03 16:30:21.929 DEBUG: Taking gradient step
2023-01-03 16:30:23.996 DEBUG: Loss 9: {'policy_loss': 0.05551565512472649, 'entropy_loss': -0.03842860460281372, 'vf_loss': 0.016154710105597492, 'total_loss': 0.01708705052191277, 'approx_kl': -0.06152684520930052, 'clip_fraction': 0.1888020858168602, 'grad_norm': 15.141695976257324}
2023-01-03 16:30:25.994 DEBUG: Taking gradient step
2023-01-03 16:30:28.143 DEBUG: Loss 10: {'policy_loss': -0.01507008424181985, 'entropy_loss': -0.03726434055715799, 'vf_loss': 0.012312173175918798, 'total_loss': -0.05233442479897784, 'approx_kl': -0.05431210156530142, 'clip_fraction': 0.2096354179084301, 'grad_norm': 10.580538749694824}
2023-01-03 16:30:30.319 DEBUG: Taking gradient step
2023-01-03 16:30:32.747 DEBUG: Loss 11: {'policy_loss': -0.024035807633023674, 'entropy_loss': -0.035844606813043356, 'vf_loss': 0.012067840109499399, 'total_loss': -0.05988041444606703, 'approx_kl': -0.05699391267262399, 'clip_fraction': 0.23567708395421505, 'grad_norm': 11.54568862915039}
2023-01-03 16:30:34.751 DEBUG: Taking gradient step
2023-01-03 16:30:36.810 DEBUG: Loss 12: {'policy_loss': 0.025480773069088736, 'entropy_loss': -0.03629223071038723, 'vf_loss': 0.013919521863304425, 'total_loss': -0.01081145764129849, 'approx_kl': -0.07721203216351569, 'clip_fraction': 0.2877604216337204, 'grad_norm': 13.142149925231934}
2023-01-03 16:30:38.837 DEBUG: Taking gradient step
2023-01-03 16:30:40.926 DEBUG: Loss 13: {'policy_loss': -0.005825257434106142, 'entropy_loss': -0.035602765157818794, 'vf_loss': 0.012893369803080895, 'total_loss': -0.041428022591924935, 'approx_kl': -0.06469543231651187, 'clip_fraction': 0.2604166679084301, 'grad_norm': 14.088607788085938}
2023-01-03 16:30:42.953 DEBUG: Taking gradient step
2023-01-03 16:30:45.021 DEBUG: Loss 14: {'policy_loss': -0.00041193300352232107, 'entropy_loss': -0.036436677910387516, 'vf_loss': 0.013633167006422336, 'total_loss': -0.03684861091390984, 'approx_kl': -0.0763045297935605, 'clip_fraction': 0.2643229216337204, 'grad_norm': 12.09381103515625}
2023-01-03 16:30:45.022 INFO: Optimization: policy loss=-0.000, vf loss=0.014, entropy loss=-0.036, total loss=-0.037, num steps=15
2023-01-03 16:30:45.023 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 16:30:46.737 INFO: Evaluation rollout: return=0.595 (0.0), episode length=6.0
2023-01-03 16:30:46.738 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 16:30:46.741 DEBUG: Deleting old model: runs/CH3NO_dna/models/CH3NO_dna_run-1_steps-13176.model
2023-01-03 16:30:46.747 DEBUG: Saving model: runs/CH3NO_dna/models/CH3NO_dna_run-1_steps-15336.model
2023-01-03 16:30:46.795 INFO: Iteration: 71/137, steps: 15336
2023-01-03 16:31:00.109 DEBUG: Atoms are too close
2023-01-03 16:31:04.107 DEBUG: Atoms are too close
2023-01-03 16:31:18.425 DEBUG: There is a single atom floating around
2023-01-03 16:31:44.422 INFO: Training rollout: return=-0.763 (4.1), episode length=5.9
2023-01-03 16:31:44.424 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 16:31:44.427 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-15336_train.pkl
2023-01-03 16:31:46.526 DEBUG: Taking gradient step
2023-01-03 16:31:48.638 DEBUG: Loss 0: {'policy_loss': -0.04202348773320298, 'entropy_loss': -0.03619733080267906, 'vf_loss': 0.008837286523612695, 'total_loss': -0.07822081853588204, 'approx_kl': 4.825900146165907e-08, 'clip_fraction': 0.0, 'grad_norm': 16.290485382080078}
2023-01-03 16:31:50.691 DEBUG: Taking gradient step
2023-01-03 16:31:52.860 DEBUG: Loss 1: {'policy_loss': 0.02166618764484804, 'entropy_loss': -0.035098809748888016, 'vf_loss': 0.010907162233024646, 'total_loss': -0.013432622104039976, 'approx_kl': -0.011927498446311802, 'clip_fraction': 0.01953125, 'grad_norm': 23.003402709960938}
2023-01-03 16:31:55.100 DEBUG: Taking gradient step
2023-01-03 16:31:57.231 DEBUG: Loss 2: {'policy_loss': 0.025412424542456277, 'entropy_loss': -0.03536032373085618, 'vf_loss': 0.00997951144677231, 'total_loss': -0.009947899188399903, 'approx_kl': -0.040372919756919146, 'clip_fraction': 0.2486979216337204, 'grad_norm': 55.38534927368164}
2023-01-03 16:31:59.309 DEBUG: Taking gradient step
2023-01-03 16:32:01.442 DEBUG: Loss 3: {'policy_loss': 0.15078937406036705, 'entropy_loss': -0.035863677971065044, 'vf_loss': 0.01077854124496624, 'total_loss': 0.11492569608930202, 'approx_kl': -0.07413461850956082, 'clip_fraction': 0.3671875, 'grad_norm': 102.70344543457031}
2023-01-03 16:32:03.527 DEBUG: Taking gradient step
2023-01-03 16:32:05.646 DEBUG: Loss 4: {'policy_loss': 0.10909229821541899, 'entropy_loss': -0.035654119215905666, 'vf_loss': 0.011866423218012043, 'total_loss': 0.07343817899951333, 'approx_kl': -0.07002311199903488, 'clip_fraction': 0.4114583358168602, 'grad_norm': 51.01225662231445}
2023-01-03 16:32:07.716 DEBUG: Taking gradient step
2023-01-03 16:32:09.841 DEBUG: Loss 5: {'policy_loss': 0.11945172243249844, 'entropy_loss': -0.034582775086164474, 'vf_loss': 0.011405963484534386, 'total_loss': 0.08486894734633396, 'approx_kl': -0.06666753068566322, 'clip_fraction': 0.3763020858168602, 'grad_norm': 39.49124526977539}
2023-01-03 16:32:11.913 DEBUG: Taking gradient step
2023-01-03 16:32:14.031 DEBUG: Loss 6: {'policy_loss': 0.06025297472976997, 'entropy_loss': -0.03401200659573078, 'vf_loss': 0.010898912478119608, 'total_loss': 0.026240968134039186, 'approx_kl': -0.07829153165221214, 'clip_fraction': 0.3697916716337204, 'grad_norm': 26.206417083740234}
2023-01-03 16:32:16.088 DEBUG: Taking gradient step
2023-01-03 16:32:18.288 DEBUG: Loss 7: {'policy_loss': -0.025677306535605543, 'entropy_loss': -0.03281976794824004, 'vf_loss': 0.008898713560784066, 'total_loss': -0.058497074483845585, 'approx_kl': -0.0711285974830389, 'clip_fraction': 0.3515625, 'grad_norm': 23.3728084564209}
2023-01-03 16:32:20.356 DEBUG: Taking gradient step
2023-01-03 16:32:22.483 DEBUG: Loss 8: {'policy_loss': -0.025221827423697316, 'entropy_loss': -0.03415903355926275, 'vf_loss': 0.009330166682995399, 'total_loss': -0.05938086098296007, 'approx_kl': -0.09449864365160465, 'clip_fraction': 0.3359375, 'grad_norm': 26.229827880859375}
2023-01-03 16:32:24.562 DEBUG: Taking gradient step
2023-01-03 16:32:26.692 DEBUG: Loss 9: {'policy_loss': 0.020415702927610583, 'entropy_loss': -0.03443955583497882, 'vf_loss': 0.010550359904602128, 'total_loss': -0.014023852907368236, 'approx_kl': -0.0840757298283279, 'clip_fraction': 0.359375, 'grad_norm': 27.092618942260742}
2023-01-03 16:32:28.762 DEBUG: Taking gradient step
2023-01-03 16:32:30.888 DEBUG: Loss 10: {'policy_loss': -0.03990761847414445, 'entropy_loss': -0.03376876702532172, 'vf_loss': 0.00893995038032391, 'total_loss': -0.07367638549946617, 'approx_kl': -0.0954157393425703, 'clip_fraction': 0.4244791716337204, 'grad_norm': 24.256080627441406}
2023-01-03 16:32:32.952 DEBUG: Taking gradient step
2023-01-03 16:32:35.093 DEBUG: Loss 11: {'policy_loss': -0.002730000582907434, 'entropy_loss': -0.03396083461120725, 'vf_loss': 0.009953312404713895, 'total_loss': -0.03669083519411468, 'approx_kl': -0.0915018655359745, 'clip_fraction': 0.44140625, 'grad_norm': 26.574623107910156}
2023-01-03 16:32:37.162 DEBUG: Taking gradient step
2023-01-03 16:32:39.282 DEBUG: Loss 12: {'policy_loss': 0.07811430977805311, 'entropy_loss': -0.033246840350329876, 'vf_loss': 0.012345137194594992, 'total_loss': 0.044867469427723246, 'approx_kl': -0.0991404578089714, 'clip_fraction': 0.49609375, 'grad_norm': 37.82796859741211}
2023-01-03 16:32:41.357 DEBUG: Taking gradient step
2023-01-03 16:32:43.446 DEBUG: Loss 13: {'policy_loss': 0.020426977751363984, 'entropy_loss': -0.032452919986099005, 'vf_loss': 0.009344280372802471, 'total_loss': -0.012025942234735021, 'approx_kl': -0.10346323624253273, 'clip_fraction': 0.4375, 'grad_norm': 35.095130920410156}
2023-01-03 16:32:45.466 DEBUG: Taking gradient step
2023-01-03 16:32:47.557 DEBUG: Loss 14: {'policy_loss': -0.00025274605270434597, 'entropy_loss': -0.03370723035186529, 'vf_loss': 0.008840654489856756, 'total_loss': -0.03395997640456963, 'approx_kl': -0.12374036014080048, 'clip_fraction': 0.4739583432674408, 'grad_norm': 32.97853469848633}
2023-01-03 16:32:47.558 INFO: Optimization: policy loss=-0.000, vf loss=0.009, entropy loss=-0.034, total loss=-0.034, num steps=15
2023-01-03 16:32:47.559 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 16:32:49.276 INFO: Evaluation rollout: return=0.593 (0.0), episode length=6.0
2023-01-03 16:32:49.277 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 16:32:49.279 INFO: Iteration: 72/137, steps: 15552
2023-01-03 16:33:07.201 DEBUG: Atoms are too close
2023-01-03 16:33:20.826 DEBUG: Atoms are too close
2023-01-03 16:33:25.982 DEBUG: Atoms are too close
2023-01-03 16:33:42.959 DEBUG: Atoms are too close
2023-01-03 16:33:43.184 DEBUG: Atoms are too close
2023-01-03 16:33:45.989 INFO: Training rollout: return=-1.877 (5.3), episode length=5.9
2023-01-03 16:33:45.991 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 16:33:45.994 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-15552_train.pkl
2023-01-03 16:33:48.040 DEBUG: Taking gradient step
2023-01-03 16:33:50.135 DEBUG: Loss 0: {'policy_loss': 0.01687431816648373, 'entropy_loss': -0.034425890538841486, 'vf_loss': 0.022291147404563196, 'total_loss': -0.017551572372357757, 'approx_kl': -6.509556738087952e-08, 'clip_fraction': 0.0, 'grad_norm': 14.017203330993652}
2023-01-03 16:33:52.170 DEBUG: Taking gradient step
2023-01-03 16:33:54.236 DEBUG: Loss 1: {'policy_loss': -0.0448935901918614, 'entropy_loss': -0.03351450292393565, 'vf_loss': 0.01892536731109487, 'total_loss': -0.07840809311579705, 'approx_kl': -0.0049304659478366375, 'clip_fraction': 0.07421875, 'grad_norm': 13.215059280395508}
2023-01-03 16:33:56.225 DEBUG: Taking gradient step
2023-01-03 16:33:58.285 DEBUG: Loss 2: {'policy_loss': -0.014560932471768194, 'entropy_loss': -0.033657560124993324, 'vf_loss': 0.019742871770001245, 'total_loss': -0.04821849259676152, 'approx_kl': -0.010581630747765303, 'clip_fraction': 0.20833333395421505, 'grad_norm': 14.884675025939941}
2023-01-03 16:34:00.311 DEBUG: Taking gradient step
2023-01-03 16:34:02.430 DEBUG: Loss 3: {'policy_loss': 0.08234520830110217, 'entropy_loss': -0.03372881282120943, 'vf_loss': 0.023102450736663442, 'total_loss': 0.04861639547989274, 'approx_kl': -0.027948093134909868, 'clip_fraction': 0.3463541716337204, 'grad_norm': 30.333498001098633}
2023-01-03 16:34:04.499 DEBUG: Taking gradient step
2023-01-03 16:34:06.626 DEBUG: Loss 4: {'policy_loss': -0.0339653976482723, 'entropy_loss': -0.03463922720402479, 'vf_loss': 0.018196783139801085, 'total_loss': -0.0686046248522971, 'approx_kl': -0.01357499836012721, 'clip_fraction': 0.3893229216337204, 'grad_norm': 17.294599533081055}
2023-01-03 16:34:08.661 DEBUG: Taking gradient step
2023-01-03 16:34:10.811 DEBUG: Loss 5: {'policy_loss': 0.027005125971957582, 'entropy_loss': -0.034517292864620686, 'vf_loss': 0.022307673327756402, 'total_loss': -0.007512166892663104, 'approx_kl': -0.022639081813395023, 'clip_fraction': 0.3463541716337204, 'grad_norm': 23.34161949157715}
2023-01-03 16:34:12.828 DEBUG: Taking gradient step
2023-01-03 16:34:14.894 DEBUG: Loss 6: {'policy_loss': -0.006030084736894602, 'entropy_loss': -0.0351174627430737, 'vf_loss': 0.021345295464177707, 'total_loss': -0.04114754747996831, 'approx_kl': -0.015393044566735625, 'clip_fraction': 0.2721354216337204, 'grad_norm': 8.388198852539062}
2023-01-03 16:34:16.912 DEBUG: Taking gradient step
2023-01-03 16:34:18.981 DEBUG: Loss 7: {'policy_loss': -0.036738954493526974, 'entropy_loss': -0.03290416765958071, 'vf_loss': 0.019586770964055256, 'total_loss': -0.06964312215310768, 'approx_kl': -0.0151890954002738, 'clip_fraction': 0.3294270858168602, 'grad_norm': 10.772286415100098}
2023-01-03 16:34:21.021 DEBUG: Taking gradient step
2023-01-03 16:34:23.087 DEBUG: Loss 8: {'policy_loss': -0.04435367733656031, 'entropy_loss': -0.033046565018594265, 'vf_loss': 0.018836432388466606, 'total_loss': -0.07740024235515458, 'approx_kl': -0.02177232038229704, 'clip_fraction': 0.375, 'grad_norm': 6.836371421813965}
2023-01-03 16:34:25.107 DEBUG: Taking gradient step
2023-01-03 16:34:27.191 DEBUG: Loss 9: {'policy_loss': -0.038172234982209896, 'entropy_loss': -0.03346692863851786, 'vf_loss': 0.0186122037952793, 'total_loss': -0.07163916362072775, 'approx_kl': -0.030279692262411118, 'clip_fraction': 0.34765625, 'grad_norm': 19.14919662475586}
2023-01-03 16:34:29.210 DEBUG: Taking gradient step
2023-01-03 16:34:31.277 DEBUG: Loss 10: {'policy_loss': 0.033088822057907384, 'entropy_loss': -0.033191647846251726, 'vf_loss': 0.021715159547017568, 'total_loss': -0.00010282578834434203, 'approx_kl': -0.020621130766812712, 'clip_fraction': 0.4361979216337204, 'grad_norm': 23.57451057434082}
2023-01-03 16:34:33.297 DEBUG: Taking gradient step
2023-01-03 16:34:35.364 DEBUG: Loss 11: {'policy_loss': -0.022170135326202184, 'entropy_loss': -0.03252093633636832, 'vf_loss': 0.01987681348966521, 'total_loss': -0.054691071662570506, 'approx_kl': -0.03315065987408161, 'clip_fraction': 0.3893229216337204, 'grad_norm': 13.71574592590332}
2023-01-03 16:34:37.377 DEBUG: Taking gradient step
2023-01-03 16:34:39.440 DEBUG: Loss 12: {'policy_loss': -0.03551179662909449, 'entropy_loss': -0.03325029835104942, 'vf_loss': 0.018204939683283867, 'total_loss': -0.0687620949801439, 'approx_kl': -0.031053020618855953, 'clip_fraction': 0.4088541716337204, 'grad_norm': 11.092432022094727}
2023-01-03 16:34:41.459 DEBUG: Taking gradient step
2023-01-03 16:34:43.525 DEBUG: Loss 13: {'policy_loss': 0.0734571069731705, 'entropy_loss': -0.032374718226492405, 'vf_loss': 0.024266624264517277, 'total_loss': 0.04108238874667809, 'approx_kl': -0.023282282054424286, 'clip_fraction': 0.2630208358168602, 'grad_norm': 13.250181198120117}
2023-01-03 16:34:45.543 DEBUG: Taking gradient step
2023-01-03 16:34:47.623 DEBUG: Loss 14: {'policy_loss': 0.004527649213334192, 'entropy_loss': -0.03269061539322138, 'vf_loss': 0.019869328040052363, 'total_loss': -0.028162966179887186, 'approx_kl': -0.04119676584377885, 'clip_fraction': 0.3098958358168602, 'grad_norm': 19.316843032836914}
2023-01-03 16:34:47.623 INFO: Optimization: policy loss=0.005, vf loss=0.020, entropy loss=-0.033, total loss=-0.028, num steps=15
2023-01-03 16:34:47.624 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 16:34:49.311 INFO: Evaluation rollout: return=0.596 (0.0), episode length=6.0
2023-01-03 16:34:49.313 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 16:34:49.317 INFO: Iteration: 73/137, steps: 15768
2023-01-03 16:35:22.405 DEBUG: Atoms are too close
2023-01-03 16:35:46.916 INFO: Training rollout: return=0.082 (2.6), episode length=6.0
2023-01-03 16:35:46.917 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 16:35:46.920 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-15768_train.pkl
2023-01-03 16:35:49.003 DEBUG: Taking gradient step
2023-01-03 16:35:51.079 DEBUG: Loss 0: {'policy_loss': -0.018704329996907333, 'entropy_loss': -0.033002695068717, 'vf_loss': 0.005849165911401143, 'total_loss': -0.051707025065624336, 'approx_kl': 3.864988684654236e-08, 'clip_fraction': 0.0, 'grad_norm': 19.250022888183594}
2023-01-03 16:35:53.097 DEBUG: Taking gradient step
2023-01-03 16:35:55.200 DEBUG: Loss 1: {'policy_loss': -0.014016650010336824, 'entropy_loss': -0.033055808395147324, 'vf_loss': 0.006510844571506892, 'total_loss': -0.04707245840548415, 'approx_kl': -0.006694444688037038, 'clip_fraction': 0.1861979179084301, 'grad_norm': 11.755278587341309}
2023-01-03 16:35:57.302 DEBUG: Taking gradient step
2023-01-03 16:35:59.371 DEBUG: Loss 2: {'policy_loss': -0.03076193367813478, 'entropy_loss': -0.03366107167676091, 'vf_loss': 0.006290751851164452, 'total_loss': -0.06442300535489569, 'approx_kl': -0.02283250936307013, 'clip_fraction': 0.3932291716337204, 'grad_norm': 12.310172080993652}
2023-01-03 16:36:01.492 DEBUG: Taking gradient step
2023-01-03 16:36:03.575 DEBUG: Loss 3: {'policy_loss': 0.007800261524831886, 'entropy_loss': -0.03327721310779452, 'vf_loss': 0.007149383280788166, 'total_loss': -0.025476951582962638, 'approx_kl': -0.016502938698977232, 'clip_fraction': 0.4453125, 'grad_norm': 33.584171295166016}
2023-01-03 16:36:05.615 DEBUG: Taking gradient step
2023-01-03 16:36:07.713 DEBUG: Loss 4: {'policy_loss': -0.019108144658914646, 'entropy_loss': -0.03402009792625904, 'vf_loss': 0.005712557556645444, 'total_loss': -0.053128242585173686, 'approx_kl': -0.019029762595891953, 'clip_fraction': 0.3984375, 'grad_norm': 13.147926330566406}
2023-01-03 16:36:09.794 DEBUG: Taking gradient step
2023-01-03 16:36:11.908 DEBUG: Loss 5: {'policy_loss': -0.03402598083628946, 'entropy_loss': -0.0320112113840878, 'vf_loss': 0.005275408559915178, 'total_loss': -0.06603719222037727, 'approx_kl': -0.027997746132314205, 'clip_fraction': 0.4401041716337204, 'grad_norm': 13.74283218383789}
2023-01-03 16:36:13.934 DEBUG: Taking gradient step
2023-01-03 16:36:16.010 DEBUG: Loss 6: {'policy_loss': 0.02577853085945531, 'entropy_loss': -0.03358518052846193, 'vf_loss': 0.005815178721845052, 'total_loss': -0.007806649669006627, 'approx_kl': -0.020134857040829957, 'clip_fraction': 0.3893229216337204, 'grad_norm': 33.684349060058594}
2023-01-03 16:36:18.028 DEBUG: Taking gradient step
2023-01-03 16:36:20.136 DEBUG: Loss 7: {'policy_loss': -0.027312619514459922, 'entropy_loss': -0.03265460254624486, 'vf_loss': 0.004513828861673288, 'total_loss': -0.05996722206070478, 'approx_kl': -0.018866591155529022, 'clip_fraction': 0.3606770858168602, 'grad_norm': 13.420557022094727}
2023-01-03 16:36:22.204 DEBUG: Taking gradient step
2023-01-03 16:36:24.272 DEBUG: Loss 8: {'policy_loss': 0.030326081251161603, 'entropy_loss': -0.03243167046457529, 'vf_loss': 0.005822593570218006, 'total_loss': -0.0021055892134136944, 'approx_kl': -0.034253792371600866, 'clip_fraction': 0.3841145858168602, 'grad_norm': 6.202755928039551}
2023-01-03 16:36:26.297 DEBUG: Taking gradient step
2023-01-03 16:36:28.355 DEBUG: Loss 9: {'policy_loss': 0.0630923269482675, 'entropy_loss': -0.032675801776349545, 'vf_loss': 0.006040974172932803, 'total_loss': 0.030416525171917952, 'approx_kl': -0.02607431064825505, 'clip_fraction': 0.3763020858168602, 'grad_norm': 18.42354393005371}
2023-01-03 16:36:30.386 DEBUG: Taking gradient step
2023-01-03 16:36:32.454 DEBUG: Loss 10: {'policy_loss': -0.017652959272179705, 'entropy_loss': -0.0328905051574111, 'vf_loss': 0.0038168264744953004, 'total_loss': -0.050543464429590804, 'approx_kl': -0.03537290683016181, 'clip_fraction': 0.3372395858168602, 'grad_norm': 21.14434242248535}
2023-01-03 16:36:34.481 DEBUG: Taking gradient step
2023-01-03 16:36:36.557 DEBUG: Loss 11: {'policy_loss': 0.001092779495035607, 'entropy_loss': -0.03307130141183734, 'vf_loss': 0.004277977146525829, 'total_loss': -0.03197852191680174, 'approx_kl': -0.038875458762049675, 'clip_fraction': 0.3984375, 'grad_norm': 15.188993453979492}
2023-01-03 16:36:38.557 DEBUG: Taking gradient step
2023-01-03 16:36:40.624 DEBUG: Loss 12: {'policy_loss': -0.040228772887859275, 'entropy_loss': -0.03361485479399562, 'vf_loss': 0.0035508867003536475, 'total_loss': -0.07384362768185489, 'approx_kl': -0.032295988872647285, 'clip_fraction': 0.3763020858168602, 'grad_norm': 13.072887420654297}
2023-01-03 16:36:42.641 DEBUG: Taking gradient step
2023-01-03 16:36:44.706 DEBUG: Loss 13: {'policy_loss': -0.017241402447845222, 'entropy_loss': -0.03295820439234376, 'vf_loss': 0.0034370754263966315, 'total_loss': -0.05019960684018898, 'approx_kl': -0.06350894924253225, 'clip_fraction': 0.4010416716337204, 'grad_norm': 11.683929443359375}
2023-01-03 16:36:46.717 DEBUG: Taking gradient step
2023-01-03 16:36:48.782 DEBUG: Loss 14: {'policy_loss': -0.03686186084759584, 'entropy_loss': -0.03450898174196482, 'vf_loss': 0.0033657518111924545, 'total_loss': -0.07137084258956065, 'approx_kl': -0.051363949198275805, 'clip_fraction': 0.4114583358168602, 'grad_norm': 13.093603134155273}
2023-01-03 16:36:48.783 INFO: Optimization: policy loss=-0.037, vf loss=0.003, entropy loss=-0.035, total loss=-0.071, num steps=15
2023-01-03 16:36:48.784 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 16:36:50.492 INFO: Evaluation rollout: return=0.600 (0.0), episode length=6.0
2023-01-03 16:36:50.493 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 16:36:50.496 INFO: Iteration: 74/137, steps: 15984
2023-01-03 16:37:04.278 DEBUG: Atoms are too close
2023-01-03 16:37:21.698 DEBUG: Atoms are too close
2023-01-03 16:37:23.937 DEBUG: Atoms are too close
2023-01-03 16:37:46.306 INFO: Training rollout: return=-0.797 (4.4), episode length=5.9
2023-01-03 16:37:46.307 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 16:37:46.310 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-15984_train.pkl
2023-01-03 16:37:48.349 DEBUG: Taking gradient step
2023-01-03 16:37:50.409 DEBUG: Loss 0: {'policy_loss': -0.011227322734931627, 'entropy_loss': -0.03383107203990221, 'vf_loss': 0.009848634206972358, 'total_loss': -0.04505839477483384, 'approx_kl': -2.173086244283695e-08, 'clip_fraction': 0.0, 'grad_norm': 10.485584259033203}
2023-01-03 16:37:52.411 DEBUG: Taking gradient step
2023-01-03 16:37:54.482 DEBUG: Loss 1: {'policy_loss': 0.014432221446462362, 'entropy_loss': -0.03607452800497413, 'vf_loss': 0.010865711662352692, 'total_loss': -0.021642306558511765, 'approx_kl': -0.015501336893066764, 'clip_fraction': 0.109375, 'grad_norm': 17.56713104248047}
2023-01-03 16:37:56.490 DEBUG: Taking gradient step
2023-01-03 16:37:58.542 DEBUG: Loss 2: {'policy_loss': -0.05033907219494431, 'entropy_loss': -0.03397146938368678, 'vf_loss': 0.008901324614699892, 'total_loss': -0.08431054157863109, 'approx_kl': -0.026225214824080467, 'clip_fraction': 0.2955729179084301, 'grad_norm': 8.850902557373047}
2023-01-03 16:38:00.555 DEBUG: Taking gradient step
2023-01-03 16:38:02.624 DEBUG: Loss 3: {'policy_loss': -0.015797270836141457, 'entropy_loss': -0.03287052921950817, 'vf_loss': 0.010523777023427093, 'total_loss': -0.04866780005564963, 'approx_kl': -0.011536001227796078, 'clip_fraction': 0.3658854216337204, 'grad_norm': 9.360325813293457}
2023-01-03 16:38:04.661 DEBUG: Taking gradient step
2023-01-03 16:38:06.770 DEBUG: Loss 4: {'policy_loss': 0.001409775548362505, 'entropy_loss': -0.033850269857794046, 'vf_loss': 0.01051589081808375, 'total_loss': -0.032440494309431536, 'approx_kl': -0.032161736860871315, 'clip_fraction': 0.3294270858168602, 'grad_norm': 8.736255645751953}
2023-01-03 16:38:08.818 DEBUG: Taking gradient step
2023-01-03 16:38:11.029 DEBUG: Loss 5: {'policy_loss': -0.009377033377865586, 'entropy_loss': -0.033867440186440945, 'vf_loss': 0.01064838620763896, 'total_loss': -0.04324447356430653, 'approx_kl': -0.047343434765934944, 'clip_fraction': 0.2786458358168602, 'grad_norm': 8.945598602294922}
2023-01-03 16:38:13.083 DEBUG: Taking gradient step
2023-01-03 16:38:15.171 DEBUG: Loss 6: {'policy_loss': -0.012647727689848533, 'entropy_loss': -0.03439716715365648, 'vf_loss': 0.011228731264337172, 'total_loss': -0.04704489484350502, 'approx_kl': -0.04959330894052982, 'clip_fraction': 0.21875, 'grad_norm': 11.952532768249512}
2023-01-03 16:38:17.226 DEBUG: Taking gradient step
2023-01-03 16:38:19.325 DEBUG: Loss 7: {'policy_loss': 0.027031185188577722, 'entropy_loss': -0.03445270750671625, 'vf_loss': 0.011643639338740623, 'total_loss': -0.007421522318138529, 'approx_kl': -0.049006409011781216, 'clip_fraction': 0.33984375, 'grad_norm': 7.8341474533081055}
2023-01-03 16:38:21.556 DEBUG: Taking gradient step
2023-01-03 16:38:23.604 DEBUG: Loss 8: {'policy_loss': -0.012742197126139424, 'entropy_loss': -0.035507879219949245, 'vf_loss': 0.0108102946726952, 'total_loss': -0.048250076346088674, 'approx_kl': -0.04495582095114514, 'clip_fraction': 0.359375, 'grad_norm': 8.438497543334961}
2023-01-03 16:38:25.622 DEBUG: Taking gradient step
2023-01-03 16:38:27.690 DEBUG: Loss 9: {'policy_loss': -0.05348602625756565, 'entropy_loss': -0.03314313432201743, 'vf_loss': 0.008903555437636117, 'total_loss': -0.08662916057958309, 'approx_kl': -0.07168909534811974, 'clip_fraction': 0.2903645858168602, 'grad_norm': 6.272528648376465}
2023-01-03 16:38:29.717 DEBUG: Taking gradient step
2023-01-03 16:38:31.786 DEBUG: Loss 10: {'policy_loss': -0.04628099877189315, 'entropy_loss': -0.03519719187170267, 'vf_loss': 0.008883724941654094, 'total_loss': -0.08147819064359582, 'approx_kl': -0.08433901332318783, 'clip_fraction': 0.3463541716337204, 'grad_norm': 5.6865620613098145}
2023-01-03 16:38:33.803 DEBUG: Taking gradient step
2023-01-03 16:38:35.870 DEBUG: Loss 11: {'policy_loss': -0.029679941515577797, 'entropy_loss': -0.03436374058946967, 'vf_loss': 0.009292875770995333, 'total_loss': -0.06404368210504746, 'approx_kl': -0.06396435512579046, 'clip_fraction': 0.3502604216337204, 'grad_norm': 9.299480438232422}
2023-01-03 16:38:37.889 DEBUG: Taking gradient step
2023-01-03 16:38:40.088 DEBUG: Loss 12: {'policy_loss': 0.003146755018648792, 'entropy_loss': -0.03557372186332941, 'vf_loss': 0.01110450669856394, 'total_loss': -0.03242696684468062, 'approx_kl': -0.10092132166028023, 'clip_fraction': 0.4361979216337204, 'grad_norm': 9.969326972961426}
2023-01-03 16:38:42.142 DEBUG: Taking gradient step
2023-01-03 16:38:44.263 DEBUG: Loss 13: {'policy_loss': -0.05033741601814275, 'entropy_loss': -0.03410375164821744, 'vf_loss': 0.008842709721083206, 'total_loss': -0.08444116766636019, 'approx_kl': -0.07906429469585419, 'clip_fraction': 0.3763020858168602, 'grad_norm': 9.734622955322266}
2023-01-03 16:38:46.333 DEBUG: Taking gradient step
2023-01-03 16:38:48.450 DEBUG: Loss 14: {'policy_loss': 0.037855921459639445, 'entropy_loss': -0.03488271124660969, 'vf_loss': 0.013326840804130555, 'total_loss': 0.0029732102130297644, 'approx_kl': -0.06943215383216739, 'clip_fraction': 0.34375, 'grad_norm': 20.33162498474121}
2023-01-03 16:38:48.451 INFO: Optimization: policy loss=0.038, vf loss=0.013, entropy loss=-0.035, total loss=0.003, num steps=15
2023-01-03 16:38:48.452 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 16:38:50.147 INFO: Evaluation rollout: return=0.598 (0.0), episode length=6.0
2023-01-03 16:38:50.147 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 16:38:50.151 INFO: Iteration: 75/137, steps: 16200
2023-01-03 16:39:42.327 DEBUG: There is a single atom floating around
2023-01-03 16:39:44.388 DEBUG: Atoms are too close
2023-01-03 16:39:44.689 DEBUG: Atoms are too close
2023-01-03 16:39:46.970 INFO: Training rollout: return=-1.420 (4.8), episode length=6.0
2023-01-03 16:39:46.971 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 16:39:46.974 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-16200_train.pkl
2023-01-03 16:39:49.088 DEBUG: Taking gradient step
2023-01-03 16:39:51.237 DEBUG: Loss 0: {'policy_loss': 0.022971691113507883, 'entropy_loss': -0.033280668780207634, 'vf_loss': 0.01855530699358189, 'total_loss': -0.010308977666699755, 'approx_kl': 3.2247044146060944e-08, 'clip_fraction': 0.0, 'grad_norm': 12.722792625427246}
2023-01-03 16:39:53.326 DEBUG: Taking gradient step
2023-01-03 16:39:55.469 DEBUG: Loss 1: {'policy_loss': 0.0031379068759886507, 'entropy_loss': -0.03345917724072933, 'vf_loss': 0.018421268472179845, 'total_loss': -0.030321270364740686, 'approx_kl': 0.0028176860651001334, 'clip_fraction': 0.07682291697710752, 'grad_norm': 9.23066234588623}
2023-01-03 16:39:57.545 DEBUG: Taking gradient step
2023-01-03 16:39:59.685 DEBUG: Loss 2: {'policy_loss': 0.060026231882569565, 'entropy_loss': -0.03352061193436384, 'vf_loss': 0.02147201791579526, 'total_loss': 0.02650561994820573, 'approx_kl': -0.0062589377630501986, 'clip_fraction': 0.1927083358168602, 'grad_norm': 11.915680885314941}
2023-01-03 16:40:01.787 DEBUG: Taking gradient step
2023-01-03 16:40:03.952 DEBUG: Loss 3: {'policy_loss': -0.021592872576811434, 'entropy_loss': -0.03270799573510885, 'vf_loss': 0.01785785822699831, 'total_loss': -0.05430086831192028, 'approx_kl': -0.010360621614381671, 'clip_fraction': 0.30859375, 'grad_norm': 11.983792304992676}
2023-01-03 16:40:06.039 DEBUG: Taking gradient step
2023-01-03 16:40:08.168 DEBUG: Loss 4: {'policy_loss': -0.040463177925116, 'entropy_loss': -0.032631498761475086, 'vf_loss': 0.016058332585288736, 'total_loss': -0.07309467668659109, 'approx_kl': -0.04393962281756103, 'clip_fraction': 0.33984375, 'grad_norm': 10.420002937316895}
2023-01-03 16:40:10.226 DEBUG: Taking gradient step
2023-01-03 16:40:12.397 DEBUG: Loss 5: {'policy_loss': 0.00468045370669299, 'entropy_loss': -0.033454157412052155, 'vf_loss': 0.01813815683064501, 'total_loss': -0.028773703705359165, 'approx_kl': -0.03124864911660552, 'clip_fraction': 0.2864583358168602, 'grad_norm': 10.18393611907959}
2023-01-03 16:40:14.483 DEBUG: Taking gradient step
2023-01-03 16:40:16.613 DEBUG: Loss 6: {'policy_loss': 0.0034121055636189123, 'entropy_loss': -0.03303925693035126, 'vf_loss': 0.01867817119390476, 'total_loss': -0.02962715136673235, 'approx_kl': -0.043771263444796205, 'clip_fraction': 0.2135416679084301, 'grad_norm': 13.245577812194824}
2023-01-03 16:40:18.887 DEBUG: Taking gradient step
2023-01-03 16:40:20.990 DEBUG: Loss 7: {'policy_loss': -0.027435589976254785, 'entropy_loss': -0.033083247020840645, 'vf_loss': 0.015834245508956336, 'total_loss': -0.060518836997095427, 'approx_kl': -0.03642416629008949, 'clip_fraction': 0.24609375, 'grad_norm': 15.955682754516602}
2023-01-03 16:40:23.033 DEBUG: Taking gradient step
2023-01-03 16:40:25.137 DEBUG: Loss 8: {'policy_loss': -0.0004777785127093639, 'entropy_loss': -0.033242620062083006, 'vf_loss': 0.017478215112058125, 'total_loss': -0.03372039857479237, 'approx_kl': -0.039044334553182125, 'clip_fraction': 0.2760416716337204, 'grad_norm': 14.1144380569458}
2023-01-03 16:40:27.185 DEBUG: Taking gradient step
2023-01-03 16:40:29.395 DEBUG: Loss 9: {'policy_loss': 0.042201597804575865, 'entropy_loss': -0.03370590740814805, 'vf_loss': 0.01955695870962596, 'total_loss': 0.008495690396427814, 'approx_kl': -0.029539994662627578, 'clip_fraction': 0.2942708358168602, 'grad_norm': 14.366582870483398}
2023-01-03 16:40:31.442 DEBUG: Taking gradient step
2023-01-03 16:40:33.543 DEBUG: Loss 10: {'policy_loss': -0.026546630177383332, 'entropy_loss': -0.03222347376868129, 'vf_loss': 0.01687685938483676, 'total_loss': -0.05877010394606462, 'approx_kl': -0.04633441474288702, 'clip_fraction': 0.2291666679084301, 'grad_norm': 14.568504333496094}
2023-01-03 16:40:35.603 DEBUG: Taking gradient step
2023-01-03 16:40:37.709 DEBUG: Loss 11: {'policy_loss': -0.03631743437458783, 'entropy_loss': -0.03310951590538025, 'vf_loss': 0.01602146657008012, 'total_loss': -0.06942695027996808, 'approx_kl': -0.05092340987175703, 'clip_fraction': 0.2408854216337204, 'grad_norm': 7.629212856292725}
2023-01-03 16:40:39.776 DEBUG: Taking gradient step
2023-01-03 16:40:41.877 DEBUG: Loss 12: {'policy_loss': 0.056816718354779305, 'entropy_loss': -0.03280995041131973, 'vf_loss': 0.019435783712373624, 'total_loss': 0.02400676794345958, 'approx_kl': -0.04343223152682185, 'clip_fraction': 0.3763020858168602, 'grad_norm': 26.82487678527832}
2023-01-03 16:40:43.931 DEBUG: Taking gradient step
2023-01-03 16:40:46.036 DEBUG: Loss 13: {'policy_loss': -0.05840377943229142, 'entropy_loss': -0.03169755497947335, 'vf_loss': 0.015119210407497313, 'total_loss': -0.09010133441176477, 'approx_kl': -0.0534131838940084, 'clip_fraction': 0.3763020858168602, 'grad_norm': 14.884437561035156}
2023-01-03 16:40:48.093 DEBUG: Taking gradient step
2023-01-03 16:40:50.198 DEBUG: Loss 14: {'policy_loss': 0.006794032889966271, 'entropy_loss': -0.032444318290799856, 'vf_loss': 0.017750111358643537, 'total_loss': -0.025650285400833583, 'approx_kl': -0.05685346480458975, 'clip_fraction': 0.4309895858168602, 'grad_norm': 14.194241523742676}
2023-01-03 16:40:50.199 INFO: Optimization: policy loss=0.007, vf loss=0.018, entropy loss=-0.032, total loss=-0.026, num steps=15
2023-01-03 16:40:50.200 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 16:40:51.928 INFO: Evaluation rollout: return=0.597 (0.0), episode length=6.0
2023-01-03 16:40:51.929 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 16:40:51.932 INFO: Iteration: 76/137, steps: 16416
2023-01-03 16:41:45.303 DEBUG: Atoms are too close
2023-01-03 16:41:49.300 INFO: Training rollout: return=-0.305 (3.4), episode length=6.0
2023-01-03 16:41:49.302 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 16:41:49.305 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-16416_train.pkl
2023-01-03 16:41:51.376 DEBUG: Taking gradient step
2023-01-03 16:41:53.492 DEBUG: Loss 0: {'policy_loss': -0.03506844646817659, 'entropy_loss': -0.03489399328827858, 'vf_loss': 0.006441436133137516, 'total_loss': -0.06996243975645516, 'approx_kl': -5.70823139867116e-08, 'clip_fraction': 0.0, 'grad_norm': 8.102581024169922}
2023-01-03 16:41:55.523 DEBUG: Taking gradient step
2023-01-03 16:41:57.612 DEBUG: Loss 1: {'policy_loss': -0.01801314146274651, 'entropy_loss': -0.03327174112200737, 'vf_loss': 0.006992418571444283, 'total_loss': -0.05128488258475388, 'approx_kl': -0.02192854299210012, 'clip_fraction': 0.1510416679084301, 'grad_norm': 10.684657096862793}
2023-01-03 16:41:59.643 DEBUG: Taking gradient step
2023-01-03 16:42:01.720 DEBUG: Loss 2: {'policy_loss': 0.011717545326980763, 'entropy_loss': -0.03410493163391948, 'vf_loss': 0.007414075768626029, 'total_loss': -0.022387386306938716, 'approx_kl': -0.02097775787115097, 'clip_fraction': 0.3463541716337204, 'grad_norm': 9.581372261047363}
2023-01-03 16:42:03.792 DEBUG: Taking gradient step
2023-01-03 16:42:05.936 DEBUG: Loss 3: {'policy_loss': 0.07471917523580054, 'entropy_loss': -0.03385264938697219, 'vf_loss': 0.010681866777916355, 'total_loss': 0.040866525848828356, 'approx_kl': -0.018912365660071373, 'clip_fraction': 0.3567708358168602, 'grad_norm': 15.388909339904785}
2023-01-03 16:42:07.995 DEBUG: Taking gradient step
2023-01-03 16:42:10.173 DEBUG: Loss 4: {'policy_loss': -0.03936268016015121, 'entropy_loss': -0.03455410897731781, 'vf_loss': 0.006598059401307861, 'total_loss': -0.07391678913746902, 'approx_kl': -0.03302823891863227, 'clip_fraction': 0.3919270858168602, 'grad_norm': 11.437592506408691}
2023-01-03 16:42:12.301 DEBUG: Taking gradient step
2023-01-03 16:42:14.501 DEBUG: Loss 5: {'policy_loss': 0.029765985338892513, 'entropy_loss': -0.03400246100500226, 'vf_loss': 0.00855230543989617, 'total_loss': -0.00423647566610974, 'approx_kl': -0.04652489069849253, 'clip_fraction': 0.3815104216337204, 'grad_norm': 17.243560791015625}
2023-01-03 16:42:16.623 DEBUG: Taking gradient step
2023-01-03 16:42:18.879 DEBUG: Loss 6: {'policy_loss': -0.016203111748829234, 'entropy_loss': -0.033230227418243885, 'vf_loss': 0.006601019356562156, 'total_loss': -0.04943333916707312, 'approx_kl': -0.05849544610828161, 'clip_fraction': 0.3515625, 'grad_norm': 10.427315711975098}
2023-01-03 16:42:21.134 DEBUG: Taking gradient step
2023-01-03 16:42:23.237 DEBUG: Loss 7: {'policy_loss': -0.02832041017705323, 'entropy_loss': -0.03314378438517451, 'vf_loss': 0.0073818150032143245, 'total_loss': -0.06146419456222774, 'approx_kl': -0.062132999300956726, 'clip_fraction': 0.3346354216337204, 'grad_norm': 9.908828735351562}
2023-01-03 16:42:25.303 DEBUG: Taking gradient step
2023-01-03 16:42:27.389 DEBUG: Loss 8: {'policy_loss': -0.024902012314993987, 'entropy_loss': -0.032690344378352165, 'vf_loss': 0.006546610612103004, 'total_loss': -0.05759235669334615, 'approx_kl': -0.07282210094854236, 'clip_fraction': 0.3763020858168602, 'grad_norm': 8.880528450012207}
2023-01-03 16:42:29.438 DEBUG: Taking gradient step
2023-01-03 16:42:31.534 DEBUG: Loss 9: {'policy_loss': -0.028379221844686525, 'entropy_loss': -0.034326281398534775, 'vf_loss': 0.007225147995718393, 'total_loss': -0.0627055032432213, 'approx_kl': -0.07801165524870157, 'clip_fraction': 0.390625, 'grad_norm': 14.622916221618652}
2023-01-03 16:42:33.591 DEBUG: Taking gradient step
2023-01-03 16:42:35.693 DEBUG: Loss 10: {'policy_loss': -0.040763680506927386, 'entropy_loss': -0.03401123080402613, 'vf_loss': 0.006768549344520337, 'total_loss': -0.07477491131095351, 'approx_kl': -0.08977197762578726, 'clip_fraction': 0.3645833358168602, 'grad_norm': 9.538578987121582}
2023-01-03 16:42:37.725 DEBUG: Taking gradient step
2023-01-03 16:42:39.814 DEBUG: Loss 11: {'policy_loss': -0.029311149696428195, 'entropy_loss': -0.03418899979442358, 'vf_loss': 0.0074031141420705686, 'total_loss': -0.06350014949085178, 'approx_kl': -0.0681215082295239, 'clip_fraction': 0.4192708358168602, 'grad_norm': 7.591181755065918}
2023-01-03 16:42:41.834 DEBUG: Taking gradient step
2023-01-03 16:42:43.912 DEBUG: Loss 12: {'policy_loss': -0.047050807635571255, 'entropy_loss': -0.03441350255161524, 'vf_loss': 0.006276452055391471, 'total_loss': -0.0814643101871865, 'approx_kl': -0.05803099554032087, 'clip_fraction': 0.4557291716337204, 'grad_norm': 8.106364250183105}
2023-01-03 16:42:45.930 DEBUG: Taking gradient step
2023-01-03 16:42:48.008 DEBUG: Loss 13: {'policy_loss': 0.0008954157788201786, 'entropy_loss': -0.033710320480167866, 'vf_loss': 0.006829679476394208, 'total_loss': -0.03281490470134769, 'approx_kl': -0.06900820974260569, 'clip_fraction': 0.4140625, 'grad_norm': 6.557188034057617}
2023-01-03 16:42:50.039 DEBUG: Taking gradient step
2023-01-03 16:42:52.122 DEBUG: Loss 14: {'policy_loss': 0.003586735877436218, 'entropy_loss': -0.03423465974628925, 'vf_loss': 0.006904185306758388, 'total_loss': -0.030647923868853035, 'approx_kl': -0.10853430908173323, 'clip_fraction': 0.4283854216337204, 'grad_norm': 12.296832084655762}
2023-01-03 16:42:52.123 INFO: Optimization: policy loss=0.004, vf loss=0.007, entropy loss=-0.034, total loss=-0.031, num steps=15
2023-01-03 16:42:52.124 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 16:42:53.803 INFO: Evaluation rollout: return=0.603 (0.0), episode length=6.0
2023-01-03 16:42:53.804 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 16:42:53.807 INFO: Iteration: 77/137, steps: 16632
2023-01-03 16:43:27.649 DEBUG: Atoms are too close
2023-01-03 16:43:51.337 INFO: Training rollout: return=0.061 (2.6), episode length=6.0
2023-01-03 16:43:51.339 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 16:43:51.341 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-16632_train.pkl
2023-01-03 16:43:53.385 DEBUG: Taking gradient step
2023-01-03 16:43:55.461 DEBUG: Loss 0: {'policy_loss': 0.030678318767996923, 'entropy_loss': -0.03443481586873531, 'vf_loss': 0.004352654189294461, 'total_loss': -0.0037564971007383943, 'approx_kl': 8.804878848245323e-08, 'clip_fraction': 0.0, 'grad_norm': 34.038700103759766}
2023-01-03 16:43:57.489 DEBUG: Taking gradient step
2023-01-03 16:43:59.578 DEBUG: Loss 1: {'policy_loss': -0.03407647353511986, 'entropy_loss': -0.03488367982208729, 'vf_loss': 0.0035115820344246485, 'total_loss': -0.06896015335720715, 'approx_kl': -0.025778946466743946, 'clip_fraction': 0.1223958358168602, 'grad_norm': 28.000232696533203}
2023-01-03 16:44:01.623 DEBUG: Taking gradient step
2023-01-03 16:44:03.773 DEBUG: Loss 2: {'policy_loss': -0.04808633105217196, 'entropy_loss': -0.03543915832415223, 'vf_loss': 0.003493783244552949, 'total_loss': -0.08352548937632419, 'approx_kl': -0.053830198012292385, 'clip_fraction': 0.2786458358168602, 'grad_norm': 26.830318450927734}
2023-01-03 16:44:05.852 DEBUG: Taking gradient step
2023-01-03 16:44:07.983 DEBUG: Loss 3: {'policy_loss': -0.01890168855862519, 'entropy_loss': -0.03402944793924689, 'vf_loss': 0.003454175651111445, 'total_loss': -0.05293113649787208, 'approx_kl': -0.07301827473565936, 'clip_fraction': 0.34375, 'grad_norm': 14.750347137451172}
2023-01-03 16:44:10.140 DEBUG: Taking gradient step
2023-01-03 16:44:12.532 DEBUG: Loss 4: {'policy_loss': 0.0015533559451574707, 'entropy_loss': -0.03570432774722576, 'vf_loss': 0.003434320683068129, 'total_loss': -0.03415097180206829, 'approx_kl': -0.06601570406928658, 'clip_fraction': 0.33984375, 'grad_norm': 28.243879318237305}
2023-01-03 16:44:14.999 DEBUG: Taking gradient step
2023-01-03 16:44:17.253 DEBUG: Loss 5: {'policy_loss': -0.016881925748158264, 'entropy_loss': -0.034311436116695404, 'vf_loss': 0.003441939632409562, 'total_loss': -0.05119336186485367, 'approx_kl': -0.07001388631761074, 'clip_fraction': 0.37890625, 'grad_norm': 27.075481414794922}
2023-01-03 16:44:19.327 DEBUG: Taking gradient step
2023-01-03 16:44:21.454 DEBUG: Loss 6: {'policy_loss': -0.02105692184657934, 'entropy_loss': -0.03494424559175968, 'vf_loss': 0.0034426381050572294, 'total_loss': -0.05600116743833902, 'approx_kl': -0.06052003242075443, 'clip_fraction': 0.375, 'grad_norm': 27.693471908569336}
2023-01-03 16:44:23.515 DEBUG: Taking gradient step
2023-01-03 16:44:25.663 DEBUG: Loss 7: {'policy_loss': -0.021747892449011513, 'entropy_loss': -0.03434097021818161, 'vf_loss': 0.0034346624534739106, 'total_loss': -0.05608886266719312, 'approx_kl': -0.1099078927654773, 'clip_fraction': 0.3580729216337204, 'grad_norm': 24.24439811706543}
2023-01-03 16:44:27.955 DEBUG: Taking gradient step
2023-01-03 16:44:30.492 DEBUG: Loss 8: {'policy_loss': -0.009837259842912751, 'entropy_loss': -0.03411219548434019, 'vf_loss': 0.004357985442632711, 'total_loss': -0.043949455327252945, 'approx_kl': -0.0891736475750804, 'clip_fraction': 0.390625, 'grad_norm': 11.536993026733398}
2023-01-03 16:44:32.938 DEBUG: Taking gradient step
2023-01-03 16:44:35.035 DEBUG: Loss 9: {'policy_loss': -0.016706949349760747, 'entropy_loss': -0.03340264409780502, 'vf_loss': 0.0034111718908511127, 'total_loss': -0.05010959344756577, 'approx_kl': -0.054038142785429955, 'clip_fraction': 0.4283854216337204, 'grad_norm': 12.868147850036621}
2023-01-03 16:44:37.076 DEBUG: Taking gradient step
2023-01-03 16:44:39.212 DEBUG: Loss 10: {'policy_loss': -0.0024749855325779738, 'entropy_loss': -0.033469327725470066, 'vf_loss': 0.003395224427322803, 'total_loss': -0.03594431325804804, 'approx_kl': -0.08962796023115516, 'clip_fraction': 0.4036458358168602, 'grad_norm': 31.577939987182617}
2023-01-03 16:44:41.282 DEBUG: Taking gradient step
2023-01-03 16:44:43.393 DEBUG: Loss 11: {'policy_loss': 0.05183696026913803, 'entropy_loss': -0.03394559770822525, 'vf_loss': 0.00430182881890552, 'total_loss': 0.017891362560912782, 'approx_kl': -0.09219546429812908, 'clip_fraction': 0.4075520858168602, 'grad_norm': 37.926326751708984}
2023-01-03 16:44:45.431 DEBUG: Taking gradient step
2023-01-03 16:44:47.511 DEBUG: Loss 12: {'policy_loss': -0.01151359744817559, 'entropy_loss': -0.03273888025432825, 'vf_loss': 0.00405526340816534, 'total_loss': -0.04425247770250384, 'approx_kl': -0.12104431539773941, 'clip_fraction': 0.3854166716337204, 'grad_norm': 10.744329452514648}
2023-01-03 16:44:49.546 DEBUG: Taking gradient step
2023-01-03 16:44:51.628 DEBUG: Loss 13: {'policy_loss': 0.014160891663729566, 'entropy_loss': -0.032858052756637335, 'vf_loss': 0.004304333103901605, 'total_loss': -0.01869716109290777, 'approx_kl': -0.10414604097604752, 'clip_fraction': 0.45703125, 'grad_norm': 14.286975860595703}
2023-01-03 16:44:53.640 DEBUG: Taking gradient step
2023-01-03 16:44:55.703 DEBUG: Loss 14: {'policy_loss': -0.0017313391521655546, 'entropy_loss': -0.032357965130358934, 'vf_loss': 0.00397765824815662, 'total_loss': -0.03408930428252449, 'approx_kl': -0.08863903488963842, 'clip_fraction': 0.43359375, 'grad_norm': 11.76875114440918}
2023-01-03 16:44:55.704 INFO: Optimization: policy loss=-0.002, vf loss=0.004, entropy loss=-0.032, total loss=-0.034, num steps=15
2023-01-03 16:44:55.705 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 16:44:57.399 INFO: Evaluation rollout: return=0.604 (0.0), episode length=6.0
2023-01-03 16:44:57.400 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 16:44:57.403 INFO: Iteration: 78/137, steps: 16848
2023-01-03 16:45:48.099 DEBUG: Atoms are too close
2023-01-03 16:45:48.101 DEBUG: Atoms are too close
2023-01-03 16:45:48.101 DEBUG: Atoms are too close
2023-01-03 16:45:50.399 DEBUG: Atoms are too close
2023-01-03 16:45:52.396 DEBUG: Atoms are too close
2023-01-03 16:45:53.162 INFO: Training rollout: return=-2.365 (5.9), episode length=5.9
2023-01-03 16:45:53.163 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 16:45:53.166 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-16848_train.pkl
2023-01-03 16:45:55.223 DEBUG: Taking gradient step
2023-01-03 16:45:57.402 DEBUG: Loss 0: {'policy_loss': -0.03841074305410073, 'entropy_loss': -0.033659519627690315, 'vf_loss': 0.021582932138934804, 'total_loss': -0.07207026268179105, 'approx_kl': 6.728805601596832e-08, 'clip_fraction': 0.0, 'grad_norm': 19.93793296813965}
2023-01-03 16:45:59.431 DEBUG: Taking gradient step
2023-01-03 16:46:01.520 DEBUG: Loss 1: {'policy_loss': 0.06100474131330175, 'entropy_loss': -0.03425469668582082, 'vf_loss': 0.0267996981503769, 'total_loss': 0.02675004462748093, 'approx_kl': -0.025188990402966738, 'clip_fraction': 0.05208333395421505, 'grad_norm': 30.209896087646484}
2023-01-03 16:46:03.527 DEBUG: Taking gradient step
2023-01-03 16:46:05.941 DEBUG: Loss 2: {'policy_loss': -0.03349117469216655, 'entropy_loss': -0.033930730540305376, 'vf_loss': 0.020906356540260056, 'total_loss': -0.06742190523247193, 'approx_kl': -0.04777619522064924, 'clip_fraction': 0.3020833358168602, 'grad_norm': 19.313743591308594}
2023-01-03 16:46:08.331 DEBUG: Taking gradient step
2023-01-03 16:46:10.798 DEBUG: Loss 3: {'policy_loss': 0.04451367715018189, 'entropy_loss': -0.033425224013626575, 'vf_loss': 0.024850959219916244, 'total_loss': 0.011088453136555312, 'approx_kl': -0.05075673293322325, 'clip_fraction': 0.4778645858168602, 'grad_norm': 17.076379776000977}
2023-01-03 16:46:13.194 DEBUG: Taking gradient step
2023-01-03 16:46:15.681 DEBUG: Loss 4: {'policy_loss': 0.07212371915992977, 'entropy_loss': -0.03152123373001814, 'vf_loss': 0.024742183829199405, 'total_loss': 0.040602485429911635, 'approx_kl': -0.07928969711065292, 'clip_fraction': 0.5299479216337204, 'grad_norm': 22.247900009155273}
2023-01-03 16:46:18.101 DEBUG: Taking gradient step
2023-01-03 16:46:20.593 DEBUG: Loss 5: {'policy_loss': 0.18204461020672877, 'entropy_loss': -0.033351496793329716, 'vf_loss': 0.02643402147147271, 'total_loss': 0.14869311341339905, 'approx_kl': -0.11246693041175604, 'clip_fraction': 0.4622395858168602, 'grad_norm': 33.4884147644043}
2023-01-03 16:46:23.002 DEBUG: Taking gradient step
2023-01-03 16:46:25.468 DEBUG: Loss 6: {'policy_loss': 0.0464133727416026, 'entropy_loss': -0.03186028450727463, 'vf_loss': 0.022743280396390814, 'total_loss': 0.014553088234327966, 'approx_kl': -0.08898888435214758, 'clip_fraction': 0.4075520858168602, 'grad_norm': 22.846351623535156}
2023-01-03 16:46:27.865 DEBUG: Taking gradient step
2023-01-03 16:46:30.333 DEBUG: Loss 7: {'policy_loss': 0.07807358773112544, 'entropy_loss': -0.0315495771355927, 'vf_loss': 0.024811428186302293, 'total_loss': 0.04652401059553273, 'approx_kl': -0.1115550808608532, 'clip_fraction': 0.4036458358168602, 'grad_norm': 27.428247451782227}
2023-01-03 16:46:32.403 DEBUG: Taking gradient step
2023-01-03 16:46:34.481 DEBUG: Loss 8: {'policy_loss': 0.018349073966543974, 'entropy_loss': -0.03220370505005121, 'vf_loss': 0.023218891842907076, 'total_loss': -0.013854631083507235, 'approx_kl': -0.11119976826012135, 'clip_fraction': 0.44921875, 'grad_norm': 17.21728515625}
2023-01-03 16:46:36.569 DEBUG: Taking gradient step
2023-01-03 16:46:38.969 DEBUG: Loss 9: {'policy_loss': 0.022463172180149357, 'entropy_loss': -0.032587668392807245, 'vf_loss': 0.024287013191378787, 'total_loss': -0.01012449621265789, 'approx_kl': -0.09918301552534103, 'clip_fraction': 0.40234375, 'grad_norm': 21.992801666259766}
2023-01-03 16:46:40.977 DEBUG: Taking gradient step
2023-01-03 16:46:43.036 DEBUG: Loss 10: {'policy_loss': 0.07450505531251692, 'entropy_loss': -0.032398633658885956, 'vf_loss': 0.027517057226265445, 'total_loss': 0.04210642165363096, 'approx_kl': -0.10190011188387871, 'clip_fraction': 0.4166666716337204, 'grad_norm': 25.68929672241211}
2023-01-03 16:46:45.052 DEBUG: Taking gradient step
2023-01-03 16:46:47.123 DEBUG: Loss 11: {'policy_loss': -0.0013982122103878992, 'entropy_loss': -0.03299116715788841, 'vf_loss': 0.02355968468162936, 'total_loss': -0.03438937936827631, 'approx_kl': -0.09878866467624903, 'clip_fraction': 0.4127604216337204, 'grad_norm': 17.295650482177734}
2023-01-03 16:46:49.139 DEBUG: Taking gradient step
2023-01-03 16:46:51.198 DEBUG: Loss 12: {'policy_loss': -0.026868595319163045, 'entropy_loss': -0.03309966577216983, 'vf_loss': 0.02211513775296965, 'total_loss': -0.059968261091332874, 'approx_kl': -0.13712674379348755, 'clip_fraction': 0.4596354216337204, 'grad_norm': 14.847434043884277}
2023-01-03 16:46:53.210 DEBUG: Taking gradient step
2023-01-03 16:46:55.283 DEBUG: Loss 13: {'policy_loss': 0.042614849016022374, 'entropy_loss': -0.03265330055728555, 'vf_loss': 0.025144815078355427, 'total_loss': 0.009961548458736827, 'approx_kl': -0.10644332692027092, 'clip_fraction': 0.4296875, 'grad_norm': 22.01692771911621}
2023-01-03 16:46:57.383 DEBUG: Taking gradient step
2023-01-03 16:46:59.463 DEBUG: Loss 14: {'policy_loss': 0.026547629177693162, 'entropy_loss': -0.030786708928644657, 'vf_loss': 0.02400096808637679, 'total_loss': -0.004239079750951492, 'approx_kl': -0.11874512583017349, 'clip_fraction': 0.45703125, 'grad_norm': 17.292112350463867}
2023-01-03 16:46:59.464 INFO: Optimization: policy loss=0.027, vf loss=0.024, entropy loss=-0.031, total loss=-0.004, num steps=15
2023-01-03 16:46:59.465 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 16:47:01.170 INFO: Evaluation rollout: return=0.581 (0.0), episode length=6.0
2023-01-03 16:47:01.171 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 16:47:01.175 INFO: Iteration: 79/137, steps: 17064
2023-01-03 16:47:15.223 DEBUG: Atoms are too close
2023-01-03 16:47:16.644 DEBUG: Atoms are too close
2023-01-03 16:47:35.185 DEBUG: Atoms are too close
2023-01-03 16:47:48.750 DEBUG: Atoms are too close
2023-01-03 16:47:57.559 INFO: Training rollout: return=-1.340 (5.2), episode length=5.9
2023-01-03 16:47:57.561 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 16:47:57.563 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-17064_train.pkl
2023-01-03 16:47:59.604 DEBUG: Taking gradient step
2023-01-03 16:48:01.679 DEBUG: Loss 0: {'policy_loss': 0.010301259155557567, 'entropy_loss': -0.032495612278580666, 'vf_loss': 0.014483078017988229, 'total_loss': -0.0221943531230231, 'approx_kl': -2.5984870255513215e-08, 'clip_fraction': 0.0, 'grad_norm': 9.558222770690918}
2023-01-03 16:48:03.716 DEBUG: Taking gradient step
2023-01-03 16:48:05.816 DEBUG: Loss 1: {'policy_loss': -0.010295722174790474, 'entropy_loss': -0.03252734197303653, 'vf_loss': 0.01262284729347042, 'total_loss': -0.042823064147827, 'approx_kl': -0.008751966757699847, 'clip_fraction': 0.13151041697710752, 'grad_norm': 17.416030883789062}
2023-01-03 16:48:07.833 DEBUG: Taking gradient step
2023-01-03 16:48:10.293 DEBUG: Loss 2: {'policy_loss': 0.03967045705560945, 'entropy_loss': -0.03297846857458353, 'vf_loss': 0.013376283354019424, 'total_loss': 0.006691988481025915, 'approx_kl': -0.014750848873518407, 'clip_fraction': 0.2955729216337204, 'grad_norm': 22.759502410888672}
2023-01-03 16:48:12.730 DEBUG: Taking gradient step
2023-01-03 16:48:15.297 DEBUG: Loss 3: {'policy_loss': 0.03232800858454243, 'entropy_loss': -0.032606106251478195, 'vf_loss': 0.014233793234678584, 'total_loss': -0.0002780976669357685, 'approx_kl': -0.026277109747752547, 'clip_fraction': 0.3307291716337204, 'grad_norm': 23.093372344970703}
2023-01-03 16:48:17.398 DEBUG: Taking gradient step
2023-01-03 16:48:19.466 DEBUG: Loss 4: {'policy_loss': 0.00289119059384451, 'entropy_loss': -0.03447196865454316, 'vf_loss': 0.013318787757246743, 'total_loss': -0.03158077806069865, 'approx_kl': -0.03934411704540253, 'clip_fraction': 0.265625, 'grad_norm': 20.17694854736328}
2023-01-03 16:48:21.717 DEBUG: Taking gradient step
2023-01-03 16:48:23.784 DEBUG: Loss 5: {'policy_loss': -0.005947976562484417, 'entropy_loss': -0.032083753030747175, 'vf_loss': 0.013042635194316891, 'total_loss': -0.03803172959323159, 'approx_kl': -0.03205040469765663, 'clip_fraction': 0.2161458358168602, 'grad_norm': 14.406591415405273}
2023-01-03 16:48:25.800 DEBUG: Taking gradient step
2023-01-03 16:48:27.838 DEBUG: Loss 6: {'policy_loss': 0.03620756268825084, 'entropy_loss': -0.034430415369570255, 'vf_loss': 0.014792613048989623, 'total_loss': 0.0017771473186805851, 'approx_kl': -0.035508677596226335, 'clip_fraction': 0.2486979216337204, 'grad_norm': 20.041969299316406}
2023-01-03 16:48:29.826 DEBUG: Taking gradient step
2023-01-03 16:48:31.861 DEBUG: Loss 7: {'policy_loss': 0.042062947471567885, 'entropy_loss': -0.03398599196225405, 'vf_loss': 0.01459259586266998, 'total_loss': 0.00807695550931384, 'approx_kl': -0.03537391638383269, 'clip_fraction': 0.3216145858168602, 'grad_norm': 15.054889678955078}
2023-01-03 16:48:33.848 DEBUG: Taking gradient step
2023-01-03 16:48:35.894 DEBUG: Loss 8: {'policy_loss': 0.05417022132572198, 'entropy_loss': -0.033672139048576355, 'vf_loss': 0.013620400589214758, 'total_loss': 0.020498082277145627, 'approx_kl': -0.06338607519865036, 'clip_fraction': 0.390625, 'grad_norm': 21.24364471435547}
2023-01-03 16:48:37.911 DEBUG: Taking gradient step
2023-01-03 16:48:39.960 DEBUG: Loss 9: {'policy_loss': 0.0007265205406514624, 'entropy_loss': -0.03384257247671485, 'vf_loss': 0.011802345013404552, 'total_loss': -0.03311605193606338, 'approx_kl': -0.051664231810718775, 'clip_fraction': 0.3997395858168602, 'grad_norm': 22.6037540435791}
2023-01-03 16:48:41.958 DEBUG: Taking gradient step
2023-01-03 16:48:44.118 DEBUG: Loss 10: {'policy_loss': 0.05225348806939697, 'entropy_loss': -0.034159738570451736, 'vf_loss': 0.014972695292118095, 'total_loss': 0.018093749498945228, 'approx_kl': -0.04822425963357091, 'clip_fraction': 0.3645833358168602, 'grad_norm': 22.510032653808594}
2023-01-03 16:48:46.114 DEBUG: Taking gradient step
2023-01-03 16:48:48.159 DEBUG: Loss 11: {'policy_loss': 0.015624005769817706, 'entropy_loss': -0.032916604075580835, 'vf_loss': 0.013896101841131332, 'total_loss': -0.01729259830576313, 'approx_kl': -0.043365719146095216, 'clip_fraction': 0.36328125, 'grad_norm': 23.306076049804688}
2023-01-03 16:48:50.154 DEBUG: Taking gradient step
2023-01-03 16:48:52.207 DEBUG: Loss 12: {'policy_loss': 0.0012842168639881054, 'entropy_loss': -0.03540821745991707, 'vf_loss': 0.01345563437852244, 'total_loss': -0.03412400059592896, 'approx_kl': -0.07871022447943687, 'clip_fraction': 0.4140625, 'grad_norm': 13.487154960632324}
2023-01-03 16:48:54.254 DEBUG: Taking gradient step
2023-01-03 16:48:56.694 DEBUG: Loss 13: {'policy_loss': -0.03681309457576827, 'entropy_loss': -0.03438033442944288, 'vf_loss': 0.012805565768455325, 'total_loss': -0.07119342900521115, 'approx_kl': -0.06872902601025999, 'clip_fraction': 0.3515625, 'grad_norm': 17.53824806213379}
2023-01-03 16:48:59.089 DEBUG: Taking gradient step
2023-01-03 16:49:01.158 DEBUG: Loss 14: {'policy_loss': 0.009275070177908516, 'entropy_loss': -0.03484530281275511, 'vf_loss': 0.013256663237929966, 'total_loss': -0.025570232634846594, 'approx_kl': -0.047366072656586766, 'clip_fraction': 0.3385416716337204, 'grad_norm': 24.454477310180664}
2023-01-03 16:49:01.158 INFO: Optimization: policy loss=0.009, vf loss=0.013, entropy loss=-0.035, total loss=-0.026, num steps=15
2023-01-03 16:49:01.160 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 16:49:02.877 INFO: Evaluation rollout: return=0.589 (0.0), episode length=6.0
2023-01-03 16:49:02.878 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 16:49:02.881 INFO: Iteration: 80/137, steps: 17280
2023-01-03 16:49:13.529 DEBUG: Atoms are too close
2023-01-03 16:49:54.374 DEBUG: Atoms are too close
2023-01-03 16:49:59.924 INFO: Training rollout: return=-0.427 (4.0), episode length=5.9
2023-01-03 16:49:59.926 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 16:49:59.928 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-17280_train.pkl
2023-01-03 16:50:01.948 DEBUG: Taking gradient step
2023-01-03 16:50:04.016 DEBUG: Loss 0: {'policy_loss': -0.00697778244517545, 'entropy_loss': -0.03245389927178621, 'vf_loss': 0.006332428362830729, 'total_loss': -0.03943168171696167, 'approx_kl': -6.6356733441352844e-09, 'clip_fraction': 0.0, 'grad_norm': 14.984516143798828}
2023-01-03 16:50:06.031 DEBUG: Taking gradient step
2023-01-03 16:50:08.114 DEBUG: Loss 1: {'policy_loss': -0.01104247627314386, 'entropy_loss': -0.03434594348073006, 'vf_loss': 0.006778814680618507, 'total_loss': -0.045388419753873914, 'approx_kl': -0.00889691011980176, 'clip_fraction': 0.07291666697710752, 'grad_norm': 10.183239936828613}
2023-01-03 16:50:10.189 DEBUG: Taking gradient step
2023-01-03 16:50:12.264 DEBUG: Loss 2: {'policy_loss': -0.017388528290298806, 'entropy_loss': -0.03502115420997143, 'vf_loss': 0.00648409233895034, 'total_loss': -0.052409682500270234, 'approx_kl': -0.008035812061280012, 'clip_fraction': 0.2747395858168602, 'grad_norm': 5.672914505004883}
2023-01-03 16:50:14.289 DEBUG: Taking gradient step
2023-01-03 16:50:16.374 DEBUG: Loss 3: {'policy_loss': -0.03625975807163973, 'entropy_loss': -0.03440500097349286, 'vf_loss': 0.0062207473021953326, 'total_loss': -0.07066475904513259, 'approx_kl': -0.02202999358996749, 'clip_fraction': 0.25, 'grad_norm': 3.025146484375}
2023-01-03 16:50:18.411 DEBUG: Taking gradient step
2023-01-03 16:50:20.490 DEBUG: Loss 4: {'policy_loss': -0.05391058094431671, 'entropy_loss': -0.03330737119540572, 'vf_loss': 0.0058051275655483505, 'total_loss': -0.08721795213972243, 'approx_kl': -0.01676887273788452, 'clip_fraction': 0.3268229216337204, 'grad_norm': 10.425027847290039}
2023-01-03 16:50:22.520 DEBUG: Taking gradient step
2023-01-03 16:50:24.606 DEBUG: Loss 5: {'policy_loss': -0.02829374891761796, 'entropy_loss': -0.03315866971388459, 'vf_loss': 0.0064129997500443695, 'total_loss': -0.061452418631502546, 'approx_kl': -0.025033815065398812, 'clip_fraction': 0.3229166716337204, 'grad_norm': 6.350920677185059}
2023-01-03 16:50:26.631 DEBUG: Taking gradient step
2023-01-03 16:50:28.702 DEBUG: Loss 6: {'policy_loss': -0.011904005798818274, 'entropy_loss': -0.03258319478482008, 'vf_loss': 0.006878580288623917, 'total_loss': -0.04448720058363835, 'approx_kl': -0.04288306087255478, 'clip_fraction': 0.2421875, 'grad_norm': 8.513688087463379}
2023-01-03 16:50:30.722 DEBUG: Taking gradient step
2023-01-03 16:50:32.789 DEBUG: Loss 7: {'policy_loss': 0.004969136039777632, 'entropy_loss': -0.03338844049721956, 'vf_loss': 0.007595367011830764, 'total_loss': -0.02841930445744193, 'approx_kl': -0.027347439900040627, 'clip_fraction': 0.2799479216337204, 'grad_norm': 5.2805280685424805}
2023-01-03 16:50:34.909 DEBUG: Taking gradient step
2023-01-03 16:50:36.985 DEBUG: Loss 8: {'policy_loss': -0.031391194365947575, 'entropy_loss': -0.032543344888836145, 'vf_loss': 0.00655718402068237, 'total_loss': -0.06393453925478372, 'approx_kl': -0.013854539953172207, 'clip_fraction': 0.3111979216337204, 'grad_norm': 6.389613151550293}
2023-01-03 16:50:39.013 DEBUG: Taking gradient step
2023-01-03 16:50:41.079 DEBUG: Loss 9: {'policy_loss': -0.04174453673740704, 'entropy_loss': -0.03134909179061651, 'vf_loss': 0.006309023764442095, 'total_loss': -0.07309362852802356, 'approx_kl': -0.04088570736348629, 'clip_fraction': 0.3229166716337204, 'grad_norm': 3.4559011459350586}
2023-01-03 16:50:43.099 DEBUG: Taking gradient step
2023-01-03 16:50:45.166 DEBUG: Loss 10: {'policy_loss': -0.011940593163098295, 'entropy_loss': -0.029297473840415478, 'vf_loss': 0.007020744667162985, 'total_loss': -0.041238067003513776, 'approx_kl': -0.037561641773208976, 'clip_fraction': 0.5169270932674408, 'grad_norm': 13.550256729125977}
2023-01-03 16:50:47.172 DEBUG: Taking gradient step
2023-01-03 16:50:49.242 DEBUG: Loss 11: {'policy_loss': -0.010099335635499473, 'entropy_loss': -0.03082715254276991, 'vf_loss': 0.007061399707634024, 'total_loss': -0.04092648817826938, 'approx_kl': -0.04072859277948737, 'clip_fraction': 0.5859375, 'grad_norm': 6.737799167633057}
2023-01-03 16:50:51.262 DEBUG: Taking gradient step
2023-01-03 16:50:53.349 DEBUG: Loss 12: {'policy_loss': -0.0016165953297731933, 'entropy_loss': -0.030741460155695677, 'vf_loss': 0.007525287357623646, 'total_loss': -0.03235805548546887, 'approx_kl': -0.022825803607702255, 'clip_fraction': 0.48828125, 'grad_norm': 12.85460090637207}
2023-01-03 16:50:55.372 DEBUG: Taking gradient step
2023-01-03 16:50:57.433 DEBUG: Loss 13: {'policy_loss': -0.028554832782779326, 'entropy_loss': -0.03134188428521156, 'vf_loss': 0.006404573847187473, 'total_loss': -0.05989671706799089, 'approx_kl': -0.0386826868634671, 'clip_fraction': 0.47265625, 'grad_norm': 4.528513431549072}
2023-01-03 16:50:59.458 DEBUG: Taking gradient step
2023-01-03 16:51:01.529 DEBUG: Loss 14: {'policy_loss': -0.033353007800565014, 'entropy_loss': -0.02931057196110487, 'vf_loss': 0.006394716187842035, 'total_loss': -0.06266357976166988, 'approx_kl': -0.03719835530500859, 'clip_fraction': 0.4375, 'grad_norm': 7.149017333984375}
2023-01-03 16:51:01.530 INFO: Optimization: policy loss=-0.033, vf loss=0.006, entropy loss=-0.029, total loss=-0.063, num steps=15
2023-01-03 16:51:01.531 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 16:51:03.227 INFO: Evaluation rollout: return=0.596 (0.0), episode length=6.0
2023-01-03 16:51:03.228 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 16:51:03.231 DEBUG: Deleting old model: runs/CH3NO_dna/models/CH3NO_dna_run-1_steps-15336.model
2023-01-03 16:51:03.237 DEBUG: Saving model: runs/CH3NO_dna/models/CH3NO_dna_run-1_steps-17496.model
2023-01-03 16:51:03.289 INFO: Iteration: 81/137, steps: 17496
2023-01-03 16:51:16.397 DEBUG: Atoms are too close
2023-01-03 16:51:27.827 DEBUG: Atoms are too close
2023-01-03 16:51:34.284 DEBUG: Atoms are too close
2023-01-03 16:51:35.409 DEBUG: Atoms are too close
2023-01-03 16:51:50.182 DEBUG: Atoms are too close
2023-01-03 16:51:50.183 DEBUG: Atoms are too close
2023-01-03 16:51:58.580 INFO: Training rollout: return=-2.734 (6.7), episode length=5.8
2023-01-03 16:51:58.581 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 16:51:58.584 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-17496_train.pkl
2023-01-03 16:52:00.573 DEBUG: Taking gradient step
2023-01-03 16:52:02.599 DEBUG: Loss 0: {'policy_loss': 0.004012066310592488, 'entropy_loss': -0.03048806171864271, 'vf_loss': 0.022893564915102534, 'total_loss': -0.026475995408050224, 'approx_kl': -7.097454357563038e-08, 'clip_fraction': 0.0, 'grad_norm': 25.29668426513672}
2023-01-03 16:52:04.577 DEBUG: Taking gradient step
2023-01-03 16:52:06.614 DEBUG: Loss 1: {'policy_loss': 0.005885001959166246, 'entropy_loss': -0.029679237864911556, 'vf_loss': 0.02175134310910603, 'total_loss': -0.02379423590574531, 'approx_kl': -0.00955469615291804, 'clip_fraction': 0.061197916977107525, 'grad_norm': 23.240947723388672}
2023-01-03 16:52:08.583 DEBUG: Taking gradient step
2023-01-03 16:52:10.615 DEBUG: Loss 2: {'policy_loss': 0.004131395466931302, 'entropy_loss': -0.030520247295498848, 'vf_loss': 0.0211080638712747, 'total_loss': -0.026388851828567546, 'approx_kl': -0.011825506808236241, 'clip_fraction': 0.2317708358168602, 'grad_norm': 31.66236114501953}
2023-01-03 16:52:12.595 DEBUG: Taking gradient step
2023-01-03 16:52:14.622 DEBUG: Loss 3: {'policy_loss': 0.014504460679639694, 'entropy_loss': -0.029143863823264837, 'vf_loss': 0.02147152647573362, 'total_loss': -0.014639403143625145, 'approx_kl': -0.02760765259154141, 'clip_fraction': 0.3541666716337204, 'grad_norm': 28.35478401184082}
2023-01-03 16:52:16.598 DEBUG: Taking gradient step
2023-01-03 16:52:18.723 DEBUG: Loss 4: {'policy_loss': 0.0052674958840034924, 'entropy_loss': -0.02927856845781207, 'vf_loss': 0.02230106532326575, 'total_loss': -0.02401107257380858, 'approx_kl': -0.020163152483291924, 'clip_fraction': 0.359375, 'grad_norm': 19.939592361450195}
2023-01-03 16:52:20.713 DEBUG: Taking gradient step
2023-01-03 16:52:22.750 DEBUG: Loss 5: {'policy_loss': 0.0025118997488407877, 'entropy_loss': -0.02800417458638549, 'vf_loss': 0.02239328862684798, 'total_loss': -0.025492274837544703, 'approx_kl': -0.0330639558378607, 'clip_fraction': 0.3138020858168602, 'grad_norm': 16.844951629638672}
2023-01-03 16:52:24.736 DEBUG: Taking gradient step
2023-01-03 16:52:26.765 DEBUG: Loss 6: {'policy_loss': -0.0036761551420102165, 'entropy_loss': -0.02958598406985402, 'vf_loss': 0.02218657998321329, 'total_loss': -0.03326213921186424, 'approx_kl': -0.0576502321055159, 'clip_fraction': 0.30859375, 'grad_norm': 38.967464447021484}
2023-01-03 16:52:28.750 DEBUG: Taking gradient step
2023-01-03 16:52:30.782 DEBUG: Loss 7: {'policy_loss': 0.01460110280743741, 'entropy_loss': -0.027904886286705732, 'vf_loss': 0.022255442336664027, 'total_loss': -0.013303783479268323, 'approx_kl': -0.04483558563515544, 'clip_fraction': 0.2018229179084301, 'grad_norm': 30.24813461303711}
2023-01-03 16:52:32.760 DEBUG: Taking gradient step
2023-01-03 16:52:34.798 DEBUG: Loss 8: {'policy_loss': -0.042760681616821575, 'entropy_loss': -0.028863378800451756, 'vf_loss': 0.01942522513288325, 'total_loss': -0.07162406041727333, 'approx_kl': -0.044902177061885595, 'clip_fraction': 0.21614583395421505, 'grad_norm': 22.974740982055664}
2023-01-03 16:52:36.780 DEBUG: Taking gradient step
2023-01-03 16:52:38.814 DEBUG: Loss 9: {'policy_loss': 0.02818138871608247, 'entropy_loss': -0.02821805700659752, 'vf_loss': 0.024052177394192485, 'total_loss': -3.6668290515049634e-05, 'approx_kl': -0.043621207820251584, 'clip_fraction': 0.33203125, 'grad_norm': 22.9044246673584}
2023-01-03 16:52:40.793 DEBUG: Taking gradient step
2023-01-03 16:52:42.812 DEBUG: Loss 10: {'policy_loss': 0.07943644659770438, 'entropy_loss': -0.027208227198570967, 'vf_loss': 0.026227972840477398, 'total_loss': 0.05222821939913341, 'approx_kl': -0.05589319113641977, 'clip_fraction': 0.37890625, 'grad_norm': 38.55050277709961}
2023-01-03 16:52:44.782 DEBUG: Taking gradient step
2023-01-03 16:52:46.853 DEBUG: Loss 11: {'policy_loss': 0.03132400741855148, 'entropy_loss': -0.02747291000559926, 'vf_loss': 0.02460582568351599, 'total_loss': 0.003851097412952219, 'approx_kl': -0.05147302011027932, 'clip_fraction': 0.3684895858168602, 'grad_norm': 33.008941650390625}
2023-01-03 16:52:48.871 DEBUG: Taking gradient step
2023-01-03 16:52:50.908 DEBUG: Loss 12: {'policy_loss': -0.023969298585879734, 'entropy_loss': -0.028191518504172564, 'vf_loss': 0.02167494970490264, 'total_loss': -0.0521608170900523, 'approx_kl': -0.05451039783656597, 'clip_fraction': 0.2864583358168602, 'grad_norm': 17.043766021728516}
2023-01-03 16:52:52.895 DEBUG: Taking gradient step
2023-01-03 16:52:54.923 DEBUG: Loss 13: {'policy_loss': -0.03951617814406157, 'entropy_loss': -0.0285756578668952, 'vf_loss': 0.021227983419115776, 'total_loss': -0.06809183601095677, 'approx_kl': -0.05848377663642168, 'clip_fraction': 0.14583333395421505, 'grad_norm': 18.502994537353516}
2023-01-03 16:52:56.911 DEBUG: Taking gradient step
2023-01-03 16:52:58.946 DEBUG: Loss 14: {'policy_loss': -0.05540352629289982, 'entropy_loss': -0.028777819126844406, 'vf_loss': 0.02069972389448795, 'total_loss': -0.08418134541974423, 'approx_kl': -0.06030400190502405, 'clip_fraction': 0.19140625, 'grad_norm': 18.480669021606445}
2023-01-03 16:52:58.947 INFO: Optimization: policy loss=-0.055, vf loss=0.021, entropy loss=-0.029, total loss=-0.084, num steps=15
2023-01-03 16:52:58.948 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 16:53:00.665 INFO: Evaluation rollout: return=0.603 (0.0), episode length=6.0
2023-01-03 16:53:00.666 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 16:53:00.669 INFO: Iteration: 82/137, steps: 17712
2023-01-03 16:53:14.578 DEBUG: Atoms are too close
2023-01-03 16:53:14.867 DEBUG: Atoms are too close
2023-01-03 16:53:28.495 DEBUG: Atoms are too close
2023-01-03 16:53:43.851 DEBUG: Atoms are too close
2023-01-03 16:53:48.018 DEBUG: Atoms are too close
2023-01-03 16:53:56.833 INFO: Training rollout: return=-1.798 (5.7), episode length=5.8
2023-01-03 16:53:56.834 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 16:53:56.837 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-17712_train.pkl
2023-01-03 16:53:58.863 DEBUG: Taking gradient step
2023-01-03 16:54:00.914 DEBUG: Loss 0: {'policy_loss': 0.014978168818867783, 'entropy_loss': -0.028101276606321335, 'vf_loss': 0.017289916222460996, 'total_loss': -0.013123107787453556, 'approx_kl': 1.8742866814136505e-08, 'clip_fraction': 0.0, 'grad_norm': 25.9597225189209}
2023-01-03 16:54:02.899 DEBUG: Taking gradient step
2023-01-03 16:54:05.027 DEBUG: Loss 1: {'policy_loss': -0.01346645548534784, 'entropy_loss': -0.027807924430817366, 'vf_loss': 0.01580810631980793, 'total_loss': -0.04127437991616521, 'approx_kl': -0.003293321584351361, 'clip_fraction': 0.0963541679084301, 'grad_norm': 14.597436904907227}
2023-01-03 16:54:07.025 DEBUG: Taking gradient step
2023-01-03 16:54:09.093 DEBUG: Loss 2: {'policy_loss': -0.011337637779243164, 'entropy_loss': -0.029012370388954878, 'vf_loss': 0.015477129300754674, 'total_loss': -0.040350008168198045, 'approx_kl': -0.01469711889512837, 'clip_fraction': 0.23828125, 'grad_norm': 19.58749008178711}
2023-01-03 16:54:11.099 DEBUG: Taking gradient step
2023-01-03 16:54:13.140 DEBUG: Loss 3: {'policy_loss': -0.028809844047308138, 'entropy_loss': -0.028826278634369373, 'vf_loss': 0.014391846051577912, 'total_loss': -0.057636122681677504, 'approx_kl': -0.021880974993109703, 'clip_fraction': 0.33203125, 'grad_norm': 10.057414054870605}
2023-01-03 16:54:15.142 DEBUG: Taking gradient step
2023-01-03 16:54:17.191 DEBUG: Loss 4: {'policy_loss': 0.01934034723940814, 'entropy_loss': -0.029936176259070635, 'vf_loss': 0.016235962150695497, 'total_loss': -0.010595829019662495, 'approx_kl': -0.041363641154021025, 'clip_fraction': 0.27734375, 'grad_norm': 15.177380561828613}
2023-01-03 16:54:19.189 DEBUG: Taking gradient step
2023-01-03 16:54:21.247 DEBUG: Loss 5: {'policy_loss': 0.008779825005855477, 'entropy_loss': -0.028643927536904812, 'vf_loss': 0.016313230549471397, 'total_loss': -0.019864102531049335, 'approx_kl': -0.04617655137553811, 'clip_fraction': 0.2630208358168602, 'grad_norm': 13.701045989990234}
2023-01-03 16:54:23.276 DEBUG: Taking gradient step
2023-01-03 16:54:25.325 DEBUG: Loss 6: {'policy_loss': 0.05581874004713981, 'entropy_loss': -0.02904431289061904, 'vf_loss': 0.018804193772393007, 'total_loss': 0.026774427156520772, 'approx_kl': -0.022274982184171677, 'clip_fraction': 0.2604166716337204, 'grad_norm': 15.266400337219238}
2023-01-03 16:54:27.340 DEBUG: Taking gradient step
2023-01-03 16:54:29.399 DEBUG: Loss 7: {'policy_loss': -0.026729666201465538, 'entropy_loss': -0.029309945181012154, 'vf_loss': 0.015459456705109544, 'total_loss': -0.05603961138247769, 'approx_kl': -0.04862267058342695, 'clip_fraction': 0.31640625, 'grad_norm': 16.810609817504883}
2023-01-03 16:54:31.498 DEBUG: Taking gradient step
2023-01-03 16:54:33.946 DEBUG: Loss 8: {'policy_loss': -0.03556883789283128, 'entropy_loss': -0.029902805108577013, 'vf_loss': 0.014876348611474311, 'total_loss': -0.06547164300140829, 'approx_kl': -0.04243562277406454, 'clip_fraction': 0.30859375, 'grad_norm': 7.955256938934326}
2023-01-03 16:54:35.996 DEBUG: Taking gradient step
2023-01-03 16:54:38.032 DEBUG: Loss 9: {'policy_loss': -0.011575638049595414, 'entropy_loss': -0.029239775612950325, 'vf_loss': 0.016115053938687444, 'total_loss': -0.040815413662545735, 'approx_kl': -0.06331849843263626, 'clip_fraction': 0.3424479216337204, 'grad_norm': 15.161727905273438}
2023-01-03 16:54:40.022 DEBUG: Taking gradient step
2023-01-03 16:54:42.120 DEBUG: Loss 10: {'policy_loss': -0.02517532585741762, 'entropy_loss': -0.030715548899024725, 'vf_loss': 0.014670412897166243, 'total_loss': -0.055890874756442346, 'approx_kl': -0.06519563682377338, 'clip_fraction': 0.3541666716337204, 'grad_norm': 8.388986587524414}
2023-01-03 16:54:44.148 DEBUG: Taking gradient step
2023-01-03 16:54:46.235 DEBUG: Loss 11: {'policy_loss': 0.039502864642012386, 'entropy_loss': -0.02923027193173766, 'vf_loss': 0.018117790552960183, 'total_loss': 0.010272592710274725, 'approx_kl': -0.05685958731919527, 'clip_fraction': 0.3580729216337204, 'grad_norm': 9.22425651550293}
2023-01-03 16:54:48.271 DEBUG: Taking gradient step
2023-01-03 16:54:50.365 DEBUG: Loss 12: {'policy_loss': -0.024303817876000028, 'entropy_loss': -0.028697533067315817, 'vf_loss': 0.015044058615321288, 'total_loss': -0.053001350943315845, 'approx_kl': -0.05350105930119753, 'clip_fraction': 0.3489583358168602, 'grad_norm': 12.302742958068848}
2023-01-03 16:54:52.396 DEBUG: Taking gradient step
2023-01-03 16:54:54.484 DEBUG: Loss 13: {'policy_loss': 0.017601960064152603, 'entropy_loss': -0.03010949259623885, 'vf_loss': 0.01660428335509355, 'total_loss': -0.012507532532086248, 'approx_kl': -0.07499976642429829, 'clip_fraction': 0.33984375, 'grad_norm': 15.692602157592773}
2023-01-03 16:54:56.571 DEBUG: Taking gradient step
2023-01-03 16:54:58.659 DEBUG: Loss 14: {'policy_loss': 0.01392626246120051, 'entropy_loss': -0.0282465280033648, 'vf_loss': 0.015591531407765322, 'total_loss': -0.014320265542164291, 'approx_kl': -0.06777760293334723, 'clip_fraction': 0.3815104216337204, 'grad_norm': 26.19086265563965}
2023-01-03 16:54:58.660 INFO: Optimization: policy loss=0.014, vf loss=0.016, entropy loss=-0.028, total loss=-0.014, num steps=15
2023-01-03 16:54:58.661 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 16:55:00.353 INFO: Evaluation rollout: return=0.606 (0.0), episode length=6.0
2023-01-03 16:55:00.355 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 16:55:00.358 INFO: Iteration: 83/137, steps: 17928
2023-01-03 16:55:06.177 DEBUG: Atoms are too close
2023-01-03 16:55:09.523 DEBUG: Atoms are too close
2023-01-03 16:55:30.890 DEBUG: Atoms are too close
2023-01-03 16:55:36.055 DEBUG: Atoms are too close
2023-01-03 16:55:43.720 DEBUG: Atoms are too close
2023-01-03 16:55:56.407 INFO: Training rollout: return=-1.879 (6.1), episode length=5.8
2023-01-03 16:55:56.408 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 16:55:56.411 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-17928_train.pkl
2023-01-03 16:55:58.476 DEBUG: Taking gradient step
2023-01-03 16:56:00.557 DEBUG: Loss 0: {'policy_loss': 0.03875290512006715, 'entropy_loss': -0.029714258387684822, 'vf_loss': 0.01725326050908086, 'total_loss': 0.009038646732382326, 'approx_kl': -4.6372102602276755e-08, 'clip_fraction': 0.0, 'grad_norm': 19.19768714904785}
2023-01-03 16:56:02.541 DEBUG: Taking gradient step
2023-01-03 16:56:04.601 DEBUG: Loss 1: {'policy_loss': -0.03617011995095698, 'entropy_loss': -0.029160906095057726, 'vf_loss': 0.01415590753379196, 'total_loss': -0.0653310260460147, 'approx_kl': -0.008071269141510129, 'clip_fraction': 0.11588541697710752, 'grad_norm': 14.420793533325195}
2023-01-03 16:56:06.637 DEBUG: Taking gradient step
2023-01-03 16:56:08.687 DEBUG: Loss 2: {'policy_loss': 0.006635588257057415, 'entropy_loss': -0.028399884700775146, 'vf_loss': 0.01627306687973669, 'total_loss': -0.02176429644371773, 'approx_kl': -0.013715916313230991, 'clip_fraction': 0.19140625, 'grad_norm': 12.310382843017578}
2023-01-03 16:56:10.683 DEBUG: Taking gradient step
2023-01-03 16:56:12.742 DEBUG: Loss 3: {'policy_loss': -0.029947424935660882, 'entropy_loss': -0.030047867447137833, 'vf_loss': 0.014493916774189531, 'total_loss': -0.059995292382798715, 'approx_kl': -0.025786533718928695, 'clip_fraction': 0.1171875, 'grad_norm': 12.045065879821777}
2023-01-03 16:56:14.759 DEBUG: Taking gradient step
2023-01-03 16:56:16.809 DEBUG: Loss 4: {'policy_loss': -0.017041064474496367, 'entropy_loss': -0.028820068575441837, 'vf_loss': 0.014919233470056251, 'total_loss': -0.0458611330499382, 'approx_kl': -0.03173995506949723, 'clip_fraction': 0.19661458395421505, 'grad_norm': 5.504092693328857}
2023-01-03 16:56:18.822 DEBUG: Taking gradient step
2023-01-03 16:56:20.904 DEBUG: Loss 5: {'policy_loss': -0.034318338018207696, 'entropy_loss': -0.03024465311318636, 'vf_loss': 0.014525517546105324, 'total_loss': -0.06456299113139405, 'approx_kl': -0.05107784550637007, 'clip_fraction': 0.2604166716337204, 'grad_norm': 11.053837776184082}
2023-01-03 16:56:22.921 DEBUG: Taking gradient step
2023-01-03 16:56:24.972 DEBUG: Loss 6: {'policy_loss': -0.05205413506886172, 'entropy_loss': -0.02843586914241314, 'vf_loss': 0.013098967714657348, 'total_loss': -0.08049000421127486, 'approx_kl': -0.056148722767829895, 'clip_fraction': 0.2942708358168602, 'grad_norm': 9.605169296264648}
2023-01-03 16:56:26.971 DEBUG: Taking gradient step
2023-01-03 16:56:29.020 DEBUG: Loss 7: {'policy_loss': -0.030669409723490488, 'entropy_loss': -0.028411325067281723, 'vf_loss': 0.01461206132764098, 'total_loss': -0.05908073479077221, 'approx_kl': -0.06367614562623203, 'clip_fraction': 0.2734375, 'grad_norm': 22.875112533569336}
2023-01-03 16:56:31.008 DEBUG: Taking gradient step
2023-01-03 16:56:33.049 DEBUG: Loss 8: {'policy_loss': -0.02720999825898959, 'entropy_loss': -0.028494957834482193, 'vf_loss': 0.014640959485513163, 'total_loss': -0.05570495609347178, 'approx_kl': -0.06345866806805134, 'clip_fraction': 0.34375, 'grad_norm': 12.194183349609375}
2023-01-03 16:56:35.066 DEBUG: Taking gradient step
2023-01-03 16:56:37.130 DEBUG: Loss 9: {'policy_loss': 0.002005456445668366, 'entropy_loss': -0.0265358854085207, 'vf_loss': 0.015773107894881636, 'total_loss': -0.024530428962852333, 'approx_kl': -0.07435727957636118, 'clip_fraction': 0.3020833358168602, 'grad_norm': 20.088577270507812}
2023-01-03 16:56:39.111 DEBUG: Taking gradient step
2023-01-03 16:56:41.255 DEBUG: Loss 10: {'policy_loss': -0.0006544763425909098, 'entropy_loss': -0.02929422352463007, 'vf_loss': 0.015329417237477752, 'total_loss': -0.029948699867220978, 'approx_kl': -0.10099138598889112, 'clip_fraction': 0.3841145932674408, 'grad_norm': 30.20085906982422}
2023-01-03 16:56:43.255 DEBUG: Taking gradient step
2023-01-03 16:56:45.303 DEBUG: Loss 11: {'policy_loss': 0.012899715546511023, 'entropy_loss': -0.027892680373042822, 'vf_loss': 0.016539453840780587, 'total_loss': -0.014992964826531799, 'approx_kl': -0.0910024018958211, 'clip_fraction': 0.3697916716337204, 'grad_norm': 18.88488006591797}
2023-01-03 16:56:47.303 DEBUG: Taking gradient step
2023-01-03 16:56:49.372 DEBUG: Loss 12: {'policy_loss': -0.015144974206203303, 'entropy_loss': -0.02857109345495701, 'vf_loss': 0.015255290974587029, 'total_loss': -0.04371606766116031, 'approx_kl': -0.08586550876498222, 'clip_fraction': 0.4192708358168602, 'grad_norm': 10.88101863861084}
2023-01-03 16:56:51.363 DEBUG: Taking gradient step
2023-01-03 16:56:53.413 DEBUG: Loss 13: {'policy_loss': -0.04988702282454915, 'entropy_loss': -0.02833653660491109, 'vf_loss': 0.014511225819267377, 'total_loss': -0.07822355942946024, 'approx_kl': -0.08332154713571072, 'clip_fraction': 0.421875, 'grad_norm': 7.853902339935303}
2023-01-03 16:56:55.685 DEBUG: Taking gradient step
2023-01-03 16:56:58.110 DEBUG: Loss 14: {'policy_loss': -0.00209212718461871, 'entropy_loss': -0.02797994902357459, 'vf_loss': 0.015681123069936694, 'total_loss': -0.0300720762081933, 'approx_kl': -0.08192414371296763, 'clip_fraction': 0.3515625, 'grad_norm': 18.721498489379883}
2023-01-03 16:56:58.111 INFO: Optimization: policy loss=-0.002, vf loss=0.016, entropy loss=-0.028, total loss=-0.030, num steps=15
2023-01-03 16:56:58.112 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 16:56:59.825 INFO: Evaluation rollout: return=0.606 (0.0), episode length=6.0
2023-01-03 16:56:59.826 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 16:56:59.829 INFO: Iteration: 84/137, steps: 18144
2023-01-03 16:57:12.622 DEBUG: Atoms are too close
2023-01-03 16:57:14.047 DEBUG: Atoms are too close
2023-01-03 16:57:23.585 DEBUG: Atoms are too close
2023-01-03 16:57:28.568 DEBUG: Atoms are too close
2023-01-03 16:57:30.855 DEBUG: Atoms are too close
2023-01-03 16:57:43.981 DEBUG: Atoms are too close
2023-01-03 16:57:47.704 DEBUG: Atoms are too close
2023-01-03 16:57:49.310 DEBUG: Atoms are too close
2023-01-03 16:57:49.602 DEBUG: Atoms are too close
2023-01-03 16:57:53.695 INFO: Training rollout: return=-4.151 (7.6), episode length=5.6
2023-01-03 16:57:53.697 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 16:57:53.699 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-18144_train.pkl
2023-01-03 16:57:55.725 DEBUG: Taking gradient step
2023-01-03 16:57:57.753 DEBUG: Loss 0: {'policy_loss': -0.06586537876435095, 'entropy_loss': -0.029407284688204527, 'vf_loss': 0.026449683457006407, 'total_loss': -0.09527266345255547, 'approx_kl': 2.444721758365631e-08, 'clip_fraction': 0.0, 'grad_norm': 20.07425880432129}
2023-01-03 16:57:59.737 DEBUG: Taking gradient step
2023-01-03 16:58:01.762 DEBUG: Loss 1: {'policy_loss': -0.056678236758776555, 'entropy_loss': -0.030295539181679487, 'vf_loss': 0.028269671229489892, 'total_loss': -0.08697377594045605, 'approx_kl': -0.016764091094955802, 'clip_fraction': 0.10546875, 'grad_norm': 12.31716251373291}
2023-01-03 16:58:03.732 DEBUG: Taking gradient step
2023-01-03 16:58:05.759 DEBUG: Loss 2: {'policy_loss': 0.029155304537139933, 'entropy_loss': -0.031142957508563995, 'vf_loss': 0.03153522196965431, 'total_loss': -0.001987652971424062, 'approx_kl': -0.04368511214852333, 'clip_fraction': 0.3346354216337204, 'grad_norm': 19.605756759643555}
2023-01-03 16:58:07.743 DEBUG: Taking gradient step
2023-01-03 16:58:09.773 DEBUG: Loss 3: {'policy_loss': 0.09230124984886752, 'entropy_loss': -0.029058688785880804, 'vf_loss': 0.03263837256419999, 'total_loss': 0.06324256106298672, 'approx_kl': -0.0761294774711132, 'clip_fraction': 0.421875, 'grad_norm': 29.86589241027832}
2023-01-03 16:58:11.733 DEBUG: Taking gradient step
2023-01-03 16:58:13.728 DEBUG: Loss 4: {'policy_loss': 0.032623223356991804, 'entropy_loss': -0.02994485991075635, 'vf_loss': 0.03018432050697839, 'total_loss': 0.0026783634462354588, 'approx_kl': -0.01756380032747984, 'clip_fraction': 0.3776041716337204, 'grad_norm': 23.311683654785156}
2023-01-03 16:58:15.677 DEBUG: Taking gradient step
2023-01-03 16:58:17.675 DEBUG: Loss 5: {'policy_loss': 0.041365703092980516, 'entropy_loss': -0.0296609322540462, 'vf_loss': 0.031156271760476154, 'total_loss': 0.011704770838934307, 'approx_kl': -0.0547996973618865, 'clip_fraction': 0.3177083358168602, 'grad_norm': 27.437990188598633}
2023-01-03 16:58:19.612 DEBUG: Taking gradient step
2023-01-03 16:58:21.613 DEBUG: Loss 6: {'policy_loss': -0.011885231254683451, 'entropy_loss': -0.029871751088649035, 'vf_loss': 0.027887394785995907, 'total_loss': -0.041756982343332485, 'approx_kl': -0.06294254306703806, 'clip_fraction': 0.2981770858168602, 'grad_norm': 21.62555694580078}
2023-01-03 16:58:23.542 DEBUG: Taking gradient step
2023-01-03 16:58:25.537 DEBUG: Loss 7: {'policy_loss': -0.018797053299184532, 'entropy_loss': -0.02904679160565138, 'vf_loss': 0.027081413654933696, 'total_loss': -0.04784384490483591, 'approx_kl': -0.046258666552603245, 'clip_fraction': 0.34375, 'grad_norm': 20.963748931884766}
2023-01-03 16:58:27.579 DEBUG: Taking gradient step
2023-01-03 16:58:29.572 DEBUG: Loss 8: {'policy_loss': 0.008877675530748343, 'entropy_loss': -0.030707851517945528, 'vf_loss': 0.028051569314642005, 'total_loss': -0.021830175987197182, 'approx_kl': -0.06934866961091757, 'clip_fraction': 0.3763020858168602, 'grad_norm': 24.610681533813477}
2023-01-03 16:58:31.508 DEBUG: Taking gradient step
2023-01-03 16:58:33.497 DEBUG: Loss 9: {'policy_loss': 0.021286744667784536, 'entropy_loss': -0.030976060312241316, 'vf_loss': 0.029190399729449812, 'total_loss': -0.00968931564445678, 'approx_kl': -0.07216378953307867, 'clip_fraction': 0.3385416716337204, 'grad_norm': 24.855297088623047}
2023-01-03 16:58:35.456 DEBUG: Taking gradient step
2023-01-03 16:58:37.452 DEBUG: Loss 10: {'policy_loss': 0.03382812583149882, 'entropy_loss': -0.029523856472223997, 'vf_loss': 0.028715685732073667, 'total_loss': 0.004304269359274822, 'approx_kl': -0.07432087231427431, 'clip_fraction': 0.3190104179084301, 'grad_norm': 25.82248306274414}
2023-01-03 16:58:39.395 DEBUG: Taking gradient step
2023-01-03 16:58:41.393 DEBUG: Loss 11: {'policy_loss': 0.0250523109842848, 'entropy_loss': -0.030586848966777325, 'vf_loss': 0.02785436608825717, 'total_loss': -0.005534537982492524, 'approx_kl': -0.07417032308876514, 'clip_fraction': 0.3268229179084301, 'grad_norm': 23.883447647094727}
2023-01-03 16:58:43.331 DEBUG: Taking gradient step
2023-01-03 16:58:45.310 DEBUG: Loss 12: {'policy_loss': 0.029671890497807694, 'entropy_loss': -0.03053971054032445, 'vf_loss': 0.027751991243422505, 'total_loss': -0.0008678200425167541, 'approx_kl': -0.08892492763698101, 'clip_fraction': 0.39453125, 'grad_norm': 31.634967803955078}
2023-01-03 16:58:47.246 DEBUG: Taking gradient step
2023-01-03 16:58:49.228 DEBUG: Loss 13: {'policy_loss': 0.044774388133529304, 'entropy_loss': -0.029115454759448767, 'vf_loss': 0.03010589277807308, 'total_loss': 0.015658933374080537, 'approx_kl': -0.078018669039011, 'clip_fraction': 0.4309895858168602, 'grad_norm': 26.962993621826172}
2023-01-03 16:58:51.188 DEBUG: Taking gradient step
2023-01-03 16:58:53.222 DEBUG: Loss 14: {'policy_loss': 0.017644059297424464, 'entropy_loss': -0.029894288629293442, 'vf_loss': 0.02722611996728543, 'total_loss': -0.012250229331868978, 'approx_kl': -0.07743398658931255, 'clip_fraction': 0.453125, 'grad_norm': 19.32114028930664}
2023-01-03 16:58:53.223 INFO: Optimization: policy loss=0.018, vf loss=0.027, entropy loss=-0.030, total loss=-0.012, num steps=15
2023-01-03 16:58:53.224 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 16:58:54.941 INFO: Evaluation rollout: return=0.614 (0.0), episode length=6.0
2023-01-03 16:58:54.942 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 16:58:54.945 INFO: Iteration: 85/137, steps: 18360
2023-01-03 16:59:03.954 DEBUG: Atoms are too close
2023-01-03 16:59:15.848 DEBUG: Atoms are too close
2023-01-03 16:59:27.300 DEBUG: Atoms are too close
2023-01-03 16:59:27.868 DEBUG: Atoms are too close
2023-01-03 16:59:42.883 DEBUG: Atoms are too close
2023-01-03 16:59:45.267 DEBUG: Atoms are too close
2023-01-03 16:59:45.582 DEBUG: Atoms are too close
2023-01-03 16:59:50.049 INFO: Training rollout: return=-2.756 (6.6), episode length=5.8
2023-01-03 16:59:50.052 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 16:59:50.055 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-18360_train.pkl
2023-01-03 16:59:52.189 DEBUG: Taking gradient step
2023-01-03 16:59:54.307 DEBUG: Loss 0: {'policy_loss': -0.03714754580128866, 'entropy_loss': -0.029460142366588116, 'vf_loss': 0.020320480455925098, 'total_loss': -0.06660768816787677, 'approx_kl': 4.2763229401998615e-08, 'clip_fraction': 0.0, 'grad_norm': 17.425317764282227}
2023-01-03 16:59:56.304 DEBUG: Taking gradient step
2023-01-03 16:59:58.338 DEBUG: Loss 1: {'policy_loss': 0.016076119276097395, 'entropy_loss': -0.029575735796242952, 'vf_loss': 0.022727954589565766, 'total_loss': -0.013499616520145558, 'approx_kl': -0.018582848366349936, 'clip_fraction': 0.1705729179084301, 'grad_norm': 14.681896209716797}
2023-01-03 17:00:00.401 DEBUG: Taking gradient step
2023-01-03 17:00:02.472 DEBUG: Loss 2: {'policy_loss': 0.03587707734710644, 'entropy_loss': -0.028811020776629448, 'vf_loss': 0.021572679510809656, 'total_loss': 0.007066056570476996, 'approx_kl': -0.0342361053917557, 'clip_fraction': 0.2552083358168602, 'grad_norm': 23.370948791503906}
2023-01-03 17:00:04.654 DEBUG: Taking gradient step
2023-01-03 17:00:06.685 DEBUG: Loss 3: {'policy_loss': 0.14245508821785427, 'entropy_loss': -0.03099678736180067, 'vf_loss': 0.02475681371173551, 'total_loss': 0.11145830085605359, 'approx_kl': -0.010138891637325287, 'clip_fraction': 0.3125, 'grad_norm': 32.97280502319336}
2023-01-03 17:00:08.658 DEBUG: Taking gradient step
2023-01-03 17:00:10.665 DEBUG: Loss 4: {'policy_loss': 0.11084986370408961, 'entropy_loss': -0.0311159105040133, 'vf_loss': 0.022731089439103423, 'total_loss': 0.07973395320007631, 'approx_kl': 0.028716727858409286, 'clip_fraction': 0.3528645858168602, 'grad_norm': 17.915699005126953}
2023-01-03 17:00:12.613 DEBUG: Early stopping at step 5 for reaching max KL.
2023-01-03 17:00:12.613 INFO: Optimization: policy loss=0.111, vf loss=0.023, entropy loss=-0.031, total loss=0.080, num steps=5
2023-01-03 17:00:12.614 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 17:00:14.330 INFO: Evaluation rollout: return=0.605 (0.0), episode length=6.0
2023-01-03 17:00:14.332 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 17:00:14.336 INFO: Iteration: 86/137, steps: 18576
2023-01-03 17:00:26.144 DEBUG: Atoms are too close
2023-01-03 17:00:45.015 DEBUG: Atoms are too close
2023-01-03 17:01:00.548 DEBUG: Atoms are too close
2023-01-03 17:01:01.535 DEBUG: Atoms are too close
2023-01-03 17:01:02.699 DEBUG: Atoms are too close
2023-01-03 17:01:03.426 DEBUG: Atoms are too close
2023-01-03 17:01:10.766 INFO: Training rollout: return=-2.582 (6.9), episode length=5.7
2023-01-03 17:01:10.768 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 17:01:10.773 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-18576_train.pkl
2023-01-03 17:01:12.708 DEBUG: Taking gradient step
2023-01-03 17:01:14.849 DEBUG: Loss 0: {'policy_loss': -0.03670350021919634, 'entropy_loss': -0.031535917427390814, 'vf_loss': 0.017264501111979236, 'total_loss': -0.06823941764658716, 'approx_kl': -5.277492221011926e-09, 'clip_fraction': 0.0, 'grad_norm': 24.635818481445312}
2023-01-03 17:01:17.004 DEBUG: Taking gradient step
2023-01-03 17:01:18.990 DEBUG: Loss 1: {'policy_loss': 0.027572157349160062, 'entropy_loss': -0.031085011549293995, 'vf_loss': 0.019617698089009004, 'total_loss': -0.003512854200133933, 'approx_kl': 0.015222528018057346, 'clip_fraction': 0.1640625, 'grad_norm': 19.240976333618164}
2023-01-03 17:01:21.225 DEBUG: Taking gradient step
2023-01-03 17:01:23.565 DEBUG: Loss 2: {'policy_loss': -0.04077064575954159, 'entropy_loss': -0.03103678487241268, 'vf_loss': 0.01735218405326693, 'total_loss': -0.07180743063195427, 'approx_kl': 0.025957461446523666, 'clip_fraction': 0.3138020858168602, 'grad_norm': 9.729562759399414}
2023-01-03 17:01:25.844 DEBUG: Taking gradient step
2023-01-03 17:01:28.165 DEBUG: Loss 3: {'policy_loss': 0.04663212114398346, 'entropy_loss': -0.031245289370417595, 'vf_loss': 0.019379395620976427, 'total_loss': 0.015386831773565868, 'approx_kl': 0.031148841604590416, 'clip_fraction': 0.3463541716337204, 'grad_norm': 24.58223533630371}
2023-01-03 17:01:30.430 DEBUG: Early stopping at step 4 for reaching max KL.
2023-01-03 17:01:30.430 INFO: Optimization: policy loss=0.047, vf loss=0.019, entropy loss=-0.031, total loss=0.015, num steps=4
2023-01-03 17:01:30.431 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 17:01:32.157 INFO: Evaluation rollout: return=0.599 (0.0), episode length=6.0
2023-01-03 17:01:32.159 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 17:01:32.162 INFO: Iteration: 87/137, steps: 18792
2023-01-03 17:01:47.075 DEBUG: Atoms are too close
2023-01-03 17:02:04.171 DEBUG: Atoms are too close
2023-01-03 17:02:05.299 DEBUG: Atoms are too close
2023-01-03 17:02:23.925 DEBUG: Atoms are too close
2023-01-03 17:02:25.361 DEBUG: Atoms are too close
2023-01-03 17:02:28.674 INFO: Training rollout: return=-2.469 (6.0), episode length=5.9
2023-01-03 17:02:28.675 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 17:02:28.679 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-18792_train.pkl
2023-01-03 17:02:30.665 DEBUG: Taking gradient step
2023-01-03 17:02:32.661 DEBUG: Loss 0: {'policy_loss': 0.008886168930658985, 'entropy_loss': -0.03387387841939926, 'vf_loss': 0.023164025063239856, 'total_loss': -0.024987709488740274, 'approx_kl': 2.5688980720417476e-08, 'clip_fraction': 0.0, 'grad_norm': 18.292686462402344}
2023-01-03 17:02:34.608 DEBUG: Taking gradient step
2023-01-03 17:02:36.602 DEBUG: Loss 1: {'policy_loss': -0.04421018172242519, 'entropy_loss': -0.035596095491200686, 'vf_loss': 0.020487643709284804, 'total_loss': -0.07980627721362588, 'approx_kl': -0.0018926383927464485, 'clip_fraction': 0.06770833395421505, 'grad_norm': 15.496818542480469}
2023-01-03 17:02:38.539 DEBUG: Taking gradient step
2023-01-03 17:02:40.526 DEBUG: Loss 2: {'policy_loss': -0.04074427729686661, 'entropy_loss': -0.03321691136807203, 'vf_loss': 0.022338003844815518, 'total_loss': -0.07396118866493864, 'approx_kl': -0.0019697645911946893, 'clip_fraction': 0.2421875, 'grad_norm': 10.069955825805664}
2023-01-03 17:02:42.455 DEBUG: Taking gradient step
2023-01-03 17:02:44.405 DEBUG: Loss 3: {'policy_loss': 0.033148950842044826, 'entropy_loss': -0.035406868904829025, 'vf_loss': 0.023897370125316647, 'total_loss': -0.002257918062784206, 'approx_kl': -0.0018843626603484154, 'clip_fraction': 0.3424479216337204, 'grad_norm': 13.972809791564941}
2023-01-03 17:02:46.274 DEBUG: Taking gradient step
2023-01-03 17:02:48.176 DEBUG: Loss 4: {'policy_loss': 0.02500383621142256, 'entropy_loss': -0.03530759550631046, 'vf_loss': 0.024386176211917347, 'total_loss': -0.010303759294887915, 'approx_kl': -0.0020340688060969114, 'clip_fraction': 0.28515625, 'grad_norm': 13.978673934936523}
2023-01-03 17:02:50.034 DEBUG: Taking gradient step
2023-01-03 17:02:51.937 DEBUG: Loss 5: {'policy_loss': -0.04665325100305545, 'entropy_loss': -0.0342232477851212, 'vf_loss': 0.02186490096383243, 'total_loss': -0.08087649878817665, 'approx_kl': -0.009880874771624804, 'clip_fraction': 0.36328125, 'grad_norm': 4.217473983764648}
2023-01-03 17:02:53.786 DEBUG: Taking gradient step
2023-01-03 17:02:55.680 DEBUG: Loss 6: {'policy_loss': -0.026948316121240372, 'entropy_loss': -0.03278686851263046, 'vf_loss': 0.02250706020366057, 'total_loss': -0.059735184633870834, 'approx_kl': -0.016041951719671488, 'clip_fraction': 0.3333333358168602, 'grad_norm': 9.716288566589355}
2023-01-03 17:02:57.541 DEBUG: Taking gradient step
2023-01-03 17:02:59.524 DEBUG: Loss 7: {'policy_loss': -0.036099622227210304, 'entropy_loss': -0.03397535812109709, 'vf_loss': 0.020946844371554436, 'total_loss': -0.07007498034830739, 'approx_kl': -0.01491542614530772, 'clip_fraction': 0.3098958358168602, 'grad_norm': 6.751620292663574}
2023-01-03 17:03:01.376 DEBUG: Taking gradient step
2023-01-03 17:03:03.262 DEBUG: Loss 8: {'policy_loss': -0.02898749229117559, 'entropy_loss': -0.03280807798728347, 'vf_loss': 0.022980587739072755, 'total_loss': -0.061795570278459055, 'approx_kl': -0.02982218423858285, 'clip_fraction': 0.3841145858168602, 'grad_norm': 9.386123657226562}
2023-01-03 17:03:05.104 DEBUG: Taking gradient step
2023-01-03 17:03:06.996 DEBUG: Loss 9: {'policy_loss': -0.018149599168158115, 'entropy_loss': -0.032781658694148064, 'vf_loss': 0.02279891482816616, 'total_loss': -0.05093125786230618, 'approx_kl': -0.029039965011179447, 'clip_fraction': 0.36328125, 'grad_norm': 8.956308364868164}
2023-01-03 17:03:08.849 DEBUG: Taking gradient step
2023-01-03 17:03:10.793 DEBUG: Loss 10: {'policy_loss': -0.01168903554321149, 'entropy_loss': -0.03282728232443333, 'vf_loss': 0.024227502024812993, 'total_loss': -0.04451631786764482, 'approx_kl': -0.032779884175397456, 'clip_fraction': 0.3736979216337204, 'grad_norm': 14.341192245483398}
2023-01-03 17:03:12.641 DEBUG: Taking gradient step
2023-01-03 17:03:14.556 DEBUG: Loss 11: {'policy_loss': -0.07015190446093254, 'entropy_loss': -0.03183315601199865, 'vf_loss': 0.019848346104530963, 'total_loss': -0.10198506047293118, 'approx_kl': -0.059506618650630116, 'clip_fraction': 0.3763020858168602, 'grad_norm': 7.354866027832031}
2023-01-03 17:03:16.522 DEBUG: Taking gradient step
2023-01-03 17:03:18.426 DEBUG: Loss 12: {'policy_loss': -0.006131977559853848, 'entropy_loss': -0.031638665590435266, 'vf_loss': 0.023026019353800886, 'total_loss': -0.037770643150289114, 'approx_kl': -0.03371947258710861, 'clip_fraction': 0.3919270858168602, 'grad_norm': 10.289778709411621}
2023-01-03 17:03:20.303 DEBUG: Taking gradient step
2023-01-03 17:03:22.435 DEBUG: Loss 13: {'policy_loss': -0.03681470996916099, 'entropy_loss': -0.03283863188698888, 'vf_loss': 0.021852327747449038, 'total_loss': -0.06965334185614987, 'approx_kl': -0.04734028875827789, 'clip_fraction': 0.3854166716337204, 'grad_norm': 8.585164070129395}
2023-01-03 17:03:24.688 DEBUG: Taking gradient step
2023-01-03 17:03:27.018 DEBUG: Loss 14: {'policy_loss': -0.041021062734712184, 'entropy_loss': -0.031592188868671656, 'vf_loss': 0.020379517585203004, 'total_loss': -0.07261325160338383, 'approx_kl': -0.05526253767311573, 'clip_fraction': 0.4010416716337204, 'grad_norm': 10.897582054138184}
2023-01-03 17:03:27.019 INFO: Optimization: policy loss=-0.041, vf loss=0.020, entropy loss=-0.032, total loss=-0.073, num steps=15
2023-01-03 17:03:27.020 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 17:03:28.765 INFO: Evaluation rollout: return=0.604 (0.0), episode length=6.0
2023-01-03 17:03:28.766 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 17:03:28.769 INFO: Iteration: 88/137, steps: 19008
2023-01-03 17:03:38.763 DEBUG: Atoms are too close
2023-01-03 17:03:41.126 DEBUG: Atoms are too close
2023-01-03 17:03:41.129 DEBUG: Atoms are too close
2023-01-03 17:03:41.130 DEBUG: Atoms are too close
2023-01-03 17:03:45.982 DEBUG: Atoms are too close
2023-01-03 17:03:58.698 DEBUG: Atoms are too close
2023-01-03 17:04:00.835 DEBUG: Atoms are too close
2023-01-03 17:04:14.178 DEBUG: Atoms are too close
2023-01-03 17:04:14.469 DEBUG: Atoms are too close
2023-01-03 17:04:18.098 DEBUG: Atoms are too close
2023-01-03 17:04:22.451 INFO: Training rollout: return=-4.288 (7.2), episode length=5.7
2023-01-03 17:04:22.452 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 17:04:22.456 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-19008_train.pkl
2023-01-03 17:04:24.296 DEBUG: Taking gradient step
2023-01-03 17:04:26.138 DEBUG: Loss 0: {'policy_loss': -0.025427293716351003, 'entropy_loss': -0.031191044952720404, 'vf_loss': 0.02994066041431498, 'total_loss': -0.05661833866907141, 'approx_kl': -5.6189797703609656e-08, 'clip_fraction': 0.0, 'grad_norm': 15.466448783874512}
2023-01-03 17:04:27.953 DEBUG: Taking gradient step
2023-01-03 17:04:29.798 DEBUG: Loss 1: {'policy_loss': -0.013777308884700766, 'entropy_loss': -0.030383008532226086, 'vf_loss': 0.031103392527516392, 'total_loss': -0.04416031741692685, 'approx_kl': -0.005823597544804215, 'clip_fraction': 0.06770833395421505, 'grad_norm': 18.28675651550293}
2023-01-03 17:04:31.604 DEBUG: Taking gradient step
2023-01-03 17:04:33.456 DEBUG: Loss 2: {'policy_loss': 0.013484136896474392, 'entropy_loss': -0.03177153645083308, 'vf_loss': 0.03244527587614521, 'total_loss': -0.01828739955435869, 'approx_kl': -0.024992204271256924, 'clip_fraction': 0.2408854216337204, 'grad_norm': 22.410688400268555}
2023-01-03 17:04:35.271 DEBUG: Taking gradient step
2023-01-03 17:04:37.119 DEBUG: Loss 3: {'policy_loss': 0.013469500073196139, 'entropy_loss': -0.031991529278457165, 'vf_loss': 0.029786951642729265, 'total_loss': -0.018522029205261022, 'approx_kl': -0.014668908901512623, 'clip_fraction': 0.2786458358168602, 'grad_norm': 21.327259063720703}
2023-01-03 17:04:38.921 DEBUG: Taking gradient step
2023-01-03 17:04:40.763 DEBUG: Loss 4: {'policy_loss': 0.02973985257204357, 'entropy_loss': -0.031338287983089685, 'vf_loss': 0.03016722563536066, 'total_loss': -0.0015984354110461143, 'approx_kl': -0.026908397674560547, 'clip_fraction': 0.38671875, 'grad_norm': 21.40911865234375}
2023-01-03 17:04:42.659 DEBUG: Taking gradient step
2023-01-03 17:04:44.512 DEBUG: Loss 5: {'policy_loss': 0.017799055875138928, 'entropy_loss': -0.032270447351038456, 'vf_loss': 0.028376287673508034, 'total_loss': -0.01447139147589953, 'approx_kl': -0.027108498383313417, 'clip_fraction': 0.3606770858168602, 'grad_norm': 17.468364715576172}
2023-01-03 17:04:46.319 DEBUG: Taking gradient step
2023-01-03 17:04:48.164 DEBUG: Loss 6: {'policy_loss': 0.03169206486531999, 'entropy_loss': -0.03233804740011692, 'vf_loss': 0.028710657187994874, 'total_loss': -0.000645982534796934, 'approx_kl': -0.025352834723889828, 'clip_fraction': 0.3502604216337204, 'grad_norm': 11.286261558532715}
2023-01-03 17:04:49.989 DEBUG: Taking gradient step
2023-01-03 17:04:51.844 DEBUG: Loss 7: {'policy_loss': 0.009112846028771729, 'entropy_loss': -0.033596474677324295, 'vf_loss': 0.02767662558097378, 'total_loss': -0.024483628648552566, 'approx_kl': -0.0341434245929122, 'clip_fraction': 0.3515625, 'grad_norm': 13.961540222167969}
2023-01-03 17:04:53.650 DEBUG: Taking gradient step
2023-01-03 17:04:55.502 DEBUG: Loss 8: {'policy_loss': 0.07519438655457522, 'entropy_loss': -0.0343520138412714, 'vf_loss': 0.028267191927557642, 'total_loss': 0.04084237271330382, 'approx_kl': -0.03075384208932519, 'clip_fraction': 0.4401041716337204, 'grad_norm': 21.137269973754883}
2023-01-03 17:04:57.319 DEBUG: Taking gradient step
2023-01-03 17:04:59.167 DEBUG: Loss 9: {'policy_loss': 0.1042203341482077, 'entropy_loss': -0.03541907202452421, 'vf_loss': 0.028504653348561636, 'total_loss': 0.06880126212368348, 'approx_kl': -0.002890956588089466, 'clip_fraction': 0.4921875, 'grad_norm': 17.486772537231445}
2023-01-03 17:05:00.978 DEBUG: Taking gradient step
2023-01-03 17:05:02.823 DEBUG: Loss 10: {'policy_loss': 0.09214966558213629, 'entropy_loss': -0.03681052662432194, 'vf_loss': 0.028034397300298247, 'total_loss': 0.05533913895781435, 'approx_kl': -0.0419649719260633, 'clip_fraction': 0.4817708358168602, 'grad_norm': 12.72672176361084}
2023-01-03 17:05:04.630 DEBUG: Taking gradient step
2023-01-03 17:05:06.482 DEBUG: Loss 11: {'policy_loss': 0.04250960303531573, 'entropy_loss': -0.03699801303446293, 'vf_loss': 0.02634043207784979, 'total_loss': 0.005511590000852801, 'approx_kl': 0.003695848397910595, 'clip_fraction': 0.5390625, 'grad_norm': 11.128535270690918}
2023-01-03 17:05:08.290 DEBUG: Taking gradient step
2023-01-03 17:05:10.129 DEBUG: Loss 12: {'policy_loss': 0.1489596737268475, 'entropy_loss': -0.037892681546509266, 'vf_loss': 0.028714471842282863, 'total_loss': 0.11106699218033825, 'approx_kl': 0.0019456376321613789, 'clip_fraction': 0.5716145932674408, 'grad_norm': 20.803556442260742}
2023-01-03 17:05:11.935 DEBUG: Taking gradient step
2023-01-03 17:05:13.787 DEBUG: Loss 13: {'policy_loss': 0.10099314642395987, 'entropy_loss': -0.036773206666111946, 'vf_loss': 0.027882223021819225, 'total_loss': 0.06421993975784793, 'approx_kl': 0.003178649814799428, 'clip_fraction': 0.49609375, 'grad_norm': 12.045356750488281}
2023-01-03 17:05:15.602 DEBUG: Taking gradient step
2023-01-03 17:05:17.450 DEBUG: Loss 14: {'policy_loss': 0.0779059244529146, 'entropy_loss': -0.03478093957528472, 'vf_loss': 0.026963565294887876, 'total_loss': 0.04312498487762988, 'approx_kl': 0.032384096179157495, 'clip_fraction': 0.42578125, 'grad_norm': 15.010313034057617}
2023-01-03 17:05:17.450 INFO: Optimization: policy loss=0.078, vf loss=0.027, entropy loss=-0.035, total loss=0.043, num steps=15
2023-01-03 17:05:17.451 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 17:05:19.133 INFO: Evaluation rollout: return=0.588 (0.0), episode length=6.0
2023-01-03 17:05:19.136 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 17:05:19.139 INFO: Iteration: 89/137, steps: 19224
2023-01-03 17:05:33.557 DEBUG: Atoms are too close
2023-01-03 17:05:34.775 DEBUG: Atoms are too close
2023-01-03 17:05:36.923 DEBUG: Atoms are too close
2023-01-03 17:05:51.299 DEBUG: Atoms are too close
2023-01-03 17:05:54.189 DEBUG: Atoms are too close
2023-01-03 17:06:09.246 DEBUG: There is a single atom floating around
2023-01-03 17:06:10.092 DEBUG: There is a single atom floating around
2023-01-03 17:06:14.198 INFO: Training rollout: return=-2.368 (5.9), episode length=5.9
2023-01-03 17:06:14.199 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 17:06:14.202 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-19224_train.pkl
2023-01-03 17:06:16.070 DEBUG: Taking gradient step
2023-01-03 17:06:17.952 DEBUG: Loss 0: {'policy_loss': -0.01806873779283039, 'entropy_loss': -0.03252656199038029, 'vf_loss': 0.026597282039267825, 'total_loss': -0.05059529978321067, 'approx_kl': 1.299971152946e-08, 'clip_fraction': 0.0, 'grad_norm': 19.0462646484375}
2023-01-03 17:06:19.799 DEBUG: Taking gradient step
2023-01-03 17:06:21.765 DEBUG: Loss 1: {'policy_loss': 0.09815130551690295, 'entropy_loss': -0.03298973431810737, 'vf_loss': 0.028489923105328725, 'total_loss': 0.06516157119879558, 'approx_kl': 0.014279847964644432, 'clip_fraction': 0.2604166716337204, 'grad_norm': 23.033897399902344}
2023-01-03 17:06:23.619 DEBUG: Early stopping at step 2 for reaching max KL.
2023-01-03 17:06:23.619 INFO: Optimization: policy loss=0.098, vf loss=0.028, entropy loss=-0.033, total loss=0.065, num steps=2
2023-01-03 17:06:23.620 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 17:06:25.536 INFO: Evaluation rollout: return=0.587 (0.0), episode length=6.0
2023-01-03 17:06:25.538 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 17:06:25.541 INFO: Iteration: 90/137, steps: 19440
2023-01-03 17:06:35.268 DEBUG: Atoms are too close
2023-01-03 17:06:58.729 DEBUG: There is a single atom floating around
2023-01-03 17:07:01.432 DEBUG: Atoms are too close
2023-01-03 17:07:02.137 DEBUG: Atoms are too close
2023-01-03 17:07:08.765 DEBUG: Atoms are too close
2023-01-03 17:07:09.892 DEBUG: Atoms are too close
2023-01-03 17:07:15.442 DEBUG: Atoms are too close
2023-01-03 17:07:16.582 DEBUG: There is a single atom floating around
2023-01-03 17:07:20.105 INFO: Training rollout: return=-3.387 (6.8), episode length=5.8
2023-01-03 17:07:20.107 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 17:07:20.110 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-19440_train.pkl
2023-01-03 17:07:21.965 DEBUG: Taking gradient step
2023-01-03 17:07:23.826 DEBUG: Loss 0: {'policy_loss': -0.03931226964506502, 'entropy_loss': -0.0309281125664711, 'vf_loss': 0.02657758700555545, 'total_loss': -0.07024038221153611, 'approx_kl': -8.088924730031977e-08, 'clip_fraction': 0.0, 'grad_norm': 16.33229637145996}
2023-01-03 17:07:25.651 DEBUG: Early stopping at step 1 for reaching max KL.
2023-01-03 17:07:25.652 INFO: Optimization: policy loss=-0.039, vf loss=0.027, entropy loss=-0.031, total loss=-0.070, num steps=1
2023-01-03 17:07:25.652 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 17:07:27.310 INFO: Evaluation rollout: return=0.590 (0.0), episode length=6.0
2023-01-03 17:07:27.311 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 17:07:27.314 DEBUG: Deleting old model: runs/CH3NO_dna/models/CH3NO_dna_run-1_steps-17496.model
2023-01-03 17:07:27.320 DEBUG: Saving model: runs/CH3NO_dna/models/CH3NO_dna_run-1_steps-19656.model
2023-01-03 17:07:27.366 INFO: Iteration: 91/137, steps: 19656
2023-01-03 17:07:39.767 DEBUG: There is a single atom floating around
2023-01-03 17:07:39.770 DEBUG: There is a single atom floating around
2023-01-03 17:07:39.771 DEBUG: There is a single atom floating around
2023-01-03 17:07:40.631 DEBUG: Atoms are too close
2023-01-03 17:07:58.729 DEBUG: Atoms are too close
2023-01-03 17:08:13.114 DEBUG: Atoms are too close
2023-01-03 17:08:13.680 DEBUG: There is a single atom floating around
2023-01-03 17:08:13.960 DEBUG: There is a single atom floating around
2023-01-03 17:08:19.025 DEBUG: Atoms are too close
2023-01-03 17:08:21.055 INFO: Training rollout: return=-3.396 (6.7), episode length=5.8
2023-01-03 17:08:21.057 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 17:08:21.060 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-19656_train.pkl
2023-01-03 17:08:22.933 DEBUG: Taking gradient step
2023-01-03 17:08:24.797 DEBUG: Loss 0: {'policy_loss': -0.018856588200265624, 'entropy_loss': -0.03153650974854827, 'vf_loss': 0.028367144828768336, 'total_loss': -0.05039309794881389, 'approx_kl': 9.848736226558685e-08, 'clip_fraction': 0.0, 'grad_norm': 16.315475463867188}
2023-01-03 17:08:26.624 DEBUG: Early stopping at step 1 for reaching max KL.
2023-01-03 17:08:26.624 INFO: Optimization: policy loss=-0.019, vf loss=0.028, entropy loss=-0.032, total loss=-0.050, num steps=1
2023-01-03 17:08:26.625 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 17:08:28.343 INFO: Evaluation rollout: return=0.587 (0.0), episode length=6.0
2023-01-03 17:08:28.344 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 17:08:28.347 INFO: Iteration: 92/137, steps: 19872
2023-01-03 17:08:40.481 DEBUG: Atoms are too close
2023-01-03 17:08:40.778 DEBUG: There is a single atom floating around
2023-01-03 17:08:42.479 DEBUG: There is a single atom floating around
2023-01-03 17:08:58.980 DEBUG: There is a single atom floating around
2023-01-03 17:08:59.541 DEBUG: There is a single atom floating around
2023-01-03 17:09:00.397 DEBUG: Atoms are too close
2023-01-03 17:09:13.669 DEBUG: There is a single atom floating around
2023-01-03 17:09:13.672 DEBUG: Atoms are too close
2023-01-03 17:09:13.948 DEBUG: There is a single atom floating around
2023-01-03 17:09:14.780 DEBUG: There is a single atom floating around
2023-01-03 17:09:14.782 DEBUG: Atoms are too close
2023-01-03 17:09:17.817 DEBUG: There is a single atom floating around
2023-01-03 17:09:19.435 DEBUG: Atoms are too close
2023-01-03 17:09:20.763 INFO: Training rollout: return=-5.170 (7.5), episode length=5.7
2023-01-03 17:09:20.764 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 17:09:20.767 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-19872_train.pkl
2023-01-03 17:09:22.584 DEBUG: Taking gradient step
2023-01-03 17:09:24.426 DEBUG: Loss 0: {'policy_loss': -0.027780093707170054, 'entropy_loss': -0.033073797821998596, 'vf_loss': 0.03646489880364935, 'total_loss': -0.06085389152916865, 'approx_kl': 1.337612047791481e-07, 'clip_fraction': 0.0, 'grad_norm': 16.08647346496582}
2023-01-03 17:09:26.232 DEBUG: Early stopping at step 1 for reaching max KL.
2023-01-03 17:09:26.232 INFO: Optimization: policy loss=-0.028, vf loss=0.036, entropy loss=-0.033, total loss=-0.061, num steps=1
2023-01-03 17:09:26.233 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 17:09:27.911 INFO: Evaluation rollout: return=0.588 (0.0), episode length=6.0
2023-01-03 17:09:27.912 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 17:09:27.915 INFO: Iteration: 93/137, steps: 20088
2023-01-03 17:09:40.078 DEBUG: Atoms are too close
2023-01-03 17:09:42.387 DEBUG: There is a single atom floating around
2023-01-03 17:09:42.689 DEBUG: There is a single atom floating around
2023-01-03 17:09:59.740 DEBUG: There is a single atom floating around
2023-01-03 17:09:59.742 DEBUG: Atoms are too close
2023-01-03 17:10:00.042 DEBUG: Atoms are too close
2023-01-03 17:10:00.043 DEBUG: There is a single atom floating around
2023-01-03 17:10:00.044 DEBUG: There is a single atom floating around
2023-01-03 17:10:15.346 DEBUG: There is a single atom floating around
2023-01-03 17:10:15.618 DEBUG: There is a single atom floating around
2023-01-03 17:10:16.527 DEBUG: There is a single atom floating around
2023-01-03 17:10:16.529 DEBUG: Atoms are too close
2023-01-03 17:10:16.810 DEBUG: Atoms are too close
2023-01-03 17:10:20.865 INFO: Training rollout: return=-5.161 (7.5), episode length=5.7
2023-01-03 17:10:20.867 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 17:10:20.869 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-20088_train.pkl
2023-01-03 17:10:22.678 DEBUG: Taking gradient step
2023-01-03 17:10:24.500 DEBUG: Loss 0: {'policy_loss': 0.018925894796340006, 'entropy_loss': -0.038268791511654854, 'vf_loss': 0.0390033920391797, 'total_loss': -0.019342896715314844, 'approx_kl': -8.044298738241196e-08, 'clip_fraction': 0.0, 'grad_norm': 14.550405502319336}
2023-01-03 17:10:26.277 DEBUG: Taking gradient step
2023-01-03 17:10:28.099 DEBUG: Loss 1: {'policy_loss': 0.021262895504481932, 'entropy_loss': -0.037235177122056484, 'vf_loss': 0.039657064626061916, 'total_loss': -0.01597228161757455, 'approx_kl': 0.015016873949207366, 'clip_fraction': 0.2044270858168602, 'grad_norm': 13.74303913116455}
2023-01-03 17:10:29.880 DEBUG: Early stopping at step 2 for reaching max KL.
2023-01-03 17:10:29.880 INFO: Optimization: policy loss=0.021, vf loss=0.040, entropy loss=-0.037, total loss=-0.016, num steps=2
2023-01-03 17:10:29.881 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 17:10:31.785 INFO: Evaluation rollout: return=0.594 (0.0), episode length=6.0
2023-01-03 17:10:31.786 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 17:10:31.789 INFO: Iteration: 94/137, steps: 20304
2023-01-03 17:10:43.961 DEBUG: There is a single atom floating around
2023-01-03 17:10:45.097 DEBUG: Atoms are too close
2023-01-03 17:10:46.502 DEBUG: Atoms are too close
2023-01-03 17:10:48.536 DEBUG: Atoms are too close
2023-01-03 17:10:48.538 DEBUG: Atoms are too close
2023-01-03 17:11:03.779 DEBUG: Atoms are too close
2023-01-03 17:11:21.373 DEBUG: There is a single atom floating around
2023-01-03 17:11:21.952 DEBUG: Atoms are too close
2023-01-03 17:11:22.522 DEBUG: There is a single atom floating around
2023-01-03 17:11:25.349 INFO: Training rollout: return=-3.326 (6.6), episode length=5.8
2023-01-03 17:11:25.351 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 17:11:25.353 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-20304_train.pkl
2023-01-03 17:11:27.217 DEBUG: Taking gradient step
2023-01-03 17:11:29.110 DEBUG: Loss 0: {'policy_loss': -0.04176952870564003, 'entropy_loss': -0.03848231676965952, 'vf_loss': 0.026278595297571414, 'total_loss': -0.08025184547529955, 'approx_kl': 8.832042414086416e-08, 'clip_fraction': 0.0, 'grad_norm': 19.869949340820312}
2023-01-03 17:11:30.956 DEBUG: Early stopping at step 1 for reaching max KL.
2023-01-03 17:11:30.957 INFO: Optimization: policy loss=-0.042, vf loss=0.026, entropy loss=-0.038, total loss=-0.080, num steps=1
2023-01-03 17:11:30.957 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 17:11:32.664 INFO: Evaluation rollout: return=0.595 (0.0), episode length=6.0
2023-01-03 17:11:32.665 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 17:11:32.668 INFO: Iteration: 95/137, steps: 20520
2023-01-03 17:11:46.071 DEBUG: There is a single atom floating around
2023-01-03 17:12:07.165 DEBUG: There is a single atom floating around
2023-01-03 17:12:10.460 DEBUG: Atoms are too close
2023-01-03 17:12:20.666 DEBUG: There is a single atom floating around
2023-01-03 17:12:27.943 DEBUG: Atoms are too close
2023-01-03 17:12:28.941 DEBUG: Atoms are too close
2023-01-03 17:12:28.993 INFO: Training rollout: return=-2.346 (5.7), episode length=5.9
2023-01-03 17:12:28.993 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 17:12:28.997 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-20520_train.pkl
2023-01-03 17:12:30.877 DEBUG: Taking gradient step
2023-01-03 17:12:32.774 DEBUG: Loss 0: {'policy_loss': 0.03062952192453588, 'entropy_loss': -0.03709561191499233, 'vf_loss': 0.023136836390307905, 'total_loss': -0.006466089990456447, 'approx_kl': -3.022918093620319e-08, 'clip_fraction': 0.0, 'grad_norm': 20.20240020751953}
2023-01-03 17:12:34.624 DEBUG: Taking gradient step
2023-01-03 17:12:36.520 DEBUG: Loss 1: {'policy_loss': 0.007331496770651695, 'entropy_loss': -0.035516510251909494, 'vf_loss': 0.024041484412987858, 'total_loss': -0.0281850134812578, 'approx_kl': -0.0018952962709590793, 'clip_fraction': 0.14192708395421505, 'grad_norm': 16.281282424926758}
2023-01-03 17:12:38.374 DEBUG: Taking gradient step
2023-01-03 17:12:40.270 DEBUG: Loss 2: {'policy_loss': 0.05581668775493141, 'entropy_loss': -0.035531263798475266, 'vf_loss': 0.02394689346744716, 'total_loss': 0.020285423956456147, 'approx_kl': 0.011008166708052158, 'clip_fraction': 0.3515625, 'grad_norm': 11.566789627075195}
2023-01-03 17:12:42.186 DEBUG: Early stopping at step 3 for reaching max KL.
2023-01-03 17:12:42.187 INFO: Optimization: policy loss=0.056, vf loss=0.024, entropy loss=-0.036, total loss=0.020, num steps=3
2023-01-03 17:12:42.187 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 17:12:43.858 INFO: Evaluation rollout: return=0.603 (0.0), episode length=6.0
2023-01-03 17:12:43.859 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 17:12:43.862 INFO: Iteration: 96/137, steps: 20736
2023-01-03 17:13:00.766 DEBUG: Atoms are too close
2023-01-03 17:13:01.377 DEBUG: Atoms are too close
2023-01-03 17:13:17.571 DEBUG: There is a single atom floating around
2023-01-03 17:13:27.387 DEBUG: Atoms are too close
2023-01-03 17:13:39.830 DEBUG: Atoms are too close
2023-01-03 17:13:39.886 INFO: Training rollout: return=-2.432 (6.1), episode length=5.9
2023-01-03 17:13:39.887 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 17:13:39.890 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-20736_train.pkl
2023-01-03 17:13:41.795 DEBUG: Taking gradient step
2023-01-03 17:13:43.756 DEBUG: Loss 0: {'policy_loss': 0.01822180606318766, 'entropy_loss': -0.03880957141518593, 'vf_loss': 0.02117197661762919, 'total_loss': -0.020587765351998265, 'approx_kl': 4.319978508249278e-08, 'clip_fraction': 0.0, 'grad_norm': 12.437666893005371}
2023-01-03 17:13:45.698 DEBUG: Taking gradient step
2023-01-03 17:13:47.864 DEBUG: Loss 1: {'policy_loss': -0.01854395856032687, 'entropy_loss': -0.03656173404306173, 'vf_loss': 0.019548150280507524, 'total_loss': -0.05510569260338861, 'approx_kl': -0.004533419851213694, 'clip_fraction': 0.125, 'grad_norm': 14.092793464660645}
2023-01-03 17:13:49.718 DEBUG: Taking gradient step
2023-01-03 17:13:51.635 DEBUG: Loss 2: {'policy_loss': 0.05273757427094433, 'entropy_loss': -0.03661393187940121, 'vf_loss': 0.02278226455284131, 'total_loss': 0.016123642391543125, 'approx_kl': -0.016451795701868832, 'clip_fraction': 0.2356770858168602, 'grad_norm': 10.82801342010498}
2023-01-03 17:13:53.488 DEBUG: Taking gradient step
2023-01-03 17:13:55.377 DEBUG: Loss 3: {'policy_loss': 0.07629866520854574, 'entropy_loss': -0.03525373339653015, 'vf_loss': 0.0213921909271827, 'total_loss': 0.041044931812015586, 'approx_kl': 0.025719458935782313, 'clip_fraction': 0.3880208358168602, 'grad_norm': 15.013126373291016}
2023-01-03 17:13:57.246 DEBUG: Taking gradient step
2023-01-03 17:13:59.186 DEBUG: Loss 4: {'policy_loss': 0.06184537446535324, 'entropy_loss': -0.039143661968410015, 'vf_loss': 0.021136807693142825, 'total_loss': 0.02270171249694322, 'approx_kl': 0.019157359842211008, 'clip_fraction': 0.3880208358168602, 'grad_norm': 11.399271011352539}
2023-01-03 17:14:01.065 DEBUG: Taking gradient step
2023-01-03 17:14:03.007 DEBUG: Loss 5: {'policy_loss': 0.044313752113798587, 'entropy_loss': -0.035635290667414665, 'vf_loss': 0.019783594919273655, 'total_loss': 0.008678461446383921, 'approx_kl': -0.011095486581325531, 'clip_fraction': 0.3658854216337204, 'grad_norm': 13.832246780395508}
2023-01-03 17:14:04.895 DEBUG: Taking gradient step
2023-01-03 17:14:06.826 DEBUG: Loss 6: {'policy_loss': 0.05203109444734604, 'entropy_loss': -0.03624812979251146, 'vf_loss': 0.020063356816387948, 'total_loss': 0.01578296465483458, 'approx_kl': -0.022496437653899193, 'clip_fraction': 0.3658854216337204, 'grad_norm': 16.162275314331055}
2023-01-03 17:14:08.711 DEBUG: Taking gradient step
2023-01-03 17:14:10.640 DEBUG: Loss 7: {'policy_loss': 0.10552554838310708, 'entropy_loss': -0.037077529821544886, 'vf_loss': 0.021416681204354727, 'total_loss': 0.0684480185615622, 'approx_kl': -0.027660964988172054, 'clip_fraction': 0.3776041716337204, 'grad_norm': 29.853622436523438}
2023-01-03 17:14:12.528 DEBUG: Taking gradient step
2023-01-03 17:14:14.457 DEBUG: Loss 8: {'policy_loss': 0.11525770378549188, 'entropy_loss': -0.03706464124843478, 'vf_loss': 0.02269267776083168, 'total_loss': 0.0781930625370571, 'approx_kl': 0.012685361783951521, 'clip_fraction': 0.3815104216337204, 'grad_norm': 15.616189956665039}
2023-01-03 17:14:16.341 DEBUG: Taking gradient step
2023-01-03 17:14:18.274 DEBUG: Loss 9: {'policy_loss': 0.10969301079262275, 'entropy_loss': -0.03706606663763523, 'vf_loss': 0.021179858154692963, 'total_loss': 0.07262694415498752, 'approx_kl': 0.014959163730964065, 'clip_fraction': 0.3828125, 'grad_norm': 22.233932495117188}
2023-01-03 17:14:20.158 DEBUG: Taking gradient step
2023-01-03 17:14:22.085 DEBUG: Loss 10: {'policy_loss': 0.02694983577205035, 'entropy_loss': -0.0365568557754159, 'vf_loss': 0.019352523551815253, 'total_loss': -0.009607020003365545, 'approx_kl': -0.027464581187814474, 'clip_fraction': 0.3697916716337204, 'grad_norm': 22.07019805908203}
2023-01-03 17:14:23.963 DEBUG: Taking gradient step
2023-01-03 17:14:25.895 DEBUG: Loss 11: {'policy_loss': 0.05850171640664028, 'entropy_loss': -0.03496462572365999, 'vf_loss': 0.020514780889479674, 'total_loss': 0.023537090682980287, 'approx_kl': -0.028298036195337772, 'clip_fraction': 0.4192708358168602, 'grad_norm': 18.291213989257812}
2023-01-03 17:14:27.872 DEBUG: Taking gradient step
2023-01-03 17:14:29.794 DEBUG: Loss 12: {'policy_loss': 0.0117596480531693, 'entropy_loss': -0.036015428602695465, 'vf_loss': 0.01877808150936621, 'total_loss': -0.024255780549526165, 'approx_kl': 0.0008199433796107769, 'clip_fraction': 0.4739583358168602, 'grad_norm': 13.384096145629883}
2023-01-03 17:14:31.683 DEBUG: Taking gradient step
2023-01-03 17:14:33.615 DEBUG: Loss 13: {'policy_loss': 0.11456881741107644, 'entropy_loss': -0.03551890142261982, 'vf_loss': 0.020770776554494184, 'total_loss': 0.07904991598845662, 'approx_kl': 0.007088416488841176, 'clip_fraction': 0.5104166716337204, 'grad_norm': 16.030488967895508}
2023-01-03 17:14:35.494 DEBUG: Taking gradient step
2023-01-03 17:14:37.445 DEBUG: Loss 14: {'policy_loss': 0.0741260626460084, 'entropy_loss': -0.03516995348036289, 'vf_loss': 0.01957337226419201, 'total_loss': 0.03895610916564552, 'approx_kl': -0.020174265606328845, 'clip_fraction': 0.5494791716337204, 'grad_norm': 14.391560554504395}
2023-01-03 17:14:37.446 INFO: Optimization: policy loss=0.074, vf loss=0.020, entropy loss=-0.035, total loss=0.039, num steps=15
2023-01-03 17:14:37.447 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 17:14:39.128 INFO: Evaluation rollout: return=0.596 (0.0), episode length=6.0
2023-01-03 17:14:39.129 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 17:14:39.132 INFO: Iteration: 97/137, steps: 20952
2023-01-03 17:14:52.749 DEBUG: Atoms are too close
2023-01-03 17:14:54.982 DEBUG: Atoms are too close
2023-01-03 17:14:56.607 DEBUG: Atoms are too close
2023-01-03 17:15:11.425 DEBUG: Atoms are too close
2023-01-03 17:15:27.163 DEBUG: Atoms are too close
2023-01-03 17:15:30.784 DEBUG: There is a single atom floating around
2023-01-03 17:15:31.356 DEBUG: Atoms are too close
2023-01-03 17:15:34.758 INFO: Training rollout: return=-2.816 (6.2), episode length=5.9
2023-01-03 17:15:34.760 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 17:15:34.762 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-20952_train.pkl
2023-01-03 17:15:36.663 DEBUG: Taking gradient step
2023-01-03 17:15:38.601 DEBUG: Loss 0: {'policy_loss': 0.013755067353402303, 'entropy_loss': -0.03282984159886837, 'vf_loss': 0.024888963741996332, 'total_loss': -0.019074774245466067, 'approx_kl': 1.200241968035698e-07, 'clip_fraction': 0.0, 'grad_norm': 16.515832901000977}
2023-01-03 17:15:40.494 DEBUG: Taking gradient step
2023-01-03 17:15:42.419 DEBUG: Loss 1: {'policy_loss': -0.0025232021667031326, 'entropy_loss': -0.03434186149388552, 'vf_loss': 0.025215333600533803, 'total_loss': -0.03686506366058864, 'approx_kl': -0.024888311745598912, 'clip_fraction': 0.1705729179084301, 'grad_norm': 17.275760650634766}
2023-01-03 17:15:44.290 DEBUG: Taking gradient step
2023-01-03 17:15:46.223 DEBUG: Loss 2: {'policy_loss': 0.09600525138451724, 'entropy_loss': -0.0322446096688509, 'vf_loss': 0.026615544834395658, 'total_loss': 0.06376064171566634, 'approx_kl': -0.02067966910544783, 'clip_fraction': 0.265625, 'grad_norm': 20.95730972290039}
2023-01-03 17:15:48.099 DEBUG: Taking gradient step
2023-01-03 17:15:50.040 DEBUG: Loss 3: {'policy_loss': 0.05993057009660109, 'entropy_loss': -0.03192408150061965, 'vf_loss': 0.025251489402058847, 'total_loss': 0.028006488595981444, 'approx_kl': -0.0297161724884063, 'clip_fraction': 0.33984375, 'grad_norm': 17.154335021972656}
2023-01-03 17:15:51.915 DEBUG: Taking gradient step
2023-01-03 17:15:53.848 DEBUG: Loss 4: {'policy_loss': 0.041116959762563424, 'entropy_loss': -0.03339479211717844, 'vf_loss': 0.02539681011407693, 'total_loss': 0.007722167645384987, 'approx_kl': 0.02352684922516346, 'clip_fraction': 0.3515625, 'grad_norm': 22.53799057006836}
2023-01-03 17:15:55.707 DEBUG: Taking gradient step
2023-01-03 17:15:57.590 DEBUG: Loss 5: {'policy_loss': 0.012567345174645476, 'entropy_loss': -0.03458441700786352, 'vf_loss': 0.02479168435412606, 'total_loss': -0.022017071833218046, 'approx_kl': 0.03195715835317969, 'clip_fraction': 0.4388020858168602, 'grad_norm': 12.388433456420898}
2023-01-03 17:15:59.435 DEBUG: Taking gradient step
2023-01-03 17:16:01.310 DEBUG: Loss 6: {'policy_loss': -0.012435374444037424, 'entropy_loss': -0.03342699632048607, 'vf_loss': 0.02343912049618752, 'total_loss': -0.04586237076452349, 'approx_kl': -0.017148726619780064, 'clip_fraction': 0.4088541716337204, 'grad_norm': 15.100369453430176}
2023-01-03 17:16:03.145 DEBUG: Taking gradient step
2023-01-03 17:16:05.007 DEBUG: Loss 7: {'policy_loss': -0.004316042531999742, 'entropy_loss': -0.034024748019874096, 'vf_loss': 0.024857743717527428, 'total_loss': -0.03834079055187383, 'approx_kl': 0.010787523351609707, 'clip_fraction': 0.46875, 'grad_norm': 12.117300033569336}
2023-01-03 17:16:06.826 DEBUG: Early stopping at step 8 for reaching max KL.
2023-01-03 17:16:06.826 INFO: Optimization: policy loss=-0.004, vf loss=0.025, entropy loss=-0.034, total loss=-0.038, num steps=8
2023-01-03 17:16:06.827 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 17:16:08.523 INFO: Evaluation rollout: return=0.596 (0.0), episode length=6.0
2023-01-03 17:16:08.524 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 17:16:08.527 INFO: Iteration: 98/137, steps: 21168
2023-01-03 17:16:20.583 DEBUG: There is a single atom floating around
2023-01-03 17:17:05.176 INFO: Training rollout: return=-0.322 (3.4), episode length=6.0
2023-01-03 17:17:05.177 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 17:17:05.180 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-21168_train.pkl
2023-01-03 17:17:07.081 DEBUG: Taking gradient step
2023-01-03 17:17:08.997 DEBUG: Loss 0: {'policy_loss': -0.016165714873942437, 'entropy_loss': -0.036713429260998964, 'vf_loss': 0.009734601375377301, 'total_loss': -0.052879144134941394, 'approx_kl': -3.240226398304458e-08, 'clip_fraction': 0.0, 'grad_norm': 15.417001724243164}
2023-01-03 17:17:10.865 DEBUG: Taking gradient step
2023-01-03 17:17:12.779 DEBUG: Loss 1: {'policy_loss': 0.028174565722924077, 'entropy_loss': -0.03577707940712571, 'vf_loss': 0.011077868636545606, 'total_loss': -0.007602513684201631, 'approx_kl': 0.0013992383610457182, 'clip_fraction': 0.2265625, 'grad_norm': 17.391864776611328}
2023-01-03 17:17:14.666 DEBUG: Taking gradient step
2023-01-03 17:17:16.580 DEBUG: Loss 2: {'policy_loss': -0.03633213819457347, 'entropy_loss': -0.032664642203599215, 'vf_loss': 0.009637684111549428, 'total_loss': -0.06899678039817268, 'approx_kl': 0.01956139225512743, 'clip_fraction': 0.3658854216337204, 'grad_norm': 10.206472396850586}
2023-01-03 17:17:18.478 DEBUG: Taking gradient step
2023-01-03 17:17:20.406 DEBUG: Loss 3: {'policy_loss': -0.004907752063393461, 'entropy_loss': -0.03466095682233572, 'vf_loss': 0.009428779632745559, 'total_loss': -0.03956870888572918, 'approx_kl': 0.01919986680150032, 'clip_fraction': 0.3528645858168602, 'grad_norm': 11.821447372436523}
2023-01-03 17:17:22.290 DEBUG: Taking gradient step
2023-01-03 17:17:24.213 DEBUG: Loss 4: {'policy_loss': -0.04594047140545805, 'entropy_loss': -0.034763616509735584, 'vf_loss': 0.008552236708091682, 'total_loss': -0.08070408791519364, 'approx_kl': -0.03205491416156292, 'clip_fraction': 0.4192708358168602, 'grad_norm': 5.59029483795166}
2023-01-03 17:17:26.101 DEBUG: Taking gradient step
2023-01-03 17:17:28.027 DEBUG: Loss 5: {'policy_loss': -0.047390121319948186, 'entropy_loss': -0.034026534762233496, 'vf_loss': 0.008029590452662475, 'total_loss': -0.08141665608218168, 'approx_kl': -0.02021400281228125, 'clip_fraction': 0.5247395932674408, 'grad_norm': 5.324131011962891}
2023-01-03 17:17:29.913 DEBUG: Taking gradient step
2023-01-03 17:17:31.838 DEBUG: Loss 6: {'policy_loss': -0.03615675845878652, 'entropy_loss': -0.03635593503713608, 'vf_loss': 0.007954155841996473, 'total_loss': -0.0725126934959226, 'approx_kl': 0.012639034233870916, 'clip_fraction': 0.5533854216337204, 'grad_norm': 4.465239524841309}
2023-01-03 17:17:33.739 DEBUG: Taking gradient step
2023-01-03 17:17:35.662 DEBUG: Loss 7: {'policy_loss': 0.017179264973530808, 'entropy_loss': -0.03447321709245443, 'vf_loss': 0.009537038709704248, 'total_loss': -0.01729395211892363, 'approx_kl': 0.0010612858459353447, 'clip_fraction': 0.5950520932674408, 'grad_norm': 7.8795294761657715}
2023-01-03 17:17:37.548 DEBUG: Taking gradient step
2023-01-03 17:17:39.481 DEBUG: Loss 8: {'policy_loss': 0.0018440816405995214, 'entropy_loss': -0.03503155242651701, 'vf_loss': 0.008139311018190109, 'total_loss': -0.03318747078591749, 'approx_kl': 0.005040615797042847, 'clip_fraction': 0.6080729216337204, 'grad_norm': 8.948991775512695}
2023-01-03 17:17:41.368 DEBUG: Taking gradient step
2023-01-03 17:17:43.294 DEBUG: Loss 9: {'policy_loss': -0.02210079193003589, 'entropy_loss': -0.036800515837967396, 'vf_loss': 0.0067386100976456875, 'total_loss': -0.05890130776800329, 'approx_kl': -0.013769921381026506, 'clip_fraction': 0.6119791716337204, 'grad_norm': 9.08493423461914}
2023-01-03 17:17:45.224 DEBUG: Taking gradient step
2023-01-03 17:17:47.177 DEBUG: Loss 10: {'policy_loss': -0.010625166119129063, 'entropy_loss': -0.03838568227365613, 'vf_loss': 0.006640196625291527, 'total_loss': -0.04901084839278519, 'approx_kl': -0.01950989756733179, 'clip_fraction': 0.7018229216337204, 'grad_norm': 11.144225120544434}
2023-01-03 17:17:49.124 DEBUG: Taking gradient step
2023-01-03 17:17:51.212 DEBUG: Loss 11: {'policy_loss': -0.01610647721220282, 'entropy_loss': -0.036821214482188225, 'vf_loss': 0.0066508369583179175, 'total_loss': -0.052927691694391044, 'approx_kl': -0.055966123938560486, 'clip_fraction': 0.65625, 'grad_norm': 12.652612686157227}
2023-01-03 17:17:53.183 DEBUG: Taking gradient step
2023-01-03 17:17:55.212 DEBUG: Loss 12: {'policy_loss': 0.025841085651926176, 'entropy_loss': -0.03672866057604551, 'vf_loss': 0.00821260277177255, 'total_loss': -0.010887574924119337, 'approx_kl': -0.0698740966618061, 'clip_fraction': 0.7174479216337204, 'grad_norm': 10.922500610351562}
2023-01-03 17:17:57.138 DEBUG: Taking gradient step
2023-01-03 17:17:59.145 DEBUG: Loss 13: {'policy_loss': 0.006007452987501763, 'entropy_loss': -0.03708758857101202, 'vf_loss': 0.008167527814974877, 'total_loss': -0.031080135583510256, 'approx_kl': -0.06741239526309073, 'clip_fraction': 0.640625, 'grad_norm': 8.752923965454102}
2023-01-03 17:18:01.504 DEBUG: Taking gradient step
2023-01-03 17:18:03.787 DEBUG: Loss 14: {'policy_loss': -0.01060946768283672, 'entropy_loss': -0.03743315301835537, 'vf_loss': 0.0071533384802086345, 'total_loss': -0.04804262070119209, 'approx_kl': -0.013612773269414902, 'clip_fraction': 0.6171875, 'grad_norm': 7.624976634979248}
2023-01-03 17:18:03.788 INFO: Optimization: policy loss=-0.011, vf loss=0.007, entropy loss=-0.037, total loss=-0.048, num steps=15
2023-01-03 17:18:03.789 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 17:18:05.482 INFO: Evaluation rollout: return=0.593 (0.0), episode length=6.0
2023-01-03 17:18:05.483 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 17:18:05.486 INFO: Iteration: 99/137, steps: 21384
2023-01-03 17:18:15.801 DEBUG: There is a single atom floating around
2023-01-03 17:18:17.848 DEBUG: Atoms are too close
2023-01-03 17:18:55.916 DEBUG: Atoms are too close
2023-01-03 17:18:57.732 DEBUG: There is a single atom floating around
2023-01-03 17:19:00.865 INFO: Training rollout: return=-1.747 (5.5), episode length=5.9
2023-01-03 17:19:00.867 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 17:19:00.870 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-21384_train.pkl
2023-01-03 17:19:02.722 DEBUG: Taking gradient step
2023-01-03 17:19:04.595 DEBUG: Loss 0: {'policy_loss': 0.04124816623771873, 'entropy_loss': -0.040558901615440845, 'vf_loss': 0.019162219357890132, 'total_loss': 0.0006892646222778839, 'approx_kl': 7.469981966323758e-09, 'clip_fraction': 0.0, 'grad_norm': 17.682409286499023}
2023-01-03 17:19:06.431 DEBUG: Taking gradient step
2023-01-03 17:19:08.307 DEBUG: Loss 1: {'policy_loss': -0.03686036134704019, 'entropy_loss': -0.03984405659139156, 'vf_loss': 0.015014848836553107, 'total_loss': -0.07670441793843175, 'approx_kl': -0.009360313648357987, 'clip_fraction': 0.18359375, 'grad_norm': 11.202595710754395}
2023-01-03 17:19:10.152 DEBUG: Taking gradient step
2023-01-03 17:19:12.015 DEBUG: Loss 2: {'policy_loss': -0.037145273045306654, 'entropy_loss': -0.041117873042821884, 'vf_loss': 0.014478193997894838, 'total_loss': -0.07826314608812854, 'approx_kl': -0.031199425226077437, 'clip_fraction': 0.359375, 'grad_norm': 10.858074188232422}
2023-01-03 17:19:13.882 DEBUG: Taking gradient step
2023-01-03 17:19:15.774 DEBUG: Loss 3: {'policy_loss': -0.023888288092830414, 'entropy_loss': -0.04180875327438116, 'vf_loss': 0.015379215191873649, 'total_loss': -0.06569704136721158, 'approx_kl': -0.022819063626229763, 'clip_fraction': 0.5, 'grad_norm': 10.780784606933594}
2023-01-03 17:19:17.602 DEBUG: Taking gradient step
2023-01-03 17:19:19.524 DEBUG: Loss 4: {'policy_loss': -0.04411363838733594, 'entropy_loss': -0.04154886677861214, 'vf_loss': 0.014674069170434631, 'total_loss': -0.08566250516594806, 'approx_kl': -0.031751698814332485, 'clip_fraction': 0.5234375, 'grad_norm': 8.667951583862305}
2023-01-03 17:19:21.392 DEBUG: Taking gradient step
2023-01-03 17:19:23.301 DEBUG: Loss 5: {'policy_loss': -0.015605607144648943, 'entropy_loss': -0.04049442056566477, 'vf_loss': 0.016231478433937307, 'total_loss': -0.05610002771031371, 'approx_kl': -0.03153943200595677, 'clip_fraction': 0.5338541716337204, 'grad_norm': 7.187359809875488}
2023-01-03 17:19:25.204 DEBUG: Taking gradient step
2023-01-03 17:19:27.132 DEBUG: Loss 6: {'policy_loss': 0.018595031984616234, 'entropy_loss': -0.0410125395283103, 'vf_loss': 0.01882445054313466, 'total_loss': -0.022417507543694065, 'approx_kl': -0.0233511570841074, 'clip_fraction': 0.5455729216337204, 'grad_norm': 8.234579086303711}
2023-01-03 17:19:29.212 DEBUG: Taking gradient step
2023-01-03 17:19:31.105 DEBUG: Loss 7: {'policy_loss': -0.025907272779018366, 'entropy_loss': -0.040970953181385994, 'vf_loss': 0.017506357635746612, 'total_loss': -0.06687822596040435, 'approx_kl': -0.019557318184524775, 'clip_fraction': 0.5, 'grad_norm': 7.415147304534912}
2023-01-03 17:19:32.949 DEBUG: Taking gradient step
2023-01-03 17:19:34.824 DEBUG: Loss 8: {'policy_loss': 0.019660654929465685, 'entropy_loss': -0.03892028424888849, 'vf_loss': 0.019516295623940336, 'total_loss': -0.019259629319422794, 'approx_kl': -0.04047817084938288, 'clip_fraction': 0.4518229216337204, 'grad_norm': 14.266462326049805}
2023-01-03 17:19:36.651 DEBUG: Taking gradient step
2023-01-03 17:19:38.624 DEBUG: Loss 9: {'policy_loss': 0.0031939323888025145, 'entropy_loss': -0.03892713552340865, 'vf_loss': 0.01760573136944568, 'total_loss': -0.03573320313460614, 'approx_kl': -0.043708916287869215, 'clip_fraction': 0.5013020932674408, 'grad_norm': 12.711200714111328}
2023-01-03 17:19:40.461 DEBUG: Taking gradient step
2023-01-03 17:19:42.342 DEBUG: Loss 10: {'policy_loss': -0.011406417352182585, 'entropy_loss': -0.03899659030139446, 'vf_loss': 0.018286671809347572, 'total_loss': -0.050403007653577046, 'approx_kl': -0.055451452266424894, 'clip_fraction': 0.5, 'grad_norm': 13.358784675598145}
2023-01-03 17:19:44.180 DEBUG: Taking gradient step
2023-01-03 17:19:46.051 DEBUG: Loss 11: {'policy_loss': 0.008569962142997677, 'entropy_loss': -0.03987336531281471, 'vf_loss': 0.01826872924192908, 'total_loss': -0.031303403169817036, 'approx_kl': -0.05638420023024082, 'clip_fraction': 0.5533854216337204, 'grad_norm': 10.274396896362305}
2023-01-03 17:19:47.879 DEBUG: Taking gradient step
2023-01-03 17:19:49.751 DEBUG: Loss 12: {'policy_loss': -0.016856820441082623, 'entropy_loss': -0.03987838886678219, 'vf_loss': 0.01690832745145134, 'total_loss': -0.05673520930786481, 'approx_kl': -0.047738008899614215, 'clip_fraction': 0.55078125, 'grad_norm': 8.961932182312012}
2023-01-03 17:19:51.597 DEBUG: Taking gradient step
2023-01-03 17:19:53.463 DEBUG: Loss 13: {'policy_loss': -0.02479223198319541, 'entropy_loss': -0.038577788043767214, 'vf_loss': 0.016955898255376002, 'total_loss': -0.06337002002696263, 'approx_kl': -0.06839299481362104, 'clip_fraction': 0.5260416716337204, 'grad_norm': 8.365161895751953}
2023-01-03 17:19:55.296 DEBUG: Taking gradient step
2023-01-03 17:19:57.161 DEBUG: Loss 14: {'policy_loss': -0.05992026478233992, 'entropy_loss': -0.04083624482154846, 'vf_loss': 0.015273835062893001, 'total_loss': -0.10075650960388838, 'approx_kl': -0.0686334390193224, 'clip_fraction': 0.4713541716337204, 'grad_norm': 9.284467697143555}
2023-01-03 17:19:57.161 INFO: Optimization: policy loss=-0.060, vf loss=0.015, entropy loss=-0.041, total loss=-0.101, num steps=15
2023-01-03 17:19:57.162 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 17:19:58.824 INFO: Evaluation rollout: return=0.530 (0.0), episode length=6.0
2023-01-03 17:19:58.825 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 17:19:58.828 INFO: Iteration: 100/137, steps: 21600
2023-01-03 17:20:52.809 DEBUG: Atoms are too close
2023-01-03 17:20:55.510 DEBUG: Atoms are too close
2023-01-03 17:20:55.887 INFO: Training rollout: return=-0.676 (3.7), episode length=6.0
2023-01-03 17:20:55.888 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 17:20:55.892 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-21600_train.pkl
2023-01-03 17:20:57.872 DEBUG: Taking gradient step
2023-01-03 17:20:59.867 DEBUG: Loss 0: {'policy_loss': -0.008769595781429659, 'entropy_loss': -0.04001452960073948, 'vf_loss': 0.010576165944169299, 'total_loss': -0.04878412538216914, 'approx_kl': -4.237517714500427e-08, 'clip_fraction': 0.0, 'grad_norm': 9.105093002319336}
2023-01-03 17:21:01.793 DEBUG: Taking gradient step
2023-01-03 17:21:03.906 DEBUG: Loss 1: {'policy_loss': 0.009112175176242819, 'entropy_loss': -0.03913984354585409, 'vf_loss': 0.011661018727105742, 'total_loss': -0.030027668369611273, 'approx_kl': -0.018611874897032976, 'clip_fraction': 0.1015625, 'grad_norm': 9.03272819519043}
2023-01-03 17:21:05.990 DEBUG: Taking gradient step
2023-01-03 17:21:08.461 DEBUG: Loss 2: {'policy_loss': -0.02221815850663706, 'entropy_loss': -0.038688139989972115, 'vf_loss': 0.010312736804495876, 'total_loss': -0.060906298496609175, 'approx_kl': -0.036094783805310726, 'clip_fraction': 0.3307291716337204, 'grad_norm': 7.5356245040893555}
2023-01-03 17:21:10.738 DEBUG: Taking gradient step
2023-01-03 17:21:13.080 DEBUG: Loss 3: {'policy_loss': 0.03962501340917973, 'entropy_loss': -0.04158100113272667, 'vf_loss': 0.012814746719063689, 'total_loss': -0.001955987723546937, 'approx_kl': -0.021449499297887087, 'clip_fraction': 0.4010416716337204, 'grad_norm': 9.367305755615234}
2023-01-03 17:21:15.334 DEBUG: Taking gradient step
2023-01-03 17:21:17.635 DEBUG: Loss 4: {'policy_loss': -0.013977985325027798, 'entropy_loss': -0.03836884908378124, 'vf_loss': 0.010194536389566616, 'total_loss': -0.052346834408809044, 'approx_kl': -0.03797753434628248, 'clip_fraction': 0.34375, 'grad_norm': 17.753263473510742}
2023-01-03 17:21:19.882 DEBUG: Taking gradient step
2023-01-03 17:21:22.182 DEBUG: Loss 5: {'policy_loss': 0.018154236745482936, 'entropy_loss': -0.03960608132183552, 'vf_loss': 0.0120897276741168, 'total_loss': -0.02145184457635258, 'approx_kl': -0.04810844827443361, 'clip_fraction': 0.3645833358168602, 'grad_norm': 9.38166332244873}
2023-01-03 17:21:24.417 DEBUG: Taking gradient step
2023-01-03 17:21:26.795 DEBUG: Loss 6: {'policy_loss': -0.016427521844482484, 'entropy_loss': -0.0402827262878418, 'vf_loss': 0.00989116909170744, 'total_loss': -0.05671024813232428, 'approx_kl': -0.05367887672036886, 'clip_fraction': 0.3880208358168602, 'grad_norm': 11.49486255645752}
2023-01-03 17:21:29.024 DEBUG: Taking gradient step
2023-01-03 17:21:31.304 DEBUG: Loss 7: {'policy_loss': -0.00895800828543123, 'entropy_loss': -0.038399096578359604, 'vf_loss': 0.01025002182966035, 'total_loss': -0.047357104863790835, 'approx_kl': -0.037399121560156345, 'clip_fraction': 0.3463541716337204, 'grad_norm': 8.231822967529297}
2023-01-03 17:21:33.530 DEBUG: Taking gradient step
2023-01-03 17:21:35.794 DEBUG: Loss 8: {'policy_loss': -0.012528358405316239, 'entropy_loss': -0.03769468376412988, 'vf_loss': 0.010263185445217073, 'total_loss': -0.05022304216944612, 'approx_kl': -0.04470977280288935, 'clip_fraction': 0.328125, 'grad_norm': 14.864188194274902}
2023-01-03 17:21:38.016 DEBUG: Taking gradient step
2023-01-03 17:21:40.295 DEBUG: Loss 9: {'policy_loss': -0.011610513736754879, 'entropy_loss': -0.039407068863511086, 'vf_loss': 0.010621059383366112, 'total_loss': -0.05101758260026597, 'approx_kl': -0.07183625549077988, 'clip_fraction': 0.3190104216337204, 'grad_norm': 7.730021953582764}
2023-01-03 17:21:42.528 DEBUG: Taking gradient step
2023-01-03 17:21:44.801 DEBUG: Loss 10: {'policy_loss': -0.0384992286954649, 'entropy_loss': -0.038217103108763695, 'vf_loss': 0.009456302023314182, 'total_loss': -0.0767163318042286, 'approx_kl': -0.06618392001837492, 'clip_fraction': 0.4140625, 'grad_norm': 6.999159812927246}
2023-01-03 17:21:47.014 DEBUG: Taking gradient step
2023-01-03 17:21:49.288 DEBUG: Loss 11: {'policy_loss': -0.027007373458574173, 'entropy_loss': -0.0389676196500659, 'vf_loss': 0.009574910138382842, 'total_loss': -0.06597499310864008, 'approx_kl': -0.05998765118420124, 'clip_fraction': 0.4322916716337204, 'grad_norm': 5.635635852813721}
2023-01-03 17:21:51.507 DEBUG: Taking gradient step
2023-01-03 17:21:53.782 DEBUG: Loss 12: {'policy_loss': 0.015727518501764143, 'entropy_loss': -0.03862892650067806, 'vf_loss': 0.01097073906107939, 'total_loss': -0.022901407998913915, 'approx_kl': -0.05811189580708742, 'clip_fraction': 0.4231770858168602, 'grad_norm': 5.993926048278809}
2023-01-03 17:21:55.991 DEBUG: Taking gradient step
2023-01-03 17:21:58.259 DEBUG: Loss 13: {'policy_loss': -0.0539063810537867, 'entropy_loss': -0.03740823036059737, 'vf_loss': 0.009103378887915597, 'total_loss': -0.09131461141438407, 'approx_kl': -0.06585890334099531, 'clip_fraction': 0.44921875, 'grad_norm': 4.883921146392822}
2023-01-03 17:22:00.483 DEBUG: Taking gradient step
2023-01-03 17:22:02.758 DEBUG: Loss 14: {'policy_loss': 0.0029087081217315756, 'entropy_loss': -0.037656283006072044, 'vf_loss': 0.011229628500517851, 'total_loss': -0.034747574884340465, 'approx_kl': -0.07891977671533823, 'clip_fraction': 0.4596354216337204, 'grad_norm': 6.5120344161987305}
2023-01-03 17:22:02.759 INFO: Optimization: policy loss=0.003, vf loss=0.011, entropy loss=-0.038, total loss=-0.035, num steps=15
2023-01-03 17:22:02.759 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 17:22:04.467 INFO: Evaluation rollout: return=0.504 (0.0), episode length=6.0
2023-01-03 17:22:04.469 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 17:22:04.473 DEBUG: Deleting old model: runs/CH3NO_dna/models/CH3NO_dna_run-1_steps-19656.model
2023-01-03 17:22:04.479 DEBUG: Saving model: runs/CH3NO_dna/models/CH3NO_dna_run-1_steps-21816.model
2023-01-03 17:22:04.525 INFO: Iteration: 101/137, steps: 21816
2023-01-03 17:22:17.095 DEBUG: Atoms are too close
2023-01-03 17:22:54.870 DEBUG: There is a single atom floating around
2023-01-03 17:23:01.225 INFO: Training rollout: return=-1.170 (4.6), episode length=5.9
2023-01-03 17:23:01.227 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 17:23:01.230 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-21816_train.pkl
2023-01-03 17:23:03.104 DEBUG: Taking gradient step
2023-01-03 17:23:04.998 DEBUG: Loss 0: {'policy_loss': 0.03267828075768069, 'entropy_loss': -0.03466983325779438, 'vf_loss': 0.014599047633906842, 'total_loss': -0.001991552500113687, 'approx_kl': 1.684141892610569e-08, 'clip_fraction': 0.0, 'grad_norm': 16.269594192504883}
2023-01-03 17:23:06.877 DEBUG: Taking gradient step
2023-01-03 17:23:08.835 DEBUG: Loss 1: {'policy_loss': -0.013880584027785832, 'entropy_loss': -0.03473529405891895, 'vf_loss': 0.012589971573634224, 'total_loss': -0.048615878086704784, 'approx_kl': 0.0037983714137226343, 'clip_fraction': 0.10546875, 'grad_norm': 18.252620697021484}
2023-01-03 17:23:10.744 DEBUG: Taking gradient step
2023-01-03 17:23:12.635 DEBUG: Loss 2: {'policy_loss': -0.03864540795601029, 'entropy_loss': -0.034761813934892416, 'vf_loss': 0.012001782074810972, 'total_loss': -0.07340722189090271, 'approx_kl': -0.007727538701146841, 'clip_fraction': 0.2669270858168602, 'grad_norm': 11.154746055603027}
2023-01-03 17:23:14.492 DEBUG: Taking gradient step
2023-01-03 17:23:16.395 DEBUG: Loss 3: {'policy_loss': -0.004080532109240345, 'entropy_loss': -0.03497999254614115, 'vf_loss': 0.01252972644477154, 'total_loss': -0.0390605246553815, 'approx_kl': -0.037780943559482694, 'clip_fraction': 0.2916666716337204, 'grad_norm': 20.78923225402832}
2023-01-03 17:23:18.372 DEBUG: Taking gradient step
2023-01-03 17:23:20.295 DEBUG: Loss 4: {'policy_loss': -0.026428741265297748, 'entropy_loss': -0.037316977977752686, 'vf_loss': 0.011808688036117974, 'total_loss': -0.06374571924305043, 'approx_kl': -0.035457937978208065, 'clip_fraction': 0.2890625, 'grad_norm': 14.357190132141113}
2023-01-03 17:23:22.163 DEBUG: Taking gradient step
2023-01-03 17:23:24.076 DEBUG: Loss 5: {'policy_loss': 0.038725778232340524, 'entropy_loss': -0.03630081843584776, 'vf_loss': 0.013894368135033718, 'total_loss': 0.002424959796492765, 'approx_kl': -0.02939098421484232, 'clip_fraction': 0.31640625, 'grad_norm': 19.79538345336914}
2023-01-03 17:23:25.932 DEBUG: Taking gradient step
2023-01-03 17:23:27.839 DEBUG: Loss 6: {'policy_loss': -0.04585481434071102, 'entropy_loss': -0.03685566131025553, 'vf_loss': 0.011776085423732999, 'total_loss': -0.08271047565096655, 'approx_kl': -0.027233873959630728, 'clip_fraction': 0.3033854179084301, 'grad_norm': 13.248129844665527}
2023-01-03 17:23:29.686 DEBUG: Taking gradient step
2023-01-03 17:23:31.584 DEBUG: Loss 7: {'policy_loss': -0.04582635694614004, 'entropy_loss': -0.03825783729553223, 'vf_loss': 0.011798313486085505, 'total_loss': -0.08408419424167227, 'approx_kl': -0.052132171113044024, 'clip_fraction': 0.4283854216337204, 'grad_norm': 12.455820083618164}
2023-01-03 17:23:33.443 DEBUG: Taking gradient step
2023-01-03 17:23:35.330 DEBUG: Loss 8: {'policy_loss': -0.012643301659372547, 'entropy_loss': -0.03784968703985214, 'vf_loss': 0.014327169894435728, 'total_loss': -0.05049298869922468, 'approx_kl': -0.05913181742653251, 'clip_fraction': 0.4505208358168602, 'grad_norm': 11.050390243530273}
2023-01-03 17:23:37.181 DEBUG: Taking gradient step
2023-01-03 17:23:39.075 DEBUG: Loss 9: {'policy_loss': -0.03621388782157939, 'entropy_loss': -0.03733473177999258, 'vf_loss': 0.012700459023301355, 'total_loss': -0.07354861960157197, 'approx_kl': -0.0473068174906075, 'clip_fraction': 0.4518229216337204, 'grad_norm': 10.90228271484375}
2023-01-03 17:23:40.920 DEBUG: Taking gradient step
2023-01-03 17:23:42.813 DEBUG: Loss 10: {'policy_loss': -0.027329274846586215, 'entropy_loss': -0.03691957052797079, 'vf_loss': 0.01351451787720272, 'total_loss': -0.06424884537455701, 'approx_kl': -0.05038253287784755, 'clip_fraction': 0.38671875, 'grad_norm': 9.711158752441406}
2023-01-03 17:23:44.654 DEBUG: Taking gradient step
2023-01-03 17:23:46.546 DEBUG: Loss 11: {'policy_loss': -0.04697522714859738, 'entropy_loss': -0.03744756709784269, 'vf_loss': 0.01229140873406644, 'total_loss': -0.08442279424644007, 'approx_kl': -0.04262742958962917, 'clip_fraction': 0.4075520858168602, 'grad_norm': 11.287803649902344}
2023-01-03 17:23:48.384 DEBUG: Taking gradient step
2023-01-03 17:23:50.276 DEBUG: Loss 12: {'policy_loss': 0.0031174348022870307, 'entropy_loss': -0.037482816725969315, 'vf_loss': 0.01549215175830157, 'total_loss': -0.034365381923682284, 'approx_kl': -0.05233033373951912, 'clip_fraction': 0.3971354216337204, 'grad_norm': 12.918477058410645}
2023-01-03 17:23:52.130 DEBUG: Taking gradient step
2023-01-03 17:23:54.027 DEBUG: Loss 13: {'policy_loss': -0.0036809291741556685, 'entropy_loss': -0.03804021514952183, 'vf_loss': 0.014158599071209296, 'total_loss': -0.04172114432367749, 'approx_kl': -0.046105076267849654, 'clip_fraction': 0.4127604216337204, 'grad_norm': 13.648652076721191}
2023-01-03 17:23:55.869 DEBUG: Taking gradient step
2023-01-03 17:23:57.756 DEBUG: Loss 14: {'policy_loss': -0.06391220901203475, 'entropy_loss': -0.03677710145711899, 'vf_loss': 0.012127217577464404, 'total_loss': -0.10068931046915375, 'approx_kl': -0.06429605605080724, 'clip_fraction': 0.4192708358168602, 'grad_norm': 9.289301872253418}
2023-01-03 17:23:57.756 INFO: Optimization: policy loss=-0.064, vf loss=0.012, entropy loss=-0.037, total loss=-0.101, num steps=15
2023-01-03 17:23:57.757 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 17:23:59.429 INFO: Evaluation rollout: return=0.505 (0.0), episode length=6.0
2023-01-03 17:23:59.430 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 17:23:59.433 INFO: Iteration: 102/137, steps: 22032
2023-01-03 17:24:06.533 DEBUG: Atoms are too close
2023-01-03 17:24:11.283 DEBUG: Atoms are too close
2023-01-03 17:24:55.271 INFO: Training rollout: return=-0.565 (4.4), episode length=5.9
2023-01-03 17:24:55.273 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 17:24:55.275 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-22032_train.pkl
2023-01-03 17:24:57.136 DEBUG: Taking gradient step
2023-01-03 17:24:59.020 DEBUG: Loss 0: {'policy_loss': 0.020231343249222822, 'entropy_loss': -0.03603588044643402, 'vf_loss': 0.007775767683075415, 'total_loss': -0.0158045371972112, 'approx_kl': -1.5133991837501526e-08, 'clip_fraction': 0.0, 'grad_norm': 17.105152130126953}
2023-01-03 17:25:00.866 DEBUG: Taking gradient step
2023-01-03 17:25:02.835 DEBUG: Loss 1: {'policy_loss': -0.040161606799024405, 'entropy_loss': -0.036065819673240185, 'vf_loss': 0.006262655455838695, 'total_loss': -0.07622742647226459, 'approx_kl': -0.01242085499688983, 'clip_fraction': 0.037760416977107525, 'grad_norm': 15.127755165100098}
2023-01-03 17:25:04.679 DEBUG: Taking gradient step
2023-01-03 17:25:06.564 DEBUG: Loss 2: {'policy_loss': -0.01736661097283193, 'entropy_loss': -0.03760627983137965, 'vf_loss': 0.006646794818101909, 'total_loss': -0.05497289080421158, 'approx_kl': -0.03292766585946083, 'clip_fraction': 0.1822916679084301, 'grad_norm': 15.50820255279541}
2023-01-03 17:25:08.416 DEBUG: Taking gradient step
2023-01-03 17:25:10.303 DEBUG: Loss 3: {'policy_loss': 0.02773574574771992, 'entropy_loss': -0.03444910841062665, 'vf_loss': 0.007351794563229179, 'total_loss': -0.00671336266290673, 'approx_kl': -0.05170334596186876, 'clip_fraction': 0.27734375, 'grad_norm': 18.52364730834961}
2023-01-03 17:25:12.148 DEBUG: Taking gradient step
2023-01-03 17:25:14.043 DEBUG: Loss 4: {'policy_loss': 0.09362114078360118, 'entropy_loss': -0.03513256274163723, 'vf_loss': 0.008925590185196498, 'total_loss': 0.058488578041963946, 'approx_kl': -0.05407183291390538, 'clip_fraction': 0.3489583358168602, 'grad_norm': 31.38918113708496}
2023-01-03 17:25:15.900 DEBUG: Taking gradient step
2023-01-03 17:25:17.785 DEBUG: Loss 5: {'policy_loss': 0.03156056548244962, 'entropy_loss': -0.03500958392396569, 'vf_loss': 0.006008879011414248, 'total_loss': -0.0034490184415160788, 'approx_kl': -0.04925000946968794, 'clip_fraction': 0.37890625, 'grad_norm': 26.46675682067871}
2023-01-03 17:25:19.622 DEBUG: Taking gradient step
2023-01-03 17:25:21.513 DEBUG: Loss 6: {'policy_loss': 0.17045397209884697, 'entropy_loss': -0.03453878778964281, 'vf_loss': 0.007884635259676497, 'total_loss': 0.13591518430920416, 'approx_kl': -0.07406548503786325, 'clip_fraction': 0.3411458358168602, 'grad_norm': 62.1924934387207}
2023-01-03 17:25:23.370 DEBUG: Taking gradient step
2023-01-03 17:25:25.266 DEBUG: Loss 7: {'policy_loss': 0.018274532580169978, 'entropy_loss': -0.03481991868466139, 'vf_loss': 0.005753014914765551, 'total_loss': -0.01654538610449141, 'approx_kl': -0.07848887331783772, 'clip_fraction': 0.3255208358168602, 'grad_norm': 26.628061294555664}
2023-01-03 17:25:27.119 DEBUG: Taking gradient step
2023-01-03 17:25:29.006 DEBUG: Loss 8: {'policy_loss': 0.009403987976686401, 'entropy_loss': -0.03446868807077408, 'vf_loss': 0.005631975681421656, 'total_loss': -0.025064700094087677, 'approx_kl': -0.04964298754930496, 'clip_fraction': 0.2981770858168602, 'grad_norm': 26.061779022216797}
2023-01-03 17:25:30.847 DEBUG: Taking gradient step
2023-01-03 17:25:32.735 DEBUG: Loss 9: {'policy_loss': 0.07467116933156585, 'entropy_loss': -0.035286955535411835, 'vf_loss': 0.007225639799660073, 'total_loss': 0.03938421379615402, 'approx_kl': -0.062140585854649544, 'clip_fraction': 0.3229166716337204, 'grad_norm': 34.138282775878906}
2023-01-03 17:25:34.573 DEBUG: Taking gradient step
2023-01-03 17:25:36.461 DEBUG: Loss 10: {'policy_loss': 0.05871199994077039, 'entropy_loss': -0.03375236922875047, 'vf_loss': 0.005454751844560565, 'total_loss': 0.024959630712019922, 'approx_kl': -0.08210585685446858, 'clip_fraction': 0.37109375, 'grad_norm': 29.761228561401367}
2023-01-03 17:25:38.299 DEBUG: Taking gradient step
2023-01-03 17:25:40.184 DEBUG: Loss 11: {'policy_loss': 0.12935284235001057, 'entropy_loss': -0.0350750763900578, 'vf_loss': 0.007563177070685689, 'total_loss': 0.09427776595995277, 'approx_kl': -0.05944514274597168, 'clip_fraction': 0.3489583358168602, 'grad_norm': 35.16641616821289}
2023-01-03 17:25:42.013 DEBUG: Taking gradient step
2023-01-03 17:25:43.880 DEBUG: Loss 12: {'policy_loss': 0.14527184175886482, 'entropy_loss': -0.034869782626628876, 'vf_loss': 0.008149189844837161, 'total_loss': 0.11040205913223596, 'approx_kl': -0.054306835401803255, 'clip_fraction': 0.3541666716337204, 'grad_norm': 41.473453521728516}
2023-01-03 17:25:45.707 DEBUG: Taking gradient step
2023-01-03 17:25:47.590 DEBUG: Loss 13: {'policy_loss': 0.028056397899148475, 'entropy_loss': -0.03399568423628807, 'vf_loss': 0.005623029234894324, 'total_loss': -0.005939286337139596, 'approx_kl': -0.0651395246386528, 'clip_fraction': 0.4283854216337204, 'grad_norm': 28.569995880126953}
2023-01-03 17:25:49.426 DEBUG: Taking gradient step
2023-01-03 17:25:51.381 DEBUG: Loss 14: {'policy_loss': 0.04061945646913251, 'entropy_loss': -0.032130942679941654, 'vf_loss': 0.006412424759492627, 'total_loss': 0.008488513789190855, 'approx_kl': -0.06276119593530893, 'clip_fraction': 0.48046875, 'grad_norm': 26.897443771362305}
2023-01-03 17:25:51.381 INFO: Optimization: policy loss=0.041, vf loss=0.006, entropy loss=-0.032, total loss=0.008, num steps=15
2023-01-03 17:25:51.382 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 17:25:53.100 INFO: Evaluation rollout: return=0.500 (0.0), episode length=6.0
2023-01-03 17:25:53.101 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 17:25:53.104 INFO: Iteration: 103/137, steps: 22248
2023-01-03 17:26:07.396 DEBUG: Atoms are too close
2023-01-03 17:26:25.933 DEBUG: Atoms are too close
2023-01-03 17:26:42.958 DEBUG: Atoms are too close
2023-01-03 17:26:43.802 DEBUG: There is a single atom floating around
2023-01-03 17:26:48.452 INFO: Training rollout: return=-1.630 (5.3), episode length=5.9
2023-01-03 17:26:48.454 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 17:26:48.457 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-22248_train.pkl
2023-01-03 17:26:50.297 DEBUG: Taking gradient step
2023-01-03 17:26:52.178 DEBUG: Loss 0: {'policy_loss': 0.02942373211160302, 'entropy_loss': -0.03337916173040867, 'vf_loss': 0.019101037351652098, 'total_loss': -0.003955429618805649, 'approx_kl': -1.008932848378663e-08, 'clip_fraction': 0.0, 'grad_norm': 16.48785400390625}
2023-01-03 17:26:54.017 DEBUG: Taking gradient step
2023-01-03 17:26:55.893 DEBUG: Loss 1: {'policy_loss': -0.006610939485781319, 'entropy_loss': -0.03256190940737724, 'vf_loss': 0.017532354377347868, 'total_loss': -0.039172848893158564, 'approx_kl': -0.00012934603728353977, 'clip_fraction': 0.265625, 'grad_norm': 8.83165454864502}
2023-01-03 17:26:57.736 DEBUG: Taking gradient step
2023-01-03 17:26:59.618 DEBUG: Loss 2: {'policy_loss': -0.048949834625597016, 'entropy_loss': -0.0315464586019516, 'vf_loss': 0.015492420056421418, 'total_loss': -0.08049629322754862, 'approx_kl': 0.015241933986544609, 'clip_fraction': 0.3736979216337204, 'grad_norm': 7.3316144943237305}
2023-01-03 17:27:01.437 DEBUG: Taking gradient step
2023-01-03 17:27:03.309 DEBUG: Loss 3: {'policy_loss': -0.0039845648141128495, 'entropy_loss': -0.03150914376601577, 'vf_loss': 0.018276584925151405, 'total_loss': -0.03549370858012862, 'approx_kl': -0.005423865281045437, 'clip_fraction': 0.40625, 'grad_norm': 10.457265853881836}
2023-01-03 17:27:05.136 DEBUG: Taking gradient step
2023-01-03 17:27:07.009 DEBUG: Loss 4: {'policy_loss': -0.0804936144546971, 'entropy_loss': -0.03131618443876505, 'vf_loss': 0.014530969499260006, 'total_loss': -0.11180979889346217, 'approx_kl': 0.002637474797666073, 'clip_fraction': 0.421875, 'grad_norm': 9.304792404174805}
2023-01-03 17:27:08.847 DEBUG: Taking gradient step
2023-01-03 17:27:10.717 DEBUG: Loss 5: {'policy_loss': -0.031010202925420574, 'entropy_loss': -0.030640828423202038, 'vf_loss': 0.016637707477450685, 'total_loss': -0.061651031348622626, 'approx_kl': 0.0054817472118884325, 'clip_fraction': 0.35546875, 'grad_norm': 14.151374816894531}
2023-01-03 17:27:12.553 DEBUG: Taking gradient step
2023-01-03 17:27:14.427 DEBUG: Loss 6: {'policy_loss': -0.02095658410118609, 'entropy_loss': -0.03193922247737646, 'vf_loss': 0.01698333392622155, 'total_loss': -0.05289580657856255, 'approx_kl': 0.0007099779322743416, 'clip_fraction': 0.375, 'grad_norm': 8.005433082580566}
2023-01-03 17:27:16.254 DEBUG: Taking gradient step
2023-01-03 17:27:18.131 DEBUG: Loss 7: {'policy_loss': -0.04208810167401388, 'entropy_loss': -0.031389142852276564, 'vf_loss': 0.015555773779308798, 'total_loss': -0.07347724452629045, 'approx_kl': -0.03262165142223239, 'clip_fraction': 0.4166666716337204, 'grad_norm': 9.343714714050293}
2023-01-03 17:27:19.963 DEBUG: Taking gradient step
2023-01-03 17:27:21.834 DEBUG: Loss 8: {'policy_loss': -0.021941106873798043, 'entropy_loss': -0.03333917399868369, 'vf_loss': 0.016159400212696715, 'total_loss': -0.055280280872481734, 'approx_kl': -0.03436500485986471, 'clip_fraction': 0.37109375, 'grad_norm': 9.19898509979248}
2023-01-03 17:27:23.684 DEBUG: Taking gradient step
2023-01-03 17:27:25.556 DEBUG: Loss 9: {'policy_loss': -0.028263806984910128, 'entropy_loss': -0.03157091839239001, 'vf_loss': 0.015851668704833326, 'total_loss': -0.05983472537730014, 'approx_kl': -0.029832535423338413, 'clip_fraction': 0.4088541716337204, 'grad_norm': 11.348316192626953}
2023-01-03 17:27:27.404 DEBUG: Taking gradient step
2023-01-03 17:27:29.285 DEBUG: Loss 10: {'policy_loss': -0.009941020743734267, 'entropy_loss': -0.03160377545282245, 'vf_loss': 0.016981694900891717, 'total_loss': -0.04154479619655671, 'approx_kl': -0.04718918772414327, 'clip_fraction': 0.3411458358168602, 'grad_norm': 11.317328453063965}
2023-01-03 17:27:31.110 DEBUG: Taking gradient step
2023-01-03 17:27:32.981 DEBUG: Loss 11: {'policy_loss': 0.0022835565705306288, 'entropy_loss': -0.03208452556282282, 'vf_loss': 0.01780544757517491, 'total_loss': -0.029800968992292187, 'approx_kl': -0.04885743837803602, 'clip_fraction': 0.37109375, 'grad_norm': 10.039902687072754}
2023-01-03 17:27:34.903 DEBUG: Taking gradient step
2023-01-03 17:27:36.776 DEBUG: Loss 12: {'policy_loss': -0.031679253240635474, 'entropy_loss': -0.03210425330325961, 'vf_loss': 0.01618373032449137, 'total_loss': -0.06378350654389509, 'approx_kl': -0.04994404222816229, 'clip_fraction': 0.3841145858168602, 'grad_norm': 10.241198539733887}
2023-01-03 17:27:38.607 DEBUG: Taking gradient step
2023-01-03 17:27:40.475 DEBUG: Loss 13: {'policy_loss': -0.04872262075652731, 'entropy_loss': -0.03179477388039231, 'vf_loss': 0.015223921826029573, 'total_loss': -0.08051739463691962, 'approx_kl': -0.05201781983487308, 'clip_fraction': 0.40234375, 'grad_norm': 9.370553016662598}
2023-01-03 17:27:42.321 DEBUG: Taking gradient step
2023-01-03 17:27:44.192 DEBUG: Loss 14: {'policy_loss': 0.03019824608225614, 'entropy_loss': -0.03268463350832462, 'vf_loss': 0.01818690715746046, 'total_loss': -0.0024863874260684787, 'approx_kl': -0.05055947182700038, 'clip_fraction': 0.43359375, 'grad_norm': 12.790426254272461}
2023-01-03 17:27:44.193 INFO: Optimization: policy loss=0.030, vf loss=0.018, entropy loss=-0.033, total loss=-0.002, num steps=15
2023-01-03 17:27:44.194 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 17:27:45.873 INFO: Evaluation rollout: return=0.495 (0.0), episode length=6.0
2023-01-03 17:27:45.875 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 17:27:45.877 INFO: Iteration: 104/137, steps: 22464
2023-01-03 17:28:00.287 DEBUG: Atoms are too close
2023-01-03 17:28:36.970 DEBUG: Atoms are too close
2023-01-03 17:28:38.944 DEBUG: Atoms are too close
2023-01-03 17:28:41.174 DEBUG: Atoms are too close
2023-01-03 17:28:42.345 INFO: Training rollout: return=-1.207 (4.8), episode length=5.9
2023-01-03 17:28:42.346 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 17:28:42.350 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-22464_train.pkl
2023-01-03 17:28:44.225 DEBUG: Taking gradient step
2023-01-03 17:28:46.128 DEBUG: Loss 0: {'policy_loss': -0.01887956273336812, 'entropy_loss': -0.03386672865599394, 'vf_loss': 0.0123404715954413, 'total_loss': -0.05274629138936206, 'approx_kl': -6.790894957475757e-09, 'clip_fraction': 0.0, 'grad_norm': 12.017738342285156}
2023-01-03 17:28:47.988 DEBUG: Taking gradient step
2023-01-03 17:28:49.879 DEBUG: Loss 1: {'policy_loss': 0.028718619716759167, 'entropy_loss': -0.033395664766430855, 'vf_loss': 0.014272845270428871, 'total_loss': -0.004677045049671688, 'approx_kl': -0.012942586094141006, 'clip_fraction': 0.11067708395421505, 'grad_norm': 14.208905220031738}
2023-01-03 17:28:51.734 DEBUG: Taking gradient step
2023-01-03 17:28:53.618 DEBUG: Loss 2: {'policy_loss': 0.003195238820109755, 'entropy_loss': -0.032854761462658644, 'vf_loss': 0.013287624082490596, 'total_loss': -0.029659522642548886, 'approx_kl': -0.03791045490652323, 'clip_fraction': 0.2513020858168602, 'grad_norm': 10.904586791992188}
2023-01-03 17:28:55.472 DEBUG: Taking gradient step
2023-01-03 17:28:57.365 DEBUG: Loss 3: {'policy_loss': 0.022506832212550176, 'entropy_loss': -0.03508561011403799, 'vf_loss': 0.012800571915729766, 'total_loss': -0.012578777901487814, 'approx_kl': -0.052422636188566685, 'clip_fraction': 0.3033854216337204, 'grad_norm': 10.260229110717773}
2023-01-03 17:28:59.213 DEBUG: Taking gradient step
2023-01-03 17:29:01.091 DEBUG: Loss 4: {'policy_loss': 0.0562988097102666, 'entropy_loss': -0.03404323663562536, 'vf_loss': 0.015450333553914723, 'total_loss': 0.02225557307464124, 'approx_kl': -0.05138635728508234, 'clip_fraction': 0.3463541716337204, 'grad_norm': 11.473307609558105}
2023-01-03 17:29:02.952 DEBUG: Taking gradient step
2023-01-03 17:29:04.844 DEBUG: Loss 5: {'policy_loss': 0.04325354562333056, 'entropy_loss': -0.0331215700134635, 'vf_loss': 0.013819788140674681, 'total_loss': 0.010131975609867061, 'approx_kl': -0.05168257490731776, 'clip_fraction': 0.41015625, 'grad_norm': 14.563898086547852}
2023-01-03 17:29:06.709 DEBUG: Taking gradient step
2023-01-03 17:29:08.602 DEBUG: Loss 6: {'policy_loss': 0.05977354547939856, 'entropy_loss': -0.035623150411993265, 'vf_loss': 0.013215518928063857, 'total_loss': 0.02415039506740529, 'approx_kl': -0.05665434920229018, 'clip_fraction': 0.4088541716337204, 'grad_norm': 14.365748405456543}
2023-01-03 17:29:10.466 DEBUG: Taking gradient step
2023-01-03 17:29:12.353 DEBUG: Loss 7: {'policy_loss': 0.022489238005128705, 'entropy_loss': -0.034161138348281384, 'vf_loss': 0.012526409674932105, 'total_loss': -0.011671900343152677, 'approx_kl': -0.09166004974395037, 'clip_fraction': 0.3515625, 'grad_norm': 13.91474437713623}
2023-01-03 17:29:14.209 DEBUG: Taking gradient step
2023-01-03 17:29:16.193 DEBUG: Loss 8: {'policy_loss': 0.007002721481577432, 'entropy_loss': -0.032733114436268806, 'vf_loss': 0.012933596283877238, 'total_loss': -0.025730392954691372, 'approx_kl': -0.07047915598377585, 'clip_fraction': 0.5182291716337204, 'grad_norm': 12.01472282409668}
2023-01-03 17:29:18.030 DEBUG: Taking gradient step
2023-01-03 17:29:19.914 DEBUG: Loss 9: {'policy_loss': 0.029628329548344188, 'entropy_loss': -0.03306558867916465, 'vf_loss': 0.014361359711760457, 'total_loss': -0.0034372591308204636, 'approx_kl': -0.08239176869392395, 'clip_fraction': 0.4973958358168602, 'grad_norm': 11.35708236694336}
2023-01-03 17:29:21.770 DEBUG: Taking gradient step
2023-01-03 17:29:23.662 DEBUG: Loss 10: {'policy_loss': 0.028213907949821388, 'entropy_loss': -0.03451712662354112, 'vf_loss': 0.013999727133087777, 'total_loss': -0.006303218673719732, 'approx_kl': -0.09399202652275562, 'clip_fraction': 0.5377604216337204, 'grad_norm': 14.421408653259277}
2023-01-03 17:29:25.500 DEBUG: Taking gradient step
2023-01-03 17:29:27.371 DEBUG: Loss 11: {'policy_loss': -0.05666650571697809, 'entropy_loss': -0.03447298938408494, 'vf_loss': 0.01120165230515811, 'total_loss': -0.09113949510106303, 'approx_kl': -0.07892363145947456, 'clip_fraction': 0.5794270932674408, 'grad_norm': 13.228836059570312}
2023-01-03 17:29:29.218 DEBUG: Taking gradient step
2023-01-03 17:29:31.100 DEBUG: Loss 12: {'policy_loss': -0.0354194008742366, 'entropy_loss': -0.03452971391379833, 'vf_loss': 0.011372230065745713, 'total_loss': -0.06994911478803494, 'approx_kl': -0.10897956509143114, 'clip_fraction': 0.5716145932674408, 'grad_norm': 10.658807754516602}
2023-01-03 17:29:32.955 DEBUG: Taking gradient step
2023-01-03 17:29:34.840 DEBUG: Loss 13: {'policy_loss': -0.010984621232829818, 'entropy_loss': -0.03280590195208788, 'vf_loss': 0.012445755322546378, 'total_loss': -0.0437905231849177, 'approx_kl': -0.08458994049578905, 'clip_fraction': 0.5377604216337204, 'grad_norm': 14.100457191467285}
2023-01-03 17:29:36.680 DEBUG: Taking gradient step
2023-01-03 17:29:38.558 DEBUG: Loss 14: {'policy_loss': 0.029500311424994284, 'entropy_loss': -0.033867163117975, 'vf_loss': 0.01402941871005959, 'total_loss': -0.0043668516929807125, 'approx_kl': -0.09455551858991385, 'clip_fraction': 0.56640625, 'grad_norm': 14.07620620727539}
2023-01-03 17:29:38.559 INFO: Optimization: policy loss=0.030, vf loss=0.014, entropy loss=-0.034, total loss=-0.004, num steps=15
2023-01-03 17:29:38.560 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 17:29:40.248 INFO: Evaluation rollout: return=0.491 (0.0), episode length=6.0
2023-01-03 17:29:40.250 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 17:29:40.253 INFO: Iteration: 105/137, steps: 22680
2023-01-03 17:30:37.120 INFO: Training rollout: return=0.503 (0.1), episode length=6.0
2023-01-03 17:30:37.121 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 17:30:37.124 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-22680_train.pkl
2023-01-03 17:30:39.021 DEBUG: Taking gradient step
2023-01-03 17:30:40.935 DEBUG: Loss 0: {'policy_loss': 0.022414228520015914, 'entropy_loss': -0.033946610521525145, 'vf_loss': 0.0018915691507742733, 'total_loss': -0.011532382001509231, 'approx_kl': 1.3048217795130768e-07, 'clip_fraction': 0.0, 'grad_norm': 15.199593544006348}
2023-01-03 17:30:42.807 DEBUG: Taking gradient step
2023-01-03 17:30:44.728 DEBUG: Loss 1: {'policy_loss': -0.06049178716909424, 'entropy_loss': -0.034486512653529644, 'vf_loss': 0.002062874252537438, 'total_loss': -0.09497829982262387, 'approx_kl': -0.010337126674130559, 'clip_fraction': 0.037760416977107525, 'grad_norm': 12.245546340942383}
2023-01-03 17:30:46.604 DEBUG: Taking gradient step
2023-01-03 17:30:48.509 DEBUG: Loss 2: {'policy_loss': 0.03999529669623211, 'entropy_loss': -0.03419693326577544, 'vf_loss': 0.0018528318925922988, 'total_loss': 0.005798363430456675, 'approx_kl': -0.016596360015682876, 'clip_fraction': 0.2434895858168602, 'grad_norm': 23.08220863342285}
2023-01-03 17:30:50.396 DEBUG: Taking gradient step
2023-01-03 17:30:52.311 DEBUG: Loss 3: {'policy_loss': 0.08020699262298406, 'entropy_loss': -0.032295755576342344, 'vf_loss': 0.0017442372787816638, 'total_loss': 0.047911237046641714, 'approx_kl': -0.025935365818440914, 'clip_fraction': 0.3033854216337204, 'grad_norm': 17.071701049804688}
2023-01-03 17:30:54.170 DEBUG: Taking gradient step
2023-01-03 17:30:56.080 DEBUG: Loss 4: {'policy_loss': 0.0808927155974928, 'entropy_loss': -0.03325076447799802, 'vf_loss': 0.001655223840270813, 'total_loss': 0.04764195111949478, 'approx_kl': -0.025869710370898247, 'clip_fraction': 0.3138020858168602, 'grad_norm': 15.555312156677246}
2023-01-03 17:30:57.946 DEBUG: Taking gradient step
2023-01-03 17:30:59.860 DEBUG: Loss 5: {'policy_loss': 0.017398734698557558, 'entropy_loss': -0.034316640347242355, 'vf_loss': 0.0016035835978831614, 'total_loss': -0.016917905648684797, 'approx_kl': -0.027793499175459146, 'clip_fraction': 0.3346354216337204, 'grad_norm': 18.163116455078125}
2023-01-03 17:31:01.744 DEBUG: Taking gradient step
2023-01-03 17:31:03.736 DEBUG: Loss 6: {'policy_loss': 0.025002078012183557, 'entropy_loss': -0.034287771210074425, 'vf_loss': 0.0013526854956044348, 'total_loss': -0.009285693197890868, 'approx_kl': -0.04069338319823146, 'clip_fraction': 0.3111979179084301, 'grad_norm': 11.818203926086426}
2023-01-03 17:31:05.617 DEBUG: Taking gradient step
2023-01-03 17:31:07.525 DEBUG: Loss 7: {'policy_loss': 0.049606383662091705, 'entropy_loss': -0.03347562486305833, 'vf_loss': 0.0012298652872294801, 'total_loss': 0.016130758799033376, 'approx_kl': -0.04687702376395464, 'clip_fraction': 0.3567708358168602, 'grad_norm': 20.807689666748047}
2023-01-03 17:31:09.397 DEBUG: Taking gradient step
2023-01-03 17:31:11.311 DEBUG: Loss 8: {'policy_loss': 0.024773253871005086, 'entropy_loss': -0.034457632806152105, 'vf_loss': 0.0010749217460720472, 'total_loss': -0.009684378935147021, 'approx_kl': -0.04548840189818293, 'clip_fraction': 0.3333333358168602, 'grad_norm': 21.171653747558594}
2023-01-03 17:31:13.187 DEBUG: Taking gradient step
2023-01-03 17:31:15.102 DEBUG: Loss 9: {'policy_loss': 0.039577978890788665, 'entropy_loss': -0.03386305319145322, 'vf_loss': 0.0009484594149512444, 'total_loss': 0.005714925699335446, 'approx_kl': -0.05831132270395756, 'clip_fraction': 0.3046875, 'grad_norm': 14.423123359680176}
2023-01-03 17:31:16.979 DEBUG: Taking gradient step
2023-01-03 17:31:18.893 DEBUG: Loss 10: {'policy_loss': 0.03376286167302295, 'entropy_loss': -0.0333846234716475, 'vf_loss': 0.0008390330076518315, 'total_loss': 0.000378238201375454, 'approx_kl': -0.055633342592045665, 'clip_fraction': 0.3190104216337204, 'grad_norm': 11.40571403503418}
2023-01-03 17:31:20.809 DEBUG: Taking gradient step
2023-01-03 17:31:22.734 DEBUG: Loss 11: {'policy_loss': 0.05589314870542461, 'entropy_loss': -0.03556552017107606, 'vf_loss': 0.0006786509052760965, 'total_loss': 0.020327628534348552, 'approx_kl': -0.09424593672156334, 'clip_fraction': 0.3333333358168602, 'grad_norm': 15.424101829528809}
2023-01-03 17:31:24.630 DEBUG: Taking gradient step
2023-01-03 17:31:26.566 DEBUG: Loss 12: {'policy_loss': 0.015335248752115012, 'entropy_loss': -0.03512692078948021, 'vf_loss': 0.0006382302325702553, 'total_loss': -0.019791672037365197, 'approx_kl': -0.06375732383457944, 'clip_fraction': 0.3450520858168602, 'grad_norm': 16.85524559020996}
2023-01-03 17:31:28.441 DEBUG: Taking gradient step
2023-01-03 17:31:30.385 DEBUG: Loss 13: {'policy_loss': -0.010985021126351836, 'entropy_loss': -0.03552990220487118, 'vf_loss': 0.0005948356997199439, 'total_loss': -0.04651492333122302, 'approx_kl': -0.0795658091083169, 'clip_fraction': 0.3059895858168602, 'grad_norm': 18.996055603027344}
2023-01-03 17:31:32.303 DEBUG: Taking gradient step
2023-01-03 17:31:34.275 DEBUG: Loss 14: {'policy_loss': 0.03587476174047974, 'entropy_loss': -0.035287081729620695, 'vf_loss': 0.0004785095502258316, 'total_loss': 0.0005876800108590464, 'approx_kl': -0.09499320108443499, 'clip_fraction': 0.3411458358168602, 'grad_norm': 20.05331802368164}
2023-01-03 17:31:34.276 INFO: Optimization: policy loss=0.036, vf loss=0.000, entropy loss=-0.035, total loss=0.001, num steps=15
2023-01-03 17:31:34.277 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 17:31:35.955 INFO: Evaluation rollout: return=0.493 (0.0), episode length=6.0
2023-01-03 17:31:35.956 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 17:31:35.959 INFO: Iteration: 106/137, steps: 22896
2023-01-03 17:31:53.839 DEBUG: Atoms are too close
2023-01-03 17:32:06.847 DEBUG: Atoms are too close
2023-01-03 17:32:08.228 DEBUG: Atoms are too close
2023-01-03 17:32:09.075 DEBUG: Atoms are too close
2023-01-03 17:32:25.794 DEBUG: Atoms are too close
2023-01-03 17:32:29.261 DEBUG: Atoms are too close
2023-01-03 17:32:31.057 INFO: Training rollout: return=-3.118 (6.3), episode length=5.9
2023-01-03 17:32:31.059 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 17:32:31.062 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-22896_train.pkl
2023-01-03 17:32:32.964 DEBUG: Taking gradient step
2023-01-03 17:32:34.875 DEBUG: Loss 0: {'policy_loss': 0.01104117515088689, 'entropy_loss': -0.034045674838125706, 'vf_loss': 0.030097822638682322, 'total_loss': -0.02300449968723882, 'approx_kl': -8.312053978443146e-08, 'clip_fraction': 0.0, 'grad_norm': 14.126513481140137}
2023-01-03 17:32:36.743 DEBUG: Taking gradient step
2023-01-03 17:32:38.662 DEBUG: Loss 1: {'policy_loss': 0.01277975970665348, 'entropy_loss': -0.03297424083575606, 'vf_loss': 0.030667843110202216, 'total_loss': -0.020194481129102583, 'approx_kl': -0.015100812655873597, 'clip_fraction': 0.1627604216337204, 'grad_norm': 21.53331756591797}
2023-01-03 17:32:40.538 DEBUG: Taking gradient step
2023-01-03 17:32:42.448 DEBUG: Loss 2: {'policy_loss': 0.004607152277524354, 'entropy_loss': -0.03585460036993027, 'vf_loss': 0.02851714907316736, 'total_loss': -0.03124744809240592, 'approx_kl': -0.030246515874750912, 'clip_fraction': 0.32421875, 'grad_norm': 20.89177131652832}
2023-01-03 17:32:44.307 DEBUG: Taking gradient step
2023-01-03 17:32:46.311 DEBUG: Loss 3: {'policy_loss': 0.0233727286677889, 'entropy_loss': -0.03429626487195492, 'vf_loss': 0.02994842357581997, 'total_loss': -0.010923536204166018, 'approx_kl': -0.03933382220566273, 'clip_fraction': 0.3411458358168602, 'grad_norm': 16.73594093322754}
2023-01-03 17:32:48.170 DEBUG: Taking gradient step
2023-01-03 17:32:50.087 DEBUG: Loss 4: {'policy_loss': 0.02870863317780487, 'entropy_loss': -0.03524853056296706, 'vf_loss': 0.029252963095521806, 'total_loss': -0.006539897385162197, 'approx_kl': -0.022893190383911133, 'clip_fraction': 0.390625, 'grad_norm': 13.885945320129395}
2023-01-03 17:32:51.942 DEBUG: Taking gradient step
2023-01-03 17:32:53.855 DEBUG: Loss 5: {'policy_loss': 0.03786477724680426, 'entropy_loss': -0.037705265916883945, 'vf_loss': 0.029333566844542563, 'total_loss': 0.00015951132992031263, 'approx_kl': -0.043707673670724034, 'clip_fraction': 0.390625, 'grad_norm': 21.507665634155273}
2023-01-03 17:32:55.707 DEBUG: Taking gradient step
2023-01-03 17:32:57.617 DEBUG: Loss 6: {'policy_loss': 0.07039019372095187, 'entropy_loss': -0.03704334236681461, 'vf_loss': 0.0310510269491391, 'total_loss': 0.03334685135413725, 'approx_kl': -0.05043834447860718, 'clip_fraction': 0.3958333358168602, 'grad_norm': 22.610517501831055}
2023-01-03 17:32:59.480 DEBUG: Taking gradient step
2023-01-03 17:33:01.397 DEBUG: Loss 7: {'policy_loss': 0.0035187557827352223, 'entropy_loss': -0.038575091399252415, 'vf_loss': 0.027680479105814157, 'total_loss': -0.03505633561651719, 'approx_kl': -0.04493340593762696, 'clip_fraction': 0.3697916716337204, 'grad_norm': 21.140235900878906}
2023-01-03 17:33:03.246 DEBUG: Taking gradient step
2023-01-03 17:33:05.143 DEBUG: Loss 8: {'policy_loss': 0.07741871456564609, 'entropy_loss': -0.04008592199534178, 'vf_loss': 0.03346497931025295, 'total_loss': 0.03733279257030431, 'approx_kl': -0.047307825181633234, 'clip_fraction': 0.37109375, 'grad_norm': 29.89618682861328}
2023-01-03 17:33:06.998 DEBUG: Taking gradient step
2023-01-03 17:33:08.905 DEBUG: Loss 9: {'policy_loss': 0.023004143579248158, 'entropy_loss': -0.03889866266399622, 'vf_loss': 0.029346178880796527, 'total_loss': -0.015894519084748066, 'approx_kl': -0.006095374934375286, 'clip_fraction': 0.4127604216337204, 'grad_norm': 15.066804885864258}
2023-01-03 17:33:10.758 DEBUG: Taking gradient step
2023-01-03 17:33:12.669 DEBUG: Loss 10: {'policy_loss': 0.05680753717236545, 'entropy_loss': -0.040059431456029415, 'vf_loss': 0.031160171410023335, 'total_loss': 0.016748105716336028, 'approx_kl': -0.024094979278743267, 'clip_fraction': 0.4296875, 'grad_norm': 19.332237243652344}
2023-01-03 17:33:14.518 DEBUG: Taking gradient step
2023-01-03 17:33:16.470 DEBUG: Loss 11: {'policy_loss': 0.1492309070006598, 'entropy_loss': -0.037625825963914394, 'vf_loss': 0.032312237180300254, 'total_loss': 0.11160508103674541, 'approx_kl': -0.041580008808523417, 'clip_fraction': 0.5677083432674408, 'grad_norm': 40.3470573425293}
2023-01-03 17:33:18.349 DEBUG: Taking gradient step
2023-01-03 17:33:20.302 DEBUG: Loss 12: {'policy_loss': 0.18700534667489394, 'entropy_loss': -0.040411665104329586, 'vf_loss': 0.0321831085522591, 'total_loss': 0.14659368157056432, 'approx_kl': 0.01686606975272298, 'clip_fraction': 0.5911458432674408, 'grad_norm': 20.411636352539062}
2023-01-03 17:33:22.210 DEBUG: Early stopping at step 13 for reaching max KL.
2023-01-03 17:33:22.210 INFO: Optimization: policy loss=0.187, vf loss=0.032, entropy loss=-0.040, total loss=0.147, num steps=13
2023-01-03 17:33:22.211 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 17:33:23.927 INFO: Evaluation rollout: return=0.500 (0.0), episode length=6.0
2023-01-03 17:33:23.928 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 17:33:23.930 INFO: Iteration: 107/137, steps: 23112
2023-01-03 17:33:38.183 DEBUG: Atoms are too close
2023-01-03 17:34:01.242 DEBUG: Atoms are too close
2023-01-03 17:34:14.232 DEBUG: Atoms are too close
2023-01-03 17:34:19.660 INFO: Training rollout: return=-0.761 (4.1), episode length=5.9
2023-01-03 17:34:19.661 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 17:34:19.664 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-23112_train.pkl
2023-01-03 17:34:21.581 DEBUG: Taking gradient step
2023-01-03 17:34:23.469 DEBUG: Loss 0: {'policy_loss': 0.004968513250651056, 'entropy_loss': -0.040157669223845005, 'vf_loss': 0.013379868924798078, 'total_loss': -0.03518915597319395, 'approx_kl': 5.405551384285445e-08, 'clip_fraction': 0.0, 'grad_norm': 14.511094093322754}
2023-01-03 17:34:25.334 DEBUG: Early stopping at step 1 for reaching max KL.
2023-01-03 17:34:25.335 INFO: Optimization: policy loss=0.005, vf loss=0.013, entropy loss=-0.040, total loss=-0.035, num steps=1
2023-01-03 17:34:25.336 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 17:34:27.036 INFO: Evaluation rollout: return=0.498 (0.0), episode length=6.0
2023-01-03 17:34:27.037 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 17:34:27.040 INFO: Iteration: 108/137, steps: 23328
2023-01-03 17:34:39.394 DEBUG: Atoms are too close
2023-01-03 17:34:41.082 DEBUG: Atoms are too close
2023-01-03 17:35:00.513 DEBUG: Atoms are too close
2023-01-03 17:35:22.684 INFO: Training rollout: return=-0.804 (4.4), episode length=5.9
2023-01-03 17:35:22.686 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 17:35:22.688 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-23328_train.pkl
2023-01-03 17:35:24.567 DEBUG: Taking gradient step
2023-01-03 17:35:26.454 DEBUG: Loss 0: {'policy_loss': 0.07135514712788504, 'entropy_loss': -0.037110683508217335, 'vf_loss': 0.015552418593338538, 'total_loss': 0.03424446361966771, 'approx_kl': -8.081163827000637e-08, 'clip_fraction': 0.0, 'grad_norm': 13.78750228881836}
2023-01-03 17:35:28.386 DEBUG: Early stopping at step 1 for reaching max KL.
2023-01-03 17:35:28.386 INFO: Optimization: policy loss=0.071, vf loss=0.016, entropy loss=-0.037, total loss=0.034, num steps=1
2023-01-03 17:35:28.387 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 17:35:30.040 INFO: Evaluation rollout: return=0.496 (0.0), episode length=6.0
2023-01-03 17:35:30.041 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 17:35:30.044 INFO: Iteration: 109/137, steps: 23544
2023-01-03 17:36:22.224 DEBUG: There is a single atom floating around
2023-01-03 17:36:26.488 INFO: Training rollout: return=-0.341 (3.3), episode length=6.0
2023-01-03 17:36:26.489 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 17:36:26.492 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-23544_train.pkl
2023-01-03 17:36:28.365 DEBUG: Taking gradient step
2023-01-03 17:36:30.270 DEBUG: Loss 0: {'policy_loss': 0.016476908654976342, 'entropy_loss': -0.03511179890483618, 'vf_loss': 0.009732242851825761, 'total_loss': -0.018634890249859835, 'approx_kl': 4.0192389860749245e-08, 'clip_fraction': 0.0, 'grad_norm': 14.498236656188965}
2023-01-03 17:36:32.145 DEBUG: Early stopping at step 1 for reaching max KL.
2023-01-03 17:36:32.145 INFO: Optimization: policy loss=0.016, vf loss=0.010, entropy loss=-0.035, total loss=-0.019, num steps=1
2023-01-03 17:36:32.146 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 17:36:33.816 INFO: Evaluation rollout: return=0.494 (0.0), episode length=6.0
2023-01-03 17:36:33.817 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 17:36:33.820 INFO: Iteration: 110/137, steps: 23760
2023-01-03 17:36:48.241 DEBUG: There is a single atom floating around
2023-01-03 17:36:50.295 DEBUG: Atoms are too close
2023-01-03 17:37:30.364 INFO: Training rollout: return=-0.344 (3.3), episode length=6.0
2023-01-03 17:37:30.365 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 17:37:30.368 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-23760_train.pkl
2023-01-03 17:37:32.233 DEBUG: Taking gradient step
2023-01-03 17:37:34.123 DEBUG: Loss 0: {'policy_loss': -0.001190162646208015, 'entropy_loss': -0.03390987729653716, 'vf_loss': 0.00843044444493857, 'total_loss': -0.03510003994274518, 'approx_kl': -5.477340891957283e-08, 'clip_fraction': 0.0, 'grad_norm': 23.48682975769043}
2023-01-03 17:37:35.972 DEBUG: Taking gradient step
2023-01-03 17:37:37.866 DEBUG: Loss 1: {'policy_loss': -0.05294685305209643, 'entropy_loss': -0.032549303490668535, 'vf_loss': 0.006923090584123892, 'total_loss': -0.08549615654276496, 'approx_kl': -0.03462825086899102, 'clip_fraction': 0.2916666716337204, 'grad_norm': 15.618603706359863}
2023-01-03 17:37:39.720 DEBUG: Taking gradient step
2023-01-03 17:37:41.606 DEBUG: Loss 2: {'policy_loss': -0.04916576040316052, 'entropy_loss': -0.030834409408271313, 'vf_loss': 0.006751553110793869, 'total_loss': -0.08000016981143183, 'approx_kl': 0.020301171811297536, 'clip_fraction': 0.3971354216337204, 'grad_norm': 9.040297508239746}
2023-01-03 17:37:43.449 DEBUG: Taking gradient step
2023-01-03 17:37:45.336 DEBUG: Loss 3: {'policy_loss': -0.0509618252174239, 'entropy_loss': -0.03240038827061653, 'vf_loss': 0.006617381703044533, 'total_loss': -0.08336221348804043, 'approx_kl': 0.004731840454041958, 'clip_fraction': 0.4544270858168602, 'grad_norm': 7.865930557250977}
2023-01-03 17:37:47.181 DEBUG: Taking gradient step
2023-01-03 17:37:49.068 DEBUG: Loss 4: {'policy_loss': -0.044281589693031254, 'entropy_loss': -0.033236110117286444, 'vf_loss': 0.006542671323457951, 'total_loss': -0.0775176998103177, 'approx_kl': 0.019295158330351114, 'clip_fraction': 0.4192708358168602, 'grad_norm': 8.201033592224121}
2023-01-03 17:37:50.923 DEBUG: Early stopping at step 5 for reaching max KL.
2023-01-03 17:37:50.924 INFO: Optimization: policy loss=-0.044, vf loss=0.007, entropy loss=-0.033, total loss=-0.078, num steps=5
2023-01-03 17:37:50.925 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 17:37:52.596 INFO: Evaluation rollout: return=0.493 (0.0), episode length=6.0
2023-01-03 17:37:52.597 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 17:37:52.599 DEBUG: Deleting old model: runs/CH3NO_dna/models/CH3NO_dna_run-1_steps-21816.model
2023-01-03 17:37:52.603 DEBUG: Saving model: runs/CH3NO_dna/models/CH3NO_dna_run-1_steps-23976.model
2023-01-03 17:37:52.649 INFO: Iteration: 111/137, steps: 23976
2023-01-03 17:38:29.583 DEBUG: Atoms are too close
2023-01-03 17:38:29.584 DEBUG: Atoms are too close
2023-01-03 17:38:48.951 INFO: Training rollout: return=-0.625 (3.7), episode length=6.0
2023-01-03 17:38:48.953 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 17:38:48.956 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-23976_train.pkl
2023-01-03 17:38:50.846 DEBUG: Taking gradient step
2023-01-03 17:38:52.758 DEBUG: Loss 0: {'policy_loss': 0.027467886803862977, 'entropy_loss': -0.032552804332226515, 'vf_loss': 0.012185071799713228, 'total_loss': -0.005084917528363542, 'approx_kl': -9.456804672680619e-08, 'clip_fraction': 0.0, 'grad_norm': 17.669527053833008}
2023-01-03 17:38:54.628 DEBUG: Taking gradient step
2023-01-03 17:38:56.542 DEBUG: Loss 1: {'policy_loss': 0.049542018369228745, 'entropy_loss': -0.03297745389863849, 'vf_loss': 0.013386185718476402, 'total_loss': 0.016564564470590265, 'approx_kl': -0.039927808567881584, 'clip_fraction': 0.2486979179084301, 'grad_norm': 17.23683738708496}
2023-01-03 17:38:58.419 DEBUG: Taking gradient step
2023-01-03 17:39:00.331 DEBUG: Loss 2: {'policy_loss': -0.0014964124653237762, 'entropy_loss': -0.03239755844697356, 'vf_loss': 0.011710142292565513, 'total_loss': -0.03389397091229734, 'approx_kl': -0.04388868249952793, 'clip_fraction': 0.4700520858168602, 'grad_norm': 9.944364547729492}
2023-01-03 17:39:02.216 DEBUG: Taking gradient step
2023-01-03 17:39:04.143 DEBUG: Loss 3: {'policy_loss': 0.02468556514749432, 'entropy_loss': -0.03226041467860341, 'vf_loss': 0.012241952604383936, 'total_loss': -0.007574849531109096, 'approx_kl': -0.05524801043793559, 'clip_fraction': 0.4752604216337204, 'grad_norm': 11.041908264160156}
2023-01-03 17:39:06.099 DEBUG: Taking gradient step
2023-01-03 17:39:08.017 DEBUG: Loss 4: {'policy_loss': -0.04108210194751194, 'entropy_loss': -0.03285383898764849, 'vf_loss': 0.009753467162859897, 'total_loss': -0.07393594093516043, 'approx_kl': -0.06213885731995106, 'clip_fraction': 0.4518229216337204, 'grad_norm': 11.548378944396973}
2023-01-03 17:39:09.887 DEBUG: Taking gradient step
2023-01-03 17:39:11.807 DEBUG: Loss 5: {'policy_loss': -0.044120527957259605, 'entropy_loss': -0.03385967900976539, 'vf_loss': 0.009759408765800824, 'total_loss': -0.07798020696702498, 'approx_kl': -0.09844168601557612, 'clip_fraction': 0.4700520932674408, 'grad_norm': 11.272287368774414}
2023-01-03 17:39:13.674 DEBUG: Taking gradient step
2023-01-03 17:39:15.587 DEBUG: Loss 6: {'policy_loss': -0.041684148152118114, 'entropy_loss': -0.0337575888261199, 'vf_loss': 0.009729103826991386, 'total_loss': -0.07544173697823801, 'approx_kl': -0.06347620207816362, 'clip_fraction': 0.4049479216337204, 'grad_norm': 10.7028226852417}
2023-01-03 17:39:17.458 DEBUG: Taking gradient step
2023-01-03 17:39:19.369 DEBUG: Loss 7: {'policy_loss': 0.014243192677692348, 'entropy_loss': -0.03295174101367593, 'vf_loss': 0.012060172386494917, 'total_loss': -0.01870854833598358, 'approx_kl': -0.06825430877506733, 'clip_fraction': 0.4166666716337204, 'grad_norm': 13.880988121032715}
2023-01-03 17:39:21.253 DEBUG: Taking gradient step
2023-01-03 17:39:23.158 DEBUG: Loss 8: {'policy_loss': 0.003736601721234946, 'entropy_loss': -0.03214229457080364, 'vf_loss': 0.011351408907013805, 'total_loss': -0.028405692849568696, 'approx_kl': -0.0637952157703694, 'clip_fraction': 0.4765625, 'grad_norm': 13.759941101074219}
2023-01-03 17:39:25.014 DEBUG: Taking gradient step
2023-01-03 17:39:26.918 DEBUG: Loss 9: {'policy_loss': 0.016546957185662188, 'entropy_loss': -0.03281611297279596, 'vf_loss': 0.011795616219106655, 'total_loss': -0.016269155787133775, 'approx_kl': -0.1002429062500596, 'clip_fraction': 0.4921875, 'grad_norm': 15.66064453125}
2023-01-03 17:39:28.779 DEBUG: Taking gradient step
2023-01-03 17:39:30.688 DEBUG: Loss 10: {'policy_loss': 0.00019210120630554217, 'entropy_loss': -0.03298882860690355, 'vf_loss': 0.012304851418221883, 'total_loss': -0.03279672740059801, 'approx_kl': -0.05753615987487137, 'clip_fraction': 0.4348958358168602, 'grad_norm': 8.65416431427002}
2023-01-03 17:39:32.567 DEBUG: Taking gradient step
2023-01-03 17:39:34.467 DEBUG: Loss 11: {'policy_loss': -0.05174025980087826, 'entropy_loss': -0.03406669106334448, 'vf_loss': 0.009817338833371839, 'total_loss': -0.08580695086422274, 'approx_kl': -0.0797562301158905, 'clip_fraction': 0.5807291716337204, 'grad_norm': 9.59107494354248}
2023-01-03 17:39:36.334 DEBUG: Taking gradient step
2023-01-03 17:39:38.226 DEBUG: Loss 12: {'policy_loss': -0.02507014936590294, 'entropy_loss': -0.03191851545125246, 'vf_loss': 0.010878430025882638, 'total_loss': -0.0569886648171554, 'approx_kl': -0.09342704620212317, 'clip_fraction': 0.57421875, 'grad_norm': 10.627565383911133}
2023-01-03 17:39:40.093 DEBUG: Taking gradient step
2023-01-03 17:39:41.998 DEBUG: Loss 13: {'policy_loss': -0.028967016687241692, 'entropy_loss': -0.03217423055320978, 'vf_loss': 0.01058989356848695, 'total_loss': -0.061141247240451474, 'approx_kl': -0.06109439706779085, 'clip_fraction': 0.6419270932674408, 'grad_norm': 14.213842391967773}
2023-01-03 17:39:43.866 DEBUG: Taking gradient step
2023-01-03 17:39:45.769 DEBUG: Loss 14: {'policy_loss': -0.019671907909517374, 'entropy_loss': -0.03257504012435675, 'vf_loss': 0.010788516300366183, 'total_loss': -0.05224694803387411, 'approx_kl': -0.09368029236793518, 'clip_fraction': 0.625, 'grad_norm': 8.728119850158691}
2023-01-03 17:39:45.769 INFO: Optimization: policy loss=-0.020, vf loss=0.011, entropy loss=-0.033, total loss=-0.052, num steps=15
2023-01-03 17:39:45.770 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 17:39:47.440 INFO: Evaluation rollout: return=0.540 (0.0), episode length=6.0
2023-01-03 17:39:47.441 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 17:39:47.444 INFO: Iteration: 112/137, steps: 24192
2023-01-03 17:40:20.988 DEBUG: Atoms are too close
2023-01-03 17:40:44.011 INFO: Training rollout: return=0.019 (2.6), episode length=6.0
2023-01-03 17:40:44.013 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 17:40:44.017 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-24192_train.pkl
2023-01-03 17:40:45.920 DEBUG: Taking gradient step
2023-01-03 17:40:47.921 DEBUG: Loss 0: {'policy_loss': -0.0042327848626753685, 'entropy_loss': -0.03308754600584507, 'vf_loss': 0.00376044373846421, 'total_loss': -0.037320330868520435, 'approx_kl': -3.1742577455418086e-08, 'clip_fraction': 0.0, 'grad_norm': 10.391016006469727}
2023-01-03 17:40:49.798 DEBUG: Taking gradient step
2023-01-03 17:40:51.715 DEBUG: Loss 1: {'policy_loss': -0.042380860412733645, 'entropy_loss': -0.0346366954036057, 'vf_loss': 0.0037985353185918153, 'total_loss': -0.07701755581633934, 'approx_kl': -0.013425953686237335, 'clip_fraction': 0.18098958395421505, 'grad_norm': 10.012640953063965}
2023-01-03 17:40:53.589 DEBUG: Taking gradient step
2023-01-03 17:40:55.502 DEBUG: Loss 2: {'policy_loss': -0.026885789010479243, 'entropy_loss': -0.03495192667469382, 'vf_loss': 0.0037830940824358688, 'total_loss': -0.06183771568517307, 'approx_kl': -0.009442112874239683, 'clip_fraction': 0.4244791716337204, 'grad_norm': 11.136824607849121}
2023-01-03 17:40:57.369 DEBUG: Taking gradient step
2023-01-03 17:40:59.280 DEBUG: Loss 3: {'policy_loss': 0.004680291295336255, 'entropy_loss': -0.03471478773280978, 'vf_loss': 0.005417067387972038, 'total_loss': -0.030034496437473523, 'approx_kl': -0.02753002243116498, 'clip_fraction': 0.546875, 'grad_norm': 5.879420280456543}
2023-01-03 17:41:01.139 DEBUG: Taking gradient step
2023-01-03 17:41:03.051 DEBUG: Loss 4: {'policy_loss': -0.026196204590432315, 'entropy_loss': -0.03331569628790021, 'vf_loss': 0.0037008200531264707, 'total_loss': -0.05951190087833253, 'approx_kl': -0.003834834322333336, 'clip_fraction': 0.50390625, 'grad_norm': 4.796429634094238}
2023-01-03 17:41:04.911 DEBUG: Taking gradient step
2023-01-03 17:41:06.832 DEBUG: Loss 5: {'policy_loss': 0.02965994252074996, 'entropy_loss': -0.03443815419450402, 'vf_loss': 0.005214665906881825, 'total_loss': -0.004778211673754057, 'approx_kl': -0.03246313612908125, 'clip_fraction': 0.3528645858168602, 'grad_norm': 3.3869454860687256}
2023-01-03 17:41:08.712 DEBUG: Taking gradient step
2023-01-03 17:41:10.643 DEBUG: Loss 6: {'policy_loss': 0.007167672322503586, 'entropy_loss': -0.0338854119181633, 'vf_loss': 0.005279677049862892, 'total_loss': -0.02671773959565972, 'approx_kl': -0.03923526423750445, 'clip_fraction': 0.26953125, 'grad_norm': 3.7698681354522705}
2023-01-03 17:41:12.526 DEBUG: Taking gradient step
2023-01-03 17:41:14.456 DEBUG: Loss 7: {'policy_loss': 0.019852564988430146, 'entropy_loss': -0.03376341797411442, 'vf_loss': 0.004707385829828874, 'total_loss': -0.013910852985684272, 'approx_kl': -0.031324817216955125, 'clip_fraction': 0.3033854216337204, 'grad_norm': 20.488059997558594}
2023-01-03 17:41:16.334 DEBUG: Taking gradient step
2023-01-03 17:41:18.258 DEBUG: Loss 8: {'policy_loss': 0.04830859312623312, 'entropy_loss': -0.03452498372644186, 'vf_loss': 0.004699428555538722, 'total_loss': 0.013783609399791258, 'approx_kl': -0.035796069001662545, 'clip_fraction': 0.2604166679084301, 'grad_norm': 9.521147727966309}
2023-01-03 17:41:20.147 DEBUG: Taking gradient step
2023-01-03 17:41:22.068 DEBUG: Loss 9: {'policy_loss': -0.03420946405778949, 'entropy_loss': -0.033315455075353384, 'vf_loss': 0.0035082399747672828, 'total_loss': -0.06752491913314287, 'approx_kl': -0.0687372675165534, 'clip_fraction': 0.3255208358168602, 'grad_norm': 6.7477312088012695}
2023-01-03 17:41:23.954 DEBUG: Taking gradient step
2023-01-03 17:41:25.871 DEBUG: Loss 10: {'policy_loss': 0.011103473333938886, 'entropy_loss': -0.033904282841831446, 'vf_loss': 0.004592139093353501, 'total_loss': -0.02280080950789256, 'approx_kl': -0.05003131029661745, 'clip_fraction': 0.4440104216337204, 'grad_norm': 6.351480484008789}
2023-01-03 17:41:27.750 DEBUG: Taking gradient step
2023-01-03 17:41:29.660 DEBUG: Loss 11: {'policy_loss': 0.029341801047102496, 'entropy_loss': -0.034211731515824795, 'vf_loss': 0.004591500691312839, 'total_loss': -0.004869930468722292, 'approx_kl': -0.0599741586484015, 'clip_fraction': 0.43359375, 'grad_norm': 8.644302368164062}
2023-01-03 17:41:31.539 DEBUG: Taking gradient step
2023-01-03 17:41:33.450 DEBUG: Loss 12: {'policy_loss': -0.013014059574949432, 'entropy_loss': -0.03382064355537295, 'vf_loss': 0.003362009166075333, 'total_loss': -0.04683470313032238, 'approx_kl': -0.049198079854249954, 'clip_fraction': 0.4244791716337204, 'grad_norm': 9.787492752075195}
2023-01-03 17:41:35.329 DEBUG: Taking gradient step
2023-01-03 17:41:37.321 DEBUG: Loss 13: {'policy_loss': -0.05192861439828919, 'entropy_loss': -0.03606866579502821, 'vf_loss': 0.003340375976473211, 'total_loss': -0.0879972801933174, 'approx_kl': -0.05831683333963156, 'clip_fraction': 0.3841145858168602, 'grad_norm': 15.37246322631836}
2023-01-03 17:41:39.187 DEBUG: Taking gradient step
2023-01-03 17:41:41.104 DEBUG: Loss 14: {'policy_loss': -0.019058079057319703, 'entropy_loss': -0.033172042574733496, 'vf_loss': 0.0032799619697324047, 'total_loss': -0.0522301216320532, 'approx_kl': -0.07110762223601341, 'clip_fraction': 0.3294270858168602, 'grad_norm': 8.511832237243652}
2023-01-03 17:41:41.105 INFO: Optimization: policy loss=-0.019, vf loss=0.003, entropy loss=-0.033, total loss=-0.052, num steps=15
2023-01-03 17:41:41.106 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 17:41:42.791 INFO: Evaluation rollout: return=0.494 (0.0), episode length=6.0
2023-01-03 17:41:42.793 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 17:41:42.798 INFO: Iteration: 113/137, steps: 24408
2023-01-03 17:42:19.169 DEBUG: Atoms are too close
2023-01-03 17:42:32.903 DEBUG: There is a single atom floating around
2023-01-03 17:42:37.922 DEBUG: Atoms are too close
2023-01-03 17:42:38.886 INFO: Training rollout: return=-1.089 (4.4), episode length=6.0
2023-01-03 17:42:38.887 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 17:42:38.890 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-24408_train.pkl
2023-01-03 17:42:40.776 DEBUG: Taking gradient step
2023-01-03 17:42:42.678 DEBUG: Loss 0: {'policy_loss': 0.02184726751272609, 'entropy_loss': -0.03325828071683645, 'vf_loss': 0.015593102564017244, 'total_loss': -0.011411013204110358, 'approx_kl': 7.885197916834841e-08, 'clip_fraction': 0.0, 'grad_norm': 29.162492752075195}
2023-01-03 17:42:44.531 DEBUG: Taking gradient step
2023-01-03 17:42:46.429 DEBUG: Loss 1: {'policy_loss': -0.0060785593818802955, 'entropy_loss': -0.0353782675229013, 'vf_loss': 0.013923147998344224, 'total_loss': -0.04145682690478159, 'approx_kl': -0.02926381421275437, 'clip_fraction': 0.12109375, 'grad_norm': 13.428509712219238}
2023-01-03 17:42:48.283 DEBUG: Taking gradient step
2023-01-03 17:42:50.173 DEBUG: Loss 2: {'policy_loss': 0.004283870534391659, 'entropy_loss': -0.03396329237148166, 'vf_loss': 0.014631383869978467, 'total_loss': -0.029679421837089996, 'approx_kl': -0.027934021782130003, 'clip_fraction': 0.30078125, 'grad_norm': 16.027833938598633}
2023-01-03 17:42:52.045 DEBUG: Taking gradient step
2023-01-03 17:42:53.942 DEBUG: Loss 3: {'policy_loss': 0.05262246791759867, 'entropy_loss': -0.033991234842687845, 'vf_loss': 0.016692559075692365, 'total_loss': 0.018631233074910825, 'approx_kl': -0.02322284271940589, 'clip_fraction': 0.3606770858168602, 'grad_norm': 23.353233337402344}
2023-01-03 17:42:55.810 DEBUG: Taking gradient step
2023-01-03 17:42:57.714 DEBUG: Loss 4: {'policy_loss': -0.027220367802582288, 'entropy_loss': -0.03401645924896002, 'vf_loss': 0.013142371571617718, 'total_loss': -0.061236827051542306, 'approx_kl': -0.03116642963141203, 'clip_fraction': 0.3411458358168602, 'grad_norm': 13.863672256469727}
2023-01-03 17:42:59.572 DEBUG: Taking gradient step
2023-01-03 17:43:01.474 DEBUG: Loss 5: {'policy_loss': 0.019599406698995653, 'entropy_loss': -0.03400200931355357, 'vf_loss': 0.01424905421792498, 'total_loss': -0.014402602614557919, 'approx_kl': -0.016993734519928694, 'clip_fraction': 0.3046875, 'grad_norm': 15.079288482666016}
2023-01-03 17:43:03.330 DEBUG: Taking gradient step
2023-01-03 17:43:05.224 DEBUG: Loss 6: {'policy_loss': 0.03317166505933291, 'entropy_loss': -0.03419992746785283, 'vf_loss': 0.015165589236665934, 'total_loss': -0.0010282624085199213, 'approx_kl': -0.03980631334707141, 'clip_fraction': 0.2096354179084301, 'grad_norm': 23.04595375061035}
2023-01-03 17:43:07.072 DEBUG: Taking gradient step
2023-01-03 17:43:08.971 DEBUG: Loss 7: {'policy_loss': 0.011029515762146797, 'entropy_loss': -0.03302151383832097, 'vf_loss': 0.01431995203322142, 'total_loss': -0.021991998076174177, 'approx_kl': -0.043999492190778255, 'clip_fraction': 0.2057291716337204, 'grad_norm': 24.285287857055664}
2023-01-03 17:43:10.834 DEBUG: Taking gradient step
2023-01-03 17:43:12.736 DEBUG: Loss 8: {'policy_loss': 0.016880120234884964, 'entropy_loss': -0.034235463477671146, 'vf_loss': 0.014813605439847749, 'total_loss': -0.017355343242786182, 'approx_kl': -0.01659521274268627, 'clip_fraction': 0.25390625, 'grad_norm': 19.527313232421875}
2023-01-03 17:43:14.612 DEBUG: Taking gradient step
2023-01-03 17:43:16.527 DEBUG: Loss 9: {'policy_loss': 0.027995881496500473, 'entropy_loss': -0.03405634546652436, 'vf_loss': 0.015275992491482211, 'total_loss': -0.00606046397002389, 'approx_kl': -0.04581700684502721, 'clip_fraction': 0.2916666679084301, 'grad_norm': 16.17459487915039}
2023-01-03 17:43:18.386 DEBUG: Taking gradient step
2023-01-03 17:43:20.366 DEBUG: Loss 10: {'policy_loss': 0.0760499029314865, 'entropy_loss': -0.033447896130383015, 'vf_loss': 0.017245289930532294, 'total_loss': 0.04260200680110348, 'approx_kl': -0.05625447258353233, 'clip_fraction': 0.3776041716337204, 'grad_norm': 14.521126747131348}
2023-01-03 17:43:22.245 DEBUG: Taking gradient step
2023-01-03 17:43:24.168 DEBUG: Loss 11: {'policy_loss': -0.0041543629045852765, 'entropy_loss': -0.03313479200005531, 'vf_loss': 0.013743327755397484, 'total_loss': -0.03728915490464059, 'approx_kl': -0.05215238919481635, 'clip_fraction': 0.4140625, 'grad_norm': 22.6287784576416}
2023-01-03 17:43:26.060 DEBUG: Taking gradient step
2023-01-03 17:43:28.001 DEBUG: Loss 12: {'policy_loss': -0.039674918210332935, 'entropy_loss': -0.0353613318875432, 'vf_loss': 0.012645963382582231, 'total_loss': -0.07503625009787614, 'approx_kl': -0.06291341222822666, 'clip_fraction': 0.4479166716337204, 'grad_norm': 15.063215255737305}
2023-01-03 17:43:29.891 DEBUG: Taking gradient step
2023-01-03 17:43:31.846 DEBUG: Loss 13: {'policy_loss': -0.013999771781817744, 'entropy_loss': -0.0336753623560071, 'vf_loss': 0.013366693710724286, 'total_loss': -0.04767513413782484, 'approx_kl': -0.06063840538263321, 'clip_fraction': 0.4088541716337204, 'grad_norm': 22.37990951538086}
2023-01-03 17:43:33.729 DEBUG: Taking gradient step
2023-01-03 17:43:35.673 DEBUG: Loss 14: {'policy_loss': -0.002347792570009607, 'entropy_loss': -0.03307343740016222, 'vf_loss': 0.013331285318841275, 'total_loss': -0.03542122997017182, 'approx_kl': -0.06687761563807726, 'clip_fraction': 0.4114583358168602, 'grad_norm': 27.28426170349121}
2023-01-03 17:43:35.673 INFO: Optimization: policy loss=-0.002, vf loss=0.013, entropy loss=-0.033, total loss=-0.035, num steps=15
2023-01-03 17:43:35.674 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 17:43:37.383 INFO: Evaluation rollout: return=0.538 (0.0), episode length=6.0
2023-01-03 17:43:37.384 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 17:43:37.387 INFO: Iteration: 114/137, steps: 24624
2023-01-03 17:44:08.974 DEBUG: Atoms are too close
2023-01-03 17:44:09.249 DEBUG: Atoms are too close
2023-01-03 17:44:25.595 DEBUG: Atoms are too close
2023-01-03 17:44:25.598 DEBUG: Atoms are too close
2023-01-03 17:44:29.333 DEBUG: Atoms are too close
2023-01-03 17:44:33.213 INFO: Training rollout: return=-2.593 (6.3), episode length=5.8
2023-01-03 17:44:33.215 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 17:44:33.217 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-24624_train.pkl
2023-01-03 17:44:35.093 DEBUG: Taking gradient step
2023-01-03 17:44:37.010 DEBUG: Loss 0: {'policy_loss': 0.033764305990661866, 'entropy_loss': -0.03514222800731659, 'vf_loss': 0.02599977231130074, 'total_loss': -0.0013779220166547299, 'approx_kl': 3.1742578343596506e-08, 'clip_fraction': 0.0, 'grad_norm': 28.408119201660156}
2023-01-03 17:44:38.868 DEBUG: Taking gradient step
2023-01-03 17:44:40.785 DEBUG: Loss 1: {'policy_loss': -0.04276638455260606, 'entropy_loss': -0.034063749480992556, 'vf_loss': 0.02122813181515304, 'total_loss': -0.07683013403359862, 'approx_kl': -0.010278373723849654, 'clip_fraction': 0.02734375, 'grad_norm': 16.09699249267578}
2023-01-03 17:44:42.649 DEBUG: Taking gradient step
2023-01-03 17:44:44.555 DEBUG: Loss 2: {'policy_loss': -0.012493714690404598, 'entropy_loss': -0.035565188620239496, 'vf_loss': 0.023803985819268556, 'total_loss': -0.048058903310644094, 'approx_kl': -0.040000044740736485, 'clip_fraction': 0.2122395858168602, 'grad_norm': 29.03304100036621}
2023-01-03 17:44:46.425 DEBUG: Taking gradient step
2023-01-03 17:44:48.327 DEBUG: Loss 3: {'policy_loss': 0.03298103462722239, 'entropy_loss': -0.034674988593906164, 'vf_loss': 0.02285147668927468, 'total_loss': -0.0016939539666837727, 'approx_kl': -0.0510557908564806, 'clip_fraction': 0.3567708358168602, 'grad_norm': 24.046024322509766}
2023-01-03 17:44:50.176 DEBUG: Taking gradient step
2023-01-03 17:44:52.087 DEBUG: Loss 4: {'policy_loss': 0.033069418828378584, 'entropy_loss': -0.036836943589150906, 'vf_loss': 0.023021375248478047, 'total_loss': -0.0037675247607723214, 'approx_kl': -0.09794338000938296, 'clip_fraction': 0.38671875, 'grad_norm': 25.525625228881836}
2023-01-03 17:44:53.936 DEBUG: Taking gradient step
2023-01-03 17:44:55.845 DEBUG: Loss 5: {'policy_loss': 0.06498335555429602, 'entropy_loss': -0.03464776091277599, 'vf_loss': 0.023047349883264245, 'total_loss': 0.030335594641520018, 'approx_kl': -0.11198953073471785, 'clip_fraction': 0.43359375, 'grad_norm': 29.19435691833496}
2023-01-03 17:44:57.691 DEBUG: Taking gradient step
2023-01-03 17:44:59.599 DEBUG: Loss 6: {'policy_loss': 0.028810366109740852, 'entropy_loss': -0.035854754969477654, 'vf_loss': 0.021231711605327993, 'total_loss': -0.007044388859736801, 'approx_kl': -0.0908839050680399, 'clip_fraction': 0.4453125, 'grad_norm': 23.03901481628418}
2023-01-03 17:45:01.457 DEBUG: Taking gradient step
2023-01-03 17:45:03.358 DEBUG: Loss 7: {'policy_loss': 0.01084581145454841, 'entropy_loss': -0.03572356980293989, 'vf_loss': 0.020586741652222993, 'total_loss': -0.024877758348391482, 'approx_kl': -0.10067618079483509, 'clip_fraction': 0.40234375, 'grad_norm': 24.212438583374023}
2023-01-03 17:45:05.296 DEBUG: Taking gradient step
2023-01-03 17:45:07.203 DEBUG: Loss 8: {'policy_loss': 0.012016101744189232, 'entropy_loss': -0.037304962053895, 'vf_loss': 0.02159372021283619, 'total_loss': -0.025288860309705757, 'approx_kl': -0.08983760885894299, 'clip_fraction': 0.4127604216337204, 'grad_norm': 27.25066375732422}
2023-01-03 17:45:09.046 DEBUG: Taking gradient step
2023-01-03 17:45:10.948 DEBUG: Loss 9: {'policy_loss': 0.03164326947659387, 'entropy_loss': -0.03747170977294445, 'vf_loss': 0.02270138406451972, 'total_loss': -0.005828440296350583, 'approx_kl': -0.11676635779440403, 'clip_fraction': 0.4361979216337204, 'grad_norm': 25.859079360961914}
2023-01-03 17:45:12.794 DEBUG: Taking gradient step
2023-01-03 17:45:14.692 DEBUG: Loss 10: {'policy_loss': 0.13481186917211824, 'entropy_loss': -0.038023218512535095, 'vf_loss': 0.026562298224605964, 'total_loss': 0.09678865065958314, 'approx_kl': -0.11143888905644417, 'clip_fraction': 0.4752604216337204, 'grad_norm': 38.923091888427734}
2023-01-03 17:45:16.554 DEBUG: Taking gradient step
2023-01-03 17:45:18.447 DEBUG: Loss 11: {'policy_loss': 0.02184703449111898, 'entropy_loss': -0.03594872076064348, 'vf_loss': 0.0216598782763588, 'total_loss': -0.014101686269524502, 'approx_kl': -0.11743609979748726, 'clip_fraction': 0.4674479216337204, 'grad_norm': 25.97504425048828}
2023-01-03 17:45:20.303 DEBUG: Taking gradient step
2023-01-03 17:45:22.209 DEBUG: Loss 12: {'policy_loss': 0.05580325162110026, 'entropy_loss': -0.036534818820655346, 'vf_loss': 0.022319903274006885, 'total_loss': 0.019268432800444914, 'approx_kl': -0.15624935552477837, 'clip_fraction': 0.4739583358168602, 'grad_norm': 22.70712661743164}
2023-01-03 17:45:24.057 DEBUG: Taking gradient step
2023-01-03 17:45:25.968 DEBUG: Loss 13: {'policy_loss': 0.08956047531985437, 'entropy_loss': -0.036501554772257805, 'vf_loss': 0.025448369661501925, 'total_loss': 0.053058920547596554, 'approx_kl': -0.12525063753128052, 'clip_fraction': 0.5, 'grad_norm': 24.56143569946289}
2023-01-03 17:45:27.805 DEBUG: Taking gradient step
2023-01-03 17:45:29.702 DEBUG: Loss 14: {'policy_loss': 0.04333438565277498, 'entropy_loss': -0.03671859111636877, 'vf_loss': 0.020842944612830892, 'total_loss': 0.006615794536406216, 'approx_kl': -0.11472958605736494, 'clip_fraction': 0.4479166716337204, 'grad_norm': 27.5791015625}
2023-01-03 17:45:29.703 INFO: Optimization: policy loss=0.043, vf loss=0.021, entropy loss=-0.037, total loss=0.007, num steps=15
2023-01-03 17:45:29.704 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 17:45:31.420 INFO: Evaluation rollout: return=0.547 (0.0), episode length=6.0
2023-01-03 17:45:31.421 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 17:45:31.424 INFO: Iteration: 115/137, steps: 24840
2023-01-03 17:46:02.359 DEBUG: Atoms are too close
2023-01-03 17:46:24.243 DEBUG: There is a single atom floating around
2023-01-03 17:46:28.692 INFO: Training rollout: return=-1.213 (4.9), episode length=5.9
2023-01-03 17:46:28.693 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 17:46:28.697 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-24840_train.pkl
2023-01-03 17:46:30.576 DEBUG: Taking gradient step
2023-01-03 17:46:32.518 DEBUG: Loss 0: {'policy_loss': 0.016034509422230996, 'entropy_loss': -0.036485820543020964, 'vf_loss': 0.01444324175296298, 'total_loss': -0.020451311120789968, 'approx_kl': -6.274785846471786e-08, 'clip_fraction': 0.0, 'grad_norm': 20.01647186279297}
2023-01-03 17:46:34.406 DEBUG: Taking gradient step
2023-01-03 17:46:36.358 DEBUG: Loss 1: {'policy_loss': -0.00015401982541290993, 'entropy_loss': -0.04004030767828226, 'vf_loss': 0.014165483411953554, 'total_loss': -0.04019432750369517, 'approx_kl': -0.004044311470352113, 'clip_fraction': 0.1223958358168602, 'grad_norm': 22.077260971069336}
2023-01-03 17:46:38.242 DEBUG: Taking gradient step
2023-01-03 17:46:40.186 DEBUG: Loss 2: {'policy_loss': 0.020907853771487305, 'entropy_loss': -0.0365973562002182, 'vf_loss': 0.014123887741285451, 'total_loss': -0.0156895024287309, 'approx_kl': -0.03719329368323088, 'clip_fraction': 0.2786458358168602, 'grad_norm': 19.23090171813965}
2023-01-03 17:46:42.092 DEBUG: Taking gradient step
2023-01-03 17:46:44.026 DEBUG: Loss 3: {'policy_loss': -0.001789482662360075, 'entropy_loss': -0.037891609594225883, 'vf_loss': 0.012699054677350972, 'total_loss': -0.039681092256585955, 'approx_kl': -0.05896957800723612, 'clip_fraction': 0.37109375, 'grad_norm': 19.5523681640625}
2023-01-03 17:46:45.923 DEBUG: Taking gradient step
2023-01-03 17:46:47.853 DEBUG: Loss 4: {'policy_loss': 0.09106261582177141, 'entropy_loss': -0.036605258006602526, 'vf_loss': 0.016004944767544788, 'total_loss': 0.054457357815168896, 'approx_kl': -0.05536689446307719, 'clip_fraction': 0.3958333358168602, 'grad_norm': 28.4373722076416}
2023-01-03 17:46:49.739 DEBUG: Taking gradient step
2023-01-03 17:46:51.775 DEBUG: Loss 5: {'policy_loss': 0.07747014332848995, 'entropy_loss': -0.03749158978462219, 'vf_loss': 0.015726014922621167, 'total_loss': 0.03997855354386776, 'approx_kl': -0.0715758171863854, 'clip_fraction': 0.515625, 'grad_norm': 23.241355895996094}
2023-01-03 17:46:53.655 DEBUG: Taking gradient step
2023-01-03 17:46:55.584 DEBUG: Loss 6: {'policy_loss': 0.01118399110535966, 'entropy_loss': -0.037463377229869366, 'vf_loss': 0.01276185876686942, 'total_loss': -0.026279386124509703, 'approx_kl': -0.046806007623672485, 'clip_fraction': 0.4752604216337204, 'grad_norm': 15.725484848022461}
2023-01-03 17:46:57.469 DEBUG: Taking gradient step
2023-01-03 17:46:59.403 DEBUG: Loss 7: {'policy_loss': 0.023171790985781822, 'entropy_loss': -0.037970609962940216, 'vf_loss': 0.014226157414794455, 'total_loss': -0.014798818977158396, 'approx_kl': -0.07053244719281793, 'clip_fraction': 0.4661458358168602, 'grad_norm': 19.375545501708984}
2023-01-03 17:47:01.280 DEBUG: Taking gradient step
2023-01-03 17:47:03.212 DEBUG: Loss 8: {'policy_loss': 0.009427014263594914, 'entropy_loss': -0.037524184212088585, 'vf_loss': 0.01377793894222288, 'total_loss': -0.028097169948493674, 'approx_kl': -0.1064677070826292, 'clip_fraction': 0.50390625, 'grad_norm': 15.702320098876953}
2023-01-03 17:47:05.082 DEBUG: Taking gradient step
2023-01-03 17:47:07.002 DEBUG: Loss 9: {'policy_loss': 0.05160678691328269, 'entropy_loss': -0.03934639785438776, 'vf_loss': 0.014666879328776073, 'total_loss': 0.012260389058894927, 'approx_kl': -0.10622847708873451, 'clip_fraction': 0.4856770932674408, 'grad_norm': 18.385040283203125}
2023-01-03 17:47:08.878 DEBUG: Taking gradient step
2023-01-03 17:47:10.794 DEBUG: Loss 10: {'policy_loss': -0.02159316223776321, 'entropy_loss': -0.039159443229436874, 'vf_loss': 0.011730617396592737, 'total_loss': -0.060752605467200085, 'approx_kl': -0.08142814598977566, 'clip_fraction': 0.44921875, 'grad_norm': 20.723968505859375}
2023-01-03 17:47:12.680 DEBUG: Taking gradient step
2023-01-03 17:47:14.594 DEBUG: Loss 11: {'policy_loss': 0.009183780927418353, 'entropy_loss': -0.040564208291471004, 'vf_loss': 0.012296537019855646, 'total_loss': -0.03138042736405265, 'approx_kl': -0.10134654864668846, 'clip_fraction': 0.5143229216337204, 'grad_norm': 25.595176696777344}
2023-01-03 17:47:16.451 DEBUG: Taking gradient step
2023-01-03 17:47:18.372 DEBUG: Loss 12: {'policy_loss': 0.07544138528201604, 'entropy_loss': -0.03900264389812946, 'vf_loss': 0.014905929250213033, 'total_loss': 0.03643874138388658, 'approx_kl': -0.12601878866553307, 'clip_fraction': 0.5559895932674408, 'grad_norm': 36.26869201660156}
2023-01-03 17:47:20.254 DEBUG: Taking gradient step
2023-01-03 17:47:22.184 DEBUG: Loss 13: {'policy_loss': 0.014910264575282627, 'entropy_loss': -0.04047164134681225, 'vf_loss': 0.012031834457993267, 'total_loss': -0.025561376771529618, 'approx_kl': -0.1164215449243784, 'clip_fraction': 0.5546875, 'grad_norm': 20.795734405517578}
2023-01-03 17:47:24.049 DEBUG: Taking gradient step
2023-01-03 17:47:25.967 DEBUG: Loss 14: {'policy_loss': 0.03458479851678527, 'entropy_loss': -0.03786748740822077, 'vf_loss': 0.013069395831990363, 'total_loss': -0.0032826888914355007, 'approx_kl': -0.1187995932996273, 'clip_fraction': 0.5638020932674408, 'grad_norm': 18.610511779785156}
2023-01-03 17:47:25.967 INFO: Optimization: policy loss=0.035, vf loss=0.013, entropy loss=-0.038, total loss=-0.003, num steps=15
2023-01-03 17:47:25.968 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 17:47:27.686 INFO: Evaluation rollout: return=0.548 (0.0), episode length=6.0
2023-01-03 17:47:27.687 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 17:47:27.690 INFO: Iteration: 116/137, steps: 25056
2023-01-03 17:47:44.508 DEBUG: Atoms are too close
2023-01-03 17:48:24.900 INFO: Training rollout: return=0.087 (2.2), episode length=6.0
2023-01-03 17:48:24.902 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 17:48:24.905 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-25056_train.pkl
2023-01-03 17:48:26.827 DEBUG: Taking gradient step
2023-01-03 17:48:28.787 DEBUG: Loss 0: {'policy_loss': -0.015565473860756709, 'entropy_loss': -0.037361280992627144, 'vf_loss': 0.004202228930110267, 'total_loss': -0.05292675485338384, 'approx_kl': -2.266218501745243e-08, 'clip_fraction': 0.0, 'grad_norm': 19.19814109802246}
2023-01-03 17:48:30.687 DEBUG: Taking gradient step
2023-01-03 17:48:32.640 DEBUG: Loss 1: {'policy_loss': -0.0063063471436692956, 'entropy_loss': -0.04083198122680187, 'vf_loss': 0.005234715965137891, 'total_loss': -0.04713832837047117, 'approx_kl': 0.0035401531495153904, 'clip_fraction': 0.24609375, 'grad_norm': 9.6402587890625}
2023-01-03 17:48:34.536 DEBUG: Taking gradient step
2023-01-03 17:48:36.519 DEBUG: Loss 2: {'policy_loss': 0.02133508493342727, 'entropy_loss': -0.03788950201123953, 'vf_loss': 0.005542926549246187, 'total_loss': -0.01655441707781226, 'approx_kl': -0.003758501261472702, 'clip_fraction': 0.36328125, 'grad_norm': 9.470841407775879}
2023-01-03 17:48:38.367 DEBUG: Taking gradient step
2023-01-03 17:48:40.260 DEBUG: Loss 3: {'policy_loss': -0.029450484640388123, 'entropy_loss': -0.036609044298529625, 'vf_loss': 0.004076560433971655, 'total_loss': -0.06605952893891776, 'approx_kl': -0.017216715728864074, 'clip_fraction': 0.3216145858168602, 'grad_norm': 12.45529556274414}
2023-01-03 17:48:42.115 DEBUG: Taking gradient step
2023-01-03 17:48:44.017 DEBUG: Loss 4: {'policy_loss': 0.013659075960100533, 'entropy_loss': -0.03973264526575804, 'vf_loss': 0.005384754351173222, 'total_loss': -0.026073569305657504, 'approx_kl': -0.04010076238773763, 'clip_fraction': 0.3528645858168602, 'grad_norm': 20.071720123291016}
2023-01-03 17:48:45.892 DEBUG: Taking gradient step
2023-01-03 17:48:47.797 DEBUG: Loss 5: {'policy_loss': -0.04356364578949212, 'entropy_loss': -0.040678275749087334, 'vf_loss': 0.003842313855217679, 'total_loss': -0.08424192153857946, 'approx_kl': -0.060583826154470444, 'clip_fraction': 0.3958333358168602, 'grad_norm': 4.851709842681885}
2023-01-03 17:48:49.670 DEBUG: Taking gradient step
2023-01-03 17:48:51.569 DEBUG: Loss 6: {'policy_loss': -0.04092613648780863, 'entropy_loss': -0.03817668929696083, 'vf_loss': 0.0037290500972970123, 'total_loss': -0.07910282578476946, 'approx_kl': -0.046744988299906254, 'clip_fraction': 0.4049479216337204, 'grad_norm': 5.730021953582764}
2023-01-03 17:48:53.437 DEBUG: Taking gradient step
2023-01-03 17:48:55.329 DEBUG: Loss 7: {'policy_loss': -0.013598445663887456, 'entropy_loss': -0.03958252631127834, 'vf_loss': 0.003617815007132126, 'total_loss': -0.0531809719751658, 'approx_kl': -0.06396522372961044, 'clip_fraction': 0.3580729216337204, 'grad_norm': 16.66597557067871}
2023-01-03 17:48:57.185 DEBUG: Taking gradient step
2023-01-03 17:48:59.087 DEBUG: Loss 8: {'policy_loss': 0.01715654060103346, 'entropy_loss': -0.03928410820662975, 'vf_loss': 0.003922573424360809, 'total_loss': -0.02212756760559629, 'approx_kl': -0.06891492009162903, 'clip_fraction': 0.4505208358168602, 'grad_norm': 19.664581298828125}
2023-01-03 17:49:00.945 DEBUG: Taking gradient step
2023-01-03 17:49:02.848 DEBUG: Loss 9: {'policy_loss': 0.0038448310531611074, 'entropy_loss': -0.03830890543758869, 'vf_loss': 0.003889908274337459, 'total_loss': -0.034464074384427584, 'approx_kl': -0.06651774793863297, 'clip_fraction': 0.44921875, 'grad_norm': 17.6843318939209}
2023-01-03 17:49:04.716 DEBUG: Taking gradient step
2023-01-03 17:49:06.620 DEBUG: Loss 10: {'policy_loss': -0.013193522148590835, 'entropy_loss': -0.03839133307337761, 'vf_loss': 0.0038535256585337948, 'total_loss': -0.05158485522196845, 'approx_kl': -0.06398467998951674, 'clip_fraction': 0.375, 'grad_norm': 11.992323875427246}
2023-01-03 17:49:08.485 DEBUG: Taking gradient step
2023-01-03 17:49:10.380 DEBUG: Loss 11: {'policy_loss': -0.025733987367955718, 'entropy_loss': -0.03918422758579254, 'vf_loss': 0.003444254908059781, 'total_loss': -0.06491821495374826, 'approx_kl': -0.049250791780650616, 'clip_fraction': 0.3385416679084301, 'grad_norm': 7.898341655731201}
2023-01-03 17:49:12.243 DEBUG: Taking gradient step
2023-01-03 17:49:14.139 DEBUG: Loss 12: {'policy_loss': -0.017590929271253785, 'entropy_loss': -0.040882814675569534, 'vf_loss': 0.0046265739492976085, 'total_loss': -0.05847374394682332, 'approx_kl': -0.07247310690581799, 'clip_fraction': 0.3984375, 'grad_norm': 5.966310501098633}
2023-01-03 17:49:16.005 DEBUG: Taking gradient step
2023-01-03 17:49:17.909 DEBUG: Loss 13: {'policy_loss': 0.02259822416128738, 'entropy_loss': -0.03982352185994387, 'vf_loss': 0.003954830496477089, 'total_loss': -0.017225297698656487, 'approx_kl': -0.10144252423197031, 'clip_fraction': 0.515625, 'grad_norm': 21.141929626464844}
2023-01-03 17:49:19.766 DEBUG: Taking gradient step
2023-01-03 17:49:21.673 DEBUG: Loss 14: {'policy_loss': -0.009880469882990375, 'entropy_loss': -0.04213212337344885, 'vf_loss': 0.004230737060826376, 'total_loss': -0.05201259325643923, 'approx_kl': -0.08960236795246601, 'clip_fraction': 0.4205729216337204, 'grad_norm': 21.74386978149414}
2023-01-03 17:49:21.673 INFO: Optimization: policy loss=-0.010, vf loss=0.004, entropy loss=-0.042, total loss=-0.052, num steps=15
2023-01-03 17:49:21.674 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 17:49:23.407 INFO: Evaluation rollout: return=0.534 (0.0), episode length=6.0
2023-01-03 17:49:23.409 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 17:49:23.413 INFO: Iteration: 117/137, steps: 25272
2023-01-03 17:49:34.426 DEBUG: Atoms are too close
2023-01-03 17:49:38.367 DEBUG: Atoms are too close
2023-01-03 17:49:41.009 DEBUG: Atoms are too close
2023-01-03 17:50:20.008 INFO: Training rollout: return=-1.218 (4.9), episode length=5.9
2023-01-03 17:50:20.009 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 17:50:20.011 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-25272_train.pkl
2023-01-03 17:50:21.878 DEBUG: Taking gradient step
2023-01-03 17:50:23.766 DEBUG: Loss 0: {'policy_loss': 0.04113328425135047, 'entropy_loss': -0.04033148102462292, 'vf_loss': 0.015354502153163975, 'total_loss': 0.0008018032267275502, 'approx_kl': -1.4202669262886047e-08, 'clip_fraction': 0.0, 'grad_norm': 23.40858268737793}
2023-01-03 17:50:25.612 DEBUG: Taking gradient step
2023-01-03 17:50:27.494 DEBUG: Loss 1: {'policy_loss': -0.024924897634093283, 'entropy_loss': -0.04056153632700443, 'vf_loss': 0.013650393830092243, 'total_loss': -0.06548643396109771, 'approx_kl': 0.006138962227851152, 'clip_fraction': 0.033854166977107525, 'grad_norm': 13.025775909423828}
2023-01-03 17:50:29.339 DEBUG: Taking gradient step
2023-01-03 17:50:31.223 DEBUG: Loss 2: {'policy_loss': -0.01719030076131489, 'entropy_loss': -0.03810345055535436, 'vf_loss': 0.01321921367578979, 'total_loss': -0.05529375131666925, 'approx_kl': -0.015131406369619071, 'clip_fraction': 0.1627604179084301, 'grad_norm': 18.10105323791504}
2023-01-03 17:50:33.059 DEBUG: Taking gradient step
2023-01-03 17:50:34.942 DEBUG: Loss 3: {'policy_loss': -0.003963497413166317, 'entropy_loss': -0.041431620717048645, 'vf_loss': 0.0123828697472598, 'total_loss': -0.04539511813021496, 'approx_kl': -0.014819195261225104, 'clip_fraction': 0.2513020858168602, 'grad_norm': 23.63945198059082}
2023-01-03 17:50:36.791 DEBUG: Taking gradient step
2023-01-03 17:50:38.664 DEBUG: Loss 4: {'policy_loss': 0.008344325566087302, 'entropy_loss': -0.04149874206632376, 'vf_loss': 0.012227048588893182, 'total_loss': -0.03315441650023646, 'approx_kl': -0.025233214139007032, 'clip_fraction': 0.2643229216337204, 'grad_norm': 27.1981258392334}
2023-01-03 17:50:40.513 DEBUG: Taking gradient step
2023-01-03 17:50:42.401 DEBUG: Loss 5: {'policy_loss': 0.13446123800104537, 'entropy_loss': -0.04066668450832367, 'vf_loss': 0.016652767566538614, 'total_loss': 0.0937945534927217, 'approx_kl': -0.03599367570132017, 'clip_fraction': 0.2317708358168602, 'grad_norm': 46.13914489746094}
2023-01-03 17:50:44.243 DEBUG: Taking gradient step
2023-01-03 17:50:46.132 DEBUG: Loss 6: {'policy_loss': 0.04660690728848022, 'entropy_loss': -0.04164073243737221, 'vf_loss': 0.014247378673664806, 'total_loss': 0.004966174851108014, 'approx_kl': -0.05168364942073822, 'clip_fraction': 0.2369791716337204, 'grad_norm': 22.377275466918945}
2023-01-03 17:50:47.974 DEBUG: Taking gradient step
2023-01-03 17:50:49.856 DEBUG: Loss 7: {'policy_loss': 0.06442430194125516, 'entropy_loss': -0.0412980318069458, 'vf_loss': 0.014761719955301095, 'total_loss': 0.02312627013430936, 'approx_kl': -0.04118352895602584, 'clip_fraction': 0.2395833358168602, 'grad_norm': 32.82271957397461}
2023-01-03 17:50:51.705 DEBUG: Taking gradient step
2023-01-03 17:50:53.599 DEBUG: Loss 8: {'policy_loss': -0.013704568096299559, 'entropy_loss': -0.04001769982278347, 'vf_loss': 0.011668640036672649, 'total_loss': -0.05372226791908303, 'approx_kl': -0.03364373929798603, 'clip_fraction': 0.2513020858168602, 'grad_norm': 23.267860412597656}
2023-01-03 17:50:55.455 DEBUG: Taking gradient step
2023-01-03 17:50:57.358 DEBUG: Loss 9: {'policy_loss': 0.010318419871175873, 'entropy_loss': -0.040865691378712654, 'vf_loss': 0.013049003835705673, 'total_loss': -0.03054727150753678, 'approx_kl': -0.07273991964757442, 'clip_fraction': 0.30078125, 'grad_norm': 23.952125549316406}
2023-01-03 17:50:59.224 DEBUG: Taking gradient step
2023-01-03 17:51:01.117 DEBUG: Loss 10: {'policy_loss': -0.009339492907038643, 'entropy_loss': -0.040463341400027275, 'vf_loss': 0.012228173595730885, 'total_loss': -0.04980283430706592, 'approx_kl': -0.051295978017151356, 'clip_fraction': 0.2942708358168602, 'grad_norm': 23.900474548339844}
2023-01-03 17:51:02.984 DEBUG: Taking gradient step
2023-01-03 17:51:04.975 DEBUG: Loss 11: {'policy_loss': 0.01638517195441691, 'entropy_loss': -0.04101814795285463, 'vf_loss': 0.013557552001676569, 'total_loss': -0.024632975998437723, 'approx_kl': -0.0587193863466382, 'clip_fraction': 0.29296875, 'grad_norm': 36.88509750366211}
2023-01-03 17:51:06.827 DEBUG: Taking gradient step
2023-01-03 17:51:08.711 DEBUG: Loss 12: {'policy_loss': -0.02609262587676009, 'entropy_loss': -0.04044225439429283, 'vf_loss': 0.012723998021325046, 'total_loss': -0.06653488027105292, 'approx_kl': -0.0688199088908732, 'clip_fraction': 0.3098958358168602, 'grad_norm': 13.977765083312988}
2023-01-03 17:51:10.559 DEBUG: Taking gradient step
2023-01-03 17:51:12.449 DEBUG: Loss 13: {'policy_loss': -0.02781362227304681, 'entropy_loss': -0.04055758286267519, 'vf_loss': 0.012693504295157611, 'total_loss': -0.068371205135722, 'approx_kl': -0.06354950275272131, 'clip_fraction': 0.2552083358168602, 'grad_norm': 28.83200454711914}
2023-01-03 17:51:14.296 DEBUG: Taking gradient step
2023-01-03 17:51:16.173 DEBUG: Loss 14: {'policy_loss': 0.0009877461285232886, 'entropy_loss': -0.04161618836224079, 'vf_loss': 0.013087478122459044, 'total_loss': -0.040628442233717504, 'approx_kl': -0.0669147246517241, 'clip_fraction': 0.3111979216337204, 'grad_norm': 36.69588088989258}
2023-01-03 17:51:16.174 INFO: Optimization: policy loss=0.001, vf loss=0.013, entropy loss=-0.042, total loss=-0.041, num steps=15
2023-01-03 17:51:16.175 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 17:51:17.861 INFO: Evaluation rollout: return=0.537 (0.0), episode length=6.0
2023-01-03 17:51:17.862 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 17:51:17.864 INFO: Iteration: 118/137, steps: 25488
2023-01-03 17:52:10.037 DEBUG: Atoms are too close
2023-01-03 17:52:15.118 INFO: Training rollout: return=0.020 (2.6), episode length=6.0
2023-01-03 17:52:15.119 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 17:52:15.122 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-25488_train.pkl
2023-01-03 17:52:16.997 DEBUG: Taking gradient step
2023-01-03 17:52:18.903 DEBUG: Loss 0: {'policy_loss': 0.02242828168826867, 'entropy_loss': -0.04062323085963726, 'vf_loss': 0.004254427267849542, 'total_loss': -0.018194949171368595, 'approx_kl': -6.558063148087712e-09, 'clip_fraction': 0.0, 'grad_norm': 14.574304580688477}
2023-01-03 17:52:20.768 DEBUG: Taking gradient step
2023-01-03 17:52:22.671 DEBUG: Loss 1: {'policy_loss': -0.022833449272506932, 'entropy_loss': -0.04131844453513622, 'vf_loss': 0.0034556075605565997, 'total_loss': -0.06415189380764316, 'approx_kl': 0.000823902664706111, 'clip_fraction': 0.08333333395421505, 'grad_norm': 13.260089874267578}
2023-01-03 17:52:24.529 DEBUG: Taking gradient step
2023-01-03 17:52:26.426 DEBUG: Loss 2: {'policy_loss': -0.00518353014913225, 'entropy_loss': -0.040368120186030865, 'vf_loss': 0.0043015383614971765, 'total_loss': -0.04555165033516312, 'approx_kl': -0.019785853393841535, 'clip_fraction': 0.1588541679084301, 'grad_norm': 13.617053985595703}
2023-01-03 17:52:28.281 DEBUG: Taking gradient step
2023-01-03 17:52:30.171 DEBUG: Loss 3: {'policy_loss': -0.041260507839732605, 'entropy_loss': -0.04282153211534023, 'vf_loss': 0.003495873716879102, 'total_loss': -0.08408203995507284, 'approx_kl': -0.0190574259031564, 'clip_fraction': 0.3463541716337204, 'grad_norm': 6.1602463722229}
2023-01-03 17:52:32.025 DEBUG: Taking gradient step
2023-01-03 17:52:33.923 DEBUG: Loss 4: {'policy_loss': 0.0302093145812009, 'entropy_loss': -0.04236311558634043, 'vf_loss': 0.005729657231122556, 'total_loss': -0.012153801005139533, 'approx_kl': -0.02629153337329626, 'clip_fraction': 0.3671875, 'grad_norm': 6.925588130950928}
2023-01-03 17:52:35.776 DEBUG: Taking gradient step
2023-01-03 17:52:37.662 DEBUG: Loss 5: {'policy_loss': -0.002875893793139357, 'entropy_loss': -0.0407732455059886, 'vf_loss': 0.004319765966933357, 'total_loss': -0.043649139299127955, 'approx_kl': -0.035502600483596325, 'clip_fraction': 0.3606770858168602, 'grad_norm': 13.62713623046875}
2023-01-03 17:52:39.518 DEBUG: Taking gradient step
2023-01-03 17:52:41.420 DEBUG: Loss 6: {'policy_loss': 0.009127745856725225, 'entropy_loss': -0.03948242496699095, 'vf_loss': 0.004656767528883636, 'total_loss': -0.030354679110265716, 'approx_kl': -0.051485512871295214, 'clip_fraction': 0.3684895858168602, 'grad_norm': 25.057756423950195}
2023-01-03 17:52:43.269 DEBUG: Taking gradient step
2023-01-03 17:52:45.162 DEBUG: Loss 7: {'policy_loss': -0.007071613005363329, 'entropy_loss': -0.04167733248323202, 'vf_loss': 0.004256317669207312, 'total_loss': -0.04874894548859535, 'approx_kl': -0.03126887558028102, 'clip_fraction': 0.4453125, 'grad_norm': 4.2260565757751465}
2023-01-03 17:52:47.015 DEBUG: Taking gradient step
2023-01-03 17:52:48.911 DEBUG: Loss 8: {'policy_loss': -0.04885938088278019, 'entropy_loss': -0.041017317213118076, 'vf_loss': 0.0034148705037465674, 'total_loss': -0.08987669809589827, 'approx_kl': -0.07455626782029867, 'clip_fraction': 0.4049479216337204, 'grad_norm': 4.485307216644287}
2023-01-03 17:52:50.767 DEBUG: Taking gradient step
2023-01-03 17:52:52.753 DEBUG: Loss 9: {'policy_loss': -0.06210945599593465, 'entropy_loss': -0.04057918302714825, 'vf_loss': 0.0034037569607434106, 'total_loss': -0.1026886390230829, 'approx_kl': -0.08332806755788624, 'clip_fraction': 0.33984375, 'grad_norm': 5.466117858886719}
2023-01-03 17:52:54.619 DEBUG: Taking gradient step
2023-01-03 17:52:56.512 DEBUG: Loss 10: {'policy_loss': -0.009282339442471053, 'entropy_loss': -0.03880372690036893, 'vf_loss': 0.005036186573825391, 'total_loss': -0.04808606634283999, 'approx_kl': -0.075050781480968, 'clip_fraction': 0.3463541716337204, 'grad_norm': 4.243844985961914}
2023-01-03 17:52:58.360 DEBUG: Taking gradient step
2023-01-03 17:53:00.256 DEBUG: Loss 11: {'policy_loss': -0.056284002055560126, 'entropy_loss': -0.04053330235183239, 'vf_loss': 0.0033288198950897174, 'total_loss': -0.09681730440739252, 'approx_kl': -0.06513717211782932, 'clip_fraction': 0.3841145858168602, 'grad_norm': 4.811655044555664}
2023-01-03 17:53:02.124 DEBUG: Taking gradient step
2023-01-03 17:53:04.018 DEBUG: Loss 12: {'policy_loss': 0.03522745643373473, 'entropy_loss': -0.04148357640951872, 'vf_loss': 0.005390562340777761, 'total_loss': -0.006256119975784, 'approx_kl': -0.05733159324154258, 'clip_fraction': 0.3528645858168602, 'grad_norm': 10.5404691696167}
2023-01-03 17:53:05.876 DEBUG: Taking gradient step
2023-01-03 17:53:07.767 DEBUG: Loss 13: {'policy_loss': -0.057487512020456114, 'entropy_loss': -0.0407177172601223, 'vf_loss': 0.00326778154487344, 'total_loss': -0.09820522928057841, 'approx_kl': -0.0771911796182394, 'clip_fraction': 0.3645833358168602, 'grad_norm': 6.700326919555664}
2023-01-03 17:53:09.618 DEBUG: Taking gradient step
2023-01-03 17:53:11.508 DEBUG: Loss 14: {'policy_loss': -0.01448139984419479, 'entropy_loss': -0.04078258853405714, 'vf_loss': 0.003823660608699787, 'total_loss': -0.05526398837825193, 'approx_kl': -0.08129752054810524, 'clip_fraction': 0.3971354216337204, 'grad_norm': 8.719306945800781}
2023-01-03 17:53:11.508 INFO: Optimization: policy loss=-0.014, vf loss=0.004, entropy loss=-0.041, total loss=-0.055, num steps=15
2023-01-03 17:53:11.509 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 17:53:13.209 INFO: Evaluation rollout: return=0.482 (0.0), episode length=6.0
2023-01-03 17:53:13.210 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 17:53:13.213 INFO: Iteration: 119/137, steps: 25704
2023-01-03 17:54:10.951 INFO: Training rollout: return=-1.044 (4.2), episode length=6.0
2023-01-03 17:54:10.953 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 17:54:10.956 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-25704_train.pkl
2023-01-03 17:54:12.862 DEBUG: Taking gradient step
2023-01-03 17:54:14.769 DEBUG: Loss 0: {'policy_loss': 0.05375881956687318, 'entropy_loss': -0.04165832698345184, 'vf_loss': 0.017304924533242, 'total_loss': 0.012100492583421336, 'approx_kl': -1.4474306198053455e-08, 'clip_fraction': 0.0, 'grad_norm': 18.70569610595703}
2023-01-03 17:54:16.644 DEBUG: Taking gradient step
2023-01-03 17:54:18.559 DEBUG: Loss 1: {'policy_loss': 0.0687030163462889, 'entropy_loss': -0.04241502936929464, 'vf_loss': 0.01664696917617299, 'total_loss': 0.026287986976994276, 'approx_kl': -0.011143077164888382, 'clip_fraction': 0.1510416679084301, 'grad_norm': 24.287784576416016}
2023-01-03 17:54:20.422 DEBUG: Taking gradient step
2023-01-03 17:54:22.338 DEBUG: Loss 2: {'policy_loss': 0.09036961583857014, 'entropy_loss': -0.040862131863832474, 'vf_loss': 0.017857527936716446, 'total_loss': 0.04950748397473767, 'approx_kl': -0.027383356355130672, 'clip_fraction': 0.3802083358168602, 'grad_norm': 25.451812744140625}
2023-01-03 17:54:24.201 DEBUG: Taking gradient step
2023-01-03 17:54:26.112 DEBUG: Loss 3: {'policy_loss': -0.0036944585721288767, 'entropy_loss': -0.04196934588253498, 'vf_loss': 0.013764999488811958, 'total_loss': -0.04566380445466386, 'approx_kl': -0.06999428570270538, 'clip_fraction': 0.4127604216337204, 'grad_norm': 22.054033279418945}
2023-01-03 17:54:27.982 DEBUG: Taking gradient step
2023-01-03 17:54:29.886 DEBUG: Loss 4: {'policy_loss': -0.02331959667057807, 'entropy_loss': -0.042067110538482666, 'vf_loss': 0.013303544469177427, 'total_loss': -0.06538670720906073, 'approx_kl': -0.0239912960678339, 'clip_fraction': 0.3346354216337204, 'grad_norm': 19.77136993408203}
2023-01-03 17:54:31.755 DEBUG: Taking gradient step
2023-01-03 17:54:33.658 DEBUG: Loss 5: {'policy_loss': -0.0029191490427494865, 'entropy_loss': -0.04126145504415035, 'vf_loss': 0.014616033553139736, 'total_loss': -0.04418060408689985, 'approx_kl': -0.07789314864203334, 'clip_fraction': 0.3606770858168602, 'grad_norm': 14.562914848327637}
2023-01-03 17:54:35.527 DEBUG: Taking gradient step
2023-01-03 17:54:37.520 DEBUG: Loss 6: {'policy_loss': -0.010575164476363141, 'entropy_loss': -0.042713045142591, 'vf_loss': 0.01393423325548333, 'total_loss': -0.05328820961895414, 'approx_kl': -0.0987017173320055, 'clip_fraction': 0.3567708358168602, 'grad_norm': 21.87648582458496}
2023-01-03 17:54:39.375 DEBUG: Taking gradient step
2023-01-03 17:54:41.288 DEBUG: Loss 7: {'policy_loss': 0.028755315258086667, 'entropy_loss': -0.041302742436528206, 'vf_loss': 0.01507110566519613, 'total_loss': -0.01254742717844154, 'approx_kl': -0.09497647546231747, 'clip_fraction': 0.37890625, 'grad_norm': 22.834938049316406}
2023-01-03 17:54:43.164 DEBUG: Taking gradient step
2023-01-03 17:54:45.073 DEBUG: Loss 8: {'policy_loss': 0.027165134469068267, 'entropy_loss': -0.04231793060898781, 'vf_loss': 0.014257656806600794, 'total_loss': -0.01515279613991954, 'approx_kl': -0.11070136912167072, 'clip_fraction': 0.3854166716337204, 'grad_norm': 34.39389419555664}
2023-01-03 17:54:46.936 DEBUG: Taking gradient step
2023-01-03 17:54:48.845 DEBUG: Loss 9: {'policy_loss': 0.04933844111382325, 'entropy_loss': -0.04242991842329502, 'vf_loss': 0.01590252448265405, 'total_loss': 0.006908522690528232, 'approx_kl': -0.11151608265936375, 'clip_fraction': 0.3776041716337204, 'grad_norm': 27.188472747802734}
2023-01-03 17:54:50.709 DEBUG: Taking gradient step
2023-01-03 17:54:52.610 DEBUG: Loss 10: {'policy_loss': -0.018935929478044174, 'entropy_loss': -0.04080191161483526, 'vf_loss': 0.013867769740696853, 'total_loss': -0.059737841092879426, 'approx_kl': -0.09773150831460953, 'clip_fraction': 0.32421875, 'grad_norm': 19.1693172454834}
2023-01-03 17:54:54.464 DEBUG: Taking gradient step
2023-01-03 17:54:56.363 DEBUG: Loss 11: {'policy_loss': 0.014955898976345541, 'entropy_loss': -0.041117558255791664, 'vf_loss': 0.014752054490290344, 'total_loss': -0.026161659279446123, 'approx_kl': -0.11311883293092251, 'clip_fraction': 0.4114583358168602, 'grad_norm': 22.296005249023438}
2023-01-03 17:54:58.217 DEBUG: Taking gradient step
2023-01-03 17:55:00.130 DEBUG: Loss 12: {'policy_loss': 0.03266173693031953, 'entropy_loss': -0.04117562621831894, 'vf_loss': 0.014253329073752428, 'total_loss': -0.008513889287999402, 'approx_kl': -0.10900111310184002, 'clip_fraction': 0.4036458358168602, 'grad_norm': 35.655181884765625}
2023-01-03 17:55:02.000 DEBUG: Taking gradient step
2023-01-03 17:55:03.909 DEBUG: Loss 13: {'policy_loss': 0.01652006413972338, 'entropy_loss': -0.04303702712059021, 'vf_loss': 0.013945668878602789, 'total_loss': -0.02651696298086683, 'approx_kl': -0.12101146578788757, 'clip_fraction': 0.3723958358168602, 'grad_norm': 25.147851943969727}
2023-01-03 17:55:05.767 DEBUG: Taking gradient step
2023-01-03 17:55:07.679 DEBUG: Loss 14: {'policy_loss': 0.025929335972004787, 'entropy_loss': -0.04137699771672487, 'vf_loss': 0.01465549463052318, 'total_loss': -0.015447661744720086, 'approx_kl': -0.12619187496602535, 'clip_fraction': 0.4713541716337204, 'grad_norm': 22.76352310180664}
2023-01-03 17:55:07.679 INFO: Optimization: policy loss=0.026, vf loss=0.015, entropy loss=-0.041, total loss=-0.015, num steps=15
2023-01-03 17:55:07.680 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 17:55:09.370 INFO: Evaluation rollout: return=0.447 (0.0), episode length=6.0
2023-01-03 17:55:09.371 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 17:55:09.374 INFO: Iteration: 120/137, steps: 25920
2023-01-03 17:55:22.584 DEBUG: Atoms are too close
2023-01-03 17:55:37.552 DEBUG: Atoms are too close
2023-01-03 17:56:06.527 INFO: Training rollout: return=-1.254 (4.9), episode length=5.9
2023-01-03 17:56:06.529 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 17:56:06.532 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-25920_train.pkl
2023-01-03 17:56:08.388 DEBUG: Taking gradient step
2023-01-03 17:56:10.271 DEBUG: Loss 0: {'policy_loss': -0.03707290037677418, 'entropy_loss': -0.04220570344477892, 'vf_loss': 0.012277533554738075, 'total_loss': -0.0792786038215531, 'approx_kl': 9.3869555684023e-08, 'clip_fraction': 0.0, 'grad_norm': 12.754809379577637}
2023-01-03 17:56:12.118 DEBUG: Taking gradient step
2023-01-03 17:56:14.005 DEBUG: Loss 1: {'policy_loss': -0.041451231105843964, 'entropy_loss': -0.03968592407181859, 'vf_loss': 0.011639717091818045, 'total_loss': -0.08113715517766255, 'approx_kl': -0.004963945131748915, 'clip_fraction': 0.1015625, 'grad_norm': 14.763018608093262}
2023-01-03 17:56:15.836 DEBUG: Taking gradient step
2023-01-03 17:56:17.715 DEBUG: Loss 2: {'policy_loss': 0.02578383469511455, 'entropy_loss': -0.041471428237855434, 'vf_loss': 0.01481064313666702, 'total_loss': -0.015687593542740883, 'approx_kl': -0.013745320204179734, 'clip_fraction': 0.2838541716337204, 'grad_norm': 22.133628845214844}
2023-01-03 17:56:19.555 DEBUG: Taking gradient step
2023-01-03 17:56:21.429 DEBUG: Loss 3: {'policy_loss': -0.040986064000877655, 'entropy_loss': -0.04243829846382141, 'vf_loss': 0.011622862772277073, 'total_loss': -0.08342436246469906, 'approx_kl': -0.0278487098403275, 'clip_fraction': 0.3033854216337204, 'grad_norm': 13.1004056930542}
2023-01-03 17:56:23.268 DEBUG: Taking gradient step
2023-01-03 17:56:25.147 DEBUG: Loss 4: {'policy_loss': 0.07955727278348518, 'entropy_loss': -0.040348976850509644, 'vf_loss': 0.016885593097091145, 'total_loss': 0.03920829593297552, 'approx_kl': -0.023344526067376137, 'clip_fraction': 0.24609375, 'grad_norm': 18.568384170532227}
2023-01-03 17:56:27.076 DEBUG: Taking gradient step
2023-01-03 17:56:28.949 DEBUG: Loss 5: {'policy_loss': -0.03229775645255466, 'entropy_loss': -0.04213025700300932, 'vf_loss': 0.011909900603642887, 'total_loss': -0.07442801345556398, 'approx_kl': -0.0389095563441515, 'clip_fraction': 0.2630208358168602, 'grad_norm': 11.525657653808594}
2023-01-03 17:56:30.783 DEBUG: Taking gradient step
2023-01-03 17:56:32.656 DEBUG: Loss 6: {'policy_loss': 0.011882145702342192, 'entropy_loss': -0.04262163024395704, 'vf_loss': 0.015099089088210754, 'total_loss': -0.030739484541614855, 'approx_kl': -0.03642208268865943, 'clip_fraction': 0.2890625, 'grad_norm': 16.229345321655273}
2023-01-03 17:56:34.503 DEBUG: Taking gradient step
2023-01-03 17:56:36.374 DEBUG: Loss 7: {'policy_loss': 0.05104197881774218, 'entropy_loss': -0.0403895378112793, 'vf_loss': 0.01629611802586087, 'total_loss': 0.01065244100646287, 'approx_kl': -0.039977661333978176, 'clip_fraction': 0.3072916716337204, 'grad_norm': 18.881956100463867}
2023-01-03 17:56:38.211 DEBUG: Taking gradient step
2023-01-03 17:56:40.112 DEBUG: Loss 8: {'policy_loss': 0.02350281736597322, 'entropy_loss': -0.0427015321329236, 'vf_loss': 0.014898423549698184, 'total_loss': -0.01919871476695037, 'approx_kl': -0.046436731703579426, 'clip_fraction': 0.2838541716337204, 'grad_norm': 10.302151679992676}
2023-01-03 17:56:41.971 DEBUG: Taking gradient step
2023-01-03 17:56:43.865 DEBUG: Loss 9: {'policy_loss': -0.006820582203305704, 'entropy_loss': -0.042774719186127186, 'vf_loss': 0.013154526244152535, 'total_loss': -0.04959530138943289, 'approx_kl': -0.06038956600241363, 'clip_fraction': 0.2942708358168602, 'grad_norm': 11.267087936401367}
2023-01-03 17:56:45.735 DEBUG: Taking gradient step
2023-01-03 17:56:47.656 DEBUG: Loss 10: {'policy_loss': -0.01826663845057615, 'entropy_loss': -0.04089688416570425, 'vf_loss': 0.012467762130730071, 'total_loss': -0.0591635226162804, 'approx_kl': -0.0717085050418973, 'clip_fraction': 0.3802083358168602, 'grad_norm': 12.647933959960938}
2023-01-03 17:56:49.534 DEBUG: Taking gradient step
2023-01-03 17:56:51.430 DEBUG: Loss 11: {'policy_loss': 0.0561986335884076, 'entropy_loss': -0.04112104419618845, 'vf_loss': 0.015938221229896736, 'total_loss': 0.015077589392219148, 'approx_kl': -0.06522572413086891, 'clip_fraction': 0.3229166716337204, 'grad_norm': 26.197776794433594}
2023-01-03 17:56:53.299 DEBUG: Taking gradient step
2023-01-03 17:56:55.197 DEBUG: Loss 12: {'policy_loss': -0.03366986778088775, 'entropy_loss': -0.041486818343400955, 'vf_loss': 0.012159481017144884, 'total_loss': -0.07515668612428869, 'approx_kl': -0.09654854517430067, 'clip_fraction': 0.3515625, 'grad_norm': 11.606514930725098}
2023-01-03 17:56:57.065 DEBUG: Taking gradient step
2023-01-03 17:56:58.970 DEBUG: Loss 13: {'policy_loss': 0.004707934826948552, 'entropy_loss': -0.042315855622291565, 'vf_loss': 0.01476930907203422, 'total_loss': -0.03760792079534302, 'approx_kl': -0.07689182367175817, 'clip_fraction': 0.3763020858168602, 'grad_norm': 16.207523345947266}
2023-01-03 17:57:00.836 DEBUG: Taking gradient step
2023-01-03 17:57:02.743 DEBUG: Loss 14: {'policy_loss': 0.0014377582114284242, 'entropy_loss': -0.041517061181366444, 'vf_loss': 0.013549135769789885, 'total_loss': -0.04007930296993802, 'approx_kl': -0.07328989636152983, 'clip_fraction': 0.44140625, 'grad_norm': 22.772184371948242}
2023-01-03 17:57:02.743 INFO: Optimization: policy loss=0.001, vf loss=0.014, entropy loss=-0.042, total loss=-0.040, num steps=15
2023-01-03 17:57:02.744 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 17:57:04.462 INFO: Evaluation rollout: return=0.535 (0.0), episode length=6.0
2023-01-03 17:57:04.463 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 17:57:04.466 DEBUG: Deleting old model: runs/CH3NO_dna/models/CH3NO_dna_run-1_steps-23976.model
2023-01-03 17:57:04.473 DEBUG: Saving model: runs/CH3NO_dna/models/CH3NO_dna_run-1_steps-26136.model
2023-01-03 17:57:04.519 INFO: Iteration: 121/137, steps: 26136
2023-01-03 17:57:14.077 DEBUG: Atoms are too close
2023-01-03 17:57:15.219 DEBUG: Atoms are too close
2023-01-03 17:57:21.426 DEBUG: There is a single atom floating around
2023-01-03 17:57:40.359 DEBUG: Atoms are too close
2023-01-03 17:57:57.166 DEBUG: Atoms are too close
2023-01-03 17:58:00.465 INFO: Training rollout: return=-3.178 (6.4), episode length=5.9
2023-01-03 17:58:00.466 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 17:58:00.470 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-26136_train.pkl
2023-01-03 17:58:02.328 DEBUG: Taking gradient step
2023-01-03 17:58:04.208 DEBUG: Loss 0: {'policy_loss': 0.03441726713380333, 'entropy_loss': -0.041184731759130955, 'vf_loss': 0.031547898469583904, 'total_loss': -0.006767464625327624, 'approx_kl': 3.748573362827301e-08, 'clip_fraction': 0.0, 'grad_norm': 18.955001831054688}
2023-01-03 17:58:06.030 DEBUG: Taking gradient step
2023-01-03 17:58:07.975 DEBUG: Loss 1: {'policy_loss': 0.0023049837292464653, 'entropy_loss': -0.04175172001123428, 'vf_loss': 0.029150571261030173, 'total_loss': -0.03944673628198782, 'approx_kl': -0.010602865600958467, 'clip_fraction': 0.11067708395421505, 'grad_norm': 17.088773727416992}
2023-01-03 17:58:09.793 DEBUG: Taking gradient step
2023-01-03 17:58:11.669 DEBUG: Loss 2: {'policy_loss': 0.021765770374469456, 'entropy_loss': -0.04295389447361231, 'vf_loss': 0.03026831155713488, 'total_loss': -0.02118812409914285, 'approx_kl': -0.005786738591268659, 'clip_fraction': 0.2591145858168602, 'grad_norm': 24.67507553100586}
2023-01-03 17:58:13.494 DEBUG: Taking gradient step
2023-01-03 17:58:15.376 DEBUG: Loss 3: {'policy_loss': -0.0016866007556594204, 'entropy_loss': -0.04382152948528528, 'vf_loss': 0.02931453006975605, 'total_loss': -0.0455081302409447, 'approx_kl': -0.027364003472030163, 'clip_fraction': 0.3359375, 'grad_norm': 15.996983528137207}
2023-01-03 17:58:17.224 DEBUG: Taking gradient step
2023-01-03 17:58:19.106 DEBUG: Loss 4: {'policy_loss': 0.0370954513101897, 'entropy_loss': -0.04079183842986822, 'vf_loss': 0.02999070784339556, 'total_loss': -0.0036963871196785195, 'approx_kl': -0.031207723077386618, 'clip_fraction': 0.3020833358168602, 'grad_norm': 19.523365020751953}
2023-01-03 17:58:20.953 DEBUG: Taking gradient step
2023-01-03 17:58:22.856 DEBUG: Loss 5: {'policy_loss': 0.04397966485146957, 'entropy_loss': -0.04283248260617256, 'vf_loss': 0.02928042946847704, 'total_loss': 0.0011471822452970085, 'approx_kl': -0.05334902694448829, 'clip_fraction': 0.34375, 'grad_norm': 14.231717109680176}
2023-01-03 17:58:24.704 DEBUG: Taking gradient step
2023-01-03 17:58:26.599 DEBUG: Loss 6: {'policy_loss': -0.012710788073240588, 'entropy_loss': -0.0426090219989419, 'vf_loss': 0.02647727349559778, 'total_loss': -0.055319810072182486, 'approx_kl': -0.03589615132659674, 'clip_fraction': 0.3385416716337204, 'grad_norm': 18.001550674438477}
2023-01-03 17:58:28.446 DEBUG: Taking gradient step
2023-01-03 17:58:30.339 DEBUG: Loss 7: {'policy_loss': 0.026038223332761103, 'entropy_loss': -0.04270871728658676, 'vf_loss': 0.027018629372748664, 'total_loss': -0.016670493953825662, 'approx_kl': -0.033729327376931906, 'clip_fraction': 0.3125, 'grad_norm': 17.535158157348633}
2023-01-03 17:58:32.195 DEBUG: Taking gradient step
2023-01-03 17:58:34.080 DEBUG: Loss 8: {'policy_loss': 0.09294819640217468, 'entropy_loss': -0.04172615148127079, 'vf_loss': 0.028087324274084537, 'total_loss': 0.05122204492090389, 'approx_kl': -0.02702671173028648, 'clip_fraction': 0.34375, 'grad_norm': 19.64031410217285}
2023-01-03 17:58:35.935 DEBUG: Taking gradient step
2023-01-03 17:58:37.814 DEBUG: Loss 9: {'policy_loss': 0.015291146002506334, 'entropy_loss': -0.04216288309544325, 'vf_loss': 0.024962205663218842, 'total_loss': -0.026871737092936915, 'approx_kl': -0.008822774980217218, 'clip_fraction': 0.3763020858168602, 'grad_norm': 15.975361824035645}
2023-01-03 17:58:39.656 DEBUG: Taking gradient step
2023-01-03 17:58:41.539 DEBUG: Loss 10: {'policy_loss': 0.03826172671817578, 'entropy_loss': -0.04331870563328266, 'vf_loss': 0.02562972485428619, 'total_loss': -0.005056978915106883, 'approx_kl': -0.01517788227647543, 'clip_fraction': 0.390625, 'grad_norm': 18.28260040283203}
2023-01-03 17:58:43.382 DEBUG: Taking gradient step
2023-01-03 17:58:45.272 DEBUG: Loss 11: {'policy_loss': 0.1279547489677336, 'entropy_loss': -0.04261056147515774, 'vf_loss': 0.028158178601740663, 'total_loss': 0.08534418749257586, 'approx_kl': -0.07559009175747633, 'clip_fraction': 0.42578125, 'grad_norm': 21.04174041748047}
2023-01-03 17:58:47.123 DEBUG: Taking gradient step
2023-01-03 17:58:49.001 DEBUG: Loss 12: {'policy_loss': 0.051586064327308084, 'entropy_loss': -0.04251148831099272, 'vf_loss': 0.026776322847630447, 'total_loss': 0.00907457601631536, 'approx_kl': -0.0534226568415761, 'clip_fraction': 0.38671875, 'grad_norm': 23.852567672729492}
2023-01-03 17:58:50.858 DEBUG: Taking gradient step
2023-01-03 17:58:52.742 DEBUG: Loss 13: {'policy_loss': 0.13341255719160777, 'entropy_loss': -0.04101539123803377, 'vf_loss': 0.02683352095653508, 'total_loss': 0.09239716595357403, 'approx_kl': -0.0468243615468964, 'clip_fraction': 0.4505208432674408, 'grad_norm': 27.449430465698242}
2023-01-03 17:58:54.657 DEBUG: Taking gradient step
2023-01-03 17:58:56.553 DEBUG: Loss 14: {'policy_loss': 0.1526540967199862, 'entropy_loss': -0.043196612037718296, 'vf_loss': 0.02858869517303269, 'total_loss': 0.1094574846822679, 'approx_kl': -0.05252819741144776, 'clip_fraction': 0.43359375, 'grad_norm': 29.11469268798828}
2023-01-03 17:58:56.554 INFO: Optimization: policy loss=0.153, vf loss=0.029, entropy loss=-0.043, total loss=0.109, num steps=15
2023-01-03 17:58:56.555 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 17:58:58.265 INFO: Evaluation rollout: return=0.540 (0.0), episode length=6.0
2023-01-03 17:58:58.266 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 17:58:58.269 INFO: Iteration: 122/137, steps: 26352
2023-01-03 17:59:29.076 DEBUG: Atoms are too close
2023-01-03 17:59:33.663 DEBUG: Atoms are too close
2023-01-03 17:59:50.688 DEBUG: Atoms are too close
2023-01-03 17:59:54.841 INFO: Training rollout: return=-0.862 (4.4), episode length=5.9
2023-01-03 17:59:54.843 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 17:59:54.846 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-26352_train.pkl
2023-01-03 17:59:56.704 DEBUG: Taking gradient step
2023-01-03 17:59:58.577 DEBUG: Loss 0: {'policy_loss': 0.05916691803166603, 'entropy_loss': -0.04229769576340914, 'vf_loss': 0.014273552034678757, 'total_loss': 0.016869222268256892, 'approx_kl': -5.3357016582822325e-09, 'clip_fraction': 0.0, 'grad_norm': 25.549211502075195}
2023-01-03 18:00:00.401 DEBUG: Taking gradient step
2023-01-03 18:00:02.283 DEBUG: Loss 1: {'policy_loss': 0.01064709869982647, 'entropy_loss': -0.041975959204137325, 'vf_loss': 0.013225143915546184, 'total_loss': -0.03132886050431086, 'approx_kl': 0.0015047146007418633, 'clip_fraction': 0.07942708395421505, 'grad_norm': 26.495943069458008}
2023-01-03 18:00:04.115 DEBUG: Taking gradient step
2023-01-03 18:00:05.999 DEBUG: Loss 2: {'policy_loss': 0.021815801953297874, 'entropy_loss': -0.04328859969973564, 'vf_loss': 0.012486677422758528, 'total_loss': -0.021472797746437768, 'approx_kl': -0.00754582928493619, 'clip_fraction': 0.3645833358168602, 'grad_norm': 34.33977127075195}
2023-01-03 18:00:07.834 DEBUG: Taking gradient step
2023-01-03 18:00:09.717 DEBUG: Loss 3: {'policy_loss': 0.11004853925589961, 'entropy_loss': -0.04282223153859377, 'vf_loss': 0.01393591319398849, 'total_loss': 0.06722630771730584, 'approx_kl': -0.03720309119671583, 'clip_fraction': 0.3984375, 'grad_norm': 40.43659973144531}
2023-01-03 18:00:11.551 DEBUG: Taking gradient step
2023-01-03 18:00:13.435 DEBUG: Loss 4: {'policy_loss': 0.0871430770582858, 'entropy_loss': -0.03920065239071846, 'vf_loss': 0.011935845559892603, 'total_loss': 0.047942424667567346, 'approx_kl': -0.03908683359622955, 'clip_fraction': 0.4375, 'grad_norm': 31.42801284790039}
2023-01-03 18:00:15.273 DEBUG: Taking gradient step
2023-01-03 18:00:17.154 DEBUG: Loss 5: {'policy_loss': 0.14540412680461529, 'entropy_loss': -0.038907287642359734, 'vf_loss': 0.012280801066721202, 'total_loss': 0.10649683916225558, 'approx_kl': -0.000523177906870842, 'clip_fraction': 0.4348958358168602, 'grad_norm': 42.4940299987793}
2023-01-03 18:00:19.001 DEBUG: Taking gradient step
2023-01-03 18:00:20.894 DEBUG: Loss 6: {'policy_loss': 0.12238339505267064, 'entropy_loss': -0.03815949149429798, 'vf_loss': 0.010033423158017299, 'total_loss': 0.08422390355837266, 'approx_kl': -0.03637427929788828, 'clip_fraction': 0.5221354216337204, 'grad_norm': 44.761600494384766}
2023-01-03 18:00:22.751 DEBUG: Taking gradient step
2023-01-03 18:00:24.636 DEBUG: Loss 7: {'policy_loss': 0.1256807750642043, 'entropy_loss': -0.03813333762809634, 'vf_loss': 0.011950366932748733, 'total_loss': 0.08754743743610796, 'approx_kl': -0.0043592192232608795, 'clip_fraction': 0.4856770932674408, 'grad_norm': 45.043121337890625}
2023-01-03 18:00:26.480 DEBUG: Taking gradient step
2023-01-03 18:00:28.362 DEBUG: Loss 8: {'policy_loss': 0.0795908166466539, 'entropy_loss': -0.037873778492212296, 'vf_loss': 0.009904585718042511, 'total_loss': 0.04171703815444161, 'approx_kl': -0.015541673172265291, 'clip_fraction': 0.41015625, 'grad_norm': 36.29057693481445}
2023-01-03 18:00:30.205 DEBUG: Taking gradient step
2023-01-03 18:00:32.093 DEBUG: Loss 9: {'policy_loss': 0.0964101068095482, 'entropy_loss': -0.039443956688046455, 'vf_loss': 0.011539295576242036, 'total_loss': 0.05696615012150174, 'approx_kl': 0.007116388529539108, 'clip_fraction': 0.4140625, 'grad_norm': 47.938682556152344}
2023-01-03 18:00:33.948 DEBUG: Taking gradient step
2023-01-03 18:00:35.842 DEBUG: Loss 10: {'policy_loss': 0.05899122043213445, 'entropy_loss': -0.03918796218931675, 'vf_loss': 0.0094981693950058, 'total_loss': 0.019803258242817715, 'approx_kl': -0.0109407939016819, 'clip_fraction': 0.3880208358168602, 'grad_norm': 29.817901611328125}
2023-01-03 18:00:37.699 DEBUG: Taking gradient step
2023-01-03 18:00:39.673 DEBUG: Loss 11: {'policy_loss': 0.10133727060017607, 'entropy_loss': -0.037891730666160583, 'vf_loss': 0.009656262332069855, 'total_loss': 0.06344553993401549, 'approx_kl': -0.03247280791401863, 'clip_fraction': 0.4973958432674408, 'grad_norm': 42.51845932006836}
2023-01-03 18:00:41.529 DEBUG: Taking gradient step
2023-01-03 18:00:43.422 DEBUG: Loss 12: {'policy_loss': 0.12712141053934123, 'entropy_loss': -0.03808240778744221, 'vf_loss': 0.010377504805286448, 'total_loss': 0.08903900275189901, 'approx_kl': -0.0613630972802639, 'clip_fraction': 0.5065104216337204, 'grad_norm': 39.77669906616211}
2023-01-03 18:00:45.259 DEBUG: Taking gradient step
2023-01-03 18:00:47.142 DEBUG: Loss 13: {'policy_loss': 0.0650943877703287, 'entropy_loss': -0.03952501900494099, 'vf_loss': 0.010581239783570586, 'total_loss': 0.025569368765387707, 'approx_kl': -0.014500625431537628, 'clip_fraction': 0.44921875, 'grad_norm': 36.75007629394531}
2023-01-03 18:00:49.000 DEBUG: Taking gradient step
2023-01-03 18:00:50.880 DEBUG: Loss 14: {'policy_loss': 0.10642378277889165, 'entropy_loss': -0.038090516813099384, 'vf_loss': 0.01052061898428431, 'total_loss': 0.06833326596579227, 'approx_kl': -0.006849575787782669, 'clip_fraction': 0.49609375, 'grad_norm': 39.056156158447266}
2023-01-03 18:00:50.880 INFO: Optimization: policy loss=0.106, vf loss=0.011, entropy loss=-0.038, total loss=0.068, num steps=15
2023-01-03 18:00:50.881 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 18:00:52.601 INFO: Evaluation rollout: return=0.557 (0.0), episode length=6.0
2023-01-03 18:00:52.602 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 18:00:52.607 INFO: Iteration: 123/137, steps: 26568
2023-01-03 18:01:11.438 DEBUG: Atoms are too close
2023-01-03 18:01:20.798 DEBUG: Atoms are too close
2023-01-03 18:01:23.385 DEBUG: Atoms are too close
2023-01-03 18:01:23.891 DEBUG: Atoms are too close
2023-01-03 18:01:49.019 INFO: Training rollout: return=-1.749 (5.6), episode length=5.9
2023-01-03 18:01:49.020 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 18:01:49.025 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-26568_train.pkl
2023-01-03 18:01:50.870 DEBUG: Taking gradient step
2023-01-03 18:01:52.741 DEBUG: Loss 0: {'policy_loss': -0.03810960104797491, 'entropy_loss': -0.037379722110927105, 'vf_loss': 0.014719311496353605, 'total_loss': -0.07548932315890201, 'approx_kl': 5.2146788220852613e-08, 'clip_fraction': 0.0, 'grad_norm': 17.129989624023438}
2023-01-03 18:01:54.580 DEBUG: Taking gradient step
2023-01-03 18:01:56.464 DEBUG: Loss 1: {'policy_loss': -0.034581056897028756, 'entropy_loss': -0.036871411837637424, 'vf_loss': 0.015484943890913781, 'total_loss': -0.07145246873466618, 'approx_kl': 0.004611923824995756, 'clip_fraction': 0.057291666977107525, 'grad_norm': 16.104677200317383}
2023-01-03 18:01:58.300 DEBUG: Taking gradient step
2023-01-03 18:02:00.195 DEBUG: Loss 2: {'policy_loss': 0.03685891190226168, 'entropy_loss': -0.036401690915226936, 'vf_loss': 0.018585331326168374, 'total_loss': 0.0004572209870347538, 'approx_kl': -0.0010197535157203674, 'clip_fraction': 0.1770833358168602, 'grad_norm': 25.810422897338867}
2023-01-03 18:02:02.036 DEBUG: Taking gradient step
2023-01-03 18:02:03.934 DEBUG: Loss 3: {'policy_loss': 0.010033150402385206, 'entropy_loss': -0.0377306011505425, 'vf_loss': 0.018411666872093866, 'total_loss': -0.02769745074815729, 'approx_kl': -2.8667040169239044e-05, 'clip_fraction': 0.21875, 'grad_norm': 17.22812843322754}
2023-01-03 18:02:05.767 DEBUG: Taking gradient step
2023-01-03 18:02:07.632 DEBUG: Loss 4: {'policy_loss': -0.009192594497007774, 'entropy_loss': -0.038337173871695995, 'vf_loss': 0.01665232506517316, 'total_loss': -0.04752976836870377, 'approx_kl': -0.008314581820741296, 'clip_fraction': 0.2994791716337204, 'grad_norm': 21.560426712036133}
2023-01-03 18:02:09.459 DEBUG: Taking gradient step
2023-01-03 18:02:11.330 DEBUG: Loss 5: {'policy_loss': 0.04266087628549296, 'entropy_loss': -0.03700567036867142, 'vf_loss': 0.017747729747115665, 'total_loss': 0.005655205916821546, 'approx_kl': -0.019014117307960987, 'clip_fraction': 0.3346354216337204, 'grad_norm': 34.82219314575195}
2023-01-03 18:02:13.145 DEBUG: Taking gradient step
2023-01-03 18:02:15.012 DEBUG: Loss 6: {'policy_loss': -0.025786561179038475, 'entropy_loss': -0.037917590234428644, 'vf_loss': 0.015051235559026521, 'total_loss': -0.06370415141346712, 'approx_kl': -0.018543705577030778, 'clip_fraction': 0.2786458358168602, 'grad_norm': 20.747255325317383}
2023-01-03 18:02:16.848 DEBUG: Taking gradient step
2023-01-03 18:02:18.717 DEBUG: Loss 7: {'policy_loss': -0.04354216180674931, 'entropy_loss': -0.03607895551249385, 'vf_loss': 0.01473352334135572, 'total_loss': -0.07962111731924315, 'approx_kl': -0.025030014105141163, 'clip_fraction': 0.26953125, 'grad_norm': 17.350513458251953}
2023-01-03 18:02:20.615 DEBUG: Taking gradient step
2023-01-03 18:02:22.481 DEBUG: Loss 8: {'policy_loss': -0.024673322556546154, 'entropy_loss': -0.035888153593987226, 'vf_loss': 0.015613410264833521, 'total_loss': -0.06056147615053338, 'approx_kl': -0.03179811965674162, 'clip_fraction': 0.2122395858168602, 'grad_norm': 20.85689353942871}
2023-01-03 18:02:24.318 DEBUG: Taking gradient step
2023-01-03 18:02:26.181 DEBUG: Loss 9: {'policy_loss': -0.048906488381353835, 'entropy_loss': -0.0356262749992311, 'vf_loss': 0.014263344009553073, 'total_loss': -0.08453276338058494, 'approx_kl': -0.01289888541214168, 'clip_fraction': 0.2330729216337204, 'grad_norm': 16.092498779296875}
2023-01-03 18:02:28.013 DEBUG: Taking gradient step
2023-01-03 18:02:29.881 DEBUG: Loss 10: {'policy_loss': 0.006372918494706999, 'entropy_loss': -0.03885302133858204, 'vf_loss': 0.016992961170888873, 'total_loss': -0.032480102843875036, 'approx_kl': -0.039072973653674126, 'clip_fraction': 0.2083333358168602, 'grad_norm': 18.56844711303711}
2023-01-03 18:02:31.709 DEBUG: Taking gradient step
2023-01-03 18:02:33.586 DEBUG: Loss 11: {'policy_loss': -0.01313822808248118, 'entropy_loss': -0.03924141265451908, 'vf_loss': 0.016030738020506658, 'total_loss': -0.05237964073700026, 'approx_kl': -0.03156199643854052, 'clip_fraction': 0.21223958395421505, 'grad_norm': 17.53861427307129}
2023-01-03 18:02:35.412 DEBUG: Taking gradient step
2023-01-03 18:02:37.290 DEBUG: Loss 12: {'policy_loss': 0.018361197866501956, 'entropy_loss': -0.03577477764338255, 'vf_loss': 0.016550350468325113, 'total_loss': -0.017413579776880593, 'approx_kl': -0.03341319755418226, 'clip_fraction': 0.28515625, 'grad_norm': 24.201202392578125}
2023-01-03 18:02:39.128 DEBUG: Taking gradient step
2023-01-03 18:02:40.999 DEBUG: Loss 13: {'policy_loss': 0.050769767458176254, 'entropy_loss': -0.03677341854199767, 'vf_loss': 0.019070814167614206, 'total_loss': 0.013996348916178583, 'approx_kl': -0.05413644015789032, 'clip_fraction': 0.3177083358168602, 'grad_norm': 31.450496673583984}
2023-01-03 18:02:42.827 DEBUG: Taking gradient step
2023-01-03 18:02:44.708 DEBUG: Loss 14: {'policy_loss': 0.0010094849657587383, 'entropy_loss': -0.036861153319478035, 'vf_loss': 0.017260421096842418, 'total_loss': -0.0358516683537193, 'approx_kl': -0.0402804259210825, 'clip_fraction': 0.3294270858168602, 'grad_norm': 22.047607421875}
2023-01-03 18:02:44.709 INFO: Optimization: policy loss=0.001, vf loss=0.017, entropy loss=-0.037, total loss=-0.036, num steps=15
2023-01-03 18:02:44.709 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 18:02:46.410 INFO: Evaluation rollout: return=0.496 (0.0), episode length=6.0
2023-01-03 18:02:46.411 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 18:02:46.414 INFO: Iteration: 124/137, steps: 26784
2023-01-03 18:02:55.177 DEBUG: Atoms are too close
2023-01-03 18:03:44.156 INFO: Training rollout: return=-0.802 (4.3), episode length=5.9
2023-01-03 18:03:44.158 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 18:03:44.161 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-26784_train.pkl
2023-01-03 18:03:46.021 DEBUG: Taking gradient step
2023-01-03 18:03:47.902 DEBUG: Loss 0: {'policy_loss': -0.00631479967835871, 'entropy_loss': -0.03751335106790066, 'vf_loss': 0.010670603923325932, 'total_loss': -0.04382815074625937, 'approx_kl': -2.5533761771612262e-08, 'clip_fraction': 0.0, 'grad_norm': 18.87191390991211}
2023-01-03 18:03:49.758 DEBUG: Taking gradient step
2023-01-03 18:03:51.645 DEBUG: Loss 1: {'policy_loss': -0.009300077462949793, 'entropy_loss': -0.036961973644793034, 'vf_loss': 0.00994388206552902, 'total_loss': -0.04626205110774283, 'approx_kl': -0.02798329433426261, 'clip_fraction': 0.125, 'grad_norm': 21.51376724243164}
2023-01-03 18:03:53.498 DEBUG: Taking gradient step
2023-01-03 18:03:55.382 DEBUG: Loss 2: {'policy_loss': -0.004837042742403069, 'entropy_loss': -0.039242301136255264, 'vf_loss': 0.009068626478452333, 'total_loss': -0.04407934387865834, 'approx_kl': -0.054539861623197794, 'clip_fraction': 0.34765625, 'grad_norm': 29.6102294921875}
2023-01-03 18:03:57.229 DEBUG: Taking gradient step
2023-01-03 18:03:59.125 DEBUG: Loss 3: {'policy_loss': 0.20859929571807795, 'entropy_loss': -0.03842726442962885, 'vf_loss': 0.012268367986667058, 'total_loss': 0.1701720312884491, 'approx_kl': -0.06336811557412148, 'clip_fraction': 0.4244791716337204, 'grad_norm': 94.06868743896484}
2023-01-03 18:04:00.980 DEBUG: Taking gradient step
2023-01-03 18:04:02.953 DEBUG: Loss 4: {'policy_loss': 0.02089763631793455, 'entropy_loss': -0.03718887781724334, 'vf_loss': 0.00909978721867153, 'total_loss': -0.01629124149930878, 'approx_kl': -0.07654715562239289, 'clip_fraction': 0.4479166716337204, 'grad_norm': 37.43867111206055}
2023-01-03 18:04:04.798 DEBUG: Taking gradient step
2023-01-03 18:04:06.682 DEBUG: Loss 5: {'policy_loss': 0.031139809920374923, 'entropy_loss': -0.036848838441073895, 'vf_loss': 0.010178433368261314, 'total_loss': -0.0057090285206989715, 'approx_kl': -0.08890824113041162, 'clip_fraction': 0.4361979216337204, 'grad_norm': 32.06884765625}
2023-01-03 18:04:08.510 DEBUG: Taking gradient step
2023-01-03 18:04:10.393 DEBUG: Loss 6: {'policy_loss': 0.01899580985253163, 'entropy_loss': -0.038498166017234325, 'vf_loss': 0.00958260851279654, 'total_loss': -0.019502356164702694, 'approx_kl': -0.09037380665540695, 'clip_fraction': 0.36328125, 'grad_norm': 30.54497718811035}
2023-01-03 18:04:12.229 DEBUG: Taking gradient step
2023-01-03 18:04:14.110 DEBUG: Loss 7: {'policy_loss': 0.06381392981665826, 'entropy_loss': -0.03808818198740482, 'vf_loss': 0.010246436998393487, 'total_loss': 0.025725747829253433, 'approx_kl': -0.08350721118040383, 'clip_fraction': 0.3932291716337204, 'grad_norm': 56.4662971496582}
2023-01-03 18:04:15.959 DEBUG: Taking gradient step
2023-01-03 18:04:17.833 DEBUG: Loss 8: {'policy_loss': 0.04119430085496671, 'entropy_loss': -0.0370947765186429, 'vf_loss': 0.00998517223523535, 'total_loss': 0.004099524336323806, 'approx_kl': -0.10370223596692085, 'clip_fraction': 0.4765625, 'grad_norm': 34.695308685302734}
2023-01-03 18:04:19.679 DEBUG: Taking gradient step
2023-01-03 18:04:21.562 DEBUG: Loss 9: {'policy_loss': 0.0157181683577044, 'entropy_loss': -0.036341254599392414, 'vf_loss': 0.009191008789734025, 'total_loss': -0.020623086241688016, 'approx_kl': -0.0845735662151128, 'clip_fraction': 0.5455729216337204, 'grad_norm': 35.63656997680664}
2023-01-03 18:04:23.408 DEBUG: Taking gradient step
2023-01-03 18:04:25.292 DEBUG: Loss 10: {'policy_loss': 0.0635003407332734, 'entropy_loss': -0.03624002914875746, 'vf_loss': 0.009905378912406554, 'total_loss': 0.027260311584515952, 'approx_kl': -0.12566210143268108, 'clip_fraction': 0.5794270932674408, 'grad_norm': 49.20225143432617}
2023-01-03 18:04:27.129 DEBUG: Taking gradient step
2023-01-03 18:04:29.002 DEBUG: Loss 11: {'policy_loss': 0.04435982418759148, 'entropy_loss': -0.03700404427945614, 'vf_loss': 0.009185242131056988, 'total_loss': 0.007355779908135351, 'approx_kl': -0.09942404227331281, 'clip_fraction': 0.546875, 'grad_norm': 43.527008056640625}
2023-01-03 18:04:30.851 DEBUG: Taking gradient step
2023-01-03 18:04:32.725 DEBUG: Loss 12: {'policy_loss': 0.09312345416522946, 'entropy_loss': -0.03718128893524408, 'vf_loss': 0.010567218345884484, 'total_loss': 0.05594216522998538, 'approx_kl': -0.1098965723067522, 'clip_fraction': 0.5065104216337204, 'grad_norm': 53.55341339111328}
2023-01-03 18:04:34.568 DEBUG: Taking gradient step
2023-01-03 18:04:36.450 DEBUG: Loss 13: {'policy_loss': 0.06399741471318365, 'entropy_loss': -0.03928855620324612, 'vf_loss': 0.010113517588769095, 'total_loss': 0.02470885850993754, 'approx_kl': -0.11755671724677086, 'clip_fraction': 0.5078125, 'grad_norm': 34.04151153564453}
2023-01-03 18:04:38.277 DEBUG: Taking gradient step
2023-01-03 18:04:40.149 DEBUG: Loss 14: {'policy_loss': 0.039693778842475776, 'entropy_loss': -0.038306811824440956, 'vf_loss': 0.009889185014950484, 'total_loss': 0.001386967018034823, 'approx_kl': -0.16368143446743488, 'clip_fraction': 0.4856770932674408, 'grad_norm': 29.72264862060547}
2023-01-03 18:04:40.150 INFO: Optimization: policy loss=0.040, vf loss=0.010, entropy loss=-0.038, total loss=0.001, num steps=15
2023-01-03 18:04:40.151 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 18:04:41.912 INFO: Evaluation rollout: return=0.491 (0.0), episode length=6.0
2023-01-03 18:04:41.913 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 18:04:41.916 INFO: Iteration: 125/137, steps: 27000
2023-01-03 18:04:52.979 DEBUG: Atoms are too close
2023-01-03 18:05:13.712 DEBUG: Atoms are too close
2023-01-03 18:05:39.484 INFO: Training rollout: return=-1.592 (5.2), episode length=5.9
2023-01-03 18:05:39.485 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 18:05:39.489 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-27000_train.pkl
2023-01-03 18:05:41.357 DEBUG: Taking gradient step
2023-01-03 18:05:43.234 DEBUG: Loss 0: {'policy_loss': -0.00427675322779125, 'entropy_loss': -0.039086111821234226, 'vf_loss': 0.0162428542651305, 'total_loss': -0.04336286504902548, 'approx_kl': -7.67565022097294e-08, 'clip_fraction': 0.0, 'grad_norm': 17.123233795166016}
2023-01-03 18:05:45.076 DEBUG: Taking gradient step
2023-01-03 18:05:47.041 DEBUG: Loss 1: {'policy_loss': 0.016484711885171185, 'entropy_loss': -0.03817063104361296, 'vf_loss': 0.01630433210364403, 'total_loss': -0.02168591915844177, 'approx_kl': -0.005283323815092444, 'clip_fraction': 0.1927083358168602, 'grad_norm': 20.958932876586914}
2023-01-03 18:05:48.877 DEBUG: Taking gradient step
2023-01-03 18:05:50.761 DEBUG: Loss 2: {'policy_loss': 0.09456603973350279, 'entropy_loss': -0.03979227086529136, 'vf_loss': 0.01806600602051351, 'total_loss': 0.05477376886821144, 'approx_kl': -0.022384769981727004, 'clip_fraction': 0.2109375, 'grad_norm': 24.408668518066406}
2023-01-03 18:05:52.607 DEBUG: Taking gradient step
2023-01-03 18:05:54.491 DEBUG: Loss 3: {'policy_loss': 0.08865275726948801, 'entropy_loss': -0.0382866570726037, 'vf_loss': 0.017484388092832055, 'total_loss': 0.050366100196884304, 'approx_kl': -0.027126022381708026, 'clip_fraction': 0.2486979216337204, 'grad_norm': 31.242382049560547}
2023-01-03 18:05:56.337 DEBUG: Taking gradient step
2023-01-03 18:05:58.220 DEBUG: Loss 4: {'policy_loss': 0.06681799893321717, 'entropy_loss': -0.038810016587376595, 'vf_loss': 0.01780097962843323, 'total_loss': 0.02800798234584058, 'approx_kl': -0.03150622430257499, 'clip_fraction': 0.2708333358168602, 'grad_norm': 36.11075210571289}
2023-01-03 18:06:00.066 DEBUG: Taking gradient step
2023-01-03 18:06:01.951 DEBUG: Loss 5: {'policy_loss': 0.09765119461671212, 'entropy_loss': -0.03989946935325861, 'vf_loss': 0.020601130089829816, 'total_loss': 0.05775172526345351, 'approx_kl': -0.03147950302809477, 'clip_fraction': 0.3307291716337204, 'grad_norm': 20.392488479614258}
2023-01-03 18:06:03.797 DEBUG: Taking gradient step
2023-01-03 18:06:05.680 DEBUG: Loss 6: {'policy_loss': -0.04003992202800398, 'entropy_loss': -0.03936137445271015, 'vf_loss': 0.014126983080491953, 'total_loss': -0.07940129648071413, 'approx_kl': -0.031498040072619915, 'clip_fraction': 0.3580729179084301, 'grad_norm': 17.01108169555664}
2023-01-03 18:06:07.518 DEBUG: Taking gradient step
2023-01-03 18:06:09.399 DEBUG: Loss 7: {'policy_loss': 0.009988267069447814, 'entropy_loss': -0.03801190946251154, 'vf_loss': 0.015635458907990604, 'total_loss': -0.028023642393063722, 'approx_kl': -0.048507383558899164, 'clip_fraction': 0.3763020932674408, 'grad_norm': 21.865375518798828}
2023-01-03 18:06:11.243 DEBUG: Taking gradient step
2023-01-03 18:06:13.129 DEBUG: Loss 8: {'policy_loss': 0.04664965490136824, 'entropy_loss': -0.039903425611555576, 'vf_loss': 0.01615516080747614, 'total_loss': 0.006746229289812663, 'approx_kl': -0.05556416558101773, 'clip_fraction': 0.3541666716337204, 'grad_norm': 25.566650390625}
2023-01-03 18:06:14.974 DEBUG: Taking gradient step
2023-01-03 18:06:16.858 DEBUG: Loss 9: {'policy_loss': 0.042479621099319756, 'entropy_loss': -0.037961164489388466, 'vf_loss': 0.015946502448018304, 'total_loss': 0.004518456609931287, 'approx_kl': -0.059486446902155876, 'clip_fraction': 0.35546875, 'grad_norm': 26.20372200012207}
2023-01-03 18:06:18.702 DEBUG: Taking gradient step
2023-01-03 18:06:20.580 DEBUG: Loss 10: {'policy_loss': -0.0004693580542289716, 'entropy_loss': -0.039686175994575024, 'vf_loss': 0.014361352807843872, 'total_loss': -0.040155534048803995, 'approx_kl': -0.04651764966547489, 'clip_fraction': 0.3854166716337204, 'grad_norm': 21.543628692626953}
2023-01-03 18:06:22.426 DEBUG: Taking gradient step
2023-01-03 18:06:24.318 DEBUG: Loss 11: {'policy_loss': 0.005398597090237416, 'entropy_loss': -0.038867900148034096, 'vf_loss': 0.015320979232018937, 'total_loss': -0.033469303057796676, 'approx_kl': -0.06854040524922311, 'clip_fraction': 0.3802083358168602, 'grad_norm': 16.877805709838867}
2023-01-03 18:06:26.164 DEBUG: Taking gradient step
2023-01-03 18:06:28.047 DEBUG: Loss 12: {'policy_loss': 0.04807701764821989, 'entropy_loss': -0.03815093357115984, 'vf_loss': 0.01738727424891917, 'total_loss': 0.009926084077060048, 'approx_kl': -0.06717875599861145, 'clip_fraction': 0.32421875, 'grad_norm': 28.164474487304688}
2023-01-03 18:06:29.885 DEBUG: Taking gradient step
2023-01-03 18:06:31.769 DEBUG: Loss 13: {'policy_loss': 0.0640855742493169, 'entropy_loss': -0.042094442062079906, 'vf_loss': 0.017933262225798177, 'total_loss': 0.021991132187237, 'approx_kl': -0.11131095234304667, 'clip_fraction': 0.3736979216337204, 'grad_norm': 20.873838424682617}
2023-01-03 18:06:33.696 DEBUG: Taking gradient step
2023-01-03 18:06:35.589 DEBUG: Loss 14: {'policy_loss': 0.07351637081295412, 'entropy_loss': -0.036936049815267324, 'vf_loss': 0.017877066267207996, 'total_loss': 0.03658032099768679, 'approx_kl': -0.07718880381435156, 'clip_fraction': 0.41015625, 'grad_norm': 20.424306869506836}
2023-01-03 18:06:35.589 INFO: Optimization: policy loss=0.074, vf loss=0.018, entropy loss=-0.037, total loss=0.037, num steps=15
2023-01-03 18:06:35.590 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 18:06:37.359 INFO: Evaluation rollout: return=0.497 (0.0), episode length=6.0
2023-01-03 18:06:37.360 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 18:06:37.364 INFO: Iteration: 126/137, steps: 27216
2023-01-03 18:06:47.110 DEBUG: Atoms are too close
2023-01-03 18:07:05.881 DEBUG: Atoms are too close
2023-01-03 18:07:08.538 DEBUG: Atoms are too close
2023-01-03 18:07:34.656 INFO: Training rollout: return=-1.382 (5.3), episode length=5.9
2023-01-03 18:07:34.658 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 18:07:34.661 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-27216_train.pkl
2023-01-03 18:07:36.498 DEBUG: Taking gradient step
2023-01-03 18:07:38.352 DEBUG: Loss 0: {'policy_loss': 0.025322377321874614, 'entropy_loss': -0.0397694930434227, 'vf_loss': 0.014021826008825606, 'total_loss': -0.014447115721548082, 'approx_kl': -2.9957544001035785e-08, 'clip_fraction': 0.0, 'grad_norm': 23.513763427734375}
2023-01-03 18:07:40.166 DEBUG: Taking gradient step
2023-01-03 18:07:42.032 DEBUG: Loss 1: {'policy_loss': -0.043591320871543764, 'entropy_loss': -0.038367290049791336, 'vf_loss': 0.011263962472678758, 'total_loss': -0.08195861092133509, 'approx_kl': -0.0031810833606868982, 'clip_fraction': 0.2200520858168602, 'grad_norm': 18.259510040283203}
2023-01-03 18:07:43.842 DEBUG: Taking gradient step
2023-01-03 18:07:45.701 DEBUG: Loss 2: {'policy_loss': 0.001791986496251917, 'entropy_loss': -0.040517374873161316, 'vf_loss': 0.012547485413686083, 'total_loss': -0.0387253883769094, 'approx_kl': -0.024002665653824806, 'clip_fraction': 0.3997395858168602, 'grad_norm': 12.645644187927246}
2023-01-03 18:07:47.509 DEBUG: Taking gradient step
2023-01-03 18:07:49.366 DEBUG: Loss 3: {'policy_loss': -0.030354245343963547, 'entropy_loss': -0.03776149824261665, 'vf_loss': 0.011292141635031339, 'total_loss': -0.06811574358658021, 'approx_kl': -0.03888679982628673, 'clip_fraction': 0.3984375, 'grad_norm': 14.171401977539062}
2023-01-03 18:07:51.174 DEBUG: Taking gradient step
2023-01-03 18:07:53.031 DEBUG: Loss 4: {'policy_loss': -0.011888058161632235, 'entropy_loss': -0.03993880935013294, 'vf_loss': 0.011915631498763948, 'total_loss': -0.05182686751176517, 'approx_kl': -0.04465913865715265, 'clip_fraction': 0.3880208358168602, 'grad_norm': 20.425334930419922}
2023-01-03 18:07:54.835 DEBUG: Taking gradient step
2023-01-03 18:07:56.692 DEBUG: Loss 5: {'policy_loss': -0.00026098145607320045, 'entropy_loss': -0.03753495216369629, 'vf_loss': 0.011902155665659097, 'total_loss': -0.03779593361976949, 'approx_kl': -0.05547229549847543, 'clip_fraction': 0.3177083358168602, 'grad_norm': 26.573335647583008}
2023-01-03 18:07:58.510 DEBUG: Taking gradient step
2023-01-03 18:08:00.370 DEBUG: Loss 6: {'policy_loss': 0.014845122655054742, 'entropy_loss': -0.03625569958239794, 'vf_loss': 0.012679436703547538, 'total_loss': -0.021410576927343196, 'approx_kl': -0.0679147532209754, 'clip_fraction': 0.4127604216337204, 'grad_norm': 23.436973571777344}
2023-01-03 18:08:02.176 DEBUG: Taking gradient step
2023-01-03 18:08:04.032 DEBUG: Loss 7: {'policy_loss': 0.002315111449671666, 'entropy_loss': -0.03691015299409628, 'vf_loss': 0.01181321021427312, 'total_loss': -0.03459504154442461, 'approx_kl': -0.08192358305677772, 'clip_fraction': 0.50390625, 'grad_norm': 15.87475872039795}
2023-01-03 18:08:05.837 DEBUG: Taking gradient step
2023-01-03 18:08:07.690 DEBUG: Loss 8: {'policy_loss': -0.015425123307516837, 'entropy_loss': -0.036244404502213, 'vf_loss': 0.012451502073271831, 'total_loss': -0.05166952780972984, 'approx_kl': -0.06388838356360793, 'clip_fraction': 0.4895833432674408, 'grad_norm': 15.959797859191895}
2023-01-03 18:08:09.485 DEBUG: Taking gradient step
2023-01-03 18:08:11.339 DEBUG: Loss 9: {'policy_loss': -0.0249585944607622, 'entropy_loss': -0.03707330394536257, 'vf_loss': 0.012069807723369566, 'total_loss': -0.062031898406124775, 'approx_kl': -0.07974299043416977, 'clip_fraction': 0.5143229216337204, 'grad_norm': 22.13674545288086}
2023-01-03 18:08:13.141 DEBUG: Taking gradient step
2023-01-03 18:08:15.087 DEBUG: Loss 10: {'policy_loss': -0.03682811673769188, 'entropy_loss': -0.03375350730493665, 'vf_loss': 0.01131688299949524, 'total_loss': -0.07058162404262852, 'approx_kl': -0.072592219337821, 'clip_fraction': 0.4817708358168602, 'grad_norm': 21.035215377807617}
2023-01-03 18:08:16.907 DEBUG: Taking gradient step
2023-01-03 18:08:18.769 DEBUG: Loss 11: {'policy_loss': 0.007608094124502302, 'entropy_loss': -0.0379774896427989, 'vf_loss': 0.013442328498201123, 'total_loss': -0.030369395518296597, 'approx_kl': -0.0872483178973198, 'clip_fraction': 0.5299479216337204, 'grad_norm': 23.640926361083984}
2023-01-03 18:08:20.587 DEBUG: Taking gradient step
2023-01-03 18:08:22.485 DEBUG: Loss 12: {'policy_loss': 0.11587354586972663, 'entropy_loss': -0.03476300090551376, 'vf_loss': 0.016275234417585008, 'total_loss': 0.08111054496421287, 'approx_kl': -0.08788301981985569, 'clip_fraction': 0.60546875, 'grad_norm': 23.85527229309082}
2023-01-03 18:08:24.323 DEBUG: Taking gradient step
2023-01-03 18:08:26.198 DEBUG: Loss 13: {'policy_loss': 0.010156209217729497, 'entropy_loss': -0.034519602078944445, 'vf_loss': 0.012031295199295376, 'total_loss': -0.024363392861214944, 'approx_kl': -0.09049487113952637, 'clip_fraction': 0.6276041716337204, 'grad_norm': 16.67939567565918}
2023-01-03 18:08:28.020 DEBUG: Taking gradient step
2023-01-03 18:08:29.885 DEBUG: Loss 14: {'policy_loss': -0.00819836149903791, 'entropy_loss': -0.03649244969710708, 'vf_loss': 0.011621678147487312, 'total_loss': -0.04469081119614498, 'approx_kl': -0.08860999625176191, 'clip_fraction': 0.5677083358168602, 'grad_norm': 20.315114974975586}
2023-01-03 18:08:29.886 INFO: Optimization: policy loss=-0.008, vf loss=0.012, entropy loss=-0.036, total loss=-0.045, num steps=15
2023-01-03 18:08:29.887 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 18:08:31.594 INFO: Evaluation rollout: return=0.506 (0.0), episode length=6.0
2023-01-03 18:08:31.595 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 18:08:31.598 INFO: Iteration: 127/137, steps: 27432
2023-01-03 18:09:04.128 DEBUG: There is a single atom floating around
2023-01-03 18:09:04.412 DEBUG: Atoms are too close
2023-01-03 18:09:28.706 INFO: Training rollout: return=-0.774 (4.1), episode length=5.9
2023-01-03 18:09:28.707 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 18:09:28.711 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-27432_train.pkl
2023-01-03 18:09:30.580 DEBUG: Taking gradient step
2023-01-03 18:09:32.460 DEBUG: Loss 0: {'policy_loss': -0.021171051973428827, 'entropy_loss': -0.03696486260741949, 'vf_loss': 0.009800887367162489, 'total_loss': -0.05813591458084832, 'approx_kl': 1.0477378964424133e-07, 'clip_fraction': 0.0, 'grad_norm': 21.922122955322266}
2023-01-03 18:09:34.321 DEBUG: Taking gradient step
2023-01-03 18:09:36.225 DEBUG: Loss 1: {'policy_loss': -0.02024128048212953, 'entropy_loss': -0.037479640915989876, 'vf_loss': 0.010020270481105643, 'total_loss': -0.05772092139811941, 'approx_kl': -0.0070100497687235475, 'clip_fraction': 0.08333333395421505, 'grad_norm': 15.81571102142334}
2023-01-03 18:09:38.070 DEBUG: Taking gradient step
2023-01-03 18:09:39.954 DEBUG: Loss 2: {'policy_loss': -0.005689507662348242, 'entropy_loss': -0.03511796984821558, 'vf_loss': 0.011152628816669667, 'total_loss': -0.04080747751056382, 'approx_kl': -0.03202656330540776, 'clip_fraction': 0.1979166716337204, 'grad_norm': 29.762643814086914}
2023-01-03 18:09:41.799 DEBUG: Taking gradient step
2023-01-03 18:09:43.692 DEBUG: Loss 3: {'policy_loss': -0.005858043087941403, 'entropy_loss': -0.03537433035671711, 'vf_loss': 0.010453063234307895, 'total_loss': -0.04123237344465852, 'approx_kl': -0.02892000926658511, 'clip_fraction': 0.3151041716337204, 'grad_norm': 19.70905113220215}
2023-01-03 18:09:45.535 DEBUG: Taking gradient step
2023-01-03 18:09:47.422 DEBUG: Loss 4: {'policy_loss': -0.004382453757019532, 'entropy_loss': -0.03463716432452202, 'vf_loss': 0.010765302532043709, 'total_loss': -0.03901961808154156, 'approx_kl': -0.020087129436433315, 'clip_fraction': 0.38671875, 'grad_norm': 25.116209030151367}
2023-01-03 18:09:49.279 DEBUG: Taking gradient step
2023-01-03 18:09:51.174 DEBUG: Loss 5: {'policy_loss': -0.03381817501794998, 'entropy_loss': -0.034815805964171886, 'vf_loss': 0.009705439775077712, 'total_loss': -0.06863398098212187, 'approx_kl': -0.040770523715764284, 'clip_fraction': 0.3971354216337204, 'grad_norm': 12.223730087280273}
2023-01-03 18:09:53.025 DEBUG: Taking gradient step
2023-01-03 18:09:54.905 DEBUG: Loss 6: {'policy_loss': 0.03941475321330552, 'entropy_loss': -0.037167572882026434, 'vf_loss': 0.013057374285966476, 'total_loss': 0.002247180331279089, 'approx_kl': -0.04035527678206563, 'clip_fraction': 0.33984375, 'grad_norm': 30.289724349975586}
2023-01-03 18:09:56.746 DEBUG: Taking gradient step
2023-01-03 18:09:58.632 DEBUG: Loss 7: {'policy_loss': -0.030675372049359037, 'entropy_loss': -0.03470131941139698, 'vf_loss': 0.009687288868496397, 'total_loss': -0.06537669146075602, 'approx_kl': -0.05096601042896509, 'clip_fraction': 0.3502604216337204, 'grad_norm': 14.50167179107666}
2023-01-03 18:10:00.557 DEBUG: Taking gradient step
2023-01-03 18:10:02.440 DEBUG: Loss 8: {'policy_loss': 0.0032157082160253064, 'entropy_loss': -0.03570576151832938, 'vf_loss': 0.01100200274691757, 'total_loss': -0.032490053302304076, 'approx_kl': -0.0559352645650506, 'clip_fraction': 0.3359375, 'grad_norm': 13.908095359802246}
2023-01-03 18:10:04.287 DEBUG: Taking gradient step
2023-01-03 18:10:06.171 DEBUG: Loss 9: {'policy_loss': -0.0411899458072897, 'entropy_loss': -0.03555413335561752, 'vf_loss': 0.009933795692022247, 'total_loss': -0.07674407916290722, 'approx_kl': -0.04974367190152407, 'clip_fraction': 0.3033854216337204, 'grad_norm': 11.769607543945312}
2023-01-03 18:10:07.998 DEBUG: Taking gradient step
2023-01-03 18:10:09.877 DEBUG: Loss 10: {'policy_loss': 0.03753953207861367, 'entropy_loss': -0.0365118533372879, 'vf_loss': 0.012823713534668229, 'total_loss': 0.0010276787413257688, 'approx_kl': -0.04901144583709538, 'clip_fraction': 0.2552083358168602, 'grad_norm': 20.555391311645508}
2023-01-03 18:10:11.707 DEBUG: Taking gradient step
2023-01-03 18:10:13.589 DEBUG: Loss 11: {'policy_loss': -0.05941873306002092, 'entropy_loss': -0.036632941104471684, 'vf_loss': 0.00910309158617905, 'total_loss': -0.0960516741644926, 'approx_kl': -0.0638837986625731, 'clip_fraction': 0.30859375, 'grad_norm': 13.78084659576416}
2023-01-03 18:10:15.423 DEBUG: Taking gradient step
2023-01-03 18:10:17.287 DEBUG: Loss 12: {'policy_loss': -0.01618483220364838, 'entropy_loss': -0.036557129584252834, 'vf_loss': 0.011167802102581805, 'total_loss': -0.05274196178790121, 'approx_kl': -0.047193665988743305, 'clip_fraction': 0.3658854216337204, 'grad_norm': 8.917413711547852}
2023-01-03 18:10:19.143 DEBUG: Taking gradient step
2023-01-03 18:10:21.026 DEBUG: Loss 13: {'policy_loss': -0.01988851699810946, 'entropy_loss': -0.036511038430035114, 'vf_loss': 0.010694299454952705, 'total_loss': -0.05639955542814457, 'approx_kl': -0.05797644145786762, 'clip_fraction': 0.3333333358168602, 'grad_norm': 13.731815338134766}
2023-01-03 18:10:22.884 DEBUG: Taking gradient step
2023-01-03 18:10:24.787 DEBUG: Loss 14: {'policy_loss': -0.02114782779437853, 'entropy_loss': -0.035008007660508156, 'vf_loss': 0.01000692421116252, 'total_loss': -0.056155835454886685, 'approx_kl': -0.06373240519315004, 'clip_fraction': 0.3372395858168602, 'grad_norm': 23.622529983520508}
2023-01-03 18:10:24.788 INFO: Optimization: policy loss=-0.021, vf loss=0.010, entropy loss=-0.035, total loss=-0.056, num steps=15
2023-01-03 18:10:24.789 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 18:10:26.517 INFO: Evaluation rollout: return=0.508 (0.0), episode length=6.0
2023-01-03 18:10:26.519 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 18:10:26.522 INFO: Iteration: 128/137, steps: 27648
2023-01-03 18:10:36.262 DEBUG: Atoms are too close
2023-01-03 18:11:00.774 DEBUG: Atoms are too close
2023-01-03 18:11:23.797 INFO: Training rollout: return=-0.858 (4.4), episode length=5.9
2023-01-03 18:11:23.798 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 18:11:23.801 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-27648_train.pkl
2023-01-03 18:11:25.696 DEBUG: Taking gradient step
2023-01-03 18:11:27.607 DEBUG: Loss 0: {'policy_loss': 0.05274540753138436, 'entropy_loss': -0.03311406075954437, 'vf_loss': 0.011785625833295814, 'total_loss': 0.019631346771839996, 'approx_kl': 1.730707843705659e-08, 'clip_fraction': 0.0, 'grad_norm': 18.833148956298828}
2023-01-03 18:11:29.477 DEBUG: Taking gradient step
2023-01-03 18:11:31.388 DEBUG: Loss 1: {'policy_loss': -0.018096483941590507, 'entropy_loss': -0.033912351820617914, 'vf_loss': 0.009476985786211367, 'total_loss': -0.052008835762208425, 'approx_kl': -0.0028772762743756175, 'clip_fraction': 0.07161458395421505, 'grad_norm': 15.462084770202637}
2023-01-03 18:11:33.254 DEBUG: Taking gradient step
2023-01-03 18:11:35.153 DEBUG: Loss 2: {'policy_loss': -0.00546624661890689, 'entropy_loss': -0.034094486851245165, 'vf_loss': 0.010324123241325079, 'total_loss': -0.03956073347015206, 'approx_kl': -0.02744784322567284, 'clip_fraction': 0.13802083395421505, 'grad_norm': 16.684621810913086}
2023-01-03 18:11:37.031 DEBUG: Taking gradient step
2023-01-03 18:11:38.946 DEBUG: Loss 3: {'policy_loss': -0.025175418065135447, 'entropy_loss': -0.031745631247758865, 'vf_loss': 0.009270008644153067, 'total_loss': -0.05692104931289431, 'approx_kl': -0.028552427422255278, 'clip_fraction': 0.2630208358168602, 'grad_norm': 13.2748384475708}
2023-01-03 18:11:40.828 DEBUG: Taking gradient step
2023-01-03 18:11:42.817 DEBUG: Loss 4: {'policy_loss': -0.05281945525499693, 'entropy_loss': -0.03311445191502571, 'vf_loss': 0.00872407414174128, 'total_loss': -0.08593390717002264, 'approx_kl': -0.05541896051727235, 'clip_fraction': 0.2291666679084301, 'grad_norm': 11.02073860168457}
2023-01-03 18:11:44.692 DEBUG: Taking gradient step
2023-01-03 18:11:46.609 DEBUG: Loss 5: {'policy_loss': -0.036461101547433844, 'entropy_loss': -0.03558023925870657, 'vf_loss': 0.009806829835183925, 'total_loss': -0.07204134080614041, 'approx_kl': -0.052864884957671165, 'clip_fraction': 0.28515625, 'grad_norm': 10.319351196289062}
2023-01-03 18:11:48.484 DEBUG: Taking gradient step
2023-01-03 18:11:50.385 DEBUG: Loss 6: {'policy_loss': 0.07154912881160791, 'entropy_loss': -0.03661378566175699, 'vf_loss': 0.01373905312132315, 'total_loss': 0.03493534314985092, 'approx_kl': -0.05421828292310238, 'clip_fraction': 0.2578125, 'grad_norm': 19.844579696655273}
2023-01-03 18:11:52.259 DEBUG: Taking gradient step
2023-01-03 18:11:54.178 DEBUG: Loss 7: {'policy_loss': -0.024541317176968752, 'entropy_loss': -0.0352840656414628, 'vf_loss': 0.00947119400009777, 'total_loss': -0.059825382818431555, 'approx_kl': -0.05656058434396982, 'clip_fraction': 0.3268229216337204, 'grad_norm': 13.006711959838867}
2023-01-03 18:11:56.061 DEBUG: Taking gradient step
2023-01-03 18:11:57.968 DEBUG: Loss 8: {'policy_loss': -0.03496815643908007, 'entropy_loss': -0.036452868953347206, 'vf_loss': 0.009036336644297394, 'total_loss': -0.07142102539242728, 'approx_kl': -0.052225650288164616, 'clip_fraction': 0.3567708358168602, 'grad_norm': 10.40915584564209}
2023-01-03 18:11:59.835 DEBUG: Taking gradient step
2023-01-03 18:12:01.750 DEBUG: Loss 9: {'policy_loss': -0.006534290764453024, 'entropy_loss': -0.035966203548014164, 'vf_loss': 0.009983910446404025, 'total_loss': -0.042500494312467184, 'approx_kl': -0.0823510626796633, 'clip_fraction': 0.38671875, 'grad_norm': 11.621585845947266}
2023-01-03 18:12:03.615 DEBUG: Taking gradient step
2023-01-03 18:12:05.519 DEBUG: Loss 10: {'policy_loss': -0.033272302685278726, 'entropy_loss': -0.03610327187925577, 'vf_loss': 0.009281586574072943, 'total_loss': -0.0693755745645345, 'approx_kl': -0.1025256821885705, 'clip_fraction': 0.4114583358168602, 'grad_norm': 6.927209854125977}
2023-01-03 18:12:07.396 DEBUG: Taking gradient step
2023-01-03 18:12:09.299 DEBUG: Loss 11: {'policy_loss': -0.028081937990951437, 'entropy_loss': -0.03522114548832178, 'vf_loss': 0.009215792970460001, 'total_loss': -0.06330308347927321, 'approx_kl': -0.0810761982575059, 'clip_fraction': 0.3580729216337204, 'grad_norm': 10.793397903442383}
2023-01-03 18:12:11.169 DEBUG: Taking gradient step
2023-01-03 18:12:13.080 DEBUG: Loss 12: {'policy_loss': -0.012145930461799275, 'entropy_loss': -0.03460334846749902, 'vf_loss': 0.009592657048815, 'total_loss': -0.046749278929298296, 'approx_kl': -0.0735079925507307, 'clip_fraction': 0.3385416716337204, 'grad_norm': 8.304039001464844}
2023-01-03 18:12:14.962 DEBUG: Taking gradient step
2023-01-03 18:12:16.870 DEBUG: Loss 13: {'policy_loss': 0.010314847110135496, 'entropy_loss': -0.03512483602389693, 'vf_loss': 0.01178059683297624, 'total_loss': -0.024809988913761436, 'approx_kl': -0.11410550400614738, 'clip_fraction': 0.359375, 'grad_norm': 10.038381576538086}
2023-01-03 18:12:18.743 DEBUG: Taking gradient step
2023-01-03 18:12:20.649 DEBUG: Loss 14: {'policy_loss': -0.03790181477892965, 'entropy_loss': -0.035688335075974464, 'vf_loss': 0.008991667667984506, 'total_loss': -0.07359014985490411, 'approx_kl': -0.09608724899590015, 'clip_fraction': 0.3203125, 'grad_norm': 9.659313201904297}
2023-01-03 18:12:20.650 INFO: Optimization: policy loss=-0.038, vf loss=0.009, entropy loss=-0.036, total loss=-0.074, num steps=15
2023-01-03 18:12:20.651 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 18:12:22.356 INFO: Evaluation rollout: return=0.507 (0.0), episode length=6.0
2023-01-03 18:12:22.357 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 18:12:22.360 INFO: Iteration: 129/137, steps: 27864
2023-01-03 18:12:50.606 DEBUG: Atoms are too close
2023-01-03 18:13:19.965 INFO: Training rollout: return=-0.417 (3.7), episode length=5.9
2023-01-03 18:13:19.966 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 18:13:19.969 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-27864_train.pkl
2023-01-03 18:13:21.871 DEBUG: Taking gradient step
2023-01-03 18:13:23.807 DEBUG: Loss 0: {'policy_loss': 0.027471765307519186, 'entropy_loss': -0.03386575076729059, 'vf_loss': 0.008042027738116509, 'total_loss': -0.006393985459771406, 'approx_kl': 8.034597454020798e-08, 'clip_fraction': 0.0, 'grad_norm': 13.570018768310547}
2023-01-03 18:13:25.684 DEBUG: Taking gradient step
2023-01-03 18:13:27.693 DEBUG: Loss 1: {'policy_loss': -0.033598768710860746, 'entropy_loss': -0.035582938231527805, 'vf_loss': 0.00616668509209767, 'total_loss': -0.06918170694238855, 'approx_kl': -0.008952757809311152, 'clip_fraction': 0.018229166977107525, 'grad_norm': 13.51261043548584}
2023-01-03 18:13:29.580 DEBUG: Taking gradient step
2023-01-03 18:13:31.500 DEBUG: Loss 2: {'policy_loss': -0.009108989764042369, 'entropy_loss': -0.03493334259837866, 'vf_loss': 0.006928225764433072, 'total_loss': -0.04404233236242103, 'approx_kl': -0.023917869199067354, 'clip_fraction': 0.1263020858168602, 'grad_norm': 16.214235305786133}
2023-01-03 18:13:33.406 DEBUG: Taking gradient step
2023-01-03 18:13:35.327 DEBUG: Loss 3: {'policy_loss': -0.04151280676023418, 'entropy_loss': -0.03406772529706359, 'vf_loss': 0.00618680323015763, 'total_loss': -0.07558053205729777, 'approx_kl': -0.023303870693780482, 'clip_fraction': 0.19921875, 'grad_norm': 14.287054061889648}
2023-01-03 18:13:37.221 DEBUG: Taking gradient step
2023-01-03 18:13:39.148 DEBUG: Loss 4: {'policy_loss': -0.01074002803407205, 'entropy_loss': -0.034964513033628464, 'vf_loss': 0.006697255333075836, 'total_loss': -0.04570454106770051, 'approx_kl': -0.042924547335132957, 'clip_fraction': 0.265625, 'grad_norm': 15.577133178710938}
2023-01-03 18:13:41.033 DEBUG: Taking gradient step
2023-01-03 18:13:42.949 DEBUG: Loss 5: {'policy_loss': -0.030949632609996697, 'entropy_loss': -0.03675410011783242, 'vf_loss': 0.006164313328446278, 'total_loss': -0.06770373272782912, 'approx_kl': -0.05467615183442831, 'clip_fraction': 0.2890625, 'grad_norm': 16.5419979095459}
2023-01-03 18:13:44.837 DEBUG: Taking gradient step
2023-01-03 18:13:46.753 DEBUG: Loss 6: {'policy_loss': 0.005318693982310028, 'entropy_loss': -0.03627979755401611, 'vf_loss': 0.007362847080070441, 'total_loss': -0.03096110357170609, 'approx_kl': -0.049925874918699265, 'clip_fraction': 0.2513020858168602, 'grad_norm': 10.172828674316406}
2023-01-03 18:13:48.650 DEBUG: Taking gradient step
2023-01-03 18:13:50.576 DEBUG: Loss 7: {'policy_loss': -0.03983159592777015, 'entropy_loss': -0.03574032336473465, 'vf_loss': 0.006146373442392517, 'total_loss': -0.0755719192925048, 'approx_kl': -0.062304500956088305, 'clip_fraction': 0.2421875, 'grad_norm': 11.737397193908691}
2023-01-03 18:13:52.471 DEBUG: Taking gradient step
2023-01-03 18:13:54.396 DEBUG: Loss 8: {'policy_loss': -0.011717368312772576, 'entropy_loss': -0.0345428641885519, 'vf_loss': 0.007759636611456544, 'total_loss': -0.04626023250132447, 'approx_kl': -0.06888301111757755, 'clip_fraction': 0.3177083358168602, 'grad_norm': 9.199328422546387}
2023-01-03 18:13:56.270 DEBUG: Taking gradient step
2023-01-03 18:13:58.196 DEBUG: Loss 9: {'policy_loss': -0.03690432839871602, 'entropy_loss': -0.03577592736110091, 'vf_loss': 0.006139819666561868, 'total_loss': -0.07268025575981693, 'approx_kl': -0.049086468294262886, 'clip_fraction': 0.3385416716337204, 'grad_norm': 14.425835609436035}
2023-01-03 18:14:00.083 DEBUG: Taking gradient step
2023-01-03 18:14:02.005 DEBUG: Loss 10: {'policy_loss': 0.05400608587015855, 'entropy_loss': -0.03307243390008807, 'vf_loss': 0.008604747991654563, 'total_loss': 0.02093365197007048, 'approx_kl': -0.06462062368518673, 'clip_fraction': 0.2890625, 'grad_norm': 17.057544708251953}
2023-01-03 18:14:03.887 DEBUG: Taking gradient step
2023-01-03 18:14:05.796 DEBUG: Loss 11: {'policy_loss': 0.01325566936543534, 'entropy_loss': -0.03318343684077263, 'vf_loss': 0.007245693555622946, 'total_loss': -0.01992776747533729, 'approx_kl': -0.051793111488223076, 'clip_fraction': 0.3229166716337204, 'grad_norm': 14.557592391967773}
2023-01-03 18:14:07.686 DEBUG: Taking gradient step
2023-01-03 18:14:09.598 DEBUG: Loss 12: {'policy_loss': -0.03584809782500471, 'entropy_loss': -0.0323474258184433, 'vf_loss': 0.0061331511533377105, 'total_loss': -0.06819552364344801, 'approx_kl': -0.0777816167101264, 'clip_fraction': 0.3346354216337204, 'grad_norm': 15.85257625579834}
2023-01-03 18:14:11.494 DEBUG: Taking gradient step
2023-01-03 18:14:13.417 DEBUG: Loss 13: {'policy_loss': 0.057383880781733135, 'entropy_loss': -0.03421548381447792, 'vf_loss': 0.008983221152530231, 'total_loss': 0.023168396967255214, 'approx_kl': -0.06548350548837334, 'clip_fraction': 0.3645833358168602, 'grad_norm': 14.781976699829102}
2023-01-03 18:14:15.372 DEBUG: Taking gradient step
2023-01-03 18:14:17.290 DEBUG: Loss 14: {'policy_loss': -0.0011151249950703363, 'entropy_loss': -0.035291419830173254, 'vf_loss': 0.007267912399139283, 'total_loss': -0.03640654482524359, 'approx_kl': -0.07581808790564537, 'clip_fraction': 0.4114583358168602, 'grad_norm': 15.464357376098633}
2023-01-03 18:14:17.290 INFO: Optimization: policy loss=-0.001, vf loss=0.007, entropy loss=-0.035, total loss=-0.036, num steps=15
2023-01-03 18:14:17.292 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 18:14:19.016 INFO: Evaluation rollout: return=0.502 (0.0), episode length=6.0
2023-01-03 18:14:19.018 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 18:14:19.021 INFO: Iteration: 130/137, steps: 28080
2023-01-03 18:15:17.085 INFO: Training rollout: return=0.095 (2.2), episode length=6.0
2023-01-03 18:15:17.086 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 18:15:17.090 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-28080_train.pkl
2023-01-03 18:15:19.006 DEBUG: Taking gradient step
2023-01-03 18:15:20.936 DEBUG: Loss 0: {'policy_loss': -0.01990982708658464, 'entropy_loss': -0.03481069207191467, 'vf_loss': 0.0035763913631180998, 'total_loss': -0.05472051915849931, 'approx_kl': -1.100124791264534e-08, 'clip_fraction': 0.0, 'grad_norm': 16.692426681518555}
2023-01-03 18:15:22.829 DEBUG: Taking gradient step
2023-01-03 18:15:24.757 DEBUG: Loss 1: {'policy_loss': -0.00887956899453055, 'entropy_loss': -0.03330585919320583, 'vf_loss': 0.004381818827331266, 'total_loss': -0.04218542818773638, 'approx_kl': -0.016863423632457852, 'clip_fraction': 0.08333333395421505, 'grad_norm': 25.530029296875}
2023-01-03 18:15:26.644 DEBUG: Taking gradient step
2023-01-03 18:15:28.571 DEBUG: Loss 2: {'policy_loss': -0.04027513786600588, 'entropy_loss': -0.0362434065900743, 'vf_loss': 0.003538442248523034, 'total_loss': -0.07651854445608018, 'approx_kl': -0.053142140386626124, 'clip_fraction': 0.37109375, 'grad_norm': 7.614606857299805}
2023-01-03 18:15:30.473 DEBUG: Taking gradient step
2023-01-03 18:15:32.392 DEBUG: Loss 3: {'policy_loss': -0.03065830644552631, 'entropy_loss': -0.036422441713511944, 'vf_loss': 0.0035269588039679328, 'total_loss': -0.06708074815903825, 'approx_kl': -0.05217504361644387, 'clip_fraction': 0.4010416716337204, 'grad_norm': 2.599062919616699}
2023-01-03 18:15:34.289 DEBUG: Taking gradient step
2023-01-03 18:15:36.207 DEBUG: Loss 4: {'policy_loss': -0.013435367638565862, 'entropy_loss': -0.033944457303732634, 'vf_loss': 0.004355567375841175, 'total_loss': -0.04737982494229849, 'approx_kl': -0.04304686468094587, 'clip_fraction': 0.43359375, 'grad_norm': 9.449637413024902}
2023-01-03 18:15:38.108 DEBUG: Taking gradient step
2023-01-03 18:15:40.038 DEBUG: Loss 5: {'policy_loss': -0.026424263163426408, 'entropy_loss': -0.03503117244690657, 'vf_loss': 0.003503260805344113, 'total_loss': -0.061455435610332974, 'approx_kl': -0.03912425460293889, 'clip_fraction': 0.4388020858168602, 'grad_norm': 14.89657974243164}
2023-01-03 18:15:41.939 DEBUG: Taking gradient step
2023-01-03 18:15:43.870 DEBUG: Loss 6: {'policy_loss': -0.025792080764679336, 'entropy_loss': -0.036961122415959835, 'vf_loss': 0.003485928604764483, 'total_loss': -0.06275320318063918, 'approx_kl': -0.05544090736657381, 'clip_fraction': 0.40625, 'grad_norm': 14.635724067687988}
2023-01-03 18:15:45.763 DEBUG: Taking gradient step
2023-01-03 18:15:47.678 DEBUG: Loss 7: {'policy_loss': 0.03547311168951259, 'entropy_loss': -0.03689747489988804, 'vf_loss': 0.0047067425019148915, 'total_loss': -0.001424363210375451, 'approx_kl': -0.0651171924546361, 'clip_fraction': 0.42578125, 'grad_norm': 27.95697021484375}
2023-01-03 18:15:49.585 DEBUG: Taking gradient step
2023-01-03 18:15:51.510 DEBUG: Loss 8: {'policy_loss': -0.03803028034010063, 'entropy_loss': -0.03576282598078251, 'vf_loss': 0.0034669617479511773, 'total_loss': -0.07379310632088315, 'approx_kl': -0.058655126951634884, 'clip_fraction': 0.3502604216337204, 'grad_norm': 8.476375579833984}
2023-01-03 18:15:53.409 DEBUG: Taking gradient step
2023-01-03 18:15:55.359 DEBUG: Loss 9: {'policy_loss': -0.020793462522804194, 'entropy_loss': -0.03383951773867011, 'vf_loss': 0.00429092156658344, 'total_loss': -0.054632980261474305, 'approx_kl': -0.07746313535608351, 'clip_fraction': 0.36328125, 'grad_norm': 2.29750394821167}
2023-01-03 18:15:57.282 DEBUG: Taking gradient step
2023-01-03 18:15:59.321 DEBUG: Loss 10: {'policy_loss': -0.0326585720762235, 'entropy_loss': -0.03609744040295482, 'vf_loss': 0.003442856694533219, 'total_loss': -0.06875601247917831, 'approx_kl': -0.06776682264171541, 'clip_fraction': 0.3502604216337204, 'grad_norm': 12.032304763793945}
2023-01-03 18:16:01.247 DEBUG: Taking gradient step
2023-01-03 18:16:03.210 DEBUG: Loss 11: {'policy_loss': 0.060574473348273275, 'entropy_loss': -0.032520380802452564, 'vf_loss': 0.005696510362434392, 'total_loss': 0.02805409254582071, 'approx_kl': -0.08179528079926968, 'clip_fraction': 0.3567708358168602, 'grad_norm': 25.141775131225586}
2023-01-03 18:16:05.095 DEBUG: Taking gradient step
2023-01-03 18:16:06.995 DEBUG: Loss 12: {'policy_loss': 0.017088207713322756, 'entropy_loss': -0.03481892263516784, 'vf_loss': 0.004633261560301999, 'total_loss': -0.01773071492184508, 'approx_kl': -0.0860061002895236, 'clip_fraction': 0.34765625, 'grad_norm': 30.67755126953125}
2023-01-03 18:16:08.851 DEBUG: Taking gradient step
2023-01-03 18:16:10.790 DEBUG: Loss 13: {'policy_loss': -0.04193667849779952, 'entropy_loss': -0.03232381492853165, 'vf_loss': 0.003422060351348205, 'total_loss': -0.07426049342633118, 'approx_kl': -0.0842880941927433, 'clip_fraction': 0.4283854216337204, 'grad_norm': 12.629837036132812}
2023-01-03 18:16:12.696 DEBUG: Taking gradient step
2023-01-03 18:16:14.631 DEBUG: Loss 14: {'policy_loss': 0.006939398464573695, 'entropy_loss': -0.03307787422090769, 'vf_loss': 0.005105216631539943, 'total_loss': -0.026138475756333997, 'approx_kl': -0.06767147313803434, 'clip_fraction': 0.4596354216337204, 'grad_norm': 3.034621238708496}
2023-01-03 18:16:14.631 INFO: Optimization: policy loss=0.007, vf loss=0.005, entropy loss=-0.033, total loss=-0.026, num steps=15
2023-01-03 18:16:14.633 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 18:16:16.348 INFO: Evaluation rollout: return=0.503 (0.0), episode length=6.0
2023-01-03 18:16:16.349 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 18:16:16.353 DEBUG: Deleting old model: runs/CH3NO_dna/models/CH3NO_dna_run-1_steps-26136.model
2023-01-03 18:16:16.358 DEBUG: Saving model: runs/CH3NO_dna/models/CH3NO_dna_run-1_steps-28296.model
2023-01-03 18:16:16.406 INFO: Iteration: 131/137, steps: 28296
2023-01-03 18:16:30.873 DEBUG: Atoms are too close
2023-01-03 18:17:11.881 DEBUG: Atoms are too close
2023-01-03 18:17:14.088 INFO: Training rollout: return=-0.512 (4.2), episode length=6.0
2023-01-03 18:17:14.089 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 18:17:14.092 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-28296_train.pkl
2023-01-03 18:17:16.012 DEBUG: Taking gradient step
2023-01-03 18:17:17.918 DEBUG: Loss 0: {'policy_loss': -0.03700577108019537, 'entropy_loss': -0.03468236047774553, 'vf_loss': 0.012617894295408667, 'total_loss': -0.0716881315579409, 'approx_kl': -8.308173526927476e-08, 'clip_fraction': 0.0, 'grad_norm': 10.102574348449707}
2023-01-03 18:17:19.799 DEBUG: Taking gradient step
2023-01-03 18:17:21.726 DEBUG: Loss 1: {'policy_loss': -0.023513181841364274, 'entropy_loss': -0.03236714331433177, 'vf_loss': 0.012844075004621775, 'total_loss': -0.05588032515569605, 'approx_kl': 0.007647091057151556, 'clip_fraction': 0.1276041679084301, 'grad_norm': 8.92306900024414}
2023-01-03 18:17:23.609 DEBUG: Taking gradient step
2023-01-03 18:17:25.536 DEBUG: Loss 2: {'policy_loss': 0.008164069744476785, 'entropy_loss': -0.032714424189180136, 'vf_loss': 0.013975173499239699, 'total_loss': -0.024550354444703347, 'approx_kl': 0.005178878782317042, 'clip_fraction': 0.19140625, 'grad_norm': 10.455836296081543}
2023-01-03 18:17:27.413 DEBUG: Taking gradient step
2023-01-03 18:17:29.327 DEBUG: Loss 3: {'policy_loss': 0.012187562109869002, 'entropy_loss': -0.034638854674994946, 'vf_loss': 0.014851637136070586, 'total_loss': -0.022451292565125944, 'approx_kl': -0.017531465273350477, 'clip_fraction': 0.2526041679084301, 'grad_norm': 12.261151313781738}
2023-01-03 18:17:31.196 DEBUG: Taking gradient step
2023-01-03 18:17:33.119 DEBUG: Loss 4: {'policy_loss': 0.02003711968457279, 'entropy_loss': -0.03365299152210355, 'vf_loss': 0.013594083386488296, 'total_loss': -0.013615871837530758, 'approx_kl': -0.01443026028573513, 'clip_fraction': 0.33984375, 'grad_norm': 21.91529083251953}
2023-01-03 18:17:34.994 DEBUG: Taking gradient step
2023-01-03 18:17:36.911 DEBUG: Loss 5: {'policy_loss': 0.06854488336188767, 'entropy_loss': -0.03377823019400239, 'vf_loss': 0.01552944428129394, 'total_loss': 0.03476665316788528, 'approx_kl': -0.02118260064162314, 'clip_fraction': 0.44140625, 'grad_norm': 27.923219680786133}
2023-01-03 18:17:38.798 DEBUG: Taking gradient step
2023-01-03 18:17:40.722 DEBUG: Loss 6: {'policy_loss': -0.01985691618295045, 'entropy_loss': -0.03311898838728666, 'vf_loss': 0.013123358394167572, 'total_loss': -0.05297590457023711, 'approx_kl': -0.012952717952430248, 'clip_fraction': 0.35546875, 'grad_norm': 13.919282913208008}
2023-01-03 18:17:42.607 DEBUG: Taking gradient step
2023-01-03 18:17:44.592 DEBUG: Loss 7: {'policy_loss': 0.031045665706974934, 'entropy_loss': -0.03174034971743822, 'vf_loss': 0.01584189278330226, 'total_loss': -0.000694684010463284, 'approx_kl': -0.013549035647884011, 'clip_fraction': 0.4231770932674408, 'grad_norm': 10.897729873657227}
2023-01-03 18:17:46.463 DEBUG: Taking gradient step
2023-01-03 18:17:48.379 DEBUG: Loss 8: {'policy_loss': 0.03067091164083861, 'entropy_loss': -0.03529547993093729, 'vf_loss': 0.015627320830071074, 'total_loss': -0.004624568290098677, 'approx_kl': -0.03618982620537281, 'clip_fraction': 0.3619791716337204, 'grad_norm': 13.644929885864258}
2023-01-03 18:17:50.269 DEBUG: Taking gradient step
2023-01-03 18:17:52.182 DEBUG: Loss 9: {'policy_loss': 0.015467183387194376, 'entropy_loss': -0.03390230145305395, 'vf_loss': 0.015280026219370683, 'total_loss': -0.018435118065859582, 'approx_kl': -0.03346575144678354, 'clip_fraction': 0.3216145858168602, 'grad_norm': 19.818294525146484}
2023-01-03 18:17:54.080 DEBUG: Taking gradient step
2023-01-03 18:17:55.992 DEBUG: Loss 10: {'policy_loss': -0.02119492295114666, 'entropy_loss': -0.03528003068640828, 'vf_loss': 0.013303797149395351, 'total_loss': -0.05647495363755494, 'approx_kl': -0.022984071634709835, 'clip_fraction': 0.2825520858168602, 'grad_norm': 10.18966007232666}
2023-01-03 18:17:57.865 DEBUG: Taking gradient step
2023-01-03 18:17:59.770 DEBUG: Loss 11: {'policy_loss': -0.007839746787912985, 'entropy_loss': -0.03726358851417899, 'vf_loss': 0.014669477640559234, 'total_loss': -0.04510333530209198, 'approx_kl': -0.01123813260346651, 'clip_fraction': 0.3359375, 'grad_norm': 14.020524024963379}
2023-01-03 18:18:01.647 DEBUG: Taking gradient step
2023-01-03 18:18:03.554 DEBUG: Loss 12: {'policy_loss': -0.0031254003245456755, 'entropy_loss': -0.034825414419174194, 'vf_loss': 0.014349319721111416, 'total_loss': -0.03795081474371987, 'approx_kl': -0.03289016825146973, 'clip_fraction': 0.3411458358168602, 'grad_norm': 19.072837829589844}
2023-01-03 18:18:05.433 DEBUG: Taking gradient step
2023-01-03 18:18:07.346 DEBUG: Loss 13: {'policy_loss': 0.007070109824317973, 'entropy_loss': -0.03401517402380705, 'vf_loss': 0.01377294489171172, 'total_loss': -0.02694506419948908, 'approx_kl': -0.030678754905238748, 'clip_fraction': 0.3333333358168602, 'grad_norm': 17.15121078491211}
2023-01-03 18:18:09.227 DEBUG: Taking gradient step
2023-01-03 18:18:11.145 DEBUG: Loss 14: {'policy_loss': -0.021988087778835083, 'entropy_loss': -0.033201404847204685, 'vf_loss': 0.012652615257856548, 'total_loss': -0.05518949262603977, 'approx_kl': -0.043818198842927814, 'clip_fraction': 0.3333333358168602, 'grad_norm': 9.500893592834473}
2023-01-03 18:18:11.145 INFO: Optimization: policy loss=-0.022, vf loss=0.013, entropy loss=-0.033, total loss=-0.055, num steps=15
2023-01-03 18:18:11.147 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 18:18:12.850 INFO: Evaluation rollout: return=0.508 (0.0), episode length=6.0
2023-01-03 18:18:12.851 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 18:18:12.854 INFO: Iteration: 132/137, steps: 28512
2023-01-03 18:18:26.588 DEBUG: Atoms are too close
2023-01-03 18:18:27.743 DEBUG: Atoms are too close
2023-01-03 18:18:43.223 DEBUG: Atoms are too close
2023-01-03 18:18:44.442 DEBUG: Atoms are too close
2023-01-03 18:19:09.114 INFO: Training rollout: return=-1.284 (5.0), episode length=5.9
2023-01-03 18:19:09.116 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 18:19:09.119 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-28512_train.pkl
2023-01-03 18:19:11.003 DEBUG: Taking gradient step
2023-01-03 18:19:12.900 DEBUG: Loss 0: {'policy_loss': -0.04394095788982421, 'entropy_loss': -0.03220127522945404, 'vf_loss': 0.01153348419321998, 'total_loss': -0.07614223311927826, 'approx_kl': 9.317106375306139e-08, 'clip_fraction': 0.0, 'grad_norm': 18.19672966003418}
2023-01-03 18:19:14.772 DEBUG: Taking gradient step
2023-01-03 18:19:16.679 DEBUG: Loss 1: {'policy_loss': -0.01684347025370567, 'entropy_loss': -0.033410897478461266, 'vf_loss': 0.0125553064165579, 'total_loss': -0.05025436773216693, 'approx_kl': -0.013524681562557817, 'clip_fraction': 0.11588541697710752, 'grad_norm': 22.94055938720703}
2023-01-03 18:19:18.555 DEBUG: Taking gradient step
2023-01-03 18:19:20.454 DEBUG: Loss 2: {'policy_loss': 0.07152614923159484, 'entropy_loss': -0.03337376797571778, 'vf_loss': 0.016097031629143735, 'total_loss': 0.038152381255877055, 'approx_kl': -0.033629968063905835, 'clip_fraction': 0.30078125, 'grad_norm': 21.39240074157715}
2023-01-03 18:19:22.338 DEBUG: Taking gradient step
2023-01-03 18:19:24.244 DEBUG: Loss 3: {'policy_loss': -0.005170177369257744, 'entropy_loss': -0.0351507356390357, 'vf_loss': 0.013193880077856551, 'total_loss': -0.04032091300829345, 'approx_kl': -0.03706390596926212, 'clip_fraction': 0.3606770858168602, 'grad_norm': 14.972883224487305}
2023-01-03 18:19:26.109 DEBUG: Taking gradient step
2023-01-03 18:19:28.096 DEBUG: Loss 4: {'policy_loss': -0.014767772866874852, 'entropy_loss': -0.03290042467415333, 'vf_loss': 0.013159236667532302, 'total_loss': -0.047668197541028176, 'approx_kl': -0.047988119535148144, 'clip_fraction': 0.3697916716337204, 'grad_norm': 15.7219877243042}
2023-01-03 18:19:29.950 DEBUG: Taking gradient step
2023-01-03 18:19:31.853 DEBUG: Loss 5: {'policy_loss': -0.05235765638613524, 'entropy_loss': -0.03418714739382267, 'vf_loss': 0.01154539353994996, 'total_loss': -0.08654480377995791, 'approx_kl': -0.05782686173915863, 'clip_fraction': 0.3802083432674408, 'grad_norm': 16.19368553161621}
2023-01-03 18:19:33.742 DEBUG: Taking gradient step
2023-01-03 18:19:35.643 DEBUG: Loss 6: {'policy_loss': -0.029782199415816044, 'entropy_loss': -0.03391478816047311, 'vf_loss': 0.012741432333840275, 'total_loss': -0.06369698757628915, 'approx_kl': -0.051361153833568096, 'clip_fraction': 0.3841145858168602, 'grad_norm': 23.786497116088867}
2023-01-03 18:19:37.518 DEBUG: Taking gradient step
2023-01-03 18:19:39.423 DEBUG: Loss 7: {'policy_loss': -0.01369269746407451, 'entropy_loss': -0.03189348243176937, 'vf_loss': 0.013891155583854911, 'total_loss': -0.04558617989584388, 'approx_kl': -0.05671035870909691, 'clip_fraction': 0.3619791716337204, 'grad_norm': 24.238101959228516}
2023-01-03 18:19:41.297 DEBUG: Taking gradient step
2023-01-03 18:19:43.212 DEBUG: Loss 8: {'policy_loss': 0.03097992564976282, 'entropy_loss': -0.032093883492052555, 'vf_loss': 0.014397165657996345, 'total_loss': -0.0011139578422897367, 'approx_kl': -0.06528066983446479, 'clip_fraction': 0.3151041716337204, 'grad_norm': 24.681371688842773}
2023-01-03 18:19:45.090 DEBUG: Taking gradient step
2023-01-03 18:19:46.983 DEBUG: Loss 9: {'policy_loss': 0.00962863372991757, 'entropy_loss': -0.03247279301285744, 'vf_loss': 0.01395228985752911, 'total_loss': -0.02284415928293987, 'approx_kl': -0.0803074948489666, 'clip_fraction': 0.36328125, 'grad_norm': 20.858285903930664}
2023-01-03 18:19:48.859 DEBUG: Taking gradient step
2023-01-03 18:19:50.760 DEBUG: Loss 10: {'policy_loss': -0.0338349195569736, 'entropy_loss': -0.03225718019530177, 'vf_loss': 0.011976887111034649, 'total_loss': -0.06609209975227537, 'approx_kl': -0.07209399063140154, 'clip_fraction': 0.3971354216337204, 'grad_norm': 18.86670684814453}
2023-01-03 18:19:52.623 DEBUG: Taking gradient step
2023-01-03 18:19:54.520 DEBUG: Loss 11: {'policy_loss': -0.06832180155083876, 'entropy_loss': -0.03289057221263647, 'vf_loss': 0.011548738224227625, 'total_loss': -0.10121237376347525, 'approx_kl': -0.09182023908942938, 'clip_fraction': 0.3854166716337204, 'grad_norm': 15.530096054077148}
2023-01-03 18:19:56.383 DEBUG: Taking gradient step
2023-01-03 18:19:58.290 DEBUG: Loss 12: {'policy_loss': -0.013579693706080576, 'entropy_loss': -0.03219392476603389, 'vf_loss': 0.013732039774567573, 'total_loss': -0.04577361847211446, 'approx_kl': -0.07777606637682766, 'clip_fraction': 0.359375, 'grad_norm': 10.261714935302734}
2023-01-03 18:20:00.154 DEBUG: Taking gradient step
2023-01-03 18:20:02.061 DEBUG: Loss 13: {'policy_loss': -0.015670875096879748, 'entropy_loss': -0.03353337710723281, 'vf_loss': 0.013951766255816966, 'total_loss': -0.04920425220411256, 'approx_kl': -0.07408982020569965, 'clip_fraction': 0.37109375, 'grad_norm': 22.147825241088867}
2023-01-03 18:20:03.944 DEBUG: Taking gradient step
2023-01-03 18:20:05.853 DEBUG: Loss 14: {'policy_loss': -0.018930721014927585, 'entropy_loss': -0.032257452607154846, 'vf_loss': 0.012909177051156262, 'total_loss': -0.05118817362208243, 'approx_kl': -0.10253080353140831, 'clip_fraction': 0.38671875, 'grad_norm': 36.8602294921875}
2023-01-03 18:20:05.853 INFO: Optimization: policy loss=-0.019, vf loss=0.013, entropy loss=-0.032, total loss=-0.051, num steps=15
2023-01-03 18:20:05.855 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 18:20:07.598 INFO: Evaluation rollout: return=0.507 (0.0), episode length=6.0
2023-01-03 18:20:07.599 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 18:20:07.602 INFO: Iteration: 133/137, steps: 28728
2023-01-03 18:20:22.967 DEBUG: Atoms are too close
2023-01-03 18:21:00.377 DEBUG: Atoms are too close
2023-01-03 18:21:04.521 INFO: Training rollout: return=-0.399 (3.6), episode length=5.9
2023-01-03 18:21:04.522 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 18:21:04.528 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-28728_train.pkl
2023-01-03 18:21:06.420 DEBUG: Taking gradient step
2023-01-03 18:21:08.321 DEBUG: Loss 0: {'policy_loss': -0.03500852506374959, 'entropy_loss': -0.03229693463072181, 'vf_loss': 0.0061926060784243744, 'total_loss': -0.06730545969447138, 'approx_kl': -3.273211035548229e-08, 'clip_fraction': 0.0, 'grad_norm': 7.480029582977295}
2023-01-03 18:21:10.180 DEBUG: Taking gradient step
2023-01-03 18:21:12.163 DEBUG: Loss 1: {'policy_loss': -0.032002537916868495, 'entropy_loss': -0.03185224859043956, 'vf_loss': 0.00616933633158321, 'total_loss': -0.06385478650730805, 'approx_kl': -0.005214797565713525, 'clip_fraction': 0.15625, 'grad_norm': 11.406342506408691}
2023-01-03 18:21:14.021 DEBUG: Taking gradient step
2023-01-03 18:21:15.923 DEBUG: Loss 2: {'policy_loss': -0.01228660906550038, 'entropy_loss': -0.030885587446391582, 'vf_loss': 0.006585029879044111, 'total_loss': -0.04317219651189196, 'approx_kl': -0.00990060530602932, 'clip_fraction': 0.2786458358168602, 'grad_norm': 8.906683921813965}
2023-01-03 18:21:17.806 DEBUG: Taking gradient step
2023-01-03 18:21:19.714 DEBUG: Loss 3: {'policy_loss': -0.02874461636046188, 'entropy_loss': -0.03083938593044877, 'vf_loss': 0.006138711129641384, 'total_loss': -0.05958400229091065, 'approx_kl': -0.017888270318508148, 'clip_fraction': 0.31640625, 'grad_norm': 8.544135093688965}
2023-01-03 18:21:21.577 DEBUG: Taking gradient step
2023-01-03 18:21:23.484 DEBUG: Loss 4: {'policy_loss': 0.016111702037322637, 'entropy_loss': -0.031760821118950844, 'vf_loss': 0.00861201390814141, 'total_loss': -0.015649119081628207, 'approx_kl': -0.03890846064314246, 'clip_fraction': 0.296875, 'grad_norm': 8.55126667022705}
2023-01-03 18:21:25.358 DEBUG: Taking gradient step
2023-01-03 18:21:27.254 DEBUG: Loss 5: {'policy_loss': 0.02231037547150213, 'entropy_loss': -0.03149518044665456, 'vf_loss': 0.00831517115559522, 'total_loss': -0.009184804975152429, 'approx_kl': -0.03418672224506736, 'clip_fraction': 0.3450520858168602, 'grad_norm': 8.488728523254395}
2023-01-03 18:21:29.130 DEBUG: Taking gradient step
2023-01-03 18:21:31.038 DEBUG: Loss 6: {'policy_loss': 0.02797860601421063, 'entropy_loss': -0.03271238273009658, 'vf_loss': 0.008506393861467062, 'total_loss': -0.004733776715885957, 'approx_kl': -0.04541704268194735, 'clip_fraction': 0.3854166716337204, 'grad_norm': 14.616973876953125}
2023-01-03 18:21:32.948 DEBUG: Taking gradient step
2023-01-03 18:21:34.863 DEBUG: Loss 7: {'policy_loss': -0.01535779330155573, 'entropy_loss': -0.03208941034972668, 'vf_loss': 0.006567690236317875, 'total_loss': -0.0474472036512824, 'approx_kl': -0.05184207297861576, 'clip_fraction': 0.4869791716337204, 'grad_norm': 8.53165054321289}
2023-01-03 18:21:36.745 DEBUG: Taking gradient step
2023-01-03 18:21:38.652 DEBUG: Loss 8: {'policy_loss': 0.009697513196160825, 'entropy_loss': -0.0316172786988318, 'vf_loss': 0.00758965301201788, 'total_loss': -0.02191976550267098, 'approx_kl': -0.045996015425771475, 'clip_fraction': 0.4609375, 'grad_norm': 8.490728378295898}
2023-01-03 18:21:40.579 DEBUG: Taking gradient step
2023-01-03 18:21:42.505 DEBUG: Loss 9: {'policy_loss': -0.048110121796453666, 'entropy_loss': -0.032281588297337294, 'vf_loss': 0.00590041758984593, 'total_loss': -0.08039171009379095, 'approx_kl': -0.05876650894060731, 'clip_fraction': 0.32421875, 'grad_norm': 6.956181526184082}
2023-01-03 18:21:44.400 DEBUG: Taking gradient step
2023-01-03 18:21:46.333 DEBUG: Loss 10: {'policy_loss': -0.037807994287377626, 'entropy_loss': -0.031917911022901535, 'vf_loss': 0.0058519195408391796, 'total_loss': -0.06972590531027915, 'approx_kl': -0.05480137374252081, 'clip_fraction': 0.2786458358168602, 'grad_norm': 6.435278415679932}
2023-01-03 18:21:48.245 DEBUG: Taking gradient step
2023-01-03 18:21:50.183 DEBUG: Loss 11: {'policy_loss': -0.034777291824683094, 'entropy_loss': -0.03144320705905557, 'vf_loss': 0.005822915229732059, 'total_loss': -0.06622049888373865, 'approx_kl': -0.05655284505337477, 'clip_fraction': 0.3502604216337204, 'grad_norm': 9.293365478515625}
2023-01-03 18:21:52.096 DEBUG: Taking gradient step
2023-01-03 18:21:54.033 DEBUG: Loss 12: {'policy_loss': -0.0038684989408960036, 'entropy_loss': -0.03282439149916172, 'vf_loss': 0.007452015687812137, 'total_loss': -0.036692890440057725, 'approx_kl': -0.04190558195114136, 'clip_fraction': 0.4765625, 'grad_norm': 10.476373672485352}
2023-01-03 18:21:55.943 DEBUG: Taking gradient step
2023-01-03 18:21:57.876 DEBUG: Loss 13: {'policy_loss': -0.01734524376799934, 'entropy_loss': -0.03193433629348874, 'vf_loss': 0.006194434001471108, 'total_loss': -0.04927958006148808, 'approx_kl': -0.0571814589202404, 'clip_fraction': 0.4153645858168602, 'grad_norm': 8.040616035461426}
2023-01-03 18:21:59.853 DEBUG: Taking gradient step
2023-01-03 18:22:01.796 DEBUG: Loss 14: {'policy_loss': -0.0373306064549299, 'entropy_loss': -0.029959806241095066, 'vf_loss': 0.0057465391985309575, 'total_loss': -0.06729041269602497, 'approx_kl': -0.04048330523073673, 'clip_fraction': 0.4075520858168602, 'grad_norm': 7.026908874511719}
2023-01-03 18:22:01.797 INFO: Optimization: policy loss=-0.037, vf loss=0.006, entropy loss=-0.030, total loss=-0.067, num steps=15
2023-01-03 18:22:01.799 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 18:22:03.534 INFO: Evaluation rollout: return=0.504 (0.0), episode length=6.0
2023-01-03 18:22:03.535 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 18:22:03.539 INFO: Iteration: 134/137, steps: 28944
2023-01-03 18:22:18.878 DEBUG: Atoms are too close
2023-01-03 18:23:00.651 INFO: Training rollout: return=-0.337 (3.4), episode length=6.0
2023-01-03 18:23:00.652 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 18:23:00.656 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-28944_train.pkl
2023-01-03 18:23:02.554 DEBUG: Taking gradient step
2023-01-03 18:23:04.472 DEBUG: Loss 0: {'policy_loss': -0.020266104141617402, 'entropy_loss': -0.032758166547864676, 'vf_loss': 0.006469603598890664, 'total_loss': -0.05302427068948208, 'approx_kl': 4.346172016722605e-08, 'clip_fraction': 0.0, 'grad_norm': 10.008447647094727}
2023-01-03 18:23:06.348 DEBUG: Taking gradient step
2023-01-03 18:23:08.256 DEBUG: Loss 1: {'policy_loss': 0.021796627049541765, 'entropy_loss': -0.03261090908199549, 'vf_loss': 0.008197992078691018, 'total_loss': -0.010814282032453722, 'approx_kl': -0.01046754082199186, 'clip_fraction': 0.04036458395421505, 'grad_norm': 11.520455360412598}
2023-01-03 18:23:10.115 DEBUG: Taking gradient step
2023-01-03 18:23:12.018 DEBUG: Loss 2: {'policy_loss': 0.04213201755964404, 'entropy_loss': -0.034247325267642736, 'vf_loss': 0.00816088544917861, 'total_loss': 0.007884692292001304, 'approx_kl': -0.02158681454602629, 'clip_fraction': 0.2825520858168602, 'grad_norm': 11.707207679748535}
2023-01-03 18:23:13.901 DEBUG: Taking gradient step
2023-01-03 18:23:15.811 DEBUG: Loss 3: {'policy_loss': -0.03255942333496747, 'entropy_loss': -0.03233930002897978, 'vf_loss': 0.0058550090807289925, 'total_loss': -0.06489872336394725, 'approx_kl': -0.02377158065792173, 'clip_fraction': 0.3997395858168602, 'grad_norm': 12.415419578552246}
2023-01-03 18:23:17.699 DEBUG: Taking gradient step
2023-01-03 18:23:19.611 DEBUG: Loss 4: {'policy_loss': 0.011627056888234469, 'entropy_loss': -0.032731672283262014, 'vf_loss': 0.0073696865509217425, 'total_loss': -0.021104615395027546, 'approx_kl': -0.027328988537192345, 'clip_fraction': 0.3697916716337204, 'grad_norm': 13.83320426940918}
2023-01-03 18:23:21.494 DEBUG: Taking gradient step
2023-01-03 18:23:23.403 DEBUG: Loss 5: {'policy_loss': -0.0013831613084732616, 'entropy_loss': -0.03266428876668215, 'vf_loss': 0.007068128781754085, 'total_loss': -0.03404745007515541, 'approx_kl': -0.03632535878568888, 'clip_fraction': 0.28515625, 'grad_norm': 12.546475410461426}
2023-01-03 18:23:25.297 DEBUG: Taking gradient step
2023-01-03 18:23:27.214 DEBUG: Loss 6: {'policy_loss': -0.03424933692590603, 'entropy_loss': -0.032016927376389503, 'vf_loss': 0.005822347271682382, 'total_loss': -0.06626626430229554, 'approx_kl': -0.02885885792784393, 'clip_fraction': 0.3033854216337204, 'grad_norm': 7.1989874839782715}
2023-01-03 18:23:29.098 DEBUG: Taking gradient step
2023-01-03 18:23:31.015 DEBUG: Loss 7: {'policy_loss': 0.005327341371293469, 'entropy_loss': -0.03312422940507531, 'vf_loss': 0.007182760538464039, 'total_loss': -0.027796888033781844, 'approx_kl': -0.035850107902660966, 'clip_fraction': 0.375, 'grad_norm': 6.878058910369873}
2023-01-03 18:23:32.889 DEBUG: Taking gradient step
2023-01-03 18:23:34.806 DEBUG: Loss 8: {'policy_loss': 0.004328799717755991, 'entropy_loss': -0.031368233263492584, 'vf_loss': 0.007031360568427802, 'total_loss': -0.027039433545736593, 'approx_kl': -0.03821025229990482, 'clip_fraction': 0.296875, 'grad_norm': 12.683609962463379}
2023-01-03 18:23:36.671 DEBUG: Taking gradient step
2023-01-03 18:23:38.588 DEBUG: Loss 9: {'policy_loss': -0.02992638837466855, 'entropy_loss': -0.031244489829987288, 'vf_loss': 0.006242229132601842, 'total_loss': -0.06117087820465583, 'approx_kl': -0.04335438134148717, 'clip_fraction': 0.2526041679084301, 'grad_norm': 7.21639347076416}
2023-01-03 18:23:40.454 DEBUG: Taking gradient step
2023-01-03 18:23:42.371 DEBUG: Loss 10: {'policy_loss': -0.06038661279514701, 'entropy_loss': -0.03136197989806533, 'vf_loss': 0.005827578606278918, 'total_loss': -0.09174859269321234, 'approx_kl': -0.05560788745060563, 'clip_fraction': 0.2916666716337204, 'grad_norm': 5.857138156890869}
2023-01-03 18:23:44.338 DEBUG: Taking gradient step
2023-01-03 18:23:46.250 DEBUG: Loss 11: {'policy_loss': -0.05043551671748807, 'entropy_loss': -0.03255435544997454, 'vf_loss': 0.006123825008061922, 'total_loss': -0.0829898721674626, 'approx_kl': -0.04207819374278188, 'clip_fraction': 0.3541666716337204, 'grad_norm': 5.691172122955322}
2023-01-03 18:23:48.122 DEBUG: Taking gradient step
2023-01-03 18:23:50.053 DEBUG: Loss 12: {'policy_loss': -0.061426804815551864, 'entropy_loss': -0.0339435045607388, 'vf_loss': 0.0058154059088362684, 'total_loss': -0.09537030937629067, 'approx_kl': -0.06592750176787376, 'clip_fraction': 0.3190104216337204, 'grad_norm': 6.680671215057373}
2023-01-03 18:23:51.926 DEBUG: Taking gradient step
2023-01-03 18:23:53.829 DEBUG: Loss 13: {'policy_loss': -0.004338936389631714, 'entropy_loss': -0.03304349444806576, 'vf_loss': 0.007512610219542507, 'total_loss': -0.037382430837697475, 'approx_kl': -0.06369470711797476, 'clip_fraction': 0.2890625, 'grad_norm': 10.398272514343262}
2023-01-03 18:23:55.717 DEBUG: Taking gradient step
2023-01-03 18:23:57.617 DEBUG: Loss 14: {'policy_loss': 0.011694228670236666, 'entropy_loss': -0.0324161727912724, 'vf_loss': 0.008058355723804344, 'total_loss': -0.020721944121035736, 'approx_kl': -0.04524961672723293, 'clip_fraction': 0.3502604216337204, 'grad_norm': 12.852914810180664}
2023-01-03 18:23:57.617 INFO: Optimization: policy loss=0.012, vf loss=0.008, entropy loss=-0.032, total loss=-0.021, num steps=15
2023-01-03 18:23:57.619 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 18:23:59.311 INFO: Evaluation rollout: return=0.505 (0.0), episode length=6.0
2023-01-03 18:23:59.312 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 18:23:59.315 INFO: Iteration: 135/137, steps: 29160
2023-01-03 18:24:31.463 DEBUG: Atoms are too close
2023-01-03 18:24:56.376 INFO: Training rollout: return=-0.348 (3.3), episode length=6.0
2023-01-03 18:24:56.378 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 18:24:56.381 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-29160_train.pkl
2023-01-03 18:24:58.302 DEBUG: Taking gradient step
2023-01-03 18:25:00.212 DEBUG: Loss 0: {'policy_loss': -0.017345059320397302, 'entropy_loss': -0.033430120907723904, 'vf_loss': 0.006701227161129692, 'total_loss': -0.050775180228121206, 'approx_kl': -7.776543498039246e-08, 'clip_fraction': 0.0, 'grad_norm': 10.984600067138672}
2023-01-03 18:25:02.099 DEBUG: Taking gradient step
2023-01-03 18:25:04.015 DEBUG: Loss 1: {'policy_loss': -0.048458747568744895, 'entropy_loss': -0.03411373682320118, 'vf_loss': 0.006190542022685202, 'total_loss': -0.08257248439194607, 'approx_kl': -0.017020803061313927, 'clip_fraction': 0.07682291697710752, 'grad_norm': 14.76671028137207}
2023-01-03 18:25:05.907 DEBUG: Taking gradient step
2023-01-03 18:25:07.812 DEBUG: Loss 2: {'policy_loss': 0.011669508872033557, 'entropy_loss': -0.034010136034339666, 'vf_loss': 0.007233719492988609, 'total_loss': -0.022340627162306108, 'approx_kl': -0.028237744292709976, 'clip_fraction': 0.2916666679084301, 'grad_norm': 23.097515106201172}
2023-01-03 18:25:09.707 DEBUG: Taking gradient step
2023-01-03 18:25:11.618 DEBUG: Loss 3: {'policy_loss': 0.006804404956827121, 'entropy_loss': -0.029830947518348694, 'vf_loss': 0.006967095678141027, 'total_loss': -0.023026542561521573, 'approx_kl': -0.03817924903705716, 'clip_fraction': 0.4466145858168602, 'grad_norm': 22.08025550842285}
2023-01-03 18:25:13.500 DEBUG: Taking gradient step
2023-01-03 18:25:15.408 DEBUG: Loss 4: {'policy_loss': -0.007064397051586759, 'entropy_loss': -0.03081271192058921, 'vf_loss': 0.006410888645319726, 'total_loss': -0.037877108972175964, 'approx_kl': -0.03041771426796913, 'clip_fraction': 0.38671875, 'grad_norm': 14.88029670715332}
2023-01-03 18:25:17.334 DEBUG: Taking gradient step
2023-01-03 18:25:19.333 DEBUG: Loss 5: {'policy_loss': -0.008992199484239047, 'entropy_loss': -0.03097242210060358, 'vf_loss': 0.006667177302706109, 'total_loss': -0.039964621584842625, 'approx_kl': -0.041300129145383835, 'clip_fraction': 0.3841145858168602, 'grad_norm': 11.230963706970215}
2023-01-03 18:25:21.218 DEBUG: Taking gradient step
2023-01-03 18:25:23.153 DEBUG: Loss 6: {'policy_loss': 0.03506073116979531, 'entropy_loss': -0.03232628805562854, 'vf_loss': 0.008542884288268722, 'total_loss': 0.0027344431141667694, 'approx_kl': -0.05961382482200861, 'clip_fraction': 0.4270833432674408, 'grad_norm': 15.49988842010498}
2023-01-03 18:25:25.058 DEBUG: Taking gradient step
2023-01-03 18:25:27.087 DEBUG: Loss 7: {'policy_loss': -0.00048178318159245587, 'entropy_loss': -0.031203086022287607, 'vf_loss': 0.006787843207339834, 'total_loss': -0.03168486920388006, 'approx_kl': -0.07754349429160357, 'clip_fraction': 0.47265625, 'grad_norm': 20.85149383544922}
2023-01-03 18:25:28.991 DEBUG: Taking gradient step
2023-01-03 18:25:30.908 DEBUG: Loss 8: {'policy_loss': -0.01220695537481542, 'entropy_loss': -0.030279059428721666, 'vf_loss': 0.006086375370271209, 'total_loss': -0.04248601480353709, 'approx_kl': -0.06506920047104359, 'clip_fraction': 0.4296875, 'grad_norm': 20.03666114807129}
2023-01-03 18:25:32.814 DEBUG: Taking gradient step
2023-01-03 18:25:34.745 DEBUG: Loss 9: {'policy_loss': -0.0314464564468325, 'entropy_loss': -0.030108635779470205, 'vf_loss': 0.006100336082346895, 'total_loss': -0.061555092226302704, 'approx_kl': -0.08595300186425447, 'clip_fraction': 0.40625, 'grad_norm': 13.72134780883789}
2023-01-03 18:25:36.671 DEBUG: Taking gradient step
2023-01-03 18:25:38.607 DEBUG: Loss 10: {'policy_loss': 0.018036143728312085, 'entropy_loss': -0.03149810899049044, 'vf_loss': 0.0072493870375013566, 'total_loss': -0.013461965262178348, 'approx_kl': -0.06758979381993413, 'clip_fraction': 0.3151041716337204, 'grad_norm': 26.895732879638672}
2023-01-03 18:25:40.511 DEBUG: Taking gradient step
2023-01-03 18:25:42.447 DEBUG: Loss 11: {'policy_loss': 0.025889247513889404, 'entropy_loss': -0.03213970735669136, 'vf_loss': 0.007697778391100073, 'total_loss': -0.00625045984280196, 'approx_kl': -0.09049337543547153, 'clip_fraction': 0.3229166716337204, 'grad_norm': 19.558578491210938}
2023-01-03 18:25:44.335 DEBUG: Taking gradient step
2023-01-03 18:25:46.266 DEBUG: Loss 12: {'policy_loss': 0.005568782247739913, 'entropy_loss': -0.03089397633448243, 'vf_loss': 0.007241701564409188, 'total_loss': -0.025325194086742518, 'approx_kl': -0.10972351487725973, 'clip_fraction': 0.3125, 'grad_norm': 22.415895462036133}
2023-01-03 18:25:48.167 DEBUG: Taking gradient step
2023-01-03 18:25:50.098 DEBUG: Loss 13: {'policy_loss': -0.01793440361775394, 'entropy_loss': -0.03253217879682779, 'vf_loss': 0.006647980762442319, 'total_loss': -0.05046658241458173, 'approx_kl': -0.11038205586373806, 'clip_fraction': 0.32421875, 'grad_norm': 14.125009536743164}
2023-01-03 18:25:52.000 DEBUG: Taking gradient step
2023-01-03 18:25:53.940 DEBUG: Loss 14: {'policy_loss': -0.01402896980377413, 'entropy_loss': -0.03175412165001035, 'vf_loss': 0.006620127918133658, 'total_loss': -0.04578309145378448, 'approx_kl': -0.10123092774301767, 'clip_fraction': 0.3580729216337204, 'grad_norm': 12.195480346679688}
2023-01-03 18:25:53.940 INFO: Optimization: policy loss=-0.014, vf loss=0.007, entropy loss=-0.032, total loss=-0.046, num steps=15
2023-01-03 18:25:53.942 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 18:25:55.664 INFO: Evaluation rollout: return=0.499 (0.0), episode length=6.0
2023-01-03 18:25:55.667 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 18:25:55.670 INFO: Iteration: 136/137, steps: 29376
2023-01-03 18:26:49.066 DEBUG: There is a single atom floating around
2023-01-03 18:26:52.856 INFO: Training rollout: return=-0.352 (3.3), episode length=6.0
2023-01-03 18:26:52.858 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 18:26:52.860 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-29376_train.pkl
2023-01-03 18:26:54.793 DEBUG: Taking gradient step
2023-01-03 18:26:56.731 DEBUG: Loss 0: {'policy_loss': 0.001900868532278656, 'entropy_loss': -0.03343074815347791, 'vf_loss': 0.007172213889967362, 'total_loss': -0.03152987962119925, 'approx_kl': 9.972913161959696e-09, 'clip_fraction': 0.0, 'grad_norm': 12.907618522644043}
2023-01-03 18:26:58.627 DEBUG: Taking gradient step
2023-01-03 18:27:00.562 DEBUG: Loss 1: {'policy_loss': -0.020438656748976686, 'entropy_loss': -0.030698974151164293, 'vf_loss': 0.006826375117446556, 'total_loss': -0.05113763090014097, 'approx_kl': -0.010317050851881504, 'clip_fraction': 0.06901041697710752, 'grad_norm': 8.955401420593262}
2023-01-03 18:27:02.467 DEBUG: Taking gradient step
2023-01-03 18:27:04.406 DEBUG: Loss 2: {'policy_loss': 0.010003707242988328, 'entropy_loss': -0.03276609955355525, 'vf_loss': 0.007922277064965405, 'total_loss': -0.022762392310566922, 'approx_kl': -0.01898160483688116, 'clip_fraction': 0.3346354216337204, 'grad_norm': 12.428641319274902}
2023-01-03 18:27:06.318 DEBUG: Taking gradient step
2023-01-03 18:27:08.259 DEBUG: Loss 3: {'policy_loss': -0.015658336701137955, 'entropy_loss': -0.0340016451664269, 'vf_loss': 0.00681543821843407, 'total_loss': -0.049659981867564845, 'approx_kl': -0.0293180039152503, 'clip_fraction': 0.4166666716337204, 'grad_norm': 14.224581718444824}
2023-01-03 18:27:10.170 DEBUG: Taking gradient step
2023-01-03 18:27:12.197 DEBUG: Loss 4: {'policy_loss': -0.03569598959834173, 'entropy_loss': -0.03385856095701456, 'vf_loss': 0.0063554143568745475, 'total_loss': -0.06955455055535628, 'approx_kl': -0.03303782269358635, 'clip_fraction': 0.3776041716337204, 'grad_norm': 7.821272373199463}
2023-01-03 18:27:14.113 DEBUG: Taking gradient step
2023-01-03 18:27:16.052 DEBUG: Loss 5: {'policy_loss': 0.016673573917285633, 'entropy_loss': -0.033687657210975885, 'vf_loss': 0.008060938465375814, 'total_loss': -0.017014083293690252, 'approx_kl': -0.03410870674997568, 'clip_fraction': 0.31640625, 'grad_norm': 13.026582717895508}
2023-01-03 18:27:17.965 DEBUG: Taking gradient step
2023-01-03 18:27:19.890 DEBUG: Loss 6: {'policy_loss': 0.029713982653245874, 'entropy_loss': -0.032429980114102364, 'vf_loss': 0.009806154160688823, 'total_loss': -0.0027159974608564896, 'approx_kl': -0.03888147929683328, 'clip_fraction': 0.4205729216337204, 'grad_norm': 18.620906829833984}
2023-01-03 18:27:21.769 DEBUG: Taking gradient step
2023-01-03 18:27:23.671 DEBUG: Loss 7: {'policy_loss': -0.012095628980724032, 'entropy_loss': -0.03274580417200923, 'vf_loss': 0.007168606187362331, 'total_loss': -0.044841433152733264, 'approx_kl': -0.03907725680619478, 'clip_fraction': 0.3723958358168602, 'grad_norm': 8.957545280456543}
2023-01-03 18:27:25.536 DEBUG: Taking gradient step
2023-01-03 18:27:27.470 DEBUG: Loss 8: {'policy_loss': -0.01330161795388175, 'entropy_loss': -0.032897470984607935, 'vf_loss': 0.007282998916524421, 'total_loss': -0.04619908893848968, 'approx_kl': -0.06577806081622839, 'clip_fraction': 0.3854166716337204, 'grad_norm': 15.26072883605957}
2023-01-03 18:27:29.366 DEBUG: Taking gradient step
2023-01-03 18:27:31.310 DEBUG: Loss 9: {'policy_loss': -0.003008229227173382, 'entropy_loss': -0.0339756915345788, 'vf_loss': 0.007511945889674833, 'total_loss': -0.036983920761752186, 'approx_kl': -0.04753103363327682, 'clip_fraction': 0.3880208358168602, 'grad_norm': 8.086026191711426}
2023-01-03 18:27:33.208 DEBUG: Taking gradient step
2023-01-03 18:27:35.143 DEBUG: Loss 10: {'policy_loss': -0.03176154230314296, 'entropy_loss': -0.0319881672039628, 'vf_loss': 0.006699658310875899, 'total_loss': -0.06374970950710576, 'approx_kl': -0.05406968202441931, 'clip_fraction': 0.3919270858168602, 'grad_norm': 8.109369277954102}
2023-01-03 18:27:37.039 DEBUG: Taking gradient step
2023-01-03 18:27:38.973 DEBUG: Loss 11: {'policy_loss': -0.05447845093180663, 'entropy_loss': -0.032487948425114155, 'vf_loss': 0.006070047402428421, 'total_loss': -0.08696639935692078, 'approx_kl': -0.061085240449756384, 'clip_fraction': 0.39453125, 'grad_norm': 11.020301818847656}
2023-01-03 18:27:40.874 DEBUG: Taking gradient step
2023-01-03 18:27:42.827 DEBUG: Loss 12: {'policy_loss': -0.017596187191520517, 'entropy_loss': -0.03130825702100992, 'vf_loss': 0.007667336823779291, 'total_loss': -0.04890444421253043, 'approx_kl': -0.06116243451833725, 'clip_fraction': 0.390625, 'grad_norm': 9.737058639526367}
2023-01-03 18:27:44.722 DEBUG: Taking gradient step
2023-01-03 18:27:46.669 DEBUG: Loss 13: {'policy_loss': -0.059033977487472494, 'entropy_loss': -0.03014623560011387, 'vf_loss': 0.006044213771312494, 'total_loss': -0.08918021308758636, 'approx_kl': -0.053801750764250755, 'clip_fraction': 0.3463541716337204, 'grad_norm': 10.382652282714844}
2023-01-03 18:27:48.562 DEBUG: Taking gradient step
2023-01-03 18:27:50.499 DEBUG: Loss 14: {'policy_loss': -0.025873139419856705, 'entropy_loss': -0.03283229935914278, 'vf_loss': 0.007271091736163405, 'total_loss': -0.058705438778999475, 'approx_kl': -0.04594092565821484, 'clip_fraction': 0.39453125, 'grad_norm': 13.465376853942871}
2023-01-03 18:27:50.500 INFO: Optimization: policy loss=-0.026, vf loss=0.007, entropy loss=-0.033, total loss=-0.059, num steps=15
2023-01-03 18:27:50.501 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 18:27:52.214 INFO: Evaluation rollout: return=0.498 (0.0), episode length=6.0
2023-01-03 18:27:52.215 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 18:27:52.217 INFO: Iteration: 137/137, steps: 29592
2023-01-03 18:28:07.346 DEBUG: Atoms are too close
2023-01-03 18:28:50.324 INFO: Training rollout: return=-0.368 (3.3), episode length=6.0
2023-01-03 18:28:50.325 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_train.txt
2023-01-03 18:28:50.329 DEBUG: Saving rollout: runs/CH3NO_dna/data/CH3NO_dna_run-1_steps-29592_train.pkl
2023-01-03 18:28:52.244 DEBUG: Taking gradient step
2023-01-03 18:28:54.167 DEBUG: Loss 0: {'policy_loss': -0.013817242009428653, 'entropy_loss': -0.03289413219317794, 'vf_loss': 0.0065113832844931096, 'total_loss': -0.04671137420260659, 'approx_kl': 4.443185375180292e-09, 'clip_fraction': 0.0, 'grad_norm': 14.217440605163574}
2023-01-03 18:28:56.046 DEBUG: Taking gradient step
2023-01-03 18:28:58.044 DEBUG: Loss 1: {'policy_loss': -0.03789561608388135, 'entropy_loss': -0.03255309863016009, 'vf_loss': 0.006071333760829451, 'total_loss': -0.07044871471404145, 'approx_kl': -0.010543908225372434, 'clip_fraction': 0.12890625, 'grad_norm': 12.485099792480469}
2023-01-03 18:28:59.929 DEBUG: Taking gradient step
2023-01-03 18:29:01.845 DEBUG: Loss 2: {'policy_loss': -0.051819849110674325, 'entropy_loss': -0.032469984609633684, 'vf_loss': 0.006107521520756568, 'total_loss': -0.08428983372030802, 'approx_kl': -0.025720534147694707, 'clip_fraction': 0.3125, 'grad_norm': 11.482532501220703}
2023-01-03 18:29:03.721 DEBUG: Taking gradient step
2023-01-03 18:29:05.637 DEBUG: Loss 3: {'policy_loss': -0.011245071063599451, 'entropy_loss': -0.030893901828676462, 'vf_loss': 0.007216929767055464, 'total_loss': -0.04213897289227592, 'approx_kl': -0.009819416562095284, 'clip_fraction': 0.3098958358168602, 'grad_norm': 23.31956672668457}
2023-01-03 18:29:07.521 DEBUG: Taking gradient step
2023-01-03 18:29:09.440 DEBUG: Loss 4: {'policy_loss': -0.04066378955943536, 'entropy_loss': -0.03026560042053461, 'vf_loss': 0.0060866642134553605, 'total_loss': -0.07092938997996998, 'approx_kl': -0.01752498745918274, 'clip_fraction': 0.3111979179084301, 'grad_norm': 8.185256958007812}
2023-01-03 18:29:11.323 DEBUG: Taking gradient step
2023-01-03 18:29:13.231 DEBUG: Loss 5: {'policy_loss': -0.04661451483608503, 'entropy_loss': -0.030626424588263035, 'vf_loss': 0.0060749863413601, 'total_loss': -0.07724093942434807, 'approx_kl': -0.02319163945503533, 'clip_fraction': 0.3020833358168602, 'grad_norm': 7.847756862640381}
2023-01-03 18:29:15.104 DEBUG: Taking gradient step
2023-01-03 18:29:17.022 DEBUG: Loss 6: {'policy_loss': -0.043498543295444385, 'entropy_loss': -0.03005408588796854, 'vf_loss': 0.006077247338944643, 'total_loss': -0.07355262918341293, 'approx_kl': -0.030428193975239992, 'clip_fraction': 0.2486979216337204, 'grad_norm': 13.531734466552734}
2023-01-03 18:29:18.907 DEBUG: Taking gradient step
2023-01-03 18:29:20.842 DEBUG: Loss 7: {'policy_loss': 0.03318293619758896, 'entropy_loss': -0.03011337388306856, 'vf_loss': 0.008370562415763432, 'total_loss': 0.0030695623145204007, 'approx_kl': -0.0340527156367898, 'clip_fraction': 0.2486979216337204, 'grad_norm': 11.942667007446289}
2023-01-03 18:29:22.748 DEBUG: Taking gradient step
2023-01-03 18:29:24.706 DEBUG: Loss 8: {'policy_loss': 0.07016025386869168, 'entropy_loss': -0.03097126353532076, 'vf_loss': 0.00946677978588198, 'total_loss': 0.039188990333370935, 'approx_kl': -0.020774290896952152, 'clip_fraction': 0.2916666716337204, 'grad_norm': 29.885513305664062}
2023-01-03 18:29:26.608 DEBUG: Taking gradient step
2023-01-03 18:29:28.556 DEBUG: Loss 9: {'policy_loss': -0.0018208923250884745, 'entropy_loss': -0.03253813832998276, 'vf_loss': 0.006653579353235241, 'total_loss': -0.03435903065507123, 'approx_kl': -0.04917910438962281, 'clip_fraction': 0.26953125, 'grad_norm': 13.185036659240723}
2023-01-03 18:29:30.450 DEBUG: Taking gradient step
2023-01-03 18:29:32.377 DEBUG: Loss 10: {'policy_loss': 0.06099469037444961, 'entropy_loss': -0.03161033056676388, 'vf_loss': 0.008864567739292546, 'total_loss': 0.02938435980768573, 'approx_kl': -0.0462978778523393, 'clip_fraction': 0.3059895858168602, 'grad_norm': 33.98566818237305}
2023-01-03 18:29:34.263 DEBUG: Taking gradient step
2023-01-03 18:29:36.210 DEBUG: Loss 11: {'policy_loss': -0.025857671010600092, 'entropy_loss': -0.03263993002474308, 'vf_loss': 0.006069611713856238, 'total_loss': -0.05849760103534317, 'approx_kl': -0.04940174613147974, 'clip_fraction': 0.2434895858168602, 'grad_norm': 14.29318904876709}
2023-01-03 18:29:38.103 DEBUG: Taking gradient step
2023-01-03 18:29:40.041 DEBUG: Loss 12: {'policy_loss': 0.014108655918882433, 'entropy_loss': -0.03338122367858887, 'vf_loss': 0.007185891517725808, 'total_loss': -0.019272567759706434, 'approx_kl': -0.04864578042179346, 'clip_fraction': 0.31640625, 'grad_norm': 13.978057861328125}
2023-01-03 18:29:41.946 DEBUG: Taking gradient step
2023-01-03 18:29:43.892 DEBUG: Loss 13: {'policy_loss': 0.03626895078672683, 'entropy_loss': -0.03202771581709385, 'vf_loss': 0.008295003506954949, 'total_loss': 0.0042412349696329815, 'approx_kl': -0.054730046540498734, 'clip_fraction': 0.38671875, 'grad_norm': 16.628372192382812}
2023-01-03 18:29:45.797 DEBUG: Taking gradient step
2023-01-03 18:29:47.809 DEBUG: Loss 14: {'policy_loss': -0.036367984028274986, 'entropy_loss': -0.03155913017690182, 'vf_loss': 0.006062914028212621, 'total_loss': -0.0679271142051768, 'approx_kl': -0.04157147649675608, 'clip_fraction': 0.3815104216337204, 'grad_norm': 11.065022468566895}
2023-01-03 18:29:47.810 INFO: Optimization: policy loss=-0.036, vf loss=0.006, entropy loss=-0.032, total loss=-0.068, num steps=15
2023-01-03 18:29:47.811 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_opt.txt
2023-01-03 18:29:49.530 INFO: Evaluation rollout: return=0.498 (0.0), episode length=6.0
2023-01-03 18:29:49.531 DEBUG: Saving info: runs/CH3NO_dna/results/CH3NO_dna_run-1_eval.txt
2023-01-03 18:29:49.534 DEBUG: Deleting old model: runs/CH3NO_dna/models/CH3NO_dna_run-1_steps-28296.model
2023-01-03 18:29:49.540 DEBUG: Saving model: runs/CH3NO_dna/models/CH3NO_dna_run-1_steps-29808.model
2023-01-03 18:29:49.587 INFO: Finished PPO
2023-01-03 20:20:23.271 INFO: {
    "bag_scale": 6,
    "beta": "-10",
    "canvas_size": 6,
    "clip_ratio": 0.2,
    "cutoff": 4.0,
    "data_dir": "runs/CH3NO_dna/data",
    "device": "cuda",
    "discount": 0.85,
    "entropy_coef": 0.06,
    "eval_formulas": "CH3NO",
    "eval_freq": 1,
    "formulas": "CH3NO",
    "gradient_clip": 0.5,
    "keep_models": false,
    "lam": 0.95,
    "learning_rate": 0.0005,
    "load_latest": false,
    "load_model": null,
    "log_dir": "runs/CH3NO_dna/logs",
    "log_level": "DEBUG",
    "max_mean_distance": 1.8,
    "max_num_steps": 30000,
    "max_num_train_iters": 15,
    "max_solo_distance": 2.0,
    "maxl": 4,
    "min_atomic_distance": 0.6,
    "min_mean_distance": 0.8,
    "min_reward": -30.0,
    "mini_batch_size": 64,
    "model": "schnet_edge",
    "model_dir": "runs/CH3NO_dna/models",
    "name": "CH3NO_dna",
    "network_width": 128,
    "num_cg_levels": 3,
    "num_channels_hidden": 10,
    "num_channels_per_element": 4,
    "num_envs": 12,
    "num_eval_episodes": null,
    "num_gaussians": 3,
    "num_interactions": 3,
    "num_steps_per_iter": 216,
    "optimizer": "adam",
    "results_dir": "runs/CH3NO_dna/results",
    "save_freq": 10,
    "save_rollouts": "train",
    "seed": 1,
    "symbols": "X,H,C,N,O",
    "target_kl": 0.03,
    "update_edges": true,
    "vf_coef": 0.0003
}
2023-01-03 20:20:23.315 INFO: CUDA Device: 0
2023-01-03 20:20:23.316 INFO: Training bags: ['CH3NO']
2023-01-03 20:20:23.316 INFO: Evaluation bags: ['CH3NO']
2023-01-03 20:20:25.167 INFO: Number of parameters: 300502
2023-01-03 20:20:25.179 INFO: Starting PPO
2023-01-03 20:20:25.179 INFO: Iteration: 0/137, steps: 0
2023-01-03 20:20:30.128 DEBUG: There is a single atom floating around
2023-01-03 20:20:31.321 DEBUG: There is a single atom floating around
2023-01-03 20:20:34.747 DEBUG: Atoms are too close
2023-01-03 20:20:35.098 DEBUG: Atoms are too close
2023-01-03 20:20:37.923 DEBUG: Atoms are too close
2023-01-03 20:20:38.639 DEBUG: There is a single atom floating around
2023-01-03 20:20:38.913 DEBUG: Atoms are too close
2023-01-03 20:20:39.496 DEBUG: There is a single atom floating around
2023-01-03 20:20:42.066 DEBUG: There is a single atom floating around
