2023-01-03 20:21:38.796 INFO: {
    "bag_scale": 6,
    "beta": "-10",
    "canvas_size": 6,
    "clip_ratio": 0.2,
    "cutoff": 4.0,
    "data_dir": "runs/CH3NO_baseline/data",
    "device": "cuda",
    "discount": 0.85,
    "entropy_coef": 0.06,
    "eval_formulas": "CH3NO",
    "eval_freq": 1,
    "formulas": "CH3NO",
    "gradient_clip": 0.5,
    "keep_models": false,
    "lam": 0.95,
    "learning_rate": 0.0005,
    "load_latest": false,
    "load_model": null,
    "log_dir": "runs/CH3NO_baseline/logs",
    "log_level": "DEBUG",
    "max_mean_distance": 1.8,
    "max_num_steps": 30000,
    "max_num_train_iters": 15,
    "max_solo_distance": 2.0,
    "maxl": 4,
    "min_atomic_distance": 0.6,
    "min_mean_distance": 0.8,
    "min_reward": -30.0,
    "mini_batch_size": 64,
    "model": "schnet_edge",
    "model_dir": "runs/CH3NO_baseline/models",
    "name": "CH3NO_baseline",
    "network_width": 128,
    "num_cg_levels": 3,
    "num_channels_hidden": 10,
    "num_channels_per_element": 4,
    "num_envs": 12,
    "num_eval_episodes": null,
    "num_gaussians": 3,
    "num_interactions": 3,
    "num_steps_per_iter": 216,
    "optimizer": "adam",
    "results_dir": "runs/CH3NO_baseline/results",
    "save_freq": 10,
    "save_rollouts": "train",
    "seed": 1,
    "symbols": "X,H,C,N,O",
    "target_kl": 0.03,
    "update_edges": true,
    "vf_coef": 0.0003
}
2023-01-03 20:21:38.837 INFO: CUDA Device: 0
2023-01-03 20:21:38.838 INFO: Training bags: ['CH3NO']
2023-01-03 20:21:38.838 INFO: Evaluation bags: ['CH3NO']
2023-01-03 20:21:40.681 INFO: Number of parameters: 300502
2023-01-03 20:21:40.696 INFO: Starting PPO
2023-01-03 20:21:40.697 INFO: Iteration: 0/137, steps: 0
2023-01-03 20:21:45.513 DEBUG: There is a single atom floating around
2023-01-03 20:21:46.685 DEBUG: There is a single atom floating around
2023-01-03 20:21:50.105 DEBUG: Atoms are too close
2023-01-03 20:21:50.473 DEBUG: Atoms are too close
2023-01-03 20:21:53.373 DEBUG: Atoms are too close
2023-01-03 20:21:54.153 DEBUG: There is a single atom floating around
2023-01-03 20:21:54.457 DEBUG: Atoms are too close
2023-01-03 20:21:55.024 DEBUG: There is a single atom floating around
2023-01-03 20:21:57.549 DEBUG: There is a single atom floating around
2023-01-03 20:21:59.542 DEBUG: Atoms are too close
2023-01-03 20:22:03.674 DEBUG: There is a single atom floating around
2023-01-03 20:22:07.244 DEBUG: Atoms are too close
2023-01-03 20:22:11.563 DEBUG: There is a single atom floating around
2023-01-03 20:22:15.215 DEBUG: Atoms are too close
2023-01-03 20:22:15.502 DEBUG: There is a single atom floating around
2023-01-03 20:22:24.520 DEBUG: Atoms are too close
2023-01-03 20:22:26.218 DEBUG: There is a single atom floating around
2023-01-03 20:22:26.501 DEBUG: There is a single atom floating around
2023-01-03 20:22:27.218 DEBUG: There is a single atom floating around
2023-01-03 20:22:32.673 DEBUG: Atoms are too close
2023-01-03 20:22:33.807 DEBUG: Atoms are too close
2023-01-03 20:22:33.880 INFO: Training rollout: return=-8.561 (9.2), episode length=5.2
2023-01-03 20:22:33.881 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 20:22:33.884 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-0_train.pkl
2023-01-03 20:22:34.905 DEBUG: Taking gradient step
2023-01-03 20:22:34.917 DEBUG: Loss 0: {'policy_loss': -0.011204542202760378, 'entropy_loss': -0.08535782620310783, 'vf_loss': 0.07002943980058243, 'total_loss': -0.02653292860528579, 'approx_kl': -3.337239218303978e-08, 'clip_fraction': 0.0, 'grad_norm': 19.567424774169922}
2023-01-03 20:22:35.923 DEBUG: Early stopping at step 1 for reaching max KL.
2023-01-03 20:22:35.924 INFO: Optimization: policy loss=-0.011, vf loss=0.070, entropy loss=-0.085, total loss=-0.027, num steps=1
2023-01-03 20:22:35.924 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 20:22:37.362 DEBUG: Atoms are too close
2023-01-03 20:22:37.363 INFO: Evaluation rollout: return=-13.050 (0.0), episode length=6.0
2023-01-03 20:22:37.364 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 20:22:37.367 DEBUG: Saving model: runs/CH3NO_baseline/models/CH3NO_baseline_run-1_steps-216.model
2023-01-03 20:22:37.397 INFO: Iteration: 1/137, steps: 216
2023-01-03 20:22:41.610 DEBUG: There is a single atom floating around
2023-01-03 20:22:48.691 DEBUG: Atoms are too close
2023-01-03 20:22:49.363 DEBUG: Atoms are too close
2023-01-03 20:22:49.364 DEBUG: There is a single atom floating around
2023-01-03 20:22:52.541 DEBUG: Atoms are too close
2023-01-03 20:22:58.441 DEBUG: There is a single atom floating around
2023-01-03 20:23:01.129 DEBUG: Atoms are too close
2023-01-03 20:23:05.915 DEBUG: Atoms are too close
2023-01-03 20:23:06.570 DEBUG: Atoms are too close
2023-01-03 20:23:06.570 DEBUG: There is a single atom floating around
2023-01-03 20:23:06.845 DEBUG: Atoms are too close
2023-01-03 20:23:07.716 DEBUG: There is a single atom floating around
2023-01-03 20:23:09.606 DEBUG: There is a single atom floating around
2023-01-03 20:23:09.608 DEBUG: There is a single atom floating around
2023-01-03 20:23:11.568 DEBUG: Atoms are too close
2023-01-03 20:23:17.267 DEBUG: Atoms are too close
2023-01-03 20:23:17.268 DEBUG: There is a single atom floating around
2023-01-03 20:23:18.579 DEBUG: Atoms are too close
2023-01-03 20:23:20.791 DEBUG: There is a single atom floating around
2023-01-03 20:23:23.362 DEBUG: Atoms are too close
2023-01-03 20:23:24.948 DEBUG: There is a single atom floating around
2023-01-03 20:23:26.630 DEBUG: There is a single atom floating around
2023-01-03 20:23:26.922 DEBUG: Atoms are too close
2023-01-03 20:23:27.709 INFO: Training rollout: return=-10.073 (8.7), episode length=5.1
2023-01-03 20:23:27.710 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 20:23:27.713 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-216_train.pkl
2023-01-03 20:23:28.706 DEBUG: Taking gradient step
2023-01-03 20:23:28.717 DEBUG: Loss 0: {'policy_loss': -0.02110452253669832, 'entropy_loss': -0.0845111720263958, 'vf_loss': 0.07387070921942977, 'total_loss': -0.03174498534366434, 'approx_kl': -4.734223324476261e-08, 'clip_fraction': 0.0, 'grad_norm': 13.000587463378906}
2023-01-03 20:23:29.717 DEBUG: Early stopping at step 1 for reaching max KL.
2023-01-03 20:23:29.717 INFO: Optimization: policy loss=-0.021, vf loss=0.074, entropy loss=-0.085, total loss=-0.032, num steps=1
2023-01-03 20:23:29.718 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 20:23:31.450 INFO: Evaluation rollout: return=-0.366 (0.0), episode length=6.0
2023-01-03 20:23:31.451 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 20:23:31.454 INFO: Iteration: 2/137, steps: 432
2023-01-03 20:23:34.490 DEBUG: There is a single atom floating around
2023-01-03 20:23:45.050 DEBUG: Atoms are too close
2023-01-03 20:23:45.350 DEBUG: Atoms are too close
2023-01-03 20:23:45.352 DEBUG: Atoms are too close
2023-01-03 20:23:45.627 DEBUG: There is a single atom floating around
2023-01-03 20:23:45.629 DEBUG: There is a single atom floating around
2023-01-03 20:23:45.988 DEBUG: There is a single atom floating around
2023-01-03 20:23:47.537 DEBUG: There is a single atom floating around
2023-01-03 20:23:56.824 DEBUG: There is a single atom floating around
2023-01-03 20:24:00.292 DEBUG: There is a single atom floating around
2023-01-03 20:24:00.372 DEBUG: Atoms are too close
2023-01-03 20:24:00.913 DEBUG: Atoms are too close
2023-01-03 20:24:01.197 DEBUG: Atoms are too close
2023-01-03 20:24:01.199 DEBUG: Atoms are too close
2023-01-03 20:24:06.047 DEBUG: There is a single atom floating around
2023-01-03 20:24:07.351 DEBUG: Atoms are too close
2023-01-03 20:24:10.583 DEBUG: There is a single atom floating around
2023-01-03 20:24:14.001 DEBUG: There is a single atom floating around
2023-01-03 20:24:14.874 DEBUG: There is a single atom floating around
2023-01-03 20:24:15.712 DEBUG: Atoms are too close
2023-01-03 20:24:17.057 DEBUG: There is a single atom floating around
2023-01-03 20:24:17.760 DEBUG: There is a single atom floating around
2023-01-03 20:24:22.046 INFO: Training rollout: return=-9.273 (8.3), episode length=5.3
2023-01-03 20:24:22.048 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 20:24:22.050 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-432_train.pkl
2023-01-03 20:24:23.023 DEBUG: Taking gradient step
2023-01-03 20:24:23.032 DEBUG: Loss 0: {'policy_loss': -0.03809183618107262, 'entropy_loss': -0.08542696759104729, 'vf_loss': 0.06943689227147641, 'total_loss': -0.05408191150064348, 'approx_kl': 1.6763806343078613e-08, 'clip_fraction': 0.0, 'grad_norm': 9.608494758605957}
2023-01-03 20:24:24.009 DEBUG: Early stopping at step 1 for reaching max KL.
2023-01-03 20:24:24.010 INFO: Optimization: policy loss=-0.038, vf loss=0.069, entropy loss=-0.085, total loss=-0.054, num steps=1
2023-01-03 20:24:24.011 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 20:24:25.705 INFO: Evaluation rollout: return=0.293 (0.0), episode length=6.0
2023-01-03 20:24:25.706 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 20:24:25.708 INFO: Iteration: 3/137, steps: 648
2023-01-03 20:24:28.135 DEBUG: There is a single atom floating around
2023-01-03 20:24:34.525 DEBUG: Atoms are too close
2023-01-03 20:24:34.797 DEBUG: Atoms are too close
2023-01-03 20:24:35.642 DEBUG: Atoms are too close
2023-01-03 20:24:35.644 DEBUG: Atoms are too close
2023-01-03 20:24:36.229 DEBUG: Atoms are too close
2023-01-03 20:24:37.185 DEBUG: Atoms are too close
2023-01-03 20:24:37.478 DEBUG: Atoms are too close
2023-01-03 20:24:37.760 DEBUG: Atoms are too close
2023-01-03 20:24:39.593 DEBUG: There is a single atom floating around
2023-01-03 20:24:45.100 DEBUG: Atoms are too close
2023-01-03 20:24:45.959 DEBUG: Atoms are too close
2023-01-03 20:24:48.094 DEBUG: There is a single atom floating around
2023-01-03 20:24:48.839 DEBUG: Atoms are too close
2023-01-03 20:24:50.067 DEBUG: Atoms are too close
2023-01-03 20:24:51.804 DEBUG: Atoms are too close
2023-01-03 20:24:54.057 DEBUG: There is a single atom floating around
2023-01-03 20:24:55.320 DEBUG: Atoms are too close
2023-01-03 20:24:55.605 DEBUG: Atoms are too close
2023-01-03 20:24:57.441 DEBUG: Atoms are too close
2023-01-03 20:24:59.403 DEBUG: Atoms are too close
2023-01-03 20:25:01.346 DEBUG: Atoms are too close
2023-01-03 20:25:02.354 DEBUG: Atoms are too close
2023-01-03 20:25:02.946 DEBUG: Atoms are too close
2023-01-03 20:25:06.660 DEBUG: Atoms are too close
2023-01-03 20:25:10.401 DEBUG: Atoms are too close
2023-01-03 20:25:14.759 DEBUG: Atoms are too close
2023-01-03 20:25:15.134 INFO: Training rollout: return=-11.582 (7.7), episode length=5.1
2023-01-03 20:25:15.135 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 20:25:15.138 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-648_train.pkl
2023-01-03 20:25:16.147 DEBUG: Taking gradient step
2023-01-03 20:25:16.156 DEBUG: Loss 0: {'policy_loss': -0.025990269555798945, 'entropy_loss': -0.08026208356022835, 'vf_loss': 0.08400979640386548, 'total_loss': -0.022242556712161812, 'approx_kl': 3.2906733338222693e-08, 'clip_fraction': 0.0, 'grad_norm': 15.928084373474121}
2023-01-03 20:25:17.084 DEBUG: Early stopping at step 1 for reaching max KL.
2023-01-03 20:25:17.084 INFO: Optimization: policy loss=-0.026, vf loss=0.084, entropy loss=-0.080, total loss=-0.022, num steps=1
2023-01-03 20:25:17.084 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 20:25:18.833 INFO: Evaluation rollout: return=0.347 (0.0), episode length=6.0
2023-01-03 20:25:18.834 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 20:25:18.837 INFO: Iteration: 4/137, steps: 864
2023-01-03 20:25:27.883 DEBUG: Atoms are too close
2023-01-03 20:25:28.166 DEBUG: Atoms are too close
2023-01-03 20:25:34.401 DEBUG: There is a single atom floating around
2023-01-03 20:25:35.304 DEBUG: There is a single atom floating around
2023-01-03 20:25:35.305 DEBUG: There is a single atom floating around
2023-01-03 20:25:35.603 DEBUG: There is a single atom floating around
2023-01-03 20:25:47.967 DEBUG: There is a single atom floating around
2023-01-03 20:25:50.325 DEBUG: Atoms are too close
2023-01-03 20:25:50.766 DEBUG: There is a single atom floating around
2023-01-03 20:25:52.515 DEBUG: Atoms are too close
2023-01-03 20:25:57.728 DEBUG: There is a single atom floating around
2023-01-03 20:26:08.807 DEBUG: There is a single atom floating around
2023-01-03 20:26:10.823 DEBUG: Atoms are too close
2023-01-03 20:26:12.474 DEBUG: Atoms are too close
2023-01-03 20:26:12.543 INFO: Training rollout: return=-5.665 (8.1), episode length=5.6
2023-01-03 20:26:12.544 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 20:26:12.547 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-864_train.pkl
2023-01-03 20:26:13.581 DEBUG: Taking gradient step
2023-01-03 20:26:13.591 DEBUG: Loss 0: {'policy_loss': 0.04431584878667813, 'entropy_loss': -0.08461300656199455, 'vf_loss': 0.048013621798626685, 'total_loss': 0.00771646402331027, 'approx_kl': 4.866160452365875e-08, 'clip_fraction': 0.0, 'grad_norm': 15.059677124023438}
2023-01-03 20:26:14.664 DEBUG: Early stopping at step 1 for reaching max KL.
2023-01-03 20:26:14.665 INFO: Optimization: policy loss=0.044, vf loss=0.048, entropy loss=-0.085, total loss=0.008, num steps=1
2023-01-03 20:26:14.665 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 20:26:16.342 INFO: Evaluation rollout: return=0.207 (0.0), episode length=6.0
2023-01-03 20:26:16.343 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 20:26:16.346 INFO: Iteration: 5/137, steps: 1080
2023-01-03 20:26:18.988 DEBUG: There is a single atom floating around
2023-01-03 20:26:26.210 DEBUG: There is a single atom floating around
2023-01-03 20:26:27.656 DEBUG: There is a single atom floating around
2023-01-03 20:26:28.492 DEBUG: Atoms are too close
2023-01-03 20:26:28.910 DEBUG: Atoms are too close
2023-01-03 20:26:28.911 DEBUG: There is a single atom floating around
2023-01-03 20:26:30.222 DEBUG: Atoms are too close
2023-01-03 20:26:31.735 DEBUG: There is a single atom floating around
2023-01-03 20:26:41.765 DEBUG: Atoms are too close
2023-01-03 20:26:42.610 DEBUG: There is a single atom floating around
2023-01-03 20:26:42.611 DEBUG: Atoms are too close
2023-01-03 20:26:44.755 DEBUG: There is a single atom floating around
2023-01-03 20:26:45.308 DEBUG: There is a single atom floating around
2023-01-03 20:26:45.309 DEBUG: Atoms are too close
2023-01-03 20:26:45.571 DEBUG: There is a single atom floating around
2023-01-03 20:26:46.316 DEBUG: Atoms are too close
2023-01-03 20:26:51.391 DEBUG: Atoms are too close
2023-01-03 20:26:55.795 DEBUG: Atoms are too close
2023-01-03 20:26:56.658 DEBUG: Atoms are too close
2023-01-03 20:26:59.330 DEBUG: Atoms are too close
2023-01-03 20:27:02.915 DEBUG: There is a single atom floating around
2023-01-03 20:27:05.465 INFO: Training rollout: return=-8.783 (8.4), episode length=5.4
2023-01-03 20:27:05.467 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 20:27:05.469 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-1080_train.pkl
2023-01-03 20:27:06.461 DEBUG: Taking gradient step
2023-01-03 20:27:06.471 DEBUG: Loss 0: {'policy_loss': -0.0814115230653739, 'entropy_loss': -0.08246506564319134, 'vf_loss': 0.05989420513419085, 'total_loss': -0.10398238357437438, 'approx_kl': 4.967052547044659e-09, 'clip_fraction': 0.0, 'grad_norm': 15.174511909484863}
2023-01-03 20:27:07.525 DEBUG: Taking gradient step
2023-01-03 20:27:07.536 DEBUG: Loss 1: {'policy_loss': 0.015476601662156962, 'entropy_loss': -0.08164536021649837, 'vf_loss': 0.06671214566385299, 'total_loss': 0.0005433871095115693, 'approx_kl': 0.03766962140798569, 'clip_fraction': 0.36328125, 'grad_norm': 20.54233169555664}
2023-01-03 20:27:08.575 DEBUG: Early stopping at step 2 for reaching max KL.
2023-01-03 20:27:08.576 INFO: Optimization: policy loss=0.015, vf loss=0.067, entropy loss=-0.082, total loss=0.001, num steps=2
2023-01-03 20:27:08.576 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 20:27:10.269 INFO: Evaluation rollout: return=0.171 (0.0), episode length=6.0
2023-01-03 20:27:10.270 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 20:27:10.272 INFO: Iteration: 6/137, steps: 1296
2023-01-03 20:27:20.736 DEBUG: There is a single atom floating around
2023-01-03 20:27:22.234 DEBUG: There is a single atom floating around
2023-01-03 20:27:24.632 DEBUG: Atoms are too close
2023-01-03 20:27:25.413 DEBUG: There is a single atom floating around
2023-01-03 20:27:43.949 DEBUG: Atoms are too close
2023-01-03 20:27:43.952 DEBUG: Atoms are too close
2023-01-03 20:27:44.789 DEBUG: Atoms are too close
2023-01-03 20:27:55.324 DEBUG: There is a single atom floating around
2023-01-03 20:27:59.167 DEBUG: There is a single atom floating around
2023-01-03 20:28:00.922 DEBUG: Atoms are too close
2023-01-03 20:28:01.498 DEBUG: There is a single atom floating around
2023-01-03 20:28:03.242 INFO: Training rollout: return=-4.034 (7.0), episode length=5.8
2023-01-03 20:28:03.243 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 20:28:03.246 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-1296_train.pkl
2023-01-03 20:28:04.274 DEBUG: Taking gradient step
2023-01-03 20:28:04.285 DEBUG: Loss 0: {'policy_loss': -0.016175866166125163, 'entropy_loss': -0.08269161358475685, 'vf_loss': 0.034744003891737284, 'total_loss': -0.06412347585914473, 'approx_kl': 1.0632599689586186e-08, 'clip_fraction': 0.0, 'grad_norm': 13.86735725402832}
2023-01-03 20:28:05.334 DEBUG: Taking gradient step
2023-01-03 20:28:05.343 DEBUG: Loss 1: {'policy_loss': 0.0010526438521752245, 'entropy_loss': -0.08075628615915775, 'vf_loss': 0.03641707807767895, 'total_loss': -0.043286564229303576, 'approx_kl': 0.018571611028164625, 'clip_fraction': 0.2083333358168602, 'grad_norm': 23.79727554321289}
2023-01-03 20:28:06.408 DEBUG: Taking gradient step
2023-01-03 20:28:06.419 DEBUG: Loss 2: {'policy_loss': -0.03834580629815661, 'entropy_loss': -0.08055699430406094, 'vf_loss': 0.03158323564757722, 'total_loss': -0.08731956495464031, 'approx_kl': 0.030627533327788115, 'clip_fraction': 0.3294270858168602, 'grad_norm': 25.516300201416016}
2023-01-03 20:28:07.448 DEBUG: Early stopping at step 3 for reaching max KL.
2023-01-03 20:28:07.449 INFO: Optimization: policy loss=-0.038, vf loss=0.032, entropy loss=-0.081, total loss=-0.087, num steps=3
2023-01-03 20:28:07.449 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 20:28:08.873 DEBUG: Atoms are too close
2023-01-03 20:28:08.874 INFO: Evaluation rollout: return=-12.921 (0.0), episode length=6.0
2023-01-03 20:28:08.875 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 20:28:08.878 INFO: Iteration: 7/137, steps: 1512
2023-01-03 20:28:18.888 DEBUG: Atoms are too close
2023-01-03 20:28:22.912 DEBUG: There is a single atom floating around
2023-01-03 20:28:22.915 DEBUG: There is a single atom floating around
2023-01-03 20:28:23.510 DEBUG: There is a single atom floating around
2023-01-03 20:28:23.883 DEBUG: There is a single atom floating around
2023-01-03 20:28:25.051 DEBUG: There is a single atom floating around
2023-01-03 20:28:41.629 DEBUG: Atoms are too close
2023-01-03 20:28:42.232 DEBUG: Atoms are too close
2023-01-03 20:28:45.013 DEBUG: Atoms are too close
2023-01-03 20:28:58.898 DEBUG: Atoms are too close
2023-01-03 20:28:59.168 DEBUG: There is a single atom floating around
2023-01-03 20:29:02.832 DEBUG: There is a single atom floating around
2023-01-03 20:29:04.226 INFO: Training rollout: return=-4.427 (7.0), episode length=5.8
2023-01-03 20:29:04.227 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 20:29:04.230 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-1512_train.pkl
2023-01-03 20:29:05.250 DEBUG: Taking gradient step
2023-01-03 20:29:05.260 DEBUG: Loss 0: {'policy_loss': -0.023995939933195848, 'entropy_loss': -0.07961532287299633, 'vf_loss': 0.03573270676464487, 'total_loss': -0.0678785560415473, 'approx_kl': 8.164595044490852e-08, 'clip_fraction': 0.0, 'grad_norm': 18.08833122253418}
2023-01-03 20:29:06.270 DEBUG: Taking gradient step
2023-01-03 20:29:06.279 DEBUG: Loss 1: {'policy_loss': -0.02907400323345313, 'entropy_loss': -0.07846994511783123, 'vf_loss': 0.03600631209735793, 'total_loss': -0.07153763625392642, 'approx_kl': 0.01850982243195176, 'clip_fraction': 0.1106770858168602, 'grad_norm': 8.727365493774414}
2023-01-03 20:29:07.293 DEBUG: Early stopping at step 2 for reaching max KL.
2023-01-03 20:29:07.293 INFO: Optimization: policy loss=-0.029, vf loss=0.036, entropy loss=-0.078, total loss=-0.072, num steps=2
2023-01-03 20:29:07.294 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 20:29:08.723 DEBUG: Atoms are too close
2023-01-03 20:29:08.725 INFO: Evaluation rollout: return=-12.917 (0.0), episode length=6.0
2023-01-03 20:29:08.726 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 20:29:08.729 INFO: Iteration: 8/137, steps: 1728
2023-01-03 20:29:20.043 DEBUG: Atoms are too close
2023-01-03 20:29:20.920 DEBUG: There is a single atom floating around
2023-01-03 20:29:20.922 DEBUG: There is a single atom floating around
2023-01-03 20:29:22.646 DEBUG: Atoms are too close
2023-01-03 20:29:22.709 DEBUG: There is a single atom floating around
2023-01-03 20:29:24.538 DEBUG: Atoms are too close
2023-01-03 20:29:37.209 DEBUG: There is a single atom floating around
2023-01-03 20:29:37.555 DEBUG: Atoms are too close
2023-01-03 20:29:40.879 DEBUG: Atoms are too close
2023-01-03 20:29:42.715 DEBUG: There is a single atom floating around
2023-01-03 20:29:54.612 DEBUG: Atoms are too close
2023-01-03 20:30:00.220 DEBUG: There is a single atom floating around
2023-01-03 20:30:01.270 INFO: Training rollout: return=-4.278 (7.4), episode length=5.8
2023-01-03 20:30:01.271 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 20:30:01.274 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-1728_train.pkl
2023-01-03 20:30:02.306 DEBUG: Taking gradient step
2023-01-03 20:30:02.315 DEBUG: Loss 0: {'policy_loss': 0.008141374438529244, 'entropy_loss': -0.07861961983144283, 'vf_loss': 0.04052356509989065, 'total_loss': -0.02995468029302294, 'approx_kl': 2.0993563026872053e-08, 'clip_fraction': 0.0, 'grad_norm': 9.131771087646484}
2023-01-03 20:30:03.373 DEBUG: Taking gradient step
2023-01-03 20:30:03.382 DEBUG: Loss 1: {'policy_loss': -0.02047511877914531, 'entropy_loss': -0.07852000184357166, 'vf_loss': 0.04158122079667747, 'total_loss': -0.057413899826039505, 'approx_kl': 0.010939748026430607, 'clip_fraction': 0.1796875, 'grad_norm': 14.565718650817871}
2023-01-03 20:30:04.439 DEBUG: Taking gradient step
2023-01-03 20:30:04.448 DEBUG: Loss 2: {'policy_loss': -0.015882170339540102, 'entropy_loss': -0.07762587815523148, 'vf_loss': 0.04009307578247156, 'total_loss': -0.053414972712300016, 'approx_kl': 0.025932131335139275, 'clip_fraction': 0.375, 'grad_norm': 10.755680084228516}
2023-01-03 20:30:05.494 DEBUG: Taking gradient step
2023-01-03 20:30:05.503 DEBUG: Loss 3: {'policy_loss': -0.02717270962973632, 'entropy_loss': -0.07675210200250149, 'vf_loss': 0.03910716357690596, 'total_loss': -0.06481764805533184, 'approx_kl': 0.04046332696452737, 'clip_fraction': 0.3307291716337204, 'grad_norm': 9.524561882019043}
2023-01-03 20:30:06.519 DEBUG: Taking gradient step
2023-01-03 20:30:06.530 DEBUG: Loss 4: {'policy_loss': -0.015287542157077082, 'entropy_loss': -0.07711022719740868, 'vf_loss': 0.04023083227608272, 'total_loss': -0.05216693707840304, 'approx_kl': 0.041280381847172976, 'clip_fraction': 0.3424479216337204, 'grad_norm': 8.692253112792969}
2023-01-03 20:30:07.583 DEBUG: Taking gradient step
2023-01-03 20:30:07.592 DEBUG: Loss 5: {'policy_loss': -0.020772206027391275, 'entropy_loss': -0.07689792662858963, 'vf_loss': 0.04141058926129708, 'total_loss': -0.05625954339468382, 'approx_kl': 0.04410388879477978, 'clip_fraction': 0.3125, 'grad_norm': 7.800442695617676}
2023-01-03 20:30:08.649 DEBUG: Taking gradient step
2023-01-03 20:30:08.658 DEBUG: Loss 6: {'policy_loss': -0.04477821439733639, 'entropy_loss': -0.07669071294367313, 'vf_loss': 0.03714901534784451, 'total_loss': -0.084319911993165, 'approx_kl': 0.026407168712466955, 'clip_fraction': 0.3046875, 'grad_norm': 12.151193618774414}
2023-01-03 20:30:09.683 DEBUG: Early stopping at step 7 for reaching max KL.
2023-01-03 20:30:09.684 INFO: Optimization: policy loss=-0.045, vf loss=0.037, entropy loss=-0.077, total loss=-0.084, num steps=7
2023-01-03 20:30:09.685 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 20:30:11.091 DEBUG: Atoms are too close
2023-01-03 20:30:11.093 INFO: Evaluation rollout: return=-12.922 (0.0), episode length=6.0
2023-01-03 20:30:11.093 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 20:30:11.096 INFO: Iteration: 9/137, steps: 1944
2023-01-03 20:30:19.717 DEBUG: There is a single atom floating around
2023-01-03 20:30:33.997 DEBUG: There is a single atom floating around
2023-01-03 20:30:38.115 DEBUG: Atoms are too close
2023-01-03 20:31:00.747 DEBUG: Atoms are too close
2023-01-03 20:31:04.758 DEBUG: Atoms are too close
2023-01-03 20:31:05.093 INFO: Training rollout: return=-2.067 (6.6), episode length=5.8
2023-01-03 20:31:05.094 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 20:31:05.097 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-1944_train.pkl
2023-01-03 20:31:06.144 DEBUG: Taking gradient step
2023-01-03 20:31:06.152 DEBUG: Loss 0: {'policy_loss': 0.00878091592445005, 'entropy_loss': -0.07719011418521404, 'vf_loss': 0.018242697073099483, 'total_loss': -0.050166501187664504, 'approx_kl': 5.7819610432829904e-08, 'clip_fraction': 0.0, 'grad_norm': 20.34531593322754}
2023-01-03 20:31:07.172 DEBUG: Taking gradient step
2023-01-03 20:31:07.180 DEBUG: Loss 1: {'policy_loss': -0.01216629890747192, 'entropy_loss': -0.07635028287768364, 'vf_loss': 0.017841032037514817, 'total_loss': -0.07067554974764075, 'approx_kl': -0.0007022725185379386, 'clip_fraction': 0.03255208395421505, 'grad_norm': 13.869565963745117}
2023-01-03 20:31:08.205 DEBUG: Taking gradient step
2023-01-03 20:31:08.217 DEBUG: Loss 2: {'policy_loss': -0.03725431861804604, 'entropy_loss': -0.07596847973763943, 'vf_loss': 0.017846651465796507, 'total_loss': -0.09537614688988896, 'approx_kl': 0.012444249936379492, 'clip_fraction': 0.2330729216337204, 'grad_norm': 10.164095878601074}
2023-01-03 20:31:09.238 DEBUG: Taking gradient step
2023-01-03 20:31:09.247 DEBUG: Loss 3: {'policy_loss': -0.015704699624275002, 'entropy_loss': -0.07650777138769627, 'vf_loss': 0.018380206539999076, 'total_loss': -0.07383226447197219, 'approx_kl': 0.014748995658010244, 'clip_fraction': 0.3997395858168602, 'grad_norm': 8.139280319213867}
2023-01-03 20:31:10.227 DEBUG: Taking gradient step
2023-01-03 20:31:10.236 DEBUG: Loss 4: {'policy_loss': -0.06280360278596739, 'entropy_loss': -0.07625094056129456, 'vf_loss': 0.01662780142350343, 'total_loss': -0.1224267419237585, 'approx_kl': 0.04313978098798543, 'clip_fraction': 0.4010416716337204, 'grad_norm': 10.05251407623291}
2023-01-03 20:31:11.264 DEBUG: Early stopping at step 5 for reaching max KL.
2023-01-03 20:31:11.265 INFO: Optimization: policy loss=-0.063, vf loss=0.017, entropy loss=-0.076, total loss=-0.122, num steps=5
2023-01-03 20:31:11.266 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 20:31:12.665 DEBUG: Atoms are too close
2023-01-03 20:31:12.667 INFO: Evaluation rollout: return=-12.925 (0.0), episode length=6.0
2023-01-03 20:31:12.667 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 20:31:12.670 INFO: Iteration: 10/137, steps: 2160
2023-01-03 20:31:21.249 DEBUG: Atoms are too close
2023-01-03 20:31:25.756 DEBUG: Atoms are too close
2023-01-03 20:31:28.351 DEBUG: Atoms are too close
2023-01-03 20:31:40.116 DEBUG: Atoms are too close
2023-01-03 20:31:41.539 DEBUG: Atoms are too close
2023-01-03 20:31:41.699 DEBUG: Atoms are too close
2023-01-03 20:31:43.441 DEBUG: There is a single atom floating around
2023-01-03 20:31:58.322 DEBUG: Atoms are too close
2023-01-03 20:31:59.073 DEBUG: Atoms are too close
2023-01-03 20:32:04.195 INFO: Training rollout: return=-3.468 (7.0), episode length=5.8
2023-01-03 20:32:04.196 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 20:32:04.199 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-2160_train.pkl
2023-01-03 20:32:05.215 DEBUG: Taking gradient step
2023-01-03 20:32:05.226 DEBUG: Loss 0: {'policy_loss': 0.021743550027282305, 'entropy_loss': -0.07537725195288658, 'vf_loss': 0.027938541418330548, 'total_loss': -0.025695160507273728, 'approx_kl': -2.6465083124982414e-08, 'clip_fraction': 0.0, 'grad_norm': 16.80743408203125}
2023-01-03 20:32:06.276 DEBUG: Taking gradient step
2023-01-03 20:32:06.285 DEBUG: Loss 1: {'policy_loss': -0.006182188016765365, 'entropy_loss': -0.07575797848403454, 'vf_loss': 0.027417775234518778, 'total_loss': -0.05452239126628113, 'approx_kl': 0.004049844108521938, 'clip_fraction': 0.06901041697710752, 'grad_norm': 13.209153175354004}
2023-01-03 20:32:07.327 DEBUG: Taking gradient step
2023-01-03 20:32:07.336 DEBUG: Loss 2: {'policy_loss': -0.009826315998955474, 'entropy_loss': -0.0762027483433485, 'vf_loss': 0.027083307659419405, 'total_loss': -0.05894575668288456, 'approx_kl': 0.018281223252415657, 'clip_fraction': 0.2669270858168602, 'grad_norm': 9.402125358581543}
2023-01-03 20:32:08.389 DEBUG: Taking gradient step
2023-01-03 20:32:08.402 DEBUG: Loss 3: {'policy_loss': -0.027462033448214764, 'entropy_loss': -0.07547336630523205, 'vf_loss': 0.02697534164807447, 'total_loss': -0.07596005810537235, 'approx_kl': 0.039108362048864365, 'clip_fraction': 0.37109375, 'grad_norm': 12.379700660705566}
2023-01-03 20:32:09.547 DEBUG: Taking gradient step
2023-01-03 20:32:09.559 DEBUG: Loss 4: {'policy_loss': 0.04092095535015522, 'entropy_loss': -0.07651303522288799, 'vf_loss': 0.031758505967502675, 'total_loss': -0.003833573905230106, 'approx_kl': 0.032600062899291515, 'clip_fraction': 0.3919270858168602, 'grad_norm': 13.642836570739746}
2023-01-03 20:32:10.706 DEBUG: Taking gradient step
2023-01-03 20:32:10.719 DEBUG: Loss 5: {'policy_loss': -0.06865224247339183, 'entropy_loss': -0.07596161402761936, 'vf_loss': 0.026737598014851302, 'total_loss': -0.11787625848615987, 'approx_kl': 0.02447602603206178, 'clip_fraction': 0.3307291716337204, 'grad_norm': 9.802756309509277}
2023-01-03 20:32:11.854 DEBUG: Taking gradient step
2023-01-03 20:32:11.867 DEBUG: Loss 6: {'policy_loss': 0.0047729087031730885, 'entropy_loss': -0.07601759396493435, 'vf_loss': 0.028320925861883055, 'total_loss': -0.042923759399878206, 'approx_kl': 0.031121494248509407, 'clip_fraction': 0.3190104216337204, 'grad_norm': 14.514823913574219}
2023-01-03 20:32:12.994 DEBUG: Taking gradient step
2023-01-03 20:32:13.007 DEBUG: Loss 7: {'policy_loss': -0.03427513742906196, 'entropy_loss': -0.07607144676148891, 'vf_loss': 0.027276587709423275, 'total_loss': -0.08306999648112759, 'approx_kl': 0.026105503551661968, 'clip_fraction': 0.3515625, 'grad_norm': 9.298368453979492}
2023-01-03 20:32:14.144 DEBUG: Taking gradient step
2023-01-03 20:32:14.157 DEBUG: Loss 8: {'policy_loss': -0.03730029545734799, 'entropy_loss': -0.07591773197054863, 'vf_loss': 0.026408686732497483, 'total_loss': -0.08680934069539914, 'approx_kl': 0.03158988384529948, 'clip_fraction': 0.3606770858168602, 'grad_norm': 15.678451538085938}
2023-01-03 20:32:15.293 DEBUG: Taking gradient step
2023-01-03 20:32:15.305 DEBUG: Loss 9: {'policy_loss': -0.04196051028973333, 'entropy_loss': -0.07573593594133854, 'vf_loss': 0.027246043804730204, 'total_loss': -0.09045040242634166, 'approx_kl': 0.03037287839106284, 'clip_fraction': 0.42578125, 'grad_norm': 14.484308242797852}
2023-01-03 20:32:16.442 DEBUG: Taking gradient step
2023-01-03 20:32:16.454 DEBUG: Loss 10: {'policy_loss': -0.08479038076956888, 'entropy_loss': -0.07698198966681957, 'vf_loss': 0.025161001558215115, 'total_loss': -0.13661136887817335, 'approx_kl': 0.01898750802502036, 'clip_fraction': 0.4192708358168602, 'grad_norm': 14.364184379577637}
2023-01-03 20:32:17.562 DEBUG: Taking gradient step
2023-01-03 20:32:17.574 DEBUG: Loss 11: {'policy_loss': -0.06163194601167228, 'entropy_loss': -0.07734515331685543, 'vf_loss': 0.02685418663227302, 'total_loss': -0.11212291269625468, 'approx_kl': 0.030006757006049156, 'clip_fraction': 0.4505208358168602, 'grad_norm': 8.946359634399414}
2023-01-03 20:32:18.710 DEBUG: Taking gradient step
2023-01-03 20:32:18.723 DEBUG: Loss 12: {'policy_loss': -0.0808682010731008, 'entropy_loss': -0.07640273869037628, 'vf_loss': 0.025296648652749224, 'total_loss': -0.13197429111072786, 'approx_kl': 0.03969128569588065, 'clip_fraction': 0.4947916716337204, 'grad_norm': 7.191648960113525}
2023-01-03 20:32:19.860 DEBUG: Early stopping at step 13 for reaching max KL.
2023-01-03 20:32:19.860 INFO: Optimization: policy loss=-0.081, vf loss=0.025, entropy loss=-0.076, total loss=-0.132, num steps=13
2023-01-03 20:32:19.861 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 20:32:21.492 INFO: Evaluation rollout: return=0.454 (0.0), episode length=6.0
2023-01-03 20:32:21.493 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 20:32:21.496 DEBUG: Deleting old model: runs/CH3NO_baseline/models/CH3NO_baseline_run-1_steps-216.model
2023-01-03 20:32:21.499 DEBUG: Saving model: runs/CH3NO_baseline/models/CH3NO_baseline_run-1_steps-2376.model
2023-01-03 20:32:21.528 INFO: Iteration: 11/137, steps: 2376
2023-01-03 20:32:31.839 DEBUG: Atoms are too close
2023-01-03 20:32:36.733 DEBUG: Atoms are too close
2023-01-03 20:32:37.283 DEBUG: Atoms are too close
2023-01-03 20:32:37.824 DEBUG: Atoms are too close
2023-01-03 20:32:45.821 DEBUG: Atoms are too close
2023-01-03 20:32:52.365 DEBUG: Atoms are too close
2023-01-03 20:32:55.866 DEBUG: There is a single atom floating around
2023-01-03 20:33:00.034 DEBUG: There is a single atom floating around
2023-01-03 20:33:14.489 INFO: Training rollout: return=-2.381 (6.2), episode length=5.9
2023-01-03 20:33:14.490 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 20:33:14.493 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-2376_train.pkl
2023-01-03 20:33:15.560 DEBUG: Taking gradient step
2023-01-03 20:33:15.571 DEBUG: Loss 0: {'policy_loss': -0.016887693712976142, 'entropy_loss': -0.07684430293738842, 'vf_loss': 0.027029700395319385, 'total_loss': -0.06670229625504517, 'approx_kl': 3.833944628439667e-08, 'clip_fraction': 0.0, 'grad_norm': 17.238679885864258}
2023-01-03 20:33:16.569 DEBUG: Taking gradient step
2023-01-03 20:33:16.579 DEBUG: Loss 1: {'policy_loss': -0.01181604076150905, 'entropy_loss': -0.076604675501585, 'vf_loss': 0.026860487751886056, 'total_loss': -0.061560228511208, 'approx_kl': -0.006654720054939389, 'clip_fraction': 0.078125, 'grad_norm': 10.722745895385742}
2023-01-03 20:33:17.606 DEBUG: Taking gradient step
2023-01-03 20:33:17.617 DEBUG: Loss 2: {'policy_loss': -0.009767524747351833, 'entropy_loss': -0.07719597406685352, 'vf_loss': 0.026860949993142685, 'total_loss': -0.06010254882106267, 'approx_kl': 0.003471331554464996, 'clip_fraction': 0.2317708358168602, 'grad_norm': 13.699312210083008}
2023-01-03 20:33:18.643 DEBUG: Taking gradient step
2023-01-03 20:33:18.653 DEBUG: Loss 3: {'policy_loss': -0.000513115400306019, 'entropy_loss': -0.07738531194627285, 'vf_loss': 0.029924594160991462, 'total_loss': -0.04797383318558741, 'approx_kl': 0.02163188625127077, 'clip_fraction': 0.2578125, 'grad_norm': 12.442831039428711}
2023-01-03 20:33:19.684 DEBUG: Taking gradient step
2023-01-03 20:33:19.695 DEBUG: Loss 4: {'policy_loss': -0.033607061651723516, 'entropy_loss': -0.07738417573273182, 'vf_loss': 0.027010574442926708, 'total_loss': -0.08398066294152862, 'approx_kl': 0.015850984025746584, 'clip_fraction': 0.2252604216337204, 'grad_norm': 6.283731460571289}
2023-01-03 20:33:20.703 DEBUG: Taking gradient step
2023-01-03 20:33:20.713 DEBUG: Loss 5: {'policy_loss': -0.00850114432522469, 'entropy_loss': -0.0775173269212246, 'vf_loss': 0.030555095005645173, 'total_loss': -0.05546337624080411, 'approx_kl': 0.04250227473676205, 'clip_fraction': 0.3033854216337204, 'grad_norm': 6.381633758544922}
2023-01-03 20:33:21.740 DEBUG: Early stopping at step 6 for reaching max KL.
2023-01-03 20:33:21.741 INFO: Optimization: policy loss=-0.009, vf loss=0.031, entropy loss=-0.078, total loss=-0.055, num steps=6
2023-01-03 20:33:21.742 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 20:33:23.369 INFO: Evaluation rollout: return=0.402 (0.0), episode length=6.0
2023-01-03 20:33:23.370 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 20:33:23.373 INFO: Iteration: 12/137, steps: 2592
2023-01-03 20:33:35.729 DEBUG: Atoms are too close
2023-01-03 20:33:39.351 DEBUG: Atoms are too close
2023-01-03 20:33:50.594 DEBUG: Atoms are too close
2023-01-03 20:33:52.778 DEBUG: Atoms are too close
2023-01-03 20:33:54.094 DEBUG: Atoms are too close
2023-01-03 20:33:58.075 DEBUG: Atoms are too close
2023-01-03 20:34:01.247 DEBUG: Atoms are too close
2023-01-03 20:34:16.736 INFO: Training rollout: return=-2.619 (6.4), episode length=5.8
2023-01-03 20:34:16.738 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 20:34:16.741 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-2592_train.pkl
2023-01-03 20:34:17.775 DEBUG: Taking gradient step
2023-01-03 20:34:17.784 DEBUG: Loss 0: {'policy_loss': -0.00369908276756541, 'entropy_loss': -0.07937422022223473, 'vf_loss': 0.021508988569025056, 'total_loss': -0.06156431442077507, 'approx_kl': 5.991508622571473e-08, 'clip_fraction': 0.0, 'grad_norm': 18.0551700592041}
2023-01-03 20:34:18.813 DEBUG: Taking gradient step
2023-01-03 20:34:18.822 DEBUG: Loss 1: {'policy_loss': 0.0003138954275829064, 'entropy_loss': -0.07954169996082783, 'vf_loss': 0.023030991036632413, 'total_loss': -0.056196813496612506, 'approx_kl': 0.00460492423735559, 'clip_fraction': 0.026041666977107525, 'grad_norm': 23.114368438720703}
2023-01-03 20:34:19.811 DEBUG: Taking gradient step
2023-01-03 20:34:19.820 DEBUG: Loss 2: {'policy_loss': 0.0024906060248087274, 'entropy_loss': -0.07907320372760296, 'vf_loss': 0.023431267338459637, 'total_loss': -0.0531513303643346, 'approx_kl': 0.016453700605779886, 'clip_fraction': 0.14322916697710752, 'grad_norm': 20.595958709716797}
2023-01-03 20:34:20.857 DEBUG: Early stopping at step 3 for reaching max KL.
2023-01-03 20:34:20.857 INFO: Optimization: policy loss=0.002, vf loss=0.023, entropy loss=-0.079, total loss=-0.053, num steps=3
2023-01-03 20:34:20.858 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 20:34:22.483 INFO: Evaluation rollout: return=0.217 (0.0), episode length=6.0
2023-01-03 20:34:22.484 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 20:34:22.487 INFO: Iteration: 13/137, steps: 2808
2023-01-03 20:34:31.451 DEBUG: Atoms are too close
2023-01-03 20:34:32.276 DEBUG: Atoms are too close
2023-01-03 20:34:35.607 DEBUG: Atoms are too close
2023-01-03 20:34:35.880 DEBUG: Atoms are too close
2023-01-03 20:34:45.434 DEBUG: Atoms are too close
2023-01-03 20:34:49.745 DEBUG: Atoms are too close
2023-01-03 20:34:53.620 DEBUG: There is a single atom floating around
2023-01-03 20:35:11.241 DEBUG: Atoms are too close
2023-01-03 20:35:14.861 INFO: Training rollout: return=-3.267 (7.0), episode length=5.7
2023-01-03 20:35:14.862 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 20:35:14.866 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-2808_train.pkl
2023-01-03 20:35:15.926 DEBUG: Taking gradient step
2023-01-03 20:35:15.935 DEBUG: Loss 0: {'policy_loss': -0.02151090718602535, 'entropy_loss': -0.07874597236514091, 'vf_loss': 0.023560069656793477, 'total_loss': -0.07669680989437279, 'approx_kl': -3.306195139884949e-08, 'clip_fraction': 0.0, 'grad_norm': 24.5781307220459}
2023-01-03 20:35:16.946 DEBUG: Taking gradient step
2023-01-03 20:35:16.954 DEBUG: Loss 1: {'policy_loss': -0.028787191233936596, 'entropy_loss': -0.07815205678343773, 'vf_loss': 0.022735708681406036, 'total_loss': -0.08420353933596827, 'approx_kl': 0.00584897305816412, 'clip_fraction': 0.04036458395421505, 'grad_norm': 21.690404891967773}
2023-01-03 20:35:17.951 DEBUG: Taking gradient step
2023-01-03 20:35:17.960 DEBUG: Loss 2: {'policy_loss': -0.007773693510915173, 'entropy_loss': -0.07852444238960743, 'vf_loss': 0.023672955995050447, 'total_loss': -0.06262517990547214, 'approx_kl': 0.009615702787414193, 'clip_fraction': 0.1354166679084301, 'grad_norm': 25.234363555908203}
2023-01-03 20:35:18.972 DEBUG: Taking gradient step
2023-01-03 20:35:18.980 DEBUG: Loss 3: {'policy_loss': -0.06515065749897991, 'entropy_loss': -0.07840262725949287, 'vf_loss': 0.021802685244349713, 'total_loss': -0.12175059951412308, 'approx_kl': 0.024450434604659677, 'clip_fraction': 0.28515625, 'grad_norm': 11.059866905212402}
2023-01-03 20:35:19.989 DEBUG: Taking gradient step
2023-01-03 20:35:19.997 DEBUG: Loss 4: {'policy_loss': -0.0338707525939896, 'entropy_loss': -0.07844914495944977, 'vf_loss': 0.023714563856068738, 'total_loss': -0.08860533369737063, 'approx_kl': 0.019516650587320328, 'clip_fraction': 0.3658854216337204, 'grad_norm': 6.026439666748047}
2023-01-03 20:35:21.015 DEBUG: Early stopping at step 5 for reaching max KL.
2023-01-03 20:35:21.016 INFO: Optimization: policy loss=-0.034, vf loss=0.024, entropy loss=-0.078, total loss=-0.089, num steps=5
2023-01-03 20:35:21.017 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 20:35:22.701 INFO: Evaluation rollout: return=0.493 (0.0), episode length=6.0
2023-01-03 20:35:22.702 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 20:35:22.705 INFO: Iteration: 14/137, steps: 3024
2023-01-03 20:35:37.937 DEBUG: Atoms are too close
2023-01-03 20:35:38.756 DEBUG: Atoms are too close
2023-01-03 20:35:39.849 DEBUG: Atoms are too close
2023-01-03 20:35:57.285 DEBUG: Atoms are too close
2023-01-03 20:35:57.830 DEBUG: Atoms are too close
2023-01-03 20:35:59.835 DEBUG: There is a single atom floating around
2023-01-03 20:36:14.778 DEBUG: There is a single atom floating around
2023-01-03 20:36:16.187 INFO: Training rollout: return=-2.490 (6.3), episode length=5.9
2023-01-03 20:36:16.189 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 20:36:16.191 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-3024_train.pkl
2023-01-03 20:36:17.246 DEBUG: Taking gradient step
2023-01-03 20:36:17.256 DEBUG: Loss 0: {'policy_loss': -0.021200693323093232, 'entropy_loss': -0.07835480198264122, 'vf_loss': 0.020467234093315256, 'total_loss': -0.07908826121241919, 'approx_kl': 1.0865441879559512e-09, 'clip_fraction': 0.0, 'grad_norm': 15.593303680419922}
2023-01-03 20:36:18.294 DEBUG: Taking gradient step
2023-01-03 20:36:18.304 DEBUG: Loss 1: {'policy_loss': -0.004166977393088324, 'entropy_loss': -0.07849596440792084, 'vf_loss': 0.02097657947071968, 'total_loss': -0.061686362330289485, 'approx_kl': -0.0066854702308773994, 'clip_fraction': 0.045572916977107525, 'grad_norm': 12.05229663848877}
2023-01-03 20:36:19.352 DEBUG: Taking gradient step
2023-01-03 20:36:19.362 DEBUG: Loss 2: {'policy_loss': -0.024384781331761758, 'entropy_loss': -0.07827411964535713, 'vf_loss': 0.02160337504694465, 'total_loss': -0.08105552593017423, 'approx_kl': -0.019796051317825913, 'clip_fraction': 0.2591145858168602, 'grad_norm': 14.451322555541992}
2023-01-03 20:36:20.382 DEBUG: Taking gradient step
2023-01-03 20:36:20.391 DEBUG: Loss 3: {'policy_loss': -0.07686693077727051, 'entropy_loss': -0.07828696072101593, 'vf_loss': 0.018473041714963757, 'total_loss': -0.13668084978332268, 'approx_kl': 0.010214766953140497, 'clip_fraction': 0.3229166716337204, 'grad_norm': 11.67175579071045}
2023-01-03 20:36:21.425 DEBUG: Taking gradient step
2023-01-03 20:36:21.435 DEBUG: Loss 4: {'policy_loss': -0.04865677647380125, 'entropy_loss': -0.07788687758147717, 'vf_loss': 0.019964733864285385, 'total_loss': -0.10657892019099303, 'approx_kl': 0.013408557046204805, 'clip_fraction': 0.3359375, 'grad_norm': 10.760847091674805}
2023-01-03 20:36:22.477 DEBUG: Taking gradient step
2023-01-03 20:36:22.487 DEBUG: Loss 5: {'policy_loss': -0.006525880100866521, 'entropy_loss': -0.07797961682081223, 'vf_loss': 0.022127570753647748, 'total_loss': -0.062377926168031006, 'approx_kl': 0.006489340448752046, 'clip_fraction': 0.3333333358168602, 'grad_norm': 9.696282386779785}
2023-01-03 20:36:23.521 DEBUG: Taking gradient step
2023-01-03 20:36:23.531 DEBUG: Loss 6: {'policy_loss': -0.027152522099562454, 'entropy_loss': -0.07791542075574398, 'vf_loss': 0.02076892141253482, 'total_loss': -0.08429902144277161, 'approx_kl': 0.0124475525226444, 'clip_fraction': 0.3216145858168602, 'grad_norm': 9.871438980102539}
2023-01-03 20:36:24.549 DEBUG: Taking gradient step
2023-01-03 20:36:24.559 DEBUG: Loss 7: {'policy_loss': -0.045955716300181, 'entropy_loss': -0.07703827880322933, 'vf_loss': 0.020588388411974662, 'total_loss': -0.10240560669143568, 'approx_kl': 0.015035921707749367, 'clip_fraction': 0.33984375, 'grad_norm': 22.225658416748047}
2023-01-03 20:36:25.566 DEBUG: Taking gradient step
2023-01-03 20:36:25.577 DEBUG: Loss 8: {'policy_loss': -0.042660761241748626, 'entropy_loss': -0.07761223614215851, 'vf_loss': 0.020924133472484282, 'total_loss': -0.09934886391142285, 'approx_kl': 0.010490691289305687, 'clip_fraction': 0.3567708358168602, 'grad_norm': 8.040655136108398}
2023-01-03 20:36:26.573 DEBUG: Taking gradient step
2023-01-03 20:36:26.581 DEBUG: Loss 9: {'policy_loss': -0.08593356925831691, 'entropy_loss': -0.07733262330293655, 'vf_loss': 0.018961900296632354, 'total_loss': -0.1443042922646211, 'approx_kl': 0.005073127336800098, 'clip_fraction': 0.3294270858168602, 'grad_norm': 9.30207347869873}
2023-01-03 20:36:27.600 DEBUG: Taking gradient step
2023-01-03 20:36:27.609 DEBUG: Loss 10: {'policy_loss': -0.049350297394857384, 'entropy_loss': -0.07888896390795708, 'vf_loss': 0.02109137919006813, 'total_loss': -0.10714788211274634, 'approx_kl': 0.00926161976531148, 'clip_fraction': 0.3177083358168602, 'grad_norm': 10.55759334564209}
2023-01-03 20:36:28.630 DEBUG: Taking gradient step
2023-01-03 20:36:28.639 DEBUG: Loss 11: {'policy_loss': -0.03611931451543395, 'entropy_loss': -0.07869280688464642, 'vf_loss': 0.02127381069332584, 'total_loss': -0.09353831070675454, 'approx_kl': 0.04243914783000946, 'clip_fraction': 0.3229166716337204, 'grad_norm': 10.71546745300293}
2023-01-03 20:36:29.622 DEBUG: Taking gradient step
2023-01-03 20:36:29.631 DEBUG: Loss 12: {'policy_loss': -0.06308826836449842, 'entropy_loss': -0.07838331907987595, 'vf_loss': 0.020110655911695544, 'total_loss': -0.12136093153267882, 'approx_kl': 0.03690895438194275, 'clip_fraction': 0.3372395858168602, 'grad_norm': 11.171298027038574}
2023-01-03 20:36:30.654 DEBUG: Taking gradient step
2023-01-03 20:36:30.662 DEBUG: Loss 13: {'policy_loss': -0.07807071976729821, 'entropy_loss': -0.07953274063766003, 'vf_loss': 0.02062094357346809, 'total_loss': -0.13698251683149015, 'approx_kl': 0.03327255230396986, 'clip_fraction': 0.40625, 'grad_norm': 5.402698993682861}
2023-01-03 20:36:31.687 DEBUG: Taking gradient step
2023-01-03 20:36:31.696 DEBUG: Loss 14: {'policy_loss': -0.03951418485021207, 'entropy_loss': -0.0787822175770998, 'vf_loss': 0.021165137007134564, 'total_loss': -0.09713126542017732, 'approx_kl': 0.022986470721662045, 'clip_fraction': 0.40625, 'grad_norm': 8.809526443481445}
2023-01-03 20:36:31.696 INFO: Optimization: policy loss=-0.040, vf loss=0.021, entropy loss=-0.079, total loss=-0.097, num steps=15
2023-01-03 20:36:31.696 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 20:36:33.308 INFO: Evaluation rollout: return=0.484 (0.0), episode length=6.0
2023-01-03 20:36:33.309 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 20:36:33.311 INFO: Iteration: 15/137, steps: 3240
2023-01-03 20:36:45.513 DEBUG: Atoms are too close
2023-01-03 20:36:46.315 DEBUG: Atoms are too close
2023-01-03 20:36:48.967 DEBUG: Atoms are too close
2023-01-03 20:36:50.193 DEBUG: Atoms are too close
2023-01-03 20:37:03.208 DEBUG: There is a single atom floating around
2023-01-03 20:37:18.027 DEBUG: There is a single atom floating around
2023-01-03 20:37:26.008 DEBUG: Atoms are too close
2023-01-03 20:37:26.010 DEBUG: There is a single atom floating around
2023-01-03 20:37:26.070 INFO: Training rollout: return=-2.700 (6.1), episode length=5.9
2023-01-03 20:37:26.071 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 20:37:26.074 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-3240_train.pkl
2023-01-03 20:37:27.103 DEBUG: Taking gradient step
2023-01-03 20:37:27.113 DEBUG: Loss 0: {'policy_loss': 0.02347849094432633, 'entropy_loss': -0.07823909446597099, 'vf_loss': 0.025195214013926645, 'total_loss': -0.029565389507718018, 'approx_kl': -3.872749698707878e-08, 'clip_fraction': 0.0, 'grad_norm': 17.737041473388672}
2023-01-03 20:37:28.097 DEBUG: Taking gradient step
2023-01-03 20:37:28.105 DEBUG: Loss 1: {'policy_loss': -0.04122960029227986, 'entropy_loss': -0.07847624644637108, 'vf_loss': 0.02237098093966362, 'total_loss': -0.09733486579898731, 'approx_kl': -0.0018136498983949423, 'clip_fraction': 0.03125, 'grad_norm': 10.798831939697266}
2023-01-03 20:37:29.111 DEBUG: Taking gradient step
2023-01-03 20:37:29.121 DEBUG: Loss 2: {'policy_loss': 0.030997573973530965, 'entropy_loss': -0.07841434888541698, 'vf_loss': 0.026080824021209432, 'total_loss': -0.02133595089067658, 'approx_kl': 0.012471787165850401, 'clip_fraction': 0.13411458395421505, 'grad_norm': 12.682666778564453}
2023-01-03 20:37:30.131 DEBUG: Taking gradient step
2023-01-03 20:37:30.141 DEBUG: Loss 3: {'policy_loss': -0.010224511891831056, 'entropy_loss': -0.07806779257953167, 'vf_loss': 0.024570899207700003, 'total_loss': -0.06372140526366273, 'approx_kl': 0.021700779907405376, 'clip_fraction': 0.20442708395421505, 'grad_norm': 10.352303504943848}
2023-01-03 20:37:31.157 DEBUG: Taking gradient step
2023-01-03 20:37:31.167 DEBUG: Loss 4: {'policy_loss': -0.02104986897406021, 'entropy_loss': -0.07828829996287823, 'vf_loss': 0.02454810821246505, 'total_loss': -0.07479006072447339, 'approx_kl': 0.032942147459834814, 'clip_fraction': 0.3151041716337204, 'grad_norm': 10.770493507385254}
2023-01-03 20:37:32.187 DEBUG: Taking gradient step
2023-01-03 20:37:32.197 DEBUG: Loss 5: {'policy_loss': -0.03474895008512403, 'entropy_loss': -0.07799575291574001, 'vf_loss': 0.024278192110386735, 'total_loss': -0.0884665108904773, 'approx_kl': 0.038914504228159785, 'clip_fraction': 0.3346354216337204, 'grad_norm': 11.10645866394043}
2023-01-03 20:37:33.174 DEBUG: Taking gradient step
2023-01-03 20:37:33.184 DEBUG: Loss 6: {'policy_loss': 0.009478256878899978, 'entropy_loss': -0.07687050104141235, 'vf_loss': 0.026596091273749706, 'total_loss': -0.04079615288876267, 'approx_kl': 0.041859026765450835, 'clip_fraction': 0.3697916716337204, 'grad_norm': 9.80988883972168}
2023-01-03 20:37:34.202 DEBUG: Early stopping at step 7 for reaching max KL.
2023-01-03 20:37:34.202 INFO: Optimization: policy loss=0.009, vf loss=0.027, entropy loss=-0.077, total loss=-0.041, num steps=7
2023-01-03 20:37:34.203 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 20:37:35.814 INFO: Evaluation rollout: return=0.473 (0.0), episode length=6.0
2023-01-03 20:37:35.815 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 20:37:35.818 INFO: Iteration: 16/137, steps: 3456
2023-01-03 20:37:49.184 DEBUG: Atoms are too close
2023-01-03 20:37:49.455 DEBUG: Atoms are too close
2023-01-03 20:38:07.002 DEBUG: There is a single atom floating around
2023-01-03 20:38:07.298 DEBUG: Atoms are too close
2023-01-03 20:38:10.413 DEBUG: Atoms are too close
2023-01-03 20:38:22.392 DEBUG: Atoms are too close
2023-01-03 20:38:24.128 DEBUG: Atoms are too close
2023-01-03 20:38:25.906 DEBUG: Atoms are too close
2023-01-03 20:38:27.079 DEBUG: Atoms are too close
2023-01-03 20:38:28.522 INFO: Training rollout: return=-3.219 (6.5), episode length=5.8
2023-01-03 20:38:28.524 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 20:38:28.527 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-3456_train.pkl
2023-01-03 20:38:29.544 DEBUG: Taking gradient step
2023-01-03 20:38:29.553 DEBUG: Loss 0: {'policy_loss': 0.006537293941468838, 'entropy_loss': -0.07802545838057995, 'vf_loss': 0.026156699263914247, 'total_loss': -0.04533146517519687, 'approx_kl': 3.0888863022937585e-08, 'clip_fraction': 0.0, 'grad_norm': 18.63637924194336}
2023-01-03 20:38:30.541 DEBUG: Taking gradient step
2023-01-03 20:38:30.551 DEBUG: Loss 1: {'policy_loss': -0.04809854239859943, 'entropy_loss': -0.07751834020018578, 'vf_loss': 0.02426790372157526, 'total_loss': -0.10134897887720995, 'approx_kl': 0.010498231393285096, 'clip_fraction': 0.04817708395421505, 'grad_norm': 15.349777221679688}
2023-01-03 20:38:31.578 DEBUG: Taking gradient step
2023-01-03 20:38:31.588 DEBUG: Loss 2: {'policy_loss': 0.004905936428619105, 'entropy_loss': -0.07771076261997223, 'vf_loss': 0.026494658084285132, 'total_loss': -0.04631016810706799, 'approx_kl': 0.035591032123193145, 'clip_fraction': 0.171875, 'grad_norm': 18.297101974487305}
2023-01-03 20:38:32.587 DEBUG: Early stopping at step 3 for reaching max KL.
2023-01-03 20:38:32.587 INFO: Optimization: policy loss=0.005, vf loss=0.026, entropy loss=-0.078, total loss=-0.046, num steps=3
2023-01-03 20:38:32.587 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 20:38:34.241 INFO: Evaluation rollout: return=0.358 (0.0), episode length=6.0
2023-01-03 20:38:34.242 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 20:38:34.244 INFO: Iteration: 17/137, steps: 3672
2023-01-03 20:38:44.881 DEBUG: Atoms are too close
2023-01-03 20:38:45.172 DEBUG: Atoms are too close
2023-01-03 20:38:48.024 DEBUG: There is a single atom floating around
2023-01-03 20:38:48.881 DEBUG: Atoms are too close
2023-01-03 20:39:14.945 DEBUG: Atoms are too close
2023-01-03 20:39:26.301 DEBUG: Atoms are too close
2023-01-03 20:39:27.424 DEBUG: Atoms are too close
2023-01-03 20:39:29.004 INFO: Training rollout: return=-2.562 (6.4), episode length=5.8
2023-01-03 20:39:29.006 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 20:39:29.009 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-3672_train.pkl
2023-01-03 20:39:30.032 DEBUG: Taking gradient step
2023-01-03 20:39:30.041 DEBUG: Loss 0: {'policy_loss': 0.00774529019439554, 'entropy_loss': -0.07682943157851696, 'vf_loss': 0.02167848917340632, 'total_loss': -0.0474056522107151, 'approx_kl': -3.709768314763551e-08, 'clip_fraction': 0.0, 'grad_norm': 15.987316131591797}
2023-01-03 20:39:31.061 DEBUG: Taking gradient step
2023-01-03 20:39:31.071 DEBUG: Loss 1: {'policy_loss': -0.0406580350059916, 'entropy_loss': -0.07616215385496616, 'vf_loss': 0.020184657630588618, 'total_loss': -0.09663553123036915, 'approx_kl': -0.002330874209292233, 'clip_fraction': 0.015625, 'grad_norm': 12.653885841369629}
2023-01-03 20:39:32.120 DEBUG: Taking gradient step
2023-01-03 20:39:32.130 DEBUG: Loss 2: {'policy_loss': -0.010236905138420908, 'entropy_loss': -0.07611979730427265, 'vf_loss': 0.02269043176993091, 'total_loss': -0.06366627067276265, 'approx_kl': -0.00036317226476967335, 'clip_fraction': 0.11588541697710752, 'grad_norm': 16.221288681030273}
2023-01-03 20:39:33.189 DEBUG: Taking gradient step
2023-01-03 20:39:33.198 DEBUG: Loss 3: {'policy_loss': -0.0420172737183585, 'entropy_loss': -0.07608041167259216, 'vf_loss': 0.021193761127542343, 'total_loss': -0.09690392426340831, 'approx_kl': 0.007938215741887689, 'clip_fraction': 0.2369791716337204, 'grad_norm': 8.574809074401855}
2023-01-03 20:39:34.258 DEBUG: Taking gradient step
2023-01-03 20:39:34.268 DEBUG: Loss 4: {'policy_loss': -0.018715424738834616, 'entropy_loss': -0.07576464116573334, 'vf_loss': 0.020888386308236122, 'total_loss': -0.07359167959633182, 'approx_kl': 0.026341599877923727, 'clip_fraction': 0.3229166716337204, 'grad_norm': 7.397889614105225}
2023-01-03 20:39:35.295 DEBUG: Taking gradient step
2023-01-03 20:39:35.309 DEBUG: Loss 5: {'policy_loss': -0.04875089795322898, 'entropy_loss': -0.0755817461758852, 'vf_loss': 0.01985002921976652, 'total_loss': -0.10448261490934767, 'approx_kl': 0.025746331550180912, 'clip_fraction': 0.34765625, 'grad_norm': 8.119773864746094}
2023-01-03 20:39:36.362 DEBUG: Early stopping at step 6 for reaching max KL.
2023-01-03 20:39:36.363 INFO: Optimization: policy loss=-0.049, vf loss=0.020, entropy loss=-0.076, total loss=-0.104, num steps=6
2023-01-03 20:39:36.363 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 20:39:38.075 INFO: Evaluation rollout: return=0.461 (0.0), episode length=6.0
2023-01-03 20:39:38.077 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 20:39:38.079 INFO: Iteration: 18/137, steps: 3888
2023-01-03 20:39:52.194 DEBUG: Atoms are too close
2023-01-03 20:39:54.382 DEBUG: Atoms are too close
2023-01-03 20:39:55.058 DEBUG: Atoms are too close
2023-01-03 20:40:06.176 DEBUG: Atoms are too close
2023-01-03 20:40:11.083 DEBUG: Atoms are too close
2023-01-03 20:40:22.800 DEBUG: Atoms are too close
2023-01-03 20:40:31.310 INFO: Training rollout: return=-1.973 (5.6), episode length=5.9
2023-01-03 20:40:31.311 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 20:40:31.315 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-3888_train.pkl
2023-01-03 20:40:32.334 DEBUG: Taking gradient step
2023-01-03 20:40:32.343 DEBUG: Loss 0: {'policy_loss': 0.009746192889350231, 'entropy_loss': -0.0756908655166626, 'vf_loss': 0.019304230434327073, 'total_loss': -0.0466404421929853, 'approx_kl': 2.3515895009040833e-08, 'clip_fraction': 0.0, 'grad_norm': 16.764955520629883}
2023-01-03 20:40:33.336 DEBUG: Taking gradient step
2023-01-03 20:40:33.344 DEBUG: Loss 1: {'policy_loss': -0.014813217250853616, 'entropy_loss': -0.07613473013043404, 'vf_loss': 0.018955671942409484, 'total_loss': -0.07199227543887816, 'approx_kl': 0.010500357020646334, 'clip_fraction': 0.12109375, 'grad_norm': 11.584600448608398}
2023-01-03 20:40:34.359 DEBUG: Taking gradient step
2023-01-03 20:40:34.368 DEBUG: Loss 2: {'policy_loss': -0.02536803453841588, 'entropy_loss': -0.0757406186312437, 'vf_loss': 0.01814438340995944, 'total_loss': -0.08296426975970014, 'approx_kl': 0.04314399929717183, 'clip_fraction': 0.2825520858168602, 'grad_norm': 8.029776573181152}
2023-01-03 20:40:35.381 DEBUG: Early stopping at step 3 for reaching max KL.
2023-01-03 20:40:35.381 INFO: Optimization: policy loss=-0.025, vf loss=0.018, entropy loss=-0.076, total loss=-0.083, num steps=3
2023-01-03 20:40:35.381 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 20:40:36.977 INFO: Evaluation rollout: return=0.385 (0.0), episode length=6.0
2023-01-03 20:40:36.979 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 20:40:36.983 INFO: Iteration: 19/137, steps: 4104
2023-01-03 20:40:45.544 DEBUG: Atoms are too close
2023-01-03 20:40:54.241 DEBUG: Atoms are too close
2023-01-03 20:41:11.464 DEBUG: Atoms are too close
2023-01-03 20:41:11.465 DEBUG: Atoms are too close
2023-01-03 20:41:11.466 DEBUG: Atoms are too close
2023-01-03 20:41:25.983 DEBUG: Atoms are too close
2023-01-03 20:41:27.736 DEBUG: Atoms are too close
2023-01-03 20:41:30.752 INFO: Training rollout: return=-2.306 (5.8), episode length=5.9
2023-01-03 20:41:30.753 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 20:41:30.756 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-4104_train.pkl
2023-01-03 20:41:31.782 DEBUG: Taking gradient step
2023-01-03 20:41:31.792 DEBUG: Loss 0: {'policy_loss': 0.04076954405847451, 'entropy_loss': -0.07634490728378296, 'vf_loss': 0.021840216257783953, 'total_loss': -0.013735146967524502, 'approx_kl': 1.505638191900971e-08, 'clip_fraction': 0.0, 'grad_norm': 24.58106803894043}
2023-01-03 20:41:32.800 DEBUG: Taking gradient step
2023-01-03 20:41:32.810 DEBUG: Loss 1: {'policy_loss': 0.008465114403909308, 'entropy_loss': -0.0761351902037859, 'vf_loss': 0.021895846700122852, 'total_loss': -0.04577422909975373, 'approx_kl': 0.0002562897279858589, 'clip_fraction': 0.1171875, 'grad_norm': 22.27475929260254}
2023-01-03 20:41:33.796 DEBUG: Taking gradient step
2023-01-03 20:41:33.805 DEBUG: Loss 2: {'policy_loss': 0.01764964964626762, 'entropy_loss': -0.07594533450901508, 'vf_loss': 0.022397738581254954, 'total_loss': -0.03589794628149252, 'approx_kl': 0.01482561114244163, 'clip_fraction': 0.2356770858168602, 'grad_norm': 18.966169357299805}
2023-01-03 20:41:34.807 DEBUG: Early stopping at step 3 for reaching max KL.
2023-01-03 20:41:34.809 INFO: Optimization: policy loss=0.018, vf loss=0.022, entropy loss=-0.076, total loss=-0.036, num steps=3
2023-01-03 20:41:34.809 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 20:41:36.469 INFO: Evaluation rollout: return=0.398 (0.0), episode length=6.0
2023-01-03 20:41:36.470 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 20:41:36.473 INFO: Iteration: 20/137, steps: 4320
2023-01-03 20:42:11.488 DEBUG: Atoms are too close
2023-01-03 20:42:24.258 DEBUG: Atoms are too close
2023-01-03 20:42:27.618 DEBUG: Atoms are too close
2023-01-03 20:42:31.266 DEBUG: Atoms are too close
2023-01-03 20:42:32.758 INFO: Training rollout: return=-1.219 (4.8), episode length=5.9
2023-01-03 20:42:32.759 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 20:42:32.762 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-4320_train.pkl
2023-01-03 20:42:33.779 DEBUG: Taking gradient step
2023-01-03 20:42:33.789 DEBUG: Loss 0: {'policy_loss': 0.05236069865858567, 'entropy_loss': -0.07448684051632881, 'vf_loss': 0.016564916197139228, 'total_loss': -0.005561225660603908, 'approx_kl': 2.1187588572502136e-08, 'clip_fraction': 0.0, 'grad_norm': 24.212366104125977}
2023-01-03 20:42:34.797 DEBUG: Taking gradient step
2023-01-03 20:42:34.806 DEBUG: Loss 1: {'policy_loss': -0.014103722032944944, 'entropy_loss': -0.07413585484027863, 'vf_loss': 0.013415013565175781, 'total_loss': -0.07482456330804779, 'approx_kl': 0.009304066188633442, 'clip_fraction': 0.1276041679084301, 'grad_norm': 10.44621467590332}
2023-01-03 20:42:35.789 DEBUG: Taking gradient step
2023-01-03 20:42:35.798 DEBUG: Loss 2: {'policy_loss': 0.03460631104124521, 'entropy_loss': -0.07400292158126831, 'vf_loss': 0.014759705754908188, 'total_loss': -0.02463690478511492, 'approx_kl': 0.015661042649298906, 'clip_fraction': 0.18489583395421505, 'grad_norm': 11.279874801635742}
2023-01-03 20:42:36.838 DEBUG: Taking gradient step
2023-01-03 20:42:36.848 DEBUG: Loss 3: {'policy_loss': -0.07042867586819657, 'entropy_loss': -0.07425288297235966, 'vf_loss': 0.012628699320732812, 'total_loss': -0.1320528595198234, 'approx_kl': 0.012855409411713481, 'clip_fraction': 0.2330729216337204, 'grad_norm': 10.290243148803711}
2023-01-03 20:42:37.878 DEBUG: Taking gradient step
2023-01-03 20:42:37.887 DEBUG: Loss 4: {'policy_loss': -0.07024485324447288, 'entropy_loss': -0.07491579465568066, 'vf_loss': 0.012372808195420268, 'total_loss': -0.13278783970473326, 'approx_kl': 0.00878447387367487, 'clip_fraction': 0.2890625, 'grad_norm': 8.265616416931152}
2023-01-03 20:42:38.919 DEBUG: Taking gradient step
2023-01-03 20:42:38.928 DEBUG: Loss 5: {'policy_loss': -0.03523751098909274, 'entropy_loss': -0.07481487840414047, 'vf_loss': 0.014323022019595785, 'total_loss': -0.09572936737363744, 'approx_kl': 0.007749236421659589, 'clip_fraction': 0.2526041716337204, 'grad_norm': 14.758700370788574}
2023-01-03 20:42:39.964 DEBUG: Taking gradient step
2023-01-03 20:42:39.974 DEBUG: Loss 6: {'policy_loss': -0.02832350593616806, 'entropy_loss': -0.07469931058585644, 'vf_loss': 0.01407693799916741, 'total_loss': -0.0889458785228571, 'approx_kl': 0.025676987832412124, 'clip_fraction': 0.3359375, 'grad_norm': 10.794634819030762}
2023-01-03 20:42:40.965 DEBUG: Taking gradient step
2023-01-03 20:42:40.973 DEBUG: Loss 7: {'policy_loss': 0.0032342323042663587, 'entropy_loss': -0.07492377422749996, 'vf_loss': 0.01596500869702415, 'total_loss': -0.05572453322620944, 'approx_kl': 0.02204216062091291, 'clip_fraction': 0.41015625, 'grad_norm': 6.147324085235596}
2023-01-03 20:42:41.960 DEBUG: Taking gradient step
2023-01-03 20:42:41.968 DEBUG: Loss 8: {'policy_loss': 0.0005148712326636523, 'entropy_loss': -0.07604064792394638, 'vf_loss': 0.015153217972441872, 'total_loss': -0.06037255871884086, 'approx_kl': 0.024062820710241795, 'clip_fraction': 0.42578125, 'grad_norm': 6.4336018562316895}
2023-01-03 20:42:42.991 DEBUG: Taking gradient step
2023-01-03 20:42:43.000 DEBUG: Loss 9: {'policy_loss': -0.04077783451547292, 'entropy_loss': -0.07596591860055923, 'vf_loss': 0.013751232036689685, 'total_loss': -0.10299252107934248, 'approx_kl': 0.030614492716267705, 'clip_fraction': 0.39453125, 'grad_norm': 7.961027145385742}
2023-01-03 20:42:44.027 DEBUG: Taking gradient step
2023-01-03 20:42:44.038 DEBUG: Loss 10: {'policy_loss': -0.023397715485286533, 'entropy_loss': -0.07564880140125751, 'vf_loss': 0.015221853591934925, 'total_loss': -0.08382466329460911, 'approx_kl': 0.019864879548549652, 'clip_fraction': 0.45703125, 'grad_norm': 7.587552070617676}
2023-01-03 20:42:45.066 DEBUG: Taking gradient step
2023-01-03 20:42:45.076 DEBUG: Loss 11: {'policy_loss': 0.011381280580500093, 'entropy_loss': -0.07624020241200924, 'vf_loss': 0.015608130945683451, 'total_loss': -0.04925079088582571, 'approx_kl': 0.003831231966614723, 'clip_fraction': 0.4622395932674408, 'grad_norm': 18.366653442382812}
2023-01-03 20:42:46.083 DEBUG: Taking gradient step
2023-01-03 20:42:46.094 DEBUG: Loss 12: {'policy_loss': 0.0043122655801933404, 'entropy_loss': -0.0765440259128809, 'vf_loss': 0.01531482664617333, 'total_loss': -0.056916933686514216, 'approx_kl': 0.028837702004238963, 'clip_fraction': 0.4270833358168602, 'grad_norm': 15.57048225402832}
2023-01-03 20:42:47.124 DEBUG: Taking gradient step
2023-01-03 20:42:47.134 DEBUG: Loss 13: {'policy_loss': -0.022484855623674582, 'entropy_loss': -0.07665452919900417, 'vf_loss': 0.01431831287794717, 'total_loss': -0.08482107194473158, 'approx_kl': 0.035473573487252, 'clip_fraction': 0.4140625, 'grad_norm': 4.431661605834961}
2023-01-03 20:42:48.162 DEBUG: Taking gradient step
2023-01-03 20:42:48.172 DEBUG: Loss 14: {'policy_loss': -0.05903406050891144, 'entropy_loss': -0.07663627713918686, 'vf_loss': 0.013079558826641276, 'total_loss': -0.12259077882145702, 'approx_kl': 0.021259614266455173, 'clip_fraction': 0.4765625, 'grad_norm': 4.813129425048828}
2023-01-03 20:42:48.172 INFO: Optimization: policy loss=-0.059, vf loss=0.013, entropy loss=-0.077, total loss=-0.123, num steps=15
2023-01-03 20:42:48.173 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 20:42:49.848 INFO: Evaluation rollout: return=0.416 (0.0), episode length=6.0
2023-01-03 20:42:49.851 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 20:42:49.853 DEBUG: Deleting old model: runs/CH3NO_baseline/models/CH3NO_baseline_run-1_steps-2376.model
2023-01-03 20:42:49.859 DEBUG: Saving model: runs/CH3NO_baseline/models/CH3NO_baseline_run-1_steps-4536.model
2023-01-03 20:42:49.889 INFO: Iteration: 21/137, steps: 4536
2023-01-03 20:43:05.011 DEBUG: Atoms are too close
2023-01-03 20:43:06.236 DEBUG: Atoms are too close
2023-01-03 20:43:26.618 DEBUG: Atoms are too close
2023-01-03 20:43:45.583 DEBUG: There is a single atom floating around
2023-01-03 20:43:46.345 INFO: Training rollout: return=-1.039 (4.4), episode length=6.0
2023-01-03 20:43:46.346 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 20:43:46.349 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-4536_train.pkl
2023-01-03 20:43:47.361 DEBUG: Taking gradient step
2023-01-03 20:43:47.371 DEBUG: Loss 0: {'policy_loss': -0.04948448963546451, 'entropy_loss': -0.0771412905305624, 'vf_loss': 0.011798304749305094, 'total_loss': -0.1148274754167218, 'approx_kl': -5.723753382369523e-08, 'clip_fraction': 0.0, 'grad_norm': 11.634353637695312}
2023-01-03 20:43:48.396 DEBUG: Taking gradient step
2023-01-03 20:43:48.405 DEBUG: Loss 1: {'policy_loss': -0.018919356705107256, 'entropy_loss': -0.07725036889314651, 'vf_loss': 0.0134291484906317, 'total_loss': -0.08274057710762207, 'approx_kl': 0.004160866606980562, 'clip_fraction': 0.01171875, 'grad_norm': 12.576154708862305}
2023-01-03 20:43:49.430 DEBUG: Taking gradient step
2023-01-03 20:43:49.441 DEBUG: Loss 2: {'policy_loss': -0.025452426959232423, 'entropy_loss': -0.07683583535254002, 'vf_loss': 0.012829927353934468, 'total_loss': -0.08945833495783798, 'approx_kl': 0.014706384157761931, 'clip_fraction': 0.16145833395421505, 'grad_norm': 4.787881851196289}
2023-01-03 20:43:50.484 DEBUG: Taking gradient step
2023-01-03 20:43:50.493 DEBUG: Loss 3: {'policy_loss': -0.03925289931201477, 'entropy_loss': -0.0773602295666933, 'vf_loss': 0.012778221750548695, 'total_loss': -0.10383490712815938, 'approx_kl': 0.024721404537558556, 'clip_fraction': 0.3411458358168602, 'grad_norm': 3.621704339981079}
2023-01-03 20:43:51.525 DEBUG: Taking gradient step
2023-01-03 20:43:51.534 DEBUG: Loss 4: {'policy_loss': -0.051428910271487466, 'entropy_loss': -0.07638831436634064, 'vf_loss': 0.012654097470802877, 'total_loss': -0.11516312716702522, 'approx_kl': 0.04358724830672145, 'clip_fraction': 0.4049479216337204, 'grad_norm': 6.861310005187988}
2023-01-03 20:43:52.522 DEBUG: Early stopping at step 5 for reaching max KL.
2023-01-03 20:43:52.522 INFO: Optimization: policy loss=-0.051, vf loss=0.013, entropy loss=-0.076, total loss=-0.115, num steps=5
2023-01-03 20:43:52.522 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 20:43:53.963 DEBUG: Atoms are too close
2023-01-03 20:43:53.965 INFO: Evaluation rollout: return=-12.869 (0.0), episode length=6.0
2023-01-03 20:43:53.965 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 20:43:53.968 INFO: Iteration: 22/137, steps: 4752
2023-01-03 20:44:03.318 DEBUG: Atoms are too close
2023-01-03 20:44:10.153 DEBUG: Atoms are too close
2023-01-03 20:44:22.754 DEBUG: Atoms are too close
2023-01-03 20:44:23.332 DEBUG: Atoms are too close
2023-01-03 20:44:25.295 DEBUG: Atoms are too close
2023-01-03 20:44:37.747 DEBUG: Atoms are too close
2023-01-03 20:44:40.434 DEBUG: Atoms are too close
2023-01-03 20:44:42.994 DEBUG: There is a single atom floating around
2023-01-03 20:44:44.315 DEBUG: There is a single atom floating around
2023-01-03 20:44:48.732 INFO: Training rollout: return=-3.616 (7.0), episode length=5.7
2023-01-03 20:44:48.733 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 20:44:48.736 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-4752_train.pkl
2023-01-03 20:44:49.684 DEBUG: Taking gradient step
2023-01-03 20:44:49.693 DEBUG: Loss 0: {'policy_loss': -0.04201392991120588, 'entropy_loss': -0.07721571624279022, 'vf_loss': 0.025950177722775872, 'total_loss': -0.09327946843122023, 'approx_kl': -3.434251993894577e-09, 'clip_fraction': 0.0, 'grad_norm': 19.059375762939453}
2023-01-03 20:44:50.705 DEBUG: Taking gradient step
2023-01-03 20:44:50.714 DEBUG: Loss 1: {'policy_loss': -0.04700658443699675, 'entropy_loss': -0.07631276175379753, 'vf_loss': 0.02591510278193177, 'total_loss': -0.0974042434088625, 'approx_kl': 0.008769122185185552, 'clip_fraction': 0.049479166977107525, 'grad_norm': 15.505276679992676}
2023-01-03 20:44:51.711 DEBUG: Taking gradient step
2023-01-03 20:44:51.719 DEBUG: Loss 2: {'policy_loss': -0.03963868541331374, 'entropy_loss': -0.07630947977304459, 'vf_loss': 0.02759154474129916, 'total_loss': -0.08835662044505917, 'approx_kl': 0.03811523714102805, 'clip_fraction': 0.203125, 'grad_norm': 11.931629180908203}
2023-01-03 20:44:52.699 DEBUG: Taking gradient step
2023-01-03 20:44:52.708 DEBUG: Loss 3: {'policy_loss': -0.015748963592343027, 'entropy_loss': -0.07653327845036983, 'vf_loss': 0.02728318311048733, 'total_loss': -0.06499905893222553, 'approx_kl': 0.035071782767772675, 'clip_fraction': 0.30078125, 'grad_norm': 15.988348007202148}
2023-01-03 20:44:53.709 DEBUG: Early stopping at step 4 for reaching max KL.
2023-01-03 20:44:53.709 INFO: Optimization: policy loss=-0.016, vf loss=0.027, entropy loss=-0.077, total loss=-0.065, num steps=4
2023-01-03 20:44:53.710 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 20:44:55.107 DEBUG: Atoms are too close
2023-01-03 20:44:55.109 INFO: Evaluation rollout: return=-12.671 (0.0), episode length=6.0
2023-01-03 20:44:55.110 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 20:44:55.112 INFO: Iteration: 23/137, steps: 4968
2023-01-03 20:45:12.113 DEBUG: Atoms are too close
2023-01-03 20:45:25.534 DEBUG: Atoms are too close
2023-01-03 20:45:30.755 DEBUG: Atoms are too close
2023-01-03 20:45:32.438 DEBUG: Atoms are too close
2023-01-03 20:45:50.026 DEBUG: Atoms are too close
2023-01-03 20:45:51.156 DEBUG: Atoms are too close
2023-01-03 20:45:51.213 INFO: Training rollout: return=-1.865 (5.4), episode length=5.9
2023-01-03 20:45:51.214 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 20:45:51.217 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-4968_train.pkl
2023-01-03 20:45:52.217 DEBUG: Taking gradient step
2023-01-03 20:45:52.227 DEBUG: Loss 0: {'policy_loss': 0.023436460987267194, 'entropy_loss': -0.07612732611596584, 'vf_loss': 0.020476294186314005, 'total_loss': -0.03221457094238464, 'approx_kl': -6.457170087514896e-08, 'clip_fraction': 0.0, 'grad_norm': 19.71590232849121}
2023-01-03 20:45:53.221 DEBUG: Taking gradient step
2023-01-03 20:45:53.230 DEBUG: Loss 1: {'policy_loss': -0.03455128417004558, 'entropy_loss': -0.07642152905464172, 'vf_loss': 0.01832873842148901, 'total_loss': -0.0926440748031983, 'approx_kl': 0.026906090788543224, 'clip_fraction': 0.05989583395421505, 'grad_norm': 20.61185646057129}
2023-01-03 20:45:54.223 DEBUG: Early stopping at step 2 for reaching max KL.
2023-01-03 20:45:54.224 INFO: Optimization: policy loss=-0.035, vf loss=0.018, entropy loss=-0.076, total loss=-0.093, num steps=2
2023-01-03 20:45:54.224 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 20:45:55.662 DEBUG: Atoms are too close
2023-01-03 20:45:55.664 INFO: Evaluation rollout: return=-12.664 (0.0), episode length=6.0
2023-01-03 20:45:55.665 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 20:45:55.668 INFO: Iteration: 24/137, steps: 5184
2023-01-03 20:46:09.227 DEBUG: Atoms are too close
2023-01-03 20:46:11.863 DEBUG: There is a single atom floating around
2023-01-03 20:46:11.866 DEBUG: Atoms are too close
2023-01-03 20:46:27.930 DEBUG: Atoms are too close
2023-01-03 20:46:29.497 DEBUG: Atoms are too close
2023-01-03 20:46:31.741 DEBUG: There is a single atom floating around
2023-01-03 20:46:46.183 DEBUG: Atoms are too close
2023-01-03 20:46:50.280 DEBUG: There is a single atom floating around
2023-01-03 20:46:50.614 INFO: Training rollout: return=-2.593 (5.8), episode length=5.9
2023-01-03 20:46:50.616 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 20:46:50.619 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-5184_train.pkl
2023-01-03 20:46:51.680 DEBUG: Taking gradient step
2023-01-03 20:46:51.691 DEBUG: Loss 0: {'policy_loss': 0.05428269394029167, 'entropy_loss': -0.07727906666696072, 'vf_loss': 0.0294513863064451, 'total_loss': 0.006455013579776056, 'approx_kl': 1.0073805967181215e-07, 'clip_fraction': 0.0, 'grad_norm': 20.718660354614258}
2023-01-03 20:46:52.707 DEBUG: Taking gradient step
2023-01-03 20:46:52.716 DEBUG: Loss 1: {'policy_loss': -0.028942898531817224, 'entropy_loss': -0.07688549719750881, 'vf_loss': 0.02456836721618095, 'total_loss': -0.0812600285131451, 'approx_kl': 0.006460320379119366, 'clip_fraction': 0.05859375, 'grad_norm': 14.020298957824707}
2023-01-03 20:46:53.732 DEBUG: Taking gradient step
2023-01-03 20:46:53.741 DEBUG: Loss 2: {'policy_loss': -0.03044796820750801, 'entropy_loss': -0.07623820379376411, 'vf_loss': 0.02450002153428415, 'total_loss': -0.08218615046698798, 'approx_kl': 0.017476997803896666, 'clip_fraction': 0.2161458358168602, 'grad_norm': 13.72111988067627}
2023-01-03 20:46:54.803 DEBUG: Taking gradient step
2023-01-03 20:46:54.811 DEBUG: Loss 3: {'policy_loss': 0.013964191604509783, 'entropy_loss': -0.07667967863380909, 'vf_loss': 0.02726961938560222, 'total_loss': -0.03544586764369709, 'approx_kl': 0.04170385026372969, 'clip_fraction': 0.3333333358168602, 'grad_norm': 14.476659774780273}
2023-01-03 20:46:55.854 DEBUG: Early stopping at step 4 for reaching max KL.
2023-01-03 20:46:55.854 INFO: Optimization: policy loss=0.014, vf loss=0.027, entropy loss=-0.077, total loss=-0.035, num steps=4
2023-01-03 20:46:55.855 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 20:46:57.544 INFO: Evaluation rollout: return=-0.527 (0.0), episode length=6.0
2023-01-03 20:46:57.546 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 20:46:57.549 INFO: Iteration: 25/137, steps: 5400
2023-01-03 20:47:03.602 DEBUG: Atoms are too close
2023-01-03 20:47:12.046 DEBUG: Atoms are too close
2023-01-03 20:47:28.612 DEBUG: Atoms are too close
2023-01-03 20:47:46.015 DEBUG: Atoms are too close
2023-01-03 20:47:53.459 INFO: Training rollout: return=-1.563 (5.7), episode length=5.8
2023-01-03 20:47:53.461 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 20:47:53.463 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-5400_train.pkl
2023-01-03 20:47:54.505 DEBUG: Taking gradient step
2023-01-03 20:47:54.513 DEBUG: Loss 0: {'policy_loss': -0.016950862699192788, 'entropy_loss': -0.07691799849271774, 'vf_loss': 0.01205150564722265, 'total_loss': -0.08181735554468787, 'approx_kl': 5.770319511100297e-08, 'clip_fraction': 0.0, 'grad_norm': 14.861572265625}
2023-01-03 20:47:55.532 DEBUG: Taking gradient step
2023-01-03 20:47:55.541 DEBUG: Loss 1: {'policy_loss': 0.011975296881639695, 'entropy_loss': -0.07610209099948406, 'vf_loss': 0.013177207822548536, 'total_loss': -0.05094958629529582, 'approx_kl': -0.005093565443530679, 'clip_fraction': 0.05078125, 'grad_norm': 15.503442764282227}
2023-01-03 20:47:56.580 DEBUG: Taking gradient step
2023-01-03 20:47:56.589 DEBUG: Loss 2: {'policy_loss': -0.007895040245889771, 'entropy_loss': -0.07684950716793537, 'vf_loss': 0.012693814206222703, 'total_loss': -0.07205073320760244, 'approx_kl': 0.005631528794765472, 'clip_fraction': 0.19921875, 'grad_norm': 6.220731735229492}
2023-01-03 20:47:57.627 DEBUG: Taking gradient step
2023-01-03 20:47:57.637 DEBUG: Loss 3: {'policy_loss': -0.028211548912861525, 'entropy_loss': -0.07653866335749626, 'vf_loss': 0.012034040012019312, 'total_loss': -0.09271617225833848, 'approx_kl': 0.02099083736538887, 'clip_fraction': 0.3372395858168602, 'grad_norm': 4.841354846954346}
2023-01-03 20:47:58.673 DEBUG: Taking gradient step
2023-01-03 20:47:58.681 DEBUG: Loss 4: {'policy_loss': 0.0020027207855891904, 'entropy_loss': -0.07619907706975937, 'vf_loss': 0.013416094708834161, 'total_loss': -0.060780261575336024, 'approx_kl': 0.017274145502597094, 'clip_fraction': 0.3515625, 'grad_norm': 4.154597282409668}
2023-01-03 20:47:59.722 DEBUG: Taking gradient step
2023-01-03 20:47:59.733 DEBUG: Loss 5: {'policy_loss': -0.049817651521214854, 'entropy_loss': -0.07635071128606796, 'vf_loss': 0.011642231904338643, 'total_loss': -0.11452613090294417, 'approx_kl': 0.0013949449639767408, 'clip_fraction': 0.3125, 'grad_norm': 2.8311686515808105}
2023-01-03 20:48:00.740 DEBUG: Taking gradient step
2023-01-03 20:48:00.750 DEBUG: Loss 6: {'policy_loss': 0.022254487983757468, 'entropy_loss': -0.07581688836216927, 'vf_loss': 0.014980323322570117, 'total_loss': -0.038582077055841685, 'approx_kl': 0.028167828917503357, 'clip_fraction': 0.2760416716337204, 'grad_norm': 3.0901997089385986}
2023-01-03 20:48:01.759 DEBUG: Taking gradient step
2023-01-03 20:48:01.769 DEBUG: Loss 7: {'policy_loss': -0.0443591208345982, 'entropy_loss': -0.07671378552913666, 'vf_loss': 0.011757822331609841, 'total_loss': -0.10931508403212502, 'approx_kl': 0.026674106251448393, 'clip_fraction': 0.2786458358168602, 'grad_norm': 4.950092792510986}
2023-01-03 20:48:02.799 DEBUG: Early stopping at step 8 for reaching max KL.
2023-01-03 20:48:02.799 INFO: Optimization: policy loss=-0.044, vf loss=0.012, entropy loss=-0.077, total loss=-0.109, num steps=8
2023-01-03 20:48:02.800 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 20:48:04.499 INFO: Evaluation rollout: return=0.664 (0.0), episode length=6.0
2023-01-03 20:48:04.500 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 20:48:04.502 INFO: Iteration: 26/137, steps: 5616
2023-01-03 20:48:19.666 DEBUG: Atoms are too close
2023-01-03 20:48:22.009 DEBUG: Atoms are too close
2023-01-03 20:48:22.011 DEBUG: Atoms are too close
2023-01-03 20:48:40.183 DEBUG: There is a single atom floating around
2023-01-03 20:48:41.017 DEBUG: There is a single atom floating around
2023-01-03 20:48:50.217 DEBUG: Atoms are too close
2023-01-03 20:48:57.829 DEBUG: There is a single atom floating around
2023-01-03 20:48:57.832 DEBUG: Atoms are too close
2023-01-03 20:48:58.653 DEBUG: Atoms are too close
2023-01-03 20:48:59.130 INFO: Training rollout: return=-3.050 (6.2), episode length=5.9
2023-01-03 20:48:59.131 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 20:48:59.134 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-5616_train.pkl
2023-01-03 20:49:00.195 DEBUG: Taking gradient step
2023-01-03 20:49:00.206 DEBUG: Loss 0: {'policy_loss': -0.026118756177247557, 'entropy_loss': -0.07501136511564255, 'vf_loss': 0.02651763049806817, 'total_loss': -0.07461249079482193, 'approx_kl': 1.0710209608078003e-08, 'clip_fraction': 0.0, 'grad_norm': 18.540760040283203}
2023-01-03 20:49:01.254 DEBUG: Taking gradient step
2023-01-03 20:49:01.264 DEBUG: Loss 1: {'policy_loss': -0.0030103171377530297, 'entropy_loss': -0.07496842555701733, 'vf_loss': 0.028672979685898554, 'total_loss': -0.0493057630088718, 'approx_kl': 0.008545251679606736, 'clip_fraction': 0.05989583395421505, 'grad_norm': 13.023202896118164}
2023-01-03 20:49:02.266 DEBUG: Taking gradient step
2023-01-03 20:49:02.277 DEBUG: Loss 2: {'policy_loss': -0.005787299794601124, 'entropy_loss': -0.07527843117713928, 'vf_loss': 0.02886738100539229, 'total_loss': -0.05219834996634812, 'approx_kl': 0.01903835590928793, 'clip_fraction': 0.20703125, 'grad_norm': 11.249754905700684}
2023-01-03 20:49:03.352 DEBUG: Taking gradient step
2023-01-03 20:49:03.363 DEBUG: Loss 3: {'policy_loss': -0.04774981190861891, 'entropy_loss': -0.07437875680625439, 'vf_loss': 0.02732322161626994, 'total_loss': -0.09480534709860336, 'approx_kl': 0.038205023389309645, 'clip_fraction': 0.3802083358168602, 'grad_norm': 10.333782196044922}
2023-01-03 20:49:04.398 DEBUG: Early stopping at step 4 for reaching max KL.
2023-01-03 20:49:04.399 INFO: Optimization: policy loss=-0.048, vf loss=0.027, entropy loss=-0.074, total loss=-0.095, num steps=4
2023-01-03 20:49:04.400 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 20:49:06.075 INFO: Evaluation rollout: return=0.648 (0.0), episode length=6.0
2023-01-03 20:49:06.076 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 20:49:06.078 INFO: Iteration: 27/137, steps: 5832
2023-01-03 20:49:23.788 DEBUG: Atoms are too close
2023-01-03 20:49:33.738 DEBUG: Atoms are too close
2023-01-03 20:49:37.323 DEBUG: Atoms are too close
2023-01-03 20:49:37.595 DEBUG: Atoms are too close
2023-01-03 20:49:38.159 DEBUG: Atoms are too close
2023-01-03 20:49:40.073 DEBUG: There is a single atom floating around
2023-01-03 20:49:59.487 DEBUG: Atoms are too close
2023-01-03 20:50:01.101 INFO: Training rollout: return=-2.424 (6.0), episode length=5.9
2023-01-03 20:50:01.103 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 20:50:01.106 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-5832_train.pkl
2023-01-03 20:50:02.154 DEBUG: Taking gradient step
2023-01-03 20:50:02.163 DEBUG: Loss 0: {'policy_loss': -0.03199788673205488, 'entropy_loss': -0.07402011938393116, 'vf_loss': 0.02076616317605747, 'total_loss': -0.08525184293992857, 'approx_kl': -6.984919309616089e-10, 'clip_fraction': 0.0, 'grad_norm': 14.293904304504395}
2023-01-03 20:50:03.193 DEBUG: Taking gradient step
2023-01-03 20:50:03.201 DEBUG: Loss 1: {'policy_loss': 0.023473610503610347, 'entropy_loss': -0.07331249676644802, 'vf_loss': 0.023979202223438262, 'total_loss': -0.025859684039399422, 'approx_kl': 0.011341631412506104, 'clip_fraction': 0.12890625, 'grad_norm': 12.307832717895508}
2023-01-03 20:50:04.232 DEBUG: Taking gradient step
2023-01-03 20:50:04.241 DEBUG: Loss 2: {'policy_loss': 0.004663596851377391, 'entropy_loss': -0.07370138727128506, 'vf_loss': 0.024135547224163258, 'total_loss': -0.044902243195744415, 'approx_kl': 0.03705833712592721, 'clip_fraction': 0.3255208358168602, 'grad_norm': 8.39927864074707}
2023-01-03 20:50:05.259 DEBUG: Taking gradient step
2023-01-03 20:50:05.268 DEBUG: Loss 3: {'policy_loss': -0.03694597237823195, 'entropy_loss': -0.07307428866624832, 'vf_loss': 0.02155052844596648, 'total_loss': -0.08846973259851379, 'approx_kl': 0.04359936900436878, 'clip_fraction': 0.4036458358168602, 'grad_norm': 10.961255073547363}
2023-01-03 20:50:06.284 DEBUG: Early stopping at step 4 for reaching max KL.
2023-01-03 20:50:06.285 INFO: Optimization: policy loss=-0.037, vf loss=0.022, entropy loss=-0.073, total loss=-0.088, num steps=4
2023-01-03 20:50:06.285 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 20:50:07.987 INFO: Evaluation rollout: return=0.622 (0.0), episode length=6.0
2023-01-03 20:50:07.990 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 20:50:07.993 INFO: Iteration: 28/137, steps: 6048
2023-01-03 20:50:24.750 DEBUG: Atoms are too close
2023-01-03 20:50:58.700 DEBUG: Atoms are too close
2023-01-03 20:51:04.295 DEBUG: Atoms are too close
2023-01-03 20:51:04.356 INFO: Training rollout: return=-0.739 (3.9), episode length=6.0
2023-01-03 20:51:04.357 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 20:51:04.359 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-6048_train.pkl
2023-01-03 20:51:05.445 DEBUG: Taking gradient step
2023-01-03 20:51:05.455 DEBUG: Loss 0: {'policy_loss': -0.03959978363301157, 'entropy_loss': -0.07323942333459854, 'vf_loss': 0.009632277008644611, 'total_loss': -0.10320692995896551, 'approx_kl': -2.2856207593235922e-08, 'clip_fraction': 0.0, 'grad_norm': 20.092317581176758}
2023-01-03 20:51:06.508 DEBUG: Taking gradient step
2023-01-03 20:51:06.517 DEBUG: Loss 1: {'policy_loss': -0.022568973946961026, 'entropy_loss': -0.07233934104442596, 'vf_loss': 0.010194900471953547, 'total_loss': -0.08471341451943344, 'approx_kl': -0.004636408295482397, 'clip_fraction': 0.041666666977107525, 'grad_norm': 18.52302360534668}
2023-01-03 20:51:07.534 DEBUG: Taking gradient step
2023-01-03 20:51:07.543 DEBUG: Loss 2: {'policy_loss': -0.03889847482414921, 'entropy_loss': -0.0728378351777792, 'vf_loss': 0.010408609150968017, 'total_loss': -0.10132770085096039, 'approx_kl': 0.004255400504916906, 'clip_fraction': 0.1888020858168602, 'grad_norm': 5.606088161468506}
2023-01-03 20:51:08.591 DEBUG: Taking gradient step
2023-01-03 20:51:08.600 DEBUG: Loss 3: {'policy_loss': -0.056689439952166625, 'entropy_loss': -0.07217999175190926, 'vf_loss': 0.010564058351619452, 'total_loss': -0.11830537335245643, 'approx_kl': 0.002145275240764022, 'clip_fraction': 0.2708333358168602, 'grad_norm': 4.351423740386963}
2023-01-03 20:51:09.644 DEBUG: Taking gradient step
2023-01-03 20:51:09.657 DEBUG: Loss 4: {'policy_loss': -0.0173535179181445, 'entropy_loss': -0.07144978456199169, 'vf_loss': 0.011537309906323102, 'total_loss': -0.0772659925738131, 'approx_kl': 0.02743296348489821, 'clip_fraction': 0.32421875, 'grad_norm': 4.534351825714111}
2023-01-03 20:51:10.677 DEBUG: Taking gradient step
2023-01-03 20:51:10.686 DEBUG: Loss 5: {'policy_loss': -0.03531229554693789, 'entropy_loss': -0.07222258113324642, 'vf_loss': 0.010687741692770166, 'total_loss': -0.09684713498741414, 'approx_kl': 0.029641229659318924, 'clip_fraction': 0.3893229216337204, 'grad_norm': 6.464991569519043}
2023-01-03 20:51:11.736 DEBUG: Taking gradient step
2023-01-03 20:51:11.745 DEBUG: Loss 6: {'policy_loss': -0.046517501778640315, 'entropy_loss': -0.0715173352509737, 'vf_loss': 0.011038778175217399, 'total_loss': -0.10699605885439661, 'approx_kl': 0.037226730957627296, 'clip_fraction': 0.3932291716337204, 'grad_norm': 12.628449440002441}
2023-01-03 20:51:12.794 DEBUG: Taking gradient step
2023-01-03 20:51:12.803 DEBUG: Loss 7: {'policy_loss': -0.028501241055475104, 'entropy_loss': -0.07123083807528019, 'vf_loss': 0.010707166895701108, 'total_loss': -0.08902491223505418, 'approx_kl': 0.029315208244952373, 'clip_fraction': 0.42578125, 'grad_norm': 4.8033647537231445}
2023-01-03 20:51:13.944 DEBUG: Taking gradient step
2023-01-03 20:51:13.952 DEBUG: Loss 8: {'policy_loss': -0.05799530126483664, 'entropy_loss': -0.07098359987139702, 'vf_loss': 0.010515392987198165, 'total_loss': -0.1184635081490355, 'approx_kl': 0.02246813429519534, 'clip_fraction': 0.4127604216337204, 'grad_norm': 4.7050065994262695}
2023-01-03 20:51:14.972 DEBUG: Taking gradient step
2023-01-03 20:51:14.981 DEBUG: Loss 9: {'policy_loss': -0.07702436418595603, 'entropy_loss': -0.07119611650705338, 'vf_loss': 0.009770911389984312, 'total_loss': -0.1384495693030251, 'approx_kl': 0.01787318824790418, 'clip_fraction': 0.4283854216337204, 'grad_norm': 6.963072299957275}
2023-01-03 20:51:16.035 DEBUG: Taking gradient step
2023-01-03 20:51:16.043 DEBUG: Loss 10: {'policy_loss': -0.06410758723743526, 'entropy_loss': -0.07070470415055752, 'vf_loss': 0.009773174820985059, 'total_loss': -0.12503911656700772, 'approx_kl': 0.0049316780641674995, 'clip_fraction': 0.41796875, 'grad_norm': 8.344782829284668}
2023-01-03 20:51:17.079 DEBUG: Taking gradient step
2023-01-03 20:51:17.089 DEBUG: Loss 11: {'policy_loss': -0.07852743397342003, 'entropy_loss': -0.07155242562294006, 'vf_loss': 0.00920931169813443, 'total_loss': -0.14087054789822567, 'approx_kl': -0.005383365787565708, 'clip_fraction': 0.34765625, 'grad_norm': 6.14385986328125}
2023-01-03 20:51:18.160 DEBUG: Taking gradient step
2023-01-03 20:51:18.169 DEBUG: Loss 12: {'policy_loss': -0.06415393594005622, 'entropy_loss': -0.07210167124867439, 'vf_loss': 0.009896650030963537, 'total_loss': -0.12635895715776707, 'approx_kl': -0.016979378182440996, 'clip_fraction': 0.3203125, 'grad_norm': 6.3943586349487305}
2023-01-03 20:51:19.217 DEBUG: Taking gradient step
2023-01-03 20:51:19.226 DEBUG: Loss 13: {'policy_loss': -0.033131786864851125, 'entropy_loss': -0.07163738086819649, 'vf_loss': 0.010725909994863992, 'total_loss': -0.09404325773818362, 'approx_kl': -0.014613694744184613, 'clip_fraction': 0.3190104216337204, 'grad_norm': 6.650050163269043}
2023-01-03 20:51:20.231 DEBUG: Taking gradient step
2023-01-03 20:51:20.239 DEBUG: Loss 14: {'policy_loss': -0.09104052966552284, 'entropy_loss': -0.07191551849246025, 'vf_loss': 0.00910835264434433, 'total_loss': -0.15384769551363878, 'approx_kl': -0.0182202085852623, 'clip_fraction': 0.36328125, 'grad_norm': 4.003747463226318}
2023-01-03 20:51:20.240 INFO: Optimization: policy loss=-0.091, vf loss=0.009, entropy loss=-0.072, total loss=-0.154, num steps=15
2023-01-03 20:51:20.240 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 20:51:21.905 INFO: Evaluation rollout: return=0.568 (0.0), episode length=6.0
2023-01-03 20:51:21.906 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 20:51:21.908 INFO: Iteration: 29/137, steps: 6264
2023-01-03 20:51:54.128 DEBUG: There is a single atom floating around
2023-01-03 20:51:58.066 DEBUG: Atoms are too close
2023-01-03 20:51:58.952 DEBUG: Atoms are too close
2023-01-03 20:52:14.261 DEBUG: Atoms are too close
2023-01-03 20:52:16.828 DEBUG: Atoms are too close
2023-01-03 20:52:16.829 DEBUG: Atoms are too close
2023-01-03 20:52:17.611 INFO: Training rollout: return=-1.862 (5.3), episode length=5.9
2023-01-03 20:52:17.612 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 20:52:17.615 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-6264_train.pkl
2023-01-03 20:52:18.681 DEBUG: Taking gradient step
2023-01-03 20:52:18.691 DEBUG: Loss 0: {'policy_loss': 0.00874405287951081, 'entropy_loss': -0.07266683876514435, 'vf_loss': 0.021494710999539996, 'total_loss': -0.04242807488609354, 'approx_kl': -9.204571682630558e-08, 'clip_fraction': 0.0, 'grad_norm': 16.04782485961914}
2023-01-03 20:52:19.728 DEBUG: Taking gradient step
2023-01-03 20:52:19.738 DEBUG: Loss 1: {'policy_loss': -0.0431864935978547, 'entropy_loss': -0.07190744392573833, 'vf_loss': 0.018299186683687466, 'total_loss': -0.09679475083990557, 'approx_kl': -0.004690367262810469, 'clip_fraction': 0.0390625, 'grad_norm': 8.000702857971191}
2023-01-03 20:52:20.796 DEBUG: Taking gradient step
2023-01-03 20:52:20.806 DEBUG: Loss 2: {'policy_loss': 0.010323306835846952, 'entropy_loss': -0.07244777120649815, 'vf_loss': 0.022127503194478447, 'total_loss': -0.039996961176172734, 'approx_kl': 0.006395137868821621, 'clip_fraction': 0.1783854179084301, 'grad_norm': 9.108664512634277}
2023-01-03 20:52:21.857 DEBUG: Taking gradient step
2023-01-03 20:52:21.866 DEBUG: Loss 3: {'policy_loss': -0.07321580443017639, 'entropy_loss': -0.0718696378171444, 'vf_loss': 0.018438413327469514, 'total_loss': -0.12664702891985127, 'approx_kl': 0.0016989721916615963, 'clip_fraction': 0.328125, 'grad_norm': 8.296642303466797}
2023-01-03 20:52:22.883 DEBUG: Taking gradient step
2023-01-03 20:52:22.893 DEBUG: Loss 4: {'policy_loss': 0.004154017477108224, 'entropy_loss': -0.07105754874646664, 'vf_loss': 0.022306559290314887, 'total_loss': -0.044596971979043526, 'approx_kl': 0.013871321134502068, 'clip_fraction': 0.4140625, 'grad_norm': 4.418945789337158}
2023-01-03 20:52:23.932 DEBUG: Taking gradient step
2023-01-03 20:52:23.942 DEBUG: Loss 5: {'policy_loss': -0.07681538233917876, 'entropy_loss': -0.07254404574632645, 'vf_loss': 0.01835832952645592, 'total_loss': -0.1310010985590493, 'approx_kl': 0.022843237034976482, 'clip_fraction': 0.4296875, 'grad_norm': 4.386852741241455}
2023-01-03 20:52:24.955 DEBUG: Taking gradient step
2023-01-03 20:52:24.964 DEBUG: Loss 6: {'policy_loss': -0.03557539652373197, 'entropy_loss': -0.07204212434589863, 'vf_loss': 0.019217970634299093, 'total_loss': -0.08839955023533151, 'approx_kl': 0.03205685596913099, 'clip_fraction': 0.3997395858168602, 'grad_norm': 5.613626480102539}
2023-01-03 20:52:25.990 DEBUG: Early stopping at step 7 for reaching max KL.
2023-01-03 20:52:25.990 INFO: Optimization: policy loss=-0.036, vf loss=0.019, entropy loss=-0.072, total loss=-0.088, num steps=7
2023-01-03 20:52:25.991 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 20:52:27.715 INFO: Evaluation rollout: return=0.541 (0.0), episode length=6.0
2023-01-03 20:52:27.717 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 20:52:27.720 INFO: Iteration: 30/137, steps: 6480
2023-01-03 20:52:45.794 DEBUG: Atoms are too close
2023-01-03 20:53:02.399 DEBUG: Atoms are too close
2023-01-03 20:53:02.990 DEBUG: Atoms are too close
2023-01-03 20:53:03.836 DEBUG: Atoms are too close
2023-01-03 20:53:23.125 DEBUG: Atoms are too close
2023-01-03 20:53:23.753 INFO: Training rollout: return=-1.336 (4.7), episode length=6.0
2023-01-03 20:53:23.755 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 20:53:23.757 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-6480_train.pkl
2023-01-03 20:53:24.819 DEBUG: Taking gradient step
2023-01-03 20:53:24.829 DEBUG: Loss 0: {'policy_loss': 0.042403608163833324, 'entropy_loss': -0.07323381118476391, 'vf_loss': 0.019379212585430974, 'total_loss': -0.011450990435499624, 'approx_kl': 2.242935082108488e-08, 'clip_fraction': 0.0, 'grad_norm': 11.929646492004395}
2023-01-03 20:53:25.857 DEBUG: Taking gradient step
2023-01-03 20:53:25.867 DEBUG: Loss 1: {'policy_loss': -0.06807155671849788, 'entropy_loss': -0.07177312858402729, 'vf_loss': 0.015008403738838317, 'total_loss': -0.12483628156368685, 'approx_kl': 0.0002174584660679102, 'clip_fraction': 0.05859375, 'grad_norm': 9.833025932312012}
2023-01-03 20:53:26.901 DEBUG: Taking gradient step
2023-01-03 20:53:26.911 DEBUG: Loss 2: {'policy_loss': -0.047914827894769, 'entropy_loss': -0.07334074936807156, 'vf_loss': 0.016333506597955433, 'total_loss': -0.10492207066488513, 'approx_kl': -0.0033437288366258144, 'clip_fraction': 0.21484375, 'grad_norm': 5.6746625900268555}
2023-01-03 20:53:27.941 DEBUG: Taking gradient step
2023-01-03 20:53:27.949 DEBUG: Loss 3: {'policy_loss': -0.017340410186398827, 'entropy_loss': -0.07216215878725052, 'vf_loss': 0.017292794094303267, 'total_loss': -0.07220977487934607, 'approx_kl': 0.005936376372119412, 'clip_fraction': 0.3098958358168602, 'grad_norm': 10.586098670959473}
2023-01-03 20:53:28.937 DEBUG: Taking gradient step
2023-01-03 20:53:28.947 DEBUG: Loss 4: {'policy_loss': -0.06630445943045898, 'entropy_loss': -0.07378002069890499, 'vf_loss': 0.014893225155092322, 'total_loss': -0.12519125497427164, 'approx_kl': 0.01759268995374441, 'clip_fraction': 0.4583333358168602, 'grad_norm': 7.922933101654053}
2023-01-03 20:53:30.025 DEBUG: Taking gradient step
2023-01-03 20:53:30.035 DEBUG: Loss 5: {'policy_loss': 0.0012743986398287364, 'entropy_loss': -0.07421122305095196, 'vf_loss': 0.017158956157220056, 'total_loss': -0.05577786825390317, 'approx_kl': 0.04134211177006364, 'clip_fraction': 0.4830729216337204, 'grad_norm': 9.229679107666016}
2023-01-03 20:53:31.125 DEBUG: Early stopping at step 6 for reaching max KL.
2023-01-03 20:53:31.126 INFO: Optimization: policy loss=0.001, vf loss=0.017, entropy loss=-0.074, total loss=-0.056, num steps=6
2023-01-03 20:53:31.126 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 20:53:32.845 INFO: Evaluation rollout: return=0.590 (0.0), episode length=6.0
2023-01-03 20:53:32.846 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 20:53:32.849 DEBUG: Deleting old model: runs/CH3NO_baseline/models/CH3NO_baseline_run-1_steps-4536.model
2023-01-03 20:53:32.851 DEBUG: Saving model: runs/CH3NO_baseline/models/CH3NO_baseline_run-1_steps-6696.model
2023-01-03 20:53:32.881 INFO: Iteration: 31/137, steps: 6696
2023-01-03 20:54:08.654 DEBUG: Atoms are too close
2023-01-03 20:54:10.691 DEBUG: Atoms are too close
2023-01-03 20:54:10.693 DEBUG: Atoms are too close
2023-01-03 20:54:29.959 DEBUG: Atoms are too close
2023-01-03 20:54:30.017 INFO: Training rollout: return=-0.989 (4.2), episode length=6.0
2023-01-03 20:54:30.018 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 20:54:30.021 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-6696_train.pkl
2023-01-03 20:54:31.066 DEBUG: Taking gradient step
2023-01-03 20:54:31.077 DEBUG: Loss 0: {'policy_loss': -0.009894103372427535, 'entropy_loss': -0.07396523281931877, 'vf_loss': 0.013261158694432163, 'total_loss': -0.07059817749731415, 'approx_kl': 2.4602435644283105e-08, 'clip_fraction': 0.0, 'grad_norm': 10.572504043579102}
2023-01-03 20:54:32.093 DEBUG: Taking gradient step
2023-01-03 20:54:32.102 DEBUG: Loss 1: {'policy_loss': -0.017243847844676946, 'entropy_loss': -0.07398861832916737, 'vf_loss': 0.013729327705711794, 'total_loss': -0.0775031384681325, 'approx_kl': -0.00014423264656215906, 'clip_fraction': 0.0234375, 'grad_norm': 14.888028144836426}
2023-01-03 20:54:33.134 DEBUG: Taking gradient step
2023-01-03 20:54:33.145 DEBUG: Loss 2: {'policy_loss': -0.04474743161782862, 'entropy_loss': -0.0741391908377409, 'vf_loss': 0.012737047967576203, 'total_loss': -0.10614957448799331, 'approx_kl': 0.003893935587257147, 'clip_fraction': 0.171875, 'grad_norm': 7.279821395874023}
2023-01-03 20:54:34.163 DEBUG: Taking gradient step
2023-01-03 20:54:34.172 DEBUG: Loss 3: {'policy_loss': 0.004234544352622646, 'entropy_loss': -0.07441553100943565, 'vf_loss': 0.015473385848338541, 'total_loss': -0.054707600808474456, 'approx_kl': 0.03241572389379144, 'clip_fraction': 0.265625, 'grad_norm': 5.741800308227539}
2023-01-03 20:54:35.182 DEBUG: Early stopping at step 4 for reaching max KL.
2023-01-03 20:54:35.182 INFO: Optimization: policy loss=0.004, vf loss=0.015, entropy loss=-0.074, total loss=-0.055, num steps=4
2023-01-03 20:54:35.183 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 20:54:36.859 INFO: Evaluation rollout: return=0.555 (0.0), episode length=6.0
2023-01-03 20:54:36.860 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 20:54:36.863 INFO: Iteration: 32/137, steps: 6912
2023-01-03 20:54:53.222 DEBUG: There is a single atom floating around
2023-01-03 20:54:54.381 DEBUG: Atoms are too close
2023-01-03 20:55:09.571 DEBUG: Atoms are too close
2023-01-03 20:55:11.352 DEBUG: Atoms are too close
2023-01-03 20:55:28.967 DEBUG: Atoms are too close
2023-01-03 20:55:32.248 DEBUG: Atoms are too close
2023-01-03 20:55:33.210 INFO: Training rollout: return=-1.860 (5.3), episode length=5.9
2023-01-03 20:55:33.211 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 20:55:33.214 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-6912_train.pkl
2023-01-03 20:55:34.271 DEBUG: Taking gradient step
2023-01-03 20:55:34.283 DEBUG: Loss 0: {'policy_loss': -0.017726929646956137, 'entropy_loss': -0.07648435235023499, 'vf_loss': 0.019568141675499633, 'total_loss': -0.07464314032169149, 'approx_kl': 1.497877144540638e-08, 'clip_fraction': 0.0, 'grad_norm': 12.783442497253418}
2023-01-03 20:55:35.271 DEBUG: Taking gradient step
2023-01-03 20:55:35.280 DEBUG: Loss 1: {'policy_loss': 0.06719932029785945, 'entropy_loss': -0.0753520131111145, 'vf_loss': 0.02308206786232183, 'total_loss': 0.014929375049066773, 'approx_kl': 0.0010182869154959917, 'clip_fraction': 0.13151041697710752, 'grad_norm': 10.435367584228516}
2023-01-03 20:55:36.316 DEBUG: Taking gradient step
2023-01-03 20:55:36.327 DEBUG: Loss 2: {'policy_loss': 0.01155110322128311, 'entropy_loss': -0.0745516661554575, 'vf_loss': 0.020321872256381816, 'total_loss': -0.04267869067779256, 'approx_kl': 0.020813144743442535, 'clip_fraction': 0.2669270858168602, 'grad_norm': 9.003073692321777}
2023-01-03 20:55:37.348 DEBUG: Taking gradient step
2023-01-03 20:55:37.357 DEBUG: Loss 3: {'policy_loss': 0.026985769153261487, 'entropy_loss': -0.07552816346287727, 'vf_loss': 0.023005385620949937, 'total_loss': -0.025537008688665847, 'approx_kl': 0.022128582000732422, 'clip_fraction': 0.40234375, 'grad_norm': 8.99794864654541}
2023-01-03 20:55:38.395 DEBUG: Taking gradient step
2023-01-03 20:55:38.406 DEBUG: Loss 4: {'policy_loss': 0.0036474379822392378, 'entropy_loss': -0.0751296617090702, 'vf_loss': 0.020632368903721627, 'total_loss': -0.050849854823109344, 'approx_kl': 0.009319113567471504, 'clip_fraction': 0.4596354216337204, 'grad_norm': 17.78854751586914}
2023-01-03 20:55:39.444 DEBUG: Early stopping at step 5 for reaching max KL.
2023-01-03 20:55:39.445 INFO: Optimization: policy loss=0.004, vf loss=0.021, entropy loss=-0.075, total loss=-0.051, num steps=5
2023-01-03 20:55:39.445 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 20:55:41.186 INFO: Evaluation rollout: return=0.548 (0.0), episode length=6.0
2023-01-03 20:55:41.187 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 20:55:41.190 INFO: Iteration: 33/137, steps: 7128
2023-01-03 20:55:58.903 DEBUG: Atoms are too close
2023-01-03 20:56:16.914 DEBUG: There is a single atom floating around
2023-01-03 20:56:18.047 DEBUG: There is a single atom floating around
2023-01-03 20:56:18.050 DEBUG: There is a single atom floating around
2023-01-03 20:56:33.751 DEBUG: Atoms are too close
2023-01-03 20:56:34.691 DEBUG: There is a single atom floating around
2023-01-03 20:56:37.829 INFO: Training rollout: return=-1.759 (5.1), episode length=6.0
2023-01-03 20:56:37.830 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 20:56:37.833 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-7128_train.pkl
2023-01-03 20:56:38.873 DEBUG: Taking gradient step
2023-01-03 20:56:38.882 DEBUG: Loss 0: {'policy_loss': -0.007789715510598841, 'entropy_loss': -0.07537768222391605, 'vf_loss': 0.019501701345471717, 'total_loss': -0.06366569638904318, 'approx_kl': -7.293419912457466e-08, 'clip_fraction': 0.0, 'grad_norm': 12.916561126708984}
2023-01-03 20:56:39.901 DEBUG: Taking gradient step
2023-01-03 20:56:39.910 DEBUG: Loss 1: {'policy_loss': -0.05591380178818932, 'entropy_loss': -0.0746152475476265, 'vf_loss': 0.017169857127642307, 'total_loss': -0.1133591922081735, 'approx_kl': -0.0006098473677411675, 'clip_fraction': 0.015625, 'grad_norm': 11.05848503112793}
2023-01-03 20:56:40.924 DEBUG: Taking gradient step
2023-01-03 20:56:40.934 DEBUG: Loss 2: {'policy_loss': -0.024832206621363182, 'entropy_loss': -0.0745401568710804, 'vf_loss': 0.01905870102469682, 'total_loss': -0.08031366246774677, 'approx_kl': 0.0014262875774875283, 'clip_fraction': 0.1484375, 'grad_norm': 13.838213920593262}
2023-01-03 20:56:41.971 DEBUG: Taking gradient step
2023-01-03 20:56:41.981 DEBUG: Loss 3: {'policy_loss': -0.0378216891755798, 'entropy_loss': -0.0744928177446127, 'vf_loss': 0.019165736974081436, 'total_loss': -0.09314876994611106, 'approx_kl': 0.0017198945861309767, 'clip_fraction': 0.2903645858168602, 'grad_norm': 6.362614631652832}
2023-01-03 20:56:42.984 DEBUG: Taking gradient step
2023-01-03 20:56:42.993 DEBUG: Loss 4: {'policy_loss': -0.0005842849087488167, 'entropy_loss': -0.07386719435453415, 'vf_loss': 0.02092028132239345, 'total_loss': -0.05353119794088951, 'approx_kl': 0.03654293529689312, 'clip_fraction': 0.4088541716337204, 'grad_norm': 13.48950481414795}
2023-01-03 20:56:44.038 DEBUG: Taking gradient step
2023-01-03 20:56:44.047 DEBUG: Loss 5: {'policy_loss': -0.08343859717869836, 'entropy_loss': -0.07257362641394138, 'vf_loss': 0.016947022177494362, 'total_loss': -0.1390652014151454, 'approx_kl': 0.014487006235867739, 'clip_fraction': 0.3984375, 'grad_norm': 8.24258804321289}
2023-01-03 20:56:45.088 DEBUG: Taking gradient step
2023-01-03 20:56:45.097 DEBUG: Loss 6: {'policy_loss': -0.07575547411713547, 'entropy_loss': -0.07336047105491161, 'vf_loss': 0.018261117686621982, 'total_loss': -0.13085482748542512, 'approx_kl': 0.03636903315782547, 'clip_fraction': 0.4075520858168602, 'grad_norm': 7.32496976852417}
2023-01-03 20:56:46.133 DEBUG: Early stopping at step 7 for reaching max KL.
2023-01-03 20:56:46.134 INFO: Optimization: policy loss=-0.076, vf loss=0.018, entropy loss=-0.073, total loss=-0.131, num steps=7
2023-01-03 20:56:46.134 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 20:56:47.840 INFO: Evaluation rollout: return=0.381 (0.0), episode length=6.0
2023-01-03 20:56:47.841 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 20:56:47.844 INFO: Iteration: 34/137, steps: 7344
2023-01-03 20:57:18.434 DEBUG: Atoms are too close
2023-01-03 20:57:23.975 DEBUG: Atoms are too close
2023-01-03 20:57:40.753 DEBUG: Atoms are too close
2023-01-03 20:57:43.109 DEBUG: Atoms are too close
2023-01-03 20:57:44.748 INFO: Training rollout: return=-1.234 (4.8), episode length=5.9
2023-01-03 20:57:44.750 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 20:57:44.752 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-7344_train.pkl
2023-01-03 20:57:45.820 DEBUG: Taking gradient step
2023-01-03 20:57:45.831 DEBUG: Loss 0: {'policy_loss': -0.03478357074917395, 'entropy_loss': -0.07393867522478104, 'vf_loss': 0.013140095654698038, 'total_loss': -0.09558215031925694, 'approx_kl': 1.299971330581684e-08, 'clip_fraction': 0.0, 'grad_norm': 15.029014587402344}
2023-01-03 20:57:46.876 DEBUG: Taking gradient step
2023-01-03 20:57:46.885 DEBUG: Loss 1: {'policy_loss': -0.056470602667132136, 'entropy_loss': -0.0747234970331192, 'vf_loss': 0.012362314337175962, 'total_loss': -0.11883178536307537, 'approx_kl': 0.004917760146781802, 'clip_fraction': 0.045572916977107525, 'grad_norm': 4.446371555328369}
2023-01-03 20:57:47.886 DEBUG: Taking gradient step
2023-01-03 20:57:47.894 DEBUG: Loss 2: {'policy_loss': -0.0037355390478864513, 'entropy_loss': -0.07446820847690105, 'vf_loss': 0.014515023912716196, 'total_loss': -0.06368872361207131, 'approx_kl': 0.014273582259193063, 'clip_fraction': 0.12239583395421505, 'grad_norm': 4.812483787536621}
2023-01-03 20:57:48.902 DEBUG: Taking gradient step
2023-01-03 20:57:48.913 DEBUG: Loss 3: {'policy_loss': -0.02124783301533011, 'entropy_loss': -0.07518050074577332, 'vf_loss': 0.013784897758958484, 'total_loss': -0.08264343600214494, 'approx_kl': 0.01565102767199278, 'clip_fraction': 0.24739583395421505, 'grad_norm': 10.87073040008545}
2023-01-03 20:57:49.941 DEBUG: Taking gradient step
2023-01-03 20:57:49.951 DEBUG: Loss 4: {'policy_loss': 0.028073927842049914, 'entropy_loss': -0.07548170536756516, 'vf_loss': 0.016879466702162373, 'total_loss': -0.030528310823352875, 'approx_kl': 0.04051169939339161, 'clip_fraction': 0.2890625, 'grad_norm': 5.099246978759766}
2023-01-03 20:57:50.980 DEBUG: Early stopping at step 5 for reaching max KL.
2023-01-03 20:57:50.980 INFO: Optimization: policy loss=0.028, vf loss=0.017, entropy loss=-0.075, total loss=-0.031, num steps=5
2023-01-03 20:57:50.981 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 20:57:52.661 INFO: Evaluation rollout: return=0.383 (0.0), episode length=6.0
2023-01-03 20:57:52.662 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 20:57:52.664 INFO: Iteration: 35/137, steps: 7560
2023-01-03 20:58:25.961 DEBUG: Atoms are too close
2023-01-03 20:58:42.705 DEBUG: Atoms are too close
2023-01-03 20:58:44.210 DEBUG: Atoms are too close
2023-01-03 20:58:49.743 INFO: Training rollout: return=-0.926 (4.6), episode length=5.9
2023-01-03 20:58:49.744 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 20:58:49.747 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-7560_train.pkl
2023-01-03 20:58:50.765 DEBUG: Taking gradient step
2023-01-03 20:58:50.776 DEBUG: Loss 0: {'policy_loss': -0.03687256894063166, 'entropy_loss': -0.07618425041437149, 'vf_loss': 0.009182424875092713, 'total_loss': -0.10387439447991043, 'approx_kl': -1.1253483478412818e-08, 'clip_fraction': 0.0, 'grad_norm': 15.659368515014648}
2023-01-03 20:58:51.802 DEBUG: Taking gradient step
2023-01-03 20:58:51.812 DEBUG: Loss 1: {'policy_loss': -0.0456181379163359, 'entropy_loss': -0.07688427343964577, 'vf_loss': 0.009114682014243647, 'total_loss': -0.11338772934173802, 'approx_kl': 0.010570278856903315, 'clip_fraction': 0.08984375, 'grad_norm': 8.216021537780762}
2023-01-03 20:58:52.840 DEBUG: Taking gradient step
2023-01-03 20:58:52.850 DEBUG: Loss 2: {'policy_loss': -0.01255687412526239, 'entropy_loss': -0.07672302424907684, 'vf_loss': 0.010453633211521028, 'total_loss': -0.07882626516281821, 'approx_kl': 0.04155556112527847, 'clip_fraction': 0.22265625, 'grad_norm': 6.130745887756348}
2023-01-03 20:58:53.880 DEBUG: Early stopping at step 3 for reaching max KL.
2023-01-03 20:58:53.881 INFO: Optimization: policy loss=-0.013, vf loss=0.010, entropy loss=-0.077, total loss=-0.079, num steps=3
2023-01-03 20:58:53.881 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 20:58:55.577 INFO: Evaluation rollout: return=0.336 (0.0), episode length=6.0
2023-01-03 20:58:55.578 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 20:58:55.581 INFO: Iteration: 36/137, steps: 7776
2023-01-03 20:59:13.218 DEBUG: Atoms are too close
2023-01-03 20:59:23.803 DEBUG: Atoms are too close
2023-01-03 20:59:32.268 DEBUG: There is a single atom floating around
2023-01-03 20:59:32.857 DEBUG: Atoms are too close
2023-01-03 20:59:42.155 DEBUG: Atoms are too close
2023-01-03 20:59:46.848 DEBUG: Atoms are too close
2023-01-03 20:59:50.708 DEBUG: Atoms are too close
2023-01-03 20:59:51.359 INFO: Training rollout: return=-2.459 (6.1), episode length=5.9
2023-01-03 20:59:51.360 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 20:59:51.363 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-7776_train.pkl
2023-01-03 20:59:52.366 DEBUG: Taking gradient step
2023-01-03 20:59:52.377 DEBUG: Loss 0: {'policy_loss': 0.005725222852913787, 'entropy_loss': -0.07573381997644901, 'vf_loss': 0.02295404571554855, 'total_loss': -0.04705455140798667, 'approx_kl': 2.8909804883348045e-08, 'clip_fraction': 0.0, 'grad_norm': 19.81340789794922}
2023-01-03 20:59:53.410 DEBUG: Taking gradient step
2023-01-03 20:59:53.420 DEBUG: Loss 1: {'policy_loss': 0.004758039221288833, 'entropy_loss': -0.07684861123561859, 'vf_loss': 0.02304531632762201, 'total_loss': -0.04904525568670775, 'approx_kl': 0.023838639492169023, 'clip_fraction': 0.1119791679084301, 'grad_norm': 10.36207389831543}
2023-01-03 20:59:54.434 DEBUG: Early stopping at step 2 for reaching max KL.
2023-01-03 20:59:54.435 INFO: Optimization: policy loss=0.005, vf loss=0.023, entropy loss=-0.077, total loss=-0.049, num steps=2
2023-01-03 20:59:54.435 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 20:59:56.114 INFO: Evaluation rollout: return=0.511 (0.0), episode length=6.0
2023-01-03 20:59:56.115 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 20:59:56.117 INFO: Iteration: 37/137, steps: 7992
2023-01-03 21:00:07.769 DEBUG: There is a single atom floating around
2023-01-03 21:00:32.318 DEBUG: Atoms are too close
2023-01-03 21:00:33.177 DEBUG: There is a single atom floating around
2023-01-03 21:00:48.172 DEBUG: Atoms are too close
2023-01-03 21:00:53.800 INFO: Training rollout: return=-1.206 (4.8), episode length=5.9
2023-01-03 21:00:53.801 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:00:53.804 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-7992_train.pkl
2023-01-03 21:00:54.884 DEBUG: Taking gradient step
2023-01-03 21:00:54.895 DEBUG: Loss 0: {'policy_loss': 0.06721587033466825, 'entropy_loss': -0.07598733715713024, 'vf_loss': 0.017032816938948425, 'total_loss': 0.008261350116486418, 'approx_kl': 4.384977092541931e-08, 'clip_fraction': 0.0, 'grad_norm': 19.230239868164062}
2023-01-03 21:00:55.914 DEBUG: Taking gradient step
2023-01-03 21:00:55.924 DEBUG: Loss 1: {'policy_loss': -0.007061549790727749, 'entropy_loss': -0.07490876130759716, 'vf_loss': 0.014139395162469351, 'total_loss': -0.06783091593585557, 'approx_kl': 0.016338261077180505, 'clip_fraction': 0.19140625, 'grad_norm': 12.027719497680664}
2023-01-03 21:00:56.965 DEBUG: Early stopping at step 2 for reaching max KL.
2023-01-03 21:00:56.966 INFO: Optimization: policy loss=-0.007, vf loss=0.014, entropy loss=-0.075, total loss=-0.068, num steps=2
2023-01-03 21:00:56.966 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:00:58.696 INFO: Evaluation rollout: return=0.494 (0.0), episode length=6.0
2023-01-03 21:00:58.699 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:00:58.703 INFO: Iteration: 38/137, steps: 8208
2023-01-03 21:01:17.078 DEBUG: Atoms are too close
2023-01-03 21:01:17.080 DEBUG: Atoms are too close
2023-01-03 21:01:31.800 DEBUG: Atoms are too close
2023-01-03 21:01:55.930 INFO: Training rollout: return=-0.672 (3.9), episode length=6.0
2023-01-03 21:01:55.931 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:01:55.934 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-8208_train.pkl
2023-01-03 21:01:56.992 DEBUG: Taking gradient step
2023-01-03 21:01:57.001 DEBUG: Loss 0: {'policy_loss': 0.06295720385335243, 'entropy_loss': -0.07595336250960827, 'vf_loss': 0.012797755796410147, 'total_loss': -0.00019840285984568107, 'approx_kl': 3.0656035931997394e-08, 'clip_fraction': 0.0, 'grad_norm': 34.351036071777344}
2023-01-03 21:01:58.048 DEBUG: Taking gradient step
2023-01-03 21:01:58.058 DEBUG: Loss 1: {'policy_loss': -0.04026738351785264, 'entropy_loss': -0.07492604106664658, 'vf_loss': 0.009638126765785456, 'total_loss': -0.10555529781871376, 'approx_kl': 0.012831529136747122, 'clip_fraction': 0.1484375, 'grad_norm': 12.370710372924805}
2023-01-03 21:01:59.048 DEBUG: Taking gradient step
2023-01-03 21:01:59.057 DEBUG: Loss 2: {'policy_loss': -0.016376893998626983, 'entropy_loss': -0.07570340298116207, 'vf_loss': 0.009818206581397176, 'total_loss': -0.08226209039839187, 'approx_kl': 0.01718885451555252, 'clip_fraction': 0.34765625, 'grad_norm': 18.445222854614258}
2023-01-03 21:02:00.098 DEBUG: Taking gradient step
2023-01-03 21:02:00.108 DEBUG: Loss 3: {'policy_loss': -0.01001966793074528, 'entropy_loss': -0.07527091540396214, 'vf_loss': 0.010663532215838191, 'total_loss': -0.07462705111886922, 'approx_kl': 0.04003320983611047, 'clip_fraction': 0.4075520858168602, 'grad_norm': 9.980435371398926}
2023-01-03 21:02:01.154 DEBUG: Early stopping at step 4 for reaching max KL.
2023-01-03 21:02:01.155 INFO: Optimization: policy loss=-0.010, vf loss=0.011, entropy loss=-0.075, total loss=-0.075, num steps=4
2023-01-03 21:02:01.155 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:02:02.920 INFO: Evaluation rollout: return=0.515 (0.0), episode length=6.0
2023-01-03 21:02:02.921 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:02:02.923 INFO: Iteration: 39/137, steps: 8424
2023-01-03 21:02:16.942 DEBUG: There is a single atom floating around
2023-01-03 21:02:19.987 DEBUG: Atoms are too close
2023-01-03 21:02:36.684 DEBUG: Atoms are too close
2023-01-03 21:03:00.582 INFO: Training rollout: return=-0.755 (4.1), episode length=5.9
2023-01-03 21:03:00.583 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:03:00.585 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-8424_train.pkl
2023-01-03 21:03:01.592 DEBUG: Taking gradient step
2023-01-03 21:03:01.602 DEBUG: Loss 0: {'policy_loss': -0.005659531352919078, 'entropy_loss': -0.0770857147872448, 'vf_loss': 0.010148007323093209, 'total_loss': -0.07259723881707067, 'approx_kl': -2.3050233721733093e-08, 'clip_fraction': 0.0, 'grad_norm': 12.989935874938965}
2023-01-03 21:03:02.556 DEBUG: Taking gradient step
2023-01-03 21:03:02.565 DEBUG: Loss 1: {'policy_loss': -0.0335634645678917, 'entropy_loss': -0.07667426764965057, 'vf_loss': 0.009806950934198005, 'total_loss': -0.10043078128334426, 'approx_kl': 0.0018234644085168839, 'clip_fraction': 0.08984375, 'grad_norm': 5.6904802322387695}
2023-01-03 21:03:03.588 DEBUG: Taking gradient step
2023-01-03 21:03:03.598 DEBUG: Loss 2: {'policy_loss': -0.03500849776270059, 'entropy_loss': -0.07612207159399986, 'vf_loss': 0.010686156933389599, 'total_loss': -0.10044441242331086, 'approx_kl': 0.014777429634705186, 'clip_fraction': 0.2161458358168602, 'grad_norm': 5.445113182067871}
2023-01-03 21:03:04.628 DEBUG: Taking gradient step
2023-01-03 21:03:04.638 DEBUG: Loss 3: {'policy_loss': 0.012668155840541429, 'entropy_loss': -0.07697020657360554, 'vf_loss': 0.011719395095654513, 'total_loss': -0.0525826556374096, 'approx_kl': 0.029528699349611998, 'clip_fraction': 0.3255208358168602, 'grad_norm': 6.8084893226623535}
2023-01-03 21:03:05.666 DEBUG: Taking gradient step
2023-01-03 21:03:05.677 DEBUG: Loss 4: {'policy_loss': -0.041733516217718564, 'entropy_loss': -0.07625978998839855, 'vf_loss': 0.009683280808445617, 'total_loss': -0.10831002539767148, 'approx_kl': 0.04289480298757553, 'clip_fraction': 0.4049479216337204, 'grad_norm': 5.266986846923828}
2023-01-03 21:03:06.674 DEBUG: Early stopping at step 5 for reaching max KL.
2023-01-03 21:03:06.675 INFO: Optimization: policy loss=-0.042, vf loss=0.010, entropy loss=-0.076, total loss=-0.108, num steps=5
2023-01-03 21:03:06.675 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:03:08.428 INFO: Evaluation rollout: return=0.597 (0.0), episode length=6.0
2023-01-03 21:03:08.429 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:03:08.432 INFO: Iteration: 40/137, steps: 8640
2023-01-03 21:03:46.033 DEBUG: Atoms are too close
2023-01-03 21:04:06.969 INFO: Training rollout: return=0.159 (2.2), episode length=6.0
2023-01-03 21:04:06.971 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:04:06.973 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-8640_train.pkl
2023-01-03 21:04:08.024 DEBUG: Taking gradient step
2023-01-03 21:04:08.035 DEBUG: Loss 0: {'policy_loss': -0.027193511520445857, 'entropy_loss': -0.075629698112607, 'vf_loss': 0.003965913429755047, 'total_loss': -0.0988572962032978, 'approx_kl': 1.3271346688270569e-08, 'clip_fraction': 0.0, 'grad_norm': 15.715398788452148}
2023-01-03 21:04:09.104 DEBUG: Taking gradient step
2023-01-03 21:04:09.113 DEBUG: Loss 1: {'policy_loss': -0.038841581598764316, 'entropy_loss': -0.07511927373707294, 'vf_loss': 0.0038979589971047802, 'total_loss': -0.11006289633873248, 'approx_kl': 0.02365175378508866, 'clip_fraction': 0.06510416697710752, 'grad_norm': 10.173126220703125}
2023-01-03 21:04:10.111 DEBUG: Taking gradient step
2023-01-03 21:04:10.120 DEBUG: Loss 2: {'policy_loss': -0.03528125186214314, 'entropy_loss': -0.07506592012941837, 'vf_loss': 0.003806325862335136, 'total_loss': -0.10654084612922637, 'approx_kl': 0.03827695641666651, 'clip_fraction': 0.2526041679084301, 'grad_norm': 4.109217166900635}
2023-01-03 21:04:11.158 DEBUG: Early stopping at step 3 for reaching max KL.
2023-01-03 21:04:11.159 INFO: Optimization: policy loss=-0.035, vf loss=0.004, entropy loss=-0.075, total loss=-0.107, num steps=3
2023-01-03 21:04:11.159 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:04:12.889 INFO: Evaluation rollout: return=0.604 (0.0), episode length=6.0
2023-01-03 21:04:12.890 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:04:12.893 DEBUG: Deleting old model: runs/CH3NO_baseline/models/CH3NO_baseline_run-1_steps-6696.model
2023-01-03 21:04:12.897 DEBUG: Saving model: runs/CH3NO_baseline/models/CH3NO_baseline_run-1_steps-8856.model
2023-01-03 21:04:12.927 INFO: Iteration: 41/137, steps: 8856
2023-01-03 21:04:26.078 DEBUG: There is a single atom floating around
2023-01-03 21:05:00.063 DEBUG: There is a single atom floating around
2023-01-03 21:05:07.462 DEBUG: Atoms are too close
2023-01-03 21:05:08.795 DEBUG: Atoms are too close
2023-01-03 21:05:10.050 INFO: Training rollout: return=-1.300 (5.2), episode length=5.9
2023-01-03 21:05:10.051 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:05:10.054 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-8856_train.pkl
2023-01-03 21:05:11.097 DEBUG: Taking gradient step
2023-01-03 21:05:11.107 DEBUG: Loss 0: {'policy_loss': 0.03381485346069672, 'entropy_loss': -0.0780175682157278, 'vf_loss': 0.014209209951531077, 'total_loss': -0.029993504803500014, 'approx_kl': 8.638016879558563e-08, 'clip_fraction': 0.0, 'grad_norm': 20.40668296813965}
2023-01-03 21:05:12.113 DEBUG: Taking gradient step
2023-01-03 21:05:12.122 DEBUG: Loss 1: {'policy_loss': 0.01733998354956423, 'entropy_loss': -0.0769776925444603, 'vf_loss': 0.014153630409706401, 'total_loss': -0.04548407858518966, 'approx_kl': 0.005982090428005904, 'clip_fraction': 0.053385416977107525, 'grad_norm': 10.301581382751465}
2023-01-03 21:05:13.133 DEBUG: Taking gradient step
2023-01-03 21:05:13.144 DEBUG: Loss 2: {'policy_loss': -0.02163116826466166, 'entropy_loss': -0.07640290260314941, 'vf_loss': 0.012651416746361333, 'total_loss': -0.08538265412144974, 'approx_kl': 0.009044948063092306, 'clip_fraction': 0.11458333395421505, 'grad_norm': 7.232570648193359}
2023-01-03 21:05:14.176 DEBUG: Taking gradient step
2023-01-03 21:05:14.186 DEBUG: Loss 3: {'policy_loss': -0.025921572666355027, 'entropy_loss': -0.07644949667155743, 'vf_loss': 0.012679359542387776, 'total_loss': -0.08969170979552468, 'approx_kl': 0.016502814134582877, 'clip_fraction': 0.23828125, 'grad_norm': 6.461258888244629}
2023-01-03 21:05:15.219 DEBUG: Taking gradient step
2023-01-03 21:05:15.228 DEBUG: Loss 4: {'policy_loss': -0.042101459251448745, 'entropy_loss': -0.07745901495218277, 'vf_loss': 0.012304453102566266, 'total_loss': -0.10725602110106525, 'approx_kl': 0.006049025803804398, 'clip_fraction': 0.3372395858168602, 'grad_norm': 6.355876922607422}
2023-01-03 21:05:16.260 DEBUG: Taking gradient step
2023-01-03 21:05:16.271 DEBUG: Loss 5: {'policy_loss': -0.051478563664441146, 'entropy_loss': -0.07715283147990704, 'vf_loss': 0.011959679769473536, 'total_loss': -0.11667171537487464, 'approx_kl': 0.012885292060673237, 'clip_fraction': 0.37109375, 'grad_norm': 5.486053466796875}
2023-01-03 21:05:17.329 DEBUG: Taking gradient step
2023-01-03 21:05:17.340 DEBUG: Loss 6: {'policy_loss': -0.029596023158756844, 'entropy_loss': -0.07733677141368389, 'vf_loss': 0.01307845562210735, 'total_loss': -0.09385433895033339, 'approx_kl': 0.028452327474951744, 'clip_fraction': 0.3697916716337204, 'grad_norm': 5.294858455657959}
2023-01-03 21:05:18.379 DEBUG: Taking gradient step
2023-01-03 21:05:18.388 DEBUG: Loss 7: {'policy_loss': -0.012660343951447328, 'entropy_loss': -0.07849235273897648, 'vf_loss': 0.014758511593552914, 'total_loss': -0.0763941850968709, 'approx_kl': 0.04474615212529898, 'clip_fraction': 0.3932291716337204, 'grad_norm': 6.296127796173096}
2023-01-03 21:05:19.367 DEBUG: Taking gradient step
2023-01-03 21:05:19.376 DEBUG: Loss 8: {'policy_loss': -0.012104287322885418, 'entropy_loss': -0.07846619188785553, 'vf_loss': 0.014180317492469036, 'total_loss': -0.07639016171827191, 'approx_kl': 0.043350338470190763, 'clip_fraction': 0.40234375, 'grad_norm': 7.616273403167725}
2023-01-03 21:05:20.405 DEBUG: Taking gradient step
2023-01-03 21:05:20.416 DEBUG: Loss 9: {'policy_loss': -0.023088788196757606, 'entropy_loss': -0.07742969319224358, 'vf_loss': 0.013904703075734761, 'total_loss': -0.08661377831326643, 'approx_kl': 0.03204679396003485, 'clip_fraction': 0.43359375, 'grad_norm': 4.109854698181152}
2023-01-03 21:05:21.454 DEBUG: Taking gradient step
2023-01-03 21:05:21.463 DEBUG: Loss 10: {'policy_loss': -0.06996774537692521, 'entropy_loss': -0.07786424458026886, 'vf_loss': 0.01160562304618152, 'total_loss': -0.13622636691101253, 'approx_kl': 0.027430912014096975, 'clip_fraction': 0.44921875, 'grad_norm': 5.721116065979004}
2023-01-03 21:05:22.492 DEBUG: Taking gradient step
2023-01-03 21:05:22.503 DEBUG: Loss 11: {'policy_loss': -0.07964058599294534, 'entropy_loss': -0.07769874110817909, 'vf_loss': 0.011067809206751565, 'total_loss': -0.14627151789437287, 'approx_kl': 0.015008908929303288, 'clip_fraction': 0.42578125, 'grad_norm': 5.180646896362305}
2023-01-03 21:05:23.532 DEBUG: Taking gradient step
2023-01-03 21:05:23.542 DEBUG: Loss 12: {'policy_loss': -0.025053742878768978, 'entropy_loss': -0.07921601086854935, 'vf_loss': 0.013807825715163941, 'total_loss': -0.09046192803215437, 'approx_kl': 0.018112528370693326, 'clip_fraction': 0.41796875, 'grad_norm': 5.210230827331543}
2023-01-03 21:05:24.539 DEBUG: Early stopping at step 13 for reaching max KL.
2023-01-03 21:05:24.539 INFO: Optimization: policy loss=-0.025, vf loss=0.014, entropy loss=-0.079, total loss=-0.090, num steps=13
2023-01-03 21:05:24.540 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:05:26.262 INFO: Evaluation rollout: return=0.460 (0.0), episode length=6.0
2023-01-03 21:05:26.264 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:05:26.267 INFO: Iteration: 42/137, steps: 9072
2023-01-03 21:05:40.638 DEBUG: Atoms are too close
2023-01-03 21:05:43.377 DEBUG: Atoms are too close
2023-01-03 21:06:00.070 DEBUG: Atoms are too close
2023-01-03 21:06:17.999 DEBUG: Atoms are too close
2023-01-03 21:06:20.707 DEBUG: Atoms are too close
2023-01-03 21:06:22.963 INFO: Training rollout: return=-1.505 (5.1), episode length=5.9
2023-01-03 21:06:22.964 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:06:22.967 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-9072_train.pkl
2023-01-03 21:06:24.008 DEBUG: Taking gradient step
2023-01-03 21:06:24.017 DEBUG: Loss 0: {'policy_loss': 0.002424672811348882, 'entropy_loss': -0.07618135772645473, 'vf_loss': 0.016625051681653624, 'total_loss': -0.05713163323345223, 'approx_kl': -1.0190221644279518e-07, 'clip_fraction': 0.0, 'grad_norm': 9.126154899597168}
2023-01-03 21:06:25.050 DEBUG: Taking gradient step
2023-01-03 21:06:25.059 DEBUG: Loss 1: {'policy_loss': 0.0776150977138376, 'entropy_loss': -0.07761277630925179, 'vf_loss': 0.01998910203532634, 'total_loss': 0.019991423439912143, 'approx_kl': 0.016270802821964025, 'clip_fraction': 0.0703125, 'grad_norm': 14.310835838317871}
2023-01-03 21:06:26.094 DEBUG: Taking gradient step
2023-01-03 21:06:26.103 DEBUG: Loss 2: {'policy_loss': 0.002421756225878008, 'entropy_loss': -0.07703767344355583, 'vf_loss': 0.018673500987890862, 'total_loss': -0.05594241622978697, 'approx_kl': 0.013936090981587768, 'clip_fraction': 0.171875, 'grad_norm': 9.19490909576416}
2023-01-03 21:06:27.131 DEBUG: Taking gradient step
2023-01-03 21:06:27.142 DEBUG: Loss 3: {'policy_loss': 0.004338961863550546, 'entropy_loss': -0.07801801525056362, 'vf_loss': 0.018798279671969682, 'total_loss': -0.05488077371504339, 'approx_kl': 0.009743718197569251, 'clip_fraction': 0.2278645858168602, 'grad_norm': 8.0524263381958}
2023-01-03 21:06:28.169 DEBUG: Taking gradient step
2023-01-03 21:06:28.179 DEBUG: Loss 4: {'policy_loss': 0.021055775344029, 'entropy_loss': -0.07791304588317871, 'vf_loss': 0.019354187670266598, 'total_loss': -0.03750308286888311, 'approx_kl': -0.0014323703944683075, 'clip_fraction': 0.2447916679084301, 'grad_norm': 15.240201950073242}
2023-01-03 21:06:29.208 DEBUG: Taking gradient step
2023-01-03 21:06:29.217 DEBUG: Loss 5: {'policy_loss': -0.016345484041093046, 'entropy_loss': -0.0802177581936121, 'vf_loss': 0.018037037872519077, 'total_loss': -0.07852620436218606, 'approx_kl': 0.039131867815740407, 'clip_fraction': 0.3567708358168602, 'grad_norm': 6.3291096687316895}
2023-01-03 21:06:30.173 DEBUG: Taking gradient step
2023-01-03 21:06:30.184 DEBUG: Loss 6: {'policy_loss': -0.04503114237469752, 'entropy_loss': -0.07842166535556316, 'vf_loss': 0.016306899460424903, 'total_loss': -0.10714590826983578, 'approx_kl': 0.023032302502542734, 'clip_fraction': 0.453125, 'grad_norm': 6.077218532562256}
2023-01-03 21:06:31.212 DEBUG: Early stopping at step 7 for reaching max KL.
2023-01-03 21:06:31.212 INFO: Optimization: policy loss=-0.045, vf loss=0.016, entropy loss=-0.078, total loss=-0.107, num steps=7
2023-01-03 21:06:31.213 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:06:32.951 INFO: Evaluation rollout: return=0.594 (0.0), episode length=6.0
2023-01-03 21:06:32.953 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:06:32.956 INFO: Iteration: 43/137, steps: 9288
2023-01-03 21:07:08.666 DEBUG: Atoms are too close
2023-01-03 21:07:24.693 DEBUG: Atoms are too close
2023-01-03 21:07:30.402 INFO: Training rollout: return=-0.259 (3.3), episode length=6.0
2023-01-03 21:07:30.404 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:07:30.406 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-9288_train.pkl
2023-01-03 21:07:31.438 DEBUG: Taking gradient step
2023-01-03 21:07:31.449 DEBUG: Loss 0: {'policy_loss': 0.01109680270194693, 'entropy_loss': -0.07795654237270355, 'vf_loss': 0.0077580377804883135, 'total_loss': -0.05910170189026832, 'approx_kl': -4.827355581937809e-08, 'clip_fraction': 0.0, 'grad_norm': 13.27075481414795}
2023-01-03 21:07:32.476 DEBUG: Taking gradient step
2023-01-03 21:07:32.485 DEBUG: Loss 1: {'policy_loss': 0.0019417375742233484, 'entropy_loss': -0.07704491727054119, 'vf_loss': 0.008472151949566735, 'total_loss': -0.06663102774675111, 'approx_kl': 0.004798772744834423, 'clip_fraction': 0.09114583395421505, 'grad_norm': 4.533653259277344}
2023-01-03 21:07:33.532 DEBUG: Taking gradient step
2023-01-03 21:07:33.543 DEBUG: Loss 2: {'policy_loss': -0.03625470120645939, 'entropy_loss': -0.07707519270479679, 'vf_loss': 0.007085855846783715, 'total_loss': -0.10624403806447247, 'approx_kl': 0.019917230121791363, 'clip_fraction': 0.34765625, 'grad_norm': 4.904293060302734}
2023-01-03 21:07:34.502 DEBUG: Taking gradient step
2023-01-03 21:07:34.511 DEBUG: Loss 3: {'policy_loss': -0.03686946315582049, 'entropy_loss': -0.07714751549065113, 'vf_loss': 0.007254683272270082, 'total_loss': -0.10676229537420154, 'approx_kl': 0.026577651500701904, 'clip_fraction': 0.4205729216337204, 'grad_norm': 4.181187152862549}
2023-01-03 21:07:35.549 DEBUG: Taking gradient step
2023-01-03 21:07:35.560 DEBUG: Loss 4: {'policy_loss': -0.027729335643287625, 'entropy_loss': -0.07661295682191849, 'vf_loss': 0.0077855663630411135, 'total_loss': -0.09655672610216498, 'approx_kl': 0.031006979290395975, 'clip_fraction': 0.4166666716337204, 'grad_norm': 3.3026106357574463}
2023-01-03 21:07:36.598 DEBUG: Taking gradient step
2023-01-03 21:07:36.609 DEBUG: Loss 5: {'policy_loss': -0.030823383730013153, 'entropy_loss': -0.0772283487021923, 'vf_loss': 0.007740051606395858, 'total_loss': -0.1003116808258096, 'approx_kl': 0.009666685335105285, 'clip_fraction': 0.46875, 'grad_norm': 8.069442749023438}
2023-01-03 21:07:37.648 DEBUG: Taking gradient step
2023-01-03 21:07:37.657 DEBUG: Loss 6: {'policy_loss': 0.00034757189164468655, 'entropy_loss': -0.07796519808471203, 'vf_loss': 0.008516359832467672, 'total_loss': -0.06910126636059967, 'approx_kl': 0.029300667345523834, 'clip_fraction': 0.5221354216337204, 'grad_norm': 8.313655853271484}
2023-01-03 21:07:38.670 DEBUG: Taking gradient step
2023-01-03 21:07:38.679 DEBUG: Loss 7: {'policy_loss': -0.03854221676553114, 'entropy_loss': -0.07749586179852486, 'vf_loss': 0.007654736249913459, 'total_loss': -0.10838334231414254, 'approx_kl': 0.0026405269745737314, 'clip_fraction': 0.5247395932674408, 'grad_norm': 6.865240573883057}
2023-01-03 21:07:39.710 DEBUG: Taking gradient step
2023-01-03 21:07:39.719 DEBUG: Loss 8: {'policy_loss': -0.04788052534197193, 'entropy_loss': -0.07685188949108124, 'vf_loss': 0.006845721722313466, 'total_loss': -0.11788669311073971, 'approx_kl': -0.0032208659686148167, 'clip_fraction': 0.5143229216337204, 'grad_norm': 3.3350002765655518}
2023-01-03 21:07:40.745 DEBUG: Taking gradient step
2023-01-03 21:07:40.754 DEBUG: Loss 9: {'policy_loss': -0.06550230035954208, 'entropy_loss': -0.07752390019595623, 'vf_loss': 0.006440120357143721, 'total_loss': -0.13658608019835458, 'approx_kl': 3.4536467865109444e-05, 'clip_fraction': 0.51171875, 'grad_norm': 3.022493839263916}
2023-01-03 21:07:41.791 DEBUG: Taking gradient step
2023-01-03 21:07:41.801 DEBUG: Loss 10: {'policy_loss': -0.011890635834540635, 'entropy_loss': -0.07752906531095505, 'vf_loss': 0.008254735019729075, 'total_loss': -0.08116496612576661, 'approx_kl': 0.008190314518287778, 'clip_fraction': 0.5377604216337204, 'grad_norm': 3.6409056186676025}
2023-01-03 21:07:42.849 DEBUG: Taking gradient step
2023-01-03 21:07:42.859 DEBUG: Loss 11: {'policy_loss': -0.02882600169254633, 'entropy_loss': -0.07752957195043564, 'vf_loss': 0.00786209117243086, 'total_loss': -0.0984934824705511, 'approx_kl': -0.009240740328095853, 'clip_fraction': 0.5130208358168602, 'grad_norm': 6.2190632820129395}
2023-01-03 21:07:43.856 DEBUG: Taking gradient step
2023-01-03 21:07:43.867 DEBUG: Loss 12: {'policy_loss': -0.06181607608235507, 'entropy_loss': -0.07772955298423767, 'vf_loss': 0.006223509385102221, 'total_loss': -0.13332211968149052, 'approx_kl': -0.007327007129788399, 'clip_fraction': 0.5625, 'grad_norm': 5.247910499572754}
2023-01-03 21:07:44.907 DEBUG: Taking gradient step
2023-01-03 21:07:44.917 DEBUG: Loss 13: {'policy_loss': -0.018771457553207124, 'entropy_loss': -0.07802056707441807, 'vf_loss': 0.008189572202558068, 'total_loss': -0.08860245242506713, 'approx_kl': -0.04543078737333417, 'clip_fraction': 0.5494791716337204, 'grad_norm': 8.03376579284668}
2023-01-03 21:07:45.945 DEBUG: Taking gradient step
2023-01-03 21:07:45.955 DEBUG: Loss 14: {'policy_loss': -0.027813355751581014, 'entropy_loss': -0.07859955169260502, 'vf_loss': 0.00776854585652615, 'total_loss': -0.09864436158765989, 'approx_kl': -0.06049246992915869, 'clip_fraction': 0.578125, 'grad_norm': 2.691673517227173}
2023-01-03 21:07:45.955 INFO: Optimization: policy loss=-0.028, vf loss=0.008, entropy loss=-0.079, total loss=-0.099, num steps=15
2023-01-03 21:07:45.955 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:07:47.674 INFO: Evaluation rollout: return=0.432 (0.0), episode length=6.0
2023-01-03 21:07:47.675 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:07:47.678 INFO: Iteration: 44/137, steps: 9504
2023-01-03 21:08:46.151 INFO: Training rollout: return=0.525 (0.1), episode length=6.0
2023-01-03 21:08:46.153 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:08:46.155 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-9504_train.pkl
2023-01-03 21:08:47.199 DEBUG: Taking gradient step
2023-01-03 21:08:47.208 DEBUG: Loss 0: {'policy_loss': 0.05500925672424664, 'entropy_loss': -0.07990357093513012, 'vf_loss': 0.0004410863035104231, 'total_loss': -0.02445322790737306, 'approx_kl': 5.0446633537148955e-09, 'clip_fraction': 0.0, 'grad_norm': 16.418132781982422}
2023-01-03 21:08:48.247 DEBUG: Taking gradient step
2023-01-03 21:08:48.256 DEBUG: Loss 1: {'policy_loss': -0.04030591083507326, 'entropy_loss': -0.07975027337670326, 'vf_loss': 0.00039761315966344924, 'total_loss': -0.11965857105211307, 'approx_kl': -0.005270495545119047, 'clip_fraction': 0.09505208395421505, 'grad_norm': 10.335221290588379}
2023-01-03 21:08:49.265 DEBUG: Taking gradient step
2023-01-03 21:08:49.275 DEBUG: Loss 2: {'policy_loss': 0.03881383102825614, 'entropy_loss': -0.07998247444629669, 'vf_loss': 0.00032643487361625444, 'total_loss': -0.040842208544424295, 'approx_kl': 0.007839453173801303, 'clip_fraction': 0.2473958358168602, 'grad_norm': 7.60080623626709}
2023-01-03 21:08:50.310 DEBUG: Taking gradient step
2023-01-03 21:08:50.319 DEBUG: Loss 3: {'policy_loss': -0.024884536569986116, 'entropy_loss': -0.0800307597965002, 'vf_loss': 0.0002917517834678757, 'total_loss': -0.10462354458301844, 'approx_kl': 0.02969325613230467, 'clip_fraction': 0.3450520858168602, 'grad_norm': 9.058616638183594}
2023-01-03 21:08:51.371 DEBUG: Early stopping at step 4 for reaching max KL.
2023-01-03 21:08:51.372 INFO: Optimization: policy loss=-0.025, vf loss=0.000, entropy loss=-0.080, total loss=-0.105, num steps=4
2023-01-03 21:08:51.372 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:08:53.125 INFO: Evaluation rollout: return=0.471 (0.0), episode length=6.0
2023-01-03 21:08:53.126 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:08:53.129 INFO: Iteration: 45/137, steps: 9720
2023-01-03 21:09:50.201 DEBUG: Atoms are too close
2023-01-03 21:09:51.133 INFO: Training rollout: return=0.164 (2.2), episode length=6.0
2023-01-03 21:09:51.135 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:09:51.137 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-9720_train.pkl
2023-01-03 21:09:52.191 DEBUG: Taking gradient step
2023-01-03 21:09:52.200 DEBUG: Loss 0: {'policy_loss': 0.08479716417796915, 'entropy_loss': -0.07839654013514519, 'vf_loss': 0.006371905728679149, 'total_loss': 0.012772529771503102, 'approx_kl': 6.154490250764866e-08, 'clip_fraction': 0.0, 'grad_norm': 39.14314651489258}
2023-01-03 21:09:53.227 DEBUG: Taking gradient step
2023-01-03 21:09:53.236 DEBUG: Loss 1: {'policy_loss': -0.035348951435171264, 'entropy_loss': -0.07779504172503948, 'vf_loss': 0.0034020059697683538, 'total_loss': -0.1097419871904424, 'approx_kl': 0.003463453147560358, 'clip_fraction': 0.041666666977107525, 'grad_norm': 7.707475662231445}
2023-01-03 21:09:54.275 DEBUG: Taking gradient step
2023-01-03 21:09:54.284 DEBUG: Loss 2: {'policy_loss': -0.042371126686346273, 'entropy_loss': -0.07801841013133526, 'vf_loss': 0.0034044842212260424, 'total_loss': -0.11698505259645547, 'approx_kl': 0.014789698645472527, 'clip_fraction': 0.2486979179084301, 'grad_norm': 3.254490375518799}
2023-01-03 21:09:55.332 DEBUG: Taking gradient step
2023-01-03 21:09:55.342 DEBUG: Loss 3: {'policy_loss': -0.006026494436257222, 'entropy_loss': -0.07772456295788288, 'vf_loss': 0.004700253440155944, 'total_loss': -0.07905080395398414, 'approx_kl': 0.04100488661788404, 'clip_fraction': 0.3697916716337204, 'grad_norm': 2.5058727264404297}
2023-01-03 21:09:56.359 DEBUG: Early stopping at step 4 for reaching max KL.
2023-01-03 21:09:56.360 INFO: Optimization: policy loss=-0.006, vf loss=0.005, entropy loss=-0.078, total loss=-0.079, num steps=4
2023-01-03 21:09:56.360 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:09:58.096 INFO: Evaluation rollout: return=0.570 (0.0), episode length=6.0
2023-01-03 21:09:58.098 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:09:58.101 INFO: Iteration: 46/137, steps: 9936
2023-01-03 21:10:12.469 DEBUG: Atoms are too close
2023-01-03 21:10:14.009 DEBUG: Atoms are too close
2023-01-03 21:10:34.915 DEBUG: Atoms are too close
2023-01-03 21:10:48.110 DEBUG: Atoms are too close
2023-01-03 21:10:48.111 DEBUG: Atoms are too close
2023-01-03 21:10:54.149 INFO: Training rollout: return=-1.511 (5.1), episode length=5.9
2023-01-03 21:10:54.151 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:10:54.153 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-9936_train.pkl
2023-01-03 21:10:55.173 DEBUG: Taking gradient step
2023-01-03 21:10:55.184 DEBUG: Loss 0: {'policy_loss': -0.003566243575388103, 'entropy_loss': -0.0774996466934681, 'vf_loss': 0.01718502100314596, 'total_loss': -0.06388086926571024, 'approx_kl': 4.2064741023750685e-08, 'clip_fraction': 0.0, 'grad_norm': 13.509611129760742}
2023-01-03 21:10:56.231 DEBUG: Taking gradient step
2023-01-03 21:10:56.242 DEBUG: Loss 1: {'policy_loss': -0.016132732168937174, 'entropy_loss': -0.07687013410031796, 'vf_loss': 0.01769381016547164, 'total_loss': -0.0753090561037835, 'approx_kl': 0.022517896024510264, 'clip_fraction': 0.10546875, 'grad_norm': 7.9033403396606445}
2023-01-03 21:10:57.282 DEBUG: Early stopping at step 2 for reaching max KL.
2023-01-03 21:10:57.283 INFO: Optimization: policy loss=-0.016, vf loss=0.018, entropy loss=-0.077, total loss=-0.075, num steps=2
2023-01-03 21:10:57.284 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:10:59.018 INFO: Evaluation rollout: return=0.559 (0.0), episode length=6.0
2023-01-03 21:10:59.020 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:10:59.023 INFO: Iteration: 47/137, steps: 10152
2023-01-03 21:11:04.925 DEBUG: There is a single atom floating around
2023-01-03 21:11:08.610 DEBUG: There is a single atom floating around
2023-01-03 21:11:23.873 DEBUG: There is a single atom floating around
2023-01-03 21:11:43.393 DEBUG: There is a single atom floating around
2023-01-03 21:11:56.354 INFO: Training rollout: return=-1.324 (5.4), episode length=5.9
2023-01-03 21:11:56.355 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:11:56.358 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-10152_train.pkl
2023-01-03 21:11:57.399 DEBUG: Taking gradient step
2023-01-03 21:11:57.410 DEBUG: Loss 0: {'policy_loss': -0.023517399134082573, 'entropy_loss': -0.07765134796500206, 'vf_loss': 0.012208320929790246, 'total_loss': -0.0889604261692944, 'approx_kl': -3.213062882423401e-08, 'clip_fraction': 0.0, 'grad_norm': 15.579702377319336}
2023-01-03 21:11:58.444 DEBUG: Taking gradient step
2023-01-03 21:11:58.454 DEBUG: Loss 1: {'policy_loss': -0.021018844120392025, 'entropy_loss': -0.07703905552625656, 'vf_loss': 0.012584348452359848, 'total_loss': -0.08547355119428873, 'approx_kl': -0.00258186599239707, 'clip_fraction': 0.08333333395421505, 'grad_norm': 15.676826477050781}
2023-01-03 21:11:59.473 DEBUG: Taking gradient step
2023-01-03 21:11:59.484 DEBUG: Loss 2: {'policy_loss': -0.01654407469525738, 'entropy_loss': -0.0785611029714346, 'vf_loss': 0.012739594576073276, 'total_loss': -0.0823655830906187, 'approx_kl': 0.015403702040202916, 'clip_fraction': 0.2682291716337204, 'grad_norm': 14.672209739685059}
2023-01-03 21:12:00.483 DEBUG: Taking gradient step
2023-01-03 21:12:00.492 DEBUG: Loss 3: {'policy_loss': -0.001569400438835085, 'entropy_loss': -0.07871714234352112, 'vf_loss': 0.014525572616117872, 'total_loss': -0.06576097016623833, 'approx_kl': 0.017443776596337557, 'clip_fraction': 0.3567708358168602, 'grad_norm': 5.891085624694824}
2023-01-03 21:12:01.528 DEBUG: Early stopping at step 4 for reaching max KL.
2023-01-03 21:12:01.528 INFO: Optimization: policy loss=-0.002, vf loss=0.015, entropy loss=-0.079, total loss=-0.066, num steps=4
2023-01-03 21:12:01.529 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:12:03.282 INFO: Evaluation rollout: return=0.559 (0.0), episode length=6.0
2023-01-03 21:12:03.283 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:12:03.286 INFO: Iteration: 48/137, steps: 10368
2023-01-03 21:12:37.082 DEBUG: Atoms are too close
2023-01-03 21:12:39.443 DEBUG: Atoms are too close
2023-01-03 21:12:58.897 DEBUG: Atoms are too close
2023-01-03 21:13:00.534 INFO: Training rollout: return=-0.631 (3.9), episode length=6.0
2023-01-03 21:13:00.536 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:13:00.538 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-10368_train.pkl
2023-01-03 21:13:01.569 DEBUG: Taking gradient step
2023-01-03 21:13:01.580 DEBUG: Loss 0: {'policy_loss': -0.0428886214172326, 'entropy_loss': -0.07683767564594746, 'vf_loss': 0.00916214450048005, 'total_loss': -0.11056415256270001, 'approx_kl': -5.5336084159307575e-08, 'clip_fraction': 0.0, 'grad_norm': 20.31400489807129}
2023-01-03 21:13:02.628 DEBUG: Taking gradient step
2023-01-03 21:13:02.638 DEBUG: Loss 1: {'policy_loss': -0.028381085303173945, 'entropy_loss': -0.07601337879896164, 'vf_loss': 0.010348014820029925, 'total_loss': -0.09404644928210568, 'approx_kl': 0.0009539152961224318, 'clip_fraction': 0.061197916977107525, 'grad_norm': 11.187726974487305}
2023-01-03 21:13:03.686 DEBUG: Taking gradient step
2023-01-03 21:13:03.696 DEBUG: Loss 2: {'policy_loss': -0.03178661514909327, 'entropy_loss': -0.0762273371219635, 'vf_loss': 0.010326438045633586, 'total_loss': -0.09768751422542318, 'approx_kl': 0.02240790007635951, 'clip_fraction': 0.1744791679084301, 'grad_norm': 10.950529098510742}
2023-01-03 21:13:04.663 DEBUG: Taking gradient step
2023-01-03 21:13:04.672 DEBUG: Loss 3: {'policy_loss': -0.02812657899511603, 'entropy_loss': -0.07650521397590637, 'vf_loss': 0.010231965493927566, 'total_loss': -0.09439982747709483, 'approx_kl': 0.02790967409964651, 'clip_fraction': 0.25390625, 'grad_norm': 9.380875587463379}
2023-01-03 21:13:05.698 DEBUG: Early stopping at step 4 for reaching max KL.
2023-01-03 21:13:05.699 INFO: Optimization: policy loss=-0.028, vf loss=0.010, entropy loss=-0.077, total loss=-0.094, num steps=4
2023-01-03 21:13:05.699 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:13:07.436 INFO: Evaluation rollout: return=0.599 (0.0), episode length=6.0
2023-01-03 21:13:07.437 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:13:07.440 INFO: Iteration: 49/137, steps: 10584
2023-01-03 21:13:41.524 DEBUG: Atoms are too close
2023-01-03 21:14:05.228 DEBUG: Atoms are too close
2023-01-03 21:14:06.134 INFO: Training rollout: return=-0.278 (3.3), episode length=6.0
2023-01-03 21:14:06.135 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:14:06.138 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-10584_train.pkl
2023-01-03 21:14:07.192 DEBUG: Taking gradient step
2023-01-03 21:14:07.201 DEBUG: Loss 0: {'policy_loss': -0.011545488740293893, 'entropy_loss': -0.07760130055248737, 'vf_loss': 0.006712556556123662, 'total_loss': -0.0824342327366576, 'approx_kl': -5.797483026981354e-08, 'clip_fraction': 0.0, 'grad_norm': 7.499319553375244}
2023-01-03 21:14:08.213 DEBUG: Taking gradient step
2023-01-03 21:14:08.224 DEBUG: Loss 1: {'policy_loss': -0.017620225431932764, 'entropy_loss': -0.07823463343083858, 'vf_loss': 0.0067096360893528825, 'total_loss': -0.08914522277341846, 'approx_kl': 0.009691808838397264, 'clip_fraction': 0.07161458395421505, 'grad_norm': 8.907519340515137}
2023-01-03 21:14:09.180 DEBUG: Taking gradient step
2023-01-03 21:14:09.190 DEBUG: Loss 2: {'policy_loss': 0.0013435789605779902, 'entropy_loss': -0.07731134817004204, 'vf_loss': 0.007292850225353123, 'total_loss': -0.06867491898411093, 'approx_kl': 0.02357682678848505, 'clip_fraction': 0.15755208395421505, 'grad_norm': 7.365394115447998}
2023-01-03 21:14:10.227 DEBUG: Early stopping at step 3 for reaching max KL.
2023-01-03 21:14:10.228 INFO: Optimization: policy loss=0.001, vf loss=0.007, entropy loss=-0.077, total loss=-0.069, num steps=3
2023-01-03 21:14:10.228 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:14:12.008 INFO: Evaluation rollout: return=0.589 (0.0), episode length=6.0
2023-01-03 21:14:12.009 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:14:12.012 INFO: Iteration: 50/137, steps: 10800
2023-01-03 21:14:25.475 DEBUG: Atoms are too close
2023-01-03 21:14:44.339 DEBUG: Atoms are too close
2023-01-03 21:15:09.813 INFO: Training rollout: return=-0.319 (3.6), episode length=5.9
2023-01-03 21:15:09.814 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:15:09.817 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-10800_train.pkl
2023-01-03 21:15:10.866 DEBUG: Taking gradient step
2023-01-03 21:15:10.875 DEBUG: Loss 0: {'policy_loss': 0.002463652035551109, 'entropy_loss': -0.07909761182963848, 'vf_loss': 0.007177406134342099, 'total_loss': -0.06945655365974528, 'approx_kl': -3.620516508817673e-08, 'clip_fraction': 0.0, 'grad_norm': 11.104647636413574}
2023-01-03 21:15:11.873 DEBUG: Taking gradient step
2023-01-03 21:15:11.882 DEBUG: Loss 1: {'policy_loss': -0.0070054952984077365, 'entropy_loss': -0.07876359857618809, 'vf_loss': 0.007165997392016265, 'total_loss': -0.07860309648257954, 'approx_kl': 0.005859098630025983, 'clip_fraction': 0.1171875, 'grad_norm': 11.453155517578125}
2023-01-03 21:15:12.898 DEBUG: Taking gradient step
2023-01-03 21:15:12.907 DEBUG: Loss 2: {'policy_loss': -0.027123188121081075, 'entropy_loss': -0.07906720228493214, 'vf_loss': 0.006828645086021173, 'total_loss': -0.09936174531999205, 'approx_kl': 0.025465909857302904, 'clip_fraction': 0.25390625, 'grad_norm': 4.649401664733887}
2023-01-03 21:15:13.887 DEBUG: Taking gradient step
2023-01-03 21:15:13.896 DEBUG: Loss 3: {'policy_loss': -0.05225447230918775, 'entropy_loss': -0.07862785272300243, 'vf_loss': 0.005992829568636657, 'total_loss': -0.12488949546355352, 'approx_kl': 0.025307655800133944, 'clip_fraction': 0.3333333358168602, 'grad_norm': 3.4525437355041504}
2023-01-03 21:15:14.908 DEBUG: Taking gradient step
2023-01-03 21:15:14.916 DEBUG: Loss 4: {'policy_loss': -0.03292170198132883, 'entropy_loss': -0.07889341376721859, 'vf_loss': 0.006401831455799543, 'total_loss': -0.10541328429274788, 'approx_kl': 0.01648047473281622, 'clip_fraction': 0.3098958358168602, 'grad_norm': 4.099547386169434}
2023-01-03 21:15:15.926 DEBUG: Taking gradient step
2023-01-03 21:15:15.934 DEBUG: Loss 5: {'policy_loss': 0.008346744116775155, 'entropy_loss': -0.07773388363420963, 'vf_loss': 0.007996336495429057, 'total_loss': -0.06139080302200542, 'approx_kl': 0.025089210830628872, 'clip_fraction': 0.33984375, 'grad_norm': 3.2434911727905273}
2023-01-03 21:15:16.945 DEBUG: Taking gradient step
2023-01-03 21:15:16.953 DEBUG: Loss 6: {'policy_loss': -0.04018601251470061, 'entropy_loss': -0.07885409705340862, 'vf_loss': 0.006399924503221264, 'total_loss': -0.11264018506488796, 'approx_kl': 0.029722984181717038, 'clip_fraction': 0.43359375, 'grad_norm': 3.634685516357422}
2023-01-03 21:15:17.973 DEBUG: Taking gradient step
2023-01-03 21:15:17.981 DEBUG: Loss 7: {'policy_loss': -0.055263606719453545, 'entropy_loss': -0.07867967709898949, 'vf_loss': 0.005969163961831074, 'total_loss': -0.12797411985661195, 'approx_kl': 0.04415820678696036, 'clip_fraction': 0.4466145858168602, 'grad_norm': 3.021738052368164}
2023-01-03 21:15:18.982 DEBUG: Taking gradient step
2023-01-03 21:15:18.991 DEBUG: Loss 8: {'policy_loss': -0.06117733097140014, 'entropy_loss': -0.07860389351844788, 'vf_loss': 0.005960977995238838, 'total_loss': -0.13382024649460916, 'approx_kl': -0.0009501995518803596, 'clip_fraction': 0.4739583358168602, 'grad_norm': 3.765951156616211}
2023-01-03 21:15:20.021 DEBUG: Taking gradient step
2023-01-03 21:15:20.030 DEBUG: Loss 9: {'policy_loss': -0.024430193996198352, 'entropy_loss': -0.07879604026675224, 'vf_loss': 0.007584548181774328, 'total_loss': -0.09564168608117626, 'approx_kl': 0.030698988121002913, 'clip_fraction': 0.5, 'grad_norm': 3.405695915222168}
2023-01-03 21:15:21.053 DEBUG: Taking gradient step
2023-01-03 21:15:21.063 DEBUG: Loss 10: {'policy_loss': -0.03633137510131638, 'entropy_loss': -0.07917706295847893, 'vf_loss': 0.0067616566271386, 'total_loss': -0.1087467814326567, 'approx_kl': 0.007996829226613045, 'clip_fraction': 0.5286458432674408, 'grad_norm': 2.0932047367095947}
2023-01-03 21:15:22.091 DEBUG: Taking gradient step
2023-01-03 21:15:22.101 DEBUG: Loss 11: {'policy_loss': -0.04329965388091239, 'entropy_loss': -0.07962093316018581, 'vf_loss': 0.006509746546653242, 'total_loss': -0.11641084049444496, 'approx_kl': -0.007144714472815394, 'clip_fraction': 0.4830729216337204, 'grad_norm': 2.6181867122650146}
2023-01-03 21:15:23.138 DEBUG: Taking gradient step
2023-01-03 21:15:23.148 DEBUG: Loss 12: {'policy_loss': -0.02663285417751232, 'entropy_loss': -0.07960824109613895, 'vf_loss': 0.006945324668463166, 'total_loss': -0.0992957706051881, 'approx_kl': -0.0014073029160499573, 'clip_fraction': 0.4778645858168602, 'grad_norm': 2.945810556411743}
2023-01-03 21:15:24.157 DEBUG: Taking gradient step
2023-01-03 21:15:24.167 DEBUG: Loss 13: {'policy_loss': -0.03706234904611494, 'entropy_loss': -0.08031315356492996, 'vf_loss': 0.006737683391268738, 'total_loss': -0.11063781921977617, 'approx_kl': -0.013781889341771603, 'clip_fraction': 0.4401041716337204, 'grad_norm': 12.242012023925781}
2023-01-03 21:15:25.174 DEBUG: Taking gradient step
2023-01-03 21:15:25.185 DEBUG: Loss 14: {'policy_loss': -0.06472109866592428, 'entropy_loss': -0.07940072752535343, 'vf_loss': 0.0059080073805209765, 'total_loss': -0.13821381881075673, 'approx_kl': 0.005858335178345442, 'clip_fraction': 0.4453125, 'grad_norm': 4.777321815490723}
2023-01-03 21:15:25.185 INFO: Optimization: policy loss=-0.065, vf loss=0.006, entropy loss=-0.079, total loss=-0.138, num steps=15
2023-01-03 21:15:25.185 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:15:26.914 INFO: Evaluation rollout: return=0.596 (0.0), episode length=6.0
2023-01-03 21:15:26.915 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:15:26.918 DEBUG: Deleting old model: runs/CH3NO_baseline/models/CH3NO_baseline_run-1_steps-8856.model
2023-01-03 21:15:26.920 DEBUG: Saving model: runs/CH3NO_baseline/models/CH3NO_baseline_run-1_steps-11016.model
2023-01-03 21:15:26.949 INFO: Iteration: 51/137, steps: 11016
2023-01-03 21:16:24.952 INFO: Training rollout: return=0.534 (0.1), episode length=6.0
2023-01-03 21:16:24.954 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:16:24.957 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-11016_train.pkl
2023-01-03 21:16:26.027 DEBUG: Taking gradient step
2023-01-03 21:16:26.036 DEBUG: Loss 0: {'policy_loss': -0.0018528215954009275, 'entropy_loss': -0.07929645292460918, 'vf_loss': 0.0003481737014447902, 'total_loss': -0.08080110081856531, 'approx_kl': 8.110267479821687e-08, 'clip_fraction': 0.0, 'grad_norm': 9.983087539672852}
2023-01-03 21:16:27.104 DEBUG: Taking gradient step
2023-01-03 21:16:27.113 DEBUG: Loss 1: {'policy_loss': -0.03524860842055795, 'entropy_loss': -0.07974628545343876, 'vf_loss': 0.00033644749319391455, 'total_loss': -0.1146584463808028, 'approx_kl': 0.033415834652259946, 'clip_fraction': 0.08203125, 'grad_norm': 9.947357177734375}
2023-01-03 21:16:28.089 DEBUG: Early stopping at step 2 for reaching max KL.
2023-01-03 21:16:28.089 INFO: Optimization: policy loss=-0.035, vf loss=0.000, entropy loss=-0.080, total loss=-0.115, num steps=2
2023-01-03 21:16:28.090 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:16:29.809 INFO: Evaluation rollout: return=0.618 (0.0), episode length=6.0
2023-01-03 21:16:29.810 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:16:29.813 INFO: Iteration: 52/137, steps: 11232
2023-01-03 21:16:34.173 DEBUG: Atoms are too close
2023-01-03 21:16:59.057 DEBUG: Atoms are too close
2023-01-03 21:17:26.554 INFO: Training rollout: return=-0.715 (5.2), episode length=5.8
2023-01-03 21:17:26.555 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:17:26.558 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-11232_train.pkl
2023-01-03 21:17:27.590 DEBUG: Taking gradient step
2023-01-03 21:17:27.599 DEBUG: Loss 0: {'policy_loss': -0.02845977244672161, 'entropy_loss': -0.07898686453700066, 'vf_loss': 0.0046798303233602494, 'total_loss': -0.102766806660362, 'approx_kl': -9.786648114129548e-08, 'clip_fraction': 0.0, 'grad_norm': 19.65424346923828}
2023-01-03 21:17:28.619 DEBUG: Taking gradient step
2023-01-03 21:17:28.628 DEBUG: Loss 1: {'policy_loss': -0.03681854459096714, 'entropy_loss': -0.07837383262813091, 'vf_loss': 0.004661186839413686, 'total_loss': -0.11053119037968435, 'approx_kl': 0.005026974715292454, 'clip_fraction': 0.1484375, 'grad_norm': 4.892640113830566}
2023-01-03 21:17:29.647 DEBUG: Taking gradient step
2023-01-03 21:17:29.656 DEBUG: Loss 2: {'policy_loss': -0.01416472432675864, 'entropy_loss': -0.0792323686182499, 'vf_loss': 0.005270691423138232, 'total_loss': -0.0881264015218703, 'approx_kl': 0.03244374552741647, 'clip_fraction': 0.3125, 'grad_norm': 4.039637088775635}
2023-01-03 21:17:30.655 DEBUG: Taking gradient step
2023-01-03 21:17:30.663 DEBUG: Loss 3: {'policy_loss': -0.003808249379525633, 'entropy_loss': -0.07887360453605652, 'vf_loss': 0.006349896382763733, 'total_loss': -0.07633195753281842, 'approx_kl': 0.0369673406239599, 'clip_fraction': 0.3984375, 'grad_norm': 3.35703706741333}
2023-01-03 21:17:31.624 DEBUG: Taking gradient step
2023-01-03 21:17:31.633 DEBUG: Loss 4: {'policy_loss': -0.04464869178283501, 'entropy_loss': -0.07995753549039364, 'vf_loss': 0.004629736446022515, 'total_loss': -0.11997649082720613, 'approx_kl': 0.04265106935054064, 'clip_fraction': 0.4283854216337204, 'grad_norm': 2.6809139251708984}
2023-01-03 21:17:32.672 DEBUG: Early stopping at step 5 for reaching max KL.
2023-01-03 21:17:32.673 INFO: Optimization: policy loss=-0.045, vf loss=0.005, entropy loss=-0.080, total loss=-0.120, num steps=5
2023-01-03 21:17:32.673 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:17:34.405 INFO: Evaluation rollout: return=0.578 (0.0), episode length=6.0
2023-01-03 21:17:34.406 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:17:34.408 INFO: Iteration: 53/137, steps: 11448
2023-01-03 21:18:32.432 INFO: Training rollout: return=0.556 (0.1), episode length=6.0
2023-01-03 21:18:32.433 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:18:32.436 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-11448_train.pkl
2023-01-03 21:18:33.471 DEBUG: Taking gradient step
2023-01-03 21:18:33.481 DEBUG: Loss 0: {'policy_loss': 0.01579665334120641, 'entropy_loss': -0.07848065160214901, 'vf_loss': 0.0002468196142022558, 'total_loss': -0.06243717864674034, 'approx_kl': 7.396253565161715e-08, 'clip_fraction': 0.0, 'grad_norm': 14.591259002685547}
2023-01-03 21:18:34.518 DEBUG: Taking gradient step
2023-01-03 21:18:34.528 DEBUG: Loss 1: {'policy_loss': -0.019334668513590142, 'entropy_loss': -0.07882576622068882, 'vf_loss': 0.00023023335504726913, 'total_loss': -0.0979302013792317, 'approx_kl': 0.0171892864163965, 'clip_fraction': 0.15234375, 'grad_norm': 9.719395637512207}
2023-01-03 21:18:35.546 DEBUG: Early stopping at step 2 for reaching max KL.
2023-01-03 21:18:35.547 INFO: Optimization: policy loss=-0.019, vf loss=0.000, entropy loss=-0.079, total loss=-0.098, num steps=2
2023-01-03 21:18:35.547 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:18:37.340 INFO: Evaluation rollout: return=0.563 (0.0), episode length=6.0
2023-01-03 21:18:37.341 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:18:37.344 INFO: Iteration: 54/137, steps: 11664
2023-01-03 21:18:51.169 DEBUG: Atoms are too close
2023-01-03 21:18:55.193 DEBUG: Atoms are too close
2023-01-03 21:19:33.198 DEBUG: There is a single atom floating around
2023-01-03 21:19:34.424 INFO: Training rollout: return=-0.610 (3.9), episode length=6.0
2023-01-03 21:19:34.425 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:19:34.428 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-11664_train.pkl
2023-01-03 21:19:35.470 DEBUG: Taking gradient step
2023-01-03 21:19:35.480 DEBUG: Loss 0: {'policy_loss': 0.02604800363666962, 'entropy_loss': -0.07815336249768734, 'vf_loss': 0.011822797676382675, 'total_loss': -0.040282561184635045, 'approx_kl': -3.158735717434524e-08, 'clip_fraction': 0.0, 'grad_norm': 20.711748123168945}
2023-01-03 21:19:36.488 DEBUG: Taking gradient step
2023-01-03 21:19:36.497 DEBUG: Loss 1: {'policy_loss': 0.008429841458836636, 'entropy_loss': -0.07918602973222733, 'vf_loss': 0.011646020186089585, 'total_loss': -0.0591101680873011, 'approx_kl': 7.829745300114155e-05, 'clip_fraction': 0.053385416977107525, 'grad_norm': 14.187664985656738}
2023-01-03 21:19:37.538 DEBUG: Taking gradient step
2023-01-03 21:19:37.546 DEBUG: Loss 2: {'policy_loss': 0.028934857480817144, 'entropy_loss': -0.07911905460059643, 'vf_loss': 0.013846481994437488, 'total_loss': -0.036337715125341785, 'approx_kl': -0.0032221758738160133, 'clip_fraction': 0.2942708358168602, 'grad_norm': 6.468952655792236}
2023-01-03 21:19:38.564 DEBUG: Taking gradient step
2023-01-03 21:19:38.574 DEBUG: Loss 3: {'policy_loss': -0.03393605466028936, 'entropy_loss': -0.07866329327225685, 'vf_loss': 0.010367743654331048, 'total_loss': -0.10223160427821515, 'approx_kl': 0.005752401193603873, 'clip_fraction': 0.3802083358168602, 'grad_norm': 6.598270416259766}
2023-01-03 21:19:39.602 DEBUG: Taking gradient step
2023-01-03 21:19:39.612 DEBUG: Loss 4: {'policy_loss': -0.023669817297275388, 'entropy_loss': -0.07841231860220432, 'vf_loss': 0.010934863519243986, 'total_loss': -0.09114727238023573, 'approx_kl': 0.0077172983437776566, 'clip_fraction': 0.4153645858168602, 'grad_norm': 4.813849449157715}
2023-01-03 21:19:40.609 DEBUG: Taking gradient step
2023-01-03 21:19:40.619 DEBUG: Loss 5: {'policy_loss': -0.01662965143877436, 'entropy_loss': -0.07855510711669922, 'vf_loss': 0.010891878874877154, 'total_loss': -0.08429287968059643, 'approx_kl': 0.024051844608038664, 'clip_fraction': 0.4166666716337204, 'grad_norm': 8.480369567871094}
2023-01-03 21:19:41.611 DEBUG: Early stopping at step 6 for reaching max KL.
2023-01-03 21:19:41.612 INFO: Optimization: policy loss=-0.017, vf loss=0.011, entropy loss=-0.079, total loss=-0.084, num steps=6
2023-01-03 21:19:41.612 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:19:43.375 INFO: Evaluation rollout: return=0.584 (0.0), episode length=6.0
2023-01-03 21:19:43.376 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:19:43.379 INFO: Iteration: 55/137, steps: 11880
2023-01-03 21:20:01.211 DEBUG: Atoms are too close
2023-01-03 21:20:01.509 DEBUG: There is a single atom floating around
2023-01-03 21:20:18.963 DEBUG: Atoms are too close
2023-01-03 21:20:38.322 DEBUG: There is a single atom floating around
2023-01-03 21:20:40.596 INFO: Training rollout: return=-0.948 (4.2), episode length=6.0
2023-01-03 21:20:40.598 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:20:40.602 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-11880_train.pkl
2023-01-03 21:20:41.663 DEBUG: Taking gradient step
2023-01-03 21:20:41.672 DEBUG: Loss 0: {'policy_loss': 0.010094069164910537, 'entropy_loss': -0.07769748009741306, 'vf_loss': 0.01519668572606514, 'total_loss': -0.05240672520643738, 'approx_kl': 5.7819612209186744e-08, 'clip_fraction': 0.0, 'grad_norm': 16.584163665771484}
2023-01-03 21:20:42.671 DEBUG: Taking gradient step
2023-01-03 21:20:42.681 DEBUG: Loss 1: {'policy_loss': 0.025490770505865953, 'entropy_loss': -0.07792405597865582, 'vf_loss': 0.016074924952850265, 'total_loss': -0.0363583605199396, 'approx_kl': 0.0013412240077741444, 'clip_fraction': 0.06380208395421505, 'grad_norm': 18.422407150268555}
2023-01-03 21:20:43.719 DEBUG: Taking gradient step
2023-01-03 21:20:43.730 DEBUG: Loss 2: {'policy_loss': -0.029596307617377218, 'entropy_loss': -0.07711480557918549, 'vf_loss': 0.014754741977924807, 'total_loss': -0.09195637121863791, 'approx_kl': 0.029032092541456223, 'clip_fraction': 0.1861979179084301, 'grad_norm': 11.307042121887207}
2023-01-03 21:20:44.775 DEBUG: Early stopping at step 3 for reaching max KL.
2023-01-03 21:20:44.775 INFO: Optimization: policy loss=-0.030, vf loss=0.015, entropy loss=-0.077, total loss=-0.092, num steps=3
2023-01-03 21:20:44.775 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:20:46.506 INFO: Evaluation rollout: return=0.587 (0.0), episode length=6.0
2023-01-03 21:20:46.507 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:20:46.511 INFO: Iteration: 56/137, steps: 12096
2023-01-03 21:21:24.404 DEBUG: There is a single atom floating around
2023-01-03 21:21:44.871 INFO: Training rollout: return=0.180 (2.2), episode length=6.0
2023-01-03 21:21:44.872 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:21:44.876 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-12096_train.pkl
2023-01-03 21:21:45.915 DEBUG: Taking gradient step
2023-01-03 21:21:45.925 DEBUG: Loss 0: {'policy_loss': -0.02442696138943952, 'entropy_loss': -0.07692206464707851, 'vf_loss': 0.003254167538187567, 'total_loss': -0.09809485849833047, 'approx_kl': 4.0046870708465576e-08, 'clip_fraction': 0.0, 'grad_norm': 13.789353370666504}
2023-01-03 21:21:46.892 DEBUG: Taking gradient step
2023-01-03 21:21:46.901 DEBUG: Loss 1: {'policy_loss': -0.011124571646527241, 'entropy_loss': -0.07577534392476082, 'vf_loss': 0.003655597410286722, 'total_loss': -0.08324431816100133, 'approx_kl': 0.009314339375123382, 'clip_fraction': 0.12760416697710752, 'grad_norm': 5.454219341278076}
2023-01-03 21:21:47.930 DEBUG: Early stopping at step 2 for reaching max KL.
2023-01-03 21:21:47.930 INFO: Optimization: policy loss=-0.011, vf loss=0.004, entropy loss=-0.076, total loss=-0.083, num steps=2
2023-01-03 21:21:47.930 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:21:49.666 INFO: Evaluation rollout: return=0.586 (0.0), episode length=6.0
2023-01-03 21:21:49.667 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:21:49.671 INFO: Iteration: 57/137, steps: 12312
2023-01-03 21:22:07.547 DEBUG: Atoms are too close
2023-01-03 21:22:25.804 DEBUG: Atoms are too close
2023-01-03 21:22:45.984 DEBUG: Atoms are too close
2023-01-03 21:22:47.130 INFO: Training rollout: return=-0.565 (3.7), episode length=6.0
2023-01-03 21:22:47.132 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:22:47.134 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-12312_train.pkl
2023-01-03 21:22:48.187 DEBUG: Taking gradient step
2023-01-03 21:22:48.197 DEBUG: Loss 0: {'policy_loss': -0.02504596892016472, 'entropy_loss': -0.07936765812337399, 'vf_loss': 0.009942035503907399, 'total_loss': -0.0944715915396313, 'approx_kl': -7.629084208815584e-08, 'clip_fraction': 0.0, 'grad_norm': 13.056896209716797}
2023-01-03 21:22:49.227 DEBUG: Taking gradient step
2023-01-03 21:22:49.236 DEBUG: Loss 1: {'policy_loss': -0.016388635854688437, 'entropy_loss': -0.07806847244501114, 'vf_loss': 0.01052540123522375, 'total_loss': -0.08393170706447582, 'approx_kl': 0.0067553059925558046, 'clip_fraction': 0.14192708395421505, 'grad_norm': 12.113451957702637}
2023-01-03 21:22:50.266 DEBUG: Taking gradient step
2023-01-03 21:22:50.275 DEBUG: Loss 2: {'policy_loss': -0.051292017499489514, 'entropy_loss': -0.07751713693141937, 'vf_loss': 0.009607973954721469, 'total_loss': -0.11920118047618741, 'approx_kl': 0.028487020637840033, 'clip_fraction': 0.34765625, 'grad_norm': 5.55087947845459}
2023-01-03 21:22:51.313 DEBUG: Early stopping at step 3 for reaching max KL.
2023-01-03 21:22:51.313 INFO: Optimization: policy loss=-0.051, vf loss=0.010, entropy loss=-0.078, total loss=-0.119, num steps=3
2023-01-03 21:22:51.314 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:22:53.047 INFO: Evaluation rollout: return=0.588 (0.0), episode length=6.0
2023-01-03 21:22:53.048 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:22:53.051 INFO: Iteration: 58/137, steps: 12528
2023-01-03 21:23:51.742 INFO: Training rollout: return=0.504 (0.3), episode length=6.0
2023-01-03 21:23:51.744 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:23:51.746 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-12528_train.pkl
2023-01-03 21:23:52.802 DEBUG: Taking gradient step
2023-01-03 21:23:52.812 DEBUG: Loss 0: {'policy_loss': 0.008216741609129672, 'entropy_loss': -0.0766705796122551, 'vf_loss': 0.00034061629056984295, 'total_loss': -0.06811322171255559, 'approx_kl': 6.278666386805298e-08, 'clip_fraction': 0.0, 'grad_norm': 24.386913299560547}
2023-01-03 21:23:53.852 DEBUG: Taking gradient step
2023-01-03 21:23:53.861 DEBUG: Loss 1: {'policy_loss': -0.025451747750121597, 'entropy_loss': -0.07698392868041992, 'vf_loss': 0.0003580940116493625, 'total_loss': -0.10207758241889216, 'approx_kl': 0.0053057020995765924, 'clip_fraction': 0.1236979179084301, 'grad_norm': 6.03557825088501}
2023-01-03 21:23:54.896 DEBUG: Taking gradient step
2023-01-03 21:23:54.905 DEBUG: Loss 2: {'policy_loss': 0.00017880850135675377, 'entropy_loss': -0.07643826678395271, 'vf_loss': 0.0003755943367583335, 'total_loss': -0.07588386394583763, 'approx_kl': 0.02178743784315884, 'clip_fraction': 0.2122395858168602, 'grad_norm': 5.67810583114624}
2023-01-03 21:23:55.961 DEBUG: Taking gradient step
2023-01-03 21:23:55.971 DEBUG: Loss 3: {'policy_loss': -0.018442125987611184, 'entropy_loss': -0.07601392082870007, 'vf_loss': 0.0003738010843014536, 'total_loss': -0.09408224573200978, 'approx_kl': 0.020962453680112958, 'clip_fraction': 0.2825520858168602, 'grad_norm': 8.544944763183594}
2023-01-03 21:23:56.995 DEBUG: Taking gradient step
2023-01-03 21:23:57.005 DEBUG: Loss 4: {'policy_loss': -0.04060774879491867, 'entropy_loss': -0.07592598348855972, 'vf_loss': 0.0003760395270602517, 'total_loss': -0.11615769275641813, 'approx_kl': 0.02984529174864292, 'clip_fraction': 0.3372395858168602, 'grad_norm': 8.945464134216309}
2023-01-03 21:23:58.005 DEBUG: Early stopping at step 5 for reaching max KL.
2023-01-03 21:23:58.006 INFO: Optimization: policy loss=-0.041, vf loss=0.000, entropy loss=-0.076, total loss=-0.116, num steps=5
2023-01-03 21:23:58.006 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:23:59.764 INFO: Evaluation rollout: return=0.554 (0.0), episode length=6.0
2023-01-03 21:23:59.767 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:23:59.769 INFO: Iteration: 59/137, steps: 12744
2023-01-03 21:24:35.258 DEBUG: Atoms are too close
2023-01-03 21:24:37.499 DEBUG: Atoms are too close
2023-01-03 21:24:51.282 DEBUG: Atoms are too close
2023-01-03 21:24:56.884 INFO: Training rollout: return=-0.610 (3.9), episode length=6.0
2023-01-03 21:24:56.886 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:24:56.888 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-12744_train.pkl
2023-01-03 21:24:57.935 DEBUG: Taking gradient step
2023-01-03 21:24:57.946 DEBUG: Loss 0: {'policy_loss': 0.03154312817631856, 'entropy_loss': -0.07386784069240093, 'vf_loss': 0.011340783734851693, 'total_loss': -0.030983928781230678, 'approx_kl': -9.107558796017656e-08, 'clip_fraction': 0.0, 'grad_norm': 14.983650207519531}
2023-01-03 21:24:58.946 DEBUG: Taking gradient step
2023-01-03 21:24:58.955 DEBUG: Loss 1: {'policy_loss': -0.03502384827194446, 'entropy_loss': -0.0736036915332079, 'vf_loss': 0.01021202699985221, 'total_loss': -0.09841551280530014, 'approx_kl': 0.01214026054367423, 'clip_fraction': 0.0390625, 'grad_norm': 8.656298637390137}
2023-01-03 21:24:59.988 DEBUG: Taking gradient step
2023-01-03 21:24:59.997 DEBUG: Loss 2: {'policy_loss': -0.0509097227113178, 'entropy_loss': -0.0725999977439642, 'vf_loss': 0.00960355195627381, 'total_loss': -0.11390616849900818, 'approx_kl': 0.03563178423792124, 'clip_fraction': 0.16015625, 'grad_norm': 6.93149995803833}
2023-01-03 21:25:01.009 DEBUG: Taking gradient step
2023-01-03 21:25:01.018 DEBUG: Loss 3: {'policy_loss': -0.05440900429862602, 'entropy_loss': -0.07330296747386456, 'vf_loss': 0.009822551939268127, 'total_loss': -0.11788941983322244, 'approx_kl': 0.04208475770428777, 'clip_fraction': 0.2604166679084301, 'grad_norm': 5.007317543029785}
2023-01-03 21:25:02.052 DEBUG: Early stopping at step 4 for reaching max KL.
2023-01-03 21:25:02.052 INFO: Optimization: policy loss=-0.054, vf loss=0.010, entropy loss=-0.073, total loss=-0.118, num steps=4
2023-01-03 21:25:02.052 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:25:03.829 INFO: Evaluation rollout: return=0.586 (0.0), episode length=6.0
2023-01-03 21:25:03.831 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:25:03.834 INFO: Iteration: 60/137, steps: 12960
2023-01-03 21:25:19.696 DEBUG: There is a single atom floating around
2023-01-03 21:25:57.524 DEBUG: Atoms are too close
2023-01-03 21:26:01.134 INFO: Training rollout: return=-0.249 (3.3), episode length=6.0
2023-01-03 21:26:01.136 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:26:01.139 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-12960_train.pkl
2023-01-03 21:26:02.147 DEBUG: Taking gradient step
2023-01-03 21:26:02.155 DEBUG: Loss 0: {'policy_loss': -0.004415453398383261, 'entropy_loss': -0.07261316664516926, 'vf_loss': 0.006910026367965121, 'total_loss': -0.0701185936755874, 'approx_kl': 9.23561316312771e-09, 'clip_fraction': 0.0, 'grad_norm': 11.260937690734863}
2023-01-03 21:26:03.193 DEBUG: Taking gradient step
2023-01-03 21:26:03.204 DEBUG: Loss 1: {'policy_loss': -0.022242689726825617, 'entropy_loss': -0.07225503586232662, 'vf_loss': 0.006659355449353112, 'total_loss': -0.08783837013979912, 'approx_kl': 0.006536554137710482, 'clip_fraction': 0.0546875, 'grad_norm': 11.336435317993164}
2023-01-03 21:26:04.234 DEBUG: Taking gradient step
2023-01-03 21:26:04.243 DEBUG: Loss 2: {'policy_loss': -0.03245491989376749, 'entropy_loss': -0.07194489985704422, 'vf_loss': 0.0064758572079065425, 'total_loss': -0.09792396254290517, 'approx_kl': 0.028256688150577247, 'clip_fraction': 0.2265625, 'grad_norm': 4.937788963317871}
2023-01-03 21:26:05.279 DEBUG: Early stopping at step 3 for reaching max KL.
2023-01-03 21:26:05.279 INFO: Optimization: policy loss=-0.032, vf loss=0.006, entropy loss=-0.072, total loss=-0.098, num steps=3
2023-01-03 21:26:05.279 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:26:07.039 INFO: Evaluation rollout: return=0.582 (0.0), episode length=6.0
2023-01-03 21:26:07.040 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:26:07.043 DEBUG: Deleting old model: runs/CH3NO_baseline/models/CH3NO_baseline_run-1_steps-11016.model
2023-01-03 21:26:07.048 DEBUG: Saving model: runs/CH3NO_baseline/models/CH3NO_baseline_run-1_steps-13176.model
2023-01-03 21:26:07.077 INFO: Iteration: 61/137, steps: 13176
2023-01-03 21:26:23.298 DEBUG: Atoms are too close
2023-01-03 21:26:44.567 DEBUG: Atoms are too close
2023-01-03 21:27:04.542 INFO: Training rollout: return=-0.179 (3.0), episode length=6.0
2023-01-03 21:27:04.544 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:27:04.546 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-13176_train.pkl
2023-01-03 21:27:05.599 DEBUG: Taking gradient step
2023-01-03 21:27:05.609 DEBUG: Loss 0: {'policy_loss': -0.036141846508038034, 'entropy_loss': -0.07169625349342823, 'vf_loss': 0.006267546464147077, 'total_loss': -0.1015705535373192, 'approx_kl': 2.4369607387608738e-08, 'clip_fraction': 0.0, 'grad_norm': 7.928858280181885}
2023-01-03 21:27:06.648 DEBUG: Taking gradient step
2023-01-03 21:27:06.658 DEBUG: Loss 1: {'policy_loss': -0.007546734665397822, 'entropy_loss': -0.07142543978989124, 'vf_loss': 0.007417059372849012, 'total_loss': -0.07155511508244006, 'approx_kl': 0.005249017151072621, 'clip_fraction': 0.0546875, 'grad_norm': 8.660629272460938}
2023-01-03 21:27:07.705 DEBUG: Taking gradient step
2023-01-03 21:27:07.716 DEBUG: Loss 2: {'policy_loss': -0.02957632096118849, 'entropy_loss': -0.07133085653185844, 'vf_loss': 0.00668679796463191, 'total_loss': -0.09422037952841501, 'approx_kl': 0.02878879476338625, 'clip_fraction': 0.2734375, 'grad_norm': 5.1637163162231445}
2023-01-03 21:27:08.734 DEBUG: Taking gradient step
2023-01-03 21:27:08.743 DEBUG: Loss 3: {'policy_loss': -0.050054091333851074, 'entropy_loss': -0.07024022936820984, 'vf_loss': 0.006262724377022591, 'total_loss': -0.11403159632503831, 'approx_kl': 0.035343232564628124, 'clip_fraction': 0.3450520858168602, 'grad_norm': 5.255486488342285}
2023-01-03 21:27:09.783 DEBUG: Early stopping at step 4 for reaching max KL.
2023-01-03 21:27:09.783 INFO: Optimization: policy loss=-0.050, vf loss=0.006, entropy loss=-0.070, total loss=-0.114, num steps=4
2023-01-03 21:27:09.783 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:27:11.531 INFO: Evaluation rollout: return=0.585 (0.0), episode length=6.0
2023-01-03 21:27:11.532 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:27:11.535 INFO: Iteration: 62/137, steps: 13392
2023-01-03 21:28:08.616 DEBUG: Atoms are too close
2023-01-03 21:28:09.835 INFO: Training rollout: return=0.191 (2.2), episode length=6.0
2023-01-03 21:28:09.836 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:28:09.839 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-13392_train.pkl
2023-01-03 21:28:10.894 DEBUG: Taking gradient step
2023-01-03 21:28:10.905 DEBUG: Loss 0: {'policy_loss': 0.034681765792909394, 'entropy_loss': -0.07180102728307247, 'vf_loss': 0.004894863488410695, 'total_loss': -0.032224398001752384, 'approx_kl': -4.89720477503397e-08, 'clip_fraction': 0.0, 'grad_norm': 29.46636199951172}
2023-01-03 21:28:11.943 DEBUG: Taking gradient step
2023-01-03 21:28:11.953 DEBUG: Loss 1: {'policy_loss': 0.013987783957201478, 'entropy_loss': -0.07137581706047058, 'vf_loss': 0.0048870385761510295, 'total_loss': -0.05250099452711808, 'approx_kl': 0.0034761729184538126, 'clip_fraction': 0.02734375, 'grad_norm': 26.36136817932129}
2023-01-03 21:28:13.002 DEBUG: Taking gradient step
2023-01-03 21:28:13.012 DEBUG: Loss 2: {'policy_loss': -0.04189376942230629, 'entropy_loss': -0.07184973359107971, 'vf_loss': 0.0032817789074751284, 'total_loss': -0.11046172410591087, 'approx_kl': 0.013100252253934741, 'clip_fraction': 0.1822916679084301, 'grad_norm': 4.758197784423828}
2023-01-03 21:28:14.055 DEBUG: Taking gradient step
2023-01-03 21:28:14.065 DEBUG: Loss 3: {'policy_loss': -0.022995253791941273, 'entropy_loss': -0.0712532289326191, 'vf_loss': 0.00357808682003643, 'total_loss': -0.09067039590452394, 'approx_kl': 0.014009659644216299, 'clip_fraction': 0.2890625, 'grad_norm': 3.2594192028045654}
2023-01-03 21:28:15.101 DEBUG: Taking gradient step
2023-01-03 21:28:15.112 DEBUG: Loss 4: {'policy_loss': 0.0025004973913822504, 'entropy_loss': -0.07089767791330814, 'vf_loss': 0.004875050013887182, 'total_loss': -0.0635221305080387, 'approx_kl': 0.03774135001003742, 'clip_fraction': 0.29296875, 'grad_norm': 2.745591878890991}
2023-01-03 21:28:16.150 DEBUG: Taking gradient step
2023-01-03 21:28:16.161 DEBUG: Loss 5: {'policy_loss': -0.031510450835571996, 'entropy_loss': -0.07180029526352882, 'vf_loss': 0.003560041668794991, 'total_loss': -0.09975070443030581, 'approx_kl': 0.0072357323952019215, 'clip_fraction': 0.296875, 'grad_norm': 2.27199649810791}
2023-01-03 21:28:17.201 DEBUG: Taking gradient step
2023-01-03 21:28:17.211 DEBUG: Loss 6: {'policy_loss': -0.00015395377303079744, 'entropy_loss': -0.07044445164501667, 'vf_loss': 0.00484464551049319, 'total_loss': -0.06575375990755426, 'approx_kl': 0.026258192025125027, 'clip_fraction': 0.30078125, 'grad_norm': 2.2878565788269043}
2023-01-03 21:28:18.243 DEBUG: Taking gradient step
2023-01-03 21:28:18.252 DEBUG: Loss 7: {'policy_loss': -0.008312383321728564, 'entropy_loss': -0.07054039277136326, 'vf_loss': 0.004295946905460399, 'total_loss': -0.07455682918763142, 'approx_kl': 0.0009901328012347221, 'clip_fraction': 0.3385416716337204, 'grad_norm': 3.175198554992676}
2023-01-03 21:28:19.242 DEBUG: Taking gradient step
2023-01-03 21:28:19.250 DEBUG: Loss 8: {'policy_loss': 0.010780159209458892, 'entropy_loss': -0.07008590176701546, 'vf_loss': 0.004576620968625234, 'total_loss': -0.054729121588931326, 'approx_kl': -0.004873424768447876, 'clip_fraction': 0.3411458358168602, 'grad_norm': 3.9188804626464844}
2023-01-03 21:28:20.280 DEBUG: Taking gradient step
2023-01-03 21:28:20.289 DEBUG: Loss 9: {'policy_loss': -0.03034991974463077, 'entropy_loss': -0.07027244009077549, 'vf_loss': 0.003605500305095333, 'total_loss': -0.09701685953031093, 'approx_kl': -0.018856173381209373, 'clip_fraction': 0.3294270858168602, 'grad_norm': 4.419101238250732}
2023-01-03 21:28:21.328 DEBUG: Taking gradient step
2023-01-03 21:28:21.337 DEBUG: Loss 10: {'policy_loss': -0.022406621556384246, 'entropy_loss': -0.07098167762160301, 'vf_loss': 0.0039491627152026445, 'total_loss': -0.0894391364627846, 'approx_kl': -0.014836593996733427, 'clip_fraction': 0.4127604216337204, 'grad_norm': 1.6209145784378052}
2023-01-03 21:28:22.346 DEBUG: Taking gradient step
2023-01-03 21:28:22.356 DEBUG: Loss 11: {'policy_loss': -0.055976729502975886, 'entropy_loss': -0.0709668044000864, 'vf_loss': 0.003136844171874561, 'total_loss': -0.12380668973118772, 'approx_kl': -0.004514759173616767, 'clip_fraction': 0.4635416716337204, 'grad_norm': 4.075414657592773}
2023-01-03 21:28:23.416 DEBUG: Taking gradient step
2023-01-03 21:28:23.426 DEBUG: Loss 12: {'policy_loss': -0.027931107427133204, 'entropy_loss': -0.07002504356205463, 'vf_loss': 0.0035499395183191005, 'total_loss': -0.09440621147086874, 'approx_kl': -0.01930095045827329, 'clip_fraction': 0.4817708358168602, 'grad_norm': 2.923130750656128}
2023-01-03 21:28:24.455 DEBUG: Taking gradient step
2023-01-03 21:28:24.466 DEBUG: Loss 13: {'policy_loss': 0.022205003762283335, 'entropy_loss': -0.07140258885920048, 'vf_loss': 0.005548749160359247, 'total_loss': -0.043648835936557884, 'approx_kl': -0.006405540741980076, 'clip_fraction': 0.5169270858168602, 'grad_norm': 2.529240608215332}
2023-01-03 21:28:25.498 DEBUG: Taking gradient step
2023-01-03 21:28:25.508 DEBUG: Loss 14: {'policy_loss': 0.005206580981621786, 'entropy_loss': -0.07107765600085258, 'vf_loss': 0.004608661957562183, 'total_loss': -0.06126241306166863, 'approx_kl': -0.020510933129116893, 'clip_fraction': 0.5416666716337204, 'grad_norm': 2.0979740619659424}
2023-01-03 21:28:25.508 INFO: Optimization: policy loss=0.005, vf loss=0.005, entropy loss=-0.071, total loss=-0.061, num steps=15
2023-01-03 21:28:25.509 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:28:27.236 INFO: Evaluation rollout: return=0.580 (0.0), episode length=6.0
2023-01-03 21:28:27.237 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:28:27.239 INFO: Iteration: 63/137, steps: 13608
2023-01-03 21:29:04.709 DEBUG: There is a single atom floating around
2023-01-03 21:29:25.015 DEBUG: Atoms are too close
2023-01-03 21:29:26.568 INFO: Training rollout: return=-0.206 (3.1), episode length=6.0
2023-01-03 21:29:26.569 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:29:26.572 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-13608_train.pkl
2023-01-03 21:29:27.605 DEBUG: Taking gradient step
2023-01-03 21:29:27.615 DEBUG: Loss 0: {'policy_loss': 0.01849194957767858, 'entropy_loss': -0.07076120190322399, 'vf_loss': 0.007882498124298783, 'total_loss': -0.04438675420124663, 'approx_kl': -1.9829411002092456e-08, 'clip_fraction': 0.0, 'grad_norm': 20.695266723632812}
2023-01-03 21:29:28.657 DEBUG: Taking gradient step
2023-01-03 21:29:28.666 DEBUG: Loss 1: {'policy_loss': -0.013399180758264892, 'entropy_loss': -0.07017762586474419, 'vf_loss': 0.00713897264275435, 'total_loss': -0.07643783398025474, 'approx_kl': 0.003959479043260217, 'clip_fraction': 0.057291666977107525, 'grad_norm': 11.835444450378418}
2023-01-03 21:29:29.684 DEBUG: Taking gradient step
2023-01-03 21:29:29.694 DEBUG: Loss 2: {'policy_loss': -0.024009919097510095, 'entropy_loss': -0.07264561951160431, 'vf_loss': 0.00762309973277152, 'total_loss': -0.08903243887634288, 'approx_kl': 0.010095430683577433, 'clip_fraction': 0.2708333358168602, 'grad_norm': 7.3291096687316895}
2023-01-03 21:29:30.658 DEBUG: Taking gradient step
2023-01-03 21:29:30.667 DEBUG: Loss 3: {'policy_loss': -0.02548086844675907, 'entropy_loss': -0.0728154219686985, 'vf_loss': 0.008111598893688558, 'total_loss': -0.09018469152176903, 'approx_kl': 0.011271183378994465, 'clip_fraction': 0.4088541716337204, 'grad_norm': 5.59930419921875}
2023-01-03 21:29:31.712 DEBUG: Taking gradient step
2023-01-03 21:29:31.720 DEBUG: Loss 4: {'policy_loss': -0.062209321312785795, 'entropy_loss': -0.07282944768667221, 'vf_loss': 0.0063953974013300436, 'total_loss': -0.12864337159812797, 'approx_kl': 0.01841667853295803, 'clip_fraction': 0.4713541716337204, 'grad_norm': 4.20615816116333}
2023-01-03 21:29:32.782 DEBUG: Taking gradient step
2023-01-03 21:29:32.792 DEBUG: Loss 5: {'policy_loss': -0.010874246967206173, 'entropy_loss': -0.07201040536165237, 'vf_loss': 0.008618838190560862, 'total_loss': -0.07426581413829768, 'approx_kl': 0.022028650855645537, 'clip_fraction': 0.5, 'grad_norm': 3.6148083209991455}
2023-01-03 21:29:33.820 DEBUG: Taking gradient step
2023-01-03 21:29:33.830 DEBUG: Loss 6: {'policy_loss': -0.0020551076354523856, 'entropy_loss': -0.07190226577222347, 'vf_loss': 0.008366254680383562, 'total_loss': -0.06559111872729231, 'approx_kl': 0.023513785941759124, 'clip_fraction': 0.48828125, 'grad_norm': 3.591545343399048}
2023-01-03 21:29:34.990 DEBUG: Taking gradient step
2023-01-03 21:29:35.000 DEBUG: Loss 7: {'policy_loss': -0.05694971641085496, 'entropy_loss': -0.07140344195067883, 'vf_loss': 0.006350215874698978, 'total_loss': -0.1220029424868348, 'approx_kl': 0.02204427181277424, 'clip_fraction': 0.5, 'grad_norm': 4.16756534576416}
2023-01-03 21:29:36.031 DEBUG: Early stopping at step 8 for reaching max KL.
2023-01-03 21:29:36.031 INFO: Optimization: policy loss=-0.057, vf loss=0.006, entropy loss=-0.071, total loss=-0.122, num steps=8
2023-01-03 21:29:36.031 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:29:37.771 INFO: Evaluation rollout: return=0.574 (0.0), episode length=6.0
2023-01-03 21:29:37.772 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:29:37.775 INFO: Iteration: 64/137, steps: 13824
2023-01-03 21:29:52.694 DEBUG: Atoms are too close
2023-01-03 21:30:11.276 DEBUG: Atoms are too close
2023-01-03 21:30:30.852 DEBUG: Atoms are too close
2023-01-03 21:30:34.867 DEBUG: Atoms are too close
2023-01-03 21:30:35.230 INFO: Training rollout: return=-1.109 (4.8), episode length=5.9
2023-01-03 21:30:35.231 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:30:35.234 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-13824_train.pkl
2023-01-03 21:30:36.271 DEBUG: Taking gradient step
2023-01-03 21:30:36.280 DEBUG: Loss 0: {'policy_loss': 0.01252410287529989, 'entropy_loss': -0.07100239023566246, 'vf_loss': 0.01482105592076785, 'total_loss': -0.04365723143959472, 'approx_kl': -3.213062882423401e-08, 'clip_fraction': 0.0, 'grad_norm': 15.67848014831543}
2023-01-03 21:30:37.305 DEBUG: Taking gradient step
2023-01-03 21:30:37.315 DEBUG: Loss 1: {'policy_loss': -0.020922830431443124, 'entropy_loss': -0.06981227546930313, 'vf_loss': 0.013631915639766696, 'total_loss': -0.07710319026097956, 'approx_kl': 0.0036888367030769587, 'clip_fraction': 0.09244791697710752, 'grad_norm': 12.470609664916992}
2023-01-03 21:30:38.348 DEBUG: Taking gradient step
2023-01-03 21:30:38.357 DEBUG: Loss 2: {'policy_loss': 0.055528183976851726, 'entropy_loss': -0.07067113928496838, 'vf_loss': 0.01855408250090404, 'total_loss': 0.003411127192787397, 'approx_kl': 0.035106829134747386, 'clip_fraction': 0.2552083358168602, 'grad_norm': 8.955397605895996}
2023-01-03 21:30:39.373 DEBUG: Taking gradient step
2023-01-03 21:30:39.383 DEBUG: Loss 3: {'policy_loss': -0.03166255060721907, 'entropy_loss': -0.0697593204677105, 'vf_loss': 0.013804093145507606, 'total_loss': -0.08761777792942196, 'approx_kl': 0.026875399285927415, 'clip_fraction': 0.35546875, 'grad_norm': 9.646554946899414}
2023-01-03 21:30:40.431 DEBUG: Taking gradient step
2023-01-03 21:30:40.442 DEBUG: Loss 4: {'policy_loss': -0.010094318439359755, 'entropy_loss': -0.06925034709274769, 'vf_loss': 0.015600993999925896, 'total_loss': -0.06374367153218155, 'approx_kl': 0.03653425630182028, 'clip_fraction': 0.4466145858168602, 'grad_norm': 5.621979236602783}
2023-01-03 21:30:41.480 DEBUG: Early stopping at step 5 for reaching max KL.
2023-01-03 21:30:41.481 INFO: Optimization: policy loss=-0.010, vf loss=0.016, entropy loss=-0.069, total loss=-0.064, num steps=5
2023-01-03 21:30:41.482 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:30:43.208 INFO: Evaluation rollout: return=0.575 (0.0), episode length=6.0
2023-01-03 21:30:43.209 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:30:43.212 INFO: Iteration: 65/137, steps: 14040
2023-01-03 21:30:59.435 DEBUG: There is a single atom floating around
2023-01-03 21:31:11.269 DEBUG: Atoms are too close
2023-01-03 21:31:21.133 DEBUG: There is a single atom floating around
2023-01-03 21:31:40.628 INFO: Training rollout: return=-0.703 (4.2), episode length=5.9
2023-01-03 21:31:40.629 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:31:40.632 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-14040_train.pkl
2023-01-03 21:31:41.635 DEBUG: Taking gradient step
2023-01-03 21:31:41.646 DEBUG: Loss 0: {'policy_loss': -0.040884478765130176, 'entropy_loss': -0.0710228905081749, 'vf_loss': 0.009052378967375258, 'total_loss': -0.1028549903059298, 'approx_kl': -7.446700323043842e-08, 'clip_fraction': 0.0, 'grad_norm': 16.789159774780273}
2023-01-03 21:31:42.674 DEBUG: Taking gradient step
2023-01-03 21:31:42.684 DEBUG: Loss 1: {'policy_loss': 0.025558689518553217, 'entropy_loss': -0.06975041888654232, 'vf_loss': 0.012864424352633245, 'total_loss': -0.03132730501535585, 'approx_kl': 0.035795232746750116, 'clip_fraction': 0.1705729179084301, 'grad_norm': 10.914158821105957}
2023-01-03 21:31:43.724 DEBUG: Early stopping at step 2 for reaching max KL.
2023-01-03 21:31:43.725 INFO: Optimization: policy loss=0.026, vf loss=0.013, entropy loss=-0.070, total loss=-0.031, num steps=2
2023-01-03 21:31:43.725 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:31:45.469 INFO: Evaluation rollout: return=0.578 (0.0), episode length=6.0
2023-01-03 21:31:45.471 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:31:45.474 INFO: Iteration: 66/137, steps: 14256
2023-01-03 21:32:24.274 DEBUG: Atoms are too close
2023-01-03 21:32:43.744 INFO: Training rollout: return=0.195 (2.2), episode length=6.0
2023-01-03 21:32:43.745 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:32:43.748 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-14256_train.pkl
2023-01-03 21:32:44.817 DEBUG: Taking gradient step
2023-01-03 21:32:44.827 DEBUG: Loss 0: {'policy_loss': -0.021002738846947727, 'entropy_loss': -0.07163409516215324, 'vf_loss': 0.0034951735232428825, 'total_loss': -0.08914166048585809, 'approx_kl': 9.701277114970708e-09, 'clip_fraction': 0.0, 'grad_norm': 7.1710405349731445}
2023-01-03 21:32:45.879 DEBUG: Taking gradient step
2023-01-03 21:32:45.888 DEBUG: Loss 1: {'policy_loss': -0.027135801279287143, 'entropy_loss': -0.071768868714571, 'vf_loss': 0.0035035654787489573, 'total_loss': -0.09540110451510918, 'approx_kl': 0.00021653738804161549, 'clip_fraction': 0.0703125, 'grad_norm': 6.519010066986084}
2023-01-03 21:32:46.894 DEBUG: Taking gradient step
2023-01-03 21:32:46.905 DEBUG: Loss 2: {'policy_loss': 0.005693513864231323, 'entropy_loss': -0.0726506058126688, 'vf_loss': 0.005045373297128406, 'total_loss': -0.06191171865130908, 'approx_kl': 0.009445505449548364, 'clip_fraction': 0.14453125, 'grad_norm': 6.977330684661865}
2023-01-03 21:32:47.948 DEBUG: Taking gradient step
2023-01-03 21:32:47.957 DEBUG: Loss 3: {'policy_loss': -0.01545145625795513, 'entropy_loss': -0.07384066842496395, 'vf_loss': 0.005086937738253888, 'total_loss': -0.0842051869446652, 'approx_kl': 0.008664609398692846, 'clip_fraction': 0.2513020858168602, 'grad_norm': 5.0029520988464355}
2023-01-03 21:32:48.992 DEBUG: Taking gradient step
2023-01-03 21:32:49.002 DEBUG: Loss 4: {'policy_loss': -0.050826061156714945, 'entropy_loss': -0.07283127307891846, 'vf_loss': 0.003523350830664667, 'total_loss': -0.12013398340496872, 'approx_kl': 0.014761576894670725, 'clip_fraction': 0.3346354216337204, 'grad_norm': 3.6463770866394043}
2023-01-03 21:32:50.041 DEBUG: Taking gradient step
2023-01-03 21:32:50.051 DEBUG: Loss 5: {'policy_loss': -0.004667518518484855, 'entropy_loss': -0.07335965149104595, 'vf_loss': 0.00468707633147903, 'total_loss': -0.07334009367805178, 'approx_kl': 0.020998917636461556, 'clip_fraction': 0.4739583358168602, 'grad_norm': 2.859828472137451}
2023-01-03 21:32:51.089 DEBUG: Taking gradient step
2023-01-03 21:32:51.100 DEBUG: Loss 6: {'policy_loss': -0.014024835641229257, 'entropy_loss': -0.07436996325850487, 'vf_loss': 0.004622477369865759, 'total_loss': -0.08377232152986837, 'approx_kl': 0.0373631096445024, 'clip_fraction': 0.51171875, 'grad_norm': 2.0956766605377197}
2023-01-03 21:32:52.127 DEBUG: Early stopping at step 7 for reaching max KL.
2023-01-03 21:32:52.127 INFO: Optimization: policy loss=-0.014, vf loss=0.005, entropy loss=-0.074, total loss=-0.084, num steps=7
2023-01-03 21:32:52.128 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:32:53.873 INFO: Evaluation rollout: return=0.583 (0.0), episode length=6.0
2023-01-03 21:32:53.875 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:32:53.877 INFO: Iteration: 67/137, steps: 14472
2023-01-03 21:33:53.162 INFO: Training rollout: return=0.573 (0.1), episode length=6.0
2023-01-03 21:33:53.163 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:33:53.166 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-14472_train.pkl
2023-01-03 21:33:54.214 DEBUG: Taking gradient step
2023-01-03 21:33:54.223 DEBUG: Loss 0: {'policy_loss': 0.02311014732248025, 'entropy_loss': -0.07411902211606503, 'vf_loss': 0.0004834120872360516, 'total_loss': -0.05052546270634872, 'approx_kl': -8.350859559413948e-08, 'clip_fraction': 0.0, 'grad_norm': 11.21741008758545}
2023-01-03 21:33:55.248 DEBUG: Taking gradient step
2023-01-03 21:33:55.259 DEBUG: Loss 1: {'policy_loss': -0.036650159189528575, 'entropy_loss': -0.07414171285927296, 'vf_loss': 0.00045735019365027954, 'total_loss': -0.11033452185515126, 'approx_kl': -0.006086956826038659, 'clip_fraction': 0.03515625, 'grad_norm': 8.195723533630371}
2023-01-03 21:33:56.240 DEBUG: Taking gradient step
2023-01-03 21:33:56.250 DEBUG: Loss 2: {'policy_loss': -0.01134488299465146, 'entropy_loss': -0.07481647655367851, 'vf_loss': 0.00038893921552272405, 'total_loss': -0.08577242033280726, 'approx_kl': -0.011621915036812425, 'clip_fraction': 0.18359375, 'grad_norm': 11.14590835571289}
2023-01-03 21:33:57.270 DEBUG: Taking gradient step
2023-01-03 21:33:57.281 DEBUG: Loss 3: {'policy_loss': 0.012310281072540112, 'entropy_loss': -0.07495990954339504, 'vf_loss': 0.0003379687762510778, 'total_loss': -0.062311659694603866, 'approx_kl': -0.005192383658140898, 'clip_fraction': 0.2604166716337204, 'grad_norm': 12.754582405090332}
2023-01-03 21:33:58.302 DEBUG: Taking gradient step
2023-01-03 21:33:58.312 DEBUG: Loss 4: {'policy_loss': -0.045397822966302126, 'entropy_loss': -0.07508417591452599, 'vf_loss': 0.00029865472716340027, 'total_loss': -0.12018334415366472, 'approx_kl': -0.009143399307504296, 'clip_fraction': 0.30078125, 'grad_norm': 11.068048477172852}
2023-01-03 21:33:59.330 DEBUG: Taking gradient step
2023-01-03 21:33:59.341 DEBUG: Loss 5: {'policy_loss': 0.020977364940212836, 'entropy_loss': -0.07513699680566788, 'vf_loss': 0.0002449629935907161, 'total_loss': -0.05391466887186431, 'approx_kl': 0.03218216309323907, 'clip_fraction': 0.34375, 'grad_norm': 6.365002632141113}
2023-01-03 21:34:00.371 DEBUG: Taking gradient step
2023-01-03 21:34:00.380 DEBUG: Loss 6: {'policy_loss': -0.06873206958509673, 'entropy_loss': -0.07495872676372528, 'vf_loss': 0.0002237680647307584, 'total_loss': -0.14346702828409125, 'approx_kl': 0.024244199972599745, 'clip_fraction': 0.37890625, 'grad_norm': 10.03137493133545}
2023-01-03 21:34:01.410 DEBUG: Early stopping at step 7 for reaching max KL.
2023-01-03 21:34:01.410 INFO: Optimization: policy loss=-0.069, vf loss=0.000, entropy loss=-0.075, total loss=-0.143, num steps=7
2023-01-03 21:34:01.411 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:34:03.118 INFO: Evaluation rollout: return=0.579 (0.0), episode length=6.0
2023-01-03 21:34:03.119 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:34:03.121 INFO: Iteration: 68/137, steps: 14688
2023-01-03 21:35:01.921 INFO: Training rollout: return=0.558 (0.1), episode length=6.0
2023-01-03 21:35:01.923 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:35:01.925 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-14688_train.pkl
2023-01-03 21:35:02.890 DEBUG: Taking gradient step
2023-01-03 21:35:02.899 DEBUG: Loss 0: {'policy_loss': -0.004325931220253487, 'entropy_loss': -0.0766067672520876, 'vf_loss': 0.0001986096028378772, 'total_loss': -0.0807340888695032, 'approx_kl': -8.606972912161837e-08, 'clip_fraction': 0.0, 'grad_norm': 12.664031982421875}
2023-01-03 21:35:03.910 DEBUG: Taking gradient step
2023-01-03 21:35:03.919 DEBUG: Loss 1: {'policy_loss': -0.07271810473763596, 'entropy_loss': -0.07595783658325672, 'vf_loss': 0.0001759669798629017, 'total_loss': -0.14849997434102977, 'approx_kl': 0.00791582535021007, 'clip_fraction': 0.04296875, 'grad_norm': 10.240910530090332}
2023-01-03 21:35:04.938 DEBUG: Taking gradient step
2023-01-03 21:35:04.947 DEBUG: Loss 2: {'policy_loss': 0.023590948833816648, 'entropy_loss': -0.07602312229573727, 'vf_loss': 0.0001417485838968705, 'total_loss': -0.052290424878023746, 'approx_kl': 0.021885770955123007, 'clip_fraction': 0.2421875, 'grad_norm': 8.325186729431152}
2023-01-03 21:35:05.966 DEBUG: Taking gradient step
2023-01-03 21:35:05.975 DEBUG: Loss 3: {'policy_loss': 0.03984426725574012, 'entropy_loss': -0.07664663158357143, 'vf_loss': 0.00012126887484736071, 'total_loss': -0.03668109545298394, 'approx_kl': 0.03422245057299733, 'clip_fraction': 0.328125, 'grad_norm': 9.199845314025879}
2023-01-03 21:35:06.985 DEBUG: Taking gradient step
2023-01-03 21:35:06.996 DEBUG: Loss 4: {'policy_loss': -0.01506413539380459, 'entropy_loss': -0.07703924551606178, 'vf_loss': 0.00010114646426148341, 'total_loss': -0.09200223444560487, 'approx_kl': 0.030643821693956852, 'clip_fraction': 0.34375, 'grad_norm': 8.8593111038208}
2023-01-03 21:35:08.045 DEBUG: Taking gradient step
2023-01-03 21:35:08.055 DEBUG: Loss 5: {'policy_loss': -0.020473259039048113, 'entropy_loss': -0.07615086808800697, 'vf_loss': 8.717982696686398e-05, 'total_loss': -0.09653694730008823, 'approx_kl': 0.0325097672175616, 'clip_fraction': 0.3528645858168602, 'grad_norm': 10.033252716064453}
2023-01-03 21:35:09.104 DEBUG: Taking gradient step
2023-01-03 21:35:09.115 DEBUG: Loss 6: {'policy_loss': -0.05524684624162176, 'entropy_loss': -0.07617783360183239, 'vf_loss': 7.635905542128077e-05, 'total_loss': -0.13134832078803288, 'approx_kl': 0.020180736668407917, 'clip_fraction': 0.2825520858168602, 'grad_norm': 5.437487602233887}
2023-01-03 21:35:10.164 DEBUG: Taking gradient step
2023-01-03 21:35:10.175 DEBUG: Loss 7: {'policy_loss': -0.045614331713168345, 'entropy_loss': -0.07642343640327454, 'vf_loss': 5.973969908870845e-05, 'total_loss': -0.1219780284173542, 'approx_kl': 0.006753224181011319, 'clip_fraction': 0.3450520858168602, 'grad_norm': 8.332086563110352}
2023-01-03 21:35:11.223 DEBUG: Taking gradient step
2023-01-03 21:35:11.236 DEBUG: Loss 8: {'policy_loss': -0.060614744319311735, 'entropy_loss': -0.07519642822444439, 'vf_loss': 5.4264149497269335e-05, 'total_loss': -0.13575690839425886, 'approx_kl': 0.008696547709405422, 'clip_fraction': 0.3723958358168602, 'grad_norm': 9.948851585388184}
2023-01-03 21:35:12.201 DEBUG: Taking gradient step
2023-01-03 21:35:12.211 DEBUG: Loss 9: {'policy_loss': 0.013876026849425932, 'entropy_loss': -0.07609102502465248, 'vf_loss': 4.577912199719086e-05, 'total_loss': -0.06216921905322936, 'approx_kl': 0.015576448990032077, 'clip_fraction': 0.4270833358168602, 'grad_norm': 9.802718162536621}
2023-01-03 21:35:13.220 DEBUG: Taking gradient step
2023-01-03 21:35:13.230 DEBUG: Loss 10: {'policy_loss': -0.009420148762114909, 'entropy_loss': -0.07665061205625534, 'vf_loss': 3.840908373422068e-05, 'total_loss': -0.08603235173463603, 'approx_kl': 0.0009521571919322014, 'clip_fraction': 0.5130208432674408, 'grad_norm': 9.658208847045898}
2023-01-03 21:35:14.261 DEBUG: Taking gradient step
2023-01-03 21:35:14.270 DEBUG: Loss 11: {'policy_loss': -0.018617613792560557, 'entropy_loss': -0.07646194845438004, 'vf_loss': 3.971257386062466e-05, 'total_loss': -0.09503984967307996, 'approx_kl': 0.011109958402812481, 'clip_fraction': 0.4947916716337204, 'grad_norm': 4.91492223739624}
2023-01-03 21:35:15.300 DEBUG: Taking gradient step
2023-01-03 21:35:15.309 DEBUG: Loss 12: {'policy_loss': -0.06431484890070222, 'entropy_loss': -0.07662513107061386, 'vf_loss': 4.0972088290393504e-05, 'total_loss': -0.14089900788302567, 'approx_kl': 0.029831350315362215, 'clip_fraction': 0.54296875, 'grad_norm': 5.669213771820068}
2023-01-03 21:35:16.361 DEBUG: Early stopping at step 13 for reaching max KL.
2023-01-03 21:35:16.361 INFO: Optimization: policy loss=-0.064, vf loss=0.000, entropy loss=-0.077, total loss=-0.141, num steps=13
2023-01-03 21:35:16.362 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:35:18.133 INFO: Evaluation rollout: return=0.562 (0.0), episode length=6.0
2023-01-03 21:35:18.134 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:35:18.136 INFO: Iteration: 69/137, steps: 14904
2023-01-03 21:35:33.204 DEBUG: Atoms are too close
2023-01-03 21:36:11.891 DEBUG: Atoms are too close
2023-01-03 21:36:15.640 INFO: Training rollout: return=-0.316 (3.6), episode length=5.9
2023-01-03 21:36:15.642 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:36:15.644 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-14904_train.pkl
2023-01-03 21:36:16.689 DEBUG: Taking gradient step
2023-01-03 21:36:16.699 DEBUG: Loss 0: {'policy_loss': -0.010656211895057267, 'entropy_loss': -0.0749283991754055, 'vf_loss': 0.006778819699084445, 'total_loss': -0.07880579137137832, 'approx_kl': -1.9829410113914037e-08, 'clip_fraction': 0.0, 'grad_norm': 18.486894607543945}
2023-01-03 21:36:17.700 DEBUG: Taking gradient step
2023-01-03 21:36:17.708 DEBUG: Loss 1: {'policy_loss': -0.0326684948744746, 'entropy_loss': -0.07532456517219543, 'vf_loss': 0.006789752106128226, 'total_loss': -0.10120330794054182, 'approx_kl': -0.00023405649699270725, 'clip_fraction': 0.08854166697710752, 'grad_norm': 9.316460609436035}
2023-01-03 21:36:18.735 DEBUG: Taking gradient step
2023-01-03 21:36:18.744 DEBUG: Loss 2: {'policy_loss': 0.06541058183345888, 'entropy_loss': -0.07527263276278973, 'vf_loss': 0.011708569552304263, 'total_loss': 0.001846518622973442, 'approx_kl': 0.033304897136986256, 'clip_fraction': 0.26953125, 'grad_norm': 2.99841046333313}
2023-01-03 21:36:19.727 DEBUG: Early stopping at step 3 for reaching max KL.
2023-01-03 21:36:19.728 INFO: Optimization: policy loss=0.065, vf loss=0.012, entropy loss=-0.075, total loss=0.002, num steps=3
2023-01-03 21:36:19.729 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:36:21.434 INFO: Evaluation rollout: return=0.562 (0.0), episode length=6.0
2023-01-03 21:36:21.436 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:36:21.438 INFO: Iteration: 70/137, steps: 15120
2023-01-03 21:37:17.550 DEBUG: Atoms are too close
2023-01-03 21:37:19.329 INFO: Training rollout: return=0.144 (2.2), episode length=6.0
2023-01-03 21:37:19.331 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:37:19.333 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-15120_train.pkl
2023-01-03 21:37:20.396 DEBUG: Taking gradient step
2023-01-03 21:37:20.407 DEBUG: Loss 0: {'policy_loss': -0.01966949861356789, 'entropy_loss': -0.07628971338272095, 'vf_loss': 0.0033429507852301807, 'total_loss': -0.09261626121105865, 'approx_kl': -4.3422915041446686e-08, 'clip_fraction': 0.0, 'grad_norm': 11.599564552307129}
2023-01-03 21:37:21.455 DEBUG: Taking gradient step
2023-01-03 21:37:21.465 DEBUG: Loss 1: {'policy_loss': -0.03544856906632957, 'entropy_loss': -0.07590854540467262, 'vf_loss': 0.0033263236197660076, 'total_loss': -0.10803079085123618, 'approx_kl': 0.007687925826758146, 'clip_fraction': 0.08984375, 'grad_norm': 6.63950252532959}
2023-01-03 21:37:22.516 DEBUG: Taking gradient step
2023-01-03 21:37:22.526 DEBUG: Loss 2: {'policy_loss': 0.014886065041048793, 'entropy_loss': -0.07579790987074375, 'vf_loss': 0.0050542777930463224, 'total_loss': -0.05585756703664863, 'approx_kl': 0.042663498781621456, 'clip_fraction': 0.3151041716337204, 'grad_norm': 2.328748941421509}
2023-01-03 21:37:23.565 DEBUG: Early stopping at step 3 for reaching max KL.
2023-01-03 21:37:23.566 INFO: Optimization: policy loss=0.015, vf loss=0.005, entropy loss=-0.076, total loss=-0.056, num steps=3
2023-01-03 21:37:23.567 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:37:25.353 INFO: Evaluation rollout: return=0.567 (0.0), episode length=6.0
2023-01-03 21:37:25.355 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:37:25.357 DEBUG: Deleting old model: runs/CH3NO_baseline/models/CH3NO_baseline_run-1_steps-13176.model
2023-01-03 21:37:25.359 DEBUG: Saving model: runs/CH3NO_baseline/models/CH3NO_baseline_run-1_steps-15336.model
2023-01-03 21:37:25.390 INFO: Iteration: 71/137, steps: 15336
2023-01-03 21:38:13.954 DEBUG: Atoms are too close
2023-01-03 21:38:23.538 INFO: Training rollout: return=-0.013 (3.0), episode length=5.9
2023-01-03 21:38:23.539 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:38:23.542 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-15336_train.pkl
2023-01-03 21:38:24.593 DEBUG: Taking gradient step
2023-01-03 21:38:24.603 DEBUG: Loss 0: {'policy_loss': -0.025488778791208096, 'entropy_loss': -0.07653605379164219, 'vf_loss': 0.0027663139496315057, 'total_loss': -0.09925851863321877, 'approx_kl': -4.190951585769653e-09, 'clip_fraction': 0.0, 'grad_norm': 13.173802375793457}
2023-01-03 21:38:25.629 DEBUG: Taking gradient step
2023-01-03 21:38:25.639 DEBUG: Loss 1: {'policy_loss': -0.029007456053073238, 'entropy_loss': -0.07717409357428551, 'vf_loss': 0.002773094031172406, 'total_loss': -0.10340845559618633, 'approx_kl': 0.014283827738836408, 'clip_fraction': 0.0703125, 'grad_norm': 3.5656301975250244}
2023-01-03 21:38:26.669 DEBUG: Taking gradient step
2023-01-03 21:38:26.679 DEBUG: Loss 2: {'policy_loss': -0.03726533119138569, 'entropy_loss': -0.07787379249930382, 'vf_loss': 0.0027478942112334056, 'total_loss': -0.1123912294794561, 'approx_kl': 0.03048026072792709, 'clip_fraction': 0.2565104216337204, 'grad_norm': 4.431694984436035}
2023-01-03 21:38:27.716 DEBUG: Early stopping at step 3 for reaching max KL.
2023-01-03 21:38:27.717 INFO: Optimization: policy loss=-0.037, vf loss=0.003, entropy loss=-0.078, total loss=-0.112, num steps=3
2023-01-03 21:38:27.717 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:38:29.425 INFO: Evaluation rollout: return=0.567 (0.0), episode length=6.0
2023-01-03 21:38:29.427 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:38:29.430 INFO: Iteration: 72/137, steps: 15552
2023-01-03 21:38:45.554 DEBUG: Atoms are too close
2023-01-03 21:38:47.303 DEBUG: Atoms are too close
2023-01-03 21:39:05.375 DEBUG: Atoms are too close
2023-01-03 21:39:27.686 INFO: Training rollout: return=-0.559 (3.7), episode length=6.0
2023-01-03 21:39:27.687 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:39:27.690 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-15552_train.pkl
2023-01-03 21:39:28.745 DEBUG: Taking gradient step
2023-01-03 21:39:28.754 DEBUG: Loss 0: {'policy_loss': -0.04801396484678458, 'entropy_loss': -0.07787729054689407, 'vf_loss': 0.009690921878323716, 'total_loss': -0.11620033351535493, 'approx_kl': 1.7617519887380695e-08, 'clip_fraction': 0.0, 'grad_norm': 12.845818519592285}
2023-01-03 21:39:29.795 DEBUG: Taking gradient step
2023-01-03 21:39:29.804 DEBUG: Loss 1: {'policy_loss': 0.07899660633187525, 'entropy_loss': -0.07954550348222256, 'vf_loss': 0.015508677555354962, 'total_loss': 0.014959780405007658, 'approx_kl': 0.021581091918051243, 'clip_fraction': 0.0885416679084301, 'grad_norm': 10.644023895263672}
2023-01-03 21:39:30.843 DEBUG: Early stopping at step 2 for reaching max KL.
2023-01-03 21:39:30.843 INFO: Optimization: policy loss=0.079, vf loss=0.016, entropy loss=-0.080, total loss=0.015, num steps=2
2023-01-03 21:39:30.844 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:39:32.570 INFO: Evaluation rollout: return=0.563 (0.0), episode length=6.0
2023-01-03 21:39:32.571 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:39:32.574 INFO: Iteration: 73/137, steps: 15768
2023-01-03 21:40:31.379 INFO: Training rollout: return=0.553 (0.0), episode length=6.0
2023-01-03 21:40:31.381 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:40:31.384 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-15768_train.pkl
2023-01-03 21:40:32.446 DEBUG: Taking gradient step
2023-01-03 21:40:32.455 DEBUG: Loss 0: {'policy_loss': 0.0013242517589088358, 'entropy_loss': -0.0782543197274208, 'vf_loss': 7.441564641050971e-05, 'total_loss': -0.07685565232210147, 'approx_kl': 6.418364861815462e-08, 'clip_fraction': 0.0, 'grad_norm': 15.36319351196289}
2023-01-03 21:40:33.482 DEBUG: Taking gradient step
2023-01-03 21:40:33.491 DEBUG: Loss 1: {'policy_loss': 0.03256303497698384, 'entropy_loss': -0.07904751598834991, 'vf_loss': 8.29986123416184e-05, 'total_loss': -0.04640148239902447, 'approx_kl': -0.0006320350803434849, 'clip_fraction': 0.01171875, 'grad_norm': 15.25624942779541}
2023-01-03 21:40:34.532 DEBUG: Taking gradient step
2023-01-03 21:40:34.540 DEBUG: Loss 2: {'policy_loss': 0.04365020661841791, 'entropy_loss': -0.0806549321860075, 'vf_loss': 9.261054446110697e-05, 'total_loss': -0.036912115023128494, 'approx_kl': -0.0014379560016095638, 'clip_fraction': 0.1380208358168602, 'grad_norm': 18.406991958618164}
2023-01-03 21:40:35.540 DEBUG: Taking gradient step
2023-01-03 21:40:35.551 DEBUG: Loss 3: {'policy_loss': 0.04847740607888893, 'entropy_loss': -0.07999534346163273, 'vf_loss': 0.00010198059605151021, 'total_loss': -0.03141595678669229, 'approx_kl': 0.008350907126441598, 'clip_fraction': 0.2643229216337204, 'grad_norm': 17.024290084838867}
2023-01-03 21:40:36.652 DEBUG: Taking gradient step
2023-01-03 21:40:36.665 DEBUG: Loss 4: {'policy_loss': -0.047627902967185484, 'entropy_loss': -0.07972456887364388, 'vf_loss': 0.00011527882401416487, 'total_loss': -0.1272371930168152, 'approx_kl': 0.018848299514502287, 'clip_fraction': 0.359375, 'grad_norm': 8.86687183380127}
2023-01-03 21:40:37.808 DEBUG: Taking gradient step
2023-01-03 21:40:37.818 DEBUG: Loss 5: {'policy_loss': -0.02983571028818413, 'entropy_loss': -0.0794165413826704, 'vf_loss': 0.0001193597294506512, 'total_loss': -0.10913289194140388, 'approx_kl': 0.02179838251322508, 'clip_fraction': 0.3645833358168602, 'grad_norm': 11.979854583740234}
2023-01-03 21:40:38.861 DEBUG: Early stopping at step 6 for reaching max KL.
2023-01-03 21:40:38.861 INFO: Optimization: policy loss=-0.030, vf loss=0.000, entropy loss=-0.079, total loss=-0.109, num steps=6
2023-01-03 21:40:38.861 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:40:40.564 INFO: Evaluation rollout: return=0.570 (0.0), episode length=6.0
2023-01-03 21:40:40.565 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:40:40.569 INFO: Iteration: 74/137, steps: 15984
2023-01-03 21:41:17.716 DEBUG: Atoms are too close
2023-01-03 21:41:38.463 INFO: Training rollout: return=0.158 (2.2), episode length=6.0
2023-01-03 21:41:38.465 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:41:38.468 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-15984_train.pkl
2023-01-03 21:41:39.496 DEBUG: Taking gradient step
2023-01-03 21:41:39.505 DEBUG: Loss 0: {'policy_loss': -0.026216194247485787, 'entropy_loss': -0.08188400790095329, 'vf_loss': 0.0032544810502085687, 'total_loss': -0.10484572109823052, 'approx_kl': 7.268196711152086e-08, 'clip_fraction': 0.0, 'grad_norm': 9.066944122314453}
2023-01-03 21:41:40.534 DEBUG: Taking gradient step
2023-01-03 21:41:40.543 DEBUG: Loss 1: {'policy_loss': 0.0014948740541080724, 'entropy_loss': -0.08167877793312073, 'vf_loss': 0.004475023170557936, 'total_loss': -0.07570888070845472, 'approx_kl': 0.004224960692226887, 'clip_fraction': 0.06640625, 'grad_norm': 4.104989051818848}
2023-01-03 21:41:41.572 DEBUG: Taking gradient step
2023-01-03 21:41:41.581 DEBUG: Loss 2: {'policy_loss': -0.03861669054256611, 'entropy_loss': -0.0820856187492609, 'vf_loss': 0.003250953946203489, 'total_loss': -0.11745135534562352, 'approx_kl': 0.032538967207074165, 'clip_fraction': 0.2591145858168602, 'grad_norm': 3.3933303356170654}
2023-01-03 21:41:42.604 DEBUG: Taking gradient step
2023-01-03 21:41:42.616 DEBUG: Loss 3: {'policy_loss': -0.04137363315270418, 'entropy_loss': -0.08118537440896034, 'vf_loss': 0.003249164714883994, 'total_loss': -0.11930984284678053, 'approx_kl': 0.03668273729272187, 'clip_fraction': 0.2994791716337204, 'grad_norm': 2.8726584911346436}
2023-01-03 21:41:43.548 DEBUG: Taking gradient step
2023-01-03 21:41:43.556 DEBUG: Loss 4: {'policy_loss': -0.04538889883721364, 'entropy_loss': -0.08148279972374439, 'vf_loss': 0.0032482806563964716, 'total_loss': -0.12362341790456158, 'approx_kl': 0.043746650917455554, 'clip_fraction': 0.3059895858168602, 'grad_norm': 3.2724180221557617}
2023-01-03 21:41:44.584 DEBUG: Early stopping at step 5 for reaching max KL.
2023-01-03 21:41:44.585 INFO: Optimization: policy loss=-0.045, vf loss=0.003, entropy loss=-0.081, total loss=-0.124, num steps=5
2023-01-03 21:41:44.586 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:41:46.210 INFO: Evaluation rollout: return=0.565 (0.0), episode length=6.0
2023-01-03 21:41:46.211 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:41:46.214 INFO: Iteration: 75/137, steps: 16200
2023-01-03 21:42:01.642 DEBUG: Atoms are too close
2023-01-03 21:42:40.774 INFO: Training rollout: return=0.129 (2.2), episode length=6.0
2023-01-03 21:42:40.776 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:42:40.779 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-16200_train.pkl
2023-01-03 21:42:41.817 DEBUG: Taking gradient step
2023-01-03 21:42:41.827 DEBUG: Loss 0: {'policy_loss': -0.027553909427567774, 'entropy_loss': -0.08112036250531673, 'vf_loss': 0.003205003722164431, 'total_loss': -0.10546926821072007, 'approx_kl': -3.391566494315157e-08, 'clip_fraction': 0.0, 'grad_norm': 15.63240909576416}
2023-01-03 21:42:42.855 DEBUG: Taking gradient step
2023-01-03 21:42:42.865 DEBUG: Loss 1: {'policy_loss': 0.01198201441060101, 'entropy_loss': -0.08125710859894753, 'vf_loss': 0.004270077452429752, 'total_loss': -0.06500501673591677, 'approx_kl': 0.006032823817804456, 'clip_fraction': 0.1549479179084301, 'grad_norm': 9.080334663391113}
2023-01-03 21:42:43.873 DEBUG: Taking gradient step
2023-01-03 21:42:43.882 DEBUG: Loss 2: {'policy_loss': -0.041457922460422916, 'entropy_loss': -0.08192100189626217, 'vf_loss': 0.003200871260380076, 'total_loss': -0.12017805309630501, 'approx_kl': 0.02432737941853702, 'clip_fraction': 0.2994791716337204, 'grad_norm': 3.6434574127197266}
2023-01-03 21:42:44.905 DEBUG: Taking gradient step
2023-01-03 21:42:44.915 DEBUG: Loss 3: {'policy_loss': -0.01302073476246039, 'entropy_loss': -0.08226278424263, 'vf_loss': 0.004044766632931363, 'total_loss': -0.09123875237215903, 'approx_kl': 0.03418292081914842, 'clip_fraction': 0.4192708432674408, 'grad_norm': 4.237185955047607}
2023-01-03 21:42:45.879 DEBUG: Taking gradient step
2023-01-03 21:42:45.888 DEBUG: Loss 4: {'policy_loss': -0.04481420738238032, 'entropy_loss': -0.08062716946005821, 'vf_loss': 0.003199725445925042, 'total_loss': -0.1222416513965135, 'approx_kl': 0.010557088069617748, 'clip_fraction': 0.4192708358168602, 'grad_norm': 3.3023083209991455}
2023-01-03 21:42:46.908 DEBUG: Taking gradient step
2023-01-03 21:42:46.917 DEBUG: Loss 5: {'policy_loss': -0.022081858879192645, 'entropy_loss': -0.08188963122665882, 'vf_loss': 0.00352223286769022, 'total_loss': -0.10044925723816124, 'approx_kl': 0.005677144508808851, 'clip_fraction': 0.4348958358168602, 'grad_norm': 2.4080564975738525}
2023-01-03 21:42:47.947 DEBUG: Taking gradient step
2023-01-03 21:42:47.956 DEBUG: Loss 6: {'policy_loss': -0.025820888811680296, 'entropy_loss': -0.08108780346810818, 'vf_loss': 0.003525493295425376, 'total_loss': -0.1033831989843631, 'approx_kl': 0.00012198509648442268, 'clip_fraction': 0.38671875, 'grad_norm': 2.225314140319824}
2023-01-03 21:42:48.948 DEBUG: Taking gradient step
2023-01-03 21:42:48.958 DEBUG: Loss 7: {'policy_loss': -0.0441796149982855, 'entropy_loss': -0.08165330067276955, 'vf_loss': 0.003199024490716368, 'total_loss': -0.12263389118033868, 'approx_kl': -0.004984854138456285, 'clip_fraction': 0.4114583358168602, 'grad_norm': 8.686779022216797}
2023-01-03 21:42:49.980 DEBUG: Taking gradient step
2023-01-03 21:42:49.989 DEBUG: Loss 8: {'policy_loss': -0.01778367381017386, 'entropy_loss': -0.08106694556772709, 'vf_loss': 0.003812406099699464, 'total_loss': -0.09503821327820147, 'approx_kl': -0.007086790166795254, 'clip_fraction': 0.4934895932674408, 'grad_norm': 8.87738037109375}
2023-01-03 21:42:51.003 DEBUG: Taking gradient step
2023-01-03 21:42:51.012 DEBUG: Loss 9: {'policy_loss': -0.006873650153170107, 'entropy_loss': -0.08141715079545975, 'vf_loss': 0.004376645835367346, 'total_loss': -0.0839141551132625, 'approx_kl': -0.0029505903366953135, 'clip_fraction': 0.5091145858168602, 'grad_norm': 3.021242380142212}
2023-01-03 21:42:52.024 DEBUG: Taking gradient step
2023-01-03 21:42:52.035 DEBUG: Loss 10: {'policy_loss': -0.015346587247800095, 'entropy_loss': -0.08146928809583187, 'vf_loss': 0.004031989314273251, 'total_loss': -0.0927838860293587, 'approx_kl': -0.006552854087203741, 'clip_fraction': 0.5364583432674408, 'grad_norm': 2.631108045578003}
2023-01-03 21:42:53.059 DEBUG: Taking gradient step
2023-01-03 21:42:53.068 DEBUG: Loss 11: {'policy_loss': -0.0433724006465969, 'entropy_loss': -0.08136848732829094, 'vf_loss': 0.003191356758172472, 'total_loss': -0.12154953121671536, 'approx_kl': 0.02312441519461572, 'clip_fraction': 0.51953125, 'grad_norm': 2.5772674083709717}
2023-01-03 21:42:54.072 DEBUG: Taking gradient step
2023-01-03 21:42:54.083 DEBUG: Loss 12: {'policy_loss': -0.04496837023318733, 'entropy_loss': -0.0813806988298893, 'vf_loss': 0.0031830345456816413, 'total_loss': -0.12316603451739498, 'approx_kl': -0.019368058303371072, 'clip_fraction': 0.4713541716337204, 'grad_norm': 2.0207290649414062}
2023-01-03 21:42:55.093 DEBUG: Taking gradient step
2023-01-03 21:42:55.102 DEBUG: Loss 13: {'policy_loss': -0.0024991890329509256, 'entropy_loss': -0.08181328140199184, 'vf_loss': 0.004868524576433598, 'total_loss': -0.07944394585850918, 'approx_kl': -0.025149979162961245, 'clip_fraction': 0.47265625, 'grad_norm': 2.333620309829712}
2023-01-03 21:42:56.120 DEBUG: Taking gradient step
2023-01-03 21:42:56.131 DEBUG: Loss 14: {'policy_loss': -0.01780348363016005, 'entropy_loss': -0.0816402081400156, 'vf_loss': 0.004014332518566719, 'total_loss': -0.09542935925160895, 'approx_kl': -0.012612349819391966, 'clip_fraction': 0.3958333358168602, 'grad_norm': 2.6558027267456055}
2023-01-03 21:42:56.131 INFO: Optimization: policy loss=-0.018, vf loss=0.004, entropy loss=-0.082, total loss=-0.095, num steps=15
2023-01-03 21:42:56.131 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:42:57.756 INFO: Evaluation rollout: return=0.585 (0.0), episode length=6.0
2023-01-03 21:42:57.758 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:42:57.761 INFO: Iteration: 76/137, steps: 16416
2023-01-03 21:43:52.595 INFO: Training rollout: return=0.543 (0.1), episode length=6.0
2023-01-03 21:43:52.596 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:43:52.599 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-16416_train.pkl
2023-01-03 21:43:53.654 DEBUG: Taking gradient step
2023-01-03 21:43:53.664 DEBUG: Loss 0: {'policy_loss': 0.0643131647238609, 'entropy_loss': -0.07901189662516117, 'vf_loss': 0.00012222885184039298, 'total_loss': -0.014576503049459871, 'approx_kl': 4.1249828997003135e-08, 'clip_fraction': 0.0, 'grad_norm': 19.193979263305664}
2023-01-03 21:43:54.709 DEBUG: Taking gradient step
2023-01-03 21:43:54.719 DEBUG: Loss 1: {'policy_loss': 0.024894462159764603, 'entropy_loss': -0.07897244207561016, 'vf_loss': 0.0001216014376010023, 'total_loss': -0.05395637847824456, 'approx_kl': 0.011561042279936373, 'clip_fraction': 0.1041666679084301, 'grad_norm': 12.996328353881836}
2023-01-03 21:43:55.758 DEBUG: Taking gradient step
2023-01-03 21:43:55.768 DEBUG: Loss 2: {'policy_loss': 0.025824286977164497, 'entropy_loss': -0.07933460175991058, 'vf_loss': 0.00011815148373100245, 'total_loss': -0.05339216329901507, 'approx_kl': 0.027761224657297134, 'clip_fraction': 0.2825520858168602, 'grad_norm': 10.739500999450684}
2023-01-03 21:43:56.806 DEBUG: Taking gradient step
2023-01-03 21:43:56.816 DEBUG: Loss 3: {'policy_loss': -0.06748090620079958, 'entropy_loss': -0.08038121648132801, 'vf_loss': 0.00012345914284684256, 'total_loss': -0.14773866353928075, 'approx_kl': 0.029840380884706974, 'clip_fraction': 0.390625, 'grad_norm': 14.51077651977539}
2023-01-03 21:43:57.850 DEBUG: Taking gradient step
2023-01-03 21:43:57.860 DEBUG: Loss 4: {'policy_loss': -0.04758967875669185, 'entropy_loss': -0.07935563661158085, 'vf_loss': 0.00011897801273921994, 'total_loss': -0.1268263373555335, 'approx_kl': 0.04223365616053343, 'clip_fraction': 0.4114583358168602, 'grad_norm': 9.910311698913574}
2023-01-03 21:43:58.865 DEBUG: Early stopping at step 5 for reaching max KL.
2023-01-03 21:43:58.865 INFO: Optimization: policy loss=-0.048, vf loss=0.000, entropy loss=-0.079, total loss=-0.127, num steps=5
2023-01-03 21:43:58.866 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:44:00.510 INFO: Evaluation rollout: return=0.573 (0.0), episode length=6.0
2023-01-03 21:44:00.512 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:44:00.515 INFO: Iteration: 77/137, steps: 16632
2023-01-03 21:44:15.976 DEBUG: There is a single atom floating around
2023-01-03 21:44:50.089 DEBUG: Atoms are too close
2023-01-03 21:44:54.920 INFO: Training rollout: return=-0.019 (3.7), episode length=6.0
2023-01-03 21:44:54.921 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:44:54.924 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-16632_train.pkl
2023-01-03 21:44:55.988 DEBUG: Taking gradient step
2023-01-03 21:44:55.998 DEBUG: Loss 0: {'policy_loss': -0.07329201047268688, 'entropy_loss': -0.08027955330908298, 'vf_loss': 0.01528378292206378, 'total_loss': -0.13828778085970608, 'approx_kl': 3.170377294026139e-08, 'clip_fraction': 0.0, 'grad_norm': 28.549135208129883}
2023-01-03 21:44:57.066 DEBUG: Taking gradient step
2023-01-03 21:44:57.076 DEBUG: Loss 1: {'policy_loss': 0.009816761039798817, 'entropy_loss': -0.07955379225313663, 'vf_loss': 0.011154382881271683, 'total_loss': -0.05858264833206613, 'approx_kl': 0.002268242766149342, 'clip_fraction': 0.00390625, 'grad_norm': 16.318056106567383}
2023-01-03 21:44:58.108 DEBUG: Taking gradient step
2023-01-03 21:44:58.117 DEBUG: Loss 2: {'policy_loss': 0.02359089979552515, 'entropy_loss': -0.07966181822121143, 'vf_loss': 0.012209853223982454, 'total_loss': -0.043861065201703825, 'approx_kl': 0.012264944380149245, 'clip_fraction': 0.1744791679084301, 'grad_norm': 6.105924606323242}
2023-01-03 21:44:59.169 DEBUG: Taking gradient step
2023-01-03 21:44:59.179 DEBUG: Loss 3: {'policy_loss': -0.011776811485448749, 'entropy_loss': -0.07949352450668812, 'vf_loss': 0.011732389131172161, 'total_loss': -0.07953794686096471, 'approx_kl': 0.036157706286758184, 'clip_fraction': 0.3072916716337204, 'grad_norm': 4.6695733070373535}
2023-01-03 21:45:00.235 DEBUG: Taking gradient step
2023-01-03 21:45:00.244 DEBUG: Loss 4: {'policy_loss': -0.01891726825577148, 'entropy_loss': -0.0786574762314558, 'vf_loss': 0.011845313735676538, 'total_loss': -0.08572943075155075, 'approx_kl': 0.03164687822572887, 'clip_fraction': 0.2864583358168602, 'grad_norm': 3.000014066696167}
2023-01-03 21:45:01.297 DEBUG: Taking gradient step
2023-01-03 21:45:01.306 DEBUG: Loss 5: {'policy_loss': -0.05640124021634625, 'entropy_loss': -0.07939382642507553, 'vf_loss': 0.011272705271903145, 'total_loss': -0.12452236136951862, 'approx_kl': 0.03308437950909138, 'clip_fraction': 0.26171875, 'grad_norm': 3.3848514556884766}
2023-01-03 21:45:02.305 DEBUG: Taking gradient step
2023-01-03 21:45:02.314 DEBUG: Loss 6: {'policy_loss': -0.03017431825437485, 'entropy_loss': -0.08037591725587845, 'vf_loss': 0.010818742276180267, 'total_loss': -0.09973149323407304, 'approx_kl': 0.04363716789521277, 'clip_fraction': 0.34765625, 'grad_norm': 1.9256532192230225}
2023-01-03 21:45:03.327 DEBUG: Taking gradient step
2023-01-03 21:45:03.336 DEBUG: Loss 7: {'policy_loss': -0.02930317869054255, 'entropy_loss': -0.079751031473279, 'vf_loss': 0.01077564224676155, 'total_loss': -0.09827856791706, 'approx_kl': 0.0120503562502563, 'clip_fraction': 0.3658854216337204, 'grad_norm': 9.022431373596191}
2023-01-03 21:45:04.377 DEBUG: Taking gradient step
2023-01-03 21:45:04.388 DEBUG: Loss 8: {'policy_loss': -0.023467131379009583, 'entropy_loss': -0.07898020930588245, 'vf_loss': 0.011553400845031106, 'total_loss': -0.09089393983986092, 'approx_kl': 0.0369019634090364, 'clip_fraction': 0.375, 'grad_norm': 9.042003631591797}
2023-01-03 21:45:05.439 DEBUG: Taking gradient step
2023-01-03 21:45:05.449 DEBUG: Loss 9: {'policy_loss': -0.024396259179474675, 'entropy_loss': -0.07898927479982376, 'vf_loss': 0.010901869383476922, 'total_loss': -0.0924836645958215, 'approx_kl': 0.040410800371319056, 'clip_fraction': 0.4674479216337204, 'grad_norm': 2.180481195449829}
2023-01-03 21:45:06.481 DEBUG: Early stopping at step 10 for reaching max KL.
2023-01-03 21:45:06.482 INFO: Optimization: policy loss=-0.024, vf loss=0.011, entropy loss=-0.079, total loss=-0.092, num steps=10
2023-01-03 21:45:06.482 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:45:08.135 INFO: Evaluation rollout: return=0.571 (0.0), episode length=6.0
2023-01-03 21:45:08.136 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:45:08.139 INFO: Iteration: 78/137, steps: 16848
2023-01-03 21:45:26.042 DEBUG: Atoms are too close
2023-01-03 21:46:03.851 INFO: Training rollout: return=0.179 (2.2), episode length=6.0
2023-01-03 21:46:03.853 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:46:03.856 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-16848_train.pkl
2023-01-03 21:46:04.912 DEBUG: Taking gradient step
2023-01-03 21:46:04.921 DEBUG: Loss 0: {'policy_loss': 0.016243227915306538, 'entropy_loss': -0.07918189279735088, 'vf_loss': 0.004124928925679106, 'total_loss': -0.05881373595636524, 'approx_kl': -8.149072527885437e-09, 'clip_fraction': 0.0, 'grad_norm': 13.4154052734375}
2023-01-03 21:46:05.959 DEBUG: Taking gradient step
2023-01-03 21:46:05.968 DEBUG: Loss 1: {'policy_loss': -0.02857746576670007, 'entropy_loss': -0.07999204285442829, 'vf_loss': 0.0032388700286776336, 'total_loss': -0.10533063859245073, 'approx_kl': 0.010839328868314624, 'clip_fraction': 0.0846354179084301, 'grad_norm': 9.513773918151855}
2023-01-03 21:46:06.998 DEBUG: Taking gradient step
2023-01-03 21:46:07.007 DEBUG: Loss 2: {'policy_loss': -0.028743304752990424, 'entropy_loss': -0.07935203239321709, 'vf_loss': 0.003245274228699633, 'total_loss': -0.10485006291750787, 'approx_kl': 0.02077674074098468, 'clip_fraction': 0.1354166679084301, 'grad_norm': 9.301534652709961}
2023-01-03 21:46:08.025 DEBUG: Taking gradient step
2023-01-03 21:46:08.034 DEBUG: Loss 3: {'policy_loss': 0.007518189282514985, 'entropy_loss': -0.07924123853445053, 'vf_loss': 0.004472992982762064, 'total_loss': -0.06725005626917349, 'approx_kl': 0.015084717189893126, 'clip_fraction': 0.1940104179084301, 'grad_norm': 18.016965866088867}
2023-01-03 21:46:09.056 DEBUG: Taking gradient step
2023-01-03 21:46:09.067 DEBUG: Loss 4: {'policy_loss': 0.028929883064341425, 'entropy_loss': -0.0788745079189539, 'vf_loss': 0.0053916084728796235, 'total_loss': -0.044553016381732855, 'approx_kl': 0.03285815427079797, 'clip_fraction': 0.28255208395421505, 'grad_norm': 5.278331279754639}
2023-01-03 21:46:10.086 DEBUG: Taking gradient step
2023-01-03 21:46:10.095 DEBUG: Loss 5: {'policy_loss': -0.022004418604567477, 'entropy_loss': -0.07882527634501457, 'vf_loss': 0.003718497166528731, 'total_loss': -0.09711119778305333, 'approx_kl': 0.025859945744741708, 'clip_fraction': 0.3828125, 'grad_norm': 6.043631076812744}
2023-01-03 21:46:11.140 DEBUG: Taking gradient step
2023-01-03 21:46:11.151 DEBUG: Loss 6: {'policy_loss': -0.04196263514332281, 'entropy_loss': -0.07903105393052101, 'vf_loss': 0.0032549039724525876, 'total_loss': -0.11773878510139124, 'approx_kl': 0.019962369580753148, 'clip_fraction': 0.3815104216337204, 'grad_norm': 5.770628929138184}
2023-01-03 21:46:12.274 DEBUG: Taking gradient step
2023-01-03 21:46:12.287 DEBUG: Loss 7: {'policy_loss': 0.00785683968651324, 'entropy_loss': -0.07811525277793407, 'vf_loss': 0.004483054766945939, 'total_loss': -0.0657753583244749, 'approx_kl': 0.02469275117618963, 'clip_fraction': 0.3841145858168602, 'grad_norm': 2.095255136489868}
2023-01-03 21:46:13.439 DEBUG: Taking gradient step
2023-01-03 21:46:13.451 DEBUG: Loss 8: {'policy_loss': -0.04661634778298267, 'entropy_loss': -0.07876759022474289, 'vf_loss': 0.003261429229026338, 'total_loss': -0.12212250877869921, 'approx_kl': 0.04328566323965788, 'clip_fraction': 0.4127604216337204, 'grad_norm': 2.2299602031707764}
2023-01-03 21:46:14.602 DEBUG: Taking gradient step
2023-01-03 21:46:14.615 DEBUG: Loss 9: {'policy_loss': -0.020442249786903996, 'entropy_loss': -0.0789483617991209, 'vf_loss': 0.004157160292348966, 'total_loss': -0.09523345129367593, 'approx_kl': 0.004371996037662029, 'clip_fraction': 0.484375, 'grad_norm': 3.0996129512786865}
2023-01-03 21:46:15.761 DEBUG: Taking gradient step
2023-01-03 21:46:15.775 DEBUG: Loss 10: {'policy_loss': 0.01800644056831492, 'entropy_loss': -0.0783469881862402, 'vf_loss': 0.0046643623192906564, 'total_loss': -0.05567618529863462, 'approx_kl': 0.016088707372546196, 'clip_fraction': 0.40234375, 'grad_norm': 8.044827461242676}
2023-01-03 21:46:16.872 DEBUG: Taking gradient step
2023-01-03 21:46:16.884 DEBUG: Loss 11: {'policy_loss': -0.01301431724397941, 'entropy_loss': -0.07876426354050636, 'vf_loss': 0.004145550212454096, 'total_loss': -0.08763303057203167, 'approx_kl': 0.03819545544683933, 'clip_fraction': 0.4192708358168602, 'grad_norm': 2.1902904510498047}
2023-01-03 21:46:18.001 DEBUG: Taking gradient step
2023-01-03 21:46:18.014 DEBUG: Loss 12: {'policy_loss': -0.05072005295451112, 'entropy_loss': -0.07950451038777828, 'vf_loss': 0.0032468643394502257, 'total_loss': -0.12697769900283917, 'approx_kl': 0.01993771642446518, 'clip_fraction': 0.4778645932674408, 'grad_norm': 1.8231323957443237}
2023-01-03 21:46:19.173 DEBUG: Taking gradient step
2023-01-03 21:46:19.187 DEBUG: Loss 13: {'policy_loss': -0.0517084451975503, 'entropy_loss': -0.08011345751583576, 'vf_loss': 0.003247401708674216, 'total_loss': -0.12857450100471185, 'approx_kl': 0.014923094771802425, 'clip_fraction': 0.4544270858168602, 'grad_norm': 2.401885986328125}
2023-01-03 21:46:20.339 DEBUG: Taking gradient step
2023-01-03 21:46:20.353 DEBUG: Loss 14: {'policy_loss': -0.0339132482119717, 'entropy_loss': -0.0789393000304699, 'vf_loss': 0.0035608163877137748, 'total_loss': -0.1092917318547278, 'approx_kl': -0.016904037445783615, 'clip_fraction': 0.4505208432674408, 'grad_norm': 2.193983793258667}
2023-01-03 21:46:20.353 INFO: Optimization: policy loss=-0.034, vf loss=0.004, entropy loss=-0.079, total loss=-0.109, num steps=15
2023-01-03 21:46:20.353 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:46:22.029 INFO: Evaluation rollout: return=0.441 (0.0), episode length=6.0
2023-01-03 21:46:22.031 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:46:22.034 INFO: Iteration: 79/137, steps: 17064
2023-01-03 21:47:08.373 DEBUG: Atoms are too close
2023-01-03 21:47:16.613 INFO: Training rollout: return=0.030 (3.1), episode length=5.9
2023-01-03 21:47:16.614 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:47:16.617 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-17064_train.pkl
2023-01-03 21:47:17.657 DEBUG: Taking gradient step
2023-01-03 21:47:17.667 DEBUG: Loss 0: {'policy_loss': 0.012735194562148276, 'entropy_loss': -0.08045792393386364, 'vf_loss': 0.0034106309986669915, 'total_loss': -0.06431209837304837, 'approx_kl': -1.234002411365509e-08, 'clip_fraction': 0.0, 'grad_norm': 15.291431427001953}
2023-01-03 21:47:18.680 DEBUG: Taking gradient step
2023-01-03 21:47:18.688 DEBUG: Loss 1: {'policy_loss': -0.03524835348342066, 'entropy_loss': -0.0800127163529396, 'vf_loss': 0.0027667038894704852, 'total_loss': -0.11249436594688977, 'approx_kl': 0.002430733758956194, 'clip_fraction': 0.10677083395421505, 'grad_norm': 2.7625131607055664}
2023-01-03 21:47:19.712 DEBUG: Taking gradient step
2023-01-03 21:47:19.724 DEBUG: Loss 2: {'policy_loss': -0.03726170202770916, 'entropy_loss': -0.08022989332675934, 'vf_loss': 0.002767456465479806, 'total_loss': -0.11472413888898869, 'approx_kl': -0.006549633573740721, 'clip_fraction': 0.2330729179084301, 'grad_norm': 3.4048609733581543}
2023-01-03 21:47:20.709 DEBUG: Taking gradient step
2023-01-03 21:47:20.720 DEBUG: Loss 3: {'policy_loss': -0.00032767213170885323, 'entropy_loss': -0.0803737360984087, 'vf_loss': 0.00397202770244307, 'total_loss': -0.07672938052767449, 'approx_kl': -0.010263001779094338, 'clip_fraction': 0.26171875, 'grad_norm': 19.45409393310547}
2023-01-03 21:47:21.736 DEBUG: Taking gradient step
2023-01-03 21:47:21.744 DEBUG: Loss 4: {'policy_loss': -0.035367812798967974, 'entropy_loss': -0.08007237128913403, 'vf_loss': 0.002756534588478352, 'total_loss': -0.11268364949962364, 'approx_kl': 0.0038826423697173595, 'clip_fraction': 0.2682291679084301, 'grad_norm': 3.208523750305176}
2023-01-03 21:47:22.757 DEBUG: Taking gradient step
2023-01-03 21:47:22.765 DEBUG: Loss 5: {'policy_loss': 0.0006804076332806407, 'entropy_loss': -0.08038482628762722, 'vf_loss': 0.003963722285585209, 'total_loss': -0.07574069636876136, 'approx_kl': -0.013394289650022984, 'clip_fraction': 0.3020833358168602, 'grad_norm': 2.5304815769195557}
2023-01-03 21:47:23.774 DEBUG: Taking gradient step
2023-01-03 21:47:23.784 DEBUG: Loss 6: {'policy_loss': -0.03919645010663428, 'entropy_loss': -0.0797462947666645, 'vf_loss': 0.0027502087171497555, 'total_loss': -0.11619253615614904, 'approx_kl': -0.007293016416952014, 'clip_fraction': 0.2630208358168602, 'grad_norm': 10.317217826843262}
2023-01-03 21:47:24.799 DEBUG: Taking gradient step
2023-01-03 21:47:24.807 DEBUG: Loss 7: {'policy_loss': 0.06116047256612395, 'entropy_loss': -0.07971951179206371, 'vf_loss': 0.0056364162715387064, 'total_loss': -0.012922622954401053, 'approx_kl': -0.009924804326146841, 'clip_fraction': 0.2591145858168602, 'grad_norm': 36.3493766784668}
2023-01-03 21:47:25.816 DEBUG: Taking gradient step
2023-01-03 21:47:25.825 DEBUG: Loss 8: {'policy_loss': -0.037799497324706555, 'entropy_loss': -0.07947435602545738, 'vf_loss': 0.0027381918869423733, 'total_loss': -0.11453566146322156, 'approx_kl': 0.006408707005903125, 'clip_fraction': 0.2604166679084301, 'grad_norm': 2.2067928314208984}
2023-01-03 21:47:26.866 DEBUG: Taking gradient step
2023-01-03 21:47:26.875 DEBUG: Loss 9: {'policy_loss': -0.03890160089725328, 'entropy_loss': -0.08071491122245789, 'vf_loss': 0.0027280322768756292, 'total_loss': -0.11688847984283554, 'approx_kl': -0.003954042214900255, 'clip_fraction': 0.3190104216337204, 'grad_norm': 3.0359654426574707}
2023-01-03 21:47:27.914 DEBUG: Taking gradient step
2023-01-03 21:47:27.923 DEBUG: Loss 10: {'policy_loss': -0.014989470021712626, 'entropy_loss': -0.08029520697891712, 'vf_loss': 0.0033750451762780413, 'total_loss': -0.0919096318243517, 'approx_kl': -0.009989364072680473, 'clip_fraction': 0.30078125, 'grad_norm': 7.434261322021484}
2023-01-03 21:47:28.966 DEBUG: Taking gradient step
2023-01-03 21:47:28.978 DEBUG: Loss 11: {'policy_loss': 0.0007549185203813147, 'entropy_loss': -0.08068432286381721, 'vf_loss': 0.004417198680757148, 'total_loss': -0.07551220566267874, 'approx_kl': -0.01613959390670061, 'clip_fraction': 0.3684895858168602, 'grad_norm': 2.2031922340393066}
2023-01-03 21:47:29.977 DEBUG: Taking gradient step
2023-01-03 21:47:29.986 DEBUG: Loss 12: {'policy_loss': -0.04963583436456649, 'entropy_loss': -0.07892515137791634, 'vf_loss': 0.0027254156973588427, 'total_loss': -0.12583557004512397, 'approx_kl': -0.030931032728403807, 'clip_fraction': 0.3958333358168602, 'grad_norm': 1.6834877729415894}
2023-01-03 21:47:31.014 DEBUG: Taking gradient step
2023-01-03 21:47:31.025 DEBUG: Loss 13: {'policy_loss': -0.04204309493811226, 'entropy_loss': -0.07854579389095306, 'vf_loss': 0.002716945319379156, 'total_loss': -0.11787194350968616, 'approx_kl': -0.02565605938434601, 'clip_fraction': 0.3541666716337204, 'grad_norm': 1.3495073318481445}
2023-01-03 21:47:32.063 DEBUG: Taking gradient step
2023-01-03 21:47:32.073 DEBUG: Loss 14: {'policy_loss': -0.04522738358836933, 'entropy_loss': -0.08016751892864704, 'vf_loss': 0.002714231793384846, 'total_loss': -0.12268067072363154, 'approx_kl': -0.029336602427065372, 'clip_fraction': 0.3502604216337204, 'grad_norm': 8.831517219543457}
2023-01-03 21:47:32.074 INFO: Optimization: policy loss=-0.045, vf loss=0.003, entropy loss=-0.080, total loss=-0.123, num steps=15
2023-01-03 21:47:32.074 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:47:33.735 INFO: Evaluation rollout: return=0.529 (0.0), episode length=6.0
2023-01-03 21:47:33.737 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:47:33.739 INFO: Iteration: 80/137, steps: 17280
2023-01-03 21:47:50.628 DEBUG: Atoms are too close
2023-01-03 21:48:29.413 INFO: Training rollout: return=0.187 (2.2), episode length=6.0
2023-01-03 21:48:29.415 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:48:29.418 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-17280_train.pkl
2023-01-03 21:48:30.464 DEBUG: Taking gradient step
2023-01-03 21:48:30.473 DEBUG: Loss 0: {'policy_loss': -0.02091210101999781, 'entropy_loss': -0.07847260311245918, 'vf_loss': 0.00316132796335461, 'total_loss': -0.0962233761691024, 'approx_kl': -5.0446637089862634e-08, 'clip_fraction': 0.0, 'grad_norm': 5.616499423980713}
2023-01-03 21:48:31.508 DEBUG: Taking gradient step
2023-01-03 21:48:31.517 DEBUG: Loss 1: {'policy_loss': -0.03798847067573307, 'entropy_loss': -0.07852272503077984, 'vf_loss': 0.003168413427326089, 'total_loss': -0.11334278227918682, 'approx_kl': 0.006040862062945962, 'clip_fraction': 0.049479166977107525, 'grad_norm': 4.454134464263916}
2023-01-03 21:48:32.517 DEBUG: Taking gradient step
2023-01-03 21:48:32.526 DEBUG: Loss 2: {'policy_loss': 0.014449776494939282, 'entropy_loss': -0.07802062295377254, 'vf_loss': 0.004263562619560024, 'total_loss': -0.05930728383927325, 'approx_kl': 0.013899064040742815, 'clip_fraction': 0.09765625, 'grad_norm': 3.5967583656311035}
2023-01-03 21:48:33.511 DEBUG: Taking gradient step
2023-01-03 21:48:33.521 DEBUG: Loss 3: {'policy_loss': -0.045366759663769754, 'entropy_loss': -0.0778408907353878, 'vf_loss': 0.0031638248592127435, 'total_loss': -0.12004382553994482, 'approx_kl': 0.009166319156065583, 'clip_fraction': 0.2513020858168602, 'grad_norm': 2.4570729732513428}
2023-01-03 21:48:34.539 DEBUG: Taking gradient step
2023-01-03 21:48:34.549 DEBUG: Loss 4: {'policy_loss': -0.04917795176438346, 'entropy_loss': -0.07621155492961407, 'vf_loss': 0.0031619751904830152, 'total_loss': -0.12222753150351451, 'approx_kl': 0.0038692093221470714, 'clip_fraction': 0.3072916716337204, 'grad_norm': 3.125356912612915}
2023-01-03 21:48:35.568 DEBUG: Taking gradient step
2023-01-03 21:48:35.579 DEBUG: Loss 5: {'policy_loss': -0.04793324580491236, 'entropy_loss': -0.07716109044849873, 'vf_loss': 0.003157862130091634, 'total_loss': -0.12193647412331945, 'approx_kl': 0.01735882693901658, 'clip_fraction': 0.33984375, 'grad_norm': 2.4389736652374268}
2023-01-03 21:48:36.587 DEBUG: Taking gradient step
2023-01-03 21:48:36.595 DEBUG: Loss 6: {'policy_loss': -0.008959438220799306, 'entropy_loss': -0.0769704282283783, 'vf_loss': 0.00430107009005778, 'total_loss': -0.08162879635911983, 'approx_kl': 0.020784073742106557, 'clip_fraction': 0.3268229179084301, 'grad_norm': 2.2506227493286133}
2023-01-03 21:48:37.582 DEBUG: Taking gradient step
2023-01-03 21:48:37.590 DEBUG: Loss 7: {'policy_loss': -0.05497205949247483, 'entropy_loss': -0.07624104991555214, 'vf_loss': 0.003140983179840327, 'total_loss': -0.12807212622818664, 'approx_kl': -0.002620859071612358, 'clip_fraction': 0.4635416716337204, 'grad_norm': 1.8500527143478394}
2023-01-03 21:48:38.609 DEBUG: Taking gradient step
2023-01-03 21:48:38.618 DEBUG: Loss 8: {'policy_loss': -0.051668250478247954, 'entropy_loss': -0.07614077068865299, 'vf_loss': 0.003125778698651099, 'total_loss': -0.12468324246824986, 'approx_kl': 0.02529426757246256, 'clip_fraction': 0.4700520932674408, 'grad_norm': 1.823232889175415}
2023-01-03 21:48:39.639 DEBUG: Taking gradient step
2023-01-03 21:48:39.647 DEBUG: Loss 9: {'policy_loss': -0.026246021541260094, 'entropy_loss': -0.0764657761901617, 'vf_loss': 0.003746822558909342, 'total_loss': -0.09896497517251246, 'approx_kl': 0.023385118693113327, 'clip_fraction': 0.4270833358168602, 'grad_norm': 1.3792459964752197}
2023-01-03 21:48:40.670 DEBUG: Taking gradient step
2023-01-03 21:48:40.680 DEBUG: Loss 10: {'policy_loss': -0.05130938178620138, 'entropy_loss': -0.07672719098627567, 'vf_loss': 0.003100371478892626, 'total_loss': -0.12493620129358442, 'approx_kl': 0.018617326393723488, 'clip_fraction': 0.46484375, 'grad_norm': 1.7385849952697754}
2023-01-03 21:48:41.709 DEBUG: Taking gradient step
2023-01-03 21:48:41.718 DEBUG: Loss 11: {'policy_loss': -0.006392335674296298, 'entropy_loss': -0.0765102319419384, 'vf_loss': 0.0041512922852859424, 'total_loss': -0.07875127533094876, 'approx_kl': 0.039040000177919865, 'clip_fraction': 0.48828125, 'grad_norm': 3.065293788909912}
2023-01-03 21:48:42.716 DEBUG: Taking gradient step
2023-01-03 21:48:42.727 DEBUG: Loss 12: {'policy_loss': -0.060155935924002986, 'entropy_loss': -0.07689251564443111, 'vf_loss': 0.0030974701762245885, 'total_loss': -0.1339509813922095, 'approx_kl': 0.009561243932694197, 'clip_fraction': 0.5091145932674408, 'grad_norm': 2.9849112033843994}
2023-01-03 21:48:43.737 DEBUG: Taking gradient step
2023-01-03 21:48:43.746 DEBUG: Loss 13: {'policy_loss': -0.05685270756443092, 'entropy_loss': -0.07737596519291401, 'vf_loss': 0.0030839750630862394, 'total_loss': -0.13114469769425868, 'approx_kl': 0.03556605242192745, 'clip_fraction': 0.5455729216337204, 'grad_norm': 2.2905712127685547}
2023-01-03 21:48:44.760 DEBUG: Taking gradient step
2023-01-03 21:48:44.768 DEBUG: Loss 14: {'policy_loss': -0.05486875979826375, 'entropy_loss': -0.07801778241991997, 'vf_loss': 0.003073978489461922, 'total_loss': -0.1298125637287218, 'approx_kl': 0.009062835946679115, 'clip_fraction': 0.52734375, 'grad_norm': 1.6348156929016113}
2023-01-03 21:48:44.768 INFO: Optimization: policy loss=-0.055, vf loss=0.003, entropy loss=-0.078, total loss=-0.130, num steps=15
2023-01-03 21:48:44.769 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:48:46.426 INFO: Evaluation rollout: return=0.609 (0.0), episode length=6.0
2023-01-03 21:48:46.427 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:48:46.430 DEBUG: Deleting old model: runs/CH3NO_baseline/models/CH3NO_baseline_run-1_steps-15336.model
2023-01-03 21:48:46.435 DEBUG: Saving model: runs/CH3NO_baseline/models/CH3NO_baseline_run-1_steps-17496.model
2023-01-03 21:48:46.464 INFO: Iteration: 81/137, steps: 17496
2023-01-03 21:49:34.157 DEBUG: There is a single atom floating around
2023-01-03 21:49:41.296 INFO: Training rollout: return=0.019 (3.0), episode length=5.9
2023-01-03 21:49:41.298 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:49:41.301 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-17496_train.pkl
2023-01-03 21:49:42.339 DEBUG: Taking gradient step
2023-01-03 21:49:42.350 DEBUG: Loss 0: {'policy_loss': 0.033666626005254746, 'entropy_loss': -0.0783702190965414, 'vf_loss': 0.004090179164798645, 'total_loss': -0.04061341392648802, 'approx_kl': 4.44706529378891e-08, 'clip_fraction': 0.0, 'grad_norm': 18.343711853027344}
2023-01-03 21:49:43.387 DEBUG: Taking gradient step
2023-01-03 21:49:43.397 DEBUG: Loss 1: {'policy_loss': -0.02521430197560224, 'entropy_loss': -0.07892752811312675, 'vf_loss': 0.0028535477662090716, 'total_loss': -0.10128828232251992, 'approx_kl': 0.0075257152784615755, 'clip_fraction': 0.04296875, 'grad_norm': 9.687385559082031}
2023-01-03 21:49:44.405 DEBUG: Taking gradient step
2023-01-03 21:49:44.413 DEBUG: Loss 2: {'policy_loss': 0.00031729772586209376, 'entropy_loss': -0.07918817922472954, 'vf_loss': 0.003504636754883639, 'total_loss': -0.07536624474398382, 'approx_kl': 0.015119555871933699, 'clip_fraction': 0.12890625, 'grad_norm': 7.753247261047363}
2023-01-03 21:49:45.418 DEBUG: Taking gradient step
2023-01-03 21:49:45.426 DEBUG: Loss 3: {'policy_loss': 0.01311509564479062, 'entropy_loss': -0.07958496920764446, 'vf_loss': 0.0041174826346368106, 'total_loss': -0.06235239092821704, 'approx_kl': 0.03880598722025752, 'clip_fraction': 0.234375, 'grad_norm': 2.4606542587280273}
2023-01-03 21:49:46.429 DEBUG: Taking gradient step
2023-01-03 21:49:46.438 DEBUG: Loss 4: {'policy_loss': 0.014252932657790998, 'entropy_loss': -0.07932766899466515, 'vf_loss': 0.004612742012051092, 'total_loss': -0.06046199432482304, 'approx_kl': 0.043245123233646154, 'clip_fraction': 0.3229166716337204, 'grad_norm': 2.4639720916748047}
2023-01-03 21:49:47.443 DEBUG: Taking gradient step
2023-01-03 21:49:47.452 DEBUG: Loss 5: {'policy_loss': -0.003386735732374576, 'entropy_loss': -0.08021130785346031, 'vf_loss': 0.003709002989090635, 'total_loss': -0.07988904059674425, 'approx_kl': 0.017226788448169827, 'clip_fraction': 0.2747395858168602, 'grad_norm': 2.6205334663391113}
2023-01-03 21:49:48.406 DEBUG: Taking gradient step
2023-01-03 21:49:48.417 DEBUG: Loss 6: {'policy_loss': -0.03915261782594163, 'entropy_loss': -0.07992788404226303, 'vf_loss': 0.0028581003341373204, 'total_loss': -0.11622240153406733, 'approx_kl': 0.010470296023413539, 'clip_fraction': 0.2955729179084301, 'grad_norm': 2.786234140396118}
2023-01-03 21:49:49.437 DEBUG: Taking gradient step
2023-01-03 21:49:49.449 DEBUG: Loss 7: {'policy_loss': -0.051677670684904184, 'entropy_loss': -0.08140561357140541, 'vf_loss': 0.002861066225362979, 'total_loss': -0.13022221803094663, 'approx_kl': -0.005920111900195479, 'clip_fraction': 0.35546875, 'grad_norm': 2.4240481853485107}
2023-01-03 21:49:50.403 DEBUG: Taking gradient step
2023-01-03 21:49:50.412 DEBUG: Loss 8: {'policy_loss': -0.0050096534758855005, 'entropy_loss': -0.08055459521710873, 'vf_loss': 0.004103095593479612, 'total_loss': -0.08146115309951461, 'approx_kl': 0.009793295990675688, 'clip_fraction': 0.4010416716337204, 'grad_norm': 16.592891693115234}
2023-01-03 21:49:51.433 DEBUG: Taking gradient step
2023-01-03 21:49:51.441 DEBUG: Loss 9: {'policy_loss': -0.042487196466290206, 'entropy_loss': -0.08033573813736439, 'vf_loss': 0.002828263792558252, 'total_loss': -0.11999467081109634, 'approx_kl': -0.0003687324933707714, 'clip_fraction': 0.484375, 'grad_norm': 6.31538724899292}
2023-01-03 21:49:52.471 DEBUG: Taking gradient step
2023-01-03 21:49:52.482 DEBUG: Loss 10: {'policy_loss': -0.005884751511480539, 'entropy_loss': -0.07975848391652107, 'vf_loss': 0.00364025775266401, 'total_loss': -0.08200297767533761, 'approx_kl': 0.0055036284029483795, 'clip_fraction': 0.4635416716337204, 'grad_norm': 1.8613771200180054}
2023-01-03 21:49:53.503 DEBUG: Taking gradient step
2023-01-03 21:49:53.512 DEBUG: Loss 11: {'policy_loss': 0.010724854181784205, 'entropy_loss': -0.08052267134189606, 'vf_loss': 0.004532255697256842, 'total_loss': -0.06526556146285502, 'approx_kl': 0.040569085627794266, 'clip_fraction': 0.5, 'grad_norm': 1.9160182476043701}
2023-01-03 21:49:54.520 DEBUG: Taking gradient step
2023-01-03 21:49:54.528 DEBUG: Loss 12: {'policy_loss': -0.04367433778494927, 'entropy_loss': -0.0802431907504797, 'vf_loss': 0.00279415152498843, 'total_loss': -0.12112337701044054, 'approx_kl': 0.030880333855748177, 'clip_fraction': 0.4986979216337204, 'grad_norm': 2.144920587539673}
2023-01-03 21:49:55.527 DEBUG: Taking gradient step
2023-01-03 21:49:55.537 DEBUG: Loss 13: {'policy_loss': -0.04023047249709549, 'entropy_loss': -0.08004711009562016, 'vf_loss': 0.002771793993835411, 'total_loss': -0.11750578859888024, 'approx_kl': 0.016114903381094337, 'clip_fraction': 0.5286458432674408, 'grad_norm': 1.6495040655136108}
2023-01-03 21:49:56.555 DEBUG: Taking gradient step
2023-01-03 21:49:56.566 DEBUG: Loss 14: {'policy_loss': 0.04160574362236873, 'entropy_loss': -0.08001789823174477, 'vf_loss': 0.005730362460537448, 'total_loss': -0.03268179214883858, 'approx_kl': 0.00042060238774865866, 'clip_fraction': 0.4895833432674408, 'grad_norm': 1.648207187652588}
2023-01-03 21:49:56.566 INFO: Optimization: policy loss=0.042, vf loss=0.006, entropy loss=-0.080, total loss=-0.033, num steps=15
2023-01-03 21:49:56.566 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:49:58.197 INFO: Evaluation rollout: return=0.638 (0.0), episode length=6.0
2023-01-03 21:49:58.198 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:49:58.201 INFO: Iteration: 82/137, steps: 17712
2023-01-03 21:50:22.272 DEBUG: Atoms are too close
2023-01-03 21:50:51.864 DEBUG: There is a single atom floating around
2023-01-03 21:50:52.707 INFO: Training rollout: return=-0.421 (4.2), episode length=5.9
2023-01-03 21:50:52.708 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:50:52.711 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-17712_train.pkl
2023-01-03 21:50:53.735 DEBUG: Taking gradient step
2023-01-03 21:50:53.745 DEBUG: Loss 0: {'policy_loss': -0.01973743353543371, 'entropy_loss': -0.07968034781515598, 'vf_loss': 0.005954338436828243, 'total_loss': -0.09346344291376145, 'approx_kl': 7.458341855226536e-08, 'clip_fraction': 0.0, 'grad_norm': 13.987762451171875}
2023-01-03 21:50:54.764 DEBUG: Taking gradient step
2023-01-03 21:50:54.773 DEBUG: Loss 1: {'policy_loss': -0.009718488237746582, 'entropy_loss': -0.08032922260463238, 'vf_loss': 0.006905871286114433, 'total_loss': -0.08314183955626453, 'approx_kl': -0.004101678146980703, 'clip_fraction': 0.08463541697710752, 'grad_norm': 9.855390548706055}
2023-01-03 21:50:55.802 DEBUG: Taking gradient step
2023-01-03 21:50:55.811 DEBUG: Loss 2: {'policy_loss': -0.02619695008031984, 'entropy_loss': -0.07943572476506233, 'vf_loss': 0.005974183933250322, 'total_loss': -0.09965849091213184, 'approx_kl': 0.0010180811514146626, 'clip_fraction': 0.2369791679084301, 'grad_norm': 10.411705017089844}
2023-01-03 21:50:56.820 DEBUG: Taking gradient step
2023-01-03 21:50:56.831 DEBUG: Loss 3: {'policy_loss': -0.011666909651126834, 'entropy_loss': -0.07893599942326546, 'vf_loss': 0.006949768757722859, 'total_loss': -0.08365314031666944, 'approx_kl': 0.024693521205335855, 'clip_fraction': 0.3346354216337204, 'grad_norm': 9.682256698608398}
2023-01-03 21:50:57.815 DEBUG: Taking gradient step
2023-01-03 21:50:57.823 DEBUG: Loss 4: {'policy_loss': 0.03144150372011977, 'entropy_loss': -0.07964606583118439, 'vf_loss': 0.00864527431356595, 'total_loss': -0.03955928779749867, 'approx_kl': 0.023916094563901424, 'clip_fraction': 0.3880208358168602, 'grad_norm': 3.5073225498199463}
2023-01-03 21:50:58.839 DEBUG: Taking gradient step
2023-01-03 21:50:58.848 DEBUG: Loss 5: {'policy_loss': 0.008009041734083747, 'entropy_loss': -0.07945882901549339, 'vf_loss': 0.007174699483390403, 'total_loss': -0.06427508779801924, 'approx_kl': 0.028341324999928474, 'clip_fraction': 0.3736979216337204, 'grad_norm': 3.664179801940918}
2023-01-03 21:50:59.866 DEBUG: Taking gradient step
2023-01-03 21:50:59.875 DEBUG: Loss 6: {'policy_loss': -0.04089619785987905, 'entropy_loss': -0.07911315932869911, 'vf_loss': 0.005632044552919292, 'total_loss': -0.11437731263565887, 'approx_kl': 0.023459925316274166, 'clip_fraction': 0.37890625, 'grad_norm': 12.880135536193848}
2023-01-03 21:51:00.862 DEBUG: Taking gradient step
2023-01-03 21:51:00.870 DEBUG: Loss 7: {'policy_loss': 0.016734453607882296, 'entropy_loss': -0.07910035364329815, 'vf_loss': 0.008191163427884429, 'total_loss': -0.05417473660753143, 'approx_kl': 0.03486684011295438, 'clip_fraction': 0.4127604216337204, 'grad_norm': 21.003185272216797}
2023-01-03 21:51:01.870 DEBUG: Early stopping at step 8 for reaching max KL.
2023-01-03 21:51:01.870 INFO: Optimization: policy loss=0.017, vf loss=0.008, entropy loss=-0.079, total loss=-0.054, num steps=8
2023-01-03 21:51:01.871 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:51:03.482 INFO: Evaluation rollout: return=0.645 (0.0), episode length=6.0
2023-01-03 21:51:03.483 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:51:03.486 INFO: Iteration: 83/137, steps: 17928
2023-01-03 21:51:19.111 DEBUG: Atoms are too close
2023-01-03 21:51:19.375 DEBUG: Atoms are too close
2023-01-03 21:51:54.931 DEBUG: Atoms are too close
2023-01-03 21:51:57.988 INFO: Training rollout: return=-0.554 (3.7), episode length=6.0
2023-01-03 21:51:57.989 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:51:57.992 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-17928_train.pkl
2023-01-03 21:51:59.047 DEBUG: Taking gradient step
2023-01-03 21:51:59.057 DEBUG: Loss 0: {'policy_loss': -0.0451566582476103, 'entropy_loss': -0.0782589390873909, 'vf_loss': 0.009520589904007205, 'total_loss': -0.113895007430994, 'approx_kl': -4.198712844072361e-08, 'clip_fraction': 0.0, 'grad_norm': 10.665580749511719}
2023-01-03 21:52:00.077 DEBUG: Taking gradient step
2023-01-03 21:52:00.086 DEBUG: Loss 1: {'policy_loss': -0.04170525066555597, 'entropy_loss': -0.07829915173351765, 'vf_loss': 0.009831431510743168, 'total_loss': -0.11017297088833045, 'approx_kl': -0.0009719202062115073, 'clip_fraction': 0.045572916977107525, 'grad_norm': 7.792562484741211}
2023-01-03 21:52:01.074 DEBUG: Taking gradient step
2023-01-03 21:52:01.082 DEBUG: Loss 2: {'policy_loss': -0.038767376851912505, 'entropy_loss': -0.0772851500660181, 'vf_loss': 0.010313327433547351, 'total_loss': -0.10573919948438326, 'approx_kl': 0.0024195965379476547, 'clip_fraction': 0.23828125, 'grad_norm': 4.409538269042969}
2023-01-03 21:52:02.101 DEBUG: Taking gradient step
2023-01-03 21:52:02.110 DEBUG: Loss 3: {'policy_loss': -0.05125883978739263, 'entropy_loss': -0.0781664252281189, 'vf_loss': 0.009925871361921041, 'total_loss': -0.11949939365359048, 'approx_kl': 0.03506457735784352, 'clip_fraction': 0.3346354216337204, 'grad_norm': 5.096347808837891}
2023-01-03 21:52:03.134 DEBUG: Taking gradient step
2023-01-03 21:52:03.144 DEBUG: Loss 4: {'policy_loss': -0.05400115109532939, 'entropy_loss': -0.07769430801272392, 'vf_loss': 0.009757401736038417, 'total_loss': -0.12193805737201491, 'approx_kl': 0.04377395287156105, 'clip_fraction': 0.3932291716337204, 'grad_norm': 5.468595504760742}
2023-01-03 21:52:04.172 DEBUG: Taking gradient step
2023-01-03 21:52:04.182 DEBUG: Loss 5: {'policy_loss': 0.029273467256307, 'entropy_loss': -0.0773073062300682, 'vf_loss': 0.014395919226765608, 'total_loss': -0.03363791974699559, 'approx_kl': 0.03682380169630051, 'clip_fraction': 0.4309895932674408, 'grad_norm': 4.1822919845581055}
2023-01-03 21:52:05.208 DEBUG: Taking gradient step
2023-01-03 21:52:05.216 DEBUG: Loss 6: {'policy_loss': -0.033817694405263374, 'entropy_loss': -0.07650774531066418, 'vf_loss': 0.0108158317588901, 'total_loss': -0.09950960795703745, 'approx_kl': 0.03493786230683327, 'clip_fraction': 0.3971354216337204, 'grad_norm': 10.275420188903809}
2023-01-03 21:52:06.209 DEBUG: Taking gradient step
2023-01-03 21:52:06.218 DEBUG: Loss 7: {'policy_loss': -0.03191120365715193, 'entropy_loss': -0.07656400091946125, 'vf_loss': 0.01094688660538231, 'total_loss': -0.09752831797123089, 'approx_kl': 0.031243830919265747, 'clip_fraction': 0.4283854216337204, 'grad_norm': 5.133113861083984}
2023-01-03 21:52:07.232 DEBUG: Taking gradient step
2023-01-03 21:52:07.241 DEBUG: Loss 8: {'policy_loss': 0.008125210035422631, 'entropy_loss': -0.07668403722345829, 'vf_loss': 0.012711750773365185, 'total_loss': -0.05584707641467046, 'approx_kl': 0.039193910313770175, 'clip_fraction': 0.4765625, 'grad_norm': 4.293792247772217}
2023-01-03 21:52:08.252 DEBUG: Early stopping at step 9 for reaching max KL.
2023-01-03 21:52:08.253 INFO: Optimization: policy loss=0.008, vf loss=0.013, entropy loss=-0.077, total loss=-0.056, num steps=9
2023-01-03 21:52:08.253 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:52:09.864 INFO: Evaluation rollout: return=0.632 (0.0), episode length=6.0
2023-01-03 21:52:09.867 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:52:09.870 INFO: Iteration: 84/137, steps: 18144
2023-01-03 21:53:04.429 INFO: Training rollout: return=0.547 (0.1), episode length=6.0
2023-01-03 21:53:04.430 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:53:04.433 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-18144_train.pkl
2023-01-03 21:53:05.376 DEBUG: Taking gradient step
2023-01-03 21:53:05.386 DEBUG: Loss 0: {'policy_loss': 0.01900796946636752, 'entropy_loss': -0.07799120433628559, 'vf_loss': 0.00023534588862619794, 'total_loss': -0.05874788898129187, 'approx_kl': 6.876265246091862e-08, 'clip_fraction': 0.0, 'grad_norm': 14.364067077636719}
2023-01-03 21:53:06.413 DEBUG: Taking gradient step
2023-01-03 21:53:06.423 DEBUG: Loss 1: {'policy_loss': 0.010861800084284182, 'entropy_loss': -0.07858015038073063, 'vf_loss': 0.00026553482256718065, 'total_loss': -0.06745281547387927, 'approx_kl': 0.003599312622100115, 'clip_fraction': 0.03645833395421505, 'grad_norm': 10.564539909362793}
2023-01-03 21:53:07.441 DEBUG: Taking gradient step
2023-01-03 21:53:07.450 DEBUG: Loss 2: {'policy_loss': -0.014619638777241817, 'entropy_loss': -0.07709771767258644, 'vf_loss': 0.00029557090927346494, 'total_loss': -0.09142178554055479, 'approx_kl': 0.015035929856821895, 'clip_fraction': 0.13020833395421505, 'grad_norm': 11.756665229797363}
2023-01-03 21:53:08.471 DEBUG: Taking gradient step
2023-01-03 21:53:08.480 DEBUG: Loss 3: {'policy_loss': -9.872486694172122e-06, 'entropy_loss': -0.07710250839591026, 'vf_loss': 0.0003141034085882106, 'total_loss': -0.07679827747401621, 'approx_kl': 0.025539933005347848, 'clip_fraction': 0.2669270858168602, 'grad_norm': 10.540186882019043}
2023-01-03 21:53:09.482 DEBUG: Early stopping at step 4 for reaching max KL.
2023-01-03 21:53:09.483 INFO: Optimization: policy loss=-0.000, vf loss=0.000, entropy loss=-0.077, total loss=-0.077, num steps=4
2023-01-03 21:53:09.483 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:53:11.100 INFO: Evaluation rollout: return=0.651 (0.0), episode length=6.0
2023-01-03 21:53:11.101 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:53:11.104 INFO: Iteration: 85/137, steps: 18360
2023-01-03 21:53:27.948 DEBUG: Atoms are too close
2023-01-03 21:54:02.187 DEBUG: Atoms are too close
2023-01-03 21:54:05.213 INFO: Training rollout: return=-0.157 (3.1), episode length=6.0
2023-01-03 21:54:05.214 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:54:05.217 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-18360_train.pkl
2023-01-03 21:54:06.231 DEBUG: Taking gradient step
2023-01-03 21:54:06.242 DEBUG: Loss 0: {'policy_loss': -0.01754099910294389, 'entropy_loss': -0.07615096680819988, 'vf_loss': 0.006555254211051512, 'total_loss': -0.08713671170009225, 'approx_kl': 4.21423465013504e-08, 'clip_fraction': 0.0, 'grad_norm': 10.836570739746094}
2023-01-03 21:54:07.269 DEBUG: Taking gradient step
2023-01-03 21:54:07.280 DEBUG: Loss 1: {'policy_loss': 0.03250009556643794, 'entropy_loss': -0.07588407024741173, 'vf_loss': 0.008469420816031765, 'total_loss': -0.03491455386494202, 'approx_kl': -0.0008135417010635138, 'clip_fraction': 0.09635416697710752, 'grad_norm': 10.079954147338867}
2023-01-03 21:54:08.297 DEBUG: Taking gradient step
2023-01-03 21:54:08.308 DEBUG: Loss 2: {'policy_loss': 0.013796229988524325, 'entropy_loss': -0.07683620229363441, 'vf_loss': 0.00799199820849728, 'total_loss': -0.055047974096612814, 'approx_kl': 0.0025057243183255196, 'clip_fraction': 0.3177083358168602, 'grad_norm': 17.94445037841797}
2023-01-03 21:54:09.298 DEBUG: Taking gradient step
2023-01-03 21:54:09.306 DEBUG: Loss 3: {'policy_loss': -0.010627622367937968, 'entropy_loss': -0.07560464553534985, 'vf_loss': 0.00740433966039656, 'total_loss': -0.07882792824289125, 'approx_kl': 0.02653714083135128, 'clip_fraction': 0.3216145858168602, 'grad_norm': 12.137709617614746}
2023-01-03 21:54:10.325 DEBUG: Taking gradient step
2023-01-03 21:54:10.334 DEBUG: Loss 4: {'policy_loss': -0.04850160110583787, 'entropy_loss': -0.0749928466975689, 'vf_loss': 0.006247679726321538, 'total_loss': -0.11724676807708523, 'approx_kl': 0.03680787538178265, 'clip_fraction': 0.30859375, 'grad_norm': 7.074738502502441}
2023-01-03 21:54:11.363 DEBUG: Early stopping at step 5 for reaching max KL.
2023-01-03 21:54:11.364 INFO: Optimization: policy loss=-0.049, vf loss=0.006, entropy loss=-0.075, total loss=-0.117, num steps=5
2023-01-03 21:54:11.364 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:54:13.018 INFO: Evaluation rollout: return=0.667 (0.0), episode length=6.0
2023-01-03 21:54:13.019 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:54:13.023 INFO: Iteration: 86/137, steps: 18576
2023-01-03 21:54:58.869 DEBUG: Atoms are too close
2023-01-03 21:55:04.822 DEBUG: There is a single atom floating around
2023-01-03 21:55:05.897 DEBUG: There is a single atom floating around
2023-01-03 21:55:06.481 INFO: Training rollout: return=-0.674 (4.2), episode length=5.9
2023-01-03 21:55:06.482 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:55:06.485 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-18576_train.pkl
2023-01-03 21:55:07.517 DEBUG: Taking gradient step
2023-01-03 21:55:07.527 DEBUG: Loss 0: {'policy_loss': 0.0002115207216810318, 'entropy_loss': -0.07545657828450203, 'vf_loss': 0.010354050149337471, 'total_loss': -0.06489100741348353, 'approx_kl': 2.4291999523029517e-08, 'clip_fraction': 0.0, 'grad_norm': 12.068103790283203}
2023-01-03 21:55:08.506 DEBUG: Taking gradient step
2023-01-03 21:55:08.515 DEBUG: Loss 1: {'policy_loss': -0.046571709458939986, 'entropy_loss': -0.07514415308833122, 'vf_loss': 0.008921025667461682, 'total_loss': -0.11279483687980953, 'approx_kl': 0.013763360388111323, 'clip_fraction': 0.04036458395421505, 'grad_norm': 10.835771560668945}
2023-01-03 21:55:09.532 DEBUG: Taking gradient step
2023-01-03 21:55:09.540 DEBUG: Loss 2: {'policy_loss': -0.0485454427405003, 'entropy_loss': -0.07505097799003124, 'vf_loss': 0.008924541257937664, 'total_loss': -0.11467187947259389, 'approx_kl': 0.03611040720716119, 'clip_fraction': 0.1875, 'grad_norm': 15.250524520874023}
2023-01-03 21:55:10.554 DEBUG: Taking gradient step
2023-01-03 21:55:10.564 DEBUG: Loss 3: {'policy_loss': -0.011833625842962093, 'entropy_loss': -0.07609295845031738, 'vf_loss': 0.010704119207514434, 'total_loss': -0.07722246508576504, 'approx_kl': 0.04147585015743971, 'clip_fraction': 0.22265625, 'grad_norm': 17.412067413330078}
2023-01-03 21:55:11.582 DEBUG: Early stopping at step 4 for reaching max KL.
2023-01-03 21:55:11.582 INFO: Optimization: policy loss=-0.012, vf loss=0.011, entropy loss=-0.076, total loss=-0.077, num steps=4
2023-01-03 21:55:11.583 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:55:12.963 DEBUG: Atoms are too close
2023-01-03 21:55:12.965 INFO: Evaluation rollout: return=-12.820 (0.0), episode length=6.0
2023-01-03 21:55:12.965 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:55:12.967 INFO: Iteration: 87/137, steps: 18792
2023-01-03 21:56:07.772 INFO: Training rollout: return=0.579 (0.1), episode length=6.0
2023-01-03 21:56:07.773 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:56:07.776 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-18792_train.pkl
2023-01-03 21:56:08.819 DEBUG: Taking gradient step
2023-01-03 21:56:08.829 DEBUG: Loss 0: {'policy_loss': -0.008411769563434469, 'entropy_loss': -0.07705181278288364, 'vf_loss': 0.00046602211040704225, 'total_loss': -0.08499756023591107, 'approx_kl': 8.079223334789276e-08, 'clip_fraction': 0.0, 'grad_norm': 9.865227699279785}
2023-01-03 21:56:09.849 DEBUG: Taking gradient step
2023-01-03 21:56:09.858 DEBUG: Loss 1: {'policy_loss': 0.019948973660619287, 'entropy_loss': -0.0770503394305706, 'vf_loss': 0.000460511446046349, 'total_loss': -0.05664085432390497, 'approx_kl': -0.01087842951528728, 'clip_fraction': 0.0234375, 'grad_norm': 8.46453857421875}
2023-01-03 21:56:10.868 DEBUG: Taking gradient step
2023-01-03 21:56:10.877 DEBUG: Loss 2: {'policy_loss': -0.08712627450289809, 'entropy_loss': -0.07776675559580326, 'vf_loss': 0.00048376021408723445, 'total_loss': -0.1644092698846141, 'approx_kl': -0.01433843676932156, 'clip_fraction': 0.19921875, 'grad_norm': 15.132623672485352}
2023-01-03 21:56:11.895 DEBUG: Taking gradient step
2023-01-03 21:56:11.905 DEBUG: Loss 3: {'policy_loss': -0.04213574578087922, 'entropy_loss': -0.07799657993018627, 'vf_loss': 0.0004641191447750732, 'total_loss': -0.1196682065662904, 'approx_kl': -0.006039215950295329, 'clip_fraction': 0.3619791716337204, 'grad_norm': 10.646854400634766}
2023-01-03 21:56:12.883 DEBUG: Taking gradient step
2023-01-03 21:56:12.893 DEBUG: Loss 4: {'policy_loss': 0.03255113949397786, 'entropy_loss': -0.07711217738687992, 'vf_loss': 0.0004416890615420331, 'total_loss': -0.044119348831360025, 'approx_kl': -0.000881620217114687, 'clip_fraction': 0.3541666716337204, 'grad_norm': 9.892313957214355}
2023-01-03 21:56:13.914 DEBUG: Taking gradient step
2023-01-03 21:56:13.923 DEBUG: Loss 5: {'policy_loss': -0.015439640707701978, 'entropy_loss': -0.07828354835510254, 'vf_loss': 0.00043818656531996594, 'total_loss': -0.09328500249748456, 'approx_kl': -0.012058720458298922, 'clip_fraction': 0.3111979216337204, 'grad_norm': 7.805675983428955}
2023-01-03 21:56:14.951 DEBUG: Taking gradient step
2023-01-03 21:56:14.960 DEBUG: Loss 6: {'policy_loss': 0.005036426183387545, 'entropy_loss': -0.07721497491002083, 'vf_loss': 0.00042155789010817025, 'total_loss': -0.0717569908365251, 'approx_kl': -0.015188825316727161, 'clip_fraction': 0.32421875, 'grad_norm': 10.249404907226562}
2023-01-03 21:56:15.990 DEBUG: Taking gradient step
2023-01-03 21:56:16.000 DEBUG: Loss 7: {'policy_loss': -0.047284162764774304, 'entropy_loss': -0.07774134166538715, 'vf_loss': 0.00041474841875357364, 'total_loss': -0.12461075601140786, 'approx_kl': -0.0138649822329171, 'clip_fraction': 0.3984375, 'grad_norm': 9.257558822631836}
2023-01-03 21:56:16.985 DEBUG: Taking gradient step
2023-01-03 21:56:16.994 DEBUG: Loss 8: {'policy_loss': -0.0222160192782287, 'entropy_loss': -0.07774855196475983, 'vf_loss': 0.00039525297962678986, 'total_loss': -0.09956931826336174, 'approx_kl': -0.021476684836670756, 'clip_fraction': 0.3515625, 'grad_norm': 7.919005393981934}
2023-01-03 21:56:18.015 DEBUG: Taking gradient step
2023-01-03 21:56:18.025 DEBUG: Loss 9: {'policy_loss': -0.023672528279180025, 'entropy_loss': -0.0780220739543438, 'vf_loss': 0.0003723496075358157, 'total_loss': -0.10132225262598801, 'approx_kl': -0.004624770954251289, 'clip_fraction': 0.41015625, 'grad_norm': 8.646404266357422}
2023-01-03 21:56:19.054 DEBUG: Taking gradient step
2023-01-03 21:56:19.063 DEBUG: Loss 10: {'policy_loss': -0.09301759143139282, 'entropy_loss': -0.07840297929942608, 'vf_loss': 0.0003644538017476247, 'total_loss': -0.17105611692907127, 'approx_kl': 0.006533026695251465, 'clip_fraction': 0.38671875, 'grad_norm': 8.206947326660156}
2023-01-03 21:56:20.112 DEBUG: Taking gradient step
2023-01-03 21:56:20.122 DEBUG: Loss 11: {'policy_loss': -0.04259583209432341, 'entropy_loss': -0.07830716669559479, 'vf_loss': 0.000329231914328012, 'total_loss': -0.12057376687559018, 'approx_kl': 0.02028672443702817, 'clip_fraction': 0.4036458358168602, 'grad_norm': 7.953568458557129}
2023-01-03 21:56:21.127 DEBUG: Taking gradient step
2023-01-03 21:56:21.135 DEBUG: Loss 12: {'policy_loss': 0.027919926693008718, 'entropy_loss': -0.07777681201696396, 'vf_loss': 0.00030424985155197166, 'total_loss': -0.04955263547240327, 'approx_kl': 0.013747058808803558, 'clip_fraction': 0.41015625, 'grad_norm': 11.098963737487793}
2023-01-03 21:56:22.150 DEBUG: Taking gradient step
2023-01-03 21:56:22.159 DEBUG: Loss 13: {'policy_loss': -0.06025648978847345, 'entropy_loss': -0.07923967950046062, 'vf_loss': 0.0002928691408379074, 'total_loss': -0.13920330014809615, 'approx_kl': 0.019315183628350496, 'clip_fraction': 0.43359375, 'grad_norm': 12.08802318572998}
2023-01-03 21:56:23.129 DEBUG: Taking gradient step
2023-01-03 21:56:23.137 DEBUG: Loss 14: {'policy_loss': 0.017579645970006386, 'entropy_loss': -0.0795166976749897, 'vf_loss': 0.0002679615652916912, 'total_loss': -0.06166909013969163, 'approx_kl': 0.018458062084391713, 'clip_fraction': 0.5208333432674408, 'grad_norm': 8.523772239685059}
2023-01-03 21:56:23.138 INFO: Optimization: policy loss=0.018, vf loss=0.000, entropy loss=-0.080, total loss=-0.062, num steps=15
2023-01-03 21:56:23.138 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:56:24.554 DEBUG: Atoms are too close
2023-01-03 21:56:24.556 INFO: Evaluation rollout: return=-12.841 (0.0), episode length=6.0
2023-01-03 21:56:24.557 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:56:24.559 INFO: Iteration: 88/137, steps: 19008
2023-01-03 21:57:20.465 INFO: Training rollout: return=0.533 (0.1), episode length=6.0
2023-01-03 21:57:20.467 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:57:20.469 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-19008_train.pkl
2023-01-03 21:57:21.509 DEBUG: Taking gradient step
2023-01-03 21:57:21.518 DEBUG: Loss 0: {'policy_loss': 0.016246705817073288, 'entropy_loss': -0.07993650063872337, 'vf_loss': 0.00025631233301400924, 'total_loss': -0.06343348248863608, 'approx_kl': 1.6919027956419086e-08, 'clip_fraction': 0.0, 'grad_norm': 14.612993240356445}
2023-01-03 21:57:22.503 DEBUG: Taking gradient step
2023-01-03 21:57:22.513 DEBUG: Loss 1: {'policy_loss': 0.04774270100447599, 'entropy_loss': -0.07983079738914967, 'vf_loss': 0.00023403643390618525, 'total_loss': -0.03185405995076748, 'approx_kl': 0.004747793776914477, 'clip_fraction': 0.09765625, 'grad_norm': 11.700033187866211}
2023-01-03 21:57:23.527 DEBUG: Taking gradient step
2023-01-03 21:57:23.536 DEBUG: Loss 2: {'policy_loss': 0.016985058085622406, 'entropy_loss': -0.07973298244178295, 'vf_loss': 0.0002259734102768281, 'total_loss': -0.06252195094588373, 'approx_kl': 0.029891947750002146, 'clip_fraction': 0.2890625, 'grad_norm': 12.697860717773438}
2023-01-03 21:57:24.551 DEBUG: Taking gradient step
2023-01-03 21:57:24.560 DEBUG: Loss 3: {'policy_loss': 0.0034647881773786186, 'entropy_loss': -0.08033358864486217, 'vf_loss': 0.00021278531797419326, 'total_loss': -0.07665601514950937, 'approx_kl': 0.02264102641493082, 'clip_fraction': 0.35546875, 'grad_norm': 14.70032024383545}
2023-01-03 21:57:25.578 DEBUG: Taking gradient step
2023-01-03 21:57:25.588 DEBUG: Loss 4: {'policy_loss': -0.040118661678767105, 'entropy_loss': -0.08105463907122612, 'vf_loss': 0.0002007858944767006, 'total_loss': -0.12097251485551652, 'approx_kl': 0.021952612791210413, 'clip_fraction': 0.3736979216337204, 'grad_norm': 11.644377708435059}
2023-01-03 21:57:26.565 DEBUG: Taking gradient step
2023-01-03 21:57:26.573 DEBUG: Loss 5: {'policy_loss': 0.024731418083781598, 'entropy_loss': -0.07985222898423672, 'vf_loss': 0.00018647060764520075, 'total_loss': -0.054934340292809906, 'approx_kl': 0.01569624152034521, 'clip_fraction': 0.35546875, 'grad_norm': 9.361430168151855}
2023-01-03 21:57:27.583 DEBUG: Taking gradient step
2023-01-03 21:57:27.592 DEBUG: Loss 6: {'policy_loss': -0.015613921320635415, 'entropy_loss': -0.07937581464648247, 'vf_loss': 0.0001813827279184521, 'total_loss': -0.09480835323919944, 'approx_kl': 0.013479971094056964, 'clip_fraction': 0.296875, 'grad_norm': 12.32850170135498}
2023-01-03 21:57:28.603 DEBUG: Taking gradient step
2023-01-03 21:57:28.614 DEBUG: Loss 7: {'policy_loss': -0.009203582687409659, 'entropy_loss': -0.07932854816317558, 'vf_loss': 0.00016535245867626948, 'total_loss': -0.08836677839190898, 'approx_kl': 0.013437900226563215, 'clip_fraction': 0.3684895858168602, 'grad_norm': 4.8880615234375}
2023-01-03 21:57:29.629 DEBUG: Taking gradient step
2023-01-03 21:57:29.637 DEBUG: Loss 8: {'policy_loss': -0.054948504922732275, 'entropy_loss': -0.08015336468815804, 'vf_loss': 0.00015989588020909123, 'total_loss': -0.13494197373068123, 'approx_kl': 0.018056587083265185, 'clip_fraction': 0.3489583358168602, 'grad_norm': 8.983346939086914}
2023-01-03 21:57:30.649 DEBUG: Taking gradient step
2023-01-03 21:57:30.657 DEBUG: Loss 9: {'policy_loss': -0.06280081487904428, 'entropy_loss': -0.08065414242446423, 'vf_loss': 0.0001489533985462723, 'total_loss': -0.14330600390496223, 'approx_kl': 0.002055471297353506, 'clip_fraction': 0.36328125, 'grad_norm': 10.787032127380371}
2023-01-03 21:57:31.637 DEBUG: Taking gradient step
2023-01-03 21:57:31.645 DEBUG: Loss 10: {'policy_loss': -0.033766564103151556, 'entropy_loss': -0.07999704778194427, 'vf_loss': 0.00013663501631564637, 'total_loss': -0.11362697686878018, 'approx_kl': 0.006591471843421459, 'clip_fraction': 0.3294270858168602, 'grad_norm': 9.82486343383789}
2023-01-03 21:57:32.658 DEBUG: Taking gradient step
2023-01-03 21:57:32.666 DEBUG: Loss 11: {'policy_loss': 0.009863978244376834, 'entropy_loss': -0.0804064180701971, 'vf_loss': 0.00013041305813551207, 'total_loss': -0.07041202676768474, 'approx_kl': 0.0250990001950413, 'clip_fraction': 0.3424479216337204, 'grad_norm': 11.239078521728516}
2023-01-03 21:57:33.684 DEBUG: Taking gradient step
2023-01-03 21:57:33.693 DEBUG: Loss 12: {'policy_loss': -0.06405063559287075, 'entropy_loss': -0.08044633083045483, 'vf_loss': 0.0001268419783258108, 'total_loss': -0.14437012444499975, 'approx_kl': 0.009381179930642247, 'clip_fraction': 0.3893229216337204, 'grad_norm': 8.596844673156738}
2023-01-03 21:57:34.712 DEBUG: Taking gradient step
2023-01-03 21:57:34.721 DEBUG: Loss 13: {'policy_loss': -0.023099600556542324, 'entropy_loss': -0.08030860871076584, 'vf_loss': 0.00011494376546303859, 'total_loss': -0.10329326550184513, 'approx_kl': 0.02058850950561464, 'clip_fraction': 0.4010416679084301, 'grad_norm': 9.13908863067627}
2023-01-03 21:57:35.717 DEBUG: Taking gradient step
2023-01-03 21:57:35.726 DEBUG: Loss 14: {'policy_loss': -0.025348111345815202, 'entropy_loss': -0.08002220280468464, 'vf_loss': 0.00010652256666538293, 'total_loss': -0.10526379158383446, 'approx_kl': 0.029292584396898746, 'clip_fraction': 0.4231770858168602, 'grad_norm': 10.903275489807129}
2023-01-03 21:57:35.726 INFO: Optimization: policy loss=-0.025, vf loss=0.000, entropy loss=-0.080, total loss=-0.105, num steps=15
2023-01-03 21:57:35.726 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:57:37.324 INFO: Evaluation rollout: return=0.563 (0.0), episode length=6.0
2023-01-03 21:57:37.325 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:57:37.328 INFO: Iteration: 89/137, steps: 19224
2023-01-03 21:57:49.825 DEBUG: There is a single atom floating around
2023-01-03 21:58:00.027 DEBUG: There is a single atom floating around
2023-01-03 21:58:10.655 DEBUG: Atoms are too close
2023-01-03 21:58:32.064 INFO: Training rollout: return=-0.995 (5.3), episode length=5.9
2023-01-03 21:58:32.066 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:58:32.068 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-19224_train.pkl
2023-01-03 21:58:33.099 DEBUG: Taking gradient step
2023-01-03 21:58:33.110 DEBUG: Loss 0: {'policy_loss': -0.0011466739095840638, 'entropy_loss': -0.08007672987878323, 'vf_loss': 0.00967745492996204, 'total_loss': -0.07154594885840525, 'approx_kl': 7.543712854385376e-08, 'clip_fraction': 0.0, 'grad_norm': 24.894695281982422}
2023-01-03 21:58:34.119 DEBUG: Taking gradient step
2023-01-03 21:58:34.128 DEBUG: Loss 1: {'policy_loss': -0.00698724158738756, 'entropy_loss': -0.08059563115239143, 'vf_loss': 0.010003072326190328, 'total_loss': -0.07757980041358867, 'approx_kl': 0.0016294661909341812, 'clip_fraction': 0.04036458395421505, 'grad_norm': 9.42090129852295}
2023-01-03 21:58:35.143 DEBUG: Taking gradient step
2023-01-03 21:58:35.152 DEBUG: Loss 2: {'policy_loss': -0.05270287581066635, 'entropy_loss': -0.0794150959700346, 'vf_loss': 0.007958508703071123, 'total_loss': -0.12415946307762982, 'approx_kl': 0.02201633295044303, 'clip_fraction': 0.1875, 'grad_norm': 7.233808994293213}
2023-01-03 21:58:36.143 DEBUG: Early stopping at step 3 for reaching max KL.
2023-01-03 21:58:36.144 INFO: Optimization: policy loss=-0.053, vf loss=0.008, entropy loss=-0.079, total loss=-0.124, num steps=3
2023-01-03 21:58:36.144 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:58:37.777 INFO: Evaluation rollout: return=0.558 (0.0), episode length=6.0
2023-01-03 21:58:37.778 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:58:37.781 INFO: Iteration: 90/137, steps: 19440
2023-01-03 21:58:47.099 DEBUG: Atoms are too close
2023-01-03 21:58:53.180 DEBUG: There is a single atom floating around
2023-01-03 21:59:21.971 DEBUG: There is a single atom floating around
2023-01-03 21:59:32.930 INFO: Training rollout: return=-0.947 (5.1), episode length=5.9
2023-01-03 21:59:32.932 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 21:59:32.935 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-19440_train.pkl
2023-01-03 21:59:33.967 DEBUG: Taking gradient step
2023-01-03 21:59:33.978 DEBUG: Loss 0: {'policy_loss': 0.020936088616207528, 'entropy_loss': -0.07876640371978283, 'vf_loss': 0.01068250692787823, 'total_loss': -0.04714780817569707, 'approx_kl': -3.864988684654236e-08, 'clip_fraction': 0.0, 'grad_norm': 15.54721736907959}
2023-01-03 21:59:34.957 DEBUG: Taking gradient step
2023-01-03 21:59:34.966 DEBUG: Loss 1: {'policy_loss': 0.007580348742699389, 'entropy_loss': -0.07862711884081364, 'vf_loss': 0.010309386854981334, 'total_loss': -0.060737383243132916, 'approx_kl': 0.005675493273884058, 'clip_fraction': 0.11328125, 'grad_norm': 11.57286262512207}
2023-01-03 21:59:35.982 DEBUG: Taking gradient step
2023-01-03 21:59:35.991 DEBUG: Loss 2: {'policy_loss': -0.051193287066323576, 'entropy_loss': -0.07979543320834637, 'vf_loss': 0.00819651307077166, 'total_loss': -0.12279220720389829, 'approx_kl': 0.015887768007814884, 'clip_fraction': 0.2330729216337204, 'grad_norm': 4.565490245819092}
2023-01-03 21:59:37.014 DEBUG: Early stopping at step 3 for reaching max KL.
2023-01-03 21:59:37.015 INFO: Optimization: policy loss=-0.051, vf loss=0.008, entropy loss=-0.080, total loss=-0.123, num steps=3
2023-01-03 21:59:37.015 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 21:59:38.646 INFO: Evaluation rollout: return=0.513 (0.0), episode length=6.0
2023-01-03 21:59:38.647 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 21:59:38.650 DEBUG: Deleting old model: runs/CH3NO_baseline/models/CH3NO_baseline_run-1_steps-17496.model
2023-01-03 21:59:38.653 DEBUG: Saving model: runs/CH3NO_baseline/models/CH3NO_baseline_run-1_steps-19656.model
2023-01-03 21:59:38.682 INFO: Iteration: 91/137, steps: 19656
2023-01-03 22:00:33.647 INFO: Training rollout: return=0.534 (0.1), episode length=6.0
2023-01-03 22:00:33.648 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 22:00:33.652 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-19656_train.pkl
2023-01-03 22:00:34.702 DEBUG: Taking gradient step
2023-01-03 22:00:34.711 DEBUG: Loss 0: {'policy_loss': 0.016974932727104045, 'entropy_loss': -0.0783365722745657, 'vf_loss': 8.529769400503162e-05, 'total_loss': -0.06127634185345662, 'approx_kl': -2.468004822731018e-08, 'clip_fraction': 0.0, 'grad_norm': 12.412013053894043}
2023-01-03 22:00:35.740 DEBUG: Taking gradient step
2023-01-03 22:00:35.749 DEBUG: Loss 1: {'policy_loss': -0.007146824080670116, 'entropy_loss': -0.07809706404805183, 'vf_loss': 8.457026229579863e-05, 'total_loss': -0.08515931786642617, 'approx_kl': 0.014828765764832497, 'clip_fraction': 0.07291666697710752, 'grad_norm': 10.789427757263184}
2023-01-03 22:00:36.786 DEBUG: Taking gradient step
2023-01-03 22:00:36.796 DEBUG: Loss 2: {'policy_loss': -0.026431295881579806, 'entropy_loss': -0.07819824293255806, 'vf_loss': 8.694507962614205e-05, 'total_loss': -0.10454259373451172, 'approx_kl': 0.033980624517425895, 'clip_fraction': 0.2408854179084301, 'grad_norm': 10.122730255126953}
2023-01-03 22:00:37.815 DEBUG: Early stopping at step 3 for reaching max KL.
2023-01-03 22:00:37.815 INFO: Optimization: policy loss=-0.026, vf loss=0.000, entropy loss=-0.078, total loss=-0.105, num steps=3
2023-01-03 22:00:37.815 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 22:00:39.457 INFO: Evaluation rollout: return=0.509 (0.0), episode length=6.0
2023-01-03 22:00:39.459 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 22:00:39.463 INFO: Iteration: 92/137, steps: 19872
2023-01-03 22:00:53.573 DEBUG: There is a single atom floating around
2023-01-03 22:01:08.128 DEBUG: There is a single atom floating around
2023-01-03 22:01:33.853 INFO: Training rollout: return=-0.333 (3.6), episode length=5.9
2023-01-03 22:01:33.855 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 22:01:33.858 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-19872_train.pkl
2023-01-03 22:01:34.925 DEBUG: Taking gradient step
2023-01-03 22:01:34.934 DEBUG: Loss 0: {'policy_loss': -0.014745354420850697, 'entropy_loss': -0.07978397607803345, 'vf_loss': 0.006434343642624313, 'total_loss': -0.08809498685625983, 'approx_kl': 9.468446293681154e-08, 'clip_fraction': 0.0, 'grad_norm': 17.113811492919922}
2023-01-03 22:01:35.984 DEBUG: Taking gradient step
2023-01-03 22:01:35.993 DEBUG: Loss 1: {'policy_loss': 0.0029768656973926666, 'entropy_loss': -0.07996884174644947, 'vf_loss': 0.007206983737429675, 'total_loss': -0.06978499231162712, 'approx_kl': 0.008880597073584795, 'clip_fraction': 0.10286458395421505, 'grad_norm': 15.969822883605957}
2023-01-03 22:01:37.015 DEBUG: Taking gradient step
2023-01-03 22:01:37.023 DEBUG: Loss 2: {'policy_loss': -0.006834404668438116, 'entropy_loss': -0.07990237511694431, 'vf_loss': 0.0077129370796678275, 'total_loss': -0.07902384270571461, 'approx_kl': 0.0368386497721076, 'clip_fraction': 0.28125, 'grad_norm': 9.78646183013916}
2023-01-03 22:01:38.081 DEBUG: Early stopping at step 3 for reaching max KL.
2023-01-03 22:01:38.081 INFO: Optimization: policy loss=-0.007, vf loss=0.008, entropy loss=-0.080, total loss=-0.079, num steps=3
2023-01-03 22:01:38.082 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 22:01:39.751 INFO: Evaluation rollout: return=0.553 (0.0), episode length=6.0
2023-01-03 22:01:39.752 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 22:01:39.755 INFO: Iteration: 93/137, steps: 20088
2023-01-03 22:02:36.663 INFO: Training rollout: return=0.573 (0.0), episode length=6.0
2023-01-03 22:02:36.667 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 22:02:36.671 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-20088_train.pkl
2023-01-03 22:02:37.678 DEBUG: Taking gradient step
2023-01-03 22:02:37.687 DEBUG: Loss 0: {'policy_loss': 0.020282476898696045, 'entropy_loss': -0.07795031182467937, 'vf_loss': 8.305300804708307e-05, 'total_loss': -0.057584781917936236, 'approx_kl': 8.226683334555673e-09, 'clip_fraction': 0.0, 'grad_norm': 9.322405815124512}
2023-01-03 22:02:38.726 DEBUG: Taking gradient step
2023-01-03 22:02:38.734 DEBUG: Loss 1: {'policy_loss': -0.00464434596117249, 'entropy_loss': -0.07774153351783752, 'vf_loss': 8.525606468820284e-05, 'total_loss': -0.08230062341432182, 'approx_kl': 0.011672837659716606, 'clip_fraction': 0.1197916679084301, 'grad_norm': 9.223979949951172}
2023-01-03 22:02:39.775 DEBUG: Taking gradient step
2023-01-03 22:02:39.784 DEBUG: Loss 2: {'policy_loss': -0.0011849754274155591, 'entropy_loss': -0.07801813259720802, 'vf_loss': 8.315462363984251e-05, 'total_loss': -0.07911995340098374, 'approx_kl': 0.016897242894629017, 'clip_fraction': 0.2604166716337204, 'grad_norm': 13.299492835998535}
2023-01-03 22:02:40.822 DEBUG: Taking gradient step
2023-01-03 22:02:40.831 DEBUG: Loss 3: {'policy_loss': -0.015016025984037517, 'entropy_loss': -0.0776574406772852, 'vf_loss': 8.234047748171294e-05, 'total_loss': -0.092591126183841, 'approx_kl': 0.02876334125176072, 'clip_fraction': 0.2942708358168602, 'grad_norm': 10.023087501525879}
2023-01-03 22:02:41.852 DEBUG: Taking gradient step
2023-01-03 22:02:41.861 DEBUG: Loss 4: {'policy_loss': -0.012481881949562339, 'entropy_loss': -0.07682379521429539, 'vf_loss': 8.099856353880084e-05, 'total_loss': -0.08922467860031894, 'approx_kl': 0.018370618723565713, 'clip_fraction': 0.3072916716337204, 'grad_norm': 15.126763343811035}
2023-01-03 22:02:42.881 DEBUG: Taking gradient step
2023-01-03 22:02:42.890 DEBUG: Loss 5: {'policy_loss': -0.010848502461149274, 'entropy_loss': -0.07765367813408375, 'vf_loss': 7.784175827147232e-05, 'total_loss': -0.08842433883696155, 'approx_kl': 0.028400696348398924, 'clip_fraction': 0.3502604216337204, 'grad_norm': 7.420969486236572}
2023-01-03 22:02:43.929 DEBUG: Taking gradient step
2023-01-03 22:02:43.938 DEBUG: Loss 6: {'policy_loss': -0.0007720696512875935, 'entropy_loss': -0.07783536799252033, 'vf_loss': 7.529521259864544e-05, 'total_loss': -0.07853214243120929, 'approx_kl': 0.0390588806476444, 'clip_fraction': 0.4010416716337204, 'grad_norm': 10.33100414276123}
2023-01-03 22:02:44.978 DEBUG: Early stopping at step 7 for reaching max KL.
2023-01-03 22:02:44.979 INFO: Optimization: policy loss=-0.001, vf loss=0.000, entropy loss=-0.078, total loss=-0.079, num steps=7
2023-01-03 22:02:44.979 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 22:02:46.368 DEBUG: Atoms are too close
2023-01-03 22:02:46.369 INFO: Evaluation rollout: return=-12.791 (0.0), episode length=6.0
2023-01-03 22:02:46.370 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 22:02:46.373 INFO: Iteration: 94/137, steps: 20304
2023-01-03 22:03:43.902 INFO: Training rollout: return=0.584 (0.1), episode length=6.0
2023-01-03 22:03:43.903 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 22:03:43.906 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-20304_train.pkl
2023-01-03 22:03:44.994 DEBUG: Taking gradient step
2023-01-03 22:03:45.003 DEBUG: Loss 0: {'policy_loss': -0.007271907037337252, 'entropy_loss': -0.08039209246635437, 'vf_loss': 9.696816655303068e-05, 'total_loss': -0.08756703133713858, 'approx_kl': -7.916241884231567e-09, 'clip_fraction': 0.0, 'grad_norm': 22.47261619567871}
2023-01-03 22:03:46.074 DEBUG: Taking gradient step
2023-01-03 22:03:46.083 DEBUG: Loss 1: {'policy_loss': -0.038248087172292305, 'entropy_loss': -0.07971136458218098, 'vf_loss': 9.645768356834126e-05, 'total_loss': -0.11786299407090493, 'approx_kl': 0.011036952724680305, 'clip_fraction': 0.11328125, 'grad_norm': 11.985323905944824}
2023-01-03 22:03:47.151 DEBUG: Taking gradient step
2023-01-03 22:03:47.160 DEBUG: Loss 2: {'policy_loss': -0.03852781665096476, 'entropy_loss': -0.0800121296197176, 'vf_loss': 9.325377447942578e-05, 'total_loss': -0.11844669249620293, 'approx_kl': 0.021550742909312248, 'clip_fraction': 0.2434895858168602, 'grad_norm': 8.86122989654541}
2023-01-03 22:03:48.240 DEBUG: Early stopping at step 3 for reaching max KL.
2023-01-03 22:03:48.240 INFO: Optimization: policy loss=-0.039, vf loss=0.000, entropy loss=-0.080, total loss=-0.118, num steps=3
2023-01-03 22:03:48.241 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 22:03:49.981 INFO: Evaluation rollout: return=-0.262 (0.0), episode length=6.0
2023-01-03 22:03:49.984 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 22:03:49.986 INFO: Iteration: 95/137, steps: 20520
2023-01-03 22:04:47.912 INFO: Training rollout: return=0.544 (0.1), episode length=6.0
2023-01-03 22:04:47.913 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 22:04:47.916 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-20520_train.pkl
2023-01-03 22:04:49.004 DEBUG: Taking gradient step
2023-01-03 22:04:49.013 DEBUG: Loss 0: {'policy_loss': 0.04799820539369408, 'entropy_loss': -0.07932349666953087, 'vf_loss': 8.015292999558144e-05, 'total_loss': -0.0312451383458412, 'approx_kl': 5.704350769519806e-08, 'clip_fraction': 0.0, 'grad_norm': 15.848649024963379}
2023-01-03 22:04:50.047 DEBUG: Taking gradient step
2023-01-03 22:04:50.057 DEBUG: Loss 1: {'policy_loss': -0.055934217166834076, 'entropy_loss': -0.07927854545414448, 'vf_loss': 8.421863512802806e-05, 'total_loss': -0.1351285439858505, 'approx_kl': -0.0011305877706035972, 'clip_fraction': 0.05989583395421505, 'grad_norm': 8.194966316223145}
2023-01-03 22:04:51.153 DEBUG: Taking gradient step
2023-01-03 22:04:51.162 DEBUG: Loss 2: {'policy_loss': -0.01184371555290073, 'entropy_loss': -0.0804024264216423, 'vf_loss': 7.991473509474168e-05, 'total_loss': -0.0921662272394483, 'approx_kl': 0.010567030869424343, 'clip_fraction': 0.265625, 'grad_norm': 6.545622825622559}
2023-01-03 22:04:52.211 DEBUG: Taking gradient step
2023-01-03 22:04:52.219 DEBUG: Loss 3: {'policy_loss': -0.052241872070752225, 'entropy_loss': -0.0790518969297409, 'vf_loss': 7.881747566763682e-05, 'total_loss': -0.13121495152482548, 'approx_kl': 0.03244282957166433, 'clip_fraction': 0.3567708358168602, 'grad_norm': 6.551525592803955}
2023-01-03 22:04:53.279 DEBUG: Early stopping at step 4 for reaching max KL.
2023-01-03 22:04:53.279 INFO: Optimization: policy loss=-0.052, vf loss=0.000, entropy loss=-0.079, total loss=-0.131, num steps=4
2023-01-03 22:04:53.280 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 22:04:54.947 INFO: Evaluation rollout: return=-0.232 (0.0), episode length=6.0
2023-01-03 22:04:54.948 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 22:04:54.950 INFO: Iteration: 96/137, steps: 20736
2023-01-03 22:05:30.914 DEBUG: There is a single atom floating around
2023-01-03 22:05:50.609 INFO: Training rollout: return=0.214 (2.2), episode length=6.0
2023-01-03 22:05:50.611 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 22:05:50.614 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-20736_train.pkl
2023-01-03 22:05:51.762 DEBUG: Taking gradient step
2023-01-03 22:05:51.772 DEBUG: Loss 0: {'policy_loss': 0.011014879904041298, 'entropy_loss': -0.07815681770443916, 'vf_loss': 0.0040696247676767425, 'total_loss': -0.06307231303272112, 'approx_kl': 6.111804395914078e-08, 'clip_fraction': 0.0, 'grad_norm': 11.08462905883789}
2023-01-03 22:05:52.819 DEBUG: Taking gradient step
2023-01-03 22:05:52.829 DEBUG: Loss 1: {'policy_loss': 0.048650911153875584, 'entropy_loss': -0.07806453295052052, 'vf_loss': 0.005184170520278275, 'total_loss': -0.02422945127636665, 'approx_kl': -0.006349595176288858, 'clip_fraction': 0.06510416697710752, 'grad_norm': 5.574240684509277}
2023-01-03 22:05:53.881 DEBUG: Taking gradient step
2023-01-03 22:05:53.889 DEBUG: Loss 2: {'policy_loss': -0.04022346720347078, 'entropy_loss': -0.07915365509688854, 'vf_loss': 0.003200246187543361, 'total_loss': -0.11617687611281596, 'approx_kl': -0.003669171128422022, 'clip_fraction': 0.30859375, 'grad_norm': 3.9954164028167725}
2023-01-03 22:05:54.928 DEBUG: Taking gradient step
2023-01-03 22:05:54.937 DEBUG: Loss 3: {'policy_loss': -0.01947160703223669, 'entropy_loss': -0.07790397293865681, 'vf_loss': 0.003513684881672527, 'total_loss': -0.09386189508922096, 'approx_kl': -0.012404733803123236, 'clip_fraction': 0.3854166716337204, 'grad_norm': 3.0781002044677734}
2023-01-03 22:05:55.978 DEBUG: Taking gradient step
2023-01-03 22:05:55.986 DEBUG: Loss 4: {'policy_loss': -0.03996188178736807, 'entropy_loss': -0.07762146927416325, 'vf_loss': 0.003194913930945726, 'total_loss': -0.1143884371305856, 'approx_kl': 0.021541128866374493, 'clip_fraction': 0.4140625, 'grad_norm': 2.693295478820801}
2023-01-03 22:05:57.039 DEBUG: Taking gradient step
2023-01-03 22:05:57.050 DEBUG: Loss 5: {'policy_loss': -0.008280254420323565, 'entropy_loss': -0.07770263031125069, 'vf_loss': 0.004441615976614719, 'total_loss': -0.08154126875495953, 'approx_kl': -0.005869876593351364, 'clip_fraction': 0.37109375, 'grad_norm': 2.2559008598327637}
2023-01-03 22:05:58.102 DEBUG: Taking gradient step
2023-01-03 22:05:58.111 DEBUG: Loss 6: {'policy_loss': -0.027262804310762605, 'entropy_loss': -0.07695944793522358, 'vf_loss': 0.003606946688873826, 'total_loss': -0.10061530555711236, 'approx_kl': -0.014211226254701614, 'clip_fraction': 0.3463541716337204, 'grad_norm': 7.32802152633667}
2023-01-03 22:05:59.141 DEBUG: Taking gradient step
2023-01-03 22:05:59.150 DEBUG: Loss 7: {'policy_loss': -0.0430654516912722, 'entropy_loss': -0.07816565781831741, 'vf_loss': 0.003184078960434688, 'total_loss': -0.11804703054915491, 'approx_kl': -0.010323153575882316, 'clip_fraction': 0.421875, 'grad_norm': 2.160548210144043}
2023-01-03 22:06:00.179 DEBUG: Taking gradient step
2023-01-03 22:06:00.189 DEBUG: Loss 8: {'policy_loss': -0.031101753058817676, 'entropy_loss': -0.07702996395528316, 'vf_loss': 0.0036001209989591355, 'total_loss': -0.1045315960151417, 'approx_kl': -0.01283431751653552, 'clip_fraction': 0.41015625, 'grad_norm': 2.3327465057373047}
2023-01-03 22:06:01.244 DEBUG: Taking gradient step
2023-01-03 22:06:01.254 DEBUG: Loss 9: {'policy_loss': -0.0519625164849415, 'entropy_loss': -0.07769516669213772, 'vf_loss': 0.003184240593468878, 'total_loss': -0.12647344258361035, 'approx_kl': -0.02201918000355363, 'clip_fraction': 0.2955729179084301, 'grad_norm': 3.1984522342681885}
2023-01-03 22:06:02.294 DEBUG: Taking gradient step
2023-01-03 22:06:02.303 DEBUG: Loss 10: {'policy_loss': -0.014926347373516141, 'entropy_loss': -0.07768100872635841, 'vf_loss': 0.004039300096754977, 'total_loss': -0.08856805600311958, 'approx_kl': -0.021976551041007042, 'clip_fraction': 0.2981770858168602, 'grad_norm': 6.088556289672852}
2023-01-03 22:06:03.336 DEBUG: Taking gradient step
2023-01-03 22:06:03.345 DEBUG: Loss 11: {'policy_loss': -0.05299697947735518, 'entropy_loss': -0.07786437310278416, 'vf_loss': 0.0031774713141223816, 'total_loss': -0.12768388126601696, 'approx_kl': -0.04299831297248602, 'clip_fraction': 0.3359375, 'grad_norm': 8.982751846313477}
2023-01-03 22:06:04.383 DEBUG: Taking gradient step
2023-01-03 22:06:04.392 DEBUG: Loss 12: {'policy_loss': -0.05307663629540057, 'entropy_loss': -0.07807776518166065, 'vf_loss': 0.003174370394361542, 'total_loss': -0.12798003108269967, 'approx_kl': -0.02661158936098218, 'clip_fraction': 0.42578125, 'grad_norm': 8.347816467285156}
2023-01-03 22:06:05.432 DEBUG: Taking gradient step
2023-01-03 22:06:05.442 DEBUG: Loss 13: {'policy_loss': -0.04548519474732374, 'entropy_loss': -0.07904474250972271, 'vf_loss': 0.003170337568249896, 'total_loss': -0.12135959968879656, 'approx_kl': -0.023761021438986063, 'clip_fraction': 0.5052083432674408, 'grad_norm': 3.165113687515259}
2023-01-03 22:06:06.490 DEBUG: Taking gradient step
2023-01-03 22:06:06.499 DEBUG: Loss 14: {'policy_loss': -0.04929146893839906, 'entropy_loss': -0.07785298675298691, 'vf_loss': 0.0031667169442207072, 'total_loss': -0.12397773874716525, 'approx_kl': -0.05443963082507253, 'clip_fraction': 0.4921875, 'grad_norm': 2.6294097900390625}
2023-01-03 22:06:06.499 INFO: Optimization: policy loss=-0.049, vf loss=0.003, entropy loss=-0.078, total loss=-0.124, num steps=15
2023-01-03 22:06:06.499 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 22:06:08.146 INFO: Evaluation rollout: return=0.614 (0.0), episode length=6.0
2023-01-03 22:06:08.147 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 22:06:08.150 INFO: Iteration: 97/137, steps: 20952
2023-01-03 22:07:01.820 DEBUG: There is a single atom floating around
2023-01-03 22:07:02.703 INFO: Training rollout: return=0.195 (2.2), episode length=6.0
2023-01-03 22:07:02.704 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 22:07:02.707 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-20952_train.pkl
2023-01-03 22:07:03.769 DEBUG: Taking gradient step
2023-01-03 22:07:03.778 DEBUG: Loss 0: {'policy_loss': -0.004173492905363574, 'entropy_loss': -0.07665122300386429, 'vf_loss': 0.003563045444856796, 'total_loss': -0.07726167046437107, 'approx_kl': 1.5793678898035068e-07, 'clip_fraction': 0.0, 'grad_norm': 11.735587120056152}
2023-01-03 22:07:04.817 DEBUG: Taking gradient step
2023-01-03 22:07:04.826 DEBUG: Loss 1: {'policy_loss': 0.00327180697895426, 'entropy_loss': -0.07605459541082382, 'vf_loss': 0.004465402424239132, 'total_loss': -0.06831738600763043, 'approx_kl': 0.012056437088176608, 'clip_fraction': 0.033854166977107525, 'grad_norm': 8.533480644226074}
2023-01-03 22:07:05.869 DEBUG: Taking gradient step
2023-01-03 22:07:05.879 DEBUG: Loss 2: {'policy_loss': -0.0373286231198094, 'entropy_loss': -0.07686902396380901, 'vf_loss': 0.003236494302863949, 'total_loss': -0.11096115278075447, 'approx_kl': 0.023855049163103104, 'clip_fraction': 0.2330729216337204, 'grad_norm': 6.955994129180908}
2023-01-03 22:07:06.911 DEBUG: Taking gradient step
2023-01-03 22:07:06.920 DEBUG: Loss 3: {'policy_loss': -0.03941704819274263, 'entropy_loss': -0.07670263573527336, 'vf_loss': 0.0032341861474850415, 'total_loss': -0.11288549778053096, 'approx_kl': 0.04210650734603405, 'clip_fraction': 0.3333333358168602, 'grad_norm': 3.9282398223876953}
2023-01-03 22:07:07.953 DEBUG: Taking gradient step
2023-01-03 22:07:07.961 DEBUG: Loss 4: {'policy_loss': -0.021814368923835474, 'entropy_loss': -0.07602712698280811, 'vf_loss': 0.003715144864318921, 'total_loss': -0.09412635104232465, 'approx_kl': 0.041599238058552146, 'clip_fraction': 0.3880208358168602, 'grad_norm': 3.180976390838623}
2023-01-03 22:07:09.011 DEBUG: Taking gradient step
2023-01-03 22:07:09.020 DEBUG: Loss 5: {'policy_loss': -0.045039510997465504, 'entropy_loss': -0.07619346305727959, 'vf_loss': 0.0032360537765940183, 'total_loss': -0.11799692027815108, 'approx_kl': 0.03128887666389346, 'clip_fraction': 0.3619791679084301, 'grad_norm': 2.597379446029663}
2023-01-03 22:07:10.060 DEBUG: Taking gradient step
2023-01-03 22:07:10.069 DEBUG: Loss 6: {'policy_loss': -0.04563150169717785, 'entropy_loss': -0.07561017200350761, 'vf_loss': 0.0032357515328601772, 'total_loss': -0.1180059221678253, 'approx_kl': 0.02406138530932367, 'clip_fraction': 0.43359375, 'grad_norm': 2.6089680194854736}
2023-01-03 22:07:11.111 DEBUG: Taking gradient step
2023-01-03 22:07:11.119 DEBUG: Loss 7: {'policy_loss': -0.021420192171200024, 'entropy_loss': -0.07659520953893661, 'vf_loss': 0.0038760103606298732, 'total_loss': -0.09413939134950676, 'approx_kl': 0.011352449073456228, 'clip_fraction': 0.3828125, 'grad_norm': 6.542825698852539}
2023-01-03 22:07:12.129 DEBUG: Taking gradient step
2023-01-03 22:07:12.137 DEBUG: Loss 8: {'policy_loss': -0.045115100299897626, 'entropy_loss': -0.0770615953952074, 'vf_loss': 0.0032291964134221695, 'total_loss': -0.11894749928168286, 'approx_kl': 0.0025243214331567287, 'clip_fraction': 0.3815104216337204, 'grad_norm': 2.75659441947937}
2023-01-03 22:07:13.185 DEBUG: Taking gradient step
2023-01-03 22:07:13.194 DEBUG: Loss 9: {'policy_loss': -0.043887842938328384, 'entropy_loss': -0.07659279182553291, 'vf_loss': 0.0032292056632314656, 'total_loss': -0.11725142910062983, 'approx_kl': 0.012621286325156689, 'clip_fraction': 0.28125, 'grad_norm': 2.899108409881592}
2023-01-03 22:07:14.233 DEBUG: Taking gradient step
2023-01-03 22:07:14.242 DEBUG: Loss 10: {'policy_loss': -0.04179978248575666, 'entropy_loss': -0.07592934183776379, 'vf_loss': 0.0032238656643545365, 'total_loss': -0.11450525865916591, 'approx_kl': -0.002448468701913953, 'clip_fraction': 0.21223958395421505, 'grad_norm': 7.230922222137451}
2023-01-03 22:07:15.292 DEBUG: Taking gradient step
2023-01-03 22:07:15.301 DEBUG: Loss 11: {'policy_loss': -0.04637355620258031, 'entropy_loss': -0.07679369859397411, 'vf_loss': 0.0032253410700615443, 'total_loss': -0.11994191372649288, 'approx_kl': 0.001660048495978117, 'clip_fraction': 0.296875, 'grad_norm': 5.846725940704346}
2023-01-03 22:07:16.291 DEBUG: Taking gradient step
2023-01-03 22:07:16.299 DEBUG: Loss 12: {'policy_loss': -0.012689689352784882, 'entropy_loss': -0.0772006344050169, 'vf_loss': 0.004441679241704398, 'total_loss': -0.08544864451609738, 'approx_kl': 0.0011103330471087247, 'clip_fraction': 0.3138020858168602, 'grad_norm': 5.94242000579834}
2023-01-03 22:07:17.309 DEBUG: Taking gradient step
2023-01-03 22:07:17.318 DEBUG: Loss 13: {'policy_loss': -0.02912427706593644, 'entropy_loss': -0.07677619718015194, 'vf_loss': 0.003546596353690236, 'total_loss': -0.10235387789239814, 'approx_kl': -0.014278167858719826, 'clip_fraction': 0.27734375, 'grad_norm': 1.8209083080291748}
2023-01-03 22:07:18.349 DEBUG: Taking gradient step
2023-01-03 22:07:18.357 DEBUG: Loss 14: {'policy_loss': -0.048490562841616416, 'entropy_loss': -0.07733046635985374, 'vf_loss': 0.0032199860766549257, 'total_loss': -0.12260104312481523, 'approx_kl': -0.0186313446611166, 'clip_fraction': 0.3111979216337204, 'grad_norm': 4.9253997802734375}
2023-01-03 22:07:18.357 INFO: Optimization: policy loss=-0.048, vf loss=0.003, entropy loss=-0.077, total loss=-0.123, num steps=15
2023-01-03 22:07:18.358 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 22:07:19.962 INFO: Evaluation rollout: return=0.569 (0.0), episode length=6.0
2023-01-03 22:07:19.963 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 22:07:19.966 INFO: Iteration: 98/137, steps: 21168
2023-01-03 22:07:36.426 DEBUG: There is a single atom floating around
2023-01-03 22:08:14.290 INFO: Training rollout: return=0.213 (2.2), episode length=6.0
2023-01-03 22:08:14.292 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 22:08:14.294 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-21168_train.pkl
2023-01-03 22:08:15.323 DEBUG: Taking gradient step
2023-01-03 22:08:15.332 DEBUG: Loss 0: {'policy_loss': -0.025809903683284847, 'entropy_loss': -0.07943578436970711, 'vf_loss': 0.00317474526012431, 'total_loss': -0.10207094279286764, 'approx_kl': -2.4757659033980417e-08, 'clip_fraction': 0.0, 'grad_norm': 13.510085105895996}
2023-01-03 22:08:16.394 DEBUG: Taking gradient step
2023-01-03 22:08:16.403 DEBUG: Loss 1: {'policy_loss': 0.006478205552184774, 'entropy_loss': -0.07938098721206188, 'vf_loss': 0.004376183212200091, 'total_loss': -0.068526598447677, 'approx_kl': -0.00028596073389053345, 'clip_fraction': 0.08072916697710752, 'grad_norm': 12.472732543945312}
2023-01-03 22:08:17.396 DEBUG: Taking gradient step
2023-01-03 22:08:17.405 DEBUG: Loss 2: {'policy_loss': -0.03949706578979946, 'entropy_loss': -0.07966422662138939, 'vf_loss': 0.0031736260358813544, 'total_loss': -0.1159876663753075, 'approx_kl': 0.016674478771165013, 'clip_fraction': 0.28125, 'grad_norm': 4.248169898986816}
2023-01-03 22:08:18.451 DEBUG: Taking gradient step
2023-01-03 22:08:18.460 DEBUG: Loss 3: {'policy_loss': -0.03976013357275415, 'entropy_loss': -0.0795688945800066, 'vf_loss': 0.003175644030401746, 'total_loss': -0.11615338412235901, 'approx_kl': 0.03155136597342789, 'clip_fraction': 0.40625, 'grad_norm': 3.524411916732788}
2023-01-03 22:08:19.499 DEBUG: Taking gradient step
2023-01-03 22:08:19.509 DEBUG: Loss 4: {'policy_loss': 0.030185979701268018, 'entropy_loss': -0.07957211136817932, 'vf_loss': 0.004514750666743424, 'total_loss': -0.04487138100016789, 'approx_kl': 0.03551279753446579, 'clip_fraction': 0.4283854216337204, 'grad_norm': 3.655625104904175}
2023-01-03 22:08:20.513 DEBUG: Early stopping at step 5 for reaching max KL.
2023-01-03 22:08:20.513 INFO: Optimization: policy loss=0.030, vf loss=0.005, entropy loss=-0.080, total loss=-0.045, num steps=5
2023-01-03 22:08:20.513 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 22:08:22.145 INFO: Evaluation rollout: return=0.364 (0.0), episode length=6.0
2023-01-03 22:08:22.146 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 22:08:22.149 INFO: Iteration: 99/137, steps: 21384
2023-01-03 22:09:17.087 INFO: Training rollout: return=0.507 (0.2), episode length=6.0
2023-01-03 22:09:17.089 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 22:09:17.091 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-21384_train.pkl
2023-01-03 22:09:18.152 DEBUG: Taking gradient step
2023-01-03 22:09:18.162 DEBUG: Loss 0: {'policy_loss': -0.018485683696461197, 'entropy_loss': -0.07886448316276073, 'vf_loss': 0.00012407944178640453, 'total_loss': -0.09722608741743552, 'approx_kl': 1.102065017022369e-08, 'clip_fraction': 0.0, 'grad_norm': 10.645487785339355}
2023-01-03 22:09:19.222 DEBUG: Taking gradient step
2023-01-03 22:09:19.230 DEBUG: Loss 1: {'policy_loss': -0.021130630304811174, 'entropy_loss': -0.07956275343894958, 'vf_loss': 0.00012180124322961174, 'total_loss': -0.10057158250053115, 'approx_kl': -0.006057025399059057, 'clip_fraction': 0.1236979179084301, 'grad_norm': 8.73237419128418}
2023-01-03 22:09:20.280 DEBUG: Taking gradient step
2023-01-03 22:09:20.289 DEBUG: Loss 2: {'policy_loss': -0.019945679199972026, 'entropy_loss': -0.07876934297382832, 'vf_loss': 0.00012362169848857305, 'total_loss': -0.09859140047531177, 'approx_kl': 0.0160711957141757, 'clip_fraction': 0.2734375, 'grad_norm': 11.081645965576172}
2023-01-03 22:09:21.348 DEBUG: Taking gradient step
2023-01-03 22:09:21.357 DEBUG: Loss 3: {'policy_loss': -0.020523124306083308, 'entropy_loss': -0.07926493510603905, 'vf_loss': 0.00012050187689452478, 'total_loss': -0.09966755753522782, 'approx_kl': 0.029176972806453705, 'clip_fraction': 0.3033854216337204, 'grad_norm': 9.560308456420898}
2023-01-03 22:09:22.392 DEBUG: Taking gradient step
2023-01-03 22:09:22.402 DEBUG: Loss 4: {'policy_loss': -0.06254689994502294, 'entropy_loss': -0.0792095772922039, 'vf_loss': 0.00011988100072094168, 'total_loss': -0.1416365962365059, 'approx_kl': 0.018956099404022098, 'clip_fraction': 0.3385416716337204, 'grad_norm': 8.031373023986816}
2023-01-03 22:09:23.446 DEBUG: Taking gradient step
2023-01-03 22:09:23.455 DEBUG: Loss 5: {'policy_loss': -0.04807615074735087, 'entropy_loss': -0.07905053161084652, 'vf_loss': 0.00011547471957724412, 'total_loss': -0.12701120763862012, 'approx_kl': 0.03428737726062536, 'clip_fraction': 0.31640625, 'grad_norm': 8.095398902893066}
2023-01-03 22:09:24.494 DEBUG: Taking gradient step
2023-01-03 22:09:24.502 DEBUG: Loss 6: {'policy_loss': 0.03461557353567329, 'entropy_loss': -0.07827201299369335, 'vf_loss': 0.00010634617763680419, 'total_loss': -0.043550093280383256, 'approx_kl': 0.019096335163339972, 'clip_fraction': 0.3020833358168602, 'grad_norm': 7.675319194793701}
2023-01-03 22:09:25.546 DEBUG: Taking gradient step
2023-01-03 22:09:25.555 DEBUG: Loss 7: {'policy_loss': -0.038855123183824516, 'entropy_loss': -0.07905210554599762, 'vf_loss': 0.00010065529341615912, 'total_loss': -0.11780657343640596, 'approx_kl': 0.01861100271344185, 'clip_fraction': 0.2864583358168602, 'grad_norm': 10.35983943939209}
2023-01-03 22:09:26.602 DEBUG: Taking gradient step
2023-01-03 22:09:26.611 DEBUG: Loss 8: {'policy_loss': -0.01726446363641363, 'entropy_loss': -0.078458983451128, 'vf_loss': 9.58024034306017e-05, 'total_loss': -0.09562764468411104, 'approx_kl': 0.009353046654723585, 'clip_fraction': 0.265625, 'grad_norm': 6.33616828918457}
2023-01-03 22:09:27.645 DEBUG: Taking gradient step
2023-01-03 22:09:27.655 DEBUG: Loss 9: {'policy_loss': -0.07046829531543905, 'entropy_loss': -0.0789402388036251, 'vf_loss': 8.815857366878204e-05, 'total_loss': -0.14932037554539535, 'approx_kl': 0.011811355128884315, 'clip_fraction': 0.30078125, 'grad_norm': 8.717216491699219}
2023-01-03 22:09:28.708 DEBUG: Taking gradient step
2023-01-03 22:09:28.717 DEBUG: Loss 10: {'policy_loss': -0.024930464911910644, 'entropy_loss': -0.07872578501701355, 'vf_loss': 7.889759676192544e-05, 'total_loss': -0.10357735233216227, 'approx_kl': 0.005672849714756012, 'clip_fraction': 0.3020833358168602, 'grad_norm': 11.329909324645996}
2023-01-03 22:09:29.758 DEBUG: Taking gradient step
2023-01-03 22:09:29.767 DEBUG: Loss 11: {'policy_loss': -0.04389544939182028, 'entropy_loss': -0.07877063751220703, 'vf_loss': 7.30337628312843e-05, 'total_loss': -0.12259305314119603, 'approx_kl': 0.017764785327017307, 'clip_fraction': 0.3255208358168602, 'grad_norm': 9.072272300720215}
2023-01-03 22:09:30.814 DEBUG: Taking gradient step
2023-01-03 22:09:30.823 DEBUG: Loss 12: {'policy_loss': -0.022782376364593904, 'entropy_loss': -0.0786990188062191, 'vf_loss': 6.418238160611294e-05, 'total_loss': -0.1014172127892069, 'approx_kl': 0.01864027325063944, 'clip_fraction': 0.28125, 'grad_norm': 5.191349506378174}
2023-01-03 22:09:31.864 DEBUG: Taking gradient step
2023-01-03 22:09:31.873 DEBUG: Loss 13: {'policy_loss': -0.052971018629590604, 'entropy_loss': -0.07942398637533188, 'vf_loss': 5.855307770300406e-05, 'total_loss': -0.1323364519272195, 'approx_kl': 0.025334322592243552, 'clip_fraction': 0.359375, 'grad_norm': 10.0798921585083}
2023-01-03 22:09:32.920 DEBUG: Taking gradient step
2023-01-03 22:09:32.929 DEBUG: Loss 14: {'policy_loss': -0.0639133848523354, 'entropy_loss': -0.07786403223872185, 'vf_loss': 5.6155506438752405e-05, 'total_loss': -0.1417212615846185, 'approx_kl': 0.01773982704617083, 'clip_fraction': 0.3919270858168602, 'grad_norm': 7.270163059234619}
2023-01-03 22:09:32.929 INFO: Optimization: policy loss=-0.064, vf loss=0.000, entropy loss=-0.078, total loss=-0.142, num steps=15
2023-01-03 22:09:32.930 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 22:09:34.556 INFO: Evaluation rollout: return=-0.018 (0.0), episode length=6.0
2023-01-03 22:09:34.558 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 22:09:34.561 INFO: Iteration: 100/137, steps: 21600
2023-01-03 22:10:29.973 INFO: Training rollout: return=0.579 (0.1), episode length=6.0
2023-01-03 22:10:29.975 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 22:10:29.977 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-21600_train.pkl
2023-01-03 22:10:30.997 DEBUG: Taking gradient step
2023-01-03 22:10:31.006 DEBUG: Loss 0: {'policy_loss': 0.004647181703828225, 'entropy_loss': -0.07854369468986988, 'vf_loss': 3.592970574655576e-05, 'total_loss': -0.0738605832802951, 'approx_kl': 2.4835262735223296e-09, 'clip_fraction': 0.0, 'grad_norm': 11.526388168334961}
2023-01-03 22:10:32.035 DEBUG: Taking gradient step
2023-01-03 22:10:32.044 DEBUG: Loss 1: {'policy_loss': 0.020266450714558064, 'entropy_loss': -0.07879408448934555, 'vf_loss': 3.0418801918955132e-05, 'total_loss': -0.05849721497286853, 'approx_kl': 0.016224451595917344, 'clip_fraction': 0.06770833395421505, 'grad_norm': 8.207778930664062}
2023-01-03 22:10:33.102 DEBUG: Taking gradient step
2023-01-03 22:10:33.111 DEBUG: Loss 2: {'policy_loss': -0.05534931522296845, 'entropy_loss': -0.0780150517821312, 'vf_loss': 2.905689828418723e-05, 'total_loss': -0.13333531010681546, 'approx_kl': 0.027074374491348863, 'clip_fraction': 0.18359375, 'grad_norm': 8.3275728225708}
2023-01-03 22:10:34.166 DEBUG: Taking gradient step
2023-01-03 22:10:34.176 DEBUG: Loss 3: {'policy_loss': 0.025331177329983717, 'entropy_loss': -0.07795803807675838, 'vf_loss': 2.29422557326344e-05, 'total_loss': -0.05260391849104202, 'approx_kl': 0.03715911484323442, 'clip_fraction': 0.2604166716337204, 'grad_norm': 11.190585136413574}
2023-01-03 22:10:35.210 DEBUG: Taking gradient step
2023-01-03 22:10:35.219 DEBUG: Loss 4: {'policy_loss': -0.04623303444380497, 'entropy_loss': -0.07684660330414772, 'vf_loss': 2.2113208747092078e-05, 'total_loss': -0.1230575245392056, 'approx_kl': 0.01700137252919376, 'clip_fraction': 0.2109375, 'grad_norm': 9.335136413574219}
2023-01-03 22:10:36.279 DEBUG: Taking gradient step
2023-01-03 22:10:36.288 DEBUG: Loss 5: {'policy_loss': -0.028299020856223905, 'entropy_loss': -0.0767491813749075, 'vf_loss': 1.8348957096351447e-05, 'total_loss': -0.10502985327403505, 'approx_kl': 0.031965891597792506, 'clip_fraction': 0.2591145858168602, 'grad_norm': 8.740511894226074}
2023-01-03 22:10:37.339 DEBUG: Taking gradient step
2023-01-03 22:10:37.348 DEBUG: Loss 6: {'policy_loss': -0.04499478625413556, 'entropy_loss': -0.07681005448102951, 'vf_loss': 1.6677105176177514e-05, 'total_loss': -0.1217881636299889, 'approx_kl': 0.036044195061549544, 'clip_fraction': 0.28515625, 'grad_norm': 10.53437328338623}
2023-01-03 22:10:38.399 DEBUG: Early stopping at step 7 for reaching max KL.
2023-01-03 22:10:38.399 INFO: Optimization: policy loss=-0.045, vf loss=0.000, entropy loss=-0.077, total loss=-0.122, num steps=7
2023-01-03 22:10:38.399 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 22:10:40.088 INFO: Evaluation rollout: return=0.539 (0.0), episode length=6.0
2023-01-03 22:10:40.089 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 22:10:40.092 DEBUG: Deleting old model: runs/CH3NO_baseline/models/CH3NO_baseline_run-1_steps-19656.model
2023-01-03 22:10:40.097 DEBUG: Saving model: runs/CH3NO_baseline/models/CH3NO_baseline_run-1_steps-21816.model
2023-01-03 22:10:40.127 INFO: Iteration: 101/137, steps: 21816
2023-01-03 22:11:33.068 DEBUG: Atoms are too close
2023-01-03 22:11:35.310 INFO: Training rollout: return=0.174 (2.2), episode length=6.0
2023-01-03 22:11:35.312 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 22:11:35.314 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-21816_train.pkl
2023-01-03 22:11:36.386 DEBUG: Taking gradient step
2023-01-03 22:11:36.395 DEBUG: Loss 0: {'policy_loss': -0.026605238870169176, 'entropy_loss': -0.07667528092861176, 'vf_loss': 0.0032576300025942127, 'total_loss': -0.10002288979618673, 'approx_kl': -8.7932377823563e-08, 'clip_fraction': 0.0, 'grad_norm': 14.628179550170898}
2023-01-03 22:11:37.435 DEBUG: Taking gradient step
2023-01-03 22:11:37.444 DEBUG: Loss 1: {'policy_loss': 0.034927078374344465, 'entropy_loss': -0.07639152929186821, 'vf_loss': 0.005362455675719347, 'total_loss': -0.03610199524180439, 'approx_kl': -2.172263339161873e-05, 'clip_fraction': 0.041666666977107525, 'grad_norm': 27.107845306396484}
2023-01-03 22:11:38.449 DEBUG: Taking gradient step
2023-01-03 22:11:38.459 DEBUG: Loss 2: {'policy_loss': 0.008974958048247425, 'entropy_loss': -0.07623779214918613, 'vf_loss': 0.0050391309956844405, 'total_loss': -0.06222370310525427, 'approx_kl': -0.0020079766400158405, 'clip_fraction': 0.1888020858168602, 'grad_norm': 5.84670877456665}
2023-01-03 22:11:39.492 DEBUG: Taking gradient step
2023-01-03 22:11:39.501 DEBUG: Loss 3: {'policy_loss': -0.039264455972733994, 'entropy_loss': -0.07638606242835522, 'vf_loss': 0.003264147774775385, 'total_loss': -0.11238637062631382, 'approx_kl': -0.003622377524152398, 'clip_fraction': 0.2799479179084301, 'grad_norm': 3.7859816551208496}
2023-01-03 22:11:40.550 DEBUG: Taking gradient step
2023-01-03 22:11:40.558 DEBUG: Loss 4: {'policy_loss': -0.040364045691397676, 'entropy_loss': -0.07625189609825611, 'vf_loss': 0.003260242481095845, 'total_loss': -0.11335569930855793, 'approx_kl': -0.0008651623502373695, 'clip_fraction': 0.3606770858168602, 'grad_norm': 3.554697275161743}
2023-01-03 22:11:41.598 DEBUG: Taking gradient step
2023-01-03 22:11:41.606 DEBUG: Loss 5: {'policy_loss': 0.004117496673980946, 'entropy_loss': -0.07550527900457382, 'vf_loss': 0.004379185150227376, 'total_loss': -0.0670085971803655, 'approx_kl': -0.009720199974253774, 'clip_fraction': 0.4661458432674408, 'grad_norm': 4.597837924957275}
2023-01-03 22:11:42.625 DEBUG: Taking gradient step
2023-01-03 22:11:42.634 DEBUG: Loss 6: {'policy_loss': -0.01698684386006663, 'entropy_loss': -0.0767382811754942, 'vf_loss': 0.0039041062274403236, 'total_loss': -0.08982101880812049, 'approx_kl': -0.012909225653856993, 'clip_fraction': 0.5130208432674408, 'grad_norm': 2.423704147338867}
2023-01-03 22:11:43.672 DEBUG: Taking gradient step
2023-01-03 22:11:43.682 DEBUG: Loss 7: {'policy_loss': -0.04691785771358538, 'entropy_loss': -0.07585236988961697, 'vf_loss': 0.003233710178517619, 'total_loss': -0.11953651742468473, 'approx_kl': -0.027092816308140755, 'clip_fraction': 0.4609375, 'grad_norm': 2.0912420749664307}
2023-01-03 22:11:44.725 DEBUG: Taking gradient step
2023-01-03 22:11:44.734 DEBUG: Loss 8: {'policy_loss': -0.026755740136053256, 'entropy_loss': -0.07654034532606602, 'vf_loss': 0.0036772494860019996, 'total_loss': -0.09961883597611727, 'approx_kl': -0.0248766359873116, 'clip_fraction': 0.5390625, 'grad_norm': 5.436023235321045}
2023-01-03 22:11:45.773 DEBUG: Taking gradient step
2023-01-03 22:11:45.782 DEBUG: Loss 9: {'policy_loss': -0.04449839605729244, 'entropy_loss': -0.07809563726186752, 'vf_loss': 0.0032120454559592493, 'total_loss': -0.1193819878632007, 'approx_kl': -0.007513481192290783, 'clip_fraction': 0.5169270932674408, 'grad_norm': 1.738266944885254}
2023-01-03 22:11:46.821 DEBUG: Taking gradient step
2023-01-03 22:11:46.831 DEBUG: Loss 10: {'policy_loss': -0.04407577709006347, 'entropy_loss': -0.0779727790504694, 'vf_loss': 0.00320525307169838, 'total_loss': -0.11884330306883448, 'approx_kl': -0.011397891910746694, 'clip_fraction': 0.4479166716337204, 'grad_norm': 5.593224048614502}
2023-01-03 22:11:47.808 DEBUG: Taking gradient step
2023-01-03 22:11:47.817 DEBUG: Loss 11: {'policy_loss': -0.046179797696311524, 'entropy_loss': -0.07792137190699577, 'vf_loss': 0.003197657562581079, 'total_loss': -0.12090351204072622, 'approx_kl': -0.026397569570690393, 'clip_fraction': 0.4661458358168602, 'grad_norm': 6.17393159866333}
2023-01-03 22:11:48.860 DEBUG: Taking gradient step
2023-01-03 22:11:48.869 DEBUG: Loss 12: {'policy_loss': -0.042095345671599865, 'entropy_loss': -0.07827853970229626, 'vf_loss': 0.003191269332968608, 'total_loss': -0.11718261604092751, 'approx_kl': -0.0033402349799871445, 'clip_fraction': 0.4479166716337204, 'grad_norm': 5.922508239746094}
2023-01-03 22:11:49.898 DEBUG: Taking gradient step
2023-01-03 22:11:49.906 DEBUG: Loss 13: {'policy_loss': -0.0015944809463842996, 'entropy_loss': -0.07807663269340992, 'vf_loss': 0.004903296546229234, 'total_loss': -0.07476781709356499, 'approx_kl': -0.027658048551529646, 'clip_fraction': 0.5052083358168602, 'grad_norm': 1.6145899295806885}
2023-01-03 22:11:50.944 DEBUG: Taking gradient step
2023-01-03 22:11:50.953 DEBUG: Loss 14: {'policy_loss': -0.0006974601438443501, 'entropy_loss': -0.07748404145240784, 'vf_loss': 0.004891572260573226, 'total_loss': -0.07328992933567896, 'approx_kl': -0.014435287564992905, 'clip_fraction': 0.5078125, 'grad_norm': 1.8828160762786865}
2023-01-03 22:11:50.954 INFO: Optimization: policy loss=-0.001, vf loss=0.005, entropy loss=-0.077, total loss=-0.073, num steps=15
2023-01-03 22:11:50.954 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 22:11:52.591 INFO: Evaluation rollout: return=0.536 (0.0), episode length=6.0
2023-01-03 22:11:52.592 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 22:11:52.595 INFO: Iteration: 102/137, steps: 22032
2023-01-03 22:12:47.437 INFO: Training rollout: return=0.514 (0.2), episode length=6.0
2023-01-03 22:12:47.438 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 22:12:47.441 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-22032_train.pkl
2023-01-03 22:12:48.509 DEBUG: Taking gradient step
2023-01-03 22:12:48.518 DEBUG: Loss 0: {'policy_loss': -0.0020514681452256283, 'entropy_loss': -0.07770600914955139, 'vf_loss': 6.884130656538878e-05, 'total_loss': -0.07968863598821163, 'approx_kl': -3.348880772691132e-08, 'clip_fraction': 0.0, 'grad_norm': 11.251067161560059}
2023-01-03 22:12:49.557 DEBUG: Taking gradient step
2023-01-03 22:12:49.565 DEBUG: Loss 1: {'policy_loss': 0.0032028033808118583, 'entropy_loss': -0.07803680002689362, 'vf_loss': 7.699393805085356e-05, 'total_loss': -0.07475700270803091, 'approx_kl': 0.00164837297052145, 'clip_fraction': 0.08984375, 'grad_norm': 7.78476619720459}
2023-01-03 22:12:50.608 DEBUG: Taking gradient step
2023-01-03 22:12:50.617 DEBUG: Loss 2: {'policy_loss': -0.021096022907102434, 'entropy_loss': -0.07791237346827984, 'vf_loss': 8.840694824176496e-05, 'total_loss': -0.0989199894271405, 'approx_kl': 0.0010644369758665562, 'clip_fraction': 0.2864583358168602, 'grad_norm': 7.7985029220581055}
2023-01-03 22:12:51.632 DEBUG: Taking gradient step
2023-01-03 22:12:51.642 DEBUG: Loss 3: {'policy_loss': -0.027949128155758667, 'entropy_loss': -0.07824214547872543, 'vf_loss': 9.640999178362988e-05, 'total_loss': -0.10609486364270046, 'approx_kl': 0.017102517769671977, 'clip_fraction': 0.3606770858168602, 'grad_norm': 8.148538589477539}
2023-01-03 22:12:52.682 DEBUG: Taking gradient step
2023-01-03 22:12:52.691 DEBUG: Loss 4: {'policy_loss': -0.018847752078391886, 'entropy_loss': -0.07795644924044609, 'vf_loss': 0.00010110088287968985, 'total_loss': -0.09670310043595828, 'approx_kl': 0.028710429091006517, 'clip_fraction': 0.3333333358168602, 'grad_norm': 7.316318988800049}
2023-01-03 22:12:53.738 DEBUG: Taking gradient step
2023-01-03 22:12:53.748 DEBUG: Loss 5: {'policy_loss': -0.03184329146966576, 'entropy_loss': -0.07877016998827457, 'vf_loss': 0.00010505594057132902, 'total_loss': -0.110508405517369, 'approx_kl': 0.012602131348103285, 'clip_fraction': 0.3658854216337204, 'grad_norm': 7.566135883331299}
2023-01-03 22:12:54.798 DEBUG: Taking gradient step
2023-01-03 22:12:54.806 DEBUG: Loss 6: {'policy_loss': -0.08431112135568263, 'entropy_loss': -0.08002230897545815, 'vf_loss': 0.00011280943637164686, 'total_loss': -0.16422062089476913, 'approx_kl': 0.02088432596065104, 'clip_fraction': 0.4231770932674408, 'grad_norm': 6.998592853546143}
2023-01-03 22:12:55.836 DEBUG: Taking gradient step
2023-01-03 22:12:55.845 DEBUG: Loss 7: {'policy_loss': -0.006940623012847032, 'entropy_loss': -0.07900818437337875, 'vf_loss': 0.00010793081078669514, 'total_loss': -0.08584087657543908, 'approx_kl': 0.023865602910518646, 'clip_fraction': 0.4166666716337204, 'grad_norm': 9.389896392822266}
2023-01-03 22:12:56.896 DEBUG: Taking gradient step
2023-01-03 22:12:56.905 DEBUG: Loss 8: {'policy_loss': -0.056684380431831966, 'entropy_loss': -0.07871434651315212, 'vf_loss': 0.00011023038998477416, 'total_loss': -0.1352884965549993, 'approx_kl': 0.010608116630464792, 'clip_fraction': 0.4427083358168602, 'grad_norm': 7.518629550933838}
2023-01-03 22:12:57.952 DEBUG: Taking gradient step
2023-01-03 22:12:57.961 DEBUG: Loss 9: {'policy_loss': -0.007943887906084718, 'entropy_loss': -0.07800124026834965, 'vf_loss': 0.00010470791211204561, 'total_loss': -0.08584042026232233, 'approx_kl': 0.0037029781378805637, 'clip_fraction': 0.4296875, 'grad_norm': 6.71417236328125}
2023-01-03 22:12:59.011 DEBUG: Taking gradient step
2023-01-03 22:12:59.019 DEBUG: Loss 10: {'policy_loss': 0.06200842683669899, 'entropy_loss': -0.0786897111684084, 'vf_loss': 0.0001014613609912709, 'total_loss': -0.01657982297071811, 'approx_kl': 0.014911143109202385, 'clip_fraction': 0.3984375, 'grad_norm': 4.997898101806641}
2023-01-03 22:13:00.059 DEBUG: Taking gradient step
2023-01-03 22:13:00.067 DEBUG: Loss 11: {'policy_loss': -0.049680413965739884, 'entropy_loss': -0.07976635731756687, 'vf_loss': 0.00010549979987524688, 'total_loss': -0.1293412714834315, 'approx_kl': 0.015530843753367662, 'clip_fraction': 0.3619791716337204, 'grad_norm': 8.163226127624512}
2023-01-03 22:13:01.115 DEBUG: Taking gradient step
2023-01-03 22:13:01.125 DEBUG: Loss 12: {'policy_loss': -0.0825970148723219, 'entropy_loss': -0.07790096662938595, 'vf_loss': 0.0001024065398421488, 'total_loss': -0.16039557496186568, 'approx_kl': -0.007216446101665497, 'clip_fraction': 0.359375, 'grad_norm': 9.319802284240723}
2023-01-03 22:13:02.167 DEBUG: Taking gradient step
2023-01-03 22:13:02.176 DEBUG: Loss 13: {'policy_loss': -0.02678182354252242, 'entropy_loss': -0.0790120605379343, 'vf_loss': 9.306378389270177e-05, 'total_loss': -0.10570082029656402, 'approx_kl': 0.012453232891857624, 'clip_fraction': 0.3268229179084301, 'grad_norm': 8.456219673156738}
2023-01-03 22:13:03.216 DEBUG: Taking gradient step
2023-01-03 22:13:03.224 DEBUG: Loss 14: {'policy_loss': -0.013304018476370527, 'entropy_loss': -0.07802001759409904, 'vf_loss': 8.847085265335085e-05, 'total_loss': -0.09123556521781621, 'approx_kl': 0.005554038565605879, 'clip_fraction': 0.359375, 'grad_norm': 7.602223873138428}
2023-01-03 22:13:03.224 INFO: Optimization: policy loss=-0.013, vf loss=0.000, entropy loss=-0.078, total loss=-0.091, num steps=15
2023-01-03 22:13:03.225 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 22:13:04.885 INFO: Evaluation rollout: return=0.481 (0.0), episode length=6.0
2023-01-03 22:13:04.886 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 22:13:04.889 INFO: Iteration: 103/137, steps: 22248
2023-01-03 22:13:13.244 DEBUG: Atoms are too close
2023-01-03 22:13:19.808 DEBUG: There is a single atom floating around
2023-01-03 22:13:56.903 DEBUG: Atoms are too close
2023-01-03 22:13:59.664 INFO: Training rollout: return=-0.715 (4.2), episode length=5.9
2023-01-03 22:13:59.665 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 22:13:59.669 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-22248_train.pkl
2023-01-03 22:14:00.721 DEBUG: Taking gradient step
2023-01-03 22:14:00.730 DEBUG: Loss 0: {'policy_loss': 0.03769307028265787, 'entropy_loss': -0.0773944016546011, 'vf_loss': 0.012473368675079536, 'total_loss': -0.027227962696863693, 'approx_kl': 4.920487661763673e-08, 'clip_fraction': 0.0, 'grad_norm': 24.977670669555664}
2023-01-03 22:14:01.760 DEBUG: Taking gradient step
2023-01-03 22:14:01.768 DEBUG: Loss 1: {'policy_loss': -0.010958349903911677, 'entropy_loss': -0.07738988846540451, 'vf_loss': 0.010616508451568276, 'total_loss': -0.07773172991774792, 'approx_kl': 0.009522904525510967, 'clip_fraction': 0.04296875, 'grad_norm': 18.902406692504883}
2023-01-03 22:14:02.798 DEBUG: Taking gradient step
2023-01-03 22:14:02.807 DEBUG: Loss 2: {'policy_loss': -0.026934519714200147, 'entropy_loss': -0.07748414389789104, 'vf_loss': 0.010819652469914825, 'total_loss': -0.09359901114217636, 'approx_kl': 0.027859857073053718, 'clip_fraction': 0.24609375, 'grad_norm': 5.300724983215332}
2023-01-03 22:14:03.848 DEBUG: Taking gradient step
2023-01-03 22:14:03.862 DEBUG: Loss 3: {'policy_loss': -0.042806199736824334, 'entropy_loss': -0.07761315815150738, 'vf_loss': 0.00955607617822145, 'total_loss': -0.11086328171011026, 'approx_kl': 0.04250385519117117, 'clip_fraction': 0.36328125, 'grad_norm': 6.224637508392334}
2023-01-03 22:14:04.897 DEBUG: Early stopping at step 4 for reaching max KL.
2023-01-03 22:14:04.898 INFO: Optimization: policy loss=-0.043, vf loss=0.010, entropy loss=-0.078, total loss=-0.111, num steps=4
2023-01-03 22:14:04.898 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 22:14:06.551 INFO: Evaluation rollout: return=0.055 (0.0), episode length=6.0
2023-01-03 22:14:06.552 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 22:14:06.555 INFO: Iteration: 104/137, steps: 22464
2023-01-03 22:14:42.158 DEBUG: There is a single atom floating around
2023-01-03 22:15:03.007 INFO: Training rollout: return=0.175 (2.2), episode length=6.0
2023-01-03 22:15:03.009 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 22:15:03.011 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-22464_train.pkl
2023-01-03 22:15:04.174 DEBUG: Taking gradient step
2023-01-03 22:15:04.188 DEBUG: Loss 0: {'policy_loss': -0.023687022220699308, 'entropy_loss': -0.07638396508991718, 'vf_loss': 0.003186718650861444, 'total_loss': -0.09688426865975505, 'approx_kl': -1.3969838619232178e-09, 'clip_fraction': 0.0, 'grad_norm': 9.645347595214844}
2023-01-03 22:15:05.340 DEBUG: Taking gradient step
2023-01-03 22:15:05.349 DEBUG: Loss 1: {'policy_loss': -0.03134130436922654, 'entropy_loss': -0.07721194438636303, 'vf_loss': 0.0031850788991309286, 'total_loss': -0.10536816985645864, 'approx_kl': 0.007074979454046115, 'clip_fraction': 0.01953125, 'grad_norm': 5.445380210876465}
2023-01-03 22:15:06.433 DEBUG: Taking gradient step
2023-01-03 22:15:06.442 DEBUG: Loss 2: {'policy_loss': -0.04049249543197854, 'entropy_loss': -0.07635647244751453, 'vf_loss': 0.003186717914379272, 'total_loss': -0.1136622499651138, 'approx_kl': 0.018550493754446507, 'clip_fraction': 0.07682291697710752, 'grad_norm': 5.229460716247559}
2023-01-03 22:15:07.486 DEBUG: Taking gradient step
2023-01-03 22:15:07.495 DEBUG: Loss 3: {'policy_loss': -0.040480406131600394, 'entropy_loss': -0.07695823162794113, 'vf_loss': 0.0031850965976081137, 'total_loss': -0.11425354116193341, 'approx_kl': 0.04422348318621516, 'clip_fraction': 0.1979166679084301, 'grad_norm': 3.548844337463379}
2023-01-03 22:15:08.514 DEBUG: Early stopping at step 4 for reaching max KL.
2023-01-03 22:15:08.514 INFO: Optimization: policy loss=-0.040, vf loss=0.003, entropy loss=-0.077, total loss=-0.114, num steps=4
2023-01-03 22:15:08.514 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 22:15:10.146 INFO: Evaluation rollout: return=-0.121 (0.0), episode length=6.0
2023-01-03 22:15:10.147 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 22:15:10.150 INFO: Iteration: 105/137, steps: 22680
2023-01-03 22:16:05.150 INFO: Training rollout: return=0.558 (0.1), episode length=6.0
2023-01-03 22:16:05.151 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 22:16:05.154 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-22680_train.pkl
2023-01-03 22:16:06.189 DEBUG: Taking gradient step
2023-01-03 22:16:06.200 DEBUG: Loss 0: {'policy_loss': 0.028691725144613028, 'entropy_loss': -0.0770573616027832, 'vf_loss': 9.34481407628844e-05, 'total_loss': -0.04827218831740729, 'approx_kl': -1.1455267667770386e-07, 'clip_fraction': 0.0, 'grad_norm': 8.832647323608398}
2023-01-03 22:16:07.219 DEBUG: Taking gradient step
2023-01-03 22:16:07.228 DEBUG: Loss 1: {'policy_loss': -0.06566988987175909, 'entropy_loss': -0.07887224666774273, 'vf_loss': 9.864878070746785e-05, 'total_loss': -0.14444348775879434, 'approx_kl': -0.01325900829397142, 'clip_fraction': 0.04817708395421505, 'grad_norm': 10.023744583129883}
2023-01-03 22:16:08.242 DEBUG: Taking gradient step
2023-01-03 22:16:08.251 DEBUG: Loss 2: {'policy_loss': 0.0073893168115805145, 'entropy_loss': -0.07700706087052822, 'vf_loss': 9.353194988068807e-05, 'total_loss': -0.06952421210906702, 'approx_kl': -0.01800335361622274, 'clip_fraction': 0.2122395858168602, 'grad_norm': 11.389565467834473}
2023-01-03 22:16:09.242 DEBUG: Taking gradient step
2023-01-03 22:16:09.250 DEBUG: Loss 3: {'policy_loss': 0.030003970157330848, 'entropy_loss': -0.07737373933196068, 'vf_loss': 9.094812851850211e-05, 'total_loss': -0.047278821046111336, 'approx_kl': -0.010083777830004692, 'clip_fraction': 0.2890625, 'grad_norm': 9.435819625854492}
2023-01-03 22:16:10.262 DEBUG: Taking gradient step
2023-01-03 22:16:10.272 DEBUG: Loss 4: {'policy_loss': -0.015050716319237366, 'entropy_loss': -0.07727931998670101, 'vf_loss': 9.294484437683646e-05, 'total_loss': -0.09223709146156155, 'approx_kl': 0.007185729453340173, 'clip_fraction': 0.2643229179084301, 'grad_norm': 12.160958290100098}
2023-01-03 22:16:11.291 DEBUG: Taking gradient step
2023-01-03 22:16:11.301 DEBUG: Loss 5: {'policy_loss': 0.004224554435362897, 'entropy_loss': -0.077054463326931, 'vf_loss': 8.805780005342691e-05, 'total_loss': -0.07274185109151468, 'approx_kl': 0.009202110348269343, 'clip_fraction': 0.2799479216337204, 'grad_norm': 8.189023971557617}
2023-01-03 22:16:12.319 DEBUG: Taking gradient step
2023-01-03 22:16:12.329 DEBUG: Loss 6: {'policy_loss': -0.034623475582556205, 'entropy_loss': -0.07713248394429684, 'vf_loss': 8.615823147844759e-05, 'total_loss': -0.11166980129537458, 'approx_kl': 0.0022835462586954236, 'clip_fraction': 0.3138020858168602, 'grad_norm': 7.730002403259277}
2023-01-03 22:16:13.307 DEBUG: Taking gradient step
2023-01-03 22:16:13.315 DEBUG: Loss 7: {'policy_loss': -0.0554144735860517, 'entropy_loss': -0.07756497152149677, 'vf_loss': 8.529137077220476e-05, 'total_loss': -0.13289415373677627, 'approx_kl': 0.005863458849489689, 'clip_fraction': 0.28125, 'grad_norm': 9.427213668823242}
2023-01-03 22:16:14.295 DEBUG: Taking gradient step
2023-01-03 22:16:14.306 DEBUG: Loss 8: {'policy_loss': -0.025531960107088685, 'entropy_loss': -0.07789689674973488, 'vf_loss': 8.0891800180542e-05, 'total_loss': -0.10334796505664302, 'approx_kl': 0.03406388545408845, 'clip_fraction': 0.296875, 'grad_norm': 9.705820083618164}
2023-01-03 22:16:15.323 DEBUG: Taking gradient step
2023-01-03 22:16:15.333 DEBUG: Loss 9: {'policy_loss': -0.07729800304893994, 'entropy_loss': -0.07845473848283291, 'vf_loss': 7.993993107864949e-05, 'total_loss': -0.1556728016006942, 'approx_kl': 0.011998750735074282, 'clip_fraction': 0.3268229216337204, 'grad_norm': 12.576363563537598}
2023-01-03 22:16:16.360 DEBUG: Taking gradient step
2023-01-03 22:16:16.368 DEBUG: Loss 10: {'policy_loss': -0.11424446126318798, 'entropy_loss': -0.07833081111311913, 'vf_loss': 7.642662988165729e-05, 'total_loss': -0.19249884574642545, 'approx_kl': 0.004518257454037666, 'clip_fraction': 0.359375, 'grad_norm': 6.577672004699707}
2023-01-03 22:16:17.386 DEBUG: Taking gradient step
2023-01-03 22:16:17.395 DEBUG: Loss 11: {'policy_loss': -0.05351041830736035, 'entropy_loss': -0.07836336828768253, 'vf_loss': 7.022813840826516e-05, 'total_loss': -0.13180355845663463, 'approx_kl': 0.008136501768603921, 'clip_fraction': 0.3697916716337204, 'grad_norm': 9.55506706237793}
2023-01-03 22:16:18.389 DEBUG: Taking gradient step
2023-01-03 22:16:18.399 DEBUG: Loss 12: {'policy_loss': -0.01603568460208716, 'entropy_loss': -0.07737117446959019, 'vf_loss': 6.419489439974557e-05, 'total_loss': -0.0933426641772776, 'approx_kl': 0.0017248268704861403, 'clip_fraction': 0.3984375, 'grad_norm': 11.763481140136719}
2023-01-03 22:16:19.425 DEBUG: Taking gradient step
2023-01-03 22:16:19.434 DEBUG: Loss 13: {'policy_loss': -0.11127297273007195, 'entropy_loss': -0.07856923900544643, 'vf_loss': 6.380775357895628e-05, 'total_loss': -0.18977840398193943, 'approx_kl': 0.0027001153212040663, 'clip_fraction': 0.3932291716337204, 'grad_norm': 10.313324928283691}
2023-01-03 22:16:20.456 DEBUG: Taking gradient step
2023-01-03 22:16:20.466 DEBUG: Loss 14: {'policy_loss': -0.04955443227827303, 'entropy_loss': -0.07849889621138573, 'vf_loss': 5.7515747289661704e-05, 'total_loss': -0.1279958127423691, 'approx_kl': 0.014129696879535913, 'clip_fraction': 0.3828125, 'grad_norm': 8.299266815185547}
2023-01-03 22:16:20.466 INFO: Optimization: policy loss=-0.050, vf loss=0.000, entropy loss=-0.078, total loss=-0.128, num steps=15
2023-01-03 22:16:20.466 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 22:16:22.077 INFO: Evaluation rollout: return=0.493 (0.0), episode length=6.0
2023-01-03 22:16:22.078 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 22:16:22.081 INFO: Iteration: 106/137, steps: 22896
2023-01-03 22:16:57.708 DEBUG: There is a single atom floating around
2023-01-03 22:17:10.140 DEBUG: Atoms are too close
2023-01-03 22:17:15.815 INFO: Training rollout: return=-0.270 (3.3), episode length=6.0
2023-01-03 22:17:15.816 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 22:17:15.819 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-22896_train.pkl
2023-01-03 22:17:16.861 DEBUG: Taking gradient step
2023-01-03 22:17:16.870 DEBUG: Loss 0: {'policy_loss': 0.03538403074111718, 'entropy_loss': -0.07624953612685204, 'vf_loss': 0.008804698970194837, 'total_loss': -0.032060806415540016, 'approx_kl': -3.651560831485767e-08, 'clip_fraction': 0.0, 'grad_norm': 13.425628662109375}
2023-01-03 22:17:17.868 DEBUG: Taking gradient step
2023-01-03 22:17:17.878 DEBUG: Loss 1: {'policy_loss': -0.016848211863940164, 'entropy_loss': -0.07623511366546154, 'vf_loss': 0.006832045528297416, 'total_loss': -0.08625128000110428, 'approx_kl': 0.004114497336558998, 'clip_fraction': 0.061197916977107525, 'grad_norm': 9.451127052307129}
2023-01-03 22:17:18.896 DEBUG: Taking gradient step
2023-01-03 22:17:18.906 DEBUG: Loss 2: {'policy_loss': 0.023294859915127947, 'entropy_loss': -0.07635661959648132, 'vf_loss': 0.008192190811372487, 'total_loss': -0.044869568869980905, 'approx_kl': 0.03874489478766918, 'clip_fraction': 0.1744791679084301, 'grad_norm': 8.15056037902832}
2023-01-03 22:17:19.926 DEBUG: Early stopping at step 3 for reaching max KL.
2023-01-03 22:17:19.927 INFO: Optimization: policy loss=0.023, vf loss=0.008, entropy loss=-0.076, total loss=-0.045, num steps=3
2023-01-03 22:17:19.927 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 22:17:21.558 INFO: Evaluation rollout: return=0.492 (0.0), episode length=6.0
2023-01-03 22:17:21.559 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 22:17:21.562 INFO: Iteration: 107/137, steps: 23112
2023-01-03 22:18:16.451 INFO: Training rollout: return=0.550 (0.2), episode length=6.0
2023-01-03 22:18:16.452 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 22:18:16.455 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-23112_train.pkl
2023-01-03 22:18:17.421 DEBUG: Taking gradient step
2023-01-03 22:18:17.429 DEBUG: Loss 0: {'policy_loss': -0.036814040646482166, 'entropy_loss': -0.07783902809023857, 'vf_loss': 5.096150452419477e-05, 'total_loss': -0.11460210723219653, 'approx_kl': -7.233272469875374e-08, 'clip_fraction': 0.0, 'grad_norm': 17.877155303955078}
2023-01-03 22:18:18.444 DEBUG: Taking gradient step
2023-01-03 22:18:18.453 DEBUG: Loss 1: {'policy_loss': 0.023129372381546755, 'entropy_loss': -0.07678987458348274, 'vf_loss': 5.024676158173721e-05, 'total_loss': -0.05361025544035425, 'approx_kl': -0.0024952125968411565, 'clip_fraction': 0.022135416977107525, 'grad_norm': 16.20371437072754}
2023-01-03 22:18:19.464 DEBUG: Taking gradient step
2023-01-03 22:18:19.473 DEBUG: Loss 2: {'policy_loss': 0.007381593187051762, 'entropy_loss': -0.07670378871262074, 'vf_loss': 4.776974240085687e-05, 'total_loss': -0.06927442578316811, 'approx_kl': 0.006333454046398401, 'clip_fraction': 0.21875, 'grad_norm': 8.90429973602295}
2023-01-03 22:18:20.479 DEBUG: Taking gradient step
2023-01-03 22:18:20.487 DEBUG: Loss 3: {'policy_loss': -0.05055059239317304, 'entropy_loss': -0.07697308249771595, 'vf_loss': 4.8913981579545974e-05, 'total_loss': -0.12747476090930945, 'approx_kl': 0.012930042576044798, 'clip_fraction': 0.3463541716337204, 'grad_norm': 10.5037202835083}
2023-01-03 22:18:21.531 DEBUG: Taking gradient step
2023-01-03 22:18:21.541 DEBUG: Loss 4: {'policy_loss': -0.011214720878210988, 'entropy_loss': -0.07631537318229675, 'vf_loss': 4.578809412314515e-05, 'total_loss': -0.08748430596638461, 'approx_kl': 0.006451962050050497, 'clip_fraction': 0.4114583432674408, 'grad_norm': 8.522929191589355}
2023-01-03 22:18:22.578 DEBUG: Taking gradient step
2023-01-03 22:18:22.588 DEBUG: Loss 5: {'policy_loss': -0.05629799989371976, 'entropy_loss': -0.07711036875844002, 'vf_loss': 4.368497909356933e-05, 'total_loss': -0.1333646836730662, 'approx_kl': -0.003612478729337454, 'clip_fraction': 0.3645833358168602, 'grad_norm': 10.759027481079102}
2023-01-03 22:18:23.628 DEBUG: Taking gradient step
2023-01-03 22:18:23.637 DEBUG: Loss 6: {'policy_loss': 0.04415741797114403, 'entropy_loss': -0.07538486644625664, 'vf_loss': 3.940456051364481e-05, 'total_loss': -0.03118804391459898, 'approx_kl': 0.010767731815576553, 'clip_fraction': 0.2890625, 'grad_norm': 13.404952049255371}
2023-01-03 22:18:24.666 DEBUG: Taking gradient step
2023-01-03 22:18:24.676 DEBUG: Loss 7: {'policy_loss': -0.060686149248440166, 'entropy_loss': -0.0764588788151741, 'vf_loss': 3.958118344974839e-05, 'total_loss': -0.13710544688016452, 'approx_kl': 0.029745286796242, 'clip_fraction': 0.2864583358168602, 'grad_norm': 8.63199234008789}
2023-01-03 22:18:25.675 DEBUG: Taking gradient step
2023-01-03 22:18:25.684 DEBUG: Loss 8: {'policy_loss': -0.0402909770248401, 'entropy_loss': -0.07587448693811893, 'vf_loss': 3.8954472908459503e-05, 'total_loss': -0.11612650949005057, 'approx_kl': 0.04293825104832649, 'clip_fraction': 0.36328125, 'grad_norm': 9.021465301513672}
2023-01-03 22:18:26.714 DEBUG: Early stopping at step 9 for reaching max KL.
2023-01-03 22:18:26.714 INFO: Optimization: policy loss=-0.040, vf loss=0.000, entropy loss=-0.076, total loss=-0.116, num steps=9
2023-01-03 22:18:26.715 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 22:18:28.388 INFO: Evaluation rollout: return=0.458 (0.0), episode length=6.0
2023-01-03 22:18:28.389 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 22:18:28.391 INFO: Iteration: 108/137, steps: 23328
2023-01-03 22:18:59.343 DEBUG: Atoms are too close
2023-01-03 22:19:17.628 DEBUG: There is a single atom floating around
2023-01-03 22:19:23.427 INFO: Training rollout: return=-0.333 (3.6), episode length=5.9
2023-01-03 22:19:23.428 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 22:19:23.431 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-23328_train.pkl
2023-01-03 22:19:24.429 DEBUG: Taking gradient step
2023-01-03 22:19:24.438 DEBUG: Loss 0: {'policy_loss': -0.03214460082821982, 'entropy_loss': -0.07762228511273861, 'vf_loss': 0.006075488564454281, 'total_loss': -0.10369139737650414, 'approx_kl': -9.906943887472153e-08, 'clip_fraction': 0.0, 'grad_norm': 16.772104263305664}
2023-01-03 22:19:25.456 DEBUG: Taking gradient step
2023-01-03 22:19:25.466 DEBUG: Loss 1: {'policy_loss': -0.01362540334061902, 'entropy_loss': -0.07704955898225307, 'vf_loss': 0.0070033912595749495, 'total_loss': -0.08367157106329715, 'approx_kl': 0.009435970336198807, 'clip_fraction': 0.029947916977107525, 'grad_norm': 8.880459785461426}
2023-01-03 22:19:26.483 DEBUG: Taking gradient step
2023-01-03 22:19:26.494 DEBUG: Loss 2: {'policy_loss': 0.013962057020243723, 'entropy_loss': -0.07781936600804329, 'vf_loss': 0.008730377540525303, 'total_loss': -0.05512693144727426, 'approx_kl': 0.02715099835768342, 'clip_fraction': 0.2369791716337204, 'grad_norm': 5.969491481781006}
2023-01-03 22:19:27.500 DEBUG: Taking gradient step
2023-01-03 22:19:27.509 DEBUG: Loss 3: {'policy_loss': -0.020796494319469686, 'entropy_loss': -0.07703620567917824, 'vf_loss': 0.006981008752300922, 'total_loss': -0.09085169124634701, 'approx_kl': 0.04124761978164315, 'clip_fraction': 0.3580729216337204, 'grad_norm': 4.270951271057129}
2023-01-03 22:19:28.480 DEBUG: Early stopping at step 4 for reaching max KL.
2023-01-03 22:19:28.481 INFO: Optimization: policy loss=-0.021, vf loss=0.007, entropy loss=-0.077, total loss=-0.091, num steps=4
2023-01-03 22:19:28.481 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 22:19:30.115 INFO: Evaluation rollout: return=0.462 (0.0), episode length=6.0
2023-01-03 22:19:30.117 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 22:19:30.120 INFO: Iteration: 109/137, steps: 23544
2023-01-03 22:20:25.210 INFO: Training rollout: return=0.579 (0.1), episode length=6.0
2023-01-03 22:20:25.211 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 22:20:25.215 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-23544_train.pkl
2023-01-03 22:20:26.178 DEBUG: Taking gradient step
2023-01-03 22:20:26.186 DEBUG: Loss 0: {'policy_loss': -0.00241486446471249, 'entropy_loss': -0.07792098261415958, 'vf_loss': 3.980630476876374e-05, 'total_loss': -0.08029604077410332, 'approx_kl': -9.483968099743834e-08, 'clip_fraction': 0.0, 'grad_norm': 13.803597450256348}
2023-01-03 22:20:27.209 DEBUG: Taking gradient step
2023-01-03 22:20:27.219 DEBUG: Loss 1: {'policy_loss': -0.05128590339742193, 'entropy_loss': -0.07836284674704075, 'vf_loss': 4.307725230440116e-05, 'total_loss': -0.12960567289215827, 'approx_kl': 0.00010774144902825356, 'clip_fraction': 0.053385416977107525, 'grad_norm': 16.293119430541992}
2023-01-03 22:20:28.237 DEBUG: Taking gradient step
2023-01-03 22:20:28.246 DEBUG: Loss 2: {'policy_loss': 0.021112268245308985, 'entropy_loss': -0.07797341980040073, 'vf_loss': 4.253907278387598e-05, 'total_loss': -0.05681861248230788, 'approx_kl': 0.018755227676592767, 'clip_fraction': 0.2395833358168602, 'grad_norm': 6.261819362640381}
2023-01-03 22:20:29.265 DEBUG: Taking gradient step
2023-01-03 22:20:29.275 DEBUG: Loss 3: {'policy_loss': -0.03298392906717028, 'entropy_loss': -0.07657532207667828, 'vf_loss': 4.463445990237128e-05, 'total_loss': -0.10951461668394617, 'approx_kl': 0.022563782054930925, 'clip_fraction': 0.27734375, 'grad_norm': 7.091235637664795}
2023-01-03 22:20:30.280 DEBUG: Taking gradient step
2023-01-03 22:20:30.289 DEBUG: Loss 4: {'policy_loss': -0.0319488745432197, 'entropy_loss': -0.0775848962366581, 'vf_loss': 4.521895114076743e-05, 'total_loss': -0.10948855182873704, 'approx_kl': 0.02171793207526207, 'clip_fraction': 0.37890625, 'grad_norm': 10.081156730651855}
2023-01-03 22:20:31.312 DEBUG: Taking gradient step
2023-01-03 22:20:31.322 DEBUG: Loss 5: {'policy_loss': -0.05926686317114417, 'entropy_loss': -0.07775812409818172, 'vf_loss': 4.4882995368455e-05, 'total_loss': -0.13698010427395743, 'approx_kl': 0.01843834831379354, 'clip_fraction': 0.33203125, 'grad_norm': 9.470968246459961}
2023-01-03 22:20:32.340 DEBUG: Taking gradient step
2023-01-03 22:20:32.356 DEBUG: Loss 6: {'policy_loss': -0.0628896505404692, 'entropy_loss': -0.07782841101288795, 'vf_loss': 4.406586541647736e-05, 'total_loss': -0.14067399568794067, 'approx_kl': 0.02453077700920403, 'clip_fraction': 0.2734375, 'grad_norm': 8.144622802734375}
2023-01-03 22:20:33.295 DEBUG: Taking gradient step
2023-01-03 22:20:33.304 DEBUG: Loss 7: {'policy_loss': -0.004925331028905577, 'entropy_loss': -0.07684739120304585, 'vf_loss': 4.172654899649417e-05, 'total_loss': -0.08173099568295493, 'approx_kl': 0.0025808773934841156, 'clip_fraction': 0.26171875, 'grad_norm': 9.778674125671387}
2023-01-03 22:20:34.326 DEBUG: Taking gradient step
2023-01-03 22:20:34.335 DEBUG: Loss 8: {'policy_loss': 0.005432028909059583, 'entropy_loss': -0.07665705122053623, 'vf_loss': 4.101799799622503e-05, 'total_loss': -0.07118400431348043, 'approx_kl': 0.0065032560378313065, 'clip_fraction': 0.3111979216337204, 'grad_norm': 6.2449469566345215}
2023-01-03 22:20:35.325 DEBUG: Taking gradient step
2023-01-03 22:20:35.333 DEBUG: Loss 9: {'policy_loss': -0.08859263259488824, 'entropy_loss': -0.07729034312069416, 'vf_loss': 4.0797556224427556e-05, 'total_loss': -0.16584217815935798, 'approx_kl': -0.002042848616838455, 'clip_fraction': 0.4049479216337204, 'grad_norm': 7.434686660766602}
2023-01-03 22:20:36.349 DEBUG: Taking gradient step
2023-01-03 22:20:36.357 DEBUG: Loss 10: {'policy_loss': -0.07976767786194942, 'entropy_loss': -0.07707175798714161, 'vf_loss': 3.970884326289423e-05, 'total_loss': -0.15679972700582814, 'approx_kl': 0.023125942330807447, 'clip_fraction': 0.3919270858168602, 'grad_norm': 8.2535400390625}
2023-01-03 22:20:37.375 DEBUG: Taking gradient step
2023-01-03 22:20:37.384 DEBUG: Loss 11: {'policy_loss': -0.05636400833050794, 'entropy_loss': -0.07661520130932331, 'vf_loss': 3.704824943667919e-05, 'total_loss': -0.13294216139039455, 'approx_kl': 0.02439100295305252, 'clip_fraction': 0.36328125, 'grad_norm': 10.639240264892578}
2023-01-03 22:20:38.398 DEBUG: Early stopping at step 12 for reaching max KL.
2023-01-03 22:20:38.399 INFO: Optimization: policy loss=-0.056, vf loss=0.000, entropy loss=-0.077, total loss=-0.133, num steps=12
2023-01-03 22:20:38.399 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 22:20:40.047 INFO: Evaluation rollout: return=0.548 (0.0), episode length=6.0
2023-01-03 22:20:40.049 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 22:20:40.052 INFO: Iteration: 110/137, steps: 23760
2023-01-03 22:20:55.371 DEBUG: There is a single atom floating around
2023-01-03 22:20:56.461 DEBUG: There is a single atom floating around
2023-01-03 22:20:57.555 DEBUG: There is a single atom floating around
2023-01-03 22:21:35.059 INFO: Training rollout: return=-0.301 (4.0), episode length=6.0
2023-01-03 22:21:35.060 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 22:21:35.063 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-23760_train.pkl
2023-01-03 22:21:36.223 DEBUG: Taking gradient step
2023-01-03 22:21:36.234 DEBUG: Loss 0: {'policy_loss': -0.006584936888971708, 'entropy_loss': -0.07668300159275532, 'vf_loss': 0.015344867975067192, 'total_loss': -0.06792307050665984, 'approx_kl': 2.695402798735813e-07, 'clip_fraction': 0.0, 'grad_norm': 10.794398307800293}
2023-01-03 22:21:37.290 DEBUG: Taking gradient step
2023-01-03 22:21:37.298 DEBUG: Loss 1: {'policy_loss': -0.017928791464204386, 'entropy_loss': -0.07650602981448174, 'vf_loss': 0.014225096350792842, 'total_loss': -0.08020972492789327, 'approx_kl': 0.003614809946157038, 'clip_fraction': 0.015625, 'grad_norm': 13.301505088806152}
2023-01-03 22:21:38.307 DEBUG: Taking gradient step
2023-01-03 22:21:38.316 DEBUG: Loss 2: {'policy_loss': -0.051829978210549695, 'entropy_loss': -0.07551511377096176, 'vf_loss': 0.013533009114085462, 'total_loss': -0.11381208286742599, 'approx_kl': 0.014549692161381245, 'clip_fraction': 0.1666666679084301, 'grad_norm': 7.345308303833008}
2023-01-03 22:21:39.355 DEBUG: Taking gradient step
2023-01-03 22:21:39.363 DEBUG: Loss 3: {'policy_loss': -0.04638699350100765, 'entropy_loss': -0.076637864112854, 'vf_loss': 0.013321306995044887, 'total_loss': -0.10970355061881677, 'approx_kl': 0.03388510341756046, 'clip_fraction': 0.30859375, 'grad_norm': 5.694894313812256}
2023-01-03 22:21:40.377 DEBUG: Early stopping at step 4 for reaching max KL.
2023-01-03 22:21:40.377 INFO: Optimization: policy loss=-0.046, vf loss=0.013, entropy loss=-0.077, total loss=-0.110, num steps=4
2023-01-03 22:21:40.378 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 22:21:42.170 INFO: Evaluation rollout: return=0.551 (0.0), episode length=6.0
2023-01-03 22:21:42.171 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 22:21:42.174 DEBUG: Deleting old model: runs/CH3NO_baseline/models/CH3NO_baseline_run-1_steps-21816.model
2023-01-03 22:21:42.180 DEBUG: Saving model: runs/CH3NO_baseline/models/CH3NO_baseline_run-1_steps-23976.model
2023-01-03 22:21:42.210 INFO: Iteration: 111/137, steps: 23976
2023-01-03 22:21:56.283 DEBUG: There is a single atom floating around
2023-01-03 22:21:58.129 DEBUG: There is a single atom floating around
2023-01-03 22:22:15.550 DEBUG: There is a single atom floating around
2023-01-03 22:22:18.318 DEBUG: There is a single atom floating around
2023-01-03 22:22:38.032 INFO: Training rollout: return=-1.025 (4.6), episode length=5.9
2023-01-03 22:22:38.033 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 22:22:38.036 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-23976_train.pkl
2023-01-03 22:22:39.075 DEBUG: Taking gradient step
2023-01-03 22:22:39.086 DEBUG: Loss 0: {'policy_loss': -0.024573460688128223, 'entropy_loss': -0.0746791809797287, 'vf_loss': 0.013532027175861237, 'total_loss': -0.08572061449199568, 'approx_kl': -9.600383599206452e-08, 'clip_fraction': 0.0, 'grad_norm': 22.360713958740234}
2023-01-03 22:22:40.104 DEBUG: Taking gradient step
2023-01-03 22:22:40.114 DEBUG: Loss 1: {'policy_loss': -0.04656065463270952, 'entropy_loss': -0.07575731351971626, 'vf_loss': 0.012735962513263309, 'total_loss': -0.10958200563916246, 'approx_kl': 0.020294979913160205, 'clip_fraction': 0.12109375, 'grad_norm': 11.894911766052246}
2023-01-03 22:22:41.126 DEBUG: Early stopping at step 2 for reaching max KL.
2023-01-03 22:22:41.127 INFO: Optimization: policy loss=-0.047, vf loss=0.013, entropy loss=-0.076, total loss=-0.110, num steps=2
2023-01-03 22:22:41.127 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 22:22:42.841 INFO: Evaluation rollout: return=0.552 (0.0), episode length=6.0
2023-01-03 22:22:42.843 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 22:22:42.845 INFO: Iteration: 112/137, steps: 24192
2023-01-03 22:23:18.534 DEBUG: Atoms are too close
2023-01-03 22:23:41.699 DEBUG: Atoms are too close
2023-01-03 22:23:44.740 INFO: Training rollout: return=-0.175 (3.1), episode length=6.0
2023-01-03 22:23:44.742 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 22:23:44.745 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-24192_train.pkl
2023-01-03 22:23:45.760 DEBUG: Taking gradient step
2023-01-03 22:23:45.770 DEBUG: Loss 0: {'policy_loss': -0.012056173907862918, 'entropy_loss': -0.07516041398048401, 'vf_loss': 0.007106060429883655, 'total_loss': -0.08011052745846327, 'approx_kl': -1.3733128412241058e-07, 'clip_fraction': 0.0, 'grad_norm': 17.69562339782715}
2023-01-03 22:23:46.796 DEBUG: Taking gradient step
2023-01-03 22:23:46.805 DEBUG: Loss 1: {'policy_loss': -0.028407021250912812, 'entropy_loss': -0.0747554786503315, 'vf_loss': 0.006901851589691606, 'total_loss': -0.0962606483115527, 'approx_kl': 0.013610316440463066, 'clip_fraction': 0.07942708395421505, 'grad_norm': 6.173609733581543}
2023-01-03 22:23:47.822 DEBUG: Taking gradient step
2023-01-03 22:23:47.830 DEBUG: Loss 2: {'policy_loss': 0.007808282830510015, 'entropy_loss': -0.07503152638673782, 'vf_loss': 0.009055459311996352, 'total_loss': -0.058167784244231455, 'approx_kl': 0.038694499991834164, 'clip_fraction': 0.2317708358168602, 'grad_norm': 6.895992755889893}
2023-01-03 22:23:48.846 DEBUG: Taking gradient step
2023-01-03 22:23:48.855 DEBUG: Loss 3: {'policy_loss': -0.05100338029306588, 'entropy_loss': -0.07424587197601795, 'vf_loss': 0.006419923820363247, 'total_loss': -0.11882932844872057, 'approx_kl': 0.042238300666213036, 'clip_fraction': 0.2721354179084301, 'grad_norm': 6.022207736968994}
2023-01-03 22:23:49.866 DEBUG: Taking gradient step
2023-01-03 22:23:49.874 DEBUG: Loss 4: {'policy_loss': -0.008403699113214518, 'entropy_loss': -0.07470615208148956, 'vf_loss': 0.008292262908775674, 'total_loss': -0.07481758828592841, 'approx_kl': 0.019864768953993917, 'clip_fraction': 0.2747395858168602, 'grad_norm': 5.882501125335693}
2023-01-03 22:23:50.865 DEBUG: Taking gradient step
2023-01-03 22:23:50.873 DEBUG: Loss 5: {'policy_loss': -0.0128703639575159, 'entropy_loss': -0.07446299493312836, 'vf_loss': 0.008533958091634767, 'total_loss': -0.07879940079900949, 'approx_kl': 0.027148696593940258, 'clip_fraction': 0.3229166716337204, 'grad_norm': 5.894089698791504}
2023-01-03 22:23:51.872 DEBUG: Taking gradient step
2023-01-03 22:23:51.882 DEBUG: Loss 6: {'policy_loss': -0.06283436171004758, 'entropy_loss': -0.07435569353401661, 'vf_loss': 0.0063737340357233555, 'total_loss': -0.1308163212083408, 'approx_kl': 0.036514138570055366, 'clip_fraction': 0.3177083358168602, 'grad_norm': 3.479553699493408}
2023-01-03 22:23:52.912 DEBUG: Taking gradient step
2023-01-03 22:23:52.921 DEBUG: Loss 7: {'policy_loss': -0.04834069547793132, 'entropy_loss': -0.0745941624045372, 'vf_loss': 0.006995682951914054, 'total_loss': -0.11593917493055447, 'approx_kl': 0.026083949021995068, 'clip_fraction': 0.3463541716337204, 'grad_norm': 3.2775588035583496}
2023-01-03 22:23:53.946 DEBUG: Taking gradient step
2023-01-03 22:23:53.954 DEBUG: Loss 8: {'policy_loss': -0.05359354301599494, 'entropy_loss': -0.07469878531992435, 'vf_loss': 0.0068068634340436845, 'total_loss': -0.12148546490187562, 'approx_kl': 0.031144414097070694, 'clip_fraction': 0.4283854216337204, 'grad_norm': 3.9676923751831055}
2023-01-03 22:23:54.944 DEBUG: Taking gradient step
2023-01-03 22:23:54.953 DEBUG: Loss 9: {'policy_loss': -0.05355347095161859, 'entropy_loss': -0.07491074874997139, 'vf_loss': 0.006656015140280913, 'total_loss': -0.12180820456130909, 'approx_kl': 0.003344725351780653, 'clip_fraction': 0.45703125, 'grad_norm': 2.967752456665039}
2023-01-03 22:23:55.973 DEBUG: Taking gradient step
2023-01-03 22:23:55.981 DEBUG: Loss 10: {'policy_loss': -0.0709134943200432, 'entropy_loss': -0.07451137900352478, 'vf_loss': 0.0063100595045474895, 'total_loss': -0.13911481381902047, 'approx_kl': -0.011035194154828787, 'clip_fraction': 0.44921875, 'grad_norm': 3.9350764751434326}
2023-01-03 22:23:57.007 DEBUG: Taking gradient step
2023-01-03 22:23:57.017 DEBUG: Loss 11: {'policy_loss': -0.07032015592467507, 'entropy_loss': -0.07505849003791809, 'vf_loss': 0.006300962980658054, 'total_loss': -0.1390776829819351, 'approx_kl': -0.015166791155934334, 'clip_fraction': 0.4557291716337204, 'grad_norm': 7.624103546142578}
2023-01-03 22:23:58.035 DEBUG: Taking gradient step
2023-01-03 22:23:58.044 DEBUG: Loss 12: {'policy_loss': 0.017990620991920933, 'entropy_loss': -0.07515128329396248, 'vf_loss': 0.009847449109182503, 'total_loss': -0.047313213192859055, 'approx_kl': -0.01668751984834671, 'clip_fraction': 0.4557291716337204, 'grad_norm': 2.7858645915985107}
2023-01-03 22:23:59.054 DEBUG: Taking gradient step
2023-01-03 22:23:59.064 DEBUG: Loss 13: {'policy_loss': -0.06960219057732325, 'entropy_loss': -0.07581421732902527, 'vf_loss': 0.0062728339195358175, 'total_loss': -0.1391435739868127, 'approx_kl': -0.011937785893678665, 'clip_fraction': 0.4518229216337204, 'grad_norm': 2.040052652359009}
2023-01-03 22:24:00.053 DEBUG: Taking gradient step
2023-01-03 22:24:00.062 DEBUG: Loss 14: {'policy_loss': -0.00900749826628626, 'entropy_loss': -0.07580094039440155, 'vf_loss': 0.008970522564672304, 'total_loss': -0.0758379160960155, 'approx_kl': -0.013224480208009481, 'clip_fraction': 0.48828125, 'grad_norm': 2.8255720138549805}
2023-01-03 22:24:00.062 INFO: Optimization: policy loss=-0.009, vf loss=0.009, entropy loss=-0.076, total loss=-0.076, num steps=15
2023-01-03 22:24:00.063 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 22:24:01.676 INFO: Evaluation rollout: return=0.628 (0.0), episode length=6.0
2023-01-03 22:24:01.677 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 22:24:01.680 INFO: Iteration: 113/137, steps: 24408
2023-01-03 22:24:35.551 DEBUG: There is a single atom floating around
2023-01-03 22:24:54.387 DEBUG: There is a single atom floating around
2023-01-03 22:24:56.961 INFO: Training rollout: return=-0.156 (3.0), episode length=6.0
2023-01-03 22:24:56.963 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 22:24:56.965 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-24408_train.pkl
2023-01-03 22:24:58.045 DEBUG: Taking gradient step
2023-01-03 22:24:58.054 DEBUG: Loss 0: {'policy_loss': -0.03770156012867994, 'entropy_loss': -0.07534297928214073, 'vf_loss': 0.006258431684157701, 'total_loss': -0.10678610772666297, 'approx_kl': -3.1975407210893536e-08, 'clip_fraction': 0.0, 'grad_norm': 12.819314002990723}
2023-01-03 22:24:59.147 DEBUG: Taking gradient step
2023-01-03 22:24:59.160 DEBUG: Loss 1: {'policy_loss': -0.015428877177803602, 'entropy_loss': -0.07560708373785019, 'vf_loss': 0.007098556572970252, 'total_loss': -0.08393740434268354, 'approx_kl': 0.006966399610973895, 'clip_fraction': 0.0078125, 'grad_norm': 15.107556343078613}
2023-01-03 22:25:00.308 DEBUG: Taking gradient step
2023-01-03 22:25:00.321 DEBUG: Loss 2: {'policy_loss': -0.016783697918684302, 'entropy_loss': -0.07501469552516937, 'vf_loss': 0.0072833117210428355, 'total_loss': -0.08451508172281083, 'approx_kl': 0.018952467711642385, 'clip_fraction': 0.1341145858168602, 'grad_norm': 6.473316192626953}
2023-01-03 22:25:01.461 DEBUG: Taking gradient step
2023-01-03 22:25:01.474 DEBUG: Loss 3: {'policy_loss': -0.032954031520653904, 'entropy_loss': -0.07533797435462475, 'vf_loss': 0.006852108754379185, 'total_loss': -0.10143989712089946, 'approx_kl': 0.04366820026189089, 'clip_fraction': 0.2877604216337204, 'grad_norm': 4.016541004180908}
2023-01-03 22:25:02.627 DEBUG: Taking gradient step
2023-01-03 22:25:02.640 DEBUG: Loss 4: {'policy_loss': -0.01798089550710728, 'entropy_loss': -0.07641682587563992, 'vf_loss': 0.007704592853811544, 'total_loss': -0.08669312852893565, 'approx_kl': 0.040094401221722364, 'clip_fraction': 0.3828125, 'grad_norm': 5.664521217346191}
2023-01-03 22:25:03.757 DEBUG: Early stopping at step 5 for reaching max KL.
2023-01-03 22:25:03.758 INFO: Optimization: policy loss=-0.018, vf loss=0.008, entropy loss=-0.076, total loss=-0.087, num steps=5
2023-01-03 22:25:03.758 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 22:25:05.473 INFO: Evaluation rollout: return=0.556 (0.0), episode length=6.0
2023-01-03 22:25:05.474 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 22:25:05.477 INFO: Iteration: 114/137, steps: 24624
2023-01-03 22:25:56.428 DEBUG: There is a single atom floating around
2023-01-03 22:25:58.384 DEBUG: There is a single atom floating around
2023-01-03 22:26:01.628 INFO: Training rollout: return=-0.299 (3.6), episode length=5.9
2023-01-03 22:26:01.630 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 22:26:01.632 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-24624_train.pkl
2023-01-03 22:26:02.669 DEBUG: Taking gradient step
2023-01-03 22:26:02.677 DEBUG: Loss 0: {'policy_loss': 0.05885556901548368, 'entropy_loss': -0.07747524976730347, 'vf_loss': 0.008924872803080061, 'total_loss': -0.009694807948739712, 'approx_kl': -4.3228890689306354e-08, 'clip_fraction': 0.0, 'grad_norm': 24.50967788696289}
2023-01-03 22:26:03.676 DEBUG: Taking gradient step
2023-01-03 22:26:03.685 DEBUG: Loss 1: {'policy_loss': -0.008531631278211795, 'entropy_loss': -0.07761782594025135, 'vf_loss': 0.007191113596616538, 'total_loss': -0.0789583436218466, 'approx_kl': 0.02144099009456113, 'clip_fraction': 0.06510416697710752, 'grad_norm': 11.16517162322998}
2023-01-03 22:26:04.700 DEBUG: Early stopping at step 2 for reaching max KL.
2023-01-03 22:26:04.701 INFO: Optimization: policy loss=-0.009, vf loss=0.007, entropy loss=-0.078, total loss=-0.079, num steps=2
2023-01-03 22:26:04.701 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 22:26:06.368 INFO: Evaluation rollout: return=0.535 (0.0), episode length=6.0
2023-01-03 22:26:06.370 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 22:26:06.373 INFO: Iteration: 115/137, steps: 24840
2023-01-03 22:26:43.367 DEBUG: Atoms are too close
2023-01-03 22:27:06.712 DEBUG: There is a single atom floating around
2023-01-03 22:27:07.577 INFO: Training rollout: return=-0.236 (3.3), episode length=6.0
2023-01-03 22:27:07.578 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 22:27:07.581 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-24840_train.pkl
2023-01-03 22:27:08.614 DEBUG: Taking gradient step
2023-01-03 22:27:08.624 DEBUG: Loss 0: {'policy_loss': 0.045146490690292966, 'entropy_loss': -0.07743089087307453, 'vf_loss': 0.008899099197643999, 'total_loss': -0.02338530098513758, 'approx_kl': 8.781596250173607e-08, 'clip_fraction': 0.0, 'grad_norm': 33.436187744140625}
2023-01-03 22:27:09.632 DEBUG: Taking gradient step
2023-01-03 22:27:09.642 DEBUG: Loss 1: {'policy_loss': -0.03595038652192155, 'entropy_loss': -0.07747872732579708, 'vf_loss': 0.006159110925328293, 'total_loss': -0.10727000292239033, 'approx_kl': 0.02760938717983663, 'clip_fraction': 0.0625, 'grad_norm': 6.27691125869751}
2023-01-03 22:27:10.635 DEBUG: Early stopping at step 2 for reaching max KL.
2023-01-03 22:27:10.636 INFO: Optimization: policy loss=-0.036, vf loss=0.006, entropy loss=-0.077, total loss=-0.107, num steps=2
2023-01-03 22:27:10.636 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 22:27:12.252 INFO: Evaluation rollout: return=0.618 (0.0), episode length=6.0
2023-01-03 22:27:12.253 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 22:27:12.256 INFO: Iteration: 116/137, steps: 25056
2023-01-03 22:27:47.282 DEBUG: Atoms are too close
2023-01-03 22:27:48.075 DEBUG: There is a single atom floating around
2023-01-03 22:28:06.232 INFO: Training rollout: return=-0.194 (3.1), episode length=6.0
2023-01-03 22:28:06.234 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 22:28:06.237 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-25056_train.pkl
2023-01-03 22:28:07.272 DEBUG: Taking gradient step
2023-01-03 22:28:07.282 DEBUG: Loss 0: {'policy_loss': -0.04134197354222687, 'entropy_loss': -0.07944805361330509, 'vf_loss': 0.006375807958382193, 'total_loss': -0.11441421919714978, 'approx_kl': 1.7047084099885979e-07, 'clip_fraction': 0.0, 'grad_norm': 14.17765998840332}
2023-01-03 22:28:08.311 DEBUG: Taking gradient step
2023-01-03 22:28:08.321 DEBUG: Loss 1: {'policy_loss': 0.02280894113623297, 'entropy_loss': -0.0780909564346075, 'vf_loss': 0.007812526840524105, 'total_loss': -0.04746948845785043, 'approx_kl': -0.002536250976845622, 'clip_fraction': 0.01953125, 'grad_norm': 22.723552703857422}
2023-01-03 22:28:09.338 DEBUG: Taking gradient step
2023-01-03 22:28:09.347 DEBUG: Loss 2: {'policy_loss': 0.017205076797202807, 'entropy_loss': -0.07763824053108692, 'vf_loss': 0.008367036243658131, 'total_loss': -0.05206612749022599, 'approx_kl': 0.005071941995993257, 'clip_fraction': 0.1236979179084301, 'grad_norm': 12.410508155822754}
2023-01-03 22:28:10.338 DEBUG: Taking gradient step
2023-01-03 22:28:10.348 DEBUG: Loss 3: {'policy_loss': -0.02398437469016123, 'entropy_loss': -0.0780778918415308, 'vf_loss': 0.006811850263099273, 'total_loss': -0.09525041626859276, 'approx_kl': 0.03825063304975629, 'clip_fraction': 0.1705729179084301, 'grad_norm': 7.520852565765381}
2023-01-03 22:28:11.384 DEBUG: Early stopping at step 4 for reaching max KL.
2023-01-03 22:28:11.385 INFO: Optimization: policy loss=-0.024, vf loss=0.007, entropy loss=-0.078, total loss=-0.095, num steps=4
2023-01-03 22:28:11.386 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 22:28:12.997 INFO: Evaluation rollout: return=0.620 (0.0), episode length=6.0
2023-01-03 22:28:12.998 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 22:28:13.001 INFO: Iteration: 117/137, steps: 25272
2023-01-03 22:28:29.523 DEBUG: There is a single atom floating around
2023-01-03 22:28:29.790 DEBUG: There is a single atom floating around
2023-01-03 22:28:45.578 DEBUG: Atoms are too close
2023-01-03 22:29:08.375 INFO: Training rollout: return=-0.591 (3.9), episode length=6.0
2023-01-03 22:29:08.376 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 22:29:08.379 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-25272_train.pkl
2023-01-03 22:29:09.402 DEBUG: Taking gradient step
2023-01-03 22:29:09.411 DEBUG: Loss 0: {'policy_loss': 0.003383503974238541, 'entropy_loss': -0.0767589583992958, 'vf_loss': 0.010667762450298393, 'total_loss': -0.06270769197475887, 'approx_kl': -9.150244295597076e-08, 'clip_fraction': 0.0, 'grad_norm': 17.14936065673828}
2023-01-03 22:29:10.430 DEBUG: Taking gradient step
2023-01-03 22:29:10.439 DEBUG: Loss 1: {'policy_loss': -0.030034915709434253, 'entropy_loss': -0.07692940905690193, 'vf_loss': 0.009904847962595963, 'total_loss': -0.09705947680374022, 'approx_kl': 0.003033696790225804, 'clip_fraction': 0.015625, 'grad_norm': 12.34949016571045}
2023-01-03 22:29:11.448 DEBUG: Taking gradient step
2023-01-03 22:29:11.457 DEBUG: Loss 2: {'policy_loss': -0.037288675306281494, 'entropy_loss': -0.07731303572654724, 'vf_loss': 0.009936394363589122, 'total_loss': -0.10466531666923962, 'approx_kl': 0.006836071144789457, 'clip_fraction': 0.18489583395421505, 'grad_norm': 12.478272438049316}
2023-01-03 22:29:12.486 DEBUG: Taking gradient step
2023-01-03 22:29:12.497 DEBUG: Loss 3: {'policy_loss': -0.07416714304977531, 'entropy_loss': -0.07778148725628853, 'vf_loss': 0.009106981463717505, 'total_loss': -0.14284164884234635, 'approx_kl': 0.005656002089381218, 'clip_fraction': 0.3046875, 'grad_norm': 5.544017791748047}
2023-01-03 22:29:13.543 DEBUG: Taking gradient step
2023-01-03 22:29:13.552 DEBUG: Loss 4: {'policy_loss': -0.035217169852854995, 'entropy_loss': -0.07676350325345993, 'vf_loss': 0.011040350982159126, 'total_loss': -0.1009403221241558, 'approx_kl': 0.024652166990563273, 'clip_fraction': 0.3880208432674408, 'grad_norm': 5.786304950714111}
2023-01-03 22:29:14.552 DEBUG: Taking gradient step
2023-01-03 22:29:14.560 DEBUG: Loss 5: {'policy_loss': -0.07511788737975883, 'entropy_loss': -0.07627062126994133, 'vf_loss': 0.0090903734058488, 'total_loss': -0.14229813524385135, 'approx_kl': 0.015906963730230927, 'clip_fraction': 0.3489583358168602, 'grad_norm': 5.870396614074707}
2023-01-03 22:29:15.601 DEBUG: Taking gradient step
2023-01-03 22:29:15.610 DEBUG: Loss 6: {'policy_loss': -0.04119614097613049, 'entropy_loss': -0.0755260270088911, 'vf_loss': 0.010512259163492379, 'total_loss': -0.10620990882152921, 'approx_kl': 0.010361933149397373, 'clip_fraction': 0.2994791716337204, 'grad_norm': 5.0232720375061035}
2023-01-03 22:29:16.661 DEBUG: Taking gradient step
2023-01-03 22:29:16.670 DEBUG: Loss 7: {'policy_loss': -0.05041859366919554, 'entropy_loss': -0.07520658150315285, 'vf_loss': 0.010225730552931729, 'total_loss': -0.11539944461941666, 'approx_kl': 0.017772193299606442, 'clip_fraction': 0.2981770858168602, 'grad_norm': 12.20991325378418}
2023-01-03 22:29:17.708 DEBUG: Taking gradient step
2023-01-03 22:29:17.717 DEBUG: Loss 8: {'policy_loss': -0.0769097407423037, 'entropy_loss': -0.07572521083056927, 'vf_loss': 0.009082244432292913, 'total_loss': -0.14355270714058005, 'approx_kl': 0.0229844453278929, 'clip_fraction': 0.3528645858168602, 'grad_norm': 9.454805374145508}
2023-01-03 22:29:18.773 DEBUG: Taking gradient step
2023-01-03 22:29:18.784 DEBUG: Loss 9: {'policy_loss': -0.04452654253530388, 'entropy_loss': -0.07487499713897705, 'vf_loss': 0.01064221114108083, 'total_loss': -0.1087593285332001, 'approx_kl': 0.03954075463116169, 'clip_fraction': 0.3424479216337204, 'grad_norm': 6.246315956115723}
2023-01-03 22:29:19.897 DEBUG: Taking gradient step
2023-01-03 22:29:19.910 DEBUG: Loss 10: {'policy_loss': -0.05919083893747623, 'entropy_loss': -0.07419011741876602, 'vf_loss': 0.009684539319698985, 'total_loss': -0.12369641703654327, 'approx_kl': 0.024526050314307213, 'clip_fraction': 0.3346354216337204, 'grad_norm': 5.336650371551514}
2023-01-03 22:29:21.045 DEBUG: Taking gradient step
2023-01-03 22:29:21.058 DEBUG: Loss 11: {'policy_loss': 0.0067262038429258125, 'entropy_loss': -0.07490249909460545, 'vf_loss': 0.012972107066344812, 'total_loss': -0.05520418818533482, 'approx_kl': 0.04168877750635147, 'clip_fraction': 0.3268229216337204, 'grad_norm': 3.8170509338378906}
2023-01-03 22:29:22.219 DEBUG: Taking gradient step
2023-01-03 22:29:22.232 DEBUG: Loss 12: {'policy_loss': -0.06190918127459803, 'entropy_loss': -0.07412306778132915, 'vf_loss': 0.009842631921749402, 'total_loss': -0.12618961713417778, 'approx_kl': 0.016710807103663683, 'clip_fraction': 0.3450520858168602, 'grad_norm': 3.734614372253418}
2023-01-03 22:29:23.369 DEBUG: Taking gradient step
2023-01-03 22:29:23.382 DEBUG: Loss 13: {'policy_loss': -0.07370228428553172, 'entropy_loss': -0.07407933659851551, 'vf_loss': 0.009662659108076264, 'total_loss': -0.13811896177597094, 'approx_kl': -0.0024465820752084255, 'clip_fraction': 0.3098958358168602, 'grad_norm': 6.206528663635254}
2023-01-03 22:29:24.536 DEBUG: Taking gradient step
2023-01-03 22:29:24.549 DEBUG: Loss 14: {'policy_loss': -0.05191758521091458, 'entropy_loss': -0.07399966195225716, 'vf_loss': 0.010397951597302672, 'total_loss': -0.11551929556586907, 'approx_kl': 0.0008471312467008829, 'clip_fraction': 0.3619791716337204, 'grad_norm': 4.623037815093994}
2023-01-03 22:29:24.549 INFO: Optimization: policy loss=-0.052, vf loss=0.010, entropy loss=-0.074, total loss=-0.116, num steps=15
2023-01-03 22:29:24.549 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 22:29:26.228 INFO: Evaluation rollout: return=0.626 (0.0), episode length=6.0
2023-01-03 22:29:26.229 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 22:29:26.232 INFO: Iteration: 118/137, steps: 25488
2023-01-03 22:30:01.279 DEBUG: Atoms are too close
2023-01-03 22:30:21.177 DEBUG: Atoms are too close
2023-01-03 22:30:29.087 INFO: Training rollout: return=-0.158 (3.1), episode length=6.0
2023-01-03 22:30:29.088 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 22:30:29.092 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-25488_train.pkl
2023-01-03 22:30:30.119 DEBUG: Taking gradient step
2023-01-03 22:30:30.129 DEBUG: Loss 0: {'policy_loss': -0.01297873031598882, 'entropy_loss': -0.07537068985402584, 'vf_loss': 0.006653939975252896, 'total_loss': -0.08169548019476178, 'approx_kl': 8.118028915760078e-08, 'clip_fraction': 0.0, 'grad_norm': 14.267160415649414}
2023-01-03 22:30:31.157 DEBUG: Taking gradient step
2023-01-03 22:30:31.166 DEBUG: Loss 1: {'policy_loss': -0.030575180566171947, 'entropy_loss': -0.07616219855844975, 'vf_loss': 0.007046259279504584, 'total_loss': -0.09969111984511711, 'approx_kl': 0.012954840552993119, 'clip_fraction': 0.08854166697710752, 'grad_norm': 9.954261779785156}
2023-01-03 22:30:32.204 DEBUG: Taking gradient step
2023-01-03 22:30:32.213 DEBUG: Loss 2: {'policy_loss': -0.0167207965196626, 'entropy_loss': -0.0751650221645832, 'vf_loss': 0.007744484758633892, 'total_loss': -0.08414133392561192, 'approx_kl': 0.03630615957081318, 'clip_fraction': 0.2916666716337204, 'grad_norm': 7.626328945159912}
2023-01-03 22:30:33.232 DEBUG: Early stopping at step 3 for reaching max KL.
2023-01-03 22:30:33.233 INFO: Optimization: policy loss=-0.017, vf loss=0.008, entropy loss=-0.075, total loss=-0.084, num steps=3
2023-01-03 22:30:33.233 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 22:30:34.893 INFO: Evaluation rollout: return=0.620 (0.0), episode length=6.0
2023-01-03 22:30:34.894 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 22:30:34.897 INFO: Iteration: 119/137, steps: 25704
2023-01-03 22:30:50.116 DEBUG: Atoms are too close
2023-01-03 22:31:10.245 DEBUG: Atoms are too close
2023-01-03 22:31:29.227 INFO: Training rollout: return=-0.172 (3.1), episode length=6.0
2023-01-03 22:31:29.229 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 22:31:29.232 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-25704_train.pkl
2023-01-03 22:31:30.273 DEBUG: Taking gradient step
2023-01-03 22:31:30.284 DEBUG: Loss 0: {'policy_loss': -0.031185573437207452, 'entropy_loss': -0.07485577277839184, 'vf_loss': 0.006294299449661194, 'total_loss': -0.09974704676593808, 'approx_kl': 8.769955428533649e-09, 'clip_fraction': 0.0, 'grad_norm': 11.59923267364502}
2023-01-03 22:31:31.303 DEBUG: Taking gradient step
2023-01-03 22:31:31.311 DEBUG: Loss 1: {'policy_loss': -0.04744574551505009, 'entropy_loss': -0.07395862974226475, 'vf_loss': 0.006302977142527727, 'total_loss': -0.11510139811478712, 'approx_kl': -0.00389537843875587, 'clip_fraction': 0.046875, 'grad_norm': 10.069500923156738}
2023-01-03 22:31:32.329 DEBUG: Taking gradient step
2023-01-03 22:31:32.340 DEBUG: Loss 2: {'policy_loss': 0.004787149419228132, 'entropy_loss': -0.07497887313365936, 'vf_loss': 0.008229816150424943, 'total_loss': -0.0619619075640063, 'approx_kl': 0.005153167643584311, 'clip_fraction': 0.29296875, 'grad_norm': 6.745131969451904}
2023-01-03 22:31:33.353 DEBUG: Taking gradient step
2023-01-03 22:31:33.362 DEBUG: Loss 3: {'policy_loss': -0.039349668902940685, 'entropy_loss': -0.07476546801626682, 'vf_loss': 0.006606845141067991, 'total_loss': -0.10750829177813953, 'approx_kl': 0.015467718243598938, 'clip_fraction': 0.4153645858168602, 'grad_norm': 5.350600242614746}
2023-01-03 22:31:34.354 DEBUG: Taking gradient step
2023-01-03 22:31:34.362 DEBUG: Loss 4: {'policy_loss': -0.05765645043989889, 'entropy_loss': -0.0756890457123518, 'vf_loss': 0.006299305682039586, 'total_loss': -0.1270461904702111, 'approx_kl': 0.030373646412044764, 'clip_fraction': 0.4401041716337204, 'grad_norm': 5.276635646820068}
2023-01-03 22:31:35.379 DEBUG: Taking gradient step
2023-01-03 22:31:35.388 DEBUG: Loss 5: {'policy_loss': -0.01847472135788321, 'entropy_loss': -0.07348785363137722, 'vf_loss': 0.007652972996894379, 'total_loss': -0.08430960199236606, 'approx_kl': 0.034735433757305145, 'clip_fraction': 0.4596354216337204, 'grad_norm': 4.278287410736084}
2023-01-03 22:31:36.414 DEBUG: Early stopping at step 6 for reaching max KL.
2023-01-03 22:31:36.414 INFO: Optimization: policy loss=-0.018, vf loss=0.008, entropy loss=-0.073, total loss=-0.084, num steps=6
2023-01-03 22:31:36.415 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 22:31:38.053 INFO: Evaluation rollout: return=0.626 (0.0), episode length=6.0
2023-01-03 22:31:38.056 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 22:31:38.059 INFO: Iteration: 120/137, steps: 25920
2023-01-03 22:31:50.154 DEBUG: There is a single atom floating around
2023-01-03 22:32:30.066 DEBUG: There is a single atom floating around
2023-01-03 22:32:32.656 INFO: Training rollout: return=-0.237 (3.3), episode length=6.0
2023-01-03 22:32:32.657 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 22:32:32.660 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-25920_train.pkl
2023-01-03 22:32:33.672 DEBUG: Taking gradient step
2023-01-03 22:32:33.682 DEBUG: Loss 0: {'policy_loss': 0.004969364223436357, 'entropy_loss': -0.07382890582084656, 'vf_loss': 0.007796491940592149, 'total_loss': -0.06106304965681805, 'approx_kl': -4.489751148639698e-08, 'clip_fraction': 0.0, 'grad_norm': 16.88454818725586}
2023-01-03 22:32:34.707 DEBUG: Taking gradient step
2023-01-03 22:32:34.718 DEBUG: Loss 1: {'policy_loss': -0.01958935675962597, 'entropy_loss': -0.0727030448615551, 'vf_loss': 0.006758910238842875, 'total_loss': -0.08553349138233819, 'approx_kl': 0.00820662546902895, 'clip_fraction': 0.05989583395421505, 'grad_norm': 8.055253982543945}
2023-01-03 22:32:35.746 DEBUG: Taking gradient step
2023-01-03 22:32:35.756 DEBUG: Loss 2: {'policy_loss': 0.013978975007845423, 'entropy_loss': -0.0737687386572361, 'vf_loss': 0.00831831719503474, 'total_loss': -0.05147144645435594, 'approx_kl': 0.012863151263445616, 'clip_fraction': 0.2096354216337204, 'grad_norm': 6.5362677574157715}
2023-01-03 22:32:36.773 DEBUG: Taking gradient step
2023-01-03 22:32:36.783 DEBUG: Loss 3: {'policy_loss': -0.03105285366247387, 'entropy_loss': -0.07319045998156071, 'vf_loss': 0.006616690390989054, 'total_loss': -0.09762662325304552, 'approx_kl': 0.03360336518380791, 'clip_fraction': 0.2916666716337204, 'grad_norm': 5.0225019454956055}
2023-01-03 22:32:37.794 DEBUG: Taking gradient step
2023-01-03 22:32:37.803 DEBUG: Loss 4: {'policy_loss': -0.04913602009348051, 'entropy_loss': -0.07328958809375763, 'vf_loss': 0.006173565369709078, 'total_loss': -0.11625204281752906, 'approx_kl': 0.038407648680731654, 'clip_fraction': 0.3346354216337204, 'grad_norm': 4.952637672424316}
2023-01-03 22:32:38.793 DEBUG: Taking gradient step
2023-01-03 22:32:38.802 DEBUG: Loss 5: {'policy_loss': 0.01138963224023571, 'entropy_loss': -0.07322289422154427, 'vf_loss': 0.009340194775121128, 'total_loss': -0.05249306720618742, 'approx_kl': 0.020250076078809798, 'clip_fraction': 0.3502604216337204, 'grad_norm': 3.8548743724823}
2023-01-03 22:32:39.828 DEBUG: Taking gradient step
2023-01-03 22:32:39.837 DEBUG: Loss 6: {'policy_loss': 0.045517227323805434, 'entropy_loss': -0.07255611382424831, 'vf_loss': 0.009812891715151865, 'total_loss': -0.017225994785291007, 'approx_kl': 0.027466680388897657, 'clip_fraction': 0.3515625, 'grad_norm': 6.660470485687256}
2023-01-03 22:32:40.842 DEBUG: Taking gradient step
2023-01-03 22:32:40.851 DEBUG: Loss 7: {'policy_loss': -0.024530341616959384, 'entropy_loss': -0.07231707312166691, 'vf_loss': 0.007000044283287805, 'total_loss': -0.0898473704553385, 'approx_kl': 0.02069060690701008, 'clip_fraction': 0.3619791716337204, 'grad_norm': 6.027705192565918}
2023-01-03 22:32:41.866 DEBUG: Taking gradient step
2023-01-03 22:32:41.876 DEBUG: Loss 8: {'policy_loss': -0.05546028565035585, 'entropy_loss': -0.072027787566185, 'vf_loss': 0.0061586036299457565, 'total_loss': -0.12132946958659507, 'approx_kl': 0.01397669326979667, 'clip_fraction': 0.3815104216337204, 'grad_norm': 4.897476673126221}
2023-01-03 22:32:42.925 DEBUG: Taking gradient step
2023-01-03 22:32:42.936 DEBUG: Loss 9: {'policy_loss': -0.026301378767572447, 'entropy_loss': -0.0723353810608387, 'vf_loss': 0.007030590909461911, 'total_loss': -0.09160616891894924, 'approx_kl': 0.002996958326548338, 'clip_fraction': 0.42578125, 'grad_norm': 4.411630630493164}
2023-01-03 22:32:43.963 DEBUG: Taking gradient step
2023-01-03 22:32:43.972 DEBUG: Loss 10: {'policy_loss': -0.019485555498299674, 'entropy_loss': -0.07214118354022503, 'vf_loss': 0.007249283356130747, 'total_loss': -0.08437745568239395, 'approx_kl': 0.006634021759964526, 'clip_fraction': 0.4270833358168602, 'grad_norm': 3.911975622177124}
2023-01-03 22:32:44.992 DEBUG: Taking gradient step
2023-01-03 22:32:45.002 DEBUG: Loss 11: {'policy_loss': -0.04238305435841249, 'entropy_loss': -0.07118166610598564, 'vf_loss': 0.006561177999539041, 'total_loss': -0.1070035424648591, 'approx_kl': 0.0042429580353200436, 'clip_fraction': 0.4153645858168602, 'grad_norm': 5.065361022949219}
2023-01-03 22:32:46.025 DEBUG: Taking gradient step
2023-01-03 22:32:46.033 DEBUG: Loss 12: {'policy_loss': -0.06879006462840476, 'entropy_loss': -0.07291599921882153, 'vf_loss': 0.0061376111939960044, 'total_loss': -0.13556845265323025, 'approx_kl': -0.0001226378371939063, 'clip_fraction': 0.4244791716337204, 'grad_norm': 4.81586217880249}
2023-01-03 22:32:47.039 DEBUG: Taking gradient step
2023-01-03 22:32:47.048 DEBUG: Loss 13: {'policy_loss': -0.02952397185750755, 'entropy_loss': -0.07202505320310593, 'vf_loss': 0.007406417639919095, 'total_loss': -0.09414260742069439, 'approx_kl': 0.009086763951927423, 'clip_fraction': 0.4817708432674408, 'grad_norm': 2.5825576782226562}
2023-01-03 22:32:48.026 DEBUG: Taking gradient step
2023-01-03 22:32:48.034 DEBUG: Loss 14: {'policy_loss': -0.022523279042757575, 'entropy_loss': -0.07263545878231525, 'vf_loss': 0.007111657169911732, 'total_loss': -0.08804708065516109, 'approx_kl': 0.018353508785367012, 'clip_fraction': 0.4049479216337204, 'grad_norm': 6.308987140655518}
2023-01-03 22:32:48.035 INFO: Optimization: policy loss=-0.023, vf loss=0.007, entropy loss=-0.073, total loss=-0.088, num steps=15
2023-01-03 22:32:48.035 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 22:32:49.709 INFO: Evaluation rollout: return=0.523 (0.0), episode length=6.0
2023-01-03 22:32:49.710 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 22:32:49.712 DEBUG: Deleting old model: runs/CH3NO_baseline/models/CH3NO_baseline_run-1_steps-23976.model
2023-01-03 22:32:49.716 DEBUG: Saving model: runs/CH3NO_baseline/models/CH3NO_baseline_run-1_steps-26136.model
2023-01-03 22:32:49.745 INFO: Iteration: 121/137, steps: 26136
2023-01-03 22:33:24.372 DEBUG: Atoms are too close
2023-01-03 22:33:46.720 INFO: Training rollout: return=0.192 (2.2), episode length=6.0
2023-01-03 22:33:46.721 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 22:33:46.724 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-26136_train.pkl
2023-01-03 22:33:47.769 DEBUG: Taking gradient step
2023-01-03 22:33:47.779 DEBUG: Loss 0: {'policy_loss': -0.022623424536376946, 'entropy_loss': -0.07440212741494179, 'vf_loss': 0.003309668276218983, 'total_loss': -0.09371588367509975, 'approx_kl': 2.9336661100387573e-08, 'clip_fraction': 0.0, 'grad_norm': 13.220044136047363}
2023-01-03 22:33:48.782 DEBUG: Taking gradient step
2023-01-03 22:33:48.791 DEBUG: Loss 1: {'policy_loss': -0.03013146754579224, 'entropy_loss': -0.07477420009672642, 'vf_loss': 0.0033035485305075957, 'total_loss': -0.10160211911201106, 'approx_kl': -0.006886525545269251, 'clip_fraction': 0.00390625, 'grad_norm': 12.39920711517334}
2023-01-03 22:33:49.806 DEBUG: Taking gradient step
2023-01-03 22:33:49.815 DEBUG: Loss 2: {'policy_loss': -0.04281994750057614, 'entropy_loss': -0.07401721365749836, 'vf_loss': 0.00330540111615224, 'total_loss': -0.11353176004192227, 'approx_kl': -0.011194533435627818, 'clip_fraction': 0.1484375, 'grad_norm': 7.6707282066345215}
2023-01-03 22:33:50.840 DEBUG: Taking gradient step
2023-01-03 22:33:50.849 DEBUG: Loss 3: {'policy_loss': -0.022387712990706566, 'entropy_loss': -0.07402288541197777, 'vf_loss': 0.003874288085320286, 'total_loss': -0.09253631031736405, 'approx_kl': -0.000605651643127203, 'clip_fraction': 0.3033854216337204, 'grad_norm': 5.1934051513671875}
2023-01-03 22:33:51.861 DEBUG: Taking gradient step
2023-01-03 22:33:51.871 DEBUG: Loss 4: {'policy_loss': -0.029704710991948238, 'entropy_loss': -0.07500052079558372, 'vf_loss': 0.0035988675363641245, 'total_loss': -0.10110636425116784, 'approx_kl': -0.015009677037596703, 'clip_fraction': 0.3541666716337204, 'grad_norm': 2.446989059448242}
2023-01-03 22:33:52.860 DEBUG: Taking gradient step
2023-01-03 22:33:52.869 DEBUG: Loss 5: {'policy_loss': -0.0528434555401739, 'entropy_loss': -0.07511591911315918, 'vf_loss': 0.0032902474942441895, 'total_loss': -0.12466912715908889, 'approx_kl': -0.0059560423251241446, 'clip_fraction': 0.3763020858168602, 'grad_norm': 2.597804546356201}
2023-01-03 22:33:53.889 DEBUG: Taking gradient step
2023-01-03 22:33:53.899 DEBUG: Loss 6: {'policy_loss': -0.016556189334997876, 'entropy_loss': -0.07492643594741821, 'vf_loss': 0.003562451415181608, 'total_loss': -0.08792017386723448, 'approx_kl': -0.0006265263073146343, 'clip_fraction': 0.30859375, 'grad_norm': 2.698827028274536}
2023-01-03 22:33:54.918 DEBUG: Taking gradient step
2023-01-03 22:33:54.929 DEBUG: Loss 7: {'policy_loss': -0.004205772086816745, 'entropy_loss': -0.07519723288714886, 'vf_loss': 0.004424825631754423, 'total_loss': -0.07497817934221118, 'approx_kl': 0.00043883523903787136, 'clip_fraction': 0.2734375, 'grad_norm': 2.7423789501190186}
2023-01-03 22:33:55.947 DEBUG: Taking gradient step
2023-01-03 22:33:55.958 DEBUG: Loss 8: {'policy_loss': 0.02448706604161622, 'entropy_loss': -0.07568217627704144, 'vf_loss': 0.005470275626803038, 'total_loss': -0.04572483460862217, 'approx_kl': 0.003212721785530448, 'clip_fraction': 0.3072916716337204, 'grad_norm': 3.860304355621338}
2023-01-03 22:33:56.977 DEBUG: Taking gradient step
2023-01-03 22:33:56.986 DEBUG: Loss 9: {'policy_loss': -0.052858571535514015, 'entropy_loss': -0.07616663351655006, 'vf_loss': 0.0032404810642805842, 'total_loss': -0.1257847239877835, 'approx_kl': -0.01594159286469221, 'clip_fraction': 0.33203125, 'grad_norm': 2.416149139404297}
2023-01-03 22:33:57.983 DEBUG: Taking gradient step
2023-01-03 22:33:57.992 DEBUG: Loss 10: {'policy_loss': -0.02142374056443735, 'entropy_loss': -0.07590366899967194, 'vf_loss': 0.004066708787852874, 'total_loss': -0.09326070077625642, 'approx_kl': -0.02085168263874948, 'clip_fraction': 0.3606770858168602, 'grad_norm': 2.702282190322876}
2023-01-03 22:33:59.005 DEBUG: Taking gradient step
2023-01-03 22:33:59.013 DEBUG: Loss 11: {'policy_loss': -0.05308990134203352, 'entropy_loss': -0.07601385749876499, 'vf_loss': 0.0032257242340617996, 'total_loss': -0.12587803460673672, 'approx_kl': -0.028207008494064212, 'clip_fraction': 0.3346354216337204, 'grad_norm': 3.43790864944458}
2023-01-03 22:34:00.007 DEBUG: Taking gradient step
2023-01-03 22:34:00.015 DEBUG: Loss 12: {'policy_loss': -0.05536494993582996, 'entropy_loss': -0.07614392787218094, 'vf_loss': 0.003215479132647809, 'total_loss': -0.1282933986753631, 'approx_kl': -0.054985318798571825, 'clip_fraction': 0.359375, 'grad_norm': 2.685051441192627}
2023-01-03 22:34:01.037 DEBUG: Taking gradient step
2023-01-03 22:34:01.045 DEBUG: Loss 13: {'policy_loss': -0.05568451955942387, 'entropy_loss': -0.07674275524914265, 'vf_loss': 0.003206447413629275, 'total_loss': -0.12922082739493723, 'approx_kl': -0.050457841251045465, 'clip_fraction': 0.3385416716337204, 'grad_norm': 2.18731689453125}
2023-01-03 22:34:02.051 DEBUG: Taking gradient step
2023-01-03 22:34:02.061 DEBUG: Loss 14: {'policy_loss': -0.006675885062773591, 'entropy_loss': -0.07644014060497284, 'vf_loss': 0.004399123553311209, 'total_loss': -0.07871690211443522, 'approx_kl': -0.0493811487685889, 'clip_fraction': 0.328125, 'grad_norm': 23.772796630859375}
2023-01-03 22:34:02.061 INFO: Optimization: policy loss=-0.007, vf loss=0.004, entropy loss=-0.076, total loss=-0.079, num steps=15
2023-01-03 22:34:02.061 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 22:34:03.774 INFO: Evaluation rollout: return=0.583 (0.0), episode length=6.0
2023-01-03 22:34:03.775 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 22:34:03.777 INFO: Iteration: 122/137, steps: 26352
2023-01-03 22:35:06.657 INFO: Training rollout: return=0.583 (0.1), episode length=6.0
2023-01-03 22:35:06.658 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 22:35:06.661 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-26352_train.pkl
2023-01-03 22:35:07.684 DEBUG: Taking gradient step
2023-01-03 22:35:07.694 DEBUG: Loss 0: {'policy_loss': -0.025942551634327175, 'entropy_loss': -0.07602356374263763, 'vf_loss': 0.00020531824767668826, 'total_loss': -0.10176079712928812, 'approx_kl': 1.2922100722789764e-07, 'clip_fraction': 0.0, 'grad_norm': 9.345020294189453}
2023-01-03 22:35:08.745 DEBUG: Taking gradient step
2023-01-03 22:35:08.755 DEBUG: Loss 1: {'policy_loss': 0.014715185822171552, 'entropy_loss': -0.07606426812708378, 'vf_loss': 0.00018542631692694382, 'total_loss': -0.061163655987985274, 'approx_kl': 0.00021472436492331326, 'clip_fraction': 0.022135416977107525, 'grad_norm': 8.716673851013184}
2023-01-03 22:35:09.791 DEBUG: Taking gradient step
2023-01-03 22:35:09.801 DEBUG: Loss 2: {'policy_loss': -0.05776295774119244, 'entropy_loss': -0.07681824080646038, 'vf_loss': 0.00018048812364368036, 'total_loss': -0.13440071042400914, 'approx_kl': 0.008327736519277096, 'clip_fraction': 0.1614583358168602, 'grad_norm': 9.912806510925293}
2023-01-03 22:35:10.841 DEBUG: Taking gradient step
2023-01-03 22:35:10.850 DEBUG: Loss 3: {'policy_loss': -0.05947801133991608, 'entropy_loss': -0.07657330110669136, 'vf_loss': 0.00016818414541187082, 'total_loss': -0.13588312830119556, 'approx_kl': 0.029772258829325438, 'clip_fraction': 0.2708333358168602, 'grad_norm': 8.59237003326416}
2023-01-03 22:35:11.902 DEBUG: Taking gradient step
2023-01-03 22:35:11.912 DEBUG: Loss 4: {'policy_loss': -0.021584305019020276, 'entropy_loss': -0.07594989240169525, 'vf_loss': 0.0001550383270887297, 'total_loss': -0.0973791590936268, 'approx_kl': 0.037760858656838536, 'clip_fraction': 0.3346354216337204, 'grad_norm': 7.864190578460693}
2023-01-03 22:35:12.952 DEBUG: Taking gradient step
2023-01-03 22:35:12.961 DEBUG: Loss 5: {'policy_loss': -0.04625158633204372, 'entropy_loss': -0.07571578212082386, 'vf_loss': 0.0001495151158458125, 'total_loss': -0.12181785333702176, 'approx_kl': 0.03512652846984565, 'clip_fraction': 0.37109375, 'grad_norm': 6.125219821929932}
2023-01-03 22:35:14.009 DEBUG: Taking gradient step
2023-01-03 22:35:14.018 DEBUG: Loss 6: {'policy_loss': 0.026641252244296587, 'entropy_loss': -0.07655994407832623, 'vf_loss': 0.00013225259964787657, 'total_loss': -0.049786439234381794, 'approx_kl': 0.041308688232675195, 'clip_fraction': 0.42578125, 'grad_norm': 5.936034679412842}
2023-01-03 22:35:15.056 DEBUG: Taking gradient step
2023-01-03 22:35:15.065 DEBUG: Loss 7: {'policy_loss': -0.07937551031409959, 'entropy_loss': -0.07530027441680431, 'vf_loss': 0.00013116441105415178, 'total_loss': -0.15454462031984975, 'approx_kl': 0.040306104347109795, 'clip_fraction': 0.4622395858168602, 'grad_norm': 9.459548950195312}
2023-01-03 22:35:16.109 DEBUG: Taking gradient step
2023-01-03 22:35:16.118 DEBUG: Loss 8: {'policy_loss': -0.0784085808043265, 'entropy_loss': -0.07589329592883587, 'vf_loss': 0.0001212291677156732, 'total_loss': -0.1541806475654467, 'approx_kl': 0.043293862021528184, 'clip_fraction': 0.44140625, 'grad_norm': 5.145359039306641}
2023-01-03 22:35:17.132 DEBUG: Early stopping at step 9 for reaching max KL.
2023-01-03 22:35:17.132 INFO: Optimization: policy loss=-0.078, vf loss=0.000, entropy loss=-0.076, total loss=-0.154, num steps=9
2023-01-03 22:35:17.133 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 22:35:18.829 INFO: Evaluation rollout: return=0.623 (0.0), episode length=6.0
2023-01-03 22:35:18.830 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 22:35:18.832 INFO: Iteration: 123/137, steps: 26568
2023-01-03 22:35:34.180 DEBUG: There is a single atom floating around
2023-01-03 22:35:52.856 DEBUG: There is a single atom floating around
2023-01-03 22:35:54.080 DEBUG: There is a single atom floating around
2023-01-03 22:36:15.144 INFO: Training rollout: return=-0.617 (3.9), episode length=6.0
2023-01-03 22:36:15.146 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 22:36:15.148 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-26568_train.pkl
2023-01-03 22:36:16.188 DEBUG: Taking gradient step
2023-01-03 22:36:16.197 DEBUG: Loss 0: {'policy_loss': 0.03264641499069449, 'entropy_loss': -0.07461519166827202, 'vf_loss': 0.011915284935084418, 'total_loss': -0.030053491742493117, 'approx_kl': 1.4800268388626137e-07, 'clip_fraction': 0.0, 'grad_norm': 23.015480041503906}
2023-01-03 22:36:17.208 DEBUG: Taking gradient step
2023-01-03 22:36:17.216 DEBUG: Loss 1: {'policy_loss': -0.0029450881310605914, 'entropy_loss': -0.07511423155665398, 'vf_loss': 0.012172199404290145, 'total_loss': -0.0658871202834244, 'approx_kl': 0.0044788013910874724, 'clip_fraction': 0.045572916977107525, 'grad_norm': 9.79259967803955}
2023-01-03 22:36:18.246 DEBUG: Taking gradient step
2023-01-03 22:36:18.255 DEBUG: Loss 2: {'policy_loss': -0.03743441100064804, 'entropy_loss': -0.07436397112905979, 'vf_loss': 0.01046147407460308, 'total_loss': -0.10133690805510476, 'approx_kl': 0.021971937036141753, 'clip_fraction': 0.2890625, 'grad_norm': 4.600379467010498}
2023-01-03 22:36:19.263 DEBUG: Early stopping at step 3 for reaching max KL.
2023-01-03 22:36:19.263 INFO: Optimization: policy loss=-0.037, vf loss=0.010, entropy loss=-0.074, total loss=-0.101, num steps=3
2023-01-03 22:36:19.264 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 22:36:20.947 INFO: Evaluation rollout: return=0.632 (0.0), episode length=6.0
2023-01-03 22:36:20.948 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 22:36:20.951 INFO: Iteration: 124/137, steps: 26784
2023-01-03 22:37:22.169 DEBUG: Atoms are too close
2023-01-03 22:37:23.083 INFO: Training rollout: return=0.199 (2.2), episode length=6.0
2023-01-03 22:37:23.084 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 22:37:23.087 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-26784_train.pkl
2023-01-03 22:37:24.133 DEBUG: Taking gradient step
2023-01-03 22:37:24.144 DEBUG: Loss 0: {'policy_loss': -0.02200362035559841, 'entropy_loss': -0.07597743161022663, 'vf_loss': 0.0032869031731429816, 'total_loss': -0.09469414879268206, 'approx_kl': 1.1598846505478377e-07, 'clip_fraction': 0.0, 'grad_norm': 16.697650909423828}
2023-01-03 22:37:25.198 DEBUG: Taking gradient step
2023-01-03 22:37:25.207 DEBUG: Loss 1: {'policy_loss': -0.041938578676236224, 'entropy_loss': -0.07574441097676754, 'vf_loss': 0.0032934376640781538, 'total_loss': -0.11438955198892561, 'approx_kl': 0.021733949426561594, 'clip_fraction': 0.1223958358168602, 'grad_norm': 12.50855541229248}
2023-01-03 22:37:26.272 DEBUG: Early stopping at step 2 for reaching max KL.
2023-01-03 22:37:26.272 INFO: Optimization: policy loss=-0.042, vf loss=0.003, entropy loss=-0.076, total loss=-0.114, num steps=2
2023-01-03 22:37:26.273 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 22:37:27.932 INFO: Evaluation rollout: return=0.634 (0.0), episode length=6.0
2023-01-03 22:37:27.933 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 22:37:27.936 INFO: Iteration: 125/137, steps: 27000
2023-01-03 22:38:24.946 INFO: Training rollout: return=0.553 (0.1), episode length=6.0
2023-01-03 22:38:24.947 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 22:38:24.950 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-27000_train.pkl
2023-01-03 22:38:26.028 DEBUG: Taking gradient step
2023-01-03 22:38:26.039 DEBUG: Loss 0: {'policy_loss': 0.06095676920926173, 'entropy_loss': -0.07470144890248775, 'vf_loss': 6.787818879028495e-05, 'total_loss': -0.013676801504435745, 'approx_kl': -8.82816237890438e-08, 'clip_fraction': 0.0, 'grad_norm': 14.838494300842285}
2023-01-03 22:38:27.114 DEBUG: Taking gradient step
2023-01-03 22:38:27.123 DEBUG: Loss 1: {'policy_loss': 0.01016526926544652, 'entropy_loss': -0.07466701418161392, 'vf_loss': 7.084525931234939e-05, 'total_loss': -0.06443089965685504, 'approx_kl': 0.015975960064679384, 'clip_fraction': 0.21484375, 'grad_norm': 11.50046157836914}
2023-01-03 22:38:28.175 DEBUG: Early stopping at step 2 for reaching max KL.
2023-01-03 22:38:28.175 INFO: Optimization: policy loss=0.010, vf loss=0.000, entropy loss=-0.075, total loss=-0.064, num steps=2
2023-01-03 22:38:28.176 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 22:38:29.864 INFO: Evaluation rollout: return=0.626 (0.0), episode length=6.0
2023-01-03 22:38:29.865 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 22:38:29.868 INFO: Iteration: 126/137, steps: 27216
2023-01-03 22:39:31.896 INFO: Training rollout: return=0.570 (0.1), episode length=6.0
2023-01-03 22:39:31.898 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 22:39:31.901 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-27216_train.pkl
2023-01-03 22:39:33.032 DEBUG: Taking gradient step
2023-01-03 22:39:33.042 DEBUG: Loss 0: {'policy_loss': -0.003966808834706039, 'entropy_loss': -0.0727155227214098, 'vf_loss': 9.459650191800798e-05, 'total_loss': -0.07658773505419783, 'approx_kl': 8.614733815193176e-09, 'clip_fraction': 0.0, 'grad_norm': 12.67431926727295}
2023-01-03 22:39:34.061 DEBUG: Taking gradient step
2023-01-03 22:39:34.071 DEBUG: Loss 1: {'policy_loss': -0.004998198187133018, 'entropy_loss': -0.07190245389938354, 'vf_loss': 9.156293615123947e-05, 'total_loss': -0.07680908915036533, 'approx_kl': 0.00688520772382617, 'clip_fraction': 0.07682291697710752, 'grad_norm': 9.167373657226562}
2023-01-03 22:39:35.077 DEBUG: Taking gradient step
2023-01-03 22:39:35.085 DEBUG: Loss 2: {'policy_loss': -0.071361185694939, 'entropy_loss': -0.07164787128567696, 'vf_loss': 9.562980053499111e-05, 'total_loss': -0.14291342718008096, 'approx_kl': 0.011323385639116168, 'clip_fraction': 0.25390625, 'grad_norm': 11.63291072845459}
2023-01-03 22:39:36.108 DEBUG: Taking gradient step
2023-01-03 22:39:36.118 DEBUG: Loss 3: {'policy_loss': -0.021060326988610437, 'entropy_loss': -0.07181856036186218, 'vf_loss': 8.881457374913689e-05, 'total_loss': -0.09279007277672349, 'approx_kl': 0.03447544714435935, 'clip_fraction': 0.3346354216337204, 'grad_norm': 11.26848316192627}
2023-01-03 22:39:37.150 DEBUG: Taking gradient step
2023-01-03 22:39:37.158 DEBUG: Loss 4: {'policy_loss': -0.011067900645425007, 'entropy_loss': -0.07264797389507294, 'vf_loss': 8.631606381004165e-05, 'total_loss': -0.0836295584766879, 'approx_kl': 0.03087220247834921, 'clip_fraction': 0.4244791716337204, 'grad_norm': 11.2147216796875}
2023-01-03 22:39:38.189 DEBUG: Taking gradient step
2023-01-03 22:39:38.200 DEBUG: Loss 5: {'policy_loss': -0.11699119550913023, 'entropy_loss': -0.07173416204750538, 'vf_loss': 9.074836689241573e-05, 'total_loss': -0.1886346091897432, 'approx_kl': 0.04277625191025436, 'clip_fraction': 0.44921875, 'grad_norm': 10.784740447998047}
2023-01-03 22:39:39.217 DEBUG: Early stopping at step 6 for reaching max KL.
2023-01-03 22:39:39.218 INFO: Optimization: policy loss=-0.117, vf loss=0.000, entropy loss=-0.072, total loss=-0.189, num steps=6
2023-01-03 22:39:39.219 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 22:39:40.866 INFO: Evaluation rollout: return=0.636 (0.0), episode length=6.0
2023-01-03 22:39:40.867 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 22:39:40.869 INFO: Iteration: 127/137, steps: 27432
2023-01-03 22:40:35.862 INFO: Training rollout: return=0.585 (0.1), episode length=6.0
2023-01-03 22:40:35.863 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 22:40:35.868 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-27432_train.pkl
2023-01-03 22:40:36.916 DEBUG: Taking gradient step
2023-01-03 22:40:36.928 DEBUG: Loss 0: {'policy_loss': 0.026610956393705414, 'entropy_loss': -0.07259251922369003, 'vf_loss': 7.408943182276586e-05, 'total_loss': -0.04590747339816186, 'approx_kl': -3.996926167815218e-08, 'clip_fraction': 0.0, 'grad_norm': 16.374691009521484}
2023-01-03 22:40:37.966 DEBUG: Taking gradient step
2023-01-03 22:40:37.976 DEBUG: Loss 1: {'policy_loss': -0.043318078707877836, 'entropy_loss': -0.07333045080304146, 'vf_loss': 7.61081070666171e-05, 'total_loss': -0.11657242140385268, 'approx_kl': -0.0031231387984007597, 'clip_fraction': 0.041666666977107525, 'grad_norm': 12.298054695129395}
2023-01-03 22:40:38.987 DEBUG: Taking gradient step
2023-01-03 22:40:38.996 DEBUG: Loss 2: {'policy_loss': -0.06671678283012761, 'entropy_loss': -0.07278803549706936, 'vf_loss': 7.461839003758603e-05, 'total_loss': -0.13943019993715938, 'approx_kl': -0.0022758236154913902, 'clip_fraction': 0.22265625, 'grad_norm': 10.667099952697754}
2023-01-03 22:40:40.018 DEBUG: Taking gradient step
2023-01-03 22:40:40.027 DEBUG: Loss 3: {'policy_loss': -0.04260055846442182, 'entropy_loss': -0.07324409298598766, 'vf_loss': 7.110061939063234e-05, 'total_loss': -0.11577355083101887, 'approx_kl': 0.015693470370024443, 'clip_fraction': 0.3294270858168602, 'grad_norm': 13.64560604095459}
2023-01-03 22:40:41.016 DEBUG: Taking gradient step
2023-01-03 22:40:41.024 DEBUG: Loss 4: {'policy_loss': -0.02924558748762811, 'entropy_loss': -0.07358064502477646, 'vf_loss': 6.868247322775991e-05, 'total_loss': -0.1027575500391768, 'approx_kl': 0.03295416384935379, 'clip_fraction': 0.3658854179084301, 'grad_norm': 9.433738708496094}
2023-01-03 22:40:42.054 DEBUG: Taking gradient step
2023-01-03 22:40:42.063 DEBUG: Loss 5: {'policy_loss': -0.061770515586814956, 'entropy_loss': -0.07274546101689339, 'vf_loss': 6.820369292065846e-05, 'total_loss': -0.1344477729107877, 'approx_kl': 0.033204466104507446, 'clip_fraction': 0.4361979216337204, 'grad_norm': 7.5794758796691895}
2023-01-03 22:40:43.071 DEBUG: Early stopping at step 6 for reaching max KL.
2023-01-03 22:40:43.071 INFO: Optimization: policy loss=-0.062, vf loss=0.000, entropy loss=-0.073, total loss=-0.134, num steps=6
2023-01-03 22:40:43.072 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 22:40:44.702 INFO: Evaluation rollout: return=0.626 (0.0), episode length=6.0
2023-01-03 22:40:44.703 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 22:40:44.706 INFO: Iteration: 128/137, steps: 27648
2023-01-03 22:40:54.953 DEBUG: Atoms are too close
2023-01-03 22:41:01.424 DEBUG: Atoms are too close
2023-01-03 22:41:27.404 DEBUG: Atoms are too close
2023-01-03 22:41:38.925 INFO: Training rollout: return=-0.887 (5.1), episode length=5.9
2023-01-03 22:41:38.926 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 22:41:38.929 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-27648_train.pkl
2023-01-03 22:41:39.952 DEBUG: Taking gradient step
2023-01-03 22:41:39.961 DEBUG: Loss 0: {'policy_loss': -0.02029209165767972, 'entropy_loss': -0.07258286699652672, 'vf_loss': 0.008765044461013108, 'total_loss': -0.08410991419319336, 'approx_kl': 5.766438881948943e-08, 'clip_fraction': 0.0, 'grad_norm': 17.389341354370117}
2023-01-03 22:41:40.959 DEBUG: Taking gradient step
2023-01-03 22:41:40.968 DEBUG: Loss 1: {'policy_loss': -0.04549960400371755, 'entropy_loss': -0.07197244092822075, 'vf_loss': 0.008298329536481377, 'total_loss': -0.10917371539545692, 'approx_kl': 0.011905997293069959, 'clip_fraction': 0.05208333395421505, 'grad_norm': 5.566745758056641}
2023-01-03 22:41:41.936 DEBUG: Taking gradient step
2023-01-03 22:41:41.944 DEBUG: Loss 2: {'policy_loss': -0.018749250181233114, 'entropy_loss': -0.07191607914865017, 'vf_loss': 0.010041719620614953, 'total_loss': -0.08062360970926832, 'approx_kl': 0.01686529628932476, 'clip_fraction': 0.1861979179084301, 'grad_norm': 4.585319519042969}
2023-01-03 22:41:42.956 DEBUG: Taking gradient step
2023-01-03 22:41:42.964 DEBUG: Loss 3: {'policy_loss': -0.004247227668061938, 'entropy_loss': -0.07196077518165112, 'vf_loss': 0.010149220490849504, 'total_loss': -0.06605878235886353, 'approx_kl': 0.01666116714477539, 'clip_fraction': 0.2395833358168602, 'grad_norm': 6.048854351043701}
2023-01-03 22:41:43.964 DEBUG: Taking gradient step
2023-01-03 22:41:43.973 DEBUG: Loss 4: {'policy_loss': -0.0034578504669614575, 'entropy_loss': -0.07375788688659668, 'vf_loss': 0.010133342696437396, 'total_loss': -0.06708239465712074, 'approx_kl': 0.027151985559612513, 'clip_fraction': 0.3463541716337204, 'grad_norm': 20.48443031311035}
2023-01-03 22:41:44.987 DEBUG: Taking gradient step
2023-01-03 22:41:44.997 DEBUG: Loss 5: {'policy_loss': -0.044093624825628015, 'entropy_loss': -0.07307224906980991, 'vf_loss': 0.008589704715814085, 'total_loss': -0.10857616917962384, 'approx_kl': 0.013629501685500145, 'clip_fraction': 0.3541666716337204, 'grad_norm': 3.8894362449645996}
2023-01-03 22:41:46.015 DEBUG: Taking gradient step
2023-01-03 22:41:46.025 DEBUG: Loss 6: {'policy_loss': -0.03230581805025826, 'entropy_loss': -0.07315336354076862, 'vf_loss': 0.009474303528448273, 'total_loss': -0.0959848780625786, 'approx_kl': 0.02086835098452866, 'clip_fraction': 0.2903645858168602, 'grad_norm': 4.34827995300293}
2023-01-03 22:41:47.023 DEBUG: Taking gradient step
2023-01-03 22:41:47.033 DEBUG: Loss 7: {'policy_loss': -0.003240769955269021, 'entropy_loss': -0.07331543043255806, 'vf_loss': 0.010451675831704137, 'total_loss': -0.06610452455612295, 'approx_kl': 0.02253873716108501, 'clip_fraction': 0.328125, 'grad_norm': 5.175955772399902}
2023-01-03 22:41:48.032 DEBUG: Early stopping at step 8 for reaching max KL.
2023-01-03 22:41:48.032 INFO: Optimization: policy loss=-0.003, vf loss=0.010, entropy loss=-0.073, total loss=-0.066, num steps=8
2023-01-03 22:41:48.032 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 22:41:49.651 INFO: Evaluation rollout: return=0.620 (0.0), episode length=6.0
2023-01-03 22:41:49.652 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 22:41:49.656 INFO: Iteration: 129/137, steps: 27864
2023-01-03 22:42:44.575 INFO: Training rollout: return=0.569 (0.1), episode length=6.0
2023-01-03 22:42:44.577 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 22:42:44.579 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-27864_train.pkl
2023-01-03 22:42:45.609 DEBUG: Taking gradient step
2023-01-03 22:42:45.618 DEBUG: Loss 0: {'policy_loss': 0.009044679637768602, 'entropy_loss': -0.07372096367180347, 'vf_loss': 7.637377877280655e-05, 'total_loss': -0.06459991025526207, 'approx_kl': 8.416827768087387e-08, 'clip_fraction': 0.0, 'grad_norm': 9.878711700439453}
2023-01-03 22:42:46.637 DEBUG: Taking gradient step
2023-01-03 22:42:46.646 DEBUG: Loss 1: {'policy_loss': -0.029631586246346844, 'entropy_loss': -0.07307401113212109, 'vf_loss': 8.468117240924744e-05, 'total_loss': -0.10262091620605868, 'approx_kl': 0.021282371366396546, 'clip_fraction': 0.10026041697710752, 'grad_norm': 11.42519760131836}
2023-01-03 22:42:47.670 DEBUG: Early stopping at step 2 for reaching max KL.
2023-01-03 22:42:47.670 INFO: Optimization: policy loss=-0.030, vf loss=0.000, entropy loss=-0.073, total loss=-0.103, num steps=2
2023-01-03 22:42:47.670 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 22:42:49.320 INFO: Evaluation rollout: return=0.618 (0.0), episode length=6.0
2023-01-03 22:42:49.321 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 22:42:49.324 INFO: Iteration: 130/137, steps: 28080
2023-01-03 22:43:41.202 DEBUG: There is a single atom floating around
2023-01-03 22:43:43.988 INFO: Training rollout: return=0.211 (2.2), episode length=6.0
2023-01-03 22:43:43.990 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 22:43:43.992 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-28080_train.pkl
2023-01-03 22:43:45.037 DEBUG: Taking gradient step
2023-01-03 22:43:45.047 DEBUG: Loss 0: {'policy_loss': 0.12269129857572847, 'entropy_loss': -0.07395084574818611, 'vf_loss': 0.00709631519075281, 'total_loss': 0.05583676801829518, 'approx_kl': 3.449774155228624e-08, 'clip_fraction': 0.0, 'grad_norm': 43.64931869506836}
2023-01-03 22:43:46.076 DEBUG: Taking gradient step
2023-01-03 22:43:46.086 DEBUG: Loss 1: {'policy_loss': 0.006532932706293834, 'entropy_loss': -0.07285175658762455, 'vf_loss': 0.004135014055884013, 'total_loss': -0.062183809825446704, 'approx_kl': 0.009081096388399601, 'clip_fraction': 0.10677083395421505, 'grad_norm': 13.52505874633789}
2023-01-03 22:43:47.093 DEBUG: Taking gradient step
2023-01-03 22:43:47.102 DEBUG: Loss 2: {'policy_loss': -0.03699706191017178, 'entropy_loss': -0.07329787127673626, 'vf_loss': 0.0032488158088304817, 'total_loss': -0.10704611737807757, 'approx_kl': 0.026245954679325223, 'clip_fraction': 0.2916666716337204, 'grad_norm': 4.814055919647217}
2023-01-03 22:43:48.122 DEBUG: Taking gradient step
2023-01-03 22:43:48.132 DEBUG: Loss 3: {'policy_loss': -0.0152064836305858, 'entropy_loss': -0.07335186190903187, 'vf_loss': 0.003571278603726913, 'total_loss': -0.08498706693589075, 'approx_kl': 0.028850328642874956, 'clip_fraction': 0.3411458358168602, 'grad_norm': 3.7857069969177246}
2023-01-03 22:43:49.110 DEBUG: Taking gradient step
2023-01-03 22:43:49.120 DEBUG: Loss 4: {'policy_loss': -0.003993610432500457, 'entropy_loss': -0.07365706004202366, 'vf_loss': 0.004474755175011055, 'total_loss': -0.07317591529951306, 'approx_kl': 0.03914773045107722, 'clip_fraction': 0.3645833358168602, 'grad_norm': 2.9209988117218018}
2023-01-03 22:43:50.139 DEBUG: Early stopping at step 5 for reaching max KL.
2023-01-03 22:43:50.140 INFO: Optimization: policy loss=-0.004, vf loss=0.004, entropy loss=-0.074, total loss=-0.073, num steps=5
2023-01-03 22:43:50.140 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 22:43:51.786 INFO: Evaluation rollout: return=0.616 (0.0), episode length=6.0
2023-01-03 22:43:51.788 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 22:43:51.792 DEBUG: Deleting old model: runs/CH3NO_baseline/models/CH3NO_baseline_run-1_steps-26136.model
2023-01-03 22:43:51.796 DEBUG: Saving model: runs/CH3NO_baseline/models/CH3NO_baseline_run-1_steps-28296.model
2023-01-03 22:43:51.825 INFO: Iteration: 131/137, steps: 28296
2023-01-03 22:44:09.545 DEBUG: Atoms are too close
2023-01-03 22:44:37.379 DEBUG: Atoms are too close
2023-01-03 22:44:46.753 INFO: Training rollout: return=-0.322 (3.7), episode length=5.9
2023-01-03 22:44:46.755 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 22:44:46.757 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-28296_train.pkl
2023-01-03 22:44:47.761 DEBUG: Taking gradient step
2023-01-03 22:44:47.770 DEBUG: Loss 0: {'policy_loss': -0.0337271612369195, 'entropy_loss': -0.07527796365320683, 'vf_loss': 0.005907771339399384, 'total_loss': -0.10309735355072694, 'approx_kl': -4.18319050510263e-08, 'clip_fraction': 0.0, 'grad_norm': 12.217342376708984}
2023-01-03 22:44:48.803 DEBUG: Taking gradient step
2023-01-03 22:44:48.813 DEBUG: Loss 1: {'policy_loss': -0.008918086782116162, 'entropy_loss': -0.07425124943256378, 'vf_loss': 0.006774437025030706, 'total_loss': -0.07639489918964924, 'approx_kl': 0.0014663792680948973, 'clip_fraction': 0.14583333395421505, 'grad_norm': 21.210508346557617}
2023-01-03 22:44:49.844 DEBUG: Taking gradient step
2023-01-03 22:44:49.853 DEBUG: Loss 2: {'policy_loss': -0.018924514521992526, 'entropy_loss': -0.07465958222746849, 'vf_loss': 0.0067709570901958605, 'total_loss': -0.08681313965926515, 'approx_kl': 0.024198728031478822, 'clip_fraction': 0.2890625, 'grad_norm': 16.860794067382812}
2023-01-03 22:44:50.871 DEBUG: Early stopping at step 3 for reaching max KL.
2023-01-03 22:44:50.872 INFO: Optimization: policy loss=-0.019, vf loss=0.007, entropy loss=-0.075, total loss=-0.087, num steps=3
2023-01-03 22:44:50.872 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 22:44:52.490 INFO: Evaluation rollout: return=0.618 (0.0), episode length=6.0
2023-01-03 22:44:52.491 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 22:44:52.494 INFO: Iteration: 132/137, steps: 28512
2023-01-03 22:45:35.000 DEBUG: Atoms are too close
2023-01-03 22:45:47.916 INFO: Training rollout: return=-0.020 (3.6), episode length=5.9
2023-01-03 22:45:47.918 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 22:45:47.921 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-28512_train.pkl
2023-01-03 22:45:48.965 DEBUG: Taking gradient step
2023-01-03 22:45:48.974 DEBUG: Loss 0: {'policy_loss': -0.01586828975534614, 'entropy_loss': -0.07487879879772663, 'vf_loss': 0.002418509480090763, 'total_loss': -0.088328579072982, 'approx_kl': 9.266659617424011e-08, 'clip_fraction': 0.0, 'grad_norm': 10.780425071716309}
2023-01-03 22:45:49.996 DEBUG: Taking gradient step
2023-01-03 22:45:50.006 DEBUG: Loss 1: {'policy_loss': -0.025989954958384222, 'entropy_loss': -0.07516244612634182, 'vf_loss': 0.0024218556937331244, 'total_loss': -0.09873054539099291, 'approx_kl': 0.01286473823711276, 'clip_fraction': 0.2005208358168602, 'grad_norm': 3.591017246246338}
2023-01-03 22:45:51.033 DEBUG: Taking gradient step
2023-01-03 22:45:51.043 DEBUG: Loss 2: {'policy_loss': -0.02662021179934725, 'entropy_loss': -0.07493456825613976, 'vf_loss': 0.0024222501607058236, 'total_loss': -0.09913252989478119, 'approx_kl': 0.024829465430229902, 'clip_fraction': 0.3151041716337204, 'grad_norm': 3.3714659214019775}
2023-01-03 22:45:51.961 DEBUG: Taking gradient step
2023-01-03 22:45:51.970 DEBUG: Loss 3: {'policy_loss': -0.029428953100563343, 'entropy_loss': -0.07504275068640709, 'vf_loss': 0.0024202400139565045, 'total_loss': -0.10205146377301391, 'approx_kl': 0.006936301942914724, 'clip_fraction': 0.3723958358168602, 'grad_norm': 2.4978160858154297}
2023-01-03 22:45:52.989 DEBUG: Taking gradient step
2023-01-03 22:45:52.999 DEBUG: Loss 4: {'policy_loss': -0.030387692171888962, 'entropy_loss': -0.07438338734209538, 'vf_loss': 0.002420116860013081, 'total_loss': -0.10235096265397126, 'approx_kl': 0.023442185949534178, 'clip_fraction': 0.4049479216337204, 'grad_norm': 2.1551694869995117}
2023-01-03 22:45:54.017 DEBUG: Taking gradient step
2023-01-03 22:45:54.027 DEBUG: Loss 5: {'policy_loss': -0.0288974297598424, 'entropy_loss': -0.07519679330289364, 'vf_loss': 0.0024163404885616294, 'total_loss': -0.1016778825741744, 'approx_kl': 0.01611301163211465, 'clip_fraction': 0.4466145858168602, 'grad_norm': 2.018754005432129}
2023-01-03 22:45:55.060 DEBUG: Taking gradient step
2023-01-03 22:45:55.069 DEBUG: Loss 6: {'policy_loss': -0.03047715560625157, 'entropy_loss': -0.07404955849051476, 'vf_loss': 0.002414194218691043, 'total_loss': -0.10211251987807529, 'approx_kl': -0.008313882164657116, 'clip_fraction': 0.4375, 'grad_norm': 1.7130306959152222}
2023-01-03 22:45:56.063 DEBUG: Taking gradient step
2023-01-03 22:45:56.073 DEBUG: Loss 7: {'policy_loss': 0.009677174742190417, 'entropy_loss': -0.07565137930214405, 'vf_loss': 0.003614220231509131, 'total_loss': -0.062359984328444515, 'approx_kl': -0.04788958188146353, 'clip_fraction': 0.5130208432674408, 'grad_norm': 1.8215627670288086}
2023-01-03 22:45:57.090 DEBUG: Taking gradient step
2023-01-03 22:45:57.100 DEBUG: Loss 8: {'policy_loss': -0.0341018245899092, 'entropy_loss': -0.07533147372305393, 'vf_loss': 0.002400365201052821, 'total_loss': -0.10703293311191031, 'approx_kl': -0.05881397030316293, 'clip_fraction': 0.5403645932674408, 'grad_norm': 1.7366182804107666}
2023-01-03 22:45:58.128 DEBUG: Taking gradient step
2023-01-03 22:45:58.138 DEBUG: Loss 9: {'policy_loss': 0.018085197749526175, 'entropy_loss': -0.07587610185146332, 'vf_loss': 0.004117225553231306, 'total_loss': -0.05367367854870584, 'approx_kl': -0.047533102333545685, 'clip_fraction': 0.5208333432674408, 'grad_norm': 1.565190076828003}
2023-01-03 22:45:59.156 DEBUG: Taking gradient step
2023-01-03 22:45:59.167 DEBUG: Loss 10: {'policy_loss': 0.0018401923627857225, 'entropy_loss': -0.07658728584647179, 'vf_loss': 0.00327550369141477, 'total_loss': -0.0714715897922713, 'approx_kl': -0.025998189579695463, 'clip_fraction': 0.5403645932674408, 'grad_norm': 1.8388290405273438}
2023-01-03 22:46:00.194 DEBUG: Taking gradient step
2023-01-03 22:46:00.203 DEBUG: Loss 11: {'policy_loss': -0.04132578492939603, 'entropy_loss': -0.07698849961161613, 'vf_loss': 0.002385889371781534, 'total_loss': -0.11592839516923063, 'approx_kl': -0.024502180516719818, 'clip_fraction': 0.4296875, 'grad_norm': 2.355020761489868}
2023-01-03 22:46:01.192 DEBUG: Taking gradient step
2023-01-03 22:46:01.200 DEBUG: Loss 12: {'policy_loss': 0.008112142265143375, 'entropy_loss': -0.07694409415125847, 'vf_loss': 0.0035790643244954286, 'total_loss': -0.06525288756161968, 'approx_kl': -0.012377585750073195, 'clip_fraction': 0.3893229216337204, 'grad_norm': 4.288897514343262}
2023-01-03 22:46:02.219 DEBUG: Taking gradient step
2023-01-03 22:46:02.227 DEBUG: Loss 13: {'policy_loss': -0.03667040680589637, 'entropy_loss': -0.07738146185874939, 'vf_loss': 0.0023718674840603592, 'total_loss': -0.11168000118058541, 'approx_kl': -0.0035005584359169006, 'clip_fraction': 0.5286458432674408, 'grad_norm': 1.9748101234436035}
2023-01-03 22:46:03.249 DEBUG: Taking gradient step
2023-01-03 22:46:03.259 DEBUG: Loss 14: {'policy_loss': -0.0014602291197171671, 'entropy_loss': -0.07760998420417309, 'vf_loss': 0.0032534056748920906, 'total_loss': -0.07581680764899817, 'approx_kl': -0.01653136033564806, 'clip_fraction': 0.57421875, 'grad_norm': 1.5891886949539185}
2023-01-03 22:46:03.259 INFO: Optimization: policy loss=-0.001, vf loss=0.003, entropy loss=-0.078, total loss=-0.076, num steps=15
2023-01-03 22:46:03.260 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 22:46:04.874 INFO: Evaluation rollout: return=0.571 (0.0), episode length=6.0
2023-01-03 22:46:04.875 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 22:46:04.879 INFO: Iteration: 133/137, steps: 28728
2023-01-03 22:46:17.170 DEBUG: Atoms are too close
2023-01-03 22:46:34.274 DEBUG: Atoms are too close
2023-01-03 22:46:59.111 INFO: Training rollout: return=-0.415 (4.0), episode length=5.9
2023-01-03 22:46:59.112 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 22:46:59.115 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-28728_train.pkl
2023-01-03 22:47:00.154 DEBUG: Taking gradient step
2023-01-03 22:47:00.163 DEBUG: Loss 0: {'policy_loss': -0.03156156153998885, 'entropy_loss': -0.07734950445592403, 'vf_loss': 0.00574138285262638, 'total_loss': -0.1031696831432865, 'approx_kl': 1.0035000741481781e-07, 'clip_fraction': 0.0, 'grad_norm': 25.777240753173828}
2023-01-03 22:47:01.182 DEBUG: Taking gradient step
2023-01-03 22:47:01.192 DEBUG: Loss 1: {'policy_loss': -0.04023400766233366, 'entropy_loss': -0.07699532434344292, 'vf_loss': 0.0057425650107446055, 'total_loss': -0.11148676699503197, 'approx_kl': 0.001962087582796812, 'clip_fraction': 0.045572916977107525, 'grad_norm': 6.618778705596924}
2023-01-03 22:47:02.208 DEBUG: Taking gradient step
2023-01-03 22:47:02.219 DEBUG: Loss 2: {'policy_loss': -0.008987225415069008, 'entropy_loss': -0.07709844224154949, 'vf_loss': 0.00747980269422727, 'total_loss': -0.07860586496239123, 'approx_kl': 0.009824909968301654, 'clip_fraction': 0.1497395858168602, 'grad_norm': 5.91033411026001}
2023-01-03 22:47:03.249 DEBUG: Taking gradient step
2023-01-03 22:47:03.260 DEBUG: Loss 3: {'policy_loss': -0.01917052419298418, 'entropy_loss': -0.07659325003623962, 'vf_loss': 0.006985933176836405, 'total_loss': -0.0887778410523874, 'approx_kl': 0.005843486404046416, 'clip_fraction': 0.2721354216337204, 'grad_norm': 10.033076286315918}
2023-01-03 22:47:04.318 DEBUG: Taking gradient step
2023-01-03 22:47:04.329 DEBUG: Loss 4: {'policy_loss': -0.017397954325563444, 'entropy_loss': -0.07703850418329239, 'vf_loss': 0.007477883680207433, 'total_loss': -0.08695857482864841, 'approx_kl': 0.024930436396971345, 'clip_fraction': 0.36328125, 'grad_norm': 3.772952079772949}
2023-01-03 22:47:05.377 DEBUG: Early stopping at step 5 for reaching max KL.
2023-01-03 22:47:05.377 INFO: Optimization: policy loss=-0.017, vf loss=0.007, entropy loss=-0.077, total loss=-0.087, num steps=5
2023-01-03 22:47:05.378 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 22:47:07.031 INFO: Evaluation rollout: return=0.593 (0.0), episode length=6.0
2023-01-03 22:47:07.033 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 22:47:07.036 INFO: Iteration: 134/137, steps: 28944
2023-01-03 22:48:02.005 INFO: Training rollout: return=0.609 (0.0), episode length=6.0
2023-01-03 22:48:02.006 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 22:48:02.008 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-28944_train.pkl
2023-01-03 22:48:03.056 DEBUG: Taking gradient step
2023-01-03 22:48:03.066 DEBUG: Loss 0: {'policy_loss': -0.006605291794403017, 'entropy_loss': -0.07577569782733917, 'vf_loss': 8.153222214788127e-05, 'total_loss': -0.08229945739959431, 'approx_kl': 2.250696218286663e-08, 'clip_fraction': 0.0, 'grad_norm': 17.50529670715332}
2023-01-03 22:48:04.094 DEBUG: Taking gradient step
2023-01-03 22:48:04.103 DEBUG: Loss 1: {'policy_loss': -0.0406458109886276, 'entropy_loss': -0.07625297456979752, 'vf_loss': 8.258992169521375e-05, 'total_loss': -0.1168161956367299, 'approx_kl': 0.009051190689206123, 'clip_fraction': 0.07161458395421505, 'grad_norm': 11.086581230163574}
2023-01-03 22:48:05.121 DEBUG: Early stopping at step 2 for reaching max KL.
2023-01-03 22:48:05.121 INFO: Optimization: policy loss=-0.041, vf loss=0.000, entropy loss=-0.076, total loss=-0.117, num steps=2
2023-01-03 22:48:05.121 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 22:48:06.764 INFO: Evaluation rollout: return=0.592 (0.0), episode length=6.0
2023-01-03 22:48:06.765 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 22:48:06.767 INFO: Iteration: 135/137, steps: 29160
2023-01-03 22:49:01.520 INFO: Training rollout: return=0.576 (0.1), episode length=6.0
2023-01-03 22:49:01.521 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 22:49:01.524 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-29160_train.pkl
2023-01-03 22:49:02.579 DEBUG: Taking gradient step
2023-01-03 22:49:02.589 DEBUG: Loss 0: {'policy_loss': 0.019092763142991243, 'entropy_loss': -0.07732975669205189, 'vf_loss': 7.153767824472367e-05, 'total_loss': -0.058165455870815924, 'approx_kl': -7.714455385610108e-08, 'clip_fraction': 0.0, 'grad_norm': 11.021799087524414}
2023-01-03 22:49:03.611 DEBUG: Taking gradient step
2023-01-03 22:49:03.620 DEBUG: Loss 1: {'policy_loss': 0.005542428810015716, 'entropy_loss': -0.07719908095896244, 'vf_loss': 7.438674068274302e-05, 'total_loss': -0.07158226540826398, 'approx_kl': 8.207769133150578e-05, 'clip_fraction': 0.15625, 'grad_norm': 12.666065216064453}
2023-01-03 22:49:04.609 DEBUG: Taking gradient step
2023-01-03 22:49:04.617 DEBUG: Loss 2: {'policy_loss': -0.025307516189850048, 'entropy_loss': -0.07766494899988174, 'vf_loss': 7.74358845323417e-05, 'total_loss': -0.10289502930519945, 'approx_kl': 0.009936967864632607, 'clip_fraction': 0.2421875, 'grad_norm': 17.24884033203125}
2023-01-03 22:49:05.657 DEBUG: Taking gradient step
2023-01-03 22:49:05.666 DEBUG: Loss 3: {'policy_loss': 0.012895054482766136, 'entropy_loss': -0.07777253165841103, 'vf_loss': 7.421267965341527e-05, 'total_loss': -0.06480326449599146, 'approx_kl': 0.023749222047626972, 'clip_fraction': 0.3203125, 'grad_norm': 19.285043716430664}
2023-01-03 22:49:06.692 DEBUG: Taking gradient step
2023-01-03 22:49:06.701 DEBUG: Loss 4: {'policy_loss': 0.003774817383797105, 'entropy_loss': -0.07764251716434956, 'vf_loss': 7.145192371851129e-05, 'total_loss': -0.07379624785683393, 'approx_kl': 0.02668548049405217, 'clip_fraction': 0.28125, 'grad_norm': 8.279462814331055}
2023-01-03 22:49:07.730 DEBUG: Taking gradient step
2023-01-03 22:49:07.739 DEBUG: Loss 5: {'policy_loss': -0.05467566902878146, 'entropy_loss': -0.07713168486952782, 'vf_loss': 7.550540730785897e-05, 'total_loss': -0.13173184849100142, 'approx_kl': 0.0241579907014966, 'clip_fraction': 0.2981770858168602, 'grad_norm': 10.0615234375}
2023-01-03 22:49:08.748 DEBUG: Taking gradient step
2023-01-03 22:49:08.759 DEBUG: Loss 6: {'policy_loss': -0.034698825094315655, 'entropy_loss': -0.07781262323260307, 'vf_loss': 7.283292020616517e-05, 'total_loss': -0.11243861540671256, 'approx_kl': 0.03218845510855317, 'clip_fraction': 0.4270833358168602, 'grad_norm': 11.02308177947998}
2023-01-03 22:49:09.783 DEBUG: Early stopping at step 7 for reaching max KL.
2023-01-03 22:49:09.784 INFO: Optimization: policy loss=-0.035, vf loss=0.000, entropy loss=-0.078, total loss=-0.112, num steps=7
2023-01-03 22:49:09.784 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 22:49:11.399 INFO: Evaluation rollout: return=0.596 (0.0), episode length=6.0
2023-01-03 22:49:11.400 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 22:49:11.402 INFO: Iteration: 136/137, steps: 29376
2023-01-03 22:49:26.941 DEBUG: Atoms are too close
2023-01-03 22:50:06.185 INFO: Training rollout: return=0.226 (2.2), episode length=6.0
2023-01-03 22:50:06.186 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 22:50:06.189 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-29376_train.pkl
2023-01-03 22:50:07.296 DEBUG: Taking gradient step
2023-01-03 22:50:07.306 DEBUG: Loss 0: {'policy_loss': -0.025264031573455695, 'entropy_loss': -0.07643592171370983, 'vf_loss': 0.003269718155830029, 'total_loss': -0.0984302351313355, 'approx_kl': -1.026783138513565e-07, 'clip_fraction': 0.0, 'grad_norm': 20.880237579345703}
2023-01-03 22:50:08.436 DEBUG: Taking gradient step
2023-01-03 22:50:08.445 DEBUG: Loss 1: {'policy_loss': -0.04141310398258273, 'entropy_loss': -0.07563784718513489, 'vf_loss': 0.003276614243817788, 'total_loss': -0.11377433692389982, 'approx_kl': 0.01539770420640707, 'clip_fraction': 0.03125, 'grad_norm': 5.298349380493164}
2023-01-03 22:50:09.566 DEBUG: Taking gradient step
2023-01-03 22:50:09.576 DEBUG: Loss 2: {'policy_loss': -0.043802311346633795, 'entropy_loss': -0.07591854594647884, 'vf_loss': 0.0032747398163461517, 'total_loss': -0.11644611747676649, 'approx_kl': 0.02349582896567881, 'clip_fraction': 0.10807291697710752, 'grad_norm': 4.579495906829834}
2023-01-03 22:50:10.695 DEBUG: Taking gradient step
2023-01-03 22:50:10.711 DEBUG: Loss 3: {'policy_loss': -0.04697549822815158, 'entropy_loss': -0.07689330354332924, 'vf_loss': 0.003269741013319767, 'total_loss': -0.12059906075816104, 'approx_kl': 0.01367949740961194, 'clip_fraction': 0.2513020858168602, 'grad_norm': 3.130214214324951}
2023-01-03 22:50:11.848 DEBUG: Taking gradient step
2023-01-03 22:50:11.862 DEBUG: Loss 4: {'policy_loss': -0.047579729342407645, 'entropy_loss': -0.07636754773557186, 'vf_loss': 0.003269336077598352, 'total_loss': -0.12067794100038115, 'approx_kl': 0.02721481816843152, 'clip_fraction': 0.3177083358168602, 'grad_norm': 2.284581422805786}
2023-01-03 22:50:12.934 DEBUG: Taking gradient step
2023-01-03 22:50:12.943 DEBUG: Loss 5: {'policy_loss': -0.02444728294519278, 'entropy_loss': -0.07632414065301418, 'vf_loss': 0.003711354350979303, 'total_loss': -0.09706006924722765, 'approx_kl': 0.0027016322128474712, 'clip_fraction': 0.4192708358168602, 'grad_norm': 1.668731927871704}
2023-01-03 22:50:13.943 DEBUG: Taking gradient step
2023-01-03 22:50:13.952 DEBUG: Loss 6: {'policy_loss': -0.04506980410056873, 'entropy_loss': -0.07628133147954941, 'vf_loss': 0.0032635922267507007, 'total_loss': -0.11808754335336744, 'approx_kl': 0.04003162030130625, 'clip_fraction': 0.48046875, 'grad_norm': 1.9933189153671265}
2023-01-03 22:50:14.990 DEBUG: Taking gradient step
2023-01-03 22:50:15.000 DEBUG: Loss 7: {'policy_loss': -0.027959638207275594, 'entropy_loss': -0.0764255803078413, 'vf_loss': 0.003576697434353032, 'total_loss': -0.10080852108076385, 'approx_kl': 0.004643554566428065, 'clip_fraction': 0.44140625, 'grad_norm': 1.8157888650894165}
2023-01-03 22:50:16.039 DEBUG: Taking gradient step
2023-01-03 22:50:16.049 DEBUG: Loss 8: {'policy_loss': -0.053654039942990665, 'entropy_loss': -0.07659711688756943, 'vf_loss': 0.0032483036427310547, 'total_loss': -0.12700285318782903, 'approx_kl': -0.02384992386214435, 'clip_fraction': 0.42578125, 'grad_norm': 1.6036802530288696}
2023-01-03 22:50:17.085 DEBUG: Taking gradient step
2023-01-03 22:50:17.095 DEBUG: Loss 9: {'policy_loss': 0.036729187416136344, 'entropy_loss': -0.07772611826658249, 'vf_loss': 0.00585518082136397, 'total_loss': -0.03514175002908217, 'approx_kl': 0.01981647708453238, 'clip_fraction': 0.37890625, 'grad_norm': 11.194544792175293}
2023-01-03 22:50:18.068 DEBUG: Taking gradient step
2023-01-03 22:50:18.077 DEBUG: Loss 10: {'policy_loss': 0.022023101635917995, 'entropy_loss': -0.07730906829237938, 'vf_loss': 0.005344340470380493, 'total_loss': -0.04994162618608089, 'approx_kl': 0.0011876900680363178, 'clip_fraction': 0.34765625, 'grad_norm': 10.105329513549805}
2023-01-03 22:50:19.177 DEBUG: Taking gradient step
2023-01-03 22:50:19.191 DEBUG: Loss 11: {'policy_loss': 0.0005677743115518261, 'entropy_loss': -0.07700304873287678, 'vf_loss': 0.004935606269441502, 'total_loss': -0.07149966815188345, 'approx_kl': 0.030062923207879066, 'clip_fraction': 0.421875, 'grad_norm': 2.718322277069092}
2023-01-03 22:50:20.358 DEBUG: Taking gradient step
2023-01-03 22:50:20.372 DEBUG: Loss 12: {'policy_loss': -0.04422704715713486, 'entropy_loss': -0.077010877430439, 'vf_loss': 0.00319546127402436, 'total_loss': -0.1180424633135495, 'approx_kl': 0.019190408289432526, 'clip_fraction': 0.3932291716337204, 'grad_norm': 3.8450820446014404}
2023-01-03 22:50:21.545 DEBUG: Taking gradient step
2023-01-03 22:50:21.560 DEBUG: Loss 13: {'policy_loss': -0.02142744464725476, 'entropy_loss': -0.07731801643967628, 'vf_loss': 0.00379765291470074, 'total_loss': -0.09494780817223031, 'approx_kl': 0.0024592974223196507, 'clip_fraction': 0.3828125, 'grad_norm': 3.897918224334717}
2023-01-03 22:50:22.695 DEBUG: Taking gradient step
2023-01-03 22:50:22.708 DEBUG: Loss 14: {'policy_loss': -0.05021687557425913, 'entropy_loss': -0.07735846564173698, 'vf_loss': 0.003183776902199578, 'total_loss': -0.12439156431379653, 'approx_kl': -0.017761964350938797, 'clip_fraction': 0.3619791716337204, 'grad_norm': 2.4198622703552246}
2023-01-03 22:50:22.709 INFO: Optimization: policy loss=-0.050, vf loss=0.003, entropy loss=-0.077, total loss=-0.124, num steps=15
2023-01-03 22:50:22.709 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 22:50:24.384 INFO: Evaluation rollout: return=0.335 (0.0), episode length=6.0
2023-01-03 22:50:24.386 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 22:50:24.388 INFO: Iteration: 137/137, steps: 29592
2023-01-03 22:51:19.827 INFO: Training rollout: return=0.579 (0.0), episode length=6.0
2023-01-03 22:51:19.828 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_train.txt
2023-01-03 22:51:19.831 DEBUG: Saving rollout: runs/CH3NO_baseline/data/CH3NO_baseline_run-1_steps-29592_train.pkl
2023-01-03 22:51:20.884 DEBUG: Taking gradient step
2023-01-03 22:51:20.894 DEBUG: Loss 0: {'policy_loss': 0.058079666346887354, 'entropy_loss': -0.07871592231094837, 'vf_loss': 0.00010348790075059963, 'total_loss': -0.020532768063310405, 'approx_kl': -9.441282600164413e-08, 'clip_fraction': 0.0, 'grad_norm': 13.974729537963867}
2023-01-03 22:51:21.930 DEBUG: Taking gradient step
2023-01-03 22:51:21.941 DEBUG: Loss 1: {'policy_loss': 0.028967274295043192, 'entropy_loss': -0.07849711738526821, 'vf_loss': 0.0001093296383893448, 'total_loss': -0.04942051345183567, 'approx_kl': 0.01297719357535243, 'clip_fraction': 0.06640625, 'grad_norm': 12.916889190673828}
2023-01-03 22:51:22.939 DEBUG: Taking gradient step
2023-01-03 22:51:22.949 DEBUG: Loss 2: {'policy_loss': -0.0017405843199456358, 'entropy_loss': -0.07881718687713146, 'vf_loss': 0.0001163305503361678, 'total_loss': -0.08044144064674094, 'approx_kl': 0.038758369628340006, 'clip_fraction': 0.29296875, 'grad_norm': 10.263948440551758}
2023-01-03 22:51:23.978 DEBUG: Early stopping at step 3 for reaching max KL.
2023-01-03 22:51:23.979 INFO: Optimization: policy loss=-0.002, vf loss=0.000, entropy loss=-0.079, total loss=-0.080, num steps=3
2023-01-03 22:51:23.979 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_opt.txt
2023-01-03 22:51:25.608 INFO: Evaluation rollout: return=0.420 (0.0), episode length=6.0
2023-01-03 22:51:25.609 DEBUG: Saving info: runs/CH3NO_baseline/results/CH3NO_baseline_run-1_eval.txt
2023-01-03 22:51:25.611 DEBUG: Deleting old model: runs/CH3NO_baseline/models/CH3NO_baseline_run-1_steps-28296.model
2023-01-03 22:51:25.615 DEBUG: Saving model: runs/CH3NO_baseline/models/CH3NO_baseline_run-1_steps-29808.model
2023-01-03 22:51:25.644 INFO: Finished PPO
